paper_id,title,authors,year,journal,type,Conference Location,pages,volume,issue,doi,Abstract,keywords,fine-tuned
Paper_00001,PROTEIN MEASUREMENT WITH THE FOLIN PHENOL REAGENT,"['OliverH. Lowry', 'NiraJ. Rosebrough', 'A. Farr', 'RoseJ. Randall']",1951,Journal of Biological Chemistry,Journal,,265-275,193,1,10.1016/s0021-9258(19)52451-6,"Since 1922 when Wu proposed the use of the Folin phenol reagent for the measurement of proteins (l), a number of modified analytical procedures ut.ilizing this reagent have been reported for the determination of proteins in serum (2-G), in antigen-antibody precipitates (7-9), and in insulin (10).Although the reagent would seem to be recommended by its great sensitivity and the simplicity of procedure possible with its use, it has not found great favor for general biochemical purposes.In the belief that this reagent, nevertheless, has considerable merit for certain application, but that its peculiarities and limitations need to be understood for its fullest exploitation, it has been studied with regard t.o effects of variations in pH, time of reaction, and concentration of reactants, permissible levels of reagents commonly used in handling proteins, and interfering subst.ances.Procedures are described for measuring protein in solution or after precipitation wit,h acids or other agents, and for the determination of as little as 0.2 y of protein. MethodReagents-Reagent A, 2 per cent N&OX in 0.10 N NaOH.Reagent B, 0.5 per cent CuS04.5Hz0 in 1 per cent sodium or potassium tartrabe.Reagent C, alkaline copper solution.Mix 50 ml. of Reagent A with 1 ml. of Reagent B. Discard after 1 day.Reagent D, carbonate-copper solution, is the same as Reagent C except for omission of NaOH.Reagent E, diluted Folin reagent.Titrate Folin-Ciocalteu phenol reagent ((II), Eimer and Amend, Fisher Scientific Company, New York) with NaOH t.o a phenolphthalein end-point.On the basis of this titration dilute the Folin reagent (about 2-fold) to make it 1 N in acid.Working standards may be prepared from human serum diluted IOO-to lOOO-fold (approximately 700 to 70 y per ml.).These in turn may be checked against a standard solution of crystalline bovine albumin (Armour and","['Reagent', 'Chemistry', 'Phenol', 'Chromatography', 'Organic chemistry']","folin phenol reagent, crystalline bovine albumin"
Paper_00006,Deep Residual Learning for Image Recognition,"['Kaiming He', 'Xiangyu Zhang', 'Shaoqing Ren', 'Jian Sun']",2016,Unknown,Unknown,,,,,10.1109/cvpr.2016.90,"Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers - 8× deeper than VGG nets [40] but still having lower complexity. An ensemble of these residual nets achieves 3.57% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC & COCO 2015 competitions1, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.","['Residual', 'Computer science', 'Coco', 'Artificial intelligence', 'Object detection', 'Deep learning', 'Segmentation', 'Pattern recognition (psychology)', 'Set (abstract data type)', 'Layer (electronics)', 'Artificial neural network', 'Task (project management)', 'Machine learning', 'Residual neural network', 'Deep neural networks', 'Algorithm', 'Chemistry', 'Management', 'Organic chemistry', 'Economics', 'Programming language']","deeper neural networks, residual learning framework, ##referenced functions, residual networks, imagenet dataset, residual nets, residual nets, image, ##s, ci, visual recognition tasks, coco object detection dataset, deep residual nets, imagenet detection, imagenet localization, coco detection, coco segmentation, [PAD] [PAD] [PAD], [PAD] [PAD] [PAD], [PAD] [PAD], [PAD], [PAD]"
Paper_00007,Generalized Gradient Approximation Made Simple,"['John P. Perdew', 'Kieron Burke', 'Matthias Ernzerhof']",1996,Physical Review Letters,Journal,,3865-3868,77,18,10.1103/physrevlett.77.3865,"Generalized gradient approximations (GGA's) for the exchange-correlation energy improve upon the local spin density (LSD) description of atoms, molecules, and solids. We present a simple derivation of a simple GGA, in which all parameters (other than those in LSD) are fundamental constants. Only general features of the detailed construction underlying the Perdew-Wang 1991 (PW91) GGA are invoked. Improvements over PW91 include an accurate description of the linear response of the uniform electron gas, correct behavior under uniform scaling, and a smoother potential.","['Simple (philosophy)', 'Scaling', 'Statistical physics', 'Linear scale', 'Physics', 'Spin density', 'Spin (aerodynamics)', 'Local-density approximation', 'Kohn–Sham equations', 'Quantum mechanics', 'Electronic structure', 'Density functional theory', 'Condensed matter physics', 'Mathematics', 'Thermodynamics', 'Geometry', 'Geodesy', 'Geography', 'Philosophy', 'Epistemology']","generalized gradient approximations, local spin density, lsd, linear response, uniform electron gas, uniform scaling, [PAD] [PAD] [PAD]"
Paper_00009,Using thematic analysis in psychology,"['Virginia Braun', 'Victoria Clarke']",2006,Qualitative Research in Psychology,Journal,,77-101,3,2,10.1191/1478088706qp063oa,"Abstract Thematic analysis is a poorly demarcated, rarely acknowledged, yet widely used qualitative analytic method within psychology. In this paper, we argue that it offers an accessible and theoretically flexible approach to analysing qualitative data. We outline what thematic analysis is, locating it in relation to other qualitative analytic methods that search for themes or patterns, and in relation to different epistemological and ontological positions. We then provide clear guidelines to those wanting to start thematic analysis, or conduct it in a more deliberate and rigorous way, and consider potential pitfalls in conducting thematic analysis. Finally, we outline the disadvantages and advantages of thematic analysis. We conclude by advocating thematic analysis as a useful and flexible method for qualitative research in and beyond psychology. Key words: epistemologyflexibilitypatternsqualitative psychologythematic analysis","['Thematic analysis', 'Thematic map', 'Qualitative analysis', 'Qualitative research', 'Relation (database)', 'Thematic structure', 'Psychology', 'Epistemology', 'Sociology', 'Computer science', 'Social science', 'Data mining', 'Philosophy', 'Cartography', 'Programming language', 'Geography']","abstract thematic analysis, qualitative analytic method, psychology, qualitative data, thematic analysis, ##tative analytic methods, thematic analysis, thematic analysis, thematic analysis, thematic analysis, epistemologyflexibilitypatternsqualitative psychologythematic analysis"
Paper_00010,Molecular Cloning: A Laboratory Manual,"['Joseph Sambrook', 'Elisabeth Fritsch', 'Tom Maniatis']",2001,['Analytical Biochemistry'],Unknown,,182-183,186,1,10.1016/0003-2697(90)90595-z,"Molecular Cloning has served as the foundation of technical expertise in labs worldwide for 30 years. No other manual has been so popular, or so influential. Molecular Cloning, Fourth Edition, by the celebrated founding author Joe Sambrook and new co-author, the distinguished HHMI investigator Michael Green, preserves the highly praised detail and clarity of previous editions and includes specific chapters and protocols commissioned for the book from expert practitioners at Yale, U Mass, Rockefeller University, Texas Tech, Cold Spring Harbor Laboratory, Washington University, and other leading institutions. The theoretical and historical underpinnings of techniques are prominent features of the presentation throughout, information that does much to help trouble-shoot experimental problems. For the fourth edition of this classic work, the content has been entirely recast to include nucleic-acid based methods selected as the most widely used and valuable in molecular and cellular biology laboratories. Core chapters from the third edition have been revised to feature current strategies and approaches to the preparation and cloning of nucleic acids, gene transfer, and expression analysis. They are augmented by 12 new chapters which show how DNA, RNA, and proteins should be prepared, evaluated, and manipulated, and how data generation and analysis can be handled. The new content includes methods for studying interactions between cellular components, such as microarrays, next-generation sequencing technologies, RNA interference, and epigenetic analysis using DNA methylation techniques and chromatin immunoprecipitation. To make sense of the wealth of data produced by these techniques, a bioinformatics chapter describes the use of analytical tools for comparing sequences of genes and proteins and identifying common expression patterns among sets of genes. Building on thirty years of trust, reliability, and authority, the fourth edition of Mol","['Cloning (programming)', 'Computational biology', 'Chromatin', 'CLARITY', 'Computer science', 'Data science', 'Biology', 'DNA', 'Genetics', 'Molecular biology', 'Programming language']","molecular cloning, molecular cloning, hhmi, texas, cellular biology, nucleic, gene transfer, expression analysis, microarrays, rna interference, epigenetic analysis, dna methylation techniques, chromatin immunoprecipitation, bioinformatics"
Paper_00011,Diagnostic and Statistical Manual of Mental Disorders,"['Janet B. W. Williams', 'Michael B. First']",2013,Encyclopedia of Social Work,Journal,,,,,10.1093/acrefore/9780199975839.013.104,"The fifth edition of the <italic>Diagnostic and Statistical Manual of Mental Disorders</italic> of the American Psychiatric Association is referred to as DSM-5<italic>™</italic>. DSM-5’s early predecessor, DSM-III, differed considerably from the first two editions. Its innovative incorporation of specified diagnostic criteria had a major impact on the field of mental health. In DSM-5, these criteria have been further updated to reflect the important gains in our understanding of mental disorders.","['Mental health', 'Psychiatry', 'Classification of mental disorders', 'Psychology', 'Diagnostic Classification of Mental Health and Developmental Disorders of Infancy and Early Childhood', 'Prevalence of mental disorders']","statistical manual, mental disorders, american psychiatric association, mental health, mental disorders"
Paper_00012,Efficient iterative schemes for<i>ab initio</i>total-energy calculations using a plane-wave basis set,"['Georg Kresse', 'J. Furthmüller']",1996,"Physical review. B, Condensed matter",Journal,,11169-11186,54,16,10.1103/physrevb.54.11169,"We present an efficient scheme for calculating the Kohn-Sham ground state of metallic systems using pseudopotentials and a plane-wave basis set. In the first part the application of Pulay's DIIS method (direct inversion in the iterative subspace) to the iterative diagonalization of large matrices will be discussed. Our approach is stable, reliable, and minimizes the number of order ${\mathit{N}}_{\mathrm{atoms}}^{3}$ operations. In the second part, we will discuss an efficient mixing scheme also based on Pulay's scheme. A special ``metric'' and a special ``preconditioning'' optimized for a plane-wave basis set will be introduced. Scaling of the method will be discussed in detail for non-self-consistent and self-consistent calculations. It will be shown that the number of iterations required to obtain a specific precision is almost independent of the system size. Altogether an order ${\mathit{N}}_{\mathrm{atoms}}^{2}$ scaling is found for systems containing up to 1000 electrons. If we take into account that the number of k points can be decreased linearly with the system size, the overall scaling can approach ${\mathit{N}}_{\mathrm{atoms}}$. We have implemented these algorithms within a powerful package called VASP (Vienna ab initio simulation package). The program and the techniques have been used successfully for a large number of different systems (liquid and amorphous semiconductors, liquid simple and transition metals, metallic and semiconducting surfaces, phonons in simple metals, transition metals, and semiconductors) and turned out to be very reliable. \textcopyright{} 1996 The American Physical Society.","['Scaling', 'Physics', 'Ab initio', 'Basis set', 'Basis (linear algebra)', 'Subspace topology', 'Plane wave', 'Statistical physics', 'Quantum mechanics', 'Mathematics', 'Mathematical analysis', 'Molecule', 'Geometry']","metallic systems, pseudopotentials, diis, iterative subspace, iterative diagonalization, large matrices, mixing scheme, preconditioning, vienna ab initio simulation package, amorphous semiconductors, transition metals, semi, ##cting, phonons, simple metals, transition metals"
Paper_00015,Density-functional thermochemistry. III. The role of exact exchange,['Axel D. Becke'],1993,The Journal of Chemical Physics,Journal,,5648-5652,98,7,10.1063/1.464913,"Despite the remarkable thermochemical accuracy of Kohn–Sham density-functional theories with gradient corrections for exchange-correlation [see, for example, A. D. Becke, J. Chem. Phys. 96, 2155 (1992)], we believe that further improvements are unlikely unless exact-exchange information is considered. Arguments to support this view are presented, and a semiempirical exchange-correlation functional containing local-spin-density, gradient, and exact-exchange terms is tested on 56 atomization energies, 42 ionization potentials, 8 proton affinities, and 10 total atomic energies of first- and second-row systems. This functional performs significantly better than previous functionals with gradient corrections only, and fits experimental atomization energies with an impressively small average absolute deviation of 2.4 kcal/mol.","['Thermochemistry', 'Density functional theory', 'Chemistry', 'Hybrid functional', 'Ionization', 'Orbital-free density functional theory', 'Spin density', 'Proton', 'Atomic physics', 'Local-density approximation', 'Physics', 'Computational chemistry', 'Quantum mechanics', 'Physical chemistry', 'Ion', 'Condensed matter physics', 'Organic chemistry']","thermochemical accuracy, gradient corrections, atomization energies, ionization potentials, proton affinities, [PAD] [PAD] [PAD] [PAD]"
Paper_00016,Controlling the False Discovery Rate: A Practical and Powerful Approach to Multiple Testing,"['Yoav Benjamini', 'Yosef Hochberg']",1995,Journal of the Royal Statistical Society Series B (Statistical Methodology),Journal,,289-300,57,1,10.1111/j.2517-6161.1995.tb02031.x,"SUMMARY The common approach to the multiplicity problem calls for controlling the familywise error rate (FWER). This approach, though, has faults, and we point out a few. A different approach to problems of multiple significance testing is presented. It calls for controlling the expected proportion of falsely rejected hypotheses — the false discovery rate. This error rate is equivalent to the FWER when all hypotheses are true but is smaller otherwise. Therefore, in problems where the control of the false discovery rate rather than that of the FWER is desired, there is potential for a gain in power. A simple sequential Bonferronitype procedure is proved to control the false discovery rate for independent test statistics, and a simulation study shows that the gain in power is substantial. The use of the new procedure and the appropriateness of the criterion are illustrated with examples.","['False discovery rate', 'Multiple comparisons problem', 'Word error rate', 'Computer science', 'Statistical hypothesis testing', 'Statistics', 'Control (management)', 'Mathematics', 'Artificial intelligence', 'Biochemistry', 'Chemistry', 'Gene']","multiplicity problem, familywise error rate, ##wer, multiple significance testing, false discovery rate, false discovery rate, sequential bonferronitype procedure, false discovery rate, independent test statistics, simulation"
Paper_00017,Development of the Colle-Salvetti correlation-energy formula into a functional of the electron density,"['Chengteh Lee', 'Weitao Yang', 'Robert G. Parr']",1988,"Physical review. B, Condensed matter",Journal,,785-789,37,2,10.1103/physrevb.37.785,"A correlation-energy formula due to Colle and Salvetti [Theor. Chim. Acta 37, 329 (1975)], in which the correlation energy density is expressed in terms of the electron density and a Laplacian of the second-order Hartree-Fock density matrix, is restated as a formula involving the density and local kinetic-energy density. On insertion of gradient expansions for the local kinetic-energy density, density-functional formulas for the correlation energy and correlation potential are then obtained. Through numerical calculations on a number of atoms, positive ions, and molecules, of both open- and closed-shell type, it is demonstrated that these formulas, like the original Colle-Salvetti formulas, give correlation energies within a few percent.","['Kinetic energy', 'Density matrix', 'Electronic correlation', 'Physics', 'Energy (signal processing)', 'Electron density', 'Atomic physics', 'Hartree–Fock method', 'Potential energy', 'Electron', 'Quantum mechanics', 'Quantum']","correlation energy density, electron density, gradient expansions, correlation energy, correlation potential, correlation energies"
Paper_00018,Cutoff criteria for fit indexes in covariance structure analysis: Conventional criteria versus new alternatives,"['Li‐tze Hu', 'Peter M. Bentler']",1999,Structural Equation Modeling A Multidisciplinary Journal,Journal,,1-55,6,1,10.1080/10705519909540118,"This article examines the adequacy of the ""rules of thumb"" conventional cutoff criteria and several new alternatives for various fit indexes used to evaluate model fit in practice. Using a 2‐index presentation strategy, which includes using the maximum likelihood (ML)‐based standardized root mean squared residual (SRMR) and supplementing it with either Tucker‐Lewis Index (TLI), Bollen's (1989) Fit Index (BL89), Relative Noncentrality Index (RNI), Comparative Fit Index (CFI), Gamma Hat, McDonald's Centrality Index (Mc), or root mean squared error of approximation (RMSEA), various combinations of cutoff values from selected ranges of cutoff criteria for the ML‐based SRMR and a given supplemental fit index were used to calculate rejection rates for various types of true‐population and misspecified models; that is, models with misspecified factor covariance(s) and models with misspecified factor loading(s). The results suggest that, for the ML method, a cutoff value close to .95 for TLI, BL89, CFI, RNI, and Gamma Hat; a cutoff value close to .90 for Mc; a cutoff value close to .08 for SRMR; and a cutoff value close to .06 for RMSEA are needed before we can conclude that there is a relatively good fit between the hypothesized model and the observed data. Furthermore, the 2‐index presentation strategy is required to reject reasonable proportions of various types of true‐population and misspecified models. Finally, using the proposed cutoff criteria, the ML‐based TLI, Mc, and RMSEA tend to overreject true‐population models at small sample size and thus are less preferable when sample size is small.","['Cutoff', 'Statistics', 'Mathematics', 'Index (typography)', 'Population', 'Covariance', 'Structural equation modeling', 'Econometrics', 'Demography', 'Physics', 'Computer science', 'Quantum mechanics', 'Sociology', 'World Wide Web']","cutoff criteria, fit indexes, maximum likelihood, standardized root mean squared residual, relative noncentrality index, comparative fit index, gamma hat, root mean squared error of approximation, supplemental, rejection rates, true ‐ population, misspecified models, misspecified factor covariance, misspecified factor loading, gamma hat, cutoff value, true ‐ population, misspecified models, ##ea"
Paper_00021,A short history of<i>SHELX</i>,['George M. Sheldrick'],2007,Acta Crystallographica Section A Foundations of Crystallography,Journal,,112-122,64,1,10.1107/s0108767307043930,"An account is given of the development of the SHELX system of computer programs from SHELX-76 to the present day. In addition to identifying useful innovations that have come into general use through their implementation in SHELX, a critical analysis is presented of the less-successful features, missed opportunities and desirable improvements for future releases of the software. An attempt is made to understand how a program originally designed for photographic intensity data, punched cards and computers over 10000 times slower than an average modern personal computer has managed to survive for so long. SHELXL is the most widely used program for small-molecule refinement and SHELXS and SHELXD are often employed for structure solution despite the availability of objectively superior programs. SHELXL also finds a niche for the refinement of macromolecules against high-resolution or twinned data; SHELXPRO acts as an interface for macromolecular applications. SHELXC, SHELXD and SHELXE are proving useful for the experimental phasing of macromolecules, especially because they are fast and robust and so are often employed in pipelines for high-throughput phasing. This paper could serve as a general literature citation when one or more of the open-source SHELX programs (and the Bruker AXS version SHELXTL) are employed in the course of a crystal-structure determination.","['Phaser', 'Computer science', 'Software', 'Interface (matter)', 'Software engineering', 'Computational science', 'Programming language', 'Parallel computing', 'Engineering', 'Bubble', 'Maximum bubble pressure method', 'Electrical engineering']","shelx, computer programs, shelx, photographic intensity data, punched cards, shelxl, shelxs, shelxd, shelxl, shelxpro, shelxc, shelxd, shelxe, shelxtl, [PAD], [PAD], [PAD], [PAD], [PAD] [PAD], [PAD] [PAD]"
Paper_00022,Adam: A Method for Stochastic Optimization,"['Diederik P. Kingma', 'Jimmy Ba']",2014,['Journal of Soft Computing Paradigm'],Unknown,,38-46,3,1,10.36548/jscp.2021.1.005,"We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.","['Regret', 'Mathematical optimization', 'Computer science', 'Diagonal', 'Convergence (economics)', 'Stochastic optimization', 'Rate of convergence', 'Optimization problem', 'Mathematics', 'Key (lock)', 'Machine learning', 'Geometry', 'Computer security', 'Economics', 'Economic growth']","adam, stochastic objective functions, adaptive estimates, memory requirements, diagonal rescaling, theoretical convergence properties, regret bound, convergence, online convex optimization framework, adam, ##astic optimization, adamax, infinity norm, [PAD], [PAD], [PAD], [PAD], [PAD]"
Paper_00023,Global Cancer Statistics 2020: GLOBOCAN Estimates of Incidence and Mortality Worldwide for 36 Cancers in 185 Countries,"['Hyuna Sung', 'Jacques Ferlay', 'Rebecca L. Siegel', 'Mathieu Laversanne', 'Isabelle Soerjomataram', 'Ahmedin Jemal', 'Freddie Bray']",2021,CA A Cancer Journal for Clinicians,Journal,,209-249,71,3,10.3322/caac.21660,"Abstract This article provides an update on the global cancer burden using the GLOBOCAN 2020 estimates of cancer incidence and mortality produced by the International Agency for Research on Cancer. Worldwide, an estimated 19.3 million new cancer cases (18.1 million excluding nonmelanoma skin cancer) and almost 10.0 million cancer deaths (9.9 million excluding nonmelanoma skin cancer) occurred in 2020. Female breast cancer has surpassed lung cancer as the most commonly diagnosed cancer, with an estimated 2.3 million new cases (11.7%), followed by lung (11.4%), colorectal (10.0 %), prostate (7.3%), and stomach (5.6%) cancers. Lung cancer remained the leading cause of cancer death, with an estimated 1.8 million deaths (18%), followed by colorectal (9.4%), liver (8.3%), stomach (7.7%), and female breast (6.9%) cancers. Overall incidence was from 2‐fold to 3‐fold higher in transitioned versus transitioning countries for both sexes, whereas mortality varied &lt;2‐fold for men and little for women. Death rates for female breast and cervical cancers, however, were considerably higher in transitioning versus transitioned countries (15.0 vs 12.8 per 100,000 and 12.4 vs 5.2 per 100,000, respectively). The global cancer burden is expected to be 28.4 million cases in 2040, a 47% rise from 2020, with a larger increase in transitioning (64% to 95%) versus transitioned (32% to 56%) countries due to demographic changes, although this may be further exacerbated by increasing risk factors associated with globalization and a growing economy. Efforts to build a sustainable infrastructure for the dissemination of cancer prevention measures and provision of cancer care in transitioning countries is critical for global cancer control.","['Medicine', 'Cancer', 'Breast cancer', 'Skin cancer', 'Lung cancer', 'Colorectal cancer', 'Incidence (geometry)', 'Demography', 'Prostate cancer', 'Mortality rate', 'Stomach cancer', 'Oncology', 'Internal medicine', 'Physics', 'Sociology', 'Optics']","global cancer burden, globocan 2020, nonmelanoma skin cancer, non, ##anoma skin, female breast cancer, lung, color, lung, color, female breast, female, cervical cancers, global, globalization, cancer"
Paper_00026,Long Short-Term Memory,"['Sepp Hochreiter', 'Jürgen Schmidhuber']",1997,Neural Computation,Journal,,1735-1780,9,8,10.1162/neco.1997.9.8.1735,"Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms.","['Term (time)', 'Short-term memory', 'Computer science', 'Mathematics', 'Psychology', 'Neuroscience', 'Cognition', 'Working memory', 'Physics', 'Quantum mechanics']","extended time intervals, recurrent backpropagation, constant error flow, constant error carousels, multiplicative gate units, constant error flow, ##st, noisy pattern representations, back, recurrent cascade correlation, elman nets, neural sequence chunking, ##st, ##st"
Paper_00027,Preferred reporting items for systematic reviews and meta-analyses: the PRISMA statement,"['David Moher', 'A. Liberati', 'Jennifer Tetzlaff', 'Douglas G. Altman']",2009,BMJ,Journal,,b2535-b2535,339,jul21 1,10.1136/bmj.b2535,"Structured summary 2 Provide a structured summary including, as applicable, background, objectives, data sources, study eligibility criteria, participants, interventions, study appraisal and synthesis methods, results, limitations, conclusions and implications of key findings, systematic review registration number Flow of information through the different phases of a systematic review No of records identified through database searching No of additional records identified through other sources No of records after duplicates removed No of studies included in qualitative synthesis No of studies included in quantitative synthesis (meta-analysis)","['Systematic review', 'Statement (logic)', 'Computer science', 'Information retrieval', 'Data science', 'MEDLINE', 'Medicine', 'World Wide Web', 'Biology', 'Political science', 'Law', 'Biochemistry']","structured summary, structured summary, study eligibility criteria, study appraisal, synthesis methods, systematic review registration, systematic review, database searching, qualitative synthesis, quantitative synthesis"
Paper_00028,Case Study Research: Design and Methods,['Robert K. Yin'],1984,['Evaluation and Program Planning'],Unknown,,373-374,9,4,10.1016/0149-7189(86)90052-2,"Buku ini menyediakan sebuah portal lengkap untuk dunia penelitian studi kasus, buku ini menawarkan cakupan yang luas dari desain dan penggunaan metode studi kasus sebagai alat penelitian yang valid. Dalam buku ini mencakup lebih dari 50 studi kasus, memberikan perhatian untuk analisis kuantitatif, membahas lebih lengkap penggunaan desain metode campuran penelitian, dan termasuk wawasan metodologi baru.","['Humanities', 'Computer science', 'Political science', 'Philosophy']",
Paper_00029,Using multivariate statistics,"['Barbara G. Tabachnick', 'Linda S. Fidell']",1983,['Contemporary Psychology: A Journal of Reviews'],Unknown,,642-642,28,8,10.1037/022267,In this Section: 1. Brief Table of Contents 2. Full Table of Contents 1. BRIEF TABLE OF CONTENTS Chapter 1 Introduction Chapter 2 A Guide to Statistical Techniques: Using the Book Chapter 3 Review of Univariate and Bivariate Statistics Chapter 4 Cleaning Up Your Act: Screening Data Prior to Analysis Chapter 5 Multiple Regression Chapter 6 Analysis of Covariance Chapter 7 Multivariate Analysis of Variance and Covariance Chapter 8 Profile Analysis: The Multivariate Approach to Repeated Measures Chapter 9 Discriminant Analysis Chapter 10 Logistic Regression Chapter 11 Survival/Failure Analysis Chapter 12 Canonical Correlation Chapter 13 Principal Components and Factor Analysis Chapter 14 Structural Equation Modeling Chapter 15 Multilevel Linear Modeling Chapter 16 Multiway Frequency Analysis 2. FULL TABLE OF CONTENTS Chapter 1: Introduction Multivariate Statistics: Why? Some Useful Definitions Linear Combinations of Variables Number and Nature of Variables to Include Statistical Power Data Appropriate for Multivariate Statistics Organization of the Book Chapter 2: A Guide to Statistical Techniques: Using the Book Research Questions and Associated Techniques Some Further Comparisons A Decision Tree Technique Chapters Preliminary Check of the Data Chapter 3: Review of Univariate and Bivariate Statistics Hypothesis Testing Analysis of Variance Parameter Estimation Effect Size Bivariate Statistics: Correlation and Regression. Chi-Square Analysis Chapter 4: Cleaning Up Your Act: Screening Data Prior to Analysis Important Issues in Data Screening Complete Examples of Data Screening Chapter 5: Multiple Regression General Purpose and Description Kinds of Research Questions Limitations to Regression Analyses Fundamental Equations for Multiple Regression Major Types of Multiple Regression Some Important Issues. Complete Examples of Regression Analysis Comparison of Programs Chapter 6: Analysis of Covariance General Purpose and Description Kinds of Research Questions Limitations to Analysis of Covariance Fundamental Equations for Analysis of Covariance Some Important Issues Complete Example of Analysis of Covariance Comparison of Programs Chapter 7: Multivariate Analysis of Variance and Covariance General Purpose and Description Kinds of Research Questions Limitations to Multivariate Analysis of Variance and Covariance Fundamental Equations for Multivariate Analysis of Variance and Covariance Some Important Issues Complete Examples of Multivariate Analysis of Variance and Covariance Comparison of Programs Chapter 8: Profile Analysis: The Multivariate Approach to Repeated Measures General Purpose and Description Kinds of Research Questions Limitations to Profile Analysis Fundamental Equations for Profile Analysis Some Important Issues Complete Examples of Profile Analysis Comparison of Programs Chapter 9: Discriminant Analysis General Purpose and Description Kinds of Research Questions Limitations to Discriminant Analysis Fundamental Equations for Discriminant Analysis Types of Discriminant Analysis Some Important Issues Comparison of Programs Chapter 10: Logistic Regression General Purpose and Description Kinds of Research Questions Limitations to Logistic Regression Analysis Fundamental Equations for Logistic Regression Types of Logistic Regression Some Important Issues Complete Examples of Logistic Regression Comparison of Programs Chapter 11: Survival/Failure Analysis General Purpose and Description Kinds of Research Questions Limitations to Survival Analysis Fundamental Equations for Survival Analysis Types of Survival Analysis Some Important Issues Complete Example of Survival Analysis Comparison of Programs Chapter 12: Canonical Correlation General Purpose and Description Kinds of Research Questions Limitations Fundamental Equations for Canonical Correlation Some Important Issues Complete Example of Canonical Correlation Comparison of Programs Chapter 13: Principal Components and Factor Analysis General Purpose and Description Kinds of Research Questions Limitations Fundamental Equations for Factor Analysis Major Types of Factor Analysis Some Important Issues Complete Example of FA Comparison of Programs Chapter 14: Structural Equation Modeling General Purpose and Description Kinds of Research Questions Limitations to Structural Equation Modeling Fundamental Equations for Structural Equations Modeling Some Important Issues Complete Examples of Structural Equation Modeling Analysis. Comparison of Programs Chapter 15: Multilevel Linear Modeling General Purpose and Description Kinds of Research Questions Limitations to Multilevel Linear Modeling Fundamental Equations Types of MLM Some Important Issues Complete Example of MLM Comparison of Programs Chapter 16: Multiway Frequency Analysis General Purpose and Description Kinds of Research Questions Limitations to Multiway Frequency Analysis Fundamental Equations for Multiway Frequency Analysis Some Important Issues Complete Example of Multiway Frequency Analysis Comparison of Programs,"['Statistics', 'Univariate', 'Multivariate statistics', 'Bivariate analysis', 'Regression analysis', 'Mathematics', 'Linear discriminant analysis']","statistical, bivariate statistics, multiple regression, co, multivariate analysis, covariance, profile analysis, repeated measures, discriminant, logistic regression, factor analysis, structural equation modeling, multilevel linear modeling, multiway frequency analysis, multivariate statistics, ##iate, decision tree, variance parameter estimation, multiple regression, co, co, covariance, multivariate analysis, covariance, ##iate, co, ##iance, ##iate, covariance, multivariate analysis, covariance, profile analysis, profile, profile, ##inant, ##inant"
Paper_00030,Projector augmented-wave method,['Peter E. Blöchl'],1994,"Physical review. B, Condensed matter",Journal,,17953-17979,50,24,10.1103/physrevb.50.17953,"An approach for electronic structure calculations is described that generalizes both the pseudopotential method and the linear augmented-plane-wave (LAPW) method in a natural way. The method allows high-quality first-principles molecular-dynamics calculations to be performed using the original fictitious Lagrangian approach of Car and Parrinello. Like the LAPW method it can be used to treat first-row and transition-metal elements with affordable effort and provides access to the full wave function. The augmentation procedure is generalized in that partial-wave expansions are not determined by the value and the derivative of the envelope function at some muffin-tin radius, but rather by the overlap with localized projector functions. The pseudopotential approach based on generalized separable pseudopotentials can be regained by a simple approximation.","['Pseudopotential', 'Projector', 'Envelope (radar)', 'Plane wave', 'Separable space', 'Wave function', 'Physics', 'Function (biology)', 'Classical mechanics', 'Quantum mechanics', 'Mathematical analysis', 'Mathematics', 'Computer science', 'Optics', 'Telecommunications', 'Radar', 'Evolutionary biology', 'Biology']","electronic structure calculations, pseudopotential method, fictitious lagrangian approach, envelope function, localized projector functions, pseudopot, generalized separable pseudopotentials, [PAD] [PAD] [PAD], [PAD], [PAD]"
Paper_00031,Global cancer statistics 2018: GLOBOCAN estimates of incidence and mortality worldwide for 36 cancers in 185 countries,"['Freddie Bray', 'Jacques Ferlay', 'Isabelle Soerjomataram', 'Rebecca L. Siegel', 'Lindsey A. Torre', 'Ahmedin Jemal']",2018,CA A Cancer Journal for Clinicians,Journal,,394-424,68,6,10.3322/caac.21492,"Abstract This article provides a status report on the global burden of cancer worldwide using the GLOBOCAN 2018 estimates of cancer incidence and mortality produced by the International Agency for Research on Cancer, with a focus on geographic variability across 20 world regions. There will be an estimated 18.1 million new cancer cases (17.0 million excluding nonmelanoma skin cancer) and 9.6 million cancer deaths (9.5 million excluding nonmelanoma skin cancer) in 2018. In both sexes combined, lung cancer is the most commonly diagnosed cancer (11.6% of the total cases) and the leading cause of cancer death (18.4% of the total cancer deaths), closely followed by female breast cancer (11.6%), prostate cancer (7.1%), and colorectal cancer (6.1%) for incidence and colorectal cancer (9.2%), stomach cancer (8.2%), and liver cancer (8.2%) for mortality. Lung cancer is the most frequent cancer and the leading cause of cancer death among males, followed by prostate and colorectal cancer (for incidence) and liver and stomach cancer (for mortality). Among females, breast cancer is the most commonly diagnosed cancer and the leading cause of cancer death, followed by colorectal and lung cancer (for incidence), and vice versa (for mortality); cervical cancer ranks fourth for both incidence and mortality. The most frequently diagnosed cancer and the leading cause of cancer death, however, substantially vary across countries and within each country depending on the degree of economic development and associated social and life style factors. It is noteworthy that high‐quality cancer registry data, the basis for planning and implementing evidence‐based cancer control programs, are not available in most low‐ and middle‐income countries. The Global Initiative for Cancer Registry Development is an international partnership that supports better estimation, as well as the collection and use of local data, to prioritize and evaluate national cancer control efforts. CA: A Cancer Journal for Clinicians 2018;0:1‐31. © 2018 American Cancer Society","['Cancer', 'Colorectal cancer', 'Medicine', 'Skin cancer', 'Breast cancer', 'Prostate cancer', 'Lung cancer', 'Liver cancer', 'Stomach cancer', 'Causes of cancer', 'Incidence (geometry)', 'Cancer registry', 'Cause of death', 'Epidemiology of cancer', 'Mortality rate', 'Oncology', 'Internal medicine', 'Disease', 'Physics', 'Optics']","global, globocan, geographic variability, non, ##anoma skin, nonmelanoma, lung cancer, female breast cancer, prostate cancer, colorectal cancer, stomach cancer, liver cancer, lung, breast, cervical cancer, cancer registry, clinicians, american cancer society"
Paper_00032,A Mathematical Theory of Communication,['Claude E. Shannon'],1948,Bell System Technical Journal,Journal,,379-423,27,3,10.1002/j.1538-7305.1948.tb01338.x,"The recent development of various methods of modulation such as PCM and PPM which exchange bandwidth for signal-to-noise ratio has intensified the interest in a general theory of communication. A basis for such a theory is contained in the important papers of Nyquist <sup xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">1</sup> and Hartley <sup xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">2</sup> on this subject. In the present paper we will extend the theory to include a number of new factors, in particular the effect of noise in the channel, and the savings possible due to the statistical structure of the original message and due to the nature of the final destination of the information.","['Bandwidth (computing)', 'Computer science', 'Nyquist–Shannon sampling theorem', 'Channel (broadcasting)', 'Communication theory', 'Mathematics', 'Algorithm', 'Theoretical computer science', 'Telecommunications', 'Statistics', 'Computer vision']","modulation, pcm, ppm, ny, xml, ##ink, ##ink, statistical structure"
Paper_00034,Moderated estimation of fold change and dispersion for RNA-seq data with DESeq2,"['Michael I. Love', 'Wolfgang Huber', 'Simon Anders']",2014,Genome biology,Journal,,,15,12,10.1186/s13059-014-0550-8,"In comparative high-throughput sequencing assays, a fundamental task is the analysis of count data, such as read counts per gene in RNA-seq, for evidence of systematic changes across experimental conditions. Small replicate numbers, discreteness, large dynamic range and the presence of outliers require a suitable statistical approach. We present DESeq2, a method for differential analysis of count data, using shrinkage estimation for dispersions and fold changes to improve stability and interpretability of estimates. This enables a more quantitative analysis focused on the strength rather than the mere presence of differential expression. The DESeq2 package is available at http://www.bioconductor.org/packages/release/bioc/html/DESeq2.html .","['Biology', 'Computational biology', 'Genome Biology', 'RNA-Seq', 'Genomics', 'Evolutionary biology', 'Genetics', 'Transcriptome', 'Genome', 'Gene', 'Gene expression']","count data, read counts, small replicate numbers, discreteness, large dynamic range, outliers, deseq2, differential analysis, count data, shrinkage estimation, ##sper, fold changes, differential expression, deseq, [PAD] [PAD] [PAD]"
Paper_00035,Gapped BLAST and PSI-BLAST: a new generation of protein database search programs,['Stephen F. Altschul'],1997,Nucleic Acids Research,Journal,,3389-3402,25,17,10.1093/nar/25.17.3389,"The BLAST programs are widely used tools for searching protein and DNA databases for sequence similarities. For protein comparisons, a variety of definitional, algorithmic and statistical refinements described here permits the execution time of the BLAST programs to be decreased substantially while enhancing their sensitivity to weak similarities. A new criterion for triggering the extension of word hits, combined with a new heuristic for generating gapped alignments, yields a gapped BLAST program that runs at approximately three times the speed of the original. In addition, a method is introduced for automatically combining statistically significant alignments produced by BLAST into a position-specific score matrix, and searching the database using this matrix. The resulting Position-Specific Iterated BLAST (PSIBLAST) program runs at approximately the same speed per iteration as gapped BLAST, but in many cases is much more sensitive to weak but biologically relevant sequence similarities. PSI-BLAST is used to uncover several new and interesting members of the BRCT superfamily.","['Iterated function', 'Heuristic', 'Sequence (biology)', 'Biology', 'Position (finance)', 'Sequence database', 'Computer science', 'Computational biology', 'Database', 'Genetics', 'Artificial intelligence', 'Mathematics', 'Gene', 'Mathematical analysis', 'Finance', 'Economics']","blast, dna databases, sequence similarities, protein comparisons, blast, word hits, gapped alignments, gapped blast, ##ly, psi, ##st, gapped blast, brct"
Paper_00036,Very Deep Convolutional Networks for Large-Scale Image Recognition,"['Karen Simonyan', 'Andrew Zisserman']",2014,['Proceedings of the 2nd International Workshop on Multimedia Assisted Dietary Management'],Conference,"MM '16: ACM Multimedia Conference, Amsterdam The Netherlands",41-49,,,10.1145/2986035.2986042,"In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.","['Computer science', 'Convolution (computer science)', 'Convolutional neural network', 'Artificial intelligence', 'Deep learning', 'Image (mathematics)', 'Scale (ratio)', 'Architecture', 'Contextual image classification', 'Pattern recognition (psychology)', 'Machine learning', 'Computer vision', 'Artificial neural network', 'Cartography', 'Art', 'Visual arts', 'Geography']","convolutional network depth, convolution filters, imagenet challenge, classification tracks, deep visual representations, computer vision"
Paper_00037,From ultrasoft pseudopotentials to the projector augmented-wave method,"['Georg Kresse', 'Daniel P. Joubert']",1999,"Physical review. B, Condensed matter",Journal,,1758-1775,59,3,10.1103/physrevb.59.1758,"The formal relationship between ultrasoft (US) Vanderbilt-type pseudopotentials and Bl\""ochl's projector augmented wave (PAW) method is derived. It is shown that the total energy functional for US pseudopotentials can be obtained by linearization of two terms in a slightly modified PAW total energy functional. The Hamilton operator, the forces, and the stress tensor are derived for this modified PAW functional. A simple way to implement the PAW method in existing plane-wave codes supporting US pseudopotentials is pointed out. In addition, critical tests are presented to compare the accuracy and efficiency of the PAW and the US pseudopotential method with relaxed core all electron methods. These tests include small molecules $({\mathrm{H}}_{2}{,\mathrm{}\mathrm{H}}_{2}{\mathrm{O},\mathrm{}\mathrm{Li}}_{2}{,\mathrm{}\mathrm{N}}_{2}{,\mathrm{}\mathrm{F}}_{2}{,\mathrm{}\mathrm{BF}}_{3}{,\mathrm{}\mathrm{SiF}}_{4})$ and several bulk systems (diamond, Si, V, Li, Ca, ${\mathrm{CaF}}_{2},$ Fe, Co, Ni). Particular attention is paid to the bulk properties and magnetic energies of Fe, Co, and Ni.","['Pseudopotential', 'Physics', 'Energy (signal processing)', 'Density functional theory', 'Tensor (intrinsic definition)', 'Atomic physics', 'Condensed matter physics', 'Crystallography', 'Quantum mechanics', 'Geometry', 'Mathematics', 'Chemistry']","projector augmented wave, total energy functional, paw total energy functional, hamilton operator, stress tensor, critical tests, us, relaxed core, small molecules, bulk systems, bulk properties, magnetic energies"
Paper_00039,The Measurement of Observer Agreement for Categorical Data,"['J. Richard Landis', 'Gary G. Koch']",1977,Biometrics,Journal,,159-159,33,1,10.2307/2529310,This paper presents a general statistical methodology for the analysis of multivariate categorical data arising from observer reliability studies. The procedure essentially involves the construction of functions of the observed proportions which are directed at the extent to which the observers agree among themselves and the construction of test statistics for hypotheses involving these functions. Tests for interobserver bias are presented in terms of first-order marginal homogeneity and measures of interobserver agreement are developed as generalized kappa-type statistics. These procedures are illustrated with a clinical diagnosis example from the epidemiological literature.,"['Categorical variable', 'Kappa', 'Statistics', 'Homogeneity (statistics)', 'Multivariate statistics', 'Mathematics', 'Statistical hypothesis testing', ""Cohen's kappa"", 'Observer (physics)', 'Econometrics', 'Poisson distribution', 'Reliability (semiconductor)', 'Type I and type II errors', 'Multivariate analysis', 'Computer science', 'Power (physics)', 'Physics', 'Geometry', 'Quantum mechanics']","multivariate categorical data, observer reliability studies, test statistics, interobserver bias, interobserver agreement, clinical diagnosis, epidemi, [PAD], [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD], [PAD], [PAD] [PAD], [PAD] [PAD] [PAD] [PAD], [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD], [PAD], [PAD], [PAD] [PAD] [PAD] [PAD] [PAD], [PAD] [PAD], [PAD], [PAD] [PAD], [PAD]"
Paper_00040,DNA sequencing with chain-terminating inhibitors,"['Frederick Sanger', 'S. Nicklen', 'Alan Coulson']",1977,Proceedings of the National Academy of Sciences,Journal,,5463-5467,74,12,10.1073/pnas.74.12.5463,"A new method for determining nucleotide sequences in DNA is described. It is similar to the ""plus and minus"" method [Sanger, F. & Coulson, A. R. (1975) J. Mol. Biol. 94, 441-448] but makes use of the 2',3'-dideoxy and arabinonucleoside analogues of the normal deoxynucleoside triphosphates, which act as specific chain-terminating inhibitors of DNA polymerase. The technique has been applied to the DNA of bacteriophage varphiX174 and is more rapid and more accurate than either the plus or the minus method.","['DNA', 'Sanger sequencing', 'Nucleotide', 'DNA polymerase', 'Polymerase chain reaction', 'Chemistry', 'DNA sequencing', 'Bacteriophage', 'Polymerase', 'Molecular biology', 'Biology', 'Biochemistry', 'Gene', 'Escherichia coli']","nucleotide sequences, dna, ##nucleosi, ##yn, dna, [PAD]"
Paper_00042,"The moderator-mediator variable distinction in social psychological research: Conceptual, strategic, and statistical considerations.","['Reuben M. Baron', 'David A. Kenny']",1986,Journal of Personality and Social Psychology,Journal,,1173-1182,51,6,10.1037//0022-3514.51.6.1173,"In this article, we attempt to distinguish between the properties of moderator and mediator variables at a number of levels. First, we seek to make theorists and researchers aware of the importance of not using the terms moderator and mediator interchangeably by carefully elaborating, both conceptually and strategically, the many ways in which moderators and mediators differ. We then go beyond this largely pedagogical function and delineate the conceptual and strategic implications of making use of such distinctions with regard to a wide range of phenomena, including control and stress, attitudes, and personality traits. We also provide a specific compendium of analytic procedures appropriate for making the most effective use of the moderator and mediator distinction, both separately and in terms of a broader causal system that includes both moderators and mediators.","['Moderation', 'Psychology', 'Social psychology', 'Personality', 'Function (biology)', 'Conceptual framework', 'Mediator', 'Cognitive psychology', 'Epistemology', 'Medicine', 'Philosophy', 'Evolutionary biology', 'Internal medicine', 'Biology']","moderator, mediator variables, moderator, mediator, media, stress, attitudes, personality traits, analytic procedures, media, causal system, ##s, mediators"
Paper_00043,ImageNet Classification with Deep Convolutional Neural Networks,"['Alex Krizhevsky', 'Ilya Sutskever', 'Geoffrey E. Hinton']",2012,['Communications of the ACM'],Conference,,84-90,60,6,10.1145/3065386,"We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5% and 17.0% which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully-connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolution operation. To reduce overriding in the fully-connected layers we employed a recently-developed regularization method called dropout that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3%, compared to 26.2% achieved by the second-best entry.","['Softmax function', 'Convolutional neural network', 'Computer science', 'Pooling', 'Dropout (neural networks)', 'Artificial intelligence', 'Convolution (computer science)', 'Regularization (linguistics)', 'Pattern recognition (psychology)', 'Deep neural networks', 'Word error rate', 'Normalization (sociology)', 'Artificial neural network', 'Machine learning', 'Sociology', 'Anthropology']","convolutional neural network, imagenet, convolutional layers, - saturating, gpu, convolution operation, regularization method, dropout, ##s"
Paper_00044,Fitting Linear Mixed-Effects Models Using<b>lme4</b>,"['Douglas M. Bates', 'Martin Mächler', 'Benjamin M. Bolker', 'Steve Walker']",2015,Journal of Statistical Software,Journal,,,67,1,10.18637/jss.v067.i01,"Maximum likelihood or restricted maximum likelihood (REML) estimates of the parameters in linear mixed-effects models can be determined using the lmer function in the lme4 package for R. As for most model-fitting functions in R, the model is described in an lmer call by a formula, in this case including both fixed- and random-effects terms. The formula and data together determine a numerical representation of the model from which the profiled deviance or the profiled REML criterion can be evaluated as a function of some of the model parameters. The appropriate criterion is optimized, using one of the constrained optimization functions in R, to provide the parameter estimates. We describe the structure of the model, the steps in evaluating the profiled deviance or REML criterion, and the structure of classes or types that represents such a model. Sufficient detail is included to allow specialization of these structures by users who wish to write functions to fit specialized linear mixed models, such as models incorporating pedigrees or smoothing splines, that are not easily expressible in the formula language used by lmer.","['Restricted maximum likelihood', 'Deviance (statistics)', 'Mixed model', 'Smoothing', 'Applied mathematics', 'Likelihood function', 'Mathematics', 'Generalized linear model', 'Linear model', 'Maximum likelihood', 'Generalized linear mixed model', 'Covariate', 'Algorithm', 'Statistics', 'Mathematical optimization', 'Computer science']","maximum likelihood, restricted maximum likelihood, lmer, ##me, numerical representation, ##d deviance, profiled reml criterion, constrained optimization functions, parameter, reml, linear mixed models, pedigrees, smoothing splines, [PAD] [PAD], [PAD] [PAD]"
Paper_00050,"CLUSTAL W: improving the sensitivity of progressive multiple sequence alignment through sequence weighting, position-specific gap penalties and weight matrix choice","['Julie Thompson', 'Desmond G. Higgins', 'Toby J. Gibson']",1994,Nucleic Acids Research,Journal,,4673-4680,22,22,10.1093/nar/22.22.4673,"The sensitivity of the commonly used progressive multiple sequence alignment method has been greatly improved for the alignment of divergent protein sequences. Firstly, individual weights are assigned to each sequence in a partial alignment in order to downweight near-duplicate sequences and up-weight the most divergent ones. Secondly, amino acid substitution matrices are varied at different alignment stages according to the divergence of the sequences to be aligned. Thirdly, residue-specific gap penalties and locally reduced gap penalties in hydrophilic regions encourage new gaps in potential loop regions rather than regular secondary structure. Fourthly, positions in early alignments where gaps have been opened receive locally reduced gap penalties to encourage the opening up of new gaps at these positions. These modifications are incorporated into a new program, CLUSTAL W which is freely available.","['Biology', 'Sequence (biology)', 'Position (finance)', 'Weighting', 'Multiple sequence alignment', 'Sensitivity (control systems)', 'Sequence alignment', 'Matrix (chemical analysis)', 'Genetics', 'Computational biology', 'Peptide sequence', 'Gene', 'Finance', 'Electronic engineering', 'Engineering', 'Economics', 'Medicine', 'Materials science', 'Composite material', 'Radiology']","progressive multiple sequence alignment method, divergent protein sequences, partial alignment, amino acid substitution matrices, locally reduced gap penalties, hydrophilic regions, clustal"
Paper_00053,Common method biases in behavioral research: A critical review of the literature and recommended remedies.,"['Philip M. Podsakoff', 'Scott MacKenzie', 'Jeong Yeon Lee', 'Nathan P. Podsakoff']",2003,Journal of Applied Psychology,Journal,,879-903,88,5,10.1037/0021-9010.88.5.879,"Interest in the problem of method biases has a long history in the behavioral sciences. Despite this, a comprehensive summary of the potential sources of method biases and how to control for them does not exist. Therefore, the purpose of this article is to examine the extent to which method biases influence behavioral research results, identify potential sources of method biases, discuss the cognitive processes through which method biases influence responses to measures, evaluate the many different procedural and statistical techniques that can be used to control method biases, and provide recommendations for how to select appropriate procedural and statistical remedies for different types of research settings.","['Psychology', 'Cognitive psychology', 'Cognitive bias', 'Cognition', 'Behavioural sciences', 'Control (management)', 'Management science', 'Computer science', 'Artificial intelligence', 'Psychotherapist', 'Neuroscience', 'Economics']","method biases, behavioral sciences, method biases, method biases, behavioral research, method biases, method, [PAD] [PAD] [PAD] [PAD]"
Paper_00055,Special points for Brillouin-zone integrations,"['Hendrik J. Monkhorst', 'J.D. Pack']",1976,"Physical review. B, Solid state",Journal,,5188-5192,13,12,10.1103/physrevb.13.5188,A method is given for generating sets of special points in the Brillouin zone which provides an efficient means of integrating periodic functions of the wave vector. The integration can be over the entire Brillouin zone or over specified portions thereof. This method also has applications in spectral and density-of-state calculations. The relationships to the Chadi-Cohen and Gilat-Raubenheimer methods are indicated.,"['Brillouin zone', 'Physics', 'State (computer science)', 'Mathematical analysis', 'Computational physics', 'Optics', 'Computer science', 'Mathematics', 'Algorithm']","brillouin zone, periodic functions, wave vector, ##uin zone"
Paper_00056,Electric Field Effect in Atomically Thin Carbon Films,"['Kostya S. Novoselov', 'A. K. Geǐm', 'С. В. Морозов', 'Da Jiang', 'Y. Zhang', 'S. V. Dubonos', 'I. V. Grigorieva', 'А. А. Firsov']",2004,Science,Journal,,666-669,306,5696,10.1126/science.1102896,"We report a naturally-occurring two-dimensional material (graphene that can be viewed as a gigantic flat fullerene molecule, describe its electronic properties and demonstrate all-metallic field-effect transistor, which uniquely exhibits ballistic transport at submicron distances even at room temperature.","['Electric field', 'Graphene', 'Materials science', 'Fullerene', 'Field-effect transistor', 'Carbon fibers', 'Nanotechnology', 'Ballistic conduction', 'Metal', 'Field (mathematics)', 'Thin film', 'Condensed matter physics', 'Transistor', 'Chemical physics', 'Optoelectronics', 'Chemistry', 'Physics', 'Composite material', 'Electron', 'Voltage', 'Mathematics', 'Quantum mechanics', 'Composite number', 'Pure mathematics', 'Metallurgy', 'Organic chemistry']","graph, flat fullerene molecule, ballistic transport, ##micron, [PAD] [PAD]"
Paper_00057,Scikit-learn: Machine Learning in Python,"['Fabián Pedregosa', 'Gaël Varoquaux', 'Alexandre Gramfort', 'Vincent Michel', 'Bertrand Thirion', 'Olivier Grisel', 'Mathieu Blondel', 'Peter Prettenhofer', 'Ron J. Weiss', 'Vincent Dubourg', 'Jake Vanderplas', 'Alexandre Passos', 'David Cournapeau', 'Matthieu Brucher', 'Matthieu Perrot', 'Édouard Duchesnay']",2012,arXiv (Cornell University),Unknown,,,,,10.48550/arxiv.1201.0490,"Scikit-learn is a Python module integrating a wide range of state-of-the-art machine learning algorithms for medium-scale supervised and unsupervised problems. This package focuses on bringing machine learning to non-specialists using a general-purpose high-level language. Emphasis is put on ease of use, performance, documentation, and API consistency. It has minimal dependencies and is distributed under the simplified BSD license, encouraging its use in both academic and commercial settings. Source code, binaries, and documentation can be downloaded from http://scikit-learn.org.","['Python (programming language)', 'Documentation', 'Computer science', 'MIT License', 'Artificial intelligence', 'Machine learning', 'Programming language', 'License', 'Software engineering', 'Operating system']","machine learning algorithms, ##ed, machine learning, documentation, api consistency, binaries, [PAD]"
Paper_00058,Official Methods of Analysis of,[],1980,Analytical Chemistry,Journal,,148A-148A,52,2,10.1021/ac50052a726,"ADVERTISEMENT RETURN TO ISSUEPREVArticleNEXTOfficial Methods of Analysis ofCite this: Anal. Chem. 1980, 52, 2, 148APublication Date (Print):February 1, 1980Publication History Published online31 May 2012Published inissue 1 February 1980https://doi.org/10.1021/ac50052a726RIGHTS & PERMISSIONSArticle Views435Altmetric-Citations8LEARN ABOUT THESE METRICSArticle Views are the COUNTER-compliant sum of full text article downloads since November 2008 (both PDF and HTML) across all institutions and individuals. These metrics are regularly updated to reflect usage leading up to the last few days.Citations are the number of other articles citing this article, calculated by Crossref and updated daily. Find more information about Crossref citation counts.The Altmetric Attention Score is a quantitative measure of the attention that a research article has received online. Clicking on the donut icon will load a page at altmetric.com with additional details about the score and the social media presence for the given article. Find more information on the Altmetric Attention Score and how the score is calculated. Share Add toView InAdd Full Text with ReferenceAdd Description ExportRISCitationCitation and abstractCitation and referencesMore Options Share onFacebookTwitterWechatLinked InReddit PDF (758 KB) Get e-Alerts Get e-Alerts","['Citation', 'Icon', 'Altmetrics', 'Social media', 'Computer science', 'Information retrieval', 'Citation analysis', 'World Wide Web', 'Library science', 'Programming language']","advertisement, ##varticlenextoff, ##l methods, analysis, ##ication, permissionsarticle views, cross, ##f, crossref, altmetric attention score, donut icon, social, altmetric attention score, ##ation"
Paper_00060,Revised effective ionic radii and systematic studies of interatomic distances in halides and chalcogenides,['R. D. Shannon'],1976,Acta Crystallographica Section A,Journal,,751-767,32,5,10.1107/s0567739476001551,"The effective ionic radii of Shannon & Prewitt [Acta Cryst. (1969), B25, 925-945] are revised to include more unusual oxidation states and coordinations. Revisions are based on new structural data, empirical bond strength-bond length relationships, and plots of (1) radii vs volume, (2) radii vs coordination number, and (3) radii vs oxidation state. Factors which affect radii additivity are polyhedral distortion, partial occupancy of cation sites, covalence, and metallic character. Mean Nb5+-O and Mo6+-O octahedral distances are linearly dependent on distortion. A decrease in cation occupancy increases mean Li+-O, Na+-O, and Ag+-O distances in a predictable manner. Covalence strongly shortens Fe2+-X, Co2+-X, Ni2+-X, Mn2+-X, Cu+-X, Ag+-X, and M-H- bonds as the electronegativity of X or M decreases. Smaller effects are seen for Zn2+-X, Cd2+-X, In2+-X, pb2+-X, and TI+-X. Bonds with delocalized electrons and therefore metallic character, e.g. Sm-S, V-S, and Re-O, are significantly shorter than similar bonds with localized electrons.","['Ionic radius', 'Crystallography', 'Electronegativity', 'Covalent bond', 'Ionic bonding', 'Bond length', 'Delocalized electron', 'Metal', 'Octahedron', 'Chemistry', 'Coordination number', 'Electron', 'Ion', 'Materials science', 'Crystal structure', 'Physics', 'Quantum mechanics', 'Organic chemistry']","effective ionic radii, coordinations, coordination, ##dii, polyhedral distortion, partial occupancy, covalence, metallic character, ##ah, ##ral distances, cation occupancy, co, del, ##lized electrons, metallic character, localized electrons"
Paper_00062,The neighbor-joining method: a new method for reconstructing phylogenetic trees.,"['Naruya Saitou', 'M Nei']",1987,Molecular Biology and Evolution,Journal,,,,,10.1093/oxfordjournals.molbev.a040454,"A new method called the neighbor-joining method is proposed for reconstructing phylogenetic trees from evolutionary distance data. The principle of this method is to find pairs of operational taxonomic units (OTUs [= neighbors]) that minimize the total branch length at each stage of clustering of OTUs starting with a starlike tree. The branch lengths as well as the topology of a parsimonious tree can quickly be obtained by using this method. Using computer simulation, we studied the efficiency of this method in obtaining the correct unrooted tree in comparison with that of five other tree-making methods: the unweighted pair group method of analysis, Farris's method, Sattath and Tversky's method, Li's method, and Tateno et al.'s modified Farris method. The new, neighbor-joining method and Sattath and Tversky's method are shown to be generally better than the other methods.","['Phylogenetic tree', 'Tree (set theory)', 'Biology', 'Cluster analysis', 'Phylogenetic network', 'Tree rearrangement', 'Computational phylogenetics', 'Algorithm', 'Mathematics', 'Computer science', 'Combinatorics', 'Artificial intelligence', 'Gene', 'Genetics']","phylogenetic trees, evolutionary distance data, operational taxonomic units, starlike tree, parsimonious tree, computer simulation, unrooted, unweighted pair group method, [PAD] [PAD], [PAD] [PAD], [PAD], [PAD] [PAD], [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD], [PAD]"
Paper_00063,Self-Consistent Equations Including Exchange and Correlation Effects,"['W. Kohn', 'L. J. Sham']",1965,Physical Review,Journal,,A1133-A1138,140,4A,10.1103/physrev.140.a1133,"From a theory of Hohenberg and Kohn, approximation methods for treating an inhomogeneous system of interacting electrons are developed. These methods are exact for systems of slowly varying or high density. For the ground state, they lead to self-consistent equations analogous to the Hartree and Hartree-Fock equations, respectively. In these equations the exchange and correlation portions of the chemical potential of a uniform electron gas appear as additional effective potentials. (The exchange portion of our effective potential differs from that due to Slater by a factor of $\frac{2}{3}$.) Electronic systems at finite temperatures and in magnetic fields are also treated by similar methods. An appendix deals with a further correction for systems with short-wavelength density oscillations.","['Physics', 'Hartree–Fock method', 'Electron', 'Fermi gas', 'Hartree', 'Electronic correlation', 'Ground state', 'Quantum electrodynamics', 'Quantum mechanics']","approximation methods, inhomogeneous system, interacting electrons, ground state, correlation, chemical potential, uniform electron gas, electronic systems, magnetic fields"
Paper_00064,CRC Handbook of Chemistry and Physics,['W.M. Haynes'],2014,CRC Press eBooks,Unknown,,,,,10.1201/b17118,"Proudly serving the scientific community for over a century, this 95th edition of the CRC Handbook of Chemistry and Physics is an update of a classic reference, mirroring the growth and direction of science. This venerable work continues to be the most accessed and respected scientific reference in the world. An authoritative resource consisting of","['Chemistry', 'Physics', 'Engineering physics']","##c, chemistry"
Paper_00066,Attention Is All You Need,"['Ashish Vaswani', 'Noam Shazeer', 'Niki Parmar', 'Jakob Uszkoreit', 'Llion Jones', 'Aidan N. Gomez', 'Łukasz Kaiser', 'Illia Polosukhin']",2017,arXiv (Cornell University),Unknown,,,,,10.48550/arxiv.1706.03762,"The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.","['Computer science', 'Machine translation', 'Transformer', 'BLEU', 'Encoder', 'Artificial intelligence', 'Parallelizable manifold', 'Parsing', 'Natural language processing', 'Decoding methods', 'Language model', 'Task (project management)', 'Convolutional neural network', 'Speech recognition', 'Machine learning', 'Algorithm', 'Physics', 'Management', 'Quantum mechanics', 'Voltage', 'Economics', 'Operating system']","dominant sequence transduction models, convolutional neural networks, attention mechanism, network architecture, transformer, attention mechanisms, con, machine translation tasks"
Paper_00068,Global cancer statistics,"['Ahmedin Jemal', 'Freddie Bray', 'Melissa M. Center', 'Jacques Ferlay', 'Elizabeth Ward', 'David Forman']",2011,CA A Cancer Journal for Clinicians,Journal,,69-90,61,2,10.3322/caac.20107,Statistics are given for global patterns of cancer incidence and mortality for males and females in 23 regions of the world.,"['Medicine', 'Statistics', 'Cancer incidence', 'Incidence (geometry)', 'Cancer', 'Demography', 'Internal medicine', 'Mathematics', 'Physics', 'Sociology', 'Optics']",females
Paper_00069,The Sequence Alignment/Map format and SAMtools,"['Heng Li', 'Robert E. Handsaker', 'Alec Wysoker', 'Tim Fennell', 'Jue Ruan', 'Nils Homer', 'Gábor Marth', 'Gonçalo R. Abecasis', 'Richard Durbin']",2009,Bioinformatics,Journal,,2078-2079,25,16,10.1093/bioinformatics/btp352,"Summary: The Sequence Alignment/Map (SAM) format is a generic alignment format for storing read alignments against reference sequences, supporting short and long reads (up to 128 Mbp) produced by different sequencing platforms. It is flexible in style, compact in size, efficient in random access and is the format in which alignments from the 1000 Genomes Project are released. SAMtools implements various utilities for post-processing alignments in the SAM format, such as indexing, variant caller and alignment viewer, and thus provides universal tools for processing read alignments. Availability: http://samtools.sourceforge.net Contact: rd@sanger.ac.uk","['Computer science', 'Search engine indexing', 'Sequence alignment', 'k-mer', 'Multiple sequence alignment', 'File format', 'Sanger sequencing', 'Sequence (biology)', 'Alignment-free sequence analysis', 'Information retrieval', 'Computational biology', 'Genome', 'DNA sequencing', 'Database', 'Biology', 'Genetics', 'Peptide sequence', 'DNA', 'Gene']","generic alignment format, read alignments, reference sequences, sequencing, random access, 1000 genomes, samtools, indexing, variant caller, alignment viewer, read alignments"
Paper_00070,Electrophoretic transfer of proteins from polyacrylamide gels to nitrocellulose sheets: procedure and some applications.,"['Harry Towbin', 'T. Staehelin', 'J. Gordon']",1979,Proceedings of the National Academy of Sciences,Journal,,4350-4354,76,9,10.1073/pnas.76.9.4350,"A method has been devised for the electrophoretic transfer of proteins from polyacrylamide gels to nitrocellulose sheets. The method results in quantitative transfer of ribosomal proteins from gels containing urea. For sodium dodecyl sulfate gels, the original band pattern was obtained with no loss of resolution, but the transfer was not quantitative. The method allows detection of proteins by autoradiography and is simpler than conventional procedures. The immobilized proteins were detectable by immunological procedures. All additional binding capacity on the nitrocellulose was blocked with excess protein; then a specific antibody was bound and, finally, a second antibody directed against the first antibody. The second antibody was either radioactively labeled or conjugated to fluorescein or to peroxidase. The specific protein was then detected by either autoradiography, under UV light, or by the peroxidase reaction product, respectively. In the latter case, as little as 100 pg of protein was clearly detectable. It is anticipated that the procedure will be applicable to analysis of a wide variety of proteins with specific reactions or ligands.","['Nitrocellulose', 'Polyacrylamide', 'Chemistry', 'Peroxidase', 'Urea', 'Chromatography', 'Electrophoresis', 'Polyacrylamide gel electrophoresis', 'Sodium dodecyl sulfate', 'Collodion', 'Electroblotting', 'Fluorescein', 'Gel electrophoresis', 'Biochemistry', 'Fluorescence', 'Enzyme', 'Polymer chemistry', 'Membrane', 'Physics', 'Quantum mechanics']","electrophoretic transfer, polyacrylamide gels, nitrocel, ##lose sheets, ribosomal proteins, urea, sodium, band pattern, ##los, per, per, ##ida"
Paper_00071,Preferred Reporting Items for Systematic Reviews and Meta-Analyses: The PRISMA Statement,"['David Moher', 'Alessandro Liberati', 'Jennifer Tetzlaff', 'Douglas G. Altman']",2009,PLoS Medicine,Journal,,e1000097-e1000097,6,7,10.1371/journal.pmed.1000097,"se ha posicionado como un centro de referencia asistencial y académica, con la proyección de conformar clínicas o centros de excelencia.Para lograr este objetivo, es indispensable que realice y se ciña a sus propias guías de práctica clínica o estándares clínicos basados en la evidencia (ECBE), que permita una adecuada y estandarizada atención de pacientes aplicando la mejor evidencia médica disponible.La obesidad es una patología de alta prevalencia en la población general, siendo uno de los motivos de consulta más","['Systematic review', 'Meta-analysis', 'MEDLINE', 'Statement (logic)', 'Medicine', 'Psychology', 'Family medicine', 'Political science', 'Pathology', 'Law']","##ide, [PAD]"
Paper_00073,Measuring inconsistency in meta-analyses,"['Julian P. T. Higgins', 'Simon G. Thompson', 'Jonathan J Deeks', 'Douglas G. Altman']",2003,BMJ,Journal,,557-560,327,7414,10.1136/bmj.327.7414.557,"Cochrane Reviews have recently started including the quantity I 2 to help readers assess the consistency of the results of studies in meta-analyses. What does this new quantity mean, and why is assessment of heterogeneity so important to clinical practice? 

Systematic reviews and meta-analyses can provide convincing and reliable evidence relevant to many aspects of medicine and health care.1 Their value is especially clear when the results of the studies they include show clinically important effects of similar magnitude. However, the conclusions are less clear when the included studies have differing results. In an attempt to establish whether studies are consistent, reports of meta-analyses commonly present a statistical test of heterogeneity. The test seeks to determine whether there are genuine differences underlying the results of the studies (heterogeneity), or whether the variation in findings is compatible with chance alone (homogeneity). However, the test is susceptible to the number of trials included in the meta-analysis. We have developed a new quantity, I 2, which we believe gives a better measure of the consistency between trials in a meta-analysis.

Assessment of the consistency of effects across studies is an essential part of meta-analysis. Unless we know how consistent the results of studies are, we cannot determine the generalisability of the findings of the meta-analysis. Indeed, several hierarchical systems for grading evidence state that the results of studies must be consistent or homogeneous to obtain the highest grading.2–4

Tests for heterogeneity are commonly used to decide on methods for combining studies and for concluding consistency or inconsistency of findings.5 6 But what does the test achieve in practice, and how should the resulting P values be interpreted?

A test for heterogeneity examines the null hypothesis that all studies are evaluating the same effect. The usual test statistic …","['Computer science', 'Data science', 'Information retrieval', 'World Wide Web']","cochrane reviews, heterogeneity, clinical practice, systematic reviews, medicine, health care, statistical test, heterogeneity, heterogeneity, chance, homogeneity, hierarchical systems, grading evidence, heterogeneity, ##onsiste, heterogeneity, test"
Paper_00074,"Perceived Usefulness, Perceived Ease of Use, and User Acceptance of Information Technology",['Fred D. Davis'],1989,MIS Quarterly,Journal,,319-319,13,3,10.2307/249008,"Valid measurement scales for predicting user acceptance of computers are in short supply. Most subjective measures used in practice are unvalidated, and their relationship to system usage is unknown. The present research develops and validates new scales for two specific variables, perceived usefulness and perceived ease of use, which are hypothesized to be fundamental determinants of user acceptance. Definitions of these two variables were used to develop scale items that were pretested for content validity and then tested for reliability and construct validity in two studies involving a total of 152 users and four application programs. The measures were refined and streamlined, resulting in two six-item scales with reliabilities of .98 for usefulness and .94 for ease of use. The scales exhibited hgih convergent, discriminant, and factorial validity. Perceived usefulness was significnatly correlated with both self-reported current usage r = .63, Study 1) and self-predicted future usage r = .85, Study 2). Perceived ease of use was also significantly correlated with current usage r = .45, Study 1) and future usage r = .59, Study 2). In both studies, usefulness had a signficnatly greater correaltion with usage behavior than did ease of use. Regression analyses suggest that perceived ease of use may actually be a causal antecdent to perceived usefulness, as opposed to a parallel, direct determinant of system usage. Implications are drawn for future research on user acceptance.","['Technology acceptance model', 'Usability', 'Information technology', 'Information system', 'Knowledge management', 'Business', 'Marketing', 'Psychology', 'Computer science', 'Human–computer interaction', 'Engineering', 'Electrical engineering', 'Operating system']","valid measurement scales, user acceptance, subjective measures, system usage, perceived usefulness, perceived ease of use, user acceptance, content validity, construct validity, factorial validity, perceived, usefulness, usage behavior, user acceptance"
Paper_00075,ImageNet: A large-scale hierarchical image database,"['Jia Deng', 'Wei Dong', 'Richard Socher', 'Li-Jia Li', 'Kai Li', 'Li Fei-Fei']",2009,2009 IEEE Conference on Computer Vision and Pattern Recognition,Conference,"2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), Miami, FL",,,,10.1109/cvpr.2009.5206848,"The explosion of image data on the Internet has the potential to foster more sophisticated and robust models and algorithms to index, retrieve, organize and interact with images and multimedia data. But exactly how such data can be harnessed and organized remains a critical problem. We introduce here a new database called ""ImageNet"", a large-scale ontology of images built upon the backbone of the WordNet structure. ImageNet aims to populate the majority of the 80,000 synsets of WordNet with an average of 500–1000 clean and full resolution images. This will result in tens of millions of annotated images organized by the semantic hierarchy of WordNet. This paper offers a detailed analysis of ImageNet in its current state: 12 subtrees with 5247 synsets and 3.2 million images in total. We show that ImageNet is much larger in scale and diversity and much more accurate than the current image datasets. Constructing such a large-scale database is a challenging task. We describe the data collection scheme with Amazon Mechanical Turk. Lastly, we illustrate the usefulness of ImageNet through three simple applications in object recognition, image classification and automatic object clustering. We hope that the scale, accuracy, diversity and hierarchical structure of ImageNet can offer unparalleled opportunities to researchers in the computer vision community and beyond.","['Computer science', 'WordNet', 'Hierarchy', 'Cluster analysis', 'Artificial intelligence', 'Information retrieval', 'Scale (ratio)', 'Object (grammar)', 'Image (mathematics)', 'Ontology', 'Data mining', 'Machine learning', 'Pattern recognition (psychology)', 'Philosophy', 'Physics', 'Epistemology', 'Quantum mechanics', 'Economics', 'Market economy']","image data, internet, multimedia data, imagenet, wordnet, imagenet, wordnet, semantic hierarchy, wordnet, imagenet, imagenet, data collection scheme, amazon mechanical turk, imagenet, object recognition, image classification, automatic object clustering, hierarchical structure, imagenet, computer vision, [PAD] [PAD], [PAD] [PAD], [PAD]"
Paper_00076,Evaluating Structural Equation Models with Unobservable Variables and Measurement Error,"['Claes Fornell', 'David F. Larcker']",1981,Journal of Marketing Research,Journal,,39-39,18,1,10.2307/3151312,"The statistical tests used in the analysis of structural equation models with unobservable variables and measurement error are examined. A drawback of the commonly applied chi square test, in addit...","['Unobservable', 'Structural equation modeling', 'Econometrics', 'Statistics', 'Observational error', 'Mathematics', 'Applied mathematics', 'Computer science']","statistical tests, structural equation models, unobservable variables, measurement error, chi square test, [PAD], [PAD], [PAD] [PAD] [PAD], [PAD] [PAD] [PAD], [PAD], [PAD] [PAD] [PAD]"
Paper_00077,Evaluating Structural Equation Models with Unobservable Variables and Measurement Error,"['Claes Fornell', 'David F. Larcker']",1981,Journal of Marketing Research,Journal,,39-50,18,1,10.1177/002224378101800104,"The statistical tests used in the analysis of structural equation models with unobservable variables and measurement error are examined. A drawback of the commonly applied chi square test, in addition to the known problems related to sample size and power, is that it may indicate an increasing correspondence between the hypothesized model and the observed data as both the measurement properties and the relationship between constructs decline. Further, and contrary to common assertion, the risk of making a Type II error can be substantial even when the sample size is large. Moreover, the present testing methods are unable to assess a model's explanatory power. To overcome these problems, the authors develop and apply a testing system based on measures of shared variance within the structural model, measurement model, and overall model.","['Unobservable', 'Structural equation modeling', 'Econometrics', 'Variance (accounting)', 'Explanatory power', 'Observational error', 'Statistics', 'Type I and type II errors', 'Sample size determination', 'Errors-in-variables models', 'LISREL', 'Mathematics', 'Assertion', 'Sample (material)', 'Bivariate analysis', 'Goodness of fit', 'Computer science', 'Philosophy', 'Chemistry', 'Accounting', 'Epistemology', 'Chromatography', 'Business', 'Programming language']","statistical tests, structural equation models, unobservable variables, measurement error, chi square test, sample size, shared variance"
Paper_00080,Trimmomatic: a flexible trimmer for Illumina sequence data,"['Anthony Bolger', 'Marc Lohse', 'Björn Usadel']",2014,Bioinformatics,Journal,,2114-2120,30,15,10.1093/bioinformatics/btu170,"Motivation: Although many next-generation sequencing (NGS) read preprocessing tools already existed, we could not find any tool or combination of tools that met our requirements in terms of flexibility, correct handling of paired-end data and high performance. We have developed Trimmomatic as a more flexible and efficient preprocessing tool, which could correctly handle paired-end data.","['Preprocessor', 'Computer science', 'Flexibility (engineering)', 'Java', 'Data mining', 'Data pre-processing', 'Sequence (biology)', 'Operating system', 'Programming language', 'Biology', 'Statistics', 'Genetics', 'Mathematics']","trimmomatic, preproces, [PAD] [PAD], [PAD] [PAD] [PAD] [PAD]"
Paper_00081,Fast and accurate short read alignment with Burrows–Wheeler transform,"['Heng Li', 'Richard Durbin']",2009,Bioinformatics,Journal,,1754-1760,25,14,10.1093/bioinformatics/btp324,"Abstract Motivation: The enormous amount of short reads generated by the new DNA sequencing technologies call for the development of fast and accurate read alignment programs. A first generation of hash table-based methods has been developed, including MAQ, which is accurate, feature rich and fast enough to align short reads from a single individual. However, MAQ does not support gapped alignment for single-end reads, which makes it unsuitable for alignment of longer reads where indels may occur frequently. The speed of MAQ is also a concern when the alignment is scaled up to the resequencing of hundreds of individuals. Results: We implemented Burrows-Wheeler Alignment tool (BWA), a new read alignment package that is based on backward search with Burrows–Wheeler Transform (BWT), to efficiently align short sequencing reads against a large reference sequence such as the human genome, allowing mismatches and gaps. BWA supports both base space reads, e.g. from Illumina sequencing machines, and color space reads from AB SOLiD machines. Evaluations on both simulated and real data suggest that BWA is ∼10–20× faster than MAQ, while achieving similar accuracy. In addition, BWA outputs alignment in the new standard SAM (Sequence Alignment/Map) format. Variant calling and other downstream analyses after the alignment can be achieved with the open source SAMtools software package. Availability: http://maq.sourceforge.net Contact: rd@sanger.ac.uk","['Computer science', 'Software', 'Alignment-free sequence analysis', 'Hash table', 'Reference genome', 'Hybrid genome assembly', 'Indel', 'Multiple sequence alignment', 'Sequence alignment', 'DNA sequencing', 'Data mining', 'Hash function', 'Algorithm', 'Biology', 'Genetics', 'Programming language', 'DNA', 'Genotype', 'Single-nucleotide polymorphism', 'Peptide sequence', 'Gene']","dna sequencing, maq, gapped alignment, backward search, burrows, human, ##wa, base space reads, illumina sequencing machines, color space reads, ab solid machines, ##wa"
Paper_00083,Adam: A Method for Stochastic Optimization,"['Diederik P. Kingma', 'Jimmy Ba']",2014,arXiv (Cornell University),Unknown,,,,,10.48550/arxiv.1412.6980,"We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.","['Regret', 'Computer science', 'Mathematical optimization', 'Diagonal', 'Stochastic optimization', 'Convergence (economics)', 'Rate of convergence', 'Optimization problem', 'Mathematics', 'Key (lock)', 'Geometry', 'Computer security', 'Machine learning', 'Economics', 'Economic growth']","adam, stochastic objective functions, adaptive estimates, memory requirements, diagonal rescaling, theoretical convergence properties, regret bound, convergence, online convex optimization framework, adam, ##astic optimization, adamax, infinity norm, [PAD], [PAD], [PAD], [PAD]"
Paper_00085,Gradient-based learning applied to document recognition,"['Yann LeCun', 'Léon Bottou', 'Yoshua Bengio', 'Patrick Haffner']",1998,Proceedings of the IEEE,Journal,,2278-2324,86,11,10.1109/5.726791,"Multilayer neural networks trained with the back-propagation algorithm constitute the best example of a successful gradient based learning technique. Given an appropriate network architecture, gradient-based learning algorithms can be used to synthesize a complex decision surface that can classify high-dimensional patterns, such as handwritten characters, with minimal preprocessing. This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task. Convolutional neural networks, which are specifically designed to deal with the variability of 2D shapes, are shown to outperform all other techniques. Real-life document recognition systems are composed of multiple modules including field extraction, segmentation recognition, and language modeling. A new learning paradigm, called graph transformer networks (GTN), allows such multimodule systems to be trained globally using gradient-based methods so as to minimize an overall performance measure. Two systems for online handwriting recognition are described. Experiments demonstrate the advantage of global training, and the flexibility of graph transformer networks. A graph transformer network for reading a bank cheque is also described. It uses convolutional neural network character recognizers combined with global training techniques to provide record accuracy on business and personal cheques. It is deployed commercially and reads several million cheques per day.","['Computer science', 'Artificial intelligence', 'Convolutional neural network', 'Intelligent character recognition', 'Handwriting recognition', 'Transformer', 'Artificial neural network', 'Pattern recognition (psychology)', 'Handwriting', 'Preprocessor', 'Deep learning', 'Graph', 'Speech recognition', 'Machine learning', 'Feature extraction', 'Character recognition', 'Theoretical computer science', 'Physics', 'Quantum mechanics', 'Voltage', 'Image (mathematics)']","multilayer neural networks, gradient based learning technique, handwritten characters, handwritten character recognition, handwritten digit recognition, convolutional neural networks, 2d, field extraction, segmentation recognition, language modeling, graph transformer networks, gt, online handwriting recognition, global training, graph transformer networks, graph transformer network, bank cheque, convolutional neural network, global training techniques, record accuracy, personal cheques"
Paper_00086,The CES-D Scale,['Lenore Sawyer Radloff'],1977,Applied Psychological Measurement,Journal,,385-401,1,3,10.1177/014662167700100306,"The CES-D scale is a short self-report scale designed to measure depressive symptomatology in the general population. The items of the scale are symptoms associated with depression which have been used in previously validated longer scales. The new scale was tested in household interview surveys and in psychiatric settings. It was found to have very high internal consistency and adequate test- retest repeatability. Validity was established by pat terns of correlations with other self-report measures, by correlations with clinical ratings of depression, and by relationships with other variables which support its construct validity. Reliability, validity, and factor structure were similar across a wide variety of demographic characteristics in the general population samples tested. The scale should be a useful tool for epidemiologic studies of de pression.","['Psychology', 'Scale (ratio)', 'Construct validity', 'Reliability (semiconductor)', 'Test validity', 'Clinical psychology', 'Psychometrics', 'Population', 'Internal consistency', 'Medicine', 'Environmental health', 'Cartography', 'Geography', 'Power (physics)', 'Physics', 'Quantum mechanics']","depressive symptomatology, general population, depression, household interview surveys, psychiatric settings, internal consistency, clinical ratings, depression, reliability, validity, factor structure, epide, de"
Paper_00087,Density-functional exchange-energy approximation with correct asymptotic behavior,['Axel D. Becke'],1988,"Physical review. A, General physics",Journal,,3098-3100,38,6,10.1103/physreva.38.3098,"Current gradient-corrected density-functional approximations for the exchange energies of atomic and molecular systems fail to reproduce the correct 1/r asymptotic behavior of the exchange-energy density. Here we report a gradient-corrected exchange-energy functional with the proper asymptotic limit. Our functional, containing only one parameter, fits the exact Hartree-Fock exchange energies of a wide variety of atomic systems with remarkable accuracy, surpassing the performance of previous functionals containing two parameters or more.","['Hybrid functional', 'Limit (mathematics)', 'Physics', 'Density functional theory', 'Energy (signal processing)', 'Energy functional', 'Variety (cybernetics)', 'Local-density approximation', 'Statistical physics', 'Exchange interaction', 'Quantum electrodynamics', 'Quantum mechanics', 'Mathematical analysis', 'Mathematics', 'Statistics', 'Ferromagnetism']","exchange energies, molecular systems, asymptotic behavior, asymptotic limit, atomic systems, [PAD]"
Paper_00088,Mind in Society: The Development of Higher Psychological Processes,['L. S. Vygotsky'],1978,['American Journal of Orthopsychiatry'],Unknown,,530-536,49,3,10.1111/j.1939-0025.1979.tb02640.x,Introduction Michael Cole and Sylvia Scribner Biographical Note on L. S. Vygotsky Basic Theory and Data 1. Tool and Symbol in Child Development 2. The Development of Perception and Attention 3. Mastery of Memory and Thinking 4. Internalization of Higher Psychological Functions 5. Problems of Method Educational Implications 6. Interaction between Learning and Development 7. The Role of Play in Development 8. The Prehistory of Written Language Afterword Vera John-Steiner and Ellen Souberman Notes Vygotsky's Works Index,"['Symbol (formal)', 'Perception', 'Psychology', 'Index (typography)', 'Cognitive science', 'Epistemology', 'Psychoanalysis', 'Cognitive psychology', 'Linguistics', 'Philosophy', 'Computer science', 'World Wide Web']","child development, perception, attention, thinking, higher psychological functions, ##his, written language"
Paper_00089,"Genetic algorithms in search, optimization, and machine learning",[],1989,Choice Reviews Online,Journal,,27-0936,27,02,10.5860/choice.27-0936,"From the Publisher:
This book brings together - in an informal and tutorial fashion - the computer techniques, mathematical tools, and research results that will enable both students and practitioners to apply genetic algorithms to problems in many fields. 

Major concepts are illustrated with running examples, and major algorithms are illustrated by Pascal computer programs. No prior knowledge of GAs or genetics is assumed, and only a minimum of computer programming and mathematics background is required.","['Computer science', 'Artificial intelligence', 'Machine learning', 'Quality control and genetic algorithms', 'Algorithm', 'Genetic algorithm', 'Meta-optimization']","computer techniques, mathematical tools, genetic algorithms, pascal computer programs"
Paper_00091,Colorimetric Method for Determination of Sugars and Related Substances,"['Michel Dubois', 'K. A. Gilles', 'J. K. Hamilton', 'P. A. Rebers', 'F. Smith']",1956,Analytical Chemistry,Journal,,350-356,28,3,10.1021/ac60111a017,"ADVERTISEMENT RETURN TO ISSUEPREVArticleNEXTColorimetric Method for Determination of Sugars and Related SubstancesMichel. DuBois, K. A. Gilles, J. K. Hamilton, P. A. Rebers, and Fred. SmithCite this: Anal. Chem. 1956, 28, 3, 350–356Publication Date (Print):March 1, 1956Publication History Published online1 May 2002Published inissue 1 March 1956https://pubs.acs.org/doi/10.1021/ac60111a017https://doi.org/10.1021/ac60111a017research-articleACS PublicationsRequest reuse permissionsArticle Views60836Altmetric-Citations37027LEARN ABOUT THESE METRICSArticle Views are the COUNTER-compliant sum of full text article downloads since November 2008 (both PDF and HTML) across all institutions and individuals. These metrics are regularly updated to reflect usage leading up to the last few days.Citations are the number of other articles citing this article, calculated by Crossref and updated daily. Find more information about Crossref citation counts.The Altmetric Attention Score is a quantitative measure of the attention that a research article has received online. Clicking on the donut icon will load a page at altmetric.com with additional details about the score and the social media presence for the given article. Find more information on the Altmetric Attention Score and how the score is calculated. Share Add toView InAdd Full Text with ReferenceAdd Description ExportRISCitationCitation and abstractCitation and referencesMore Options Share onFacebookTwitterWechatLinked InRedditEmail Other access optionsGet e-Alertsclose Get e-Alerts","['Citation', 'Icon', 'Altmetrics', 'Social media', 'Computer science', 'Information retrieval', 'Library science', 'World Wide Web', 'Programming language']","##varticlenextcolor, ##tric method, sugar, permissionsar, ##le, ##f, ##f, altmetric attention score, social, altmetric, ##citation, abstract, ##ation, references"
Paper_00093,Inhomogeneous Electron Gas,"['P. C. Hohenberg', 'W. Kohn']",1964,Physical Review,Journal,,B864-B871,136,3B,10.1103/physrev.136.b864,"This paper deals with the ground state of an interacting electron gas in an external potential $v(\mathrm{r})$. It is proved that there exists a universal functional of the density, $F[n(\mathrm{r})]$, independent of $v(\mathrm{r})$, such that the expression $E\ensuremath{\equiv}\ensuremath{\int}v(\mathrm{r})n(\mathrm{r})d\mathrm{r}+F[n(\mathrm{r})]$ has as its minimum value the correct ground-state energy associated with $v(\mathrm{r})$. The functional $F[n(\mathrm{r})]$ is then discussed for two situations: (1) $n(\mathrm{r})={n}_{0}+\stackrel{\ifmmode \tilde{}\else \~{}\fi{}}{n}(\mathrm{r})$, $\frac{\stackrel{\ifmmode \tilde{}\else \~{}\fi{}}{n}}{{n}_{0}}\ensuremath{\ll}1$, and (2) $n(\mathrm{r})=\ensuremath{\phi}(\frac{\mathrm{r}}{{r}_{0}})$ with $\ensuremath{\phi}$ arbitrary and ${r}_{0}\ensuremath{\rightarrow}\ensuremath{\infty}$. In both cases $F$ can be expressed entirely in terms of the correlation energy and linear and higher order electronic polarizabilities of a uniform electron gas. This approach also sheds some light on generalized Thomas-Fermi methods and their limitations. Some new extensions of these methods are presented.","['Physics', 'Energy (signal processing)', 'Order (exchange)', 'Ground state', 'Fermi gas', 'State (computer science)', 'Electron', 'Atomic physics', 'Combinatorics', 'Quantum mechanics', 'Mathematics', 'Finance', 'Algorithm', 'Economics']","ground state, interacting electron gas, external potential, universal functional, correlation energy, uniform electron gas"
Paper_00095,"Bias in meta-analysis detected by a simple, graphical test","['Matthias Egger', 'George Davey Smith', 'Martin Schneider', 'C. Minder']",1997,BMJ,Journal,,629-634,315,7109,10.1136/bmj.315.7109.629,"<h3>Abstract</h3> <b>Objective:</b> Funnel plots (plots of effect estimates against sample size) may be useful to detect bias in meta-analyses that were later contradicted by large trials. We examined whether a simple test of asymmetry of funnel plots predicts discordance of results when meta-analyses are compared to large trials, and we assessed the prevalence of bias in published meta-analyses. <b>Design:</b> Medline search to identify pairs consisting of a meta-analysis and a single large trial (concordance of results was assumed if effects were in the same direction and the meta-analytic estimate was within 30% of the trial); analysis of funnel plots from 37 meta-analyses identified from a hand search of four leading general medicine journals 1993-6 and 38 meta-analyses from the second 1996 issue of the <i>Cochrane Database of Systematic Reviews</i>. <b>Main outcome measure:</b> Degree of funnel plot asymmetry as measured by the intercept from regression of standard normal deviates against precision. <b>Results:</b> In the eight pairs of meta-analysis and large trial that were identified (five from cardiovascular medicine, one from diabetic medicine, one from geriatric medicine, one from perinatal medicine) there were four concordant and four discordant pairs. In all cases discordance was due to meta-analyses showing larger effects. Funnel plot asymmetry was present in three out of four discordant pairs but in none of concordant pairs. In 14 (38%) journal meta-analyses and 5 (13%) Cochrane reviews, funnel plot asymmetry indicated that there was bias. <b>Conclusions:</b> A simple analysis of funnel plots provides a useful test for the likely presence of bias in meta-analyses, but as the capacity to detect bias will be limited when meta-analyses are based on a limited number of small trials the results from such analyses should be treated with considerable caution. <h3>Key messages</h3> Systematic reviews of randomised trials are the best strategy for appraising evidence; however, the findings of some meta-analyses were later contradicted by large trials Funnel plots, plots of the trials9 effect estimates against sample size, are skewed and asymmetrical in the presence of publication bias and other biases Funnel plot asymmetry, measured by regression analysis, predicts discordance of results when meta-analyses are compared with single large trials Funnel plot asymmetry was found in 38% of meta-analyses published in leading general medicine journals and in 13% of reviews from the <i>Cochrane Database of Systematic Reviews</i> Critical examination of systematic reviews for publication and related biases should be considered a routine procedure","['Funnel plot', 'Publication bias', 'Meta-analysis', 'Concordance', 'Meta-regression', 'Medicine', 'Asymmetry', 'Statistics', 'Systematic error', 'Forest plot', 'Sample size determination', 'Mathematics', 'Internal medicine', 'Physics', 'Quantum mechanics']","funnel plots, effect estimates, sample size, asymmetry, funnel plots, funnel plots, general medicine, funnel plot, cardiovascular medicine, diabetic medicine, geriatric medicine, perinatal medicine, funnel plot asymmetry, funnel plot as, funnel plots, systematic reviews, randomised trials, funnel, publication bias, funnel plot as"
Paper_00097,A RAPID METHOD OF TOTAL LIPID EXTRACTION AND PURIFICATION,"['E. G. Bligh', 'W. J. Dyer']",1959,Canadian Journal of Biochemistry and Physiology,Journal,,911-917,37,8,10.1139/o59-099,"Lipid decomposition studies in frozen fish have led to the development of a simple and rapid method for the extraction and purification of lipids from biological materials. The entire procedure can be carried out in approximately 10 minutes; it is efficient, reproducible, and free from deleterious manipulations. The wet tissue is homogenized with a mixture of chloroform and methanol in such proportions that a miscible system is formed with the water in the tissue. Dilution with chloroform and water separates the homogenate into two layers, the chloroform layer containing all the lipids and the methanolic layer containing all the non-lipids. A purified lipid extract is obtained merely by isolating the chloroform layer. The method has been applied to fish muscle and may easily be adapted to use with other tissues.","['Chloroform', 'Chromatography', 'Extraction (chemistry)', 'Chemistry', 'Dilution', 'Methanol', 'Fish <Actinopterygii>', 'Biology', 'Organic chemistry', 'Fishery', 'Physics', 'Thermodynamics']","lipid decomposition, frozen fish, lip, wet, chloroform layer, lip, lip, purified lipid extract, fish muscle"
Paper_00098,"Short-Term Effects of Nose-Only Cigarette Smoke Exposure on Glutathione Redox Homeostasis, Cytochrome P450 1A1/2 and Respiratory Enzyme Activities in Mice Tissues","['Haider Raza', 'Annie John', 'Abderrahim Nemmar']",2013,Cellular Physiology and Biochemistry,Journal,,683-692,31,4-5,10.1159/000350087,"Short-term exposure to cigarette smoke (CS) or lipopolysaccharide (LPS) leads to acute lung inflammation through oxidant-antioxidant imbalance. We studied the response in mice exposed to smoke or LPS during five consecutive days, as measured by superoxide dismutase (SOD), catalase (CAT), and glutathione peroxidase (GPx) activities, as well as lipid peroxidation and nitric oxide levels in bronchoalveolar lavage fluid (BALF), lung homogenates, and plasma. Control mice were exposed to ambient air. Exposure to CS or LPS led to a similar influx of alveolar macrophages and neutrophils into the BALF; however, hydroxyproline levels were increased only in the CS group (p<0.001); SOD activity was increased in the BALF (p<0.001) and lung homogenates (p<0.05) of the CS group but was decreased in the BALF (p<0.05), lung homogenates (p<0.05) and plasma (p<0.01) of the LPS group. CAT activity was increased in the BALF (p<0.01), lung homogenates (p<0.001) and plasma (p<0.05) of the CS group but decreased in the BALF (p<0.001) and plasma (p<0.05) of the LPS group. GPx activity was reduced in the BALF (p<0.01) and plasma (p<0.01) of both the CS and LPS groups. Lipid peroxidation was increased in the BALF (p<0.001) and lung homogenates (p<0.001) of the CS group. Finally, the levels of nitrite were reduced in the CS (p<0.01) and LPS (p<0.001) groups. Our data show that the activity profiles of enzymes contributing to oxidant-antioxidant imbalance in the lungs differ depending on the inflammatory stimulus, and that SOD, CAT and GPx may be useful markers of oxidative stress in acute lung inflammation induced by exposure to CS.","['Chemistry', 'Tumor necrosis factor alpha', 'Reactive oxygen species', 'p38 mitogen-activated protein kinases', 'NADPH oxidase', 'Protein kinase B', 'Oxidative stress', 'Inflammation', 'NOX4', 'Phosphorylation', 'Protein kinase A', 'Endocrinology', 'Internal medicine', 'Immunology', 'Biochemistry', 'Biology', 'Medicine']","cigarette smoke, acute lung inflammation, superoxide dismuta, g, ##tat, ##one peroxida, lipid peroxidation, lung, ##d, lung, lipid per, lung homogen, ##tive stress, acute lung inflammation"
Paper_00099,A new look at the statistical model identification,['Hirotugu Akaike'],1974,IEEE Transactions on Automatic Control,Journal,,716-723,19,6,10.1109/tac.1974.1100705,The history of the development of statistical hypothesis testing in time series analysis is reviewed briefly and it is pointed out that the hypothesis testing procedure is not adequately defined as the procedure for statistical model identification. The classical maximum likelihood estimation procedure is reviewed and a new estimate minimum information theoretical criterion (AIC) estimate (MAICE) which is designed for the purpose of statistical identification is introduced. When there are several competing models the MAICE is defined by the model and the maximum likelihood estimates of the parameters which give the minimum of AIC defined by AIC = (-2)log-(maximum likelihood) + 2(number of independently adjusted parameters within the model). MAICE provides a versatile procedure for statistical model identification which is free from the ambiguities inherent in the application of conventional hypothesis testing procedure. The practical utility of MAICE in time series analysis is demonstrated with some numerical examples.,"['Identification (biology)', 'Statistical hypothesis testing', 'Statistical model', 'Maximum likelihood', 'Series (stratigraphy)', 'Estimation theory', 'Mathematics', 'Computer science', 'Statistical theory', 'Statistical analysis', 'Likelihood-ratio test', 'Statistics', 'Algorithm', 'Paleontology', 'Botany', 'Biology']","statistical hypothesis testing, time series analysis, hypothesis testing, statistical model identification, maximum likelihood estimation procedure, estimate minimum information theoretical criterion, statistical identification, maximum likelihood estimates, independently, maice, statistical model identification, maice, time series analysis, [PAD], [PAD], [PAD], [PAD], [PAD] [PAD], [PAD], [PAD], [PAD], [PAD], [PAD]"
Paper_00100,Image Quality Assessment: From Error Visibility to Structural Similarity,"['Zhou Wang', 'Alan C. Bovik', 'H.R. Sheikh', 'Eero P. Simoncelli']",2004,IEEE Transactions on Image Processing,Journal,,600-612,13,4,10.1109/tip.2003.819861,"Objective methods for assessing perceptual image quality traditionally attempted to quantify the visibility of errors (differences) between a distorted image and a reference image using a variety of known properties of the human visual system. Under the assumption that human visual perception is highly adapted for extracting structural information from a scene, we introduce an alternative complementary framework for quality assessment based on the degradation of structural information. As a specific example of this concept, we develop a structural similarity index and demonstrate its promise through a set of intuitive examples, as well as comparison to both subjective ratings and state-of-the-art objective methods on a database of images compressed with JPEG and JPEG2000. A MATLAB implementation of the proposed algorithm is available online at http://www.cns.nyu.edu//spl sim/lcv/ssim/.","['Artificial intelligence', 'JPEG', 'Computer science', 'Human visual system model', 'Image quality', 'Visibility', 'Computer vision', 'JPEG 2000', 'Structural similarity', 'Similarity (geometry)', 'Image compression', 'Transform coding', 'Visualization', 'Perception', 'Set (abstract data type)', 'Pattern recognition (psychology)', 'Image (mathematics)', 'Image processing', 'Discrete cosine transform', 'Neuroscience', 'Biology', 'Physics', 'Optics', 'Programming language']","objective methods, perceptual image quality, distorted image, reference image, human visual system, human visual perception, structural information, quality assessment, structural information, structural similarity index, subjective ratings, jpeg, ##lab"
Paper_00101,Maximum Likelihood from Incomplete Data Via the <i>EM</i> Algorithm,"['A. P. Dempster', 'N. M. Laird', 'Donald B. Rubin']",1977,Journal of the Royal Statistical Society Series B (Statistical Methodology),Journal,,1-22,39,1,10.1111/j.2517-6161.1977.tb01600.x,"Summary A broadly applicable algorithm for computing maximum likelihood estimates from incomplete data is presented at various levels of generality. Theory showing the monotone behaviour of the likelihood and convergence of the algorithm is derived. Many examples are sketched, including missing value situations, applications to grouped, censored or truncated data, finite mixture models, variance component estimation, hyperparameter estimation, iteratively reweighted least squares and factor analysis.","['Maximum likelihood', 'Expectation–maximization algorithm', 'Computer science', 'Algorithm', 'Mathematics', 'Statistics']","maximum likelihood estimates, incomplete data, monotone behaviour, missing value situations, finite mixture models, variance component estimation, hyperparameter estimation, iteratively reweighted least squares, factor analysis, [PAD] [PAD], [PAD] [PAD] [PAD] [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD] [PAD] [PAD], [PAD]"
Paper_00102,Regression Shrinkage and Selection Via the Lasso,['Robert Tibshirani'],1996,Journal of the Royal Statistical Society Series B (Statistical Methodology),Journal,,267-288,58,1,10.1111/j.2517-6161.1996.tb02080.x,SUMMARY We propose a new method for estimation in linear models. The ‘lasso’ minimizes the residual sum of squares subject to the sum of the absolute value of the coefficients being less than a constant. Because of the nature of this constraint it tends to produce some coefficients that are exactly 0 and hence gives interpretable models. Our simulation studies suggest that the lasso enjoys some of the favourable properties of both subset selection and ridge regression. It produces interpretable models like subset selection and exhibits the stability of ridge regression. There is also an interesting relationship with recent work in adaptive function estimation by Donoho and Johnstone. The lasso idea is quite general and can be applied in a variety of statistical models: extensions to generalized regression models and tree-based models are briefly described.,"['Shrinkage', 'Lasso (programming language)', 'Selection (genetic algorithm)', 'Regression', 'Computer science', 'Statistics', 'Artificial intelligence', 'Mathematics', 'World Wide Web']","linear models, lasso, residual sum of squares, lasso, subset selection, ridge regression, subset selection, ridge regression, adaptive function estimation, lasso, statistical, generalized regression models"
Paper_00106,The PRISMA 2020 statement: an updated guideline for reporting systematic reviews,"['Matthew J. Page', 'Joanne E. McKenzie', 'Patrick M. Bossuyt', 'Isabelle Boutron', 'Tammy Hoffmann', 'Cynthia D. Mulrow', 'Larissa Shamseer', 'Jennifer Tetzlaff', 'Elie A. Akl', 'Sue Brennan', 'Roger Chou', 'Julie Glanville', 'Jeremy Grimshaw', 'Asbjørn Hróbjartsson', 'Manoj M. Lalu', 'Tianjing Li', 'Elizabeth Loder', 'Evan Mayo‐Wilson', 'Steve McDonald', 'Luke A. McGuinness', 'Lesley Stewart', 'James Thomas', 'Andrea C. Tricco', 'Vivian Welch', 'Penny Whiting', 'David Moher']",2021,BMJ,Journal,,n71-n71,,,10.1136/bmj.n71,"The Preferred Reporting Items for Systematic reviews and Meta-Analyses (PRISMA) statement, published in 2009, was designed to help systematic reviewers transparently report why the review was done, what the authors did, and what they found. Over the past decade, advances in systematic review methodology and terminology have necessitated an update to the guideline. The PRISMA 2020 statement replaces the 2009 statement and includes new reporting guidance that reflects advances in methods to identify, select, appraise, and synthesise studies. The structure and presentation of the items have been modified to facilitate implementation. In this article, we present the PRISMA 2020 27-item checklist, an expanded checklist that details reporting recommendations for each item, the PRISMA 2020 abstract checklist, and the revised flow diagrams for original and updated reviews.","['Checklist', 'Systematic review', 'Guideline', 'Statement (logic)', 'Terminology', 'Presentation (obstetrics)', 'MEDLINE', 'Computer science', 'Management science', 'Medicine', 'Medical education', 'Psychology', 'Engineering', 'Political science', 'Pathology', 'Law', 'Linguistics', 'Philosophy', 'Cognitive psychology', 'Radiology']","systematic reviews, prism, systematic reviewers, systematic review methodology, prisma, prisma, prisma 2020, flow diagrams"
Paper_00109,Gene set enrichment analysis: A knowledge-based approach for interpreting genome-wide expression profiles,"['Aravind Subramanian', 'Pablo Tamayo', 'Vamsi K. Mootha', 'Sayan Mukherjee', 'Benjamin L. Ebert', 'Michael A. Gillette', 'Amanda G. Paulovich', 'Scott L. Pomeroy', 'Todd R. Golub', 'Eric S. Lander', 'Jill P. Mesirov']",2005,Proceedings of the National Academy of Sciences,Journal,,15545-15550,102,43,10.1073/pnas.0506580102,"Although genomewide RNA expression analysis has become a routine tool in biomedical research, extracting biological insight from such information remains a major challenge. Here, we describe a powerful analytical method called Gene Set Enrichment Analysis (GSEA) for interpreting gene expression data. The method derives its power by focusing on gene sets, that is, groups of genes that share common biological function, chromosomal location, or regulation. We demonstrate how GSEA yields insights into several cancer-related data sets, including leukemia and lung cancer. Notably, where single-gene analysis finds little similarity between two independent studies of patient survival in lung cancer, GSEA reveals many biological pathways in common. The GSEA method is embodied in a freely available software package, together with an initial database of 1,325 biologically defined gene sets.","['Computational biology', 'Gene', 'Biology', 'Function (biology)', 'Gene expression', 'Set (abstract data type)', 'Genome', 'Gene nomenclature', 'Gene expression profiling', 'Genetics', 'Bioinformatics', 'Computer science', 'Taxonomy (biology)', 'Botany', 'Nomenclature', 'Programming language']","genomewide rna expression analysis, biomedical research, gene set enrichment analysis, gsea, gene, ##romosomal, ##ea, lung cancer, patient survival, lung cancer, gsea"
Paper_00112,MEGA6: Molecular Evolutionary Genetics Analysis Version 6.0,"['Koichiro Tamura', 'Glen Stecher', 'Daniel S. Peterson', 'Alan Filipski', 'Sudhir Kumar']",2013,Molecular Biology and Evolution,Journal,,2725-2729,30,12,10.1093/molbev/mst197,"We announce the release of an advanced version of the Molecular Evolutionary Genetics Analysis (MEGA) software, which currently contains facilities for building sequence alignments, inferring phylogenetic histories, and conducting molecular evolutionary analysis. In version 6.0, MEGA now enables the inference of timetrees, as it implements the RelTime method for estimating divergence times for all branching points in a phylogeny. A new Timetree Wizard in MEGA6 facilitates this timetree inference by providing a graphical user interface (GUI) to specify the phylogeny and calibration constraints step-by-step. This version also contains enhanced algorithms to search for the optimal trees under evolutionary criteria and implements a more advanced memory management that can double the size of sequence data sets to which MEGA can be applied. Both GUI and command-line versions of MEGA6 can be downloaded from www.megasoftware.net free of charge.","['Biology', 'Phylogenetic tree', 'Mega-', 'Phylogenetics', 'Divergence (linguistics)', 'Inference', 'Wizard', 'Graphical user interface', 'Human evolutionary genetics', 'Software', 'Computer science', 'Multiple sequence alignment', 'Sequence (biology)', 'Evolutionary biology', 'Sequence alignment', 'Artificial intelligence', 'Programming language', 'Genetics', 'Gene', 'Linguistics', 'Philosophy', 'Physics', 'Astronomy', 'World Wide Web', 'Peptide sequence']","molecular evolutionary genetics analysis, mega, sequence alignments, phylogenetic histories, molecular evolutionary analysis, mega, time, reltime method, divergence times, timetree wizard, mega6, timetree, graphical user interface, ##ogen, calibration constraints, memory management, mega, mega6, megasoft"
Paper_00113,Preferred reporting items for systematic reviews and meta-analyses: the PRISMA Statement.,"['David Moher', 'Alessandro Liberati', 'Jennifer Tetzlaff', 'Douglas G. Altman']",2009,['International Journal of Surgery'],Unknown,,336-341,8,5,10.1016/j.ijsu.2010.02.007,"Systematic reviews and meta-analyses have become increasingly important in health care. Clinicians read them to keep up to date with their field,1,2 and they are often used as a starting point for developing clinical practice guidelines. Granting agencies may require a systematic review to ensure there is justification for further research,3 and some health care journals are moving in this direction.4 As with all research, the value of a systematic review depends on what was done, what was found, and the clarity of reporting. As with other publications, the reporting quality of systematic reviews varies, limiting readers' ability to assess the strengths and weaknesses of those reviews.

Several early studies evaluated the quality of review reports. In 1987, Mulrow examined 50 review articles published in 4 leading medical journals in 1985 and 1986 and found that none met all 8 explicit scientific criteria, such as a quality assessment of included studies.5 In 1987, Sacks and colleagues6 evaluated the adequacy of reporting of 83 meta-analyses on 23 characteristics in 6 domains. Reporting was generally poor; between 1 and 14 characteristics were adequately reported (mean = 7.7; standard deviation = 2.7). A 1996 update of this study found little improvement.7

In 1996, to address the suboptimal reporting of meta-analyses, an international group developed a guidance called the QUOROM Statement (QUality Of Reporting Of Meta-analyses), which focused on the reporting of meta-analyses of randomized controlled trials.8 In this article, we summarize a revision of these guidelines, renamed PRISMA (Preferred Reporting Items for Systematic reviews and Meta-Analyses), which have been updated to address several conceptual and practical advances in the science of systematic reviews (Box 1).



Box 1

Conceptual issues in the evolution from QUOROM to PRISMA","['Systematic review', 'CLARITY', 'Meta-analysis', 'Medicine', 'Strengths and weaknesses', 'MEDLINE', 'Health care', 'Alternative medicine', 'Consolidated Standards of Reporting Trials', 'Family medicine', 'Medical education', 'Psychology', 'Pathology', 'Political science', 'Social psychology', 'Biochemistry', 'Chemistry', 'Law']","systematic reviews, meta, health care, clinic, clinical practice guidelines, systematic, health care journals, systematic review, systematic reviews, medical journals, quality assessment, quorom statement, quality of reporting, randomized controlled trials, prisma, systematic reviews, quorom, prisma"
Paper_00114,Estimating the Dimension of a Model,['Gideon Schwarz'],1978,The Annals of Statistics,Journal,,,6,2,10.1214/aos/1176344136,"The problem of selecting one of a number of models of different dimensions is treated by finding its Bayes solution, and evaluating the leading terms of its asymptotic expansion. These terms are a valid large-sample criterion beyond the Bayesian context, since they do not depend on the a priori distribution.","['Mathematics', 'A priori and a posteriori', 'Context (archaeology)', 'Dimension (graph theory)', 'Bayes factor', ""Bayes' theorem"", 'Applied mathematics', 'Bayesian probability', 'Statistics', 'Econometrics', 'Combinatorics', 'Paleontology', 'Philosophy', 'Epistemology', 'Biology']","bayes solution, asymptotic expansion, bay, [PAD] [PAD], [PAD], [PAD], [PAD], [PAD], [PAD] [PAD] [PAD] [PAD], [PAD], [PAD], [PAD] [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD], [PAD] [PAD], [PAD] [PAD], [PAD], [PAD], [PAD], [PAD], [PAD] [PAD], [PAD] [PAD] [PAD]"
Paper_00115,A consistent and accurate<i>ab initio</i>parametrization of density functional dispersion correction (DFT-D) for the 94 elements H-Pu,"['Stefan Grimme', 'Jens Antony', 'Stephan Ehrlich', 'Helge Krieg']",2010,The Journal of Chemical Physics,Journal,,,132,15,10.1063/1.3382344,"The method of dispersion correction as an add-on to standard Kohn-Sham density functional theory (DFT-D) has been refined regarding higher accuracy, broader range of applicability, and less empiricism. The main new ingredients are atom-pairwise specific dispersion coefficients and cutoff radii that are both computed from first principles. The coefficients for new eighth-order dispersion terms are computed using established recursion relations. System (geometry) dependent information is used for the first time in a DFT-D type approach by employing the new concept of fractional coordination numbers (CN). They are used to interpolate between dispersion coefficients of atoms in different chemical environments. The method only requires adjustment of two global parameters for each density functional, is asymptotically exact for a gas of weakly interacting neutral atoms, and easily allows the computation of atomic forces. Three-body nonadditivity terms are considered. The method has been assessed on standard benchmark sets for inter- and intramolecular noncovalent interactions with a particular emphasis on a consistent description of light and heavy element systems. The mean absolute deviations for the S22 benchmark set of noncovalent interactions for 11 standard density functionals decrease by 15%-40% compared to the previous (already accurate) DFT-D version. Spectacular improvements are found for a tripeptide-folding model and all tested metallic systems. The rectification of the long-range behavior and the use of more accurate C(6) coefficients also lead to a much better description of large (infinite) systems as shown for graphene sheets and the adsorption of benzene on an Ag(111) surface. For graphene it is found that the inclusion of three-body terms substantially (by about 10%) weakens the interlayer binding. We propose the revised DFT-D method as a general tool for the computation of the dispersion energy in molecules and solids of any kind with DFT and related (low-cost) electronic structure methods for large systems.","['Density functional theory', 'Dispersion (optics)', 'Ab initio', 'Parametrization (atmospheric modeling)', 'Intramolecular force', 'Range (aeronautics)', 'Statistical physics', 'Computational chemistry', 'Cutoff', 'Basis set', 'Standard deviation', 'Physics', 'Chemistry', 'Molecular physics', 'Mathematics', 'Materials science', 'Quantum mechanics', 'Statistics', 'Composite material', 'Radiative transfer']","dispersion correction, dispersion coefficients, cutoff radii, recursion relations, fractional coordination numbers, ##spersion coefficients, weakly interacting neutral atoms, mean absolute deviations, non, ##valent interactions, graphene sheets, ##or, graphene, interlayer binding, dispersion energy, electronic structure"
Paper_00116,Going deeper with convolutions,"['Christian Szegedy', 'Wei Liu', 'Yangqing Jia', 'Pierre Sermanet', 'Scott Reed', 'Dragomir Anguelov', 'Dumitru Erhan', 'Vincent Vanhoucke', 'Andrew Rabinovich']",2015,Unknown,Unknown,,1-9,,,10.1109/cvpr.2015.7298594,"We propose a deep convolutional neural network architecture codenamed Inception that achieves the new state of the art for classification and detection in the ImageNet Large-Scale Visual Recognition Challenge 2014 (ILSVRC14). The main hallmark of this architecture is the improved utilization of the computing resources inside the network. By a carefully crafted design, we increased the depth and width of the network while keeping the computational budget constant. To optimize quality, the architectural decisions were based on the Hebbian principle and the intuition of multi-scale processing. One particular incarnation used in our submission for ILSVRC14 is called GoogLeNet, a 22 layers deep network, the quality of which is assessed in the context of classification and detection.","['Computer science', 'Architecture', 'Convolutional neural network', 'Intuition', 'Artificial intelligence', 'Deep learning', 'Network architecture', 'Context (archaeology)', 'Artificial neural network', 'Scale (ratio)', 'Pattern recognition (psychology)', 'Machine learning', 'Computer network', 'Biology', 'Art', 'Paleontology', 'Philosophy', 'Physics', 'Epistemology', 'Quantum mechanics', 'Visual arts']","deep convolutional neural network architecture, image, ilsvrc, computational, hebbian principle, ##svrc, googlenet, [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD] [PAD], [PAD] [PAD] [PAD], [PAD] [PAD], [PAD] [PAD], [PAD]"
Paper_00117,Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks,"['Shaoqing Ren', 'Kaiming He', 'Ross Girshick', 'Jian Sun']",2016,IEEE Transactions on Pattern Analysis and Machine Intelligence,Journal,,1137-1149,39,6,10.1109/tpami.2016.2577031,"State-of-the-art object detection networks depend on region proposal algorithms to hypothesize object locations. Advances like SPPnet [1] and Fast R-CNN [2] have reduced the running time of these detection networks, exposing region proposal computation as a bottleneck. In this work, we introduce a Region Proposal Network(RPN) that shares full-image convolutional features with the detection network, thus enabling nearly cost-free region proposals. An RPN is a fully convolutional network that simultaneously predicts object bounds and objectness scores at each position. The RPN is trained end-to-end to generate high-quality region proposals, which are used by Fast R-CNN for detection. We further merge RPN and Fast R-CNN into a single network by sharing their convolutional features-using the recently popular terminology of neural networks with 'attention' mechanisms, the RPN component tells the unified network where to look. For the very deep VGG-16 model [3], our detection system has a frame rate of 5 fps (including all steps) on a GPU, while achieving state-of-the-art object detection accuracy on PASCAL VOC 2007, 2012, and MS COCO datasets with only 300 proposals per image. In ILSVRC and COCO 2015 competitions, Faster R-CNN and RPN are the foundations of the 1st-place winning entries in several tracks. Code has been made publicly available.","['Computer science', 'Object detection', 'Artificial intelligence', 'Computer vision', 'Object (grammar)', 'Cognitive neuroscience of visual object recognition', 'Pattern recognition (psychology)']","region proposal algorithms, sppnet, region proposal network, ##p, ##p, objectness scores, ##p, neural networks, ##p, unified network, pascal voc, ##s, coco, ##pn"
Paper_00118,Optimization by Simulated Annealing,"['Scott Kirkpatrick', 'C. D. Gelatt', 'M.P. Vecchi']",1983,Science,Journal,,671-680,220,4598,10.1126/science.220.4598.671,There is a deep and useful connection between statistical mechanics (the behavior of systems with many degrees of freedom in thermal equilibrium at a finite temperature) and multivariate or combinatorial optimization (finding the minimum of a given function depending on many parameters). A detailed analogy with annealing in solids provides a framework for optimization of the properties of very large and complex systems. This connection to statistical mechanics exposes new information and provides an unfamiliar perspective on traditional optimization problems and methods.,"['Statistical mechanics', 'Simulated annealing', 'Connection (principal bundle)', 'Analogy', 'Computer science', 'Optimization problem', 'Mathematical optimization', 'Extremal optimization', 'Multivariate statistics', 'Statistical physics', 'Complex system', 'Degrees of freedom (physics and chemistry)', 'Theoretical computer science', 'Algorithm', 'Mathematics', 'Artificial intelligence', 'Physics', 'Multi-swarm optimization', 'Machine learning', 'Thermodynamics', 'Linguistics', 'Philosophy', 'Geometry']","statistical mechanics, thermal equilibrium, combinatorial optimization, annealing, solids, statistical mechanics, [PAD] [PAD], [PAD], [PAD] [PAD], [PAD], [PAD] [PAD], [PAD] [PAD], [PAD] [PAD], [PAD]"
Paper_00119,UCSF Chimera—A visualization system for exploratory research and analysis,"['Eric F. Pettersen', 'Thomas D. Goddard', 'Conrad C. Huang', 'Gregory S. Couch', 'Daniel M. Greenblatt', 'Elaine C. Meng', 'Thomas E. Ferrin']",2004,Journal of Computational Chemistry,Journal,,1605-1612,25,13,10.1002/jcc.20084,"The design, implementation, and capabilities of an extensible visualization system, UCSF Chimera, are discussed. Chimera is segmented into a core that provides basic services and visualization, and extensions that provide most higher level functionality. This architecture ensures that the extension mechanism satisfies the demands of outside developers who wish to incorporate new features. Two unusual extensions are presented: Multiscale, which adds the ability to visualize large-scale molecular assemblies such as viral coats, and Collaboratory, which allows researchers to share a Chimera session interactively despite being at separate locales. Other extensions include Multalign Viewer, for showing multiple sequence alignments and associated structures; ViewDock, for screening docked ligand orientations; Movie, for replaying molecular dynamics trajectories; and Volume Viewer, for display and analysis of volumetric data. A discussion of the usage of Chimera in real-world situations is given, along with anticipated future directions. Chimera includes full user documentation, is free to academic and nonprofit users, and is available for Microsoft Windows, Linux, Apple Mac OS X, SGI IRIX, and HP Tru64 Unix from http://www.cgl.ucsf.edu/chimera/.","['Computer science', 'Chimera (genetics)', 'Visualization', 'Computer graphics (images)', 'Data mining', 'Chemistry', 'Biochemistry', 'Gene']","extensible visualization system, ucsf chimera, chimera, multiscale, viral coats, collaboratory, multalign viewer, multiple sequence alignments, viewdock, docked ligand orientations, movie, molecular dynamics, volume viewer, volumetric data, chi, ##a, chimera, ##i ir, ##a"
Paper_00120,Cytoscape: A Software Environment for Integrated Models of Biomolecular Interaction Networks,"['Paul Shannon', 'Andrew Markiel', 'Owen Ozier', 'Nitin S. Baliga', 'Jonathan T. Wang', 'Daniel Ramage', 'Nada Amin', 'Benno Schwikowski', 'Trey Ideker']",2003,Genome Research,Journal,,2498-2504,13,11,10.1101/gr.1239303,"Cytoscape is an open source software project for integrating biomolecular interaction networks with high-throughput expression data and other molecular states into a unified conceptual framework. Although applicable to any system of molecular components and interactions, Cytoscape is most powerful when used in conjunction with large databases of protein-protein, protein-DNA, and genetic interactions that are increasingly available for humans and model organisms. Cytoscape's software Core provides basic functionality to layout and query the network; to visually integrate the network with expression profiles, phenotypes, and other molecular states; and to link the network to databases of functional annotations. The Core is extensible through a straightforward plug-in architecture, allowing rapid development of additional computational analyses and features. Several case studies of Cytoscape plug-ins are surveyed, including a search for interaction pathways correlating with changes in gene expression, a study of protein complexes involved in cellular recovery to DNA damage, inference of a combined physical/functional interaction network for Halobacterium , and an interface to detailed stochastic/kinetic gene regulatory models.","['Computational biology', 'Biology', 'Interaction network', 'Software', 'Inference', 'Gene regulatory network', 'Interface (matter)', 'Biological network', 'Computer science', 'Systems biology', 'Plug-in', 'Bioinformatics', 'Gene', 'Gene expression', 'Genetics', 'Artificial intelligence', 'Programming language', 'Pulmonary surfactant', 'Biochemistry', 'Gibbs isotherm']","cytoscape, biomolecular interaction networks, cytoscape, cytoscape, expression, pheno, functional, cytoscape, interaction, protein complexes, cellular recovery, dna, haloba, [PAD]"
Paper_00121,The Hospital Anxiety and Depression Scale,"['A. S. Zigmond', 'R. P. Snaith']",1983,Acta Psychiatrica Scandinavica,Journal,,361-370,67,6,10.1111/j.1600-0447.1983.tb09716.x,ABSTRACT– A self-assessment scale has been developed and found to be a reliable instrument for detecting states of depression and anxiety in the setting of an hospital medical outpatient clinic. The anxiety and depressive subscales are also valid measures of severity of the emotional disorder. It is suggested that the introduction of the scales into general hospital practice would facilitate the large task of detection and management of emotional disorder in patients under investigation and treatment in medical and surgical departments.,"['Anxiety', 'Depression (economics)', 'Hospital Anxiety and Depression Scale', 'Psychiatry', 'Scale (ratio)', 'Psychology', 'Clinical psychology', 'Outpatient clinic', 'Medicine', 'Physics', 'Quantum mechanics', 'Internal medicine', 'Economics', 'Macroeconomics']","anxiety, hospital medical outpatient clinic, depressive sub, general hospital practice, [PAD] [PAD]"
Paper_00122,STAR: ultrafast universal RNA-seq aligner,"['Alexander Dobin', 'Carrie Davis', 'Felix Schlesinger', 'Jörg Drenkow', 'Chris Zaleski', 'Sonali Jha', 'Philippe Batut', 'Mark Chaisson', 'T Gingeras']",2012,Bioinformatics,Journal,,15-21,29,1,10.1093/bioinformatics/bts635,"Motivation: Accurate alignment of high-throughput RNA-seq data is a challenging and yet unsolved problem because of the non-contiguous transcript structure, relatively short read lengths and constantly increasing throughput of the sequencing technologies. Currently available RNA-seq aligners suffer from high mapping error rates, low mapping speed, read length limitation and mapping biases. Results: To align our large (>80 billon reads) ENCODE Transcriptome RNA-seq dataset, we developed the Spliced Transcripts Alignment to a Reference (STAR) software based on a previously undescribed RNA-seq alignment algorithm that uses sequential maximum mappable seed search in uncompressed suffix arrays followed by seed clustering and stitching procedure. STAR outperforms other aligners by a factor of >50 in mapping speed, aligning to the human genome 550 million 2 × 76 bp paired-end reads per hour on a modest 12-core server, while at the same time improving alignment sensitivity and precision. In addition to unbiased de novo detection of canonical junctions, STAR can discover non-canonical splices and chimeric (fusion) transcripts, and is also capable of mapping full-length RNA sequences. Using Roche 454 sequencing of reverse transcription polymerase chain reaction amplicons, we experimentally validated 1960 novel intergenic splice junctions with an 80–90% success rate, corroborating the high precision of the STAR mapping strategy. Availability and implementation: STAR is implemented as a standalone C++ code. STAR is free open source software distributed under GPLv3 license and can be downloaded from http://code.google.com/p/rna-star/. Contact:dobin@cshl.edu.","['Computer science', 'JSON', 'Computational biology', 'Software', 'RNA-Seq', 'Adapter (computing)', 'Algorithm', 'Biology', 'Genetics', 'Transcriptome', 'Gene', 'Database', 'Programming language', 'Operating system', 'Gene expression']","mapping error rates, read length limitation, mapping, ##liced transcripts, sequential maximum mappable seed search, ##pressed, seed clustering, stitching, canonical junctions, roche 454 sequencing, reverse transcription polymerase chain reaction amplicons, ##genic splice junctions, star"
Paper_00123,Handbook of Mathematical Functions,['Donald A. McQuarrie'],1966,American Journal of Physics,Journal,,177-177,34,2,10.1119/1.1972842,First Page,"['Physics', 'Theoretical physics', 'Applied mathematics', 'Statistical physics', 'Mathematics']",
Paper_00125,Model Selection and Multimodel Inference: A Practical Information-Theoretic Approach,"['Fred S. Guthery', 'Kenneth P. Burnham', 'David Anderson']",2003,Journal of Wildlife Management,Journal,,655-655,67,3,10.2307/3802723,Introduction * Information and Likelihood Theory: A Basis for Model Selection and Inference * Basic Use of the Information-Theoretic Approach * Formal Inference From More Than One Model: Multi-Model Inference (MMI) * Monte Carlo Insights and Extended Examples * Statistical Theory and Numerical Results * Summary,"['Selection (genetic algorithm)', 'Inference', 'Computer science', 'Model selection', 'Artificial intelligence']","information, likelihood theory, model selection, inference, formal inference, monte, statistical theory, numerical results"
Paper_00127,MUSCLE: multiple sequence alignment with high accuracy and high throughput,['R. C. Edgar'],2004,Nucleic Acids Research,Journal,,1792-1797,32,5,10.1093/nar/gkh340,"We describe MUSCLE, a new computer program for creating multiple alignments of protein sequences. Elements of the algorithm include fast distance estimation using kmer counting, progressive alignment using a new profile function we call the log-expectation score, and refinement using tree-dependent restricted partitioning. The speed and accuracy of MUSCLE are compared with T-Coffee, MAFFT and CLUSTALW on four test sets of reference alignments: BAliBASE, SABmark, SMART and a new benchmark, PREFAB. MUSCLE achieves the highest, or joint highest, rank in accuracy on each of these sets. Without refinement, MUSCLE achieves average accuracy statistically indistinguishable from T-Coffee and MAFFT, and is the fastest of the tested methods for large numbers of sequences, aligning 5000 sequences of average length 350 in 7 min on a current desktop computer. The MUSCLE program, source code and PREFAB test data are freely available at http://www.drive5. com/muscle.","['Benchmark (surveying)', 'Multiple sequence alignment', 'Biology', 'Computer science', 'Rank (graph theory)', 'Sequence alignment', 'Source code', 'Tree (set theory)', 'Mathematics', 'Combinatorics', 'Biochemistry', 'Geodesy', 'Peptide sequence', 'Gene', 'Geography', 'Operating system']","muscle, multiple alignments, protein sequences, fast distance estimation, kmer counting, progressive alignment, profile function, cl, ##w, reference, balibase, sabmark, smart, muscle, muscle, prefab"
Paper_00128,Particle swarm optimization,"['James Kennedy', 'R.C. Eberhart']",2002,Unknown,Unknown,,1942-1948,4,,10.1109/icnn.1995.488968,"A concept for the optimization of nonlinear functions using particle swarm methodology is introduced. The evolution of several paradigms is outlined, and an implementation of one of the paradigms is discussed. Benchmark testing of the paradigm is described, and applications, including nonlinear function optimization and neural network training, are proposed. The relationships between particle swarm optimization and both artificial life and genetic algorithms are described.","['Particle swarm optimization', 'Multi-swarm optimization', 'Benchmark (surveying)', 'Metaheuristic', 'Computer science', 'Artificial neural network', 'Nonlinear system', 'Swarm intelligence', 'Parallel metaheuristic', 'Mathematical optimization', 'Meta-optimization', 'Swarm behaviour', 'Artificial intelligence', 'Algorithm', 'Mathematics', 'Physics', 'Geodesy', 'Quantum mechanics', 'Geography']","nonlinear functions, particle swarm methodology, benchmark testing, nonlinear function optimization, neural network training, particle swarm optimization, genetic algorithms, [PAD], [PAD], [PAD], [PAD] [PAD], [PAD], [PAD], [PAD], [PAD] [PAD] [PAD] [PAD] [PAD]"
Paper_00130,A fast and elitist multiobjective genetic algorithm: NSGA-II,"['Kalyanmoy Deb', 'Amrit Pratap', 'Sakshi Agarwal', 'T. Meyarivan']",2002,IEEE Transactions on Evolutionary Computation,Journal,,182-197,6,2,10.1109/4235.996017,"Multi-objective evolutionary algorithms (MOEAs) that use non-dominated sorting and sharing have been criticized mainly for: (1) their O(MN/sup 3/) computational complexity (where M is the number of objectives and N is the population size); (2) their non-elitism approach; and (3) the need to specify a sharing parameter. In this paper, we suggest a non-dominated sorting-based MOEA, called NSGA-II (Non-dominated Sorting Genetic Algorithm II), which alleviates all of the above three difficulties. Specifically, a fast non-dominated sorting approach with O(MN/sup 2/) computational complexity is presented. Also, a selection operator is presented that creates a mating pool by combining the parent and offspring populations and selecting the best N solutions (with respect to fitness and spread). Simulation results on difficult test problems show that NSGA-II is able, for most problems, to find a much better spread of solutions and better convergence near the true Pareto-optimal front compared to the Pareto-archived evolution strategy and the strength-Pareto evolutionary algorithm - two other elitist MOEAs that pay special attention to creating a diverse Pareto-optimal front. Moreover, we modify the definition of dominance in order to solve constrained multi-objective problems efficiently. Simulation results of the constrained NSGA-II on a number of test problems, including a five-objective, seven-constraint nonlinear problem, are compared with another constrained multi-objective optimizer, and the much better performance of NSGA-II is observed.","['Mathematical optimization', 'Sorting', 'Evolutionary algorithm', 'Multi-objective optimization', 'Pareto principle', 'Population', 'Computer science', 'Computational complexity theory', 'Selection (genetic algorithm)', 'Convergence (economics)', 'Genetic algorithm', 'Mathematics', 'Algorithm', 'Artificial intelligence', 'Demography', 'Sociology', 'Economics', 'Economic growth']","computational complexity, selection operator, mating pool, spread, dominance"
Paper_00131,LIBSVM,"['Chih-Chung Chang', 'Chih‐Jen Lin']",2011,ACM Transactions on Intelligent Systems and Technology,Journal,,1-27,2,3,10.1145/1961189.1961199,"LIBSVM is a library for Support Vector Machines (SVMs). We have been actively developing this package since the year 2000. The goal is to help users to easily apply SVM to their applications. LIBSVM has gained wide popularity in machine learning and many other areas. In this article, we present all implementation details of LIBSVM. Issues such as solving SVM optimization problems theoretical convergence multiclass classification probability estimates and parameter selection are discussed in detail.","['Computer science', 'Support vector machine', 'Popularity', 'Machine learning', 'Artificial intelligence', 'Selection (genetic algorithm)', 'Convergence (economics)', 'Multiclass classification', 'Data mining', 'Psychology', 'Social psychology', 'Economics', 'Economic growth']","libsvm, support vector machines, svms, svm, libsvm, machine learning, libsvm, svm, theoretical convergence multiclass classification probability estimates, parameter selection, [PAD] [PAD] [PAD] [PAD], [PAD], [PAD] [PAD] [PAD] [PAD], [PAD], [PAD] [PAD], [PAD] [PAD], [PAD], [PAD], [PAD], [PAD], [PAD] [PAD] [PAD], [PAD], [PAD] [PAD] [PAD] [PAD] [PAD]"
Paper_00133,Situated Learning: Legitimate Peripheral Participation.,"['Maurice Bloch', 'Jean Lave', 'Étienne Wenger']",1994,Man,Journal,,487-487,29,2,10.2307/2804509,"In this important theoretical treatist, Jean Lave, anthropologist, and Etienne Wenger, computer scientist, push forward the notion of situated learning - that learning is fundamentally a social process. The authors maintain that learning viewed as situated activity has as its central defining characteristic a process they call legitimate peripheral participation (LPP). Learners participate in communities of practitioners, moving toward full participation in the sociocultural practices of a community. LPP provides a way to speak about crucial relations between newcomers and old-timers and about their activities, identities, artefacts, knowledge and practice. The communities discussed in the book are midwives, tailors, quartermasters, butchers, and recovering alcoholics, however, the process by which participants in those communities learn can be generalised to other social groups.","['Situated', 'Situated learning', 'Peripheral', 'Psychology', 'Computer science', 'Pedagogy', 'Artificial intelligence', 'Operating system']","situated learning, social process, legitimate peripheral participation, sociocultural practices, midwives, tailors, quartermasters, butchers, recovering alcoholics"
Paper_00134,Social Foundations of Thought and Action : A Social Cognitive Theory,['A. Bandura'],1986,['The Academy of Management Review'],Unknown,,169,12,1,10.2307/258004,1. Models of Human Nature and Casualty. 2. Observational Learning. 3. Enactive Learning. 4. Social Diffusion and Innovation. 5. Predictive Knowledge and Forethought. 6. Incentive Motivators. 7. Vicarious Motivators. 8. Self-Regulatory Mechanisms. 9. Self-Efficacy. 10. Cognitive Regulators. References. Index.,"['Observational learning', 'Social learning', 'Social cognitive theory', 'Action (physics)', 'Psychology', 'Social learning theory', 'Incentive', 'Observational study', 'Cognition', 'Social psychology', 'Cognitive psychology', 'Epistemology', 'Cognitive science', 'Sociology', 'Experiential learning', 'Economics', 'Pedagogy', 'Medicine', 'Philosophy', 'Physics', 'Pathology', 'Quantum mechanics', 'Neuroscience', 'Microeconomics']","human nature, observational learning, enactive learning, social diffusion, innovation, predictive knowledge, forethought, incentive motivators, vicarious motivators, cognitive regulators, [PAD] [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD], [PAD] [PAD], [PAD], [PAD], [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD]"
Paper_00136,MEGA7: Molecular Evolutionary Genetics Analysis Version 7.0 for Bigger Datasets,"['Sudhir Kumar', 'Glen Stecher', 'Koichiro Tamura']",2016,Molecular Biology and Evolution,Journal,,1870-1874,33,7,10.1093/molbev/msw054,"Abstract We present the latest version of the Molecular Evolutionary Genetics Analysis (M ega ) software, which contains many sophisticated methods and tools for phylogenomics and phylomedicine. In this major upgrade, M ega has been optimized for use on 64-bit computing systems for analyzing larger datasets. Researchers can now explore and analyze tens of thousands of sequences in M ega . The new version also provides an advanced wizard for building timetrees and includes a new functionality to automatically predict gene duplication events in gene family trees. The 64-bit M ega is made available in two interfaces: graphical and command line. The graphical user interface (GUI) is a native Microsoft Windows application that can also be used on Mac OS X. The command line M ega is available as native applications for Windows, Linux, and Mac OS X. They are intended for use in high-throughput and scripted analysis. Both versions are available from www.megasoftware.net free of charge.","['Biology', 'Human evolutionary genetics', 'Evolutionary biology', 'Computational biology', 'Molecular evolution', 'Genetics', 'Phylogenetics', 'Gene']","molecular evolutionary genetics analysis, phylogenomics, phylomedicine, time, gene duplication events, gene family trees, graphical user interface, linux, scripted, megasoft, [PAD], [PAD], [PAD], [PAD], [PAD], [PAD]"
Paper_00138,"Introduction to Mediation, Moderation, and Conditional Process Analysis: A Regression-Based Approach",['Andrew F. Hayes'],2013,['The Cambridge Handbook of Research Methods in Clinical Psychology'],Unknown,,396-414,,,10.1017/9781316995808.037,"I. FUNDAMENTAL CONCEPTS 1. Introduction 1.1. A Scientist in Training 1.2. Questions of Whether, If, How, and When 1.3. Conditional Process Analysis 1.4. Correlation, Causality, and Statistical Modeling 1.5. Statistical Software 1.6. Overview of this Book 1.7. Chapter Summary 2. Simple Linear Regression 2.1. Correlation and Prediction 2.2. The Simple Linear Regression Equation 2.3. Statistical Inference 2.4. Assumptions for Interpretation and Statistical Inference 2.5. Chapter Summary 3. Multiple Linear Regression 3.1. The Multiple Linear Regression Equation 3.2. Partial Association and Statistical Control 3.3. Statistical Inference in Multiple Regression 3.4. Statistical and Conceptual Diagrams 3.5. Chapter Summary II. MEDIATION ANALYSIS 4. The Simple Mediation Model 4.1. The Simple Mediation Model 4.2. Estimation of the Direct, Indirect, and Total Effects of X 4.3. Example with Dichotomous X: The Influence of Presumed Media Influence 4.4. Statistical Inference 4.5. An Example with Continuous X: Economic Stress among Small Business Owners 4.6. Chapter Summary 5. Multiple Mediator Models 5.1. The Parallel Multiple Mediator Model 5.2. Example Using the Presumed Media Influence Study 5.3. Statistical Inference 5.4. The Serial Multiple Mediator Model 5.5. Complementarity and Competition among Mediators 5.6. OLS Regression versus Structural Equation Modeling 5.7. Chapter Summary III. MODERATION ANALYSIS 6. Miscellaneous Topics in Mediation Analysis 6.1. What About Baron and Kenny? 6.2. Confounding and Causal Order 6.3. Effect Size 6.4. Multiple Xs or Ys: Analyze Separately or Simultaneously? 6.5. Reporting a Mediation Analysis 6.6. Chapter Summary 7. Fundamentals of Moderation Analysis 7.1. Conditional and Unconditional Effects 7.2. An Example: Sex Discrimination in the Workplace 7.3. Visualizing Moderation 7.4. Probing an Interaction 7.5. Chapter Summary 8. Extending Moderation Analysis Principles 8.1. Moderation Involving a Dichotomous Moderator 8.2. Interaction between Two Quantitative Variables 8.3. Hierarchical versus Simultaneous Variable Entry 8.4. The Equivalence between Moderated Regression Analysis and a 2 x 2 Factorial Analysis of Variance 8.5. Chapter Summary 9. Miscellaneous Topics in Moderation Analysis 9.1. Truths and Myths about Mean Centering 9.2. The Estimation and Interpretation of Standardized Regression Coefficients in a Moderation Analysis 9.3. Artificial Categorization and Subgroups Analysis 9.4. More Than One Moderator 9.5. Reporting a Moderation Analysis 9.6. Chapter Summary IV. CONDITIONAL PROCESS ANALYSIS 10. Conditional Process Analysis 10.1. Examples of Conditional Process Models in the Literature 10.2. Conditional Direct and Indirect Effects 10.3. Example: Hiding Your Feelings from Your Work Team 10.4. Statistical Inference 10.5. Conditional Process Analysis in PROCESS 10.6. Chapter Summary 11. Further Examples of Conditional Process Analysis 11.1. Revisiting the Sexual Discrimination Study 11.2. Moderation of the Direct and Indirect Effects in a Conditional Process Model 11.3. Visualizing the Direct and Indirect Effects 11.4. Mediated Moderation 11.5. Chapter Summary 12. Miscellaneous Topics in Conditional Process Analysis 12.1. A Strategy for Approaching Your Analysis 12.2. Can a Variable Simultaneously Mediate and Moderate Another Variable's Effect? 12.3. Comparing Conditional Indirect Effects and a Formal Test of Moderated Mediation 12.4. The Pitfalls of Subgroups Analysis 12.5. Writing about Conditional Process Modeling 12.6. Chapter Summary Appendix A. Using PROCESS Appendix B. Monte Carlo Confidence Intervals in SPSS and SAS","['Statistical inference', 'Econometrics', 'Structural equation modeling', 'Simple linear regression', 'Mediation', 'Regression analysis', 'Causal inference', 'Moderation', 'Linear regression', 'Statistics', 'Statistical model', 'Inference', 'Mathematics', 'Computer science', 'Artificial intelligence', 'Political science', 'Law']","scientist, conditional process analysis, correlation, causality, statistical modeling, statistical software, simple linear regression, correlation, prediction, simple linear regression equation, statistical inference, statistical inference, multiple linear regression, multiple linear regression equation, partial association, statistical control, statistical inference, multiple regression, conceptual diagrams, mediation analysis, simple mediation model, simple mediation model, total, presumed media influence, statistical inference, economic stress, small business owners, multiple mediator models, parallel multiple mediator model, presumed media influence study, statistical inference, serial multiple mediator model, complementarity, competition, mediators, ##s regression, structural equation modeling, moderation analysis, mediation analysis, confounding, causal order, effect size, mediation analysis, moderation analysis, unconditional effects, sex discrimination, workplace, visualizing moderation, moderation analysis, moderation, dichotomous moderator, moderated regression analysis, factorial analysis, moderation analysis"
Paper_00141,CONFIDENCE LIMITS ON PHYLOGENIES: AN APPROACH USING THE BOOTSTRAP,['Joseph Felsenstein'],1985,Evolution,Journal,,783-791,39,4,10.1111/j.1558-5646.1985.tb00420.x,"The recently-developed statistical method known as the ""bootstrap"" can be used to place confidence intervals on phylogenies. It involves resampling points from one's own data, with replacement, to create a series of bootstrap samples of the same size as the original data. Each of these is analyzed, and the variation among the resulting estimates taken to indicate the size of the error involved in making estimates from the original data. In the case of phylogenies, it is argued that the proper method of resampling is to keep all of the original species while sampling characters with replacement, under the assumption that the characters have been independently drawn by the systematist and have evolved independently. Majority-rule consensus trees can be used to construct a phylogeny showing all of the inferred monophyletic groups that occurred in a majority of the bootstrap samples. If a group shows up 95% of the time or more, the evidence for it is taken to be statistically significant. Existing computer programs can be used to analyze different bootstrap samples by using weights on the characters, the weight of a character being how many times it was drawn in bootstrap sampling. When all characters are perfectly compatible, as envisioned by Hennig, bootstrap sampling becomes unnecessary; the bootstrap method would show significant evidence for a group if it is defined by three or more characters.","['Biology', 'Confidence interval', 'Evolutionary biology', 'Statistics', 'Mathematics']","statistical, bootstrap, confidence intervals, ph, ##ogen, bootstrap samples, phylogenies, ph, monophyletic groups, bootstrap sampling, bootstrap sampling, bootstrap method"
Paper_00142,An Introduction to the Bootstrap,"['Bradley Efron', 'Robert Tibshirani']",1994,Chapman and Hall/CRC eBooks,Unknown,,,,,10.1201/9780429246593,"This article presents bootstrap methods for estimation, using simple arguments. Minitab macros for implementing these methods are given.",['Computer science'],"bootstrap methods, estimation, minitab macros, [PAD], [PAD] [PAD], [PAD] [PAD] [PAD], [PAD], [PAD], [PAD] [PAD] [PAD], [PAD] [PAD] [PAD], [PAD], [PAD], [PAD], [PAD] [PAD], [PAD], [PAD] [PAD] [PAD] [PAD], [PAD], [PAD] [PAD] [PAD] [PAD], [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD], [PAD] [PAD], [PAD], [PAD]"
Paper_00143,"MEGA5: Molecular Evolutionary Genetics Analysis Using Maximum Likelihood, Evolutionary Distance, and Maximum Parsimony Methods","['Koichiro Tamura', 'Daniel G. Peterson', 'Nora Peterson', 'Glen Stecher', 'M Nei', 'Sudhir Kumar']",2011,Molecular Biology and Evolution,Journal,,2731-2739,28,10,10.1093/molbev/msr121,"Comparative analysis of molecular sequence data is essential for reconstructing the evolutionary histories of species and inferring the nature and extent of selective forces shaping the evolution of genes and species. Here, we announce the release of Molecular Evolutionary Genetics Analysis version 5 (MEGA5), which is a user-friendly software for mining online databases, building sequence alignments and phylogenetic trees, and using methods of evolutionary bioinformatics in basic biology, biomedicine, and evolution. The newest addition in MEGA5 is a collection of maximum likelihood (ML) analyses for inferring evolutionary trees, selecting best-fit substitution models (nucleotide or amino acid), inferring ancestral states and sequences (along with probabilities), and estimating evolutionary rates site-by-site. In computer simulation analyses, ML tree inference algorithms in MEGA5 compared favorably with other software packages in terms of computational efficiency and the accuracy of the estimates of phylogenetic trees, substitution parameters, and rate variation among sites. The MEGA user interface has now been enhanced to be activity driven to make it easier for the use of both beginners and experienced scientists. This version of MEGA is intended for the Windows platform, and it has been configured for effective use on Mac OS X and Linux desktops. It is available free of charge from http://www.megasoftware.net.","['Phylogenetic tree', 'Biology', 'Maximum parsimony', 'Mega-', 'Phylogenetics', 'Tree (set theory)', 'Evolutionary biology', 'Molecular evolution', 'Software', 'Inference', 'Computational biology', 'Genetics', 'Computer science', 'Gene', 'Clade', 'Artificial intelligence', 'Mathematics', 'Mathematical analysis', 'Physics', 'Astronomy', 'Programming language']","comparative analysis, molecular sequence data, evolutionary histories, selective forces, molecular evolutionary genetics analysis, mega, online databases, sequence alignments, phylogenetic trees, evolutionary bioinformatics, basic biology, ##med, mega, maximum likelihood, evolutionary, computer simulation analyses, ml tree inference algorithms, mega5, computational efficiency, phylogenetic, substitution parameters, rate variation, mega, linux, megasoft"
Paper_00144,<i>Ab initio</i>molecular dynamics for liquid metals,"['Georg Kresse', 'J. Häfner']",1993,"Physical review. B, Condensed matter",Journal,,558-561,47,1,10.1103/physrevb.47.558,"We present ab initio quantum-mechanical molecular-dynamics calculations based on the calculation of the electronic ground state and of the Hellmann-Feynman forces in the local-density approximation at each molecular-dynamics step. This is possible using conjugate-gradient techniques for energy minimization, and predicting the wave functions for new ionic positions using subspace alignment. This approach avoids the instabilities inherent in quantum-mechanical molecular-dynamics calculations for metals based on the use of a fictitious Newtonian dynamics for the electronic degrees of freedom. This method gives perfect control of the adiabaticity and allows us to perform simulations over several picoseconds.","['Degrees of freedom (physics and chemistry)', 'Molecular dynamics', 'Ab initio', 'Physics', 'Quantum', 'Electronic structure', 'Quantum dynamics', 'Ground state', 'Ab initio quantum chemistry methods', 'Wave function', 'Picosecond', 'Potential energy', 'Classical mechanics', 'Quantum mechanics', 'Molecule', 'Laser']","electronic ground state, energy minimization, wave functions, ionic positions, subspace alignment, ##tabilities, fictitious newtonian dynamics, electronic degrees of freedom, adi, [PAD] [PAD], [PAD], [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD], [PAD] [PAD]"
Paper_00145,A Mathematical Theory of Communication,['Claude E. Shannon'],1948,Bell System Technical Journal,Journal,,623-656,27,4,10.1002/j.1538-7305.1948.tb00917.x,"In this final installment of the paper we consider the case where the signals or the messages or both are continuously variable, in contrast with the discrete nature assumed until now. To a considerable extent the continuous case can be obtained through a limiting process from the discrete case by dividing the continuum of messages and signals into a large but finite number of small regions and calculating the various parameters involved on a discrete basis. As the size of the regions is decreased these parameters in general approach as limits the proper values for the continuous case. There are, however, a few new effects that appear and also a general change of emphasis in the direction of specialization of the general results to particular cases.","['Limiting', 'General theory', 'Basis (linear algebra)', 'Contrast (vision)', 'Process (computing)', 'Emphasis (telecommunications)', 'Mathematics', 'Variable (mathematics)', 'Computer science', 'Applied mathematics', 'Mathematical analysis', 'Telecommunications', 'Mathematical economics', 'Engineering', 'Geometry', 'Mechanical engineering', 'Artificial intelligence', 'Operating system']",
Paper_00146,The CLUSTAL_X windows interface: flexible strategies for multiple sequence alignment aided by quality analysis tools,"['Julie Thompson', 'Toby J. Gibson', 'Frédéric Plewniak', 'François Jeanmougin', 'Desmond G. Higgins']",1997,Nucleic Acids Research,Journal,,4876-4882,25,24,10.1093/nar/25.24.4876,"CLUSTAL X is a new windows interface for the widely-used progressive multiple sequence alignment program CLUSTAL W. The new system is easy to use, providing an integrated system for performing multiple sequence and profile alignments and analysing the results. CLUSTAL X displays the sequence alignment in a window on the screen. A versatile sequence colouring scheme allows the user to highlight conserved features in the alignment. Pull-down menus provide all the options required for traditional multiple sequence and profile alignment. New features include: the ability to cut-and-paste sequences to change the order of the alignment, selection of a subset of the sequences to be realigned, and selection of a sub-range of the alignment to be realigned and inserted back into the original alignment. Alignment quality analysis can be performed and low-scoring segments or exceptional residues can be highlighted. Quality analysis and realignment of selected residue ranges provide the user with a powerful tool to improve and refine difficult alignments and to trap errors in input sequences. CLUSTAL X has been compiled on SUN Solaris, IRIX5.3 on Silicon Graphics, Digital UNIX on DECstations, Microsoft Windows (32 bit) for PCs, Linux ELF for x86 PCs, and Macintosh PowerMac.","['Multiple sequence alignment', 'Unix', 'Sequence alignment', 'Graphics', 'Sequence (biology)', 'Alignment-free sequence analysis', 'Computer science', 'Sequence analysis', 'Interface (matter)', 'Biology', 'x86', 'Microsoft Windows', 'Bioinformatics', 'Software', 'Computer graphics (images)', 'Operating system', 'Genetics', 'Peptide sequence', 'Bubble', 'Maximum bubble pressure method', 'Gene']","clustal, progressive multiple sequence alignment program clustal, profile alignments, ##al, profile, alignment quality analysis, quality analysis, real, clustal, sun solaris, silicon graphics, digital unix, microsoft, linux elf, x86 pcs, macintosh powermac"
Paper_00147,A power primer.,['Jacob Cohen'],1992,Psychological Bulletin,Journal,,155-159,112,1,10.1037/0033-2909.112.1.155,"One possible reason for the continued neglect of statistical power analysis in research in the behavioral sciences is the inaccessibility of or difficulty with the standard material. A convenient, although not comprehensive, presentation of required sample sizes is provided here. Effect-size indexes and conventional values for these are given for operationally defined small, medium, and large effects. The sample sizes necessary for .80 power to detect effects at these levels are tabled for eight standard statistical tests: (a) the difference between independent means, (b) the significance of a product-moment correlation, (c) the difference between independent rs, (d) the sign test, (e) the difference between independent proportions, (f) chi-square tests for goodness of fit and contingency tables, (g) one-way analysis of variance, and (h) the significance of a multiple or multiple partial correlation.","['Primer (cosmetics)', 'Psychology', 'Power (physics)', 'Statistics', 'Mathematics', 'Chemistry', 'Physics', 'Organic chemistry', 'Quantum mechanics']","statistical power analysis, behavioral, sign test, independent proportions, goodness of fit, contingency tables"
Paper_00151,Basics of qualitative research : techniques and procedures for developing grounded theory,"['Anselm L. Strauss', 'Juliet Corbin']",1998,['Canadian Journal of University Continuing Education'],Unknown,,,36,2,10.21225/d5g01t,"Part I: Introduction to Grounded Theory of Anselm Strauss Chapter 1: Inspiration and Background Chapter 2: Theoretical Foundations Chapter 3: Practical Considerations for Getting Started Chapter 4: Prelude to Analysis Chapter 5: Strategies for Qualitative Data Analysis Chapter 6: Memos and Diagrams Chapter 7: Theoretical Sampling Chapter 8: Context Chapter 9: Process Chapter 10: Techniques for Achieving Theoretical Integration Chapter 11: The Use of Computer Programs in Qualitative Data Analysis Part II: Research Demonstration Project Chapter 12 Open Coding: Identifying Concepts Chapter 13: Developing Concepts in Terms of Their Properties and Dimensions Chapter 14: Analyzing Data for Context Chapter 15: Bringing Process Into the Analysis Chapter 16: Integrating Categories Part III: Finishing the Research Project Chapter 17: Writing Theses, Monographs, and Dissertations, and Giving Talks About Your Research Chapter 18: Criteria for Evaluation Chapter 19: Student Questions and Answers","['Grounded theory', 'Computer science', 'Context (archaeology)', 'Process (computing)', 'Management science', 'Theoretical sampling', 'Qualitative research', 'Data science', 'Engineering', 'Sociology', 'Social science', 'Programming language', 'Geography', 'Archaeology']","grounded theory, inspiration, theoretical foundations, qualitative data analysis, memo, theoretical sampling, theoretical integration, computer programs, qualitative data analysis, research demonstration project, open coding, student questions"
Paper_00152,Firm Resources and Sustained Competitive Advantage,['Jay B. Barney'],1991,Journal of Management,Journal,,99-120,17,1,10.1177/014920639101700108,"Understanding sources of sustained competitive advantage has become a major area of research in strategic management. Building on the assumptions that strategic resources are heterogeneously distributed acrossfirms and that these differences are stable over time, this article examines the link betweenfirm resources and sustained competitive advantage. Four empirical indicators of the potential of firm resources to generate sustained competitive advantage-value, rareness, imitability, and substitutability-are discussed. The model is applied by analyzing the potential of severalfirm resourcesfor generating sustained competitive advantages. The article concludes by examining implications of this firm resource model of sustained competitive advantage for other business disciplines.","['Competitive advantage', 'Industrial organization', 'Resource (disambiguation)', 'Business', 'Strategic management', 'Resource-based view', 'Value (mathematics)', 'Economics', 'Marketing', 'Computer science', 'Computer network', 'Machine learning']","sustained competitive advantage, strategic management, strategic resources, ##firm resources, sustained competitive advantage, firm resources, sustained competitive advantage, value, rareness, imitability, substitutability, sustained competitive advantages, firm resource model, sustained competitive advantage"
Paper_00153,Diffusion of Innovations,['Everett M. Rogers'],1962,"['The Clearing House: A Journal of Educational Strategies, Issues and Ideas']",Unknown,,429-434,45,7,10.1080/00098655.1971.11478291,Contents Preface CHAPTER 1. ELEMENTS OF DIFFUSION CHAPTER 2. A HISTORY OF DIFFUSION RESEARCH CHAPTER 3. CONTRIBUTIONS AND CRITICISMS OF DIFFUSION RESEARCH CHAPTER 4. THE GENERATION OF INNOVATIONS CHAPTER 5. THE INNOVATION-DECISION PROCESS CHAPTER 6. ATTRIBUTES OF INNOVATIONS AND THEIR RATE OF ADOPTION CHAPTER 7. INNOVATIVENESS AND ADOPTER CATEGORIES CHAPTER 8. DIFFUSION NETWORKS CHAPTER 9. THE CHANGE AGENT CHAPTER 10. INNOVATION IN ORGANIZATIONS CHAPTER 11. CONSEQUENCES OF INNOVATIONS Glossary Bibliography Name Index Subject Index,"['Glossary', 'Innovation diffusion', 'Diffusion', 'Index (typography)', 'Diffusion of innovations', 'Subject (documents)', 'Early adopter', 'Knowledge management', 'Sociology', 'Computer science', 'Social science', 'Business', 'Library science', 'Marketing', 'Philosophy', 'Linguistics', 'Thermodynamics', 'World Wide Web', 'Physics']","diffusion, diffusion research, diffusion research, innovativeness, adopter categories, diffusion networks, change agent, innovation, organizations, consequences"
Paper_00154,Elements of Information Theory,"['Thomas M. Cover', 'Joy A. Thomas']",2001,Unknown,Unknown,,,,,10.1002/0471200611,"Preface to the Second Edition. Preface to the First Edition. Acknowledgments for the Second Edition. Acknowledgments for the First Edition. 1. Introduction and Preview. 1.1 Preview of the Book. 2. Entropy, Relative Entropy, and Mutual Information. 2.1 Entropy. 2.2 Joint Entropy and Conditional Entropy. 2.3 Relative Entropy and Mutual Information. 2.4 Relationship Between Entropy and Mutual Information. 2.5 Chain Rules for Entropy, Relative Entropy, and Mutual Information. 2.6 Jensen's Inequality and Its Consequences. 2.7 Log Sum Inequality and Its Applications. 2.8 Data-Processing Inequality. 2.9 Sufficient Statistics. 2.10 Fano's Inequality. Summary. Problems. Historical Notes. 3. Asymptotic Equipartition Property. 3.1 Asymptotic Equipartition Property Theorem. 3.2 Consequences of the AEP: Data Compression. 3.3 High-Probability Sets and the Typical Set. Summary. Problems. Historical Notes. 4. Entropy Rates of a Stochastic Process. 4.1 Markov Chains. 4.2 Entropy Rate. 4.3 Example: Entropy Rate of a Random Walk on a Weighted Graph. 4.4 Second Law of Thermodynamics. 4.5 Functions of Markov Chains. Summary. Problems. Historical Notes. 5. Data Compression. 5.1 Examples of Codes. 5.2 Kraft Inequality. 5.3 Optimal Codes. 5.4 Bounds on the Optimal Code Length. 5.5 Kraft Inequality for Uniquely Decodable Codes. 5.6 Huffman Codes. 5.7 Some Comments on Huffman Codes. 5.8 Optimality of Huffman Codes. 5.9 Shannon-Fano-Elias Coding. 5.10 Competitive Optimality of the Shannon Code. 5.11 Generation of Discrete Distributions from Fair Coins. Summary. Problems. Historical Notes. 6. Gambling and Data Compression. 6.1 The Horse Race. 6.2 Gambling and Side Information. 6.3 Dependent Horse Races and Entropy Rate. 6.4 The Entropy of English. 6.5 Data Compression and Gambling. 6.6 Gambling Estimate of the Entropy of English. Summary. Problems. Historical Notes. 7. Channel Capacity. 7.1 Examples of Channel Capacity. 7.2 Symmetric Channels. 7.3 Properties of Channel Capacity. 7.4 Preview of the Channel Coding Theorem. 7.5 Definitions. 7.6 Jointly Typical Sequences. 7.7 Channel Coding Theorem. 7.8 Zero-Error Codes. 7.9 Fano's Inequality and the Converse to the Coding Theorem. 7.10 Equality in the Converse to the Channel Coding Theorem. 7.11 Hamming Codes. 7.12 Feedback Capacity. 7.13 Source-Channel Separation Theorem. Summary. Problems. Historical Notes. 8. Differential Entropy. 8.1 Definitions. 8.2 AEP for Continuous Random Variables. 8.3 Relation of Differential Entropy to Discrete Entropy. 8.4 Joint and Conditional Differential Entropy. 8.5 Relative Entropy and Mutual Information. 8.6 Properties of Differential Entropy, Relative Entropy, and Mutual Information. Summary. Problems. Historical Notes. 9. Gaussian Channel. 9.1 Gaussian Channel: Definitions. 9.2 Converse to the Coding Theorem for Gaussian Channels. 9.3 Bandlimited Channels. 9.4 Parallel Gaussian Channels. 9.5 Channels with Colored Gaussian Noise. 9.6 Gaussian Channels with Feedback. Summary. Problems. Historical Notes. 10. Rate Distortion Theory. 10.1 Quantization. 10.2 Definitions. 10.3 Calculation of the Rate Distortion Function. 10.4 Converse to the Rate Distortion Theorem. 10.5 Achievability of the Rate Distortion Function. 10.6 Strongly Typical Sequences and Rate Distortion. 10.7 Characterization of the Rate Distortion Function. 10.8 Computation of Channel Capacity and the Rate Distortion Function. Summary. Problems. Historical Notes. 11. Information Theory and Statistics. 11.1 Method of Types. 11.2 Law of Large Numbers. 11.3 Universal Source Coding. 11.4 Large Deviation Theory. 11.5 Examples of Sanov's Theorem. 11.6 Conditional Limit Theorem. 11.7 Hypothesis Testing. 11.8 Chernoff-Stein Lemma. 11.9 Chernoff Information. 11.10 Fisher Information and the Cram-er-Rao Inequality. Summary. Problems. Historical Notes. 12. Maximum Entropy. 12.1 Maximum Entropy Distributions. 12.2 Examples. 12.3 Anomalous Maximum Entropy Problem. 12.4 Spectrum Estimation. 12.5 Entropy Rates of a Gaussian Process. 12.6 Burg's Maximum Entropy Theorem. Summary. Problems. Historical Notes. 13. Universal Source Coding. 13.1 Universal Codes and Channel Capacity. 13.2 Universal Coding for Binary Sequences. 13.3 Arithmetic Coding. 13.4 Lempel-Ziv Coding. 13.5 Optimality of Lempel-Ziv Algorithms. Compression. Summary. Problems. Historical Notes. 14. Kolmogorov Complexity. 14.1 Models of Computation. 14.2 Kolmogorov Complexity: Definitions and Examples. 14.3 Kolmogorov Complexity and Entropy. 14.4 Kolmogorov Complexity of Integers. 14.5 Algorithmically Random and Incompressible Sequences. 14.6 Universal Probability. 14.7 Kolmogorov complexity. 14.9 Universal Gambling. 14.10 Occam's Razor. 14.11 Kolmogorov Complexity and Universal Probability. 14.12 Kolmogorov Sufficient Statistic. 14.13 Minimum Description Length Principle. Summary. Problems. Historical Notes. 15. Network Information Theory. 15.1 Gaussian Multiple-User Channels. 15.2 Jointly Typical Sequences. 15.3 Multiple-Access Channel. 15.4 Encoding of Correlated Sources. 15.5 Duality Between Slepian-Wolf Encoding and Multiple-Access Channels. 15.6 Broadcast Channel. 15.7 Relay Channel. 15.8 Source Coding with Side Information. 15.9 Rate Distortion with Side Information. 15.10 General Multiterminal Networks. Summary. Problems. Historical Notes. 16. Information Theory and Portfolio Theory. 16.1 The Stock Market: Some Definitions. 16.2 Kuhn-Tucker Characterization of the Log-Optimal Portfolio. 16.3 Asymptotic Optimality of the Log-Optimal Portfolio. 16.4 Side Information and the Growth Rate. 16.5 Investment in Stationary Markets. 16.6 Competitive Optimality of the Log-Optimal Portfolio. 16.7 Universal Portfolios. 16.8 Shannon-McMillan-Breiman Theorem (General AEP). Summary. Problems. Historical Notes. 17. Inequalities in Information Theory. 17.1 Basic Inequalities of Information Theory. 17.2 Differential Entropy. 17.3 Bounds on Entropy and Relative Entropy. 17.4 Inequalities for Types. 17.5 Combinatorial Bounds on Entropy. 17.6 Entropy Rates of Subsets. 17.7 Entropy and Fisher Information. 17.8 Entropy Power Inequality and Brunn-Minkowski Inequality. 17.9 Inequalities for Determinants. 17.10 Inequalities for Ratios of Determinants. Summary. Problems. Historical Notes. Bibliography. List of Symbols. Index.",['Computer science'],"##knowled, ##ents, ##led, entropy, relative entropy, mutual information, joint entropy, conditional entropy, relative entropy, mutual information, mutual information, chain rules, relative entropy, mutual information, log sum inequality, sufficient statistics, asymptotic equipartition property, asymptotic equipartition property, data compression, entropy rates, stochastic process, markov chains, entropy rate, entropy rate, random walk, weighted graph, thermodynamics, markov chains, data compression, optimal codes, optimal code, kraft inequality, uniquely decodable codes, huffman codes, huffman codes, optimality, ##man codes, competitive optimality, shannon code, discrete distributions, fair coins, gambling, data compression, horse race, side information, dependent horse races, entropy rate, entropy, data compression, gambling, gambling estimate, channel capacity, channel capacity, symmetric channels, channel capacity, channel coding"
Paper_00155,Comparison of simple potential functions for simulating liquid water,"['William L. Jorgensen', 'Jayaraman Chandrasekhar', 'Jeffry D. Madura', 'Roger Impey', 'Michael L. Klein']",1983,The Journal of Chemical Physics,Journal,,926-935,79,2,10.1063/1.445869,"Classical Monte Carlo simulations have been carried out for liquid water in the NPT ensemble at 25 °C and 1 atm using six of the simpler intermolecular potential functions for the water dimer: Bernal–Fowler (BF), SPC, ST2, TIPS2, TIP3P, and TIP4P. Comparisons are made with experimental thermodynamic and structural data including the recent neutron diffraction results of Thiessen and Narten. The computed densities and potential energies are in reasonable accord with experiment except for the original BF model, which yields an 18% overestimate of the density and poor structural results. The TIPS2 and TIP4P potentials yield oxygen–oxygen partial structure functions in good agreement with the neutron diffraction results. The accord with the experimental OH and HH partial structure functions is poorer; however, the computed results for these functions are similar for all the potential functions. Consequently, the discrepancy may be due to the correction terms needed in processing the neutron data or to an effect uniformly neglected in the computations. Comparisons are also made for self-diffusion coefficients obtained from molecular dynamics simulations. Overall, the SPC, ST2, TIPS2, and TIP4P models give reasonable structural and thermodynamic descriptions of liquid water and they should be useful in simulations of aqueous solutions. The simplicity of the SPC, TIPS2, and TIP4P functions is also attractive from a computational standpoint.","['Neutron diffraction', 'Water model', 'Molecular dynamics', 'Monte Carlo method', 'Water dimer', 'Thermodynamics', 'Statistical physics', 'Chemistry', 'Liquid water', 'Diffraction', 'Physics', 'Computational chemistry', 'Molecule', 'Mathematics', 'Hydrogen bond', 'Statistics', 'Organic chemistry', 'Optics']","monte carlo simulations, liquid water, npt ensemble, ##molecular potential functions, water dimer, bern, tips, neutron diffraction, potential, neutron diffraction, molecular dynamics simulations"
Paper_00157,Densely Connected Convolutional Networks,"['Gao Huang', 'Zhuang Liu', 'Laurens van der Maaten', 'Kilian Q. Weinberger']",2017,Unknown,Unknown,,,,,10.1109/cvpr.2017.243,"Recent work has shown that convolutional networks can be substantially deeper, more accurate, and efficient to train if they contain shorter connections between layers close to the input and those close to the output. In this paper, we embrace this observation and introduce the Dense Convolutional Network (DenseNet), which connects each layer to every other layer in a feed-forward fashion. Whereas traditional convolutional networks with L layers have L connections-one between each layer and its subsequent layer-our network has L(L+1)/2 direct connections. For each layer, the feature-maps of all preceding layers are used as inputs, and its own feature-maps are used as inputs into all subsequent layers. DenseNets have several compelling advantages: they alleviate the vanishing-gradient problem, strengthen feature propagation, encourage feature reuse, and substantially reduce the number of parameters. We evaluate our proposed architecture on four highly competitive object recognition benchmark tasks (CIFAR-10, CIFAR-100, SVHN, and ImageNet). DenseNets obtain significant improvements over the state-of-the-art on most of them, whilst requiring less memory and computation to achieve high performance. Code and pre-trained models are available at https://github.com/liuzhuang13/DenseNet.","['Computer science', 'Benchmark (surveying)', 'Feature (linguistics)', 'Layer (electronics)', 'Convolutional neural network', 'Computation', 'Code (set theory)', 'Reuse', 'Object (grammar)', 'Convolutional code', 'Pattern recognition (psychology)', 'Artificial intelligence', 'Computer engineering', 'Algorithm', 'Set (abstract data type)', 'Programming language', 'Decoding methods', 'Engineering', 'Philosophy', 'Linguistics', 'Chemistry', 'Geodesy', 'Organic chemistry', 'Geography', 'Waste management']","convolutional networks, dense convolutional network, densenet, convolutional networks, densenets, feature propagation, feature reuse, ci, sv, imagenet, densenets, dense, [PAD]"
Paper_00161,Nonparametric Estimation from Incomplete Observations,"['Edward L. Kaplan', 'Paul Meier']",1958,Journal of the American Statistical Association,Journal,,457-481,53,282,10.1080/01621459.1958.10501452,"Abstract In lifetesting, medical follow-up, and other fields the observation of the time of occurrence of the event of interest (called a death) may be prevented for some of the items of the sample by the previous occurrence of some other event (called a loss). Losses may be either accidental or controlled, the latter resulting from a decision to terminate certain observations. In either case it is usually assumed in this paper that the lifetime (age at death) is independent of the potential loss time; in practice this assumption deserves careful scrutiny. Despite the resulting incompleteness of the data, it is desired to estimate the proportion P(t) of items in the population whose lifetimes would exceed t (in the absence of such losses), without making any assumption about the form of the function P(t). The observation for each item of a suitable initial event, marking the beginning of its lifetime, is presupposed. For random samples of size N the product-limit (PL) estimate can be defined as follows: List and label the N observed lifetimes (whether to death or loss) in order of increasing magnitude, so that one has 0≤t 1ǐ≤t 2ǐ≤ … ≤t N ǐ. Then P(t)= II. [(N – r)/(N – r + 1)], where r assumes those values for which tr ≤t and for which tr ǐ measures the time to death. This estimate is the distribution, unrestricted as to form, which maximizes the likelihood of the observations. Other estimates that are discussed are the actuarial estimates (which are also products, but with the number of factors usually reduced by grouping); and reduced-sample (RS) estimates, which require that losses not be accidental, so that the limits of observation (potential loss times) are known even for those items whose deaths are observed. When no losses occur at ages less than t, the estimate of P(t) in all cases reduces to the usual binomial estimate, namely, the observed proportion of survivors.","['Statistics', 'Mathematics', 'Nonparametric statistics', 'Event (particle physics)', 'Population', 'Econometrics', 'Demography', 'Physics', 'Quantum mechanics', 'Sociology']","lifetesting, random samples, actuarial estimates, binomial estimate"
Paper_00163,MAFFT Multiple Sequence Alignment Software Version 7: Improvements in Performance and Usability,"['Kazutaka Katoh', 'Daron M. Standley']",2013,Molecular Biology and Evolution,Journal,,772-780,30,4,10.1093/molbev/mst010,"We report a major update of the MAFFT multiple sequence alignment program. This version has several new features, including options for adding unaligned sequences into an existing alignment, adjustment of direction in nucleotide alignment, constrained alignment and parallel processing, which were implemented after the previous major update. This report shows actual examples to explain how these features work, alone and in combination. Some examples incorrectly aligned by MAFFT are also shown to clarify its limitations. We discuss how to avoid misalignments, and our ongoing efforts to overcome such limitations.","['Multiple sequence alignment', 'Usability', 'Software', 'Sequence (biology)', 'Biology', 'Sequence alignment', 'Computer science', 'Human–computer interaction', 'Genetics', 'Programming language', 'Peptide sequence', 'Gene']","mafft multiple sequence alignment, unaligned sequences, nucleotide alignment, constrained alignment, parallel processing"
Paper_00164,Multiple regression: testing and interpreting interactions,[],1992,Choice Reviews Online,Journal,,29-3352,29,06,10.5860/choice.29-3352,Introduction Interactions between Continuous Predictors in Multiple Regression The Effects of Predictor Scaling on Coefficients of Regression Equations Testing and Probing Three-Way Interactions Structuring Regression Equations to Reflect Higher Order Relationships Model and Effect Testing with Higher Order Terms Interactions between Categorical and Continuous Variables Reliability and Statistical Power Conclusion Some Contrasts Between ANOVA and MR in Practice,"['Regression testing', 'Regression', 'Regression analysis', 'Regression diagnostic', 'Statistics', 'Computer science', 'Mathematics', 'Polynomial regression', 'Programming language', 'Software construction', 'Software', 'Software system']","continuous predictors, multiple regression, predictor scaling, regression equations, regression equations, higher order relationships, continuous variables, statistical power conclusion, anova, [PAD]"
Paper_00165,Three Approaches to Qualitative Content Analysis,"['Hsiu-Fang Hsieh', 'Sarah E. Shannon']",2005,Qualitative Health Research,Journal,,1277-1288,15,9,10.1177/1049732305276687,"Content analysis is a widely used qualitative research technique. Rather than being a single method, current applications of content analysis show three distinct approaches: conventional, directed, or summative. All three approaches are used to interpret meaning from the content of text data and, hence, adhere to the naturalistic paradigm. The major differences among the approaches are coding schemes, origins of codes, and threats to trustworthiness. In conventional content analysis, coding categories are derived directly from the text data. With a directed approach, analysis starts with a theory or relevant research findings as guidance for initial codes. A summative content analysis involves counting and comparisons, usually of keywords or content, followed by the interpretation of the underlying context. The authors delineate analytic procedures specific to each approach and techniques addressing trustworthiness with hypothetical examples drawn from the area of end-of-life care.","['Content analysis', 'Summative assessment', 'Coding (social sciences)', 'Content (measure theory)', 'Qualitative research', 'Computer science', 'Meaning (existential)', 'Trustworthiness', 'Qualitative analysis', 'Context (archaeology)', 'Interpretation (philosophy)', 'Psychology', 'Social psychology', 'Mathematics education', 'Formative assessment', 'Mathematics', 'Sociology', 'Statistics', 'Social science', 'Mathematical analysis', 'Paleontology', 'Psychotherapist', 'Biology', 'Programming language']","content analysis, qualitative research, content analysis, text data, naturalist, coding schemes, trustworthiness, content analysis, coding, summative content analysis, trustworthiness"
Paper_00166,An Inventory for Measuring Depression,['Aaron T. Beck'],1961,Archives of General Psychiatry,Journal,,561-561,4,6,10.1001/archpsyc.1961.01710120031004,"The difficulties inherent in obtaining consistent and adequate diagnoses for the purposes of research and therapy have been pointed out by a number of authors. Pasamanick<sup>12</sup>in a recent article viewed the low interclinician agreement on diagnosis as an indictment of the present state of psychiatry and called for ""the development of objective, measurable and verifiable criteria of classification based not on personal or parochial considerations, but on behavioral and other objectively measurable manifestations."" Attempts by other investigators to subject clinical observations and judgments to objective measurement have resulted in a wide variety of psychiatric rating scales.<sup>4,15</sup>These have been well summarized in a review article by Lorr<sup>11</sup>on ""Rating Scales and Check Lists for the Evaluation of Psychopathology."" In the area of psychological testing, a variety of paper-and-pencil tests have been devised for the purpose of measuring specific","['Variety (cybernetics)', 'Psychology', 'Psychopathology', 'Indictment', 'Medical diagnosis', 'Rating scale', 'Clinical psychology', 'Psychological testing', 'Psychiatry', 'Medicine', 'Developmental psychology', 'Computer science', 'Artificial intelligence', 'Pathology', 'Political science', 'Law']","##inician agreement, diagnosis, psychiatric, rating scales, check lists, psychopathology, psychological testing"
Paper_00167,BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding,"['Jacob Devlin', 'Ming‐Wei Chang', 'Kenton Lee', 'Kristina Toutanova']",2018,arXiv (Cornell University),Unknown,,,,,10.48550/arxiv.1810.04805,"We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5% (7.7% point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).","['Transformer', 'Computer science', 'Training (meteorology)', 'Artificial intelligence', 'Electrical engineering', 'Engineering', 'Geography', 'Voltage', 'Meteorology']","language representation model, bert, bidirectional encoder representations, transformers, language representation, bert, bidirectional representations, question answering, language inference, bert, natural language processing, glue score, multinli accuracy, squad, question answering test, squad"
Paper_00168,The Strength of Weak Ties,['Mark Granovetter'],1973,American Journal of Sociology,Journal,,1360-1380,78,6,10.1086/225469,"Analysis of social networks is suggested as a tool for linking micro and macro levels of sociological theory. The procedure is illustrated by elaboration of the macro implications of one aspect of small-scale interaction: the strength of dyadic ties. It is argued that the degree of overlap of two individuals' friendship networks varies directly with the strength of their tie to one another. The impact of this principle on diffusion of influence and information, mobility opportunity, and community organization is explored. Stress is laid on the cohesive power of weak ties. Most network models deal, implicitly, with strong ties, thus confining their applicability to small, well-defined groups. Emphasis on weak ties lends itself to discussion of relations between groups and to analysis of segments of social structure not easily defined in terms of primary groups.",['Business'],"social networks, sociological theory, dyadic ties, friendship networks, mobility opportunity, community organization, weak ties, weak ties"
Paper_00170,Multivariate Data Analysis.,"['H. Herne', 'William W. Cooley', 'Paul R. Lohnes']",1973,Journal of the Royal Statistical Society Series A (General),Journal,,101-101,136,1,10.2307/2344428,"Offers an applications-oriented approach to multivariate data analysis, focusing on the use of each technique, rather than its mathematical derivation. The text introduces a six-step framework for organizing and discussing techniques with flowcharts for each.

Well-suited for the non-statistician, this applications-oriented introduction to multivariate analysis focuses on the fundamental concepts that affect the use of specific techniques rather than the mathematical derivation of the technique. Provides an overview of several techniques and approaches that are available to analysts today - e.g., data warehousing and data mining, neural networks and resampling/bootstrapping. Chapters are organized to provide a practical, logical progression of the phases of analysis and to group similar types of techniques applicable to most situations.



Table of Contents 

1. Introduction. 

I. PREPARING FOR A MULTIVARIATE ANALYSIS. 

2. Examining Your Data. 

3. Factor Analysis. 

II. DEPENDENCE TECHNIQUES. 

4. Multiple Regression. 

5. Multiple Discriminant Analysis and Logistic Regression. 

6. Multivariate Analysis of Variance. 

7. Conjoint Analysis. 

8. Canonical Correlation Analysis. 

III. INTERDEPENDENCE TECHNIQUES. 

9. Cluster Analysis. 

10. Multidimensional Scaling. 

IV. ADVANCED AND EMERGING TECHNIQUES. 

11. Structural Equation Modeling. 

12. Emerging Techniques in Multivariate Analysis. 

Appendix A: Applications of Multivariate Data Analysis. 

Index.","['Multivariate statistics', 'Computer science', 'Multivariate analysis', 'Bootstrapping (finance)', 'Univariate', 'Data mining', 'Linear discriminant analysis', 'Multivariate analysis of variance', 'Correspondence analysis', 'Statistics', 'Artificial intelligence', 'Machine learning', 'Econometrics', 'Mathematics']","multivariate data analysis, flowcharts, multivariate analysis, data ware, data mining, neural networks, multivariate analysis, factor analysis, dependence techniques, multiple regression, multiple discriminant analysis, logistic regression, multivariate analysis, variance, conjoint analysis, canonical correlation analysis, interdependence techniques, cluster analysis, multidimensional scaling, structural equation modeling, multivariate analysis, multivariate data analysis"
Paper_00171,"You Only Look Once: Unified, Real-Time Object Detection","['Joseph Redmon', 'Santosh Divvala', 'Ross Girshick', 'Ali Farhadi']",2016,Unknown,Unknown,,779-788,,,10.1109/cvpr.2016.91,"We present YOLO, a new approach to object detection. Prior work on object detection repurposes classifiers to perform detection. Instead, we frame object detection as a regression problem to spatially separated bounding boxes and associated class probabilities. A single neural network predicts bounding boxes and class probabilities directly from full images in one evaluation. Since the whole detection pipeline is a single network, it can be optimized end-to-end directly on detection performance. Our unified architecture is extremely fast. Our base YOLO model processes images in real-time at 45 frames per second. A smaller version of the network, Fast YOLO, processes an astounding 155 frames per second while still achieving double the mAP of other real-time detectors. Compared to state-of-the-art detection systems, YOLO makes more localization errors but is less likely to predict false positives on background. Finally, YOLO learns very general representations of objects. It outperforms other detection methods, including DPM and R-CNN, when generalizing from natural images to other domains like artwork.","['Object detection', 'Computer science', 'Bounding overwatch', 'Artificial intelligence', 'False positive paradox', 'Pipeline (software)', 'Frame (networking)', 'Computer vision', 'Pattern recognition (psychology)', 'Object (grammar)', 'Viola–Jones object detection framework', 'Class (philosophy)', 'Detector', 'Minimum bounding box', 'Frame rate', 'Base (topology)', 'False positives and false negatives', 'Image (mathematics)', 'Face detection', 'Mathematics', 'Telecommunications', 'Mathematical analysis', 'Facial recognition system', 'Programming language']","yolo, object detection, object detection, classifiers, object detection, regression problem, spatially separated bounding boxes, class probabilities, single neural network, class probabilities, unified architecture, yolo, yolo, localization errors, yolo, artwork"
Paper_00172,<i>The Structure of Scientific Revolutions</i>,"['Thomas Kühn', 'Richard Schlegel']",1963,Physics Today,Journal,,69-69,16,4,10.1063/1.3050879,"A good book may have the power to change the way we see the world, but a great book actually becomes part of our daily consciousness, pervading our thinking to the point that we take it for granted, and we forget how provocative and challenging its ideas once were-and still are. The Structure of Scientific Revolutions is that kind of book. When it was first published in 1962, it was a landmark event in the history and philosophy of science. And fifty years later, it still has many lessons to teach. With The Structure of Scientific Revolutions, Kuhn challenged long-standing linear notions of scientific progress, arguing that transformative ideas don't arise from the day-to-day, gradual process of experimentation and data accumulation, but that revolutions in those breakthrough moments that disrupt accepted thinking and offer unanticipated ideas, occur outside of normal science, as he called it. Though Kuhn was writing when physics ruled the sciences, his ideas on how scientific revolutions bring order to the anomalies that amass over time in research experiments are still instructive in our biotech age. This new edition of Kuhn's essential work in the history of science includes an insightful introductory essay by Ian Hacking that clarifies terms popularized by Kuhn, including paradigm and incommensurability, and applies Kuhn's ideas to the science of today. Usefully keyed to the separate sections of the book, Hacking's essay provides important background information as well as a contemporary context. Newly designed, with an expanded index, this edition will be eagerly welcomed by the next generation of readers seeking to understand the history of our perspectives on science.","['Engineering physics', 'Engineering ethics', 'Physics', 'Engineering']","scientific revolutions, scientific revolutions, scientific progress, transformative ideas, data accumulation, paradigm, incommensurability"
Paper_00173,Applied logistic regression,"['David W. Hosmer', 'Stanley Lemeshow']",1990,Choice Reviews Online,Journal,,27-3338,27,06,10.5860/choice.27-3338,"From the reviews of the First Edition. An interesting, useful, and well-written book on logistic regression models... Hosmer and Lemeshow have used very little mathematics, have presented difficult concepts heuristically and through illustrative examples, and have included references.- Choice Well written, clearly organized, and comprehensive... the authors carefully walk the reader through the estimation of interpretation of coefficients from a wide variety of logistic regression models . . . their careful explication of the quantitative re-expression of coefficients from these various models is excellent. - Contemporary Sociology An extremely well-written book that will certainly prove an invaluable acquisition to the practicing statistician who finds other literature on analysis of discrete data hard to follow or heavily theoretical.-The Statistician In this revised and updated edition of their popular book, David Hosmer and Stanley Lemeshow continue to provide an amazingly accessible introduction to the logistic regression model while incorporating advances of the last decade, including a variety of software packages for the analysis of data sets. Hosmer and Lemeshow extend the discussion from biostatistics and epidemiology to cutting-edge applications in data mining and machine learning, guiding readers step-by-step through the use of modeling techniques for dichotomous data in diverse fields. Ample new topics and expanded discussions of existing material are accompanied by a wealth of real-world examples-with extensive data sets available over the Internet.","['Logistic regression', 'Statistics', 'Regression', 'Mathematics']","logistic regression models, logistic regression models, contemporary sociology, stat, stat, logistic regression model, biostatistics, epidemiology, data mining, machine learning"
Paper_00174,Convex Optimization,"['Stephen Boyd', 'Lieven Vandenberghe']",2004,Unknown,Unknown,,,,,10.1017/cbo9780511804441,"Convex optimization problems arise frequently in many different fields. This book provides a comprehensive introduction to the subject, and shows in detail how such problems can be solved numerically with great efficiency. The book begins with the basic elements of convex sets and functions, and then describes various classes of convex optimization problems. Duality and approximation techniques are then covered, as are statistical estimation techniques. Various geometrical problems are then presented, and there is detailed discussion of unconstrained and constrained minimization problems, and interior-point methods. The focus of the book is on recognizing convex optimization problems and then finding the most appropriate technique for solving them. It contains many worked examples and homework exercises and will appeal to students, researchers and practitioners in fields such as engineering, computer science, mathematics, statistics, finance and economics.","['Proper convex function', 'Convex analysis', 'Duality (order theory)', 'Convex optimization', 'Mathematical optimization', 'Point (geometry)', 'Regular polygon', 'Optimization problem', 'Conic optimization', 'Computer science', 'Focus (optics)', 'Mathematics', 'Combinatorics', 'Geometry', 'Physics', 'Optics']","convex optimization problems, convex sets, convex optimization problems, duality, approximation techniques, statistical estimation techniques, constrained minimization, convex optimization problems, computer science, mathematics, statistics, finance, economics"
Paper_00177,Nonparametric Statistics for the Behavioral Sciences,"['Henri Guitton', 'Sidney Siegel']",1958,Revue économique,Journal,,675-675,9,4,10.2307/3498751,"This is the revision of the classic text in the field, adding two new chapters and thoroughly updating all others. The original structure is retained, and the book continues to serve as a combined text/reference.","['Nonparametric statistics', 'Statistics', 'Econometrics', 'Behavioural sciences', 'Psychology', 'Data science', 'Computer science', 'Mathematics', 'Psychotherapist']",
Paper_00178,Structural equation modeling in practice: A review and recommended two-step approach.,"['James C. Anderson', 'David W. Gerbing']",1988,Psychological Bulletin,Journal,,411-423,103,3,10.1037/0033-2909.103.3.411,"In this article, we provide guidance for substantive researchers on the use of structural equation modeling in practice for theory testing and development. We present a comprehensive, two-step modeling approach that employs a series of nested models and sequential chi-square difference tests. We discuss the comparative advantages of this approach over a one-step approach. Considerations in specification, assessment of fit, and respecification of measurement models using confirmatory factor analysis are reviewed. As background to the two-step approach, the distinction between exploratory and confirmatory analysis, the distinction between complementary approaches for theory testing versus predictive application, and some developments in estimation methods also are discussed.","['Structural equation modeling', 'Psychology', 'Computer science', 'Management science', 'Calculus (dental)', 'Econometrics', 'Mathematics', 'Medicine', 'Engineering', 'Machine learning', 'Orthodontics']","structural equation modeling, theory testing, nested models, measurement models, confirmatory factor analysis, confirmatory, theory testing, predict, estimation methods, [PAD] [PAD]"
Paper_00181,Crystal structure refinement with<i>SHELXL</i>,['George M. Sheldrick'],2014,Acta Crystallographica Section C Structural Chemistry,Journal,,3-8,71,1,10.1107/s2053229614024218,"The improvements in the crystal structure refinement program SHELXL have been closely coupled with the development and increasing importance of the CIF (Crystallographic Information Framework) format for validating and archiving crystal structures. An important simplification is that now only one file in CIF format (for convenience, referred to simply as `a CIF') containing embedded reflection data and SHELXL instructions is needed for a complete structure archive; the program SHREDCIF can be used to extract the .hkl and .ins files required for further refinement with SHELXL. Recent developments in SHELXL facilitate refinement against neutron diffraction data, the treatment of H atoms, the determination of absolute structure, the input of partial structure factors and the refinement of twinned and disordered structures. SHELXL is available free to academics for the Windows, Linux and Mac OS X operating systems, and is particularly suitable for multiple-core processors.","['Computer science', 'Crystal structure', 'File format', 'Data structure', 'Crystallography', 'Core (optical fiber)', 'Reflection (computer programming)', 'Operating system', 'Programming language', 'Chemistry', 'Telecommunications']","crystal structure refinement program shelxl, ci, crystallographic information framework, crystal, embedded reflection data, shelxl, ##f, shel, ##l, shelxl, neutron diffraction data, absolute structure, partial structure factors, disordered structures, shelxl"
Paper_00183,The Protein Data Bank,['Helen Berman'],2000,Nucleic Acids Research,Journal,,235-242,28,1,10.1093/nar/28.1.235,"The Protein Data Bank (PDB; http://www.rcsb.org/pdb/ ) is the single worldwide archive of structural data of biological macromolecules. This paper describes the goals of the PDB, the systems in place for data deposition and access, how to obtain further information, and near-term plans for the future development of the resource.","['Protein Data Bank (RCSB PDB)', 'Protein Data Bank', 'Biology', 'Data bank', 'Resource (disambiguation)', 'Bioinformatics', 'Computer science', 'Protein structure', 'Biochemistry', 'Telecommunications', 'Computer network']","protein data bank, structural data, biological macromo, [PAD]"
Paper_00184,<tt>edgeR</tt>: a Bioconductor package for differential expression analysis of digital gene expression data,"['Mark D. Robinson', 'Davis J. McCarthy', 'Gordon K. Smyth']",2009,Bioinformatics,Journal,,139-140,26,1,10.1093/bioinformatics/btp616,"Summary: It is expected that emerging digital gene expression (DGE) technologies will overtake microarray technologies in the near future for many functional genomics applications. One of the fundamental data analysis tasks, especially for gene expression studies, involves determining whether there is evidence that counts for a transcript or exon are significantly different across experimental conditions. edgeR is a Bioconductor software package for examining differential expression of replicated count data. An overdispersed Poisson model is used to account for both biological and technical variability. Empirical Bayes methods are used to moderate the degree of overdispersion across transcripts, improving the reliability of inference. The methodology can be used even with the most minimal levels of replication, provided at least one phenotype or experimental condition is replicated. The software may have other applications beyond sequencing data, such as proteome peptide count data.","['Bioconductor', 'Count data', 'Computer science', 'R package', 'Computational biology', 'Software', 'Inference', 'Biology', 'Overdispersion', 'Data mining', 'Genetics', 'Gene', 'Poisson distribution', 'Statistics', 'Mathematics', 'Artificial intelligence', 'Computational science', 'Programming language']","digital gene expression, microarray technologies, functional genomics, data analysis, gene expression studies, edger, bioconductor software, replicated count data, overdispersed poisson model, empirical bayes methods, proteome peptide count data"
Paper_00186,Firm resources and sustained competitive advantage,['Jay B. Barney'],2004,Advances in strategic management,Unknown,,203-227,,,10.1016/s0742-3322(00)17018-4,"Understanding sources of sustained competitive advantage has become a major area of research in strategic management. Building on the assumptions that strategic resources are heterogeneously distributed across firms and that these differences are stable over time, this article examines the link between firm resources and sustained competitive advantage. Four empirical indicators of the potential of firm resources to generate sustained competitive advantage-value, rareness, imitability, and substitutability are discussed. The model is applied by analyzing the potential of several firm resources for generating sustained competitive advantages. The article concludes by examining implications of this firm resource model of sustained competitive advantage for other business disciplines.","['Competitive advantage', 'Industrial organization', 'Business', 'Resource (disambiguation)', 'Resource-based view', 'Strategic management', 'Value (mathematics)', 'Marketing', 'Computer science', 'Computer network', 'Machine learning']","sustained competitive advantage, strategic management, strategic resources, firm resources, sustained competitive advantage, firm resources, sustained competitive advantage, value, rareness, imitability, substitutability, firm resources, sustained competitive advantages, firm resource model, sustained competitive advantage"
Paper_00190,Equation of State Calculations by Fast Computing Machines,"['N. Metropolis', 'Arianna W. Rosenbluth', 'M. N. Rosenbluth', 'Augusta H. Teller', 'Edward Teller']",1953,The Journal of Chemical Physics,Journal,,1087-1092,21,6,10.1063/1.1699114,"A general method, suitable for fast computing machines, for investigating such properties as equations of state for substances consisting of interacting individual molecules is described. The method consists of a modified Monte Carlo integration over configuration space. Results for the two-dimensional rigid-sphere system have been obtained on the Los Alamos MANIAC and are presented here. These results are compared to the free volume equation of state and to a four-term virial coefficient expansion.","['Virial coefficient', 'Monte Carlo method', 'Equation of state', 'Statistical physics', 'State (computer science)', 'State space', 'Physics', 'Thermodynamics', 'Computer science', 'Mathematics', 'Algorithm', 'Statistics']","fast computing machines, equations of state, configuration space, free volume equation of state, virial coefficient expansion, [PAD]"
Paper_00191,Visualizing Data using t-SNE,"['Laurens van der Maaten', 'Geoffrey E. Hinton']",2008,['2020 25th International Conference on Pattern Recognition (ICPR)'],Journal,,1051-1058,9,86,10.1109/icpr48806.2021.9412900,"We present a new technique called “t-SNE” that visualizes high-dimensional data by giving each datapoint a location in a two or three-dimensional map. The technique is a variation of Stochastic Neighbor Embedding (Hinton and Roweis, 2002) that is much easier to optimize, and produces significantly better visualizations by reducing the tendency to crowd points together in the center of the map. t-SNE is better than existing techniques at creating a single map that reveals structure at many different scales. This is particularly important for high-dimensional data that lie on several different, but related, low-dimensional manifolds, such as images of objects from multiple classes seen from multiple viewpoints. For visualizing the structure of very large datasets, we show how t-SNE can use random walks on neighborhood graphs to allow the implicit structure of all of the data to influence the way in which a subset of the data is displayed. We illustrate the performance of t-SNE on a wide variety of datasets and compare it with many other non-parametric visualization techniques, including Sammon mapping, Isomap, and Locally Linear Embedding. The visualizations produced by t-SNE are significantly better than those produced by the other techniques on almost all of the datasets.","['Isomap', 'Computer science', 'Embedding', 'Visualization', 'Nonlinear dimensionality reduction', 'Variety (cybernetics)', 'Artificial intelligence', 'Dimensionality reduction', 'Pattern recognition (psychology)', 'Data mining', 'Theoretical computer science']","stochastic neighbor embedding, random walks, neighborhood graphs, implicit structure, ##metric, sammon mapping, isomap, locally linear embedding, [PAD], [PAD]"
Paper_00192,User Acceptance of Information Technology: Toward a Unified View,"['Venkatesh', 'Jeremy Morris', 'Davis', 'Davis']",2003,MIS Quarterly,Journal,,425-425,27,3,10.2307/30036540,"Information technology (IT) acceptance research has yielded many competing models, each with different sets of acceptance determinants. In this paper, we (1) review user acceptance literature and discuss eight prominent models, (2) empirically compare the eight models and their extensions, (3) formulate a unified model that integrates elements across the eight models, and (4) empirically validate the unified model. The eight models reviewed are the theory of reasoned action, the technology acceptance model, the motivational model, the theory of planned behavior, a model combining the technology acceptance model and the theory of planned behavior, the model of PC utilization, the innovation diffusion theory, and the social cognitive theory. Using data from four organizations over a six-month period with three points of measurement, the eight models explained between 17 percent and 53 percent of the variance in user intentions to use information technology. Next, a unified model, called the Unified Theory of Acceptance and Use of Technology (UTAUT), was formulated, with four core determinants of intention and usage, and up to four moderators of key relationships. UTAUT was then tested using the original data and found to outperform the eight individual models (adjusted R2 of 69 percent). UTAUT was then confirmed with data from two new organizations with similar results (adjusted R2 of 70 percent). UTAUT thus provides a useful tool for managers needing to assess the likelihood of success for new technology introductions and helps them understand the drivers of acceptance in order to proactively design interventions (including training, marketing, etc.) targeted at populations of users that may be less inclined to adopt and use new systems. The paper also makes several recommendations for future research including developing a deeper understanding of the dynamic influences studied here, refining measurement of the core constructs used in UTAUT, and understanding the organizational outcomes associated with new technology use.","['Technology acceptance model', 'Knowledge management', 'Information technology', 'Computer science', 'Information system', 'Business', 'Human–computer interaction', 'Engineering', 'Usability', 'Electrical engineering', 'Operating system']","information technology, acceptance, acceptance determinants, user acceptance literature, unified model, reasoned action, technology acceptance model, motivational model, planned behavior, technology acceptance model, planned behavior, pc utilization, innovation diffusion theory, social cognitive theory, unified theory, utaut, utaut, utaut, utaut, training, marketing, ##ut"
Paper_00193,Emergence of Scaling in Random Networks,"['Albert‐László Barabási', 'Réka Albert']",1999,Science,Journal,,509-512,286,5439,10.1126/science.286.5439.509,"Systems as diverse as genetic networks or the World Wide Web are best described as networks with complex topology. A common property of many large networks is that the vertex connectivities follow a scale-free power-law distribution. This feature was found to be a consequence of two generic mechanisms: (i) networks expand continuously by the addition of new vertices, and (ii) new vertices attach preferentially to sites that are already well connected. A model based on these two ingredients reproduces the observed stationary scale-free distributions, which indicates that the development of large networks is governed by robust self-organizing phenomena that go beyond the particulars of the individual systems.","['Vertex (graph theory)', 'Complex network', 'Scaling', 'Scale-free network', 'Computer science', 'Topology (electrical circuits)', 'Preferential attachment', 'Theoretical computer science', 'Random graph', 'Statistical physics', 'Mathematics', 'Combinatorics', 'Physics', 'Graph', 'World Wide Web', 'Geometry']","genetic networks, world wide web, complex topology, vertex connectivities"
Paper_00194,Prospect theory: An analysis of decision under risk,"['Daniel Kahneman', 'Amos Tversky']",1988,Cambridge University Press eBooks,Unknown,,183-214,,,10.1017/cbo9780511609220.014,"Expected utility theory has dominated the analysis of decision making under risk. It has been generally accepted as a normative model of rational choice (Keeney and Raiffa, 1976), and widely applied as a descriptive model of economic behavior (e.g., Friedman and Savage, 1948, and Arrow, 1971). Thus, it is assumed that all reasonable people would wish to obey the axioms of the theory (von Neumann & Morgenstern, 1944, and Savage, 1954), and that most people actually do, most of the time.","['Axiom', 'Arrow', 'Normative', 'Expected utility hypothesis', 'Subjective expected utility', 'Mathematical economics', 'Decision theory', 'Von Neumann architecture', 'Von Neumann–Morgenstern utility theorem', 'Economics', 'Positive economics', 'Computer science', 'Epistemology', 'Microeconomics', 'Mathematics', 'Philosophy', 'Geometry', 'Programming language', 'Operating system']","expected utility theory, decision making, risk, normative model, rational choice, descriptive model, economic behavior"
Paper_00196,Dropout: a simple way to prevent neural networks from overfitting,"['Nitish Srivastava', 'Geoffrey E. Hinton', 'Alex Krizhevsky', 'Ilya Sutskever', 'Ruslan Salakhutdinov']",2014,['Asian Journal of Research in Computer Science'],Journal,,163-185,18,2,10.9734/ajrcos/2025/v18i2569,"Deep neural nets with a large number of parameters are very powerful machine learning systems. However, overfitting is a serious problem in such networks. Large networks are also slow to use, making it difficult to deal with overfitting by combining the predictions of many different large neural nets at test time. Dropout is a technique for addressing this problem. The key idea is to randomly drop units (along with their connections) from the neural network during training. This prevents units from co-adapting too much. During training, dropout samples from an exponential number of different networks. At test time, it is easy to approximate the effect of averaging the predictions of all these thinned networks by simply using a single unthinned network that has smaller weights. This significantly reduces overfitting and gives major improvements over other regularization methods. We show that dropout improves the performance of neural networks on supervised learning tasks in vision, speech recognition, document classification and computational biology, obtaining state-of-the-art results on many benchmark data sets.","['Overfitting', 'Dropout (neural networks)', 'Computer science', 'Artificial intelligence', 'Artificial neural network', 'Machine learning', 'Benchmark (surveying)', 'Deep neural networks', 'Regularization (linguistics)', 'Geodesy', 'Geography']","deep neural nets, machine learning systems, overfitting, ##tting, dropout, unthinned network, ##ization, dropout, supervised learning tasks, vision, speech recognition, document classification, computational biology, [PAD], [PAD]"
Paper_00197,The Discovery of Grounded Theory; Strategies for Qualitative Research,"['Barney G. Glaser', 'Anselm L. Strauss', 'Elizabeth Strutzel']",1968,Nursing Research,Journal,,364-364,17,4,10.1097/00006199-196807000-00014,"Most writing on sociological method has been concerned with how accurate facts can be obtained and how theory can thereby be more rigorously tested. In The Discovery of Grounded Barney Glaser and Anselm Strauss address the equally Important enterprise of how the discovery of theory from data--systematically obtained and analyzed in social research--can be furthered. The discovery of theory from data--grounded theory--is a major task confronting sociology, for such a theory fits empirical situations, and is understandable to sociologists and laymen alike. Most important, it provides relevant predictions, explanations, interpretations, and applications. In Part I of the book, Generation Theory by Comparative Analysis, the authors present a strategy whereby sociologists can facilitate the discovery of grounded theory, both substantive and formal. This strategy involves the systematic choice and study of several comparison groups. In Part II, The Flexible Use of Data, the generation of theory from qualitative, especially documentary, and quantitative data Is considered. In Part III, Implications of Grounded Theory, Glaser and Strauss examine the credibility of grounded theory. The Discovery of Grounded Theory is directed toward improving social scientists' capacity for generating theory that will be relevant to their research. While aimed primarily at sociologists, it will be useful to anyone Interested In studying social phenomena--political, educational, economic, industrial-- especially If their studies are based on qualitative data.","['Grounded theory', 'Qualitative research', 'Psychology', 'Sociology', 'Social science']","sociological method, grounded, social research, grounded, generation theory, comparative analysis, grounded theory, comparison groups, quantitative data, grounded theory, grounded theory, grounded theory, ##tative"
Paper_00200,The MOS 36-item short-form health survey (SF-36). I. Conceptual framework and item selection.,"['John E. Ware', 'Cathy D. Sherbourne']",1992,['Medical Care'],Unknown,,247-263,31,3,10.1097/00005650-199303000-00006,"A 36-item short-form (SF-36) was constructed to survey health status in the Medical Outcomes Study. The SF-36 was designed for use in clinical practice and research, health policy evaluations, and general population surveys. The SF-36 includes one multi-item scale that assesses eight health concepts: 1) limitations in physical activities because of health problems; 2) limitations in social activities because of physical or emotional problems; 3) limitations in usual role activities because of physical health problems; 4) bodily pain; 5) general mental health (psychological distress and well-being); 6) limitations in usual role activities because of emotional problems; 7) vitality (energy and fatigue); and 8) general health perceptions. The survey was constructed for self-administration by persons 14 years of age and older, and for administration by a trained interviewer in person or by telephone. The history of the development of the SF-36, the origin of specific items, and the logic underlying their selection are summarized. The content and features of the SF-36 are compared with the 20-item Medical Outcomes Study short-form.","['Vitality', 'Psychology', 'Scale (ratio)', 'Mental health', 'SF-36', 'Population', 'Emotional distress', 'Typology', 'Gerontology', 'Clinical psychology', 'Applied psychology', 'Medicine', 'Psychiatry', 'Anxiety', 'Health related quality of life', 'Disease', 'Philosophy', 'Physics', 'Theology', 'Environmental health', 'Archaeology', 'Pathology', 'Quantum mechanics', 'History']","health status, medical outcomes study, clinical practice, health policy evaluations, general population surveys, social activities, bodily pain, general mental health, vitality, general health perceptions, medical outcomes"
Paper_00132,Absorptive Capacity: A New Perspective on Learning and Innovation,"['Wesley M. Cohen', 'Daniel A. Levinthal']",1990,Administrative Science Quarterly,Journal,,128-128,35,1,10.2307/2393553,"In this paper, we argue that the ability of a firm to recognize the value of new, external information, assimilate it, and apply it to commercial ends is critical to its innovative capabilities. We label this capability a firm's absorptive capacity and suggest that it is largely a function of the firm's level of prior related knowledge. The discussion focuses first on the cognitive basis for an individual's absorptive capacity including, in particular, prior related knowledge and diversity of background. We then characterize the factors that influence absorptive capacity at the organizational level, how an organization's absorptive capacity differs from that of its individual members, and the role of diversity of expertise within an organization. We argue that the development of absorptive capacity, and, in turn, innovative performance are history- or path-dependent and argue how lack of investment in an area of expertise early on may foreclose the future development of a technical capability in that area. We formulate a model of firm investment in research and development (R&D), in which R&D contributes to a firm's absorptive capacity, and test predictions relating a firm's investment in R&D to the knowledge underlying technical change within an industry. Discussion focuses on the implications of absorptive capacity for the analysis of other related innovative activities, including basic research, the adoption and diffusion of innovations, and decisions to participate in cooperative R&D ventures. **","['Absorptive capacity', 'Perspective (graphical)', 'Knowledge management', 'Psychology', 'Sociology', 'Computer science', 'Artificial intelligence']","absorptive capacity, absorptive capacity, absorptive capacity, ##ptive capacity, absorptive capacity, innovative performance, technical, firm investment, ##ptive, absorptive capacity"
Paper_00133,A new mathematical model for relative quantification in real-time RT-PCR,['Michael W. Pfaffl'],2001,Nucleic Acids Research,Journal,,45e-45,29,9,10.1093/nar/29.9.e45,"Use of the real-time polymerase chain reaction (PCR) to amplify cDNA products reverse transcribed from mRNA is on the way to becoming a routine tool in molecular biology to study low abundance gene expression. Real-time PCR is easy to perform, provides the necessary accuracy and produces reliable as well as rapid quantification results. But accurate quantification of nucleic acids requires a reproducible methodology and an adequate mathematical model for data analysis. This study enters into the particular topics of the relative quantification in real-time RT–PCR of a target gene transcript in comparison to a reference gene transcript. Therefore, a new mathematical model is presented. The relative expression ratio is calculated only from the real-time PCR efficiencies and the crossing point deviation of an unknown sample versus a control. This model needs no calibration curve. Control levels were included in the model to standardise each reaction run with respect to RNA integrity, sample loading and inter-PCR variations. High accuracy and reproducibility (<2.5% variation) were reached in LightCycler PCR using the established mathematical model.","['Biology', 'Real-time polymerase chain reaction', 'Computational biology', 'Polymerase chain reaction', 'Complementary DNA', 'Biological system', 'Melting curve analysis', 'Reproducibility', 'Sample (material)', 'Nucleic acid', 'Digital polymerase chain reaction', 'Gene expression', 'Gene', 'Genetics', 'Statistics', 'Mathematics', 'Chromatography', 'Chemistry']","molecular biology, low abundance gene expression, nuclei, relative quantification, relative expression ratio, crossing point deviation, ##ration, rna integrity, sample loading, light"
Paper_00134,Convex Optimization,"['Stephen Boyd', 'Lieven Vandenberghe']",2004,"['Chapman &amp; Hall/CRC Applied Algorithms and Data Structures series', 'Algorithms and Theory of Computation Handbook, Second Edition, Volume 1']",Unknown,,1-40,,,10.1201/9781584888239-c32,"Convex optimization problems arise frequently in many different fields. A comprehensive introduction to the subject, this book shows in detail how such problems can be solved numerically with great efficiency. The focus is on recognizing convex optimization problems and then finding the most appropriate technique for solving them. The text contains many worked examples and homework exercises and will appeal to students, researchers and practitioners in fields such as engineering, computer science, mathematics, statistics, finance, and economics.","['Appeal', 'Subject (documents)', 'Focus (optics)', 'Regular polygon', 'Convex optimization', 'Convex analysis', 'Computer science', 'Mathematical optimization', 'Proper convex function', 'Optimization problem', 'Mathematical economics', 'Management science', 'Mathematics', 'Engineering', 'Political science', 'Physics', 'Geometry', 'Library science', 'Optics', 'Law']","convex optimization problems, convex optimization problems, homework exercises, computer science, statistics, finance, economics"
Paper_00135,ImageNet classification with deep convolutional neural networks,"['Alex Krizhevsky', 'Ilya Sutskever', 'Geoffrey E. Hinton']",2017,Communications of the ACM,Journal,,84-90,60,6,10.1145/3065386,"We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5% and 17.0%, respectively, which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolution operation. To reduce overfitting in the fully connected layers we employed a recently developed regularization method called ""dropout"" that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3%, compared to 26.2% achieved by the second-best entry.","['Softmax function', 'Computer science', 'Overfitting', 'Convolutional neural network', 'Pooling', 'Dropout (neural networks)', 'Artificial intelligence', 'Pattern recognition (psychology)', 'Regularization (linguistics)', 'Convolution (computer science)', 'Deep neural networks', 'Word error rate', 'Deep learning', 'Artificial neural network', 'Machine learning']","convolutional neural network, imagenet, convolutional layers, - saturating, gpu, convolution operation, regularization method, dropout, ils"
Paper_00136,Como Elaborar Projetos de Pesquisa,['Antônio Carlos Gil'],2010,['Revista Trabalho Necessário'],Unknown,,,15,28,10.22409/tn.15i28.p10563,"Elaborar um projeto de pesquisa para conferir maior eficiencia a investigacao para em determinado prazo alcancar o conjunto das metas estabelecidas. Envolve quatro elementos necessarios a sua compreensao: processo, eficiencia, prazos e metas. O planejamento da pesquisa pode ser definido como o processo sistematizado que confere eficiencia a investigacao, que em determinado para alcancar as metas estabelecidas, este e concretizado pela elaboracao de um projeto de pesquisa (formulacao do problema; construcao de hipoteses ou especificacao dos objetivos; identificacao do tipo de pesquisa; operacionalizacao das variaveis; selecao da amostra; elaboracao dos instrumentos e determinacao da estrategia de coleta de dados; determinacao do plano de analise dos dados; previsao da forma de apresentacao dos resultados; cronograma da execucao da pesquisa; definicao dos recursos humanos, materiais e financeiros a serem alocados), que possibilita esquematizar atividades e experiencias.","['Humanities', 'Philosophy', 'Political science', 'Computer science']",
Paper_00137,Glove: Global Vectors for Word Representation,"['Jeffrey Pennington', 'Richard Socher', 'Christopher D. Manning']",2014,Unknown,Unknown,,,,,10.3115/v1/d14-1162,"Recent methods for learning vector space representations of words have succeeded in capturing fine-grained semantic and syntactic regularities using vector arithmetic, but the origin of these regularities has remained opaque. We analyze and make explicit the model properties needed for such regularities to emerge in word vectors. The result is a new global logbilinear regression model that combines the advantages of the two major model families in the literature: global matrix factorization and local context window methods. Our model efficiently leverages statistical information by training only on the nonzero elements in a word-word cooccurrence matrix, rather than on the entire sparse matrix or on individual context windows in a large corpus. The model produces a vector space with meaningful substructure, as evidenced by its performance of 75% on a recent word analogy task. It also outperforms related models on similarity tasks and named entity recognition.","['Computer science', 'Representation (politics)', 'Word (group theory)', 'Natural language processing', 'Artificial intelligence', 'Human–computer interaction', 'Computer graphics (images)', 'Linguistics', 'Philosophy', 'Politics', 'Political science', 'Law']","vector space representations, words, syntactic regularities, vector arithmetic, word vectors, global logbilinear regression model, global matrix factorization, local context window methods, word analogy, similarity tasks, entity recognition, [PAD] [PAD] [PAD] [PAD] [PAD] [PAD], [PAD] [PAD]"
Paper_00138,Inference of Population Structure Using Multilocus Genotype Data,"['Jonathan K. Pritchard', 'Matthew Stephens', 'Peter Donnelly']",2000,Genetics,Journal,,945-959,155,2,10.1093/genetics/155.2.945,"Abstract We describe a model-based clustering method for using multilocus genotype data to infer population structure and assign individuals to populations. We assume a model in which there are K populations (where K may be unknown), each of which is characterized by a set of allele frequencies at each locus. Individuals in the sample are assigned (probabilistically) to populations, or jointly to two or more populations if their genotypes indicate that they are admixed. Our model does not assume a particular mutation process, and it can be applied to most of the commonly used genetic markers, provided that they are not closely linked. Applications of our method include demonstrating the presence of population structure, assigning individuals to populations, studying hybrid zones, and identifying migrants and admixed individuals. We show that the method can produce highly accurate assignments using modest numbers of loci—e.g., seven microsatellite loci in an example using genotype data from an endangered bird species. The software used for this article is available from http://www.stats.ox.ac.uk/~pritch/home.html.","['Biology', 'Microsatellite', 'Genotype', 'Locus (genetics)', 'Genetics', 'Inference', 'Population', 'Population genetics', 'Cluster analysis', 'Allele', 'Genetic structure', 'Population structure', 'Evolutionary biology', 'Allele frequency', 'Genetic data', 'Computational biology', 'Genetic variation', 'Computer science', 'Artificial intelligence', 'Gene', 'Demography', 'Sociology']","clustering, multilocus genotype data, population structure, allele frequencies, mutation process, hybrid zones, admixed individuals, microsatellite loci, gen"
Paper_00140,"Estimation of the Concentration of Low-Density Lipoprotein Cholesterol in Plasma, Without Use of the Preparative Ultracentrifuge","['William T. Friedewald', 'Robert I. Levy', 'Donald S. Fredrickson']",1972,Clinical Chemistry,Journal,,499-502,18,6,10.1093/clinchem/18.6.499,"Abstract A method for estimating the cholesterol content of the serum low-density lipoprotein fraction (Sf0-20) is presented. The method involves measurements of fasting plasma total cholesterol, triglyceride, and high-density lipoprotein cholesterol concentrations, none of which requires the use of the preparative ultracentrifuge. Comparison of this suggested procedure with the more direct procedure, in which the ultracentrifuge is used, yielded correlation coefficients of .94 to .99, depending on the patient population compared.","['Ultracentrifuge', 'Chemistry', 'Cholesterol', 'Chromatography', 'Triglyceride', 'Lipoprotein', 'Fraction (chemistry)', 'High-density lipoprotein', 'Population', 'Plasma lipoprotein', 'Biochemistry', 'Medicine', 'Environmental health']","cholesterol content, fasting plasma, triglyceride, preparative ultracentrifuge, ultracentrifuge, correlation coefficients, [PAD], [PAD], [PAD] [PAD], [PAD] [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD], [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"
Paper_00141,Self-efficacy: Toward a unifying theory of behavioral change.,['Albert Bandura'],1977,Psychological Review,Journal,,191-215,84,2,10.1037//0033-295x.84.2.191,"The present article presents an integrative theoretical framework to explain and to predict psychological changes achieved by different modes of treatment. This theory states that psychological procedures, whatever their form, alter the level and strength of self-efficacy. It is hypothesized that expectations of personal efficacy determine whether coping behavior will be initiated, how much effort will be expended, and how long it will be sustained in the face of obstacles and aversive experiences. Persistence in activities that are subjectively threatening but in fact relatively safe produces, through experiences of mastery, further enhancement of self-efficacy and corresponding reductions in defensive behavior. In the proposed model, expectations of personal efficacy are derived from four principal sources of information: performance accomplishments, vicarious experience, verbal persuasion, and physiological states. The more dependable the experiential sources, the greater are the changes in perceived selfefficacy. A number of factors are identified as influencing the cognitive processing of efficacy information arising from enactive, vicarious, exhortative, and emotive sources. The differential power of diverse therapeutic procedures is analyzed in terms of the postulated cognitive mechanism of operation. Findings are reported from microanalyses of enactive, vicarious, and emotive modes of treatment that support the hypothesized relationship between perceived self-efficacy and behavioral changes. Possible directions for further research are discussed.","['Psychology', 'Cognitive psychology', 'Behavior change', 'Cognitive science', 'Social psychology']","psychological changes, psychological procedures, personal efficacy, coping behavior, ##ive, defensive behavior, personal efficacy, performance accomplishments, vicarious experience, verbal persuasion, physiological states, perceived self, cognitive processing, efficacy, ##hort, emotive, therapeutic, ##ive"
Paper_00142,Quantifying heterogeneity in a meta‐analysis,"['Julian P. T. Higgins', 'Simon G. Thompson']",2002,Statistics in Medicine,Journal,,1539-1558,21,11,10.1002/sim.1186,"Abstract The extent of heterogeneity in a meta‐analysis partly determines the difficulty in drawing overall conclusions. This extent may be measured by estimating a between‐study variance, but interpretation is then specific to a particular treatment effect metric. A test for the existence of heterogeneity exists, but depends on the number of studies in the meta‐analysis. We develop measures of the impact of heterogeneity on a meta‐analysis, from mathematical criteria, that are independent of the number of studies and the treatment effect metric. We derive and propose three suitable statistics: H is the square root of the χ 2 heterogeneity statistic divided by its degrees of freedom; R is the ratio of the standard error of the underlying mean from a random effects meta‐analysis to the standard error of a fixed effect meta‐analytic estimate, and I 2 is a transformation of H that describes the proportion of total variation in study estimates that is due to heterogeneity. We discuss interpretation, interval estimates and other properties of these measures and examine them in five example data sets showing different amounts of heterogeneity. We conclude that H and I 2 , which can usually be calculated for published meta‐analyses, are particularly useful summaries of the impact of heterogeneity. One or both should be presented in published meta‐analyses in preference to the test for heterogeneity. Copyright © 2002 John Wiley &amp; Sons, Ltd.","['Meta-analysis', 'Study heterogeneity', 'Statistics', 'Statistic', 'Random effects model', 'Metric (unit)', 'Spatial heterogeneity', 'Econometrics', 'Mathematics', 'Variance (accounting)', 'Standard error', 'Confidence interval', 'Computer science', 'Medicine', 'Operations management', 'Accounting', 'Business', 'Internal medicine', 'Economics', 'Biology', 'Ecology']","heterogeneity, meta ‐ analysis, treatment effect metric, heterogeneity, meta ‐ analysis, heterogen, ##y, meta ‐ analysis, treatment effect metric, ##gen, degrees of freedom, standard error, random effects, standard, fixed effect, interval estimates, het, hetero"
Paper_00143,MEGA X: Molecular Evolutionary Genetics Analysis across Computing Platforms,"['Sudhir Kumar', 'Glen Stecher', 'Michael Li', 'Christina Knyaz', 'Koichiro Tamura']",2018,Molecular Biology and Evolution,Journal,,1547-1549,35,6,10.1093/molbev/msy096,"The Molecular Evolutionary Genetics Analysis (Mega) software implements many analytical methods and tools for phylogenomics and phylomedicine. Here, we report a transformation of Mega to enable cross-platform use on Microsoft Windows and Linux operating systems. Mega X does not require virtualization or emulation software and provides a uniform user experience across platforms. Mega X has additionally been upgraded to use multiple computing cores for many molecular evolutionary analyses. Mega X is available in two interfaces (graphical and command line) and can be downloaded from www.megasoftware.net free of charge.","['Mega-', 'Emulation', 'Biology', 'Software', 'Virtualization', 'Phylogenomics', 'Operating system', 'OS X', 'Computer science', 'Computational biology', 'Phylogenetic tree', 'Genetics', 'Cloud computing', 'Clade', 'Physics', 'Astronomy', 'Economics', 'Gene', 'Economic growth']","molecular evolutionary genetics analysis, mega, phylogenomics, phylomedicine, mega, linux, mega, virtualization, emulation, mega, molecular evolutionary analyses, mega, megasoft, [PAD] [PAD], [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD] [PAD], [PAD]"
Paper_00145,Fully convolutional networks for semantic segmentation,"['Jonathan Long', 'Evan Shelhamer', 'Trevor Darrell']",2015,Unknown,Unknown,,,,,10.1109/cvpr.2015.7298965,"Convolutional networks are powerful visual models that yield hierarchies of features. We show that convolutional networks by themselves, trained end-to-end, pixels-to-pixels, exceed the state-of-the-art in semantic segmentation. Our key insight is to build ""fully convolutional"" networks that take input of arbitrary size and produce correspondingly-sized output with efficient inference and learning. We define and detail the space of fully convolutional networks, explain their application to spatially dense prediction tasks, and draw connections to prior models. We adapt contemporary classification networks (AlexNet [20], the VGG net [31], and GoogLeNet [32]) into fully convolutional networks and transfer their learned representations by fine-tuning [3] to the segmentation task. We then define a skip architecture that combines semantic information from a deep, coarse layer with appearance information from a shallow, fine layer to produce accurate and detailed segmentations. Our fully convolutional network achieves state-of-the-art segmentation of PASCAL VOC (20% relative improvement to 62.2% mean IU on 2012), NYUDv2, and SIFT Flow, while inference takes less than one fifth of a second for a typical image.","['Computer science', 'Artificial intelligence', 'Segmentation', 'Convolutional neural network', 'Pattern recognition (psychology)', 'Inference', 'Pixel', 'Pascal (unit)', 'Programming language']","convolutional networks, visual models, convolutional networks, semantic segmentation, ##volutional, spatially dense prediction tasks, classification networks, alexnet, vgg net, googlenet, ##volutional networks, segment, skip architecture, semantic information, appearance information, pascal voc, nyudv2, sift flow"
Paper_00146,limma powers differential expression analyses for RNA-sequencing and microarray studies,"['Matthew E. Ritchie', 'Belinda Phipson', 'Di Wu', 'Yifang Hu', 'Charity W. Law', 'Wei Shi', 'Gordon K. Smyth']",2015,Nucleic Acids Research,Journal,,e47-e47,43,7,10.1093/nar/gkv007,"limma is an R/Bioconductor software package that provides an integrated solution for analysing data from gene expression experiments. It contains rich features for handling complex experimental designs and for information borrowing to overcome the problem of small sample sizes. Over the past decade, limma has been a popular choice for gene discovery through differential expression analyses of microarray and high-throughput PCR data. The package contains particularly strong facilities for reading, normalizing and exploring such data. Recently, the capabilities of limma have been significantly expanded in two important directions. First, the package can now perform both differential expression and differential splicing analyses of RNA sequencing (RNA-seq) data. All the downstream analysis tools previously restricted to microarray data are now available for RNA-seq as well. These capabilities allow users to analyse both RNA-seq and microarray data with very similar pipelines. Second, the package is now able to go past the traditional gene-wise expression analyses in a variety of ways, analysing expression profiles in terms of co-regulated sets of genes or in terms of higher-order expression signatures. This provides enhanced possibilities for biological interpretation of gene expression differences. This article reviews the philosophy and design of the limma package, summarizing both new and historical features, with an emphasis on recent enhancements and features that have not been previously described.","['Biology', 'Bioconductor', 'Computational biology', 'DNA microarray', 'Microarray analysis techniques', 'Gene chip analysis', 'Expression (computer science)', 'Data mining', 'Gene expression', 'Genetics', 'Gene', 'Computer science', 'Programming language']","limma, gene expression experiments, limma, differential expression analyses, limma, differential expression, differential splicing analyses, gene, limma"
Paper_00152,,"['Jacob Devlin', 'Ming‐Wei Chang', 'Kenton Lee', 'Kristina Toutanova']",2019,Unknown,Unknown,,,,,10.18653/v1/n19-1423,"Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova. Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers). 2019.","['Computer science', 'Computational linguistics', 'Linguistics', 'Library science', 'Artificial intelligence', 'Philosophy']","computational linguistics, human language technologies, [PAD], [PAD] [PAD] [PAD], [PAD]"
Paper_00153,Principles and Practice of Structural Equation Modeling,['Rex B. Kline'],1998,['Canadian Graduate Journal of Sociology and Criminology'],Unknown,,59-60,1,1,10.15353/cgjsc.v1i1.3787,"Designed for students and researchers without an extensive quantitative background, this book offers an informative guide to the application, interpretation and pitfalls of structural equation modelling (SEM) in the social sciences. The book covers introductory techniques including path analysis and confirmatory factor analysis, and provides an overview of more advanced methods such as the evaluation of non-linear effects, the analysis of means in convariance structure models, and latent growth models for longitudinal data. Providing examples from various disciplines to illustrate all aspects of SEM, the book offers clear instructions on the preparation and screening of data, common mistakes to avoid and widely used software programs (Amos, EQS and LISREL). The book aims to provide the skills necessary to begin to use SEM in research and to interpret and critique the use of method by others.","['LISREL', 'Structural equation modeling', 'Path analysis (statistics)', 'Confirmatory factor analysis', 'Computer science', 'Latent variable', 'Interpretation (philosophy)', 'Management science', 'Data science', 'Artificial intelligence', 'Engineering', 'Machine learning', 'Programming language']","structural equation modelling, ##m, social, path analysis, confirmatory factor analysis, non - linear effects, convariance structure models, latent growth models, longitudinal data, amos, eqs, lisrel"
Paper_00154,The Iron Cage Revisited: Institutional Isomorphism and Collective Rationality in Organizational Fields,"['Paul DiMaggio', 'Walter W. Powell']",1983,American Sociological Review,Journal,,147-147,48,2,10.2307/2095101,"Instead of examining why organizations are dissimilar, this study explores why organizations tend to be increasingly and inevitably homogenous in their forms and practices. Organizations in a similar line of work are structured into an organizational field by powerful forces that lead them to become similar. Rather than the causes of rationalization and bureaucratization suggested by Max Weber, including competition and the need for efficiency, institutional similarity is due to the structuration of organizational fields, a process caused largely by the state and the professions, which are the great rationalizers of the late 20th century. In highly structured organizational fields, rational efforts of individuals aggregately lead to structural, cultural, and output homogeneity. Homogenization is best captured by the concept of isomorphism, the process whereby one element in a population resembles others that confront the same environmental conditions. The two types of isomorphism are competitive and institutional. Three processes lead to organizational similarity: (1) coercive isomorphism stemming from political influence and the problem of legitimacy; (2) mimetic isomorphism resulting from uniform responses to uncertainty; and (3) normative isomorphism associated with professionalism. While these isomorphic processes improve organizational transactions, they do not necessarily increase internal efficiency. Twelve hypotheses are offered for further research about which organizational fields will be most homogenous. These hypotheses relate the impact of resource centralization and dependency, goal ambiguity and technical uncertainty, and professionalism and structuration on isomorphic change. Finally, useful implications of the study for theories of organizations and social change are offered. (TNM)","['Rationality', 'Isomorphism (crystallography)', 'Organizational field', 'Cage', 'Sociology', 'Political science', 'Business', 'Institutional theory', 'Mathematics', 'Combinatorics', 'Social science', 'Law', 'Chemistry', 'Crystal structure', 'Crystallography']","organizational field, rationalization, bureaucratization, competition, institutional similarity, professions, output homogen, homogenization, isomorphism, isomorphism, organizational similarity, coercive isomorphism, political influence, legitimacy, mimetic isomorphism, uncertainty, ##tive isomorphism, professionalism, iso, resource centralization, dependency, goal ambiguity, technical uncertainty, professionalism, ##uration, isomorphic change, organizations, social change"
Paper_00155,Some Tests of Specification for Panel Data: Monte Carlo Evidence and an Application to Employment Equations,"['Manuel Arellano', 'Stephen Bond']",1991,The Review of Economic Studies,Journal,,277-277,58,2,10.2307/2297968,"This paper presents specification tests that are applicable after estimating a dynamic model from panel data by the generalized method of moments (GMM), and studies the practical performance of these procedures using both generated and real data. Our GMM estimator optimally exploits all the linear moment restrictions that follow from the assumption of no serial correlation in the errors, in an equation which contains individual effects, lagged dependent variables and no strictly exogenous variables. We propose a test of serial correlation based on the GMM residuals and compare this with Sargan tests of over-identifying restrictions and Hausman specification tests.","['Generalized method of moments', 'Estimator', 'Panel data', 'Hausman test', 'Econometrics', 'Monte Carlo method', 'Specification', 'Moment (physics)', 'Autocorrelation', 'Instrumental variable', 'Computer science', 'Mathematics', 'Statistics', 'Fixed effects model', 'Physics', 'Classical mechanics']","specification tests, dynamic model, panel data, generalized method of moments, gm, gmm estima, linear moment restrictions, serial correlation, lagged dependent variables, serial correlation, gmm residual, ##gan, hausman specification tests, [PAD], [PAD] [PAD], [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD], [PAD], [PAD] [PAD], [PAD] [PAD], [PAD] [PAD] [PAD] [PAD], [PAD] [PAD], [PAD], [PAD] [PAD], [PAD], [PAD] [PAD] [PAD] [PAD]"
Paper_00156,"Co-Integration and Error Correction: Representation, Estimation, and Testing","['Robert F. Engle', 'C. W. J. Granger']",1987,Econometrica,Journal,,251-251,55,2,10.2307/1913236,"The relationship between co-integration and error correction models, first suggested in Granger (1981), is here extended and used to develop estimation procedures, tests, and empirical examples. If each element of a vector of time series x first achieves stationarity after differencing, but a linear combination a'x is already stationary, the time series x are said to be co-integrated with co-integrating vector a. There may be several such co-integrating vectors so that a becomes a matrix. Interpreting a'x,= 0 as a long run equilibrium, co-integration implies that deviations from equilibrium are stationary, with finite variance, even though the series themselves are nonstationary and have infinite variance. The paper presents a representation theorem based on Granger (1983), which connects the moving average, autoregressive, and error correction representations for co-integrated systems. A vector autoregression in differenced variables is incompatible with these representations. Estimation of these models is discussed and a simple but asymptotically efficient two-step estimator is proposed. Testing for co-integration combines the problems of unit root tests and tests with parameters unidentified under the null. Seven statistics are formulated and analyzed. The critical values of these statistics are calculated based on a Monte Carlo simulation. Using these critical values, the power properties of the tests are examined and one test procedure is recommended for application. In a series of examples it is found that consumption and income are co-integrated, wages and prices are not, short and long interest rates are, and nominal GNP is co-integrated with M2, but not M1, M3, or aggregate liquid assets.","['Estimation', 'Representation (politics)', 'Econometrics', 'Computer science', 'Statistics', 'Mathematics', 'Economics', 'Political science', 'Management', 'Law', 'Politics']","error correction models, estimation procedures, time series, representation theorem, moving average, autoregressive, error correction representations, vector autoregression, differenced variables, unit root tests, monte carlo simulation, nominal gnp, aggregate liquid assets"
Paper_00157,Neural Networks: A Comprehensive Foundation,['Simon Haykin'],1998,['Neurocomputing'],Unknown,,359-360,8,3,10.1016/0925-2312(95)90026-8,"From the Publisher:
This book represents the most comprehensive treatment available of neural networks from an engineering perspective. Thorough, well-organized, and completely up to date, it examines all the important aspects of this emerging technology, including the learning process, back-propagation learning, radial-basis function networks, self-organizing systems, modular networks, temporal processing and neurodynamics, and VLSI implementation of neural networks. Written in a concise and fluid manner, by a foremost engineering textbook author, to make the material more accessible, this book is ideal for professional engineers and graduate students entering this exciting field. Computer experiments, problems, worked examples, a bibliography, photographs, and illustrations reinforce key concepts.","['Modular design', 'Computer science', 'Field (mathematics)', 'Artificial neural network', 'Process (computing)', 'Function (biology)', 'Ideal (ethics)', 'Key (lock)', 'Perspective (graphical)', 'Artificial intelligence', 'Foundation (evidence)', 'Engineering', 'Geography', 'Epistemology', 'Mathematics', 'Philosophy', 'Computer security', 'Archaeology', 'Evolutionary biology', 'Pure mathematics', 'Biology', 'Operating system']","neural networks, learning process, modular networks, temporal processing, neurodynamics, vlsi implementation, neural networks, professional engineers, graduate students, [PAD], [PAD] [PAD], [PAD], [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD], [PAD]"
Paper_00158,KEGG: Kyoto Encyclopedia of Genes and Genomes,"['Hiroyuki Ogata', 'Susumu Goto', 'Kazushige Sato', 'Wataru Fujibuchi', 'Hidemasa Bono', 'Minoru Kanehisa']",1999,Nucleic Acids Research,Journal,,29-34,27,1,10.1093/nar/27.1.29,"Kyoto Encyclopedia of Genes and Genomes (KEGG) is a knowledge base for systematic analysis of gene functions in terms of the networks of genes and molecules. The major component of KEGG is the PATHWAY database that consists of graphical diagrams of biochemical pathways including most of the known metabolic pathways and some of the known regulatory pathways. The pathway information is also represented by the ortholog group tables summarizing orthologous and paralogous gene groups among different organisms. KEGG maintains the GENES database for the gene catalogs of all organisms with complete genomes and selected organisms with partial genomes, which are continuously re-annotated, as well as the LIGAND database for chemical compounds and enzymes. Each gene catalog is associated with the graphical genome map for chromosomal locations that is represented by Java applet. In addition to the data collection efforts, KEGG develops and provides various computational tools, such as for reconstructing biochemical pathways from the complete genome sequence and for predicting gene regulatory networks from the gene expression profiles. The KEGG databases are daily updated and made freely available (http://www.genome.ad.jp/kegg/).","['KEGG', 'Genome', 'Biology', 'Gene', 'Encyclopedia', 'Computational biology', 'Genetics', 'Gene expression', 'Transcriptome', 'Computer science', 'Library science']","kyoto encyclopedia, ##gg, gene functions, ##gg, pathway database, graphical diagrams, biochemical pathways, metabolic, ##g, ##gg, genes database, gene, partial genomes, ligand database, graphical genome map, java, kegg, gene, gene, ##gg"
Paper_00160,Histograms of Oriented Gradients for Human Detection,"['Navneet Dalal', 'Bill Triggs']",2005,Unknown,Unknown,,886-893,1,,10.1109/cvpr.2005.177,"We study the question of feature sets for robust visual object recognition; adopting linear SVM based human detection as a test case. After reviewing existing edge and gradient based descriptors, we show experimentally that grids of histograms of oriented gradient (HOG) descriptors significantly outperform existing feature sets for human detection. We study the influence of each stage of the computation on performance, concluding that fine-scale gradients, fine orientation binning, relatively coarse spatial binning, and high-quality local contrast normalization in overlapping descriptor blocks are all important for good results. The new approach gives near-perfect separation on the original MIT pedestrian database, so we introduce a more challenging dataset containing over 1800 annotated human images with a large range of pose variations and backgrounds.","['Histogram', 'Computer science', 'Artificial intelligence', 'Pattern recognition (psychology)', 'Image (mathematics)']","feature sets, robust visual object recognition, linear svm, ##to, oriented gradient, human detection, fine orientation binning, relatively, overlapping descriptor blocks, mit pedestrian database, pose variations"
Paper_00161,Development and validation of brief measures of positive and negative affect: The PANAS scales.,"['David Watson', 'L A Clark', 'Auke Tellegen']",1988,Journal of Personality and Social Psychology,Journal,,1063-1070,54,6,10.1037//0022-3514.54.6.1063,"In recent studies of the structure of affect, positive and negative affect have consistently emerged as two dominant and relatively independent dimensions. A number of mood scales have been created to measure these factors; however, many existing measures are inadequate, showing low reliability or poor convergent or discriminant validity. To fill the need for reliable and valid Positive Affect and Negative Affect scales that are also brief and easy to administer, we developed two 10-item mood scales that comprise the Positive and Negative Affect Schedule (PANAS). The scales are shown to be highly internally consistent, largely uncorrelated, and stable at appropriate levels over a 2-month time period. Normative data and factorial and external evidence of convergent and discriminant validity for the scales are also presented.","['Psychology', 'Discriminant validity', 'Affect (linguistics)', 'Mood', 'Social psychology', 'Test validity', 'Uncorrelated', 'Convergent validity', 'Normative', 'Psychometrics', 'Factorial', 'Developmental psychology', 'Statistics', 'Internal consistency', 'Mathematics', 'Communication', 'Philosophy', 'Epistemology', 'Mathematical analysis']","affect, negative affect, mood scales, negative, negative affect schedule, ##tive data"
Paper_00162,PD-1 and PD-L1 Immune Checkpoint Blockade to Treat Breast Cancer,"['Andreas D. Hartkopf', 'Florin‐Andrei Taran', 'Markus Wallwiener', 'Christina B. Walter', 'Bernhard Krämer', 'Eva‐Maria Grischke', 'Sara Y. Brucker']",2016,Breast Care,Journal,,385-390,11,6,10.1159/000453569,"Immune checkpoint inhibition represents a major recent breakthrough in the treatment of malignant diseases including breast cancer. Blocking the programmed death receptor-1 (PD-1) and its ligand, PD-L1, has shown impressive antitumor activity and may lead to durable long-term disease control, especially in the triple-negative subtypes of breast cancer (TNBC). Although immune checkpoint blockade is generally well tolerated, specific immune-related adverse events (irAEs) may occur. This review summarizes the clinical efficacy, perspectives, and future challenges of using PD-1/PD-L1-directed antibodies in the treatment of breast cancer.","['Blockade', 'Medicine', 'Breast cancer', 'Immune checkpoint', 'Oncology', 'PD-L1', 'Internal medicine', 'Cancer', 'Immune system', 'Immunotherapy', 'Immunology', 'Receptor']","immune checkpoint inhibition, mali, breast cancer, programmed death receptor, antitumor, breast cancer, immune checkpoint blockade, breast cancer"
Paper_00163,Matplotlib: A 2D Graphics Environment,['John D. Hunter'],2007,Computing in Science & Engineering,Journal,,90-95,9,3,10.1109/mcse.2007.55,"Matplotlib is a 2D graphics package used for Python for application development, interactive scripting,and publication-quality image generation across user interfaces and operating systems","['Computer science', 'Graphics', 'Computer graphics (images)', 'Computer graphics']","matplotlib, 2d graphics package, python, application development, interactive scripting, [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD], [PAD], [PAD] [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"
Paper_00166,Multiwfn: A multifunctional wavefunction analyzer,"['Tian Lu', 'Feiwu Chen']",2011,Journal of Computational Chemistry,Journal,,580-592,33,5,10.1002/jcc.22885,"Multiwfn is a multifunctional program for wavefunction analysis. Its main functions are: (1) Calculating and visualizing real space function, such as electrostatic potential and electron localization function at point, in a line, in a plane or in a spatial scope. (2) Population analysis. (3) Bond order analysis. (4) Orbital composition analysis. (5) Plot density-of-states and spectrum. (6) Topology analysis for electron density. Some other useful utilities involved in quantum chemistry studies are also provided. The built-in graph module enables the results of wavefunction analysis to be plotted directly or exported to high-quality graphic file. The program interface is very user-friendly and suitable for both research and teaching purpose. The code of Multiwfn is substantially optimized and parallelized. Its efficiency is demonstrated to be significantly higher than related programs with the same functions. Five practical examples involving a wide variety of systems and analysis methods are given to illustrate the usefulness of Multiwfn. The program is free of charge and open-source. Its precompiled file and source codes are available from http://multiwfn.codeplex.com.","['Wave function', 'Computer science', 'Graph', 'Computational science', 'Theoretical computer science', 'Physics', 'Quantum mechanics']","multiwfn, multifunctional program, wavefunction analysis, real space, electrostatic potential, electron localization function, population analysis, bond order analysis, orbital composition analysis, topology analysis, electron density, quantum chemistry studies, wavefunction analysis, multiwfn, multiwfn, multiwf"
Paper_00167,Gaussian basis sets for use in correlated molecular calculations. I. The atoms boron through neon and hydrogen,['Thom H. Dunning'],1989,The Journal of Chemical Physics,Journal,,1007-1023,90,2,10.1063/1.456153,"In the past, basis sets for use in correlated molecular calculations have largely been taken from single configuration calculations. Recently, Almlöf, Taylor, and co-workers have found that basis sets of natural orbitals derived from correlated atomic calculations (ANOs) provide an excellent description of molecular correlation effects. We report here a careful study of correlation effects in the oxygen atom, establishing that compact sets of primitive Gaussian functions effectively and efficiently describe correlation effects if the exponents of the functions are optimized in atomic correlated calculations, although the primitive (sp) functions for describing correlation effects can be taken from atomic Hartree–Fock calculations if the appropriate primitive set is used. Test calculations on oxygen-containing molecules indicate that these primitive basis sets describe molecular correlation effects as well as the ANO sets of Almlöf and Taylor. Guided by the calculations on oxygen, basis sets for use in correlated atomic and molecular calculations were developed for all of the first row atoms from boron through neon and for hydrogen. As in the oxygen atom calculations, it was found that the incremental energy lowerings due to the addition of correlating functions fall into distinct groups. This leads to the concept of correlation consistent basis sets, i.e., sets which include all functions in a given group as well as all functions in any higher groups. Correlation consistent sets are given for all of the atoms considered. The most accurate sets determined in this way, [5s4p3d2f1g], consistently yield 99% of the correlation energy obtained with the corresponding ANO sets, even though the latter contains 50% more primitive functions and twice as many primitive polarization functions. It is estimated that this set yields 94%–97% of the total (HF+1+2) correlation energy for the atoms neon through boron.","['Neon', 'Basis set', 'Basis (linear algebra)', 'STO-nG basis sets', 'Gaussian', 'Molecular orbital', 'Atom (system on chip)', 'Chemistry', 'Atomic orbital', 'Electronic correlation', 'Atomic physics', 'Basis function', 'Correlation', 'Molecule', 'Computational chemistry', 'Physics', 'Quantum mechanics', 'Mathematics', 'Linear combination of atomic orbitals', 'Density functional theory', 'Argon', 'Geometry', 'Computer science', 'Embedded system', 'Electron']","basis sets, correlated molecular calculations, single configuration calculations, natural orbitals, correlated atomic calculations, an, molecular correlation effects, correlation effects, oxygen atom, primitive gaussian functions, correlation, atomic correlated calculations, correlation, atomic hartree – fock, molecular correlation effects, an, oxygen atom calculations, ##ental energy lowerings, correlation consistent basis sets, correlation consistent sets, primitive polarization functions, correlation"
Paper_00169,Basics of Qualitative Research: Grounded Theory Procedures and Techniques.,"['Carolyn Ellis', 'Anselm Strauss', 'Juliet Corbin']",1992,Contemporary Sociology A Journal of Reviews,Journal,,138-138,21,1,10.2307/2074814,"Introduction Getting Started Theoretical Sensitivity The Uses of Literature Open Coding Techniques for Enhancing Theoretical Sensitivity Axial Coding Selective Coding Process The Conditional Matrix Theoretical Sampling Memos and Diagrams Writing Theses and Monographs, and Giving Talks about Your Research Criteria for Judging a Grounded Theory Study","['Grounded theory', 'Qualitative research', 'Computer science', 'Sociology', 'Social science']","theoretical sensitivity, open coding techniques, axial coding selective coding process, conditional matrix theoretical sampling, diagrams, grounded"
Paper_00170,An Algorithm for Least-Squares Estimation of Nonlinear Parameters,['Donald W. Marquardt'],1963,Journal of the Society for Industrial and Applied Mathematics,Journal,,431-441,11,2,10.1137/0111030,"Previous article Next article An Algorithm for Least-Squares Estimation of Nonlinear ParametersDonald W. MarquardtDonald W. Marquardthttps://doi.org/10.1137/0111030PDFPDF PLUSBibTexSections ToolsAdd to favoritesExport CitationTrack CitationsEmail SectionsAbout[1] G. W. Booth, , G. E. P. Box, , M. E. Muller and , T. I. Peterson, Forecasting by Generalized Regression Methods, Nonlinear Estimation (Princeton—IBM), Mimeo. (IBM Share Program No. 687 WL NL1), International Business Machines Corp., 1959 Google Scholar[2] G. E. P. Box and , G. A. Coutie, Application of digital computers in the exploration of functional relationships, Proc. Inst. Elec. Engrs. B, 103 (1957), 100–107 MR0094906 Google Scholar[3] Haskell B. Curry, The method of steepest descent for non-linear minimization problems, Quart. Appl. Math., 2 (1944), 258–261 MR0010667 0061.26801 CrossrefGoogle Scholar[4] H. O. Hartley, The modified Gauss-Newton method for the fitting of non-linear regression functions by least squares, Technometrics, 3 (1961), 269–280 MR0124117 0096.34603 CrossrefISIGoogle Scholar[5] D. W. Marquardt, , Chem. Eng. Progr., 55 (1959), 65–70 Google Scholar[6] D. W. Marquardt, , R. G. Bennett and , E. J. Burrell, , Jour. Molec. Spectroscopy, 7 (1961), 269–279 10.1016/0022-2852(61)90360-5 CrossrefISIGoogle Scholar[7] D. D. Morrison, Methods for nonlinear least squares problems and convergence proofs, Tracking Programs and Orbit Determination, Proc. Jet Propulsion Laboratory Seminar, 1960, 1–9 Google Scholar[8] Kenneth Levenberg, A method for the solution of certain non-linear problems in least squares, Quart. Appl. Math., 2 (1944), 164–168 MR0010666 0063.03501 CrossrefGoogle Scholar Previous article Next article FiguresRelatedReferencesCited ByDetails Shadowing-Based Data Assimilation Method for Partially Observed ModelsBart M. de Leeuw and Svetlana DubinkinaSIAM Journal on Applied Dynamical Systems, Vol. 21, No. 2 | 11 April 2022AbstractPDF (2268 KB)Localized Sensitivity Analysis at High-Curvature Boundary Points of Reconstructing Inclusions in Transmission ProblemsHabib Ammari, Yat Tin Chow, and Hongyu LiuSIAM Journal on Mathematical Analysis, Vol. 54, No. 2 | 9 March 2022AbstractPDF (829 KB)A Stochastic Levenberg--Marquardt Method Using Random Models with Complexity ResultsEl Houcine Bergou, Youssef Diouane, Vyacheslav Kungurtsev, and Clément W. RoyerSIAM/ASA Journal on Uncertainty Quantification, Vol. 10, No. 1 | 29 March 2022AbstractPDF (616 KB)Derivative-Free Bayesian Inversion Using Multiscale DynamicsG. A. Pavliotis, A. M. Stuart, and U. VaesSIAM Journal on Applied Dynamical Systems, Vol. 21, No. 1 | 24 January 2022AbstractPDF (2356 KB)Convergence of Newton-MR under Inexact Hessian InformationYang Liu and Fred RoostaSIAM Journal on Optimization, Vol. 31, No. 1 | 7 January 2021AbstractPDF (3140 KB)A Nonmonotone Matrix-Free Algorithm for Nonlinear Equality-Constrained Least-Squares ProblemsEl Houcine Bergou, Youssef Diouane, Vyacheslav Kungurtsev, and Clément W. RoyerSIAM Journal on Scientific Computing, Vol. 43, No. 5 | 13 September 2021AbstractPDF (951 KB)Random Sampling from Joint Probability Distributions Defined in a Bayesian FrameworkThierry A. Mara, Marwan Fahs, Qian Shao, and Anis YounesSIAM Journal on Scientific Computing, Vol. 41, No. 1 | 15 January 2019AbstractPDF (5620 KB)On the Quadratic Convergence of the Cubic Regularization Method under a Local Error Bound ConditionMan-Chung Yue, Zirui Zhou, and Anthony Man-Cho SoSIAM Journal on Optimization, Vol. 29, No. 1 | 28 March 2019AbstractPDF (621 KB)The Conjugate Residual Method in Linesearch and Trust-Region MethodsMarie-Ange Dahito and Dominique OrbanSIAM Journal on Optimization, Vol. 29, No. 3 | 25 July 2019AbstractPDF (977 KB)Variable Projection Methods for an Optimized Dynamic Mode DecompositionTravis Askham and J. Nathan KutzSIAM Journal on Applied Dynamical Systems, Vol. 17, No. 1 | 1 February 2018AbstractPDF (1906 KB)A Duality-Based Optimization Approach for Model Adaptivity in Heterogeneous Multiscale ProblemsMatthias Maier and Rolf RannacherMultiscale Modeling & Simulation, Vol. 16, No. 1 | 1 March 2018AbstractPDF (4572 KB)Iterative Importance Sampling Algorithms for Parameter EstimationMatthias Morzfeld, Marcus S. Day, Ray W. Grout, George Shu Heng Pau, Stefan A. Finsterle, and John B. BellSIAM Journal on Scientific Computing, Vol. 40, No. 2 | 1 March 2018AbstractPDF (1644 KB)Newton Correction Methods for Computing Real Eigenpairs of Symmetric TensorsAriel Jaffe, Roi Weiss, and Boaz NadlerSIAM Journal on Matrix Analysis and Applications, Vol. 39, No. 3 | 3 July 2018AbstractPDF (1076 KB)Survey of Multifidelity Methods in Uncertainty Propagation, Inference, and OptimizationBenjamin Peherstorfer, Karen Willcox, and Max GunzburgerSIAM Review, Vol. 60, No. 3 | 8 August 2018AbstractPDF (825 KB)The Use of Quadratic Regularization with a Cubic Descent Condition for Unconstrained OptimizationE. G. Birgin and J. M. MartínezSIAM Journal on Optimization, Vol. 27, No. 2 | 6 June 2017AbstractPDF (586 KB)An ODE-Based Method for Computing the Distance of Coprime Polynomials to Common DivisibilityNicola Guglielmi and Ivan MarkovskySIAM Journal on Numerical Analysis, Vol. 55, No. 3 | 22 June 2017AbstractPDF (593 KB)Levenberg--Marquardt Methods Based on Probabilistic Gradient Models and Inexact Subproblem Solution, with Application to Data AssimilationSIAM/ASA Journal on Uncertainty Quantification, Vol. 4, No. 1 | 16 August 2016AbstractPDF (558 KB)Synchronization of Independently Moving Cameras via Motion RecoverySIAM Journal on Imaging Sciences, Vol. 9, No. 3 | 7 July 2016AbstractPDF (4822 KB)An Efficient Gauss--Newton Algorithm for Symmetric Low-Rank Product Matrix ApproximationsSIAM Journal on Optimization, Vol. 25, No. 3 | 6 August 2015AbstractPDF (521 KB)An Algebraic Solution for the Candecomp/PARAFAC Decomposition with Circulant FactorsSIAM Journal on Matrix Analysis and Applications, Vol. 35, No. 4 | 11 December 2014AbstractPDF (354 KB)Factorization Approach to Structured Low-Rank Approximation with ApplicationsSIAM Journal on Matrix Analysis and Applications, Vol. 35, No. 3 | 11 September 2014AbstractPDF (401 KB)Structured Low-Rank Approximation with Missing DataSIAM Journal on Matrix Analysis and Applications, Vol. 34, No. 2 | 27 June 2013AbstractPDF (255 KB)Rank-Deficient Nonlinear Least Squares Problems and Subset SelectionSIAM Journal on Numerical Analysis, Vol. 49, No. 3 | 23 June 2011AbstractPDF (267 KB)Computing Points that Satisfy Second Order Necessary Optimality Conditions for Unconstrained MinimizationSIAM Journal on Optimization, Vol. 20, No. 4 | 19 February 2010AbstractPDF (214 KB)On the Convergence of Recursive Trust-Region Methods for Multiscale Nonlinear Optimization and Applications to Nonlinear MechanicsSIAM Journal on Numerical Analysis, Vol. 47, No. 4 | 4 September 2009AbstractPDF (1673 KB)Relative Periodic Solutions of the Complex Ginzburg--Landau EquationSIAM Journal on Applied Dynamical Systems, Vol. 4, No. 4 | 7 August 2006AbstractPDF (871 KB)Linear versus Nonlinear Dimensionality Reduction of High-Dimensional Dynamical SystemsSIAM Journal on Scientific Computing, Vol. 25, No. 6 | 25 July 2006AbstractPDF (814 KB)Analyzing the Dynamics of Cellular Flames Using Karhunen--Loève Decomposition and Autoassociative Neural NetworksSIAM Journal on Scientific Computing, Vol. 24, No. 5 | 25 July 2006AbstractPDF (932 KB)An Elementary Model for Control of a Semiconductor Etching ProcessSIAM Review, Vol. 44, No. 4 | 4 August 2006AbstractPDF (1001 KB)A Global Convergence Theory for Dennis, El-Alem, and Maciel's Class of Trust-Region Algorithms for Constrained Optimization without Assuming RegularitySIAM Journal on Optimization, Vol. 9, No. 4 | 31 July 2006AbstractPDF (426 KB)A Trust-Region Approach to Nonlinear Systems of Equalities and InequalitiesSIAM Journal on Optimization, Vol. 9, No. 2 | 31 July 2006AbstractPDF (436 KB)Convergence Properties of Minimization Algorithms for Convex Constraints Using a Structured Trust RegionSIAM Journal on Optimization, Vol. 6, No. 4 | 31 July 2006AbstractPDF (3077 KB)Restricted Step and Levenberg–Marquardt Techniques in Proximal Bundle Methods for Nonconvex Nondifferentiable OptimizationSIAM Journal on Optimization, Vol. 6, No. 1 | 31 July 2006AbstractPDF (2829 KB)A Parallel Nonlinear Least-Squares Solver: Theoretical Analysis and Numerical ResultsSIAM Journal on Scientific and Statistical Computing, Vol. 13, No. 3 | 13 July 2006AbstractPDF (2479 KB)The Early Use of Matrix Diagonal Increments in Statistical ProblemsSIAM Review, Vol. 31, No. 3 | 18 July 2006AbstractPDF (937 KB)Nonstandard Scaling Matrices for Trust Region Gauss–Newton MethodsSIAM Journal on Scientific and Statistical Computing, Vol. 10, No. 4 | 13 July 2006AbstractPDF (1559 KB)A Continuation Approach for Solving Large-Residual Nonlinear Least Squares ProblemsSIAM Journal on Scientific and Statistical Computing, Vol. 8, No. 4 | 14 July 2006AbstractPDF (1744 KB)The Use of Linear Programming for the Solution of Sparse Sets of Nonlinear EquationsSIAM Journal on Scientific and Statistical Computing, Vol. 8, No. 2 | 14 July 2006AbstractPDF (1172 KB)Newton’s Method with a Model Trust Region ModificationSIAM Journal on Numerical Analysis, Vol. 19, No. 2 | 17 July 2006AbstractPDF (2105 KB)Computing Optimal Locally Constrained StepsSIAM Journal on Scientific and Statistical Computing, Vol. 2, No. 2 | 16 May 2012AbstractPDF (1401 KB)Robust Methods for Solving Systems of Nonlinear EquationsSIAM Journal on Scientific and Statistical Computing, Vol. 1, No. 1 | 16 May 2012AbstractPDF (1004 KB)Some Problems in the Control of Distributed Systems, and Their Numerical SolutionSIAM Journal on Control and Optimization, Vol. 17, No. 1 | 18 July 2006AbstractPDF (1597 KB)Minimum Principles for Ill-Posed ProblemsSIAM Journal on Mathematical Analysis, Vol. 9, No. 4 | 17 February 2012AbstractPDF (937 KB)Approximation to Data by Splines with Free KnotsSIAM Journal on Numerical Analysis, Vol. 15, No. 2 | 14 July 2006AbstractPDF (1543 KB)Dynamic Optimal Control Models in Advertising: a SurveySIAM Review, Vol. 19, No. 4 | 17 February 2012AbstractPDF (4271 KB)Use of Smoothing and Damping Techniques in the Solution of Nonlinear EquationsSIAM Review, Vol. 19, No. 1 | 18 July 2006AbstractPDF (1086 KB)Nonlinear Mean-Square Approximation of Finite SetsSIAM Journal on Numerical Analysis, Vol. 12, No. 1 | 14 July 2006AbstractPDF (522 KB)Complex Linear Least SquaresSIAM Review, Vol. 15, No. 4 | 18 July 2006AbstractPDF (2012 KB)Multivariate Splines with Nondegenerate PartitionsSIAM Journal on Numerical Analysis, Vol. 10, No. 4 | 14 July 2006AbstractPDF (836 KB)Parameter Selection for Modified Newton Methods for Function MinimizationSIAM Journal on Numerical Analysis, Vol. 7, No. 3 | 14 July 2006AbstractPDF (692 KB)Comparison of Gradient Methods for the Solution of Nonlinear Parameter Estimation ProblemsSIAM Journal on Numerical Analysis, Vol. 7, No. 1 | 14 July 2006AbstractPDF (2230 KB)An Accelerated Gradient Projection Method for Linearly Constrained Nonlinear EstimationSIAM Journal on Applied Mathematics, Vol. 18, No. 2 | 1 August 2006AbstractPDF (1092 KB)A Survey of Numerical Methods for Unconstrained OptimizationSIAM Review, Vol. 12, No. 1 | 18 July 2006AbstractPDF (2399 KB)On a Theorem Used in Nonlinear Least SquaresSIAM Journal on Applied Mathematics, Vol. 14, No. 5 | 13 July 2006AbstractPDF (312 KB)On the Stationary Values of a Second-Degree Polynomial on the Unit SphereJournal of the Society for Industrial and Applied Mathematics, Vol. 13, No. 4 | 13 July 2006AbstractPDF (1358 KB) Volume 11, Issue 2| 1963Journal of the Society for Industrial and Applied Mathematics205-519 History Submitted:13 June 1962Published online:13 July 2006 InformationCopyright © 1963 Society for Industrial and Applied MathematicsPDF Download Article & Publication DataArticle DOI:10.1137/0111030Article page range:pp. 431-441ISSN (print):0368-4245ISSN (online):2168-3484Publisher:Society for Industrial and Applied Mathematics","['Non-linear least squares', 'Algorithm', 'Least-squares function approximation', 'Estimation', 'Nonlinear system', 'Computer science', 'Mathematics', 'Estimation theory', 'Statistics', 'Engineering', 'Physics', 'Systems engineering', 'Quantum mechanics', 'Estimator']","nonlinear parameters, generalized regression methods, nonlinear estimation, international business machines corp, digital computers, functional relationships, steepest descent, linear, non - linear regression functions, least, techno, cross, nonlinear least squares problems, convergence proofs, tracking programs, orbit determination, jet propulsion laboratory, - linear problems, least squares"
Paper_00171,Data mining: concepts and techniques,"['Jiawei Han', 'Micheline Kamber', 'Jian Pei']",2012,Choice Reviews Online,Journal,,49-3305,49,06,10.5860/choice.49-3305,"The increasing volume of data in modern business and science calls for more complex and sophisticated tools. Although advances in data mining technology have made extensive data collection much easier, it's still always evolving and there is a constant need for new techniques and tools that can help us transform this data into useful information and knowledge. Since the previous edition's publication, great advances have been made in the field of data mining. Not only does the third of edition of Data Mining: Concepts and Techniques continue the tradition of equipping you with an understanding and application of the theory and practice of discovering patterns hidden in large data sets, it also focuses on new, important topics in the field: data warehouses and data cube technology, mining stream, mining social networks, and mining spatial, multimedia and other complex data. Each chapter is a stand-alone guide to a critical topic, presenting proven algorithms and sound implementations ready to be used directly or with strategic modification against live data. This is the resource you need if you want to apply today's most powerful data mining techniques to meet real business challenges. * Presents dozens of algorithms and implementation examples, all in pseudo-code and suitable for use in real-world, large-scale data mining projects. * Addresses advanced topics such as mining object-relational databases, spatial databases, multimedia databases, time-series databases, text databases, the World Wide Web, and applications in several fields. *Provides a comprehensive, practical look at the concepts and techniques you need to get the most out of real business data","['Computer science', 'Data science', 'Data mining']","data mining, data mining, data mining, data warehouses, data cube technology, mining stream, mining social networks, mining spatial, spatial databases, multimedia databases, text databases, [PAD] [PAD], [PAD], [PAD]"
Paper_00172,Highly accurate protein structure prediction with AlphaFold,"['John Jumper', 'Richard Evans', 'Alexander Pritzel', 'Tim Green', 'Michael Figurnov', 'Olaf Ronneberger', 'Kathryn Tunyasuvunakool', 'Russ Bates', 'Augustin Žídek', 'Anna Potapenko', 'Alex Bridgland', 'Clemens Meyer', 'Simon Kohl', 'Andrew J. Ballard', 'Andrew Cowie', 'Bernardino Romera‐Paredes', 'Stanislav Nikolov', 'Rishub Jain', 'Jonas Adler', 'Trevor Back', 'Stig Petersen', 'David Reiman', 'Ellen Clancy', 'Michał Zieliński', 'Martin Steinegger', 'Michalina Pacholska', 'Tamas Berghammer', 'Sebastian W. Bodenstein', 'David Silver', 'Oriol Vinyals', 'Andrew Senior', 'Koray Kavukcuoglu', 'Pushmeet Kohli', 'Demis Hassabis']",2021,Nature,Journal,,583-589,596,7873,10.1038/s41586-021-03819-2,"Abstract Proteins are essential to life, and understanding their structure can facilitate a mechanistic understanding of their function. Through an enormous experimental effort 1–4 , the structures of around 100,000 unique proteins have been determined 5 , but this represents a small fraction of the billions of known protein sequences 6,7 . Structural coverage is bottlenecked by the months to years of painstaking effort required to determine a single protein structure. Accurate computational approaches are needed to address this gap and to enable large-scale structural bioinformatics. Predicting the three-dimensional structure that a protein will adopt based solely on its amino acid sequence—the structure prediction component of the ‘protein folding problem’ 8 —has been an important open research problem for more than 50 years 9 . Despite recent progress 10–14 , existing methods fall far short of atomic accuracy, especially when no homologous structure is available. Here we provide the first computational method that can regularly predict protein structures with atomic accuracy even in cases in which no similar structure is known. We validated an entirely redesigned version of our neural network-based model, AlphaFold, in the challenging 14th Critical Assessment of protein Structure Prediction (CASP14) 15 , demonstrating accuracy competitive with experimental structures in a majority of cases and greatly outperforming other methods. Underpinning the latest version of AlphaFold is a novel machine learning approach that incorporates physical and biological knowledge about protein structure, leveraging multi-sequence alignments, into the design of the deep learning algorithm.","['Protein structure prediction', 'Computer science', 'CASP', 'Protein structure', 'Threading (protein sequence)', 'Artificial intelligence', 'Machine learning', 'Structural bioinformatics', 'Artificial neural network', 'Protein superfamily', 'Sequence (biology)', 'Function (biology)', 'Computational biology', 'Biology', 'Biochemistry', 'Genetics', 'Evolutionary biology', 'Gene']","structure prediction, protein folding problem, alphafold, protein structure prediction, ##fold, machine learning, deep learning algorithm"
Paper_00173,<i>Coot</i>: model-building tools for molecular graphics,"['Paul Emsley', 'Kevin Cowtan']",2004,Acta Crystallographica Section D Biological Crystallography,Journal,,2126-2132,60,12,10.1107/s0907444904019158,"CCP4mg is a project that aims to provide a general-purpose tool for structural biologists, providing tools for X-ray structure solution, structure comparison and analysis, and publication-quality graphics. The map-fitting tools are available as a stand-alone package, distributed as 'Coot'.","['Graphics', 'R package', 'Computer science', 'Computer graphics (images)', 'Molecular graphics', 'Computer graphics', 'Computational science']","ccp, ##mg, structural biologists, structure comparison, coot, [PAD] [PAD] [PAD], [PAD] [PAD], [PAD] [PAD] [PAD]"
Paper_00174,RAxML version 8: a tool for phylogenetic analysis and post-analysis of large phylogenies,['Alexandros Stamatakis'],2014,Bioinformatics,Journal,,1312-1313,30,9,10.1093/bioinformatics/btu033,"Abstract Motivation: Phylogenies are increasingly used in all fields of medical and biological research. Moreover, because of the next-generation sequencing revolution, datasets used for conducting phylogenetic analyses grow at an unprecedented pace. RAxML (Randomized Axelerated Maximum Likelihood) is a popular program for phylogenetic analyses of large datasets under maximum likelihood. Since the last RAxML paper in 2006, it has been continuously maintained and extended to accommodate the increasingly growing input datasets and to serve the needs of the user community. Results: I present some of the most notable new features and extensions of RAxML, such as a substantial extension of substitution models and supported data types, the introduction of SSE3, AVX and AVX2 vector intrinsics, techniques for reducing the memory requirements of the code and a plethora of operations for conducting post-analyses on sets of trees. In addition, an up-to-date 50-page user manual covering all new RAxML options is available. Availability and implementation: The code is available under GNU GPL at https://github.com/stamatak/standard-RAxML. Contact: alexandros.stamatakis@h-its.org Supplementary information: Supplementary data are available at Bioinformatics online.","['Phylogenetic tree', 'Computer science', 'Intrinsics', 'Pace', 'Maximum likelihood', 'Biology', 'Artificial intelligence', 'Geography', 'Statistics', 'Mathematics', 'Biochemistry', 'Geodesy', 'Gene']","abstract motivation, phylogenies, biological research, phylogenetic analyses, raxml, randomized axelerated maximum likelihood, phylogenetic analyses, maximum likelihood, raxml, substitution models, sse3, avx, avx2 vector intrinsics, memory requirements, rax, bioinformatics"
Paper_00175,"AutoDock Vina: Improving the speed and accuracy of docking with a new scoring function, efficient optimization, and multithreading","['Oleg Trott', 'Arthur J. Olson']",2009,Journal of Computational Chemistry,Journal,,455-461,31,2,10.1002/jcc.21334,"AutoDock Vina, a new program for molecular docking and virtual screening, is presented. AutoDock Vina achieves an approximately two orders of magnitude speed-up compared with the molecular docking software previously developed in our lab (AutoDock 4), while also significantly improving the accuracy of the binding mode predictions, judging by our tests on the training set used in AutoDock 4 development. Further speed-up is achieved from parallelism, by using multithreading on multicore machines. AutoDock Vina automatically calculates the grid maps and clusters the results in a way transparent to the user. © 2009 Wiley Periodicals, Inc. J Comput Chem 2010","['AutoDock', 'Multithreading', 'Computer science', 'Parallel computing', 'Grid', 'Software', 'Docking (animal)', 'Operating system', 'Mathematics', 'Chemistry', 'Thread (computing)', 'Medicine', 'Biochemistry', 'Geometry', 'Nursing', 'In silico', 'Gene']","autodock vin, molecular docking, virtual screening, autodock vina, molecular docking, autodock, binding mode predictions, training, autodock, parallelism, multithreading, multicore machines, autodock vin, grid maps, wiley, [PAD] [PAD], [PAD], [PAD] [PAD], [PAD], [PAD], [PAD], [PAD] [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD] [PAD] [PAD], [PAD] [PAD] [PAD]"
Paper_00179,The Pricing of Options and Corporate Liabilities,"['Fischer Black', 'Myron S. Scholes']",1973,Journal of Political Economy,Journal,,637-654,81,3,10.1086/260062,"If options are correctly priced in the market, it should not be possible to make sure profits by creating portfolios of long and short positions in options and their underlying stocks. Using this principle, a theoretical valuation formula for options is derived. Since almost all corporate liabilities can be viewed as combinations of options, the formula and the analysis that led to it are also applicable to corporate liabilities such as common stock, corporate bonds, and warrants. In particular, the formula can be used to derive the discount that should be applied to a corporate bond because of the possibility of default.","['Business', 'Economics', 'Financial economics', 'Actuarial science']","theoretical valuation formula, options, corporate liabilities, corporate liabilities, common stock, corporate bonds, warrants, corporate bond, [PAD] [PAD], [PAD], [PAD]"
Paper_00180,MEGA4: Molecular Evolutionary Genetics Analysis (MEGA) Software Version 4.0,"['Koichiro Tamura', 'Joel T. Dudley', 'M Nei', 'Sudhir Kumar']",2007,Molecular Biology and Evolution,Journal,,1596-1599,24,8,10.1093/molbev/msm092,"We announce the release of the fourth version of MEGA software, which expands on the existing facilities for editing DNA sequence data from autosequencers, mining Web-databases, performing automatic and manual sequence alignment, analyzing sequence alignments to estimate evolutionary distances, inferring phylogenetic trees, and testing evolutionary hypotheses. Version 4 includes a unique facility to generate captions, written in figure legend format, in order to provide natural language descriptions of the models and methods used in the analyses. This facility aims to promote a better understanding of the underlying assumptions used in analyses, and of the results generated. Another new feature is the Maximum Composite Likelihood (MCL) method for estimating evolutionary distances between all pairs of sequences simultaneously, with and without incorporating rate variation among sites and substitution pattern heterogeneities among lineages. This MCL method also can be used to estimate transition/transversion bias and nucleotide substitution pattern without knowledge of the phylogenetic tree. This new version is a native 32-bit Windows application with multi-threading and multi-user supports, and it is also available to run in a Linux desktop environment (via the Wine compatibility layer) and on Intel-based Macintosh computers under the Parallels program. The current version of MEGA is available free of charge at http://www.megasoftware.net.","['Mega-', 'Phylogenetic tree', 'Biology', 'Transversion', 'Software', 'Substitution (logic)', 'Computer science', 'Genetics', 'Programming language', 'Mutation', 'Gene', 'Physics', 'Astronomy']","mega, dna sequence data, autosequencers, sequence alignments, evolutionary distances, phylogenetic trees, evolutionary hypotheses, ##ions, figure legend, maximum composite likelihood, mc, evolutionary distances, rate variation, substitution pattern heterogeneities, nucleotide substitution pattern, phylogenetic, linux, wine, parallels, mega, megasoft"
Paper_00182,"Magnesium Replacement Improves the Metabolic Profile in Obese and Pre-Diabetic Patients with Mild-to-Moderate Chronic Kidney Disease: A 3-Month, Randomised, Double-Blind, Placebo-Controlled Study","['Ömer Toprak', 'Hüseyin Kurt', 'Yasin Sarı', 'Cihat Şarkış', 'Halil Us', 'Ali Kırık']",2017,Kidney & Blood Pressure Research,Journal,,33-42,42,1,10.1159/000468530,"Epidemiological studies have associated low dietary Mg2+ intake with insulin resistance (IR) and increased risk for metabolic syndrome; however, the effect of Mg2+ supplementation on IR has not been adequately investigated. This study aimed to investigate the effects of oral Mg2+ supplementation on insulin sensitivity (IS) and serum lipids.<br />Forty-eight patients with mild uncomplicated hypertension participated in the study. Among them, 24 subjects were assigned to 600 mg of pidolate Mg2+ daily in addition to lifestyle recommendations for a 12-week period, and another 24 age- and sex-matched controls were only given lifestyle recommendations. At baseline and study-end, blood sampling for determination of fasting glucose and insulin levels, serum lipids and other standard laboratory tests, as well as an oral glucose tolerance test (OGTT) for estimation of IS indices, were performed in all subjects.<br />In the Mg2+ supplementation group the OGTT-derived IS indices of Stumvoll, Matsuda and Cedercholm in were increased between baseline baseline and study-end. In contrast, none of these parameters were changed in the control group. Reductions in total cholesterol, LDL-cholesterol and triglyceride levels, along with a parallel increase in HDL-cholesterol levels, were evident at study-end in the intervention group, but not in the control group.<br />This study suggests that oral Mg2+ supplementation improves IS and lipid profile in mildly hypertensive patients. These potential beneficial effects of Mg2+ on associated metabolic factors could be helpful for patients with hypertension in terms of overall cardiovascular risk reduction.","['Medicine', 'Internal medicine', 'Triglyceride', 'Placebo', 'Insulin resistance', 'Lipid profile', 'Endocrinology', 'Metabolic syndrome', 'Cholesterol', 'Diabetes mellitus', 'Insulin', 'Kidney disease', 'Blood lipids', 'Gastroenterology', 'Obesity', 'Alternative medicine', 'Pathology']","epidemi, insulin resistance, metabolic syndrome, serum lipids, blood sampling, serum lipids, oral glucose tolerance test, og, ##m, lip, mildly hypertensive patients, cardiovascular risk"
Paper_00183,A New Approach to Linear Filtering and Prediction Problems,['R. E. Kalman'],1960,Journal of Basic Engineering,Journal,,35-45,82,1,10.1115/1.3662552,"The classical filtering and prediction problem is re-examined using the Bode-Shannon representation of random processes and the “state-transition” method of analysis of dynamic systems. New results are: (1) The formulation and methods of solution of the problem apply without modification to stationary and nonstationary statistics and to growing-memory and infinite-memory filters. (2) A nonlinear difference (or differential) equation is derived for the covariance matrix of the optimal estimation error. From the solution of this equation the co-efficients of the difference (or differential) equation of the optimal linear filter are obtained without further calculations. (3) The filtering problem is shown to be the dual of the noise-free regulator problem. The new method developed here is applied to two well-known problems, confirming and extending earlier results. The discussion is largely self-contained and proceeds from first principles; basic concepts of the theory of random processes are reviewed in the Appendix.","['Mathematics', 'Applied mathematics', 'Covariance', 'Filter (signal processing)', 'Representation (politics)', 'Filtering problem', 'Nonlinear system', 'Linear filter', 'Differential equation', 'Noise (video)', 'Partial differential equation', 'Covariance matrix', 'Linear system', 'Kalman filter', 'Mathematical optimization', 'Computer science', 'Algorithm', 'Mathematical analysis', 'Statistics', 'Artificial intelligence', 'Physics', 'Quantum mechanics', 'Politics', 'Political science', 'Extended Kalman filter', 'Law', 'Image (mathematics)', 'Computer vision']","classical filtering, prediction problem, random processes, dynamic systems, nonstationary statistics, nonlinear difference, covariance matrix, optimal estimation error, optimal linear filter, filtering, random processes, [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD] [PAD], [PAD] [PAD], [PAD] [PAD], [PAD] [PAD] [PAD] [PAD]"
Paper_00184,"Communities of Practice: Learning, Meaning, and Identity",['Étienne Wenger'],1998,['Australian Journal of Education'],Unknown,,195-198,44,2,10.1177/000494410004400207,"This book presents a theory of learning that starts with the assumption that engagement in social practice is the fundamental process by which we get to know what we know and by which we become who we are. The primary unit of analysis of this process is neither the individual nor social institutions, but the informal 'communities of practice' that people form as they pursue shared enterprises over time. To give a social account of learning, the theory explores in a systematic way the intersection of issues of community, social practice, meaning, and identity. The result is a broad framework for thinking about learning as a process of social participation. This ambitious but thoroughly accessible framework has relevance for the practitioner as well as the theoretician, presented with all the breadth, depth, and rigor necessary to address such a complex and yet profoundly human topic.","['Meaning (existential)', 'Identity (music)', 'Process (computing)', 'Relevance (law)', 'Intersection (aeronautics)', 'Epistemology', 'Sociology', 'Social practice', 'Political science', 'Computer science', 'Aesthetics', 'Engineering', 'Art', 'Philosophy', 'Performance art', 'Law', 'Art history', 'Aerospace engineering', 'Operating system']","learning, social practice, social institutions, community, social practice, meaning, social participation"
Paper_00185,Clinical Characteristics of Coronavirus Disease 2019 in China,"['Wei‐jie Guan', 'Zhengyi Ni', 'Yu Hu', 'Wenhua Liang', 'Chun‐Quan Ou', 'Jianxing He', 'Lei Liu', 'Hong Shan', 'Chunliang Lei', 'David S.C. Hui', 'Bin Du', 'Lanjuan Li', 'Guang Zeng', 'Kwok‐Yung Yuen', 'Ruchong Chen', 'Chunli Tang', 'Tao Wang', 'Pingyan Chen', 'Jie Xiang', 'Shiyue Li', 'Jinlin Wang', 'Zijing Liang', 'Yixiang Peng', 'Wei Li', 'Yong Liu', 'Yahua Hu', 'Peng Peng', 'Jianming Wang', 'Jiyang Liu', 'Zhong Chen', 'Gang Li', 'Zhijian Zheng', 'Shaoqin Qiu', 'Jie Luo', 'Chang-jiang Ye', 'Shaoyong Zhu', 'Nanshan Zhong']",2020,New England Journal of Medicine,Journal,,1708-1720,382,18,10.1056/nejmoa2002032,"BackgroundSince December 2019, when coronavirus disease 2019 (Covid-19) emerged in Wuhan city and rapidly spread throughout China, data have been needed on the clinical characteristics of the affected patients.MethodsWe extracted data regarding 1099 patients with laboratory-confirmed Covid-19 from 552 hospitals in 30 provinces, autonomous regions, and municipalities in mainland China through January 29, 2020. The primary composite end point was admission to an intensive care unit (ICU), the use of mechanical ventilation, or death.ResultsThe median age of the patients was 47 years; 41.9% of the patients were female. The primary composite end point occurred in 67 patients (6.1%), including 5.0% who were admitted to the ICU, 2.3% who underwent invasive mechanical ventilation, and 1.4% who died. Only 1.9% of the patients had a history of direct contact with wildlife. Among nonresidents of Wuhan, 72.3% had contact with residents of Wuhan, including 31.3% who had visited the city. The most common symptoms were fever (43.8% on admission and 88.7% during hospitalization) and cough (67.8%). Diarrhea was uncommon (3.8%). The median incubation period was 4 days (interquartile range, 2 to 7). On admission, ground-glass opacity was the most common radiologic finding on chest computed tomography (CT) (56.4%). No radiographic or CT abnormality was found in 157 of 877 patients (17.9%) with nonsevere disease and in 5 of 173 patients (2.9%) with severe disease. Lymphocytopenia was present in 83.2% of the patients on admission.ConclusionsDuring the first 2 months of the current outbreak, Covid-19 spread rapidly throughout China and caused varying degrees of illness. Patients often presented without fever, and many did not have abnormal radiologic findings. (Funded by the National Health Commission of China and others.) Quick Take Clinical Characteristics of Covid-19 2m 8s","['Medicine', 'Interquartile range', 'Lymphocytopenia', 'Intensive care unit', 'Mechanical ventilation', 'Pneumonia', 'Contact tracing', 'Disease', 'Internal medicine', 'Coronavirus disease 2019 (COVID-19)', 'Pediatrics', 'Emergency medicine', 'Infectious disease (medical specialty)', 'Lymphocyte']","coronavirus disease, co, mechanical ventilation, invasive mechanical ventilation, ##rrhea, chest computed tomography, nonsevere, lymphocytopenia, co"
Paper_00187,"A Novel Coronavirus from Patients with Pneumonia in China, 2019","['Na Zhu', 'Dingyu Zhang', 'Wen‐Ching Wang', 'Xingwang Li', 'Bo Yang', 'Jingdong Song', 'Xiang Zhao', 'Baoying Huang', 'Weifeng Shi', 'Roujian Lu', 'Peihua Niu', 'Faxian Zhan', 'Xuejun Ma', 'Dayan Wang', 'Wenbo Xu', 'Guizhen Wu', 'George F. Gao', 'Wenjie Tan']",2020,New England Journal of Medicine,Journal,,727-733,382,8,10.1056/nejmoa2001017,"In December 2019, a cluster of patients with pneumonia of unknown cause was linked to a seafood wholesale market in Wuhan, China. A previously unknown betacoronavirus was discovered through the use of unbiased sequencing in samples from patients with pneumonia. Human airway epithelial cells were used to isolate a novel coronavirus, named 2019-nCoV, which formed a clade within the subgenus sarbecovirus, Orthocoronavirinae subfamily. Different from both MERS-CoV and SARS-CoV, 2019-nCoV is the seventh member of the family of coronaviruses that infect humans. Enhanced surveillance and further investigation are ongoing. (Funded by the National Key Research and Development Program of China and the National Major Project for Control and Prevention of Infectious Disease in China.).","['Pneumonia', 'Coronavirus disease 2019 (COVID-19)', 'Coronavirus', 'Severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2)', '2019-20 coronavirus outbreak', 'Virology', 'China', 'Medicine', 'Betacoronavirus', 'Geography', 'Internal medicine', 'Outbreak', 'Infectious disease (medical specialty)', 'Archaeology', 'Disease']","pneumonia, seafood wholesale market, betacorona, unbiased sequencing, human airway epithelial cells, corona, ##be, ##ocoronavir, corona, [PAD], [PAD] [PAD], [PAD], [PAD]"
Paper_00189,Bowling alone: the collapse and revival of American community,['Robert D. Putnam'],2000,Choice Reviews Online,Journal,,38-2454,38,04,10.5860/choice.38-2454,"BOWLING ALONE warns Americans that their stock of social capital, the very fabric of their connections with each other, has been accelerating down. Putnam describes the resulting impoverishment of their lives and communities. Drawing on evidence that includes nearly half a million interviews conducted over a quarter of a century in America, Putnam shows how changes in work, family structure, age, suburban life, television, computers, women's roles and other factors are isolating Americans from each other in a trend whose reflection can clearly be seen in British society. We sign 30 percent fewer petitions than we did ten years ago. Membership in organisations- from the Boy Scouts to political parties and the Church is falling. Ties with friends and relatives are fraying: we're 35 percent less likely to visit our neighbours or have dinner with our families than we were thirty years ago. We watch sport alone instead of with our friends. A century ago, American citizens' means of connecting were at a low point after decades of urbanisation, industrialisation and immigration uprooted them from families and friends. That generation demonstrated a capacity for renewal by creating the organisations that pulled Americans together. Putnam shows how we can learn from them and reinvent common enterprises that will make us secure, productive, happy and hopeful.","['Quarter (Canadian coin)', 'Politics', 'Immigration', 'Industrialisation', 'Social capital', 'Urbanization', 'Sociology', 'Craft', 'History', 'Political science', 'Economic history', 'Political economy', 'Economic growth', 'Law', 'Social science', 'Economics', 'Archaeology']","social capital, women, boy scouts"
Paper_00190,The NCEP/NCAR 40-Year Reanalysis Project,"['Eugenia Kalnay', 'Masao Kanamitsu', 'Robert Kistler', 'William D. Collins', 'Dennis G. Deaven', 'L. S. Gandin', 'Mark Iredell', 'Suranjana Saha', 'Glenn H. White', 'John S. Woollen', 'Yutong Zhu', 'Ants Leetmaa', 'R. Reynolds', 'Muthuvel Chelliah', 'W. Ebisuzaki', 'W. Higgins', 'John E. Janowiak', 'K. C. Mo', 'C. Ropelewski', 'J. Wang', 'Roy L. Jenne', 'Dennis Joseph']",1996,Bulletin of the American Meteorological Society,Journal,,437-471,77,3,10.1175/1520-0477(1996)077<0437:tnyrp>2.0.co;2,"The NCEP and NCAR are cooperating in a project (denoted “reanalysis”) to produce a 40-year record of global analyses of atmospheric fields in support of the needs of the research and climate monitoring communities. This effort involves the recovery of land surface, ship, rawinsonde, pibal, aircraft, satellite, and other data; quality controlling and assimilating these data with a data assimilation system that is kept unchanged over the reanalysis period 1957–96. This eliminates perceived climate jumps associated with changes in the data assimilation system. The NCEP/NCAR 40-yr reanalysis uses a frozen state-of-the-art global data assimilation system and a database as complete as possible. The data assimilation and the model used are identical to the global system implemented operationally at the NCEP on 11 January 1995, except that the horizontal resolution is T62 (about 210 km). The database has been enhanced with many sources of observations not available in real time for operations, provided by different countries and organizations. The system has been designed with advanced quality control and monitoring components, and can produce 1 mon of reanalysis per day on a Cray YMP/8 supercomputer. Different types of output archives are being created to satisfy different user needs, including a “quick look” CD-ROM (one per year) with six tropospheric and stratospheric fields available twice daily, as well as surface, top-of-the-atmosphere, and isentropic fields. Reanalysis information and selected output is also available on-line via the Internet (http//:nic.fb4.noaa.gov:8000). A special CDROM, containing 13 years of selected observed, daily, monthly, and climatological data from the NCEP/NCAR Reanalysis, is included with this issue. Output variables are classified into four classes, depending on the degree to which they are influenced by the observations and/or the model. For example, “C” variables (such as precipitation and surface fluxes) are completely determined by the model during the data assimilation and should be used with caution. Nevertheless, a comparison of these variables with observations and with several climatologies shows that they generally contain considerable useful information. Eight-day forecasts, produced every 5 days, should be useful for predictability studies and for monitoring the quality of the observing systems. The 40 years of reanalysis (1957–96) should be completed in early 1997. A continuation into the future through an identical Climate Data Assimilation System will allow researchers to reliably compare recent anomalies with those in earlier decades. Since changes in the observing systems will inevitably produce perceived changes in the climate, parallel reanalyses (at least 1 year long) will be generated for the periods immediately after the introduction of new observing systems, such as new types of satellite data. NCEP plans currently call for an updated reanalysis using a state-of-the-art system every five years or so. The successive reanalyses will be greatly facilitated by the generation of the comprehensive database in the present reanalysis.","['Radiosonde', 'Data assimilation', 'Meteorology', 'Environmental science', 'Troposphere', 'Climatology', 'Satellite', 'Computer science', 'Database', 'Geography', 'Geology', 'Aerospace engineering', 'Engineering']","##ep, reanalysis, atmospheric fields, climate monitoring, ##ins, ##bal, climate jumps, horizontal resolution, quality control, ##ratospheric, isentropic, ##to, precipitation, surface fluxes, climatologies, predictability studies"
Paper_00191,Preparation of Graphitic Oxide,"['William S. Hummers', 'Richard E. Offeman']",1958,Journal of the American Chemical Society,Journal,,1339-1339,80,6,10.1021/ja01539a017,"ADVERTISEMENT RETURN TO ISSUEPREVArticleNEXTPreparation of Graphitic OxideWilliam S. Hummers Jr. and Richard E. OffemanCite this: J. Am. Chem. Soc. 1958, 80, 6, 1339Publication Date (Print):March 1, 1958Publication History Published online1 May 2002Published inissue 1 March 1958https://pubs.acs.org/doi/10.1021/ja01539a017https://doi.org/10.1021/ja01539a017research-articleACS PublicationsRequest reuse permissionsArticle Views106696Altmetric-Citations26571LEARN ABOUT THESE METRICSArticle Views are the COUNTER-compliant sum of full text article downloads since November 2008 (both PDF and HTML) across all institutions and individuals. These metrics are regularly updated to reflect usage leading up to the last few days.Citations are the number of other articles citing this article, calculated by Crossref and updated daily. Find more information about Crossref citation counts.The Altmetric Attention Score is a quantitative measure of the attention that a research article has received online. Clicking on the donut icon will load a page at altmetric.com with additional details about the score and the social media presence for the given article. Find more information on the Altmetric Attention Score and how the score is calculated. Share Add toView InAdd Full Text with ReferenceAdd Description ExportRISCitationCitation and abstractCitation and referencesMore Options Share onFacebookTwitterWechatLinked InRedditEmail Other access optionsGet e-Alertsclose Get e-Alerts","['Altmetrics', 'Citation', 'Icon', 'Social media', 'Computer science', 'World Wide Web', 'Information retrieval', 'Library science', 'Programming language']","graphitic oxide, permissionsarticle views, ##le, ##f, altmetric attention score, social, altmetric attention score, reference, ##d, ##ation, abstract, references, [PAD]"
Paper_00195,Molecular dynamics with coupling to an external bath,"['Herman J. C. Berendsen', 'Johan P. M. Postma', 'Wilfred F. van Gunsteren', 'A. DiNola', 'J.R. Haak']",1984,The Journal of Chemical Physics,Journal,,3684-3690,81,8,10.1063/1.448118,"In molecular dynamics (MD) simulations the need often arises to maintain such parameters as temperature or pressure rather than energy and volume, or to impose gradients for studying transport properties in nonequilibrium MD. A method is described to realize coupling to an external bath with constant temperature or pressure with adjustable time constants for the coupling. The method is easily extendable to other variables and to gradients, and can be applied also to polyatomic molecules involving internal constraints. The influence of coupling time constants on dynamical variables is evaluated. A leap-frog algorithm is presented for the general case involving constraints with coupling to both a constant temperature and a constant pressure bath.","['Coupling (piping)', 'Constant (computer programming)', 'Molecular dynamics', 'Polyatomic ion', 'Coupling constant', 'Non-equilibrium thermodynamics', 'Dynamics (music)', 'Statistical physics', 'Time constant', 'Physics', 'Volume (thermodynamics)', 'Thermodynamics', 'Chemistry', 'Molecule', 'Chemical physics', 'Classical mechanics', 'Materials science', 'Computational chemistry', 'Quantum mechanics', 'Computer science', 'Acoustics', 'Electrical engineering', 'Metallurgy', 'Programming language', 'Engineering']","molecular dynamics, ##s, transport properties, nonequilibrium md, external bath, adjustable time constants, polyatomic molecules, internal constraints, coupling time constants, constant pressure bath"
Paper_00196,Regression Models and Life-Tables,['D. R. Cox'],1972,Journal of the Royal Statistical Society Series B (Statistical Methodology),Journal,,187-202,34,2,10.1111/j.2517-6161.1972.tb00899.x,"Summary The analysis of censored failure times is considered. It is assumed that on each individual are available values of one or more explanatory variables. The hazard function (age-specific failure rate) is taken to be a function of the explanatory variables and unknown regression coefficients multiplied by an arbitrary and unknown function of time. A conditional likelihood is obtained, leading to inferences about the unknown regression coefficients. Some generalizations are outlined.","['Regression analysis', 'Statistics', 'Regression', 'Econometrics', 'Computer science', 'Mathematics']","censored failure times, ##planatory variables, hazard function, ##planatory variables, unknown regression coefficients, conditional likelihood, unknown regression coefficients, [PAD]"
Paper_00197,A Global Measure of Perceived Stress,"['Sheldon Cohen', 'Thomas W. Kamarck', 'Robin Mermelstein']",1983,Journal of Health and Social Behavior,Journal,,385-385,24,4,10.2307/2136404,"This paper presents evidence from three samples, two of college students and one of participants in a community smoking-cessation program, for the reliability and validity of a 14-item instrument, the Perceived Stress Scale (PSS), designed to measure the degree to which situations in one's life are appraised as stressful. The PSS showed adequate reliability and, as predicted, was correlated with life-event scores, depressive and physical symptomatology, utilization of health services, social anxiety, and smoking-reduction maintenance. In all comparisons, the PSS was a better predictor of the outcome in question than were life-event scores. When compared to a depressive symptomatology scale, the PSS was found to measure a different and independently predictive construct. Additional data indicate adequate reliability and validity of a four-item version of the PSS for telephone interviews. The PSS is suggested for examining the role of nonspecific appraised stress in the etiology of disease and behavioral disorders and as an outcome measure of experienced levels of stress.","['Psychology', 'Clinical psychology', 'Anxiety', 'Reliability (semiconductor)', 'Construct validity', 'Scale (ratio)', 'Psychometrics', 'Perceived Stress Scale', 'Stress (linguistics)', 'Psychiatry', 'Linguistics', 'Philosophy', 'Power (physics)', 'Physics', 'Quantum mechanics']","college, perceived stress scale, physical symptomatology, health services, social anxiety, depressive symptomatology scale, telephone interviews, nonspecific appraised stress, behavioral disorders"
Paper_00198,MrBayes 3: Bayesian phylogenetic inference under mixed models,"['Fredrik Ronquist', 'John P. Huelsenbeck']",2003,Bioinformatics,Journal,,1572-1574,19,12,10.1093/bioinformatics/btg180,"MrBayes 3 performs Bayesian phylogenetic analysis combining information from different data partitions or subsets evolving under different stochastic evolutionary models. This allows the user to analyze heterogeneous data sets consisting of different data types-e.g. morphological, nucleotide, and protein-and to explore a wide variety of structured models mixing partition-unique and shared parameters. The program employs MPI to parallelize Metropolis coupling on Macintosh or UNIX clusters.","['Unix', 'Partition (number theory)', 'Phylogenetic tree', 'Bayesian probability', 'Computer science', 'Inference', 'Biology', 'Artificial intelligence', 'Software', 'Mathematics', 'Combinatorics', 'Programming language', 'Genetics', 'Gene']","mrbayes, bayesian phylogenetic analysis, data partitions, stochastic evolutionary models, heterogeneous data sets, nucleotide, structured models, mpi, metropolis coupling, macintosh, unix clusters, [PAD], [PAD], [PAD] [PAD], [PAD], [PAD] [PAD] [PAD] [PAD] [PAD], [PAD] [PAD], [PAD] [PAD], [PAD], [PAD], [PAD] [PAD]"
Paper_00199,Situated Learning,"['Jean Lave', 'Étienne Wenger']",1991,Unknown,Unknown,,,,,10.1017/cbo9780511815355,"In this important theoretical treatist, Jean Lave, anthropologist, and Etienne Wenger, computer scientist, push forward the notion of situated learning - that learning is fundamentally a social process. The authors maintain that learning viewed as situated activity has as its central defining characteristic a process they call legitimate peripheral participation (LPP). Learners participate in communities of practitioners, moving toward full participation in the sociocultural practices of a community. LPP provides a way to speak about crucial relations between newcomers and old-timers and about their activities, identities, artefacts, knowledge and practice. The communities discussed in the book are midwives, tailors, quartermasters, butchers, and recovering alcoholics, however, the process by which participants in those communities learn can be generalised to other social groups.","['Situated', 'Situated learning', 'Sociocultural evolution', 'Sociology', 'Social learning', 'Community of practice', 'Process (computing)', 'Pedagogy', 'Psychology', 'Computer science', 'Anthropology', 'Artificial intelligence', 'Operating system']","situated learning, social process, legitimate peripheral participation, sociocultural practices, midwives, tailors, quartermasters, butchers, recovering alcoholics, [PAD]"
Paper_00201,"Summary of the Second Report of the National Cholesterol Education Program (NCEP) Expert Panel on Detection, Evaluation, and Treatment of High Blood Cholesterol in Adults (Adult Treatment Panel II)",['Scott M. Grundy'],1993,JAMA,Journal,,3015-3015,269,23,10.1001/jama.1993.03500230097036,"THE SECOND report of the Expert Panel on Detection, Evaluation, and Treatment of High Blood Cholesterol in Adults (Adult Treatment Panel II, or ATP II) presents the National Cholesterol Education Program's updated recommendations for cholesterol management. It is similar to the first in general outline, and the fundamental approach to treatment of high blood cholesterol is comparable. This report continues to identify low-density lipoproteins (LDL) as the primary target of cholesterol-lowering therapy. As in the first report, the second report emphasizes the role of the clinical approach in primary prevention of coronary heart disease (CHD). Dietary therapy remains the first line of treatment of high blood cholesterol, and drug therapy is reserved for patients who are considered to be at high risk for CHD. However, the second report contains new features that distinguish it from the first. These include the following: Increased emphasis on See also pp 3002 and 3009.","['Medicine', 'National Cholesterol Education Program', 'Cholesterol', 'Blood cholesterol', 'Coronary heart disease', 'Internal medicine', 'Metabolic syndrome', 'Obesity']","high blood cholesterol, adults, adult treatment panel, national cho, cholesterol management, high, coronary heart disease, dietary therapy, drug therapy"
Paper_00203,Society and the Adolescent Self-Image,['Morris Rosenberg'],1965,Princeton University Press eBooks,Unknown,,,,,10.1515/9781400876136,"Over 5,000 high-school students of different social, religious, and national backgrounds were studied to show the effects of family experience, neighborhoods, minority groups, etc. on their self-image and response to society. Originally published in 1965. The Princeton Legacy Library uses the latest print-on-demand technology to again make available previously out-of-print books from the distinguished backlist of Princeton University Press. These editions preserve the original texts of these important books while presenting them in durable paperback and hardcover editions. The goal of the Princeton Legacy Library is to vastly increase access to the rich scholarly heritage found in the thousands of books published by Princeton University Press since its founding in 1905.","['Art history', 'History', 'Library science', 'Media studies', 'Sociology', 'Computer science']","neighborhoods, minority groups, princeton legacy library, princeton, princeton legacy library, scholarly"
Paper_00204,The Cochrane Collaboration's tool for assessing risk of bias in randomised trials,"['Julian P. T. Higgins', 'Doug Altman', 'Peter C Gøtzsche', 'Peter Jüni', 'David Moher', 'Andrew D Oxman', 'Jelena Savović', 'Kenneth F. Schulz', 'Laura Weeks', 'Jonathan A C Sterne']",2011,BMJ,Journal,,d5928-d5928,343,oct18 2,10.1136/bmj.d5928,"Flaws in the design, conduct, analysis, and reporting of randomised trials can cause the effect of an intervention to be underestimated or overestimated. The Cochrane Collaboration's tool for assessing risk of bias aims to make the process clearer and more accurate","['Randomized controlled trial', 'Cochrane collaboration', 'Intervention (counseling)', 'Medicine', 'Meta-analysis', 'Psychology', 'Risk analysis (engineering)', 'Cochrane Library', 'Internal medicine', 'Nursing']","randomised trials, cochrane collaboration, [PAD], [PAD] [PAD]"
Paper_00205,Discovering Statistics Using SPSS,"['Andy P. Field', 'Jeremy N. V. Miles']",2000,['PsyPag Quarterly'],Unknown,,31-32,1,56,10.53841/bpspag.2005.1.56.31,"Hot on the heels of the 3rd edition of Andy Field's award-winning Discovering Statistics Using SPSS comes this brand new version for students using SAS(R). Andy has teamed up with a co-author, Jeremy Miles, to adapt the book with all the most up-to-date commands and programming language from SAS(R) 9.2. If you're using SAS(R), this is the only book on statistics that you will need! The book provides a comprehensive collection of statistical methods, tests and procedures, covering everything you're likely to need to know for your course, all presented in Andy's accessible and humourous writing style. Suitable for those new to statistics as well as students on intermediate and more advanced courses, the book walks students through from basic to advanced level concepts, all the while reinforcing knowledge through the use of SAS(R). A 'cast of characters' supports the learning process throughout the book, from providing tips on how to enter data in SAS(R) properly to testing knowledge covered in chapters interactively, and 'real world' and invented examples illustrate the concepts and make the techniques come alive. The book's companion website (see link above) provides students with a wide range of invented and real published research datasets. Lecturers can find multiple choice questions and PowerPoint slides for each chapter to support their teaching.","['Computer science', 'Process (computing)', 'Field (mathematics)', 'Mathematics education', 'Data science', 'Mathematics', 'Programming language', 'Pure mathematics']","statistics, spss, sas, programming, multiple choice questions, powerpoint slides"
Paper_00206,Consolidated criteria for reporting qualitative research (COREQ): a 32-item checklist for interviews and focus groups,"['Allison Tong', 'Peter Sainsbury', 'Jonathan C. Craig']",2007,International Journal for Quality in Health Care,Journal,,349-357,19,6,10.1093/intqhc/mzm042,"Qualitative research explores complex phenomena encountered by clinicians, health care providers, policy makers and consumers. Although partial checklists are available, no consolidated reporting framework exists for any type of qualitative design.To develop a checklist for explicit and comprehensive reporting of qualitative studies (in depth interviews and focus groups).We performed a comprehensive search in Cochrane and Campbell Protocols, Medline, CINAHL, systematic reviews of qualitative studies, author or reviewer guidelines of major medical journals and reference lists of relevant publications for existing checklists used to assess qualitative studies. Seventy-six items from 22 checklists were compiled into a comprehensive list. All items were grouped into three domains: (i) research team and reflexivity, (ii) study design and (iii) data analysis and reporting. Duplicate items and those that were ambiguous, too broadly defined and impractical to assess were removed.Items most frequently included in the checklists related to sampling method, setting for data collection, method of data collection, respondent validation of findings, method of recording data, description of the derivation of themes and inclusion of supporting quotations. We grouped all items into three domains: (i) research team and reflexivity, (ii) study design and (iii) data analysis and reporting.The criteria included in COREQ, a 32-item checklist, can help researchers to report important aspects of the research team, study methods, context of the study, findings, analysis and interpretations.","['Checklist', 'CINAHL', 'Qualitative research', 'Respondent', 'Data collection', 'Context (archaeology)', 'Research design', 'Focus group', 'Qualitative property', 'Psychology', 'MEDLINE', 'Medical education', 'Applied psychology', 'Computer science', 'Medicine', 'Nursing', 'Sociology', 'Paleontology', 'Social science', 'Machine learning', 'Political science', 'Psychological intervention', 'Anthropology', 'Law', 'Cognitive psychology', 'Biology']","qualitative research, clinic, health care providers, policy, qualitative design, qualitative studies, focus groups, cochrane, medline, cinahl, systematic reviews, qualitative studies, medical journals, qualitative, reflexivity, study design, data analysis, sampling method, respondent validation, reflexivity, study design, data analysis, ##q"
Paper_00208,Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation,"['Ross Girshick', 'Jeff Donahue', 'Trevor Darrell', 'Jitendra Malik']",2014,2009 IEEE Conference on Computer Vision and Pattern Recognition,Conference,"2014 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Columbus, OH, USA",580-587,,,10.1109/cvpr.2014.81,"Object detection performance, as measured on the canonical PASCAL VOC dataset, has plateaued in the last few years. The best-performing methods are complex ensemble systems that typically combine multiple low-level image features with high-level context. In this paper, we propose a simple and scalable detection algorithm that improves mean average precision (mAP) by more than 30% relative to the previous best result on VOC 2012 -- achieving a mAP of 53.3%. Our approach combines two key insights: (1) one can apply high-capacity convolutional neural networks (CNNs) to bottom-up region proposals in order to localize and segment objects and (2) when labeled training data is scarce, supervised pre-training for an auxiliary task, followed by domain-specific fine-tuning, yields a significant performance boost. Since we combine region proposals with CNNs, we call our method R-CNN: Regions with CNN features. We also present experiments that provide insight into what the network learns, revealing a rich hierarchy of image features. Source code for the complete system is available at http://www.cs.berkeley.edu/~rbg/rcnn.","['Pascal (unit)', 'Computer science', 'Convolutional neural network', 'Object detection', 'Artificial intelligence', 'Pattern recognition (psychology)', 'Segmentation', 'Scalability', 'Context (archaeology)', 'Image (mathematics)', 'Machine learning', 'Paleontology', 'Database', 'Biology', 'Programming language']","object detection performance, pascal voc dataset, complex ensemble systems, ##ble detection algorithm, mean average precision, convolutional neural networks"
Paper_00209,Dynamic capabilities and strategic management,"['David J. Teece', 'Gary P. Pisano', 'Amy Shuen']",1997,Strategic Management Journal,Journal,,509-533,18,7,10.1002/(sici)1097-0266(199708)18:7<509::aid-smj882>3.0.co;2-z,"The dynamic capabilities framework analyzes the sources and methods of wealth creation and capture by private enterprise firms operating in environments of rapid technological change. The competitive advantage of firms is seen as resting on distinctive processes (ways of coordinating and combining), shaped by the firm's (specific) asset positions (such as the firm's portfolio of difficult-to-trade knowledge assets and complementary assets), and the evolution path(s) it has adopted or inherited. The importance of path dependencies is amplified where conditions of increasing returns exist. Whether and how a firm's competitive advantage is eroded depends on the stability of market demand, and the ease of replicability (expanding internally) and imitatability (replication by competitors). If correct, the framework suggests that private wealth creation in regimes of rapid technological change depends in large measure on honing internal technological, organizational, and managerial processes inside the firm. In short, identifying new opportunities and organizing effectively and efficiently to embrace them are generally more fundamental to private wealth creation than is strategizing, if by strategizing one means engaging in business conduct that keeps competitors off balance, raises rival's costs, and excludes new entrants. © 1997 by John Wiley & Sons, Ltd.","['Competitor analysis', 'Industrial organization', 'Complementary assets', 'Asset (computer security)', 'Portfolio', 'Competitive advantage', 'Business', 'Dynamic capabilities', 'Balance (ability)', 'Economics', 'Marketing', 'Microeconomics', 'Computer science', 'Finance', 'Medicine', 'Computer security', 'Physical medicine and rehabilitation']","dynamic capabilities framework, wealth creation, private enterprise firms, technological change, competitive advantage, competitive advantage, market demand, private wealth creation, managerial, private wealth creation"
Paper_00210,Sample Selection Bias as a Specification Error,['James J. Heckman'],1979,Econometrica,Journal,,153-153,47,1,10.2307/1912352,Sample selection bias as a specification error This paper discusses the bias that results from using non-randomly selected samples to estimate behavioral relationships as an ordinary specification error or «omitted variables» bias. A simple consistent two stage estimator is considered that enables analysts to utilize simple regression methods to estimate behavioral functions by least squares methods. The asymptotic distribution of the estimator is derived.,"['Selection (genetic algorithm)', 'Selection bias', 'Statistics', 'Econometrics', 'Sample (material)', 'Computer science', 'Economics', 'Mathematics', 'Artificial intelligence', 'Chemistry', 'Chromatography']","sample selection bias, specification error, - randomly, behavioral relationships, omitted variables, regression methods, behavioral functions, least, asymptotic distribution, [PAD] [PAD], [PAD]"
Paper_00211,The Satisfaction With Life Scale,"['E Diener', 'Robert A. Emmons', 'Randy J. Larsen', 'S. Griffin']",1985,Journal of Personality Assessment,Journal,,71-75,49,1,10.1207/s15327752jpa4901_13,"This article reports the development and validation of a scale to measure global life satisfaction, the Satisfaction With Life Scale (SWLS). Among the various components of subjective well-being, the SWLS is narrowly focused to assess global life satisfaction and does not tap related constructs such as positive affect or loneliness. The SWLS is shown to have favorable psychometric properties, including high internal consistency and high temporal reliability. Scores on the SWLS correlate moderately to highly with other measures of subjective well-being, and correlate predictably with specific personality characteristics. It is noted that the SWLS is Suited for use with different age groups, and other potential uses of the scale are discussed.","['Psychology', 'Life satisfaction', 'Loneliness', 'Scale (ratio)', 'Subjective well-being', 'Internal consistency', 'Reliability (semiconductor)', 'Clinical psychology', 'Personality', 'Psychometrics', 'Social psychology', 'Happiness', 'Power (physics)', 'Physics', 'Quantum mechanics']","global life satisfaction, satisfaction with life scale, swls, subjective well - being, swls, global life satisfaction, positive affect, loneliness, psychometric, internal consistency, high temporal reliability, subjective well - being, personality characteristics"
Paper_00215,Statistical Learning Theory,"['Yuhai Wu', 'Vladimir Vapnik']",1999,Technometrics,Journal,,377-377,41,4,10.2307/1271368,"A comprehensive look at learning and generalization theory. The statistical theory of learning and generalization concerns the problem of choosing desired functions on the basis of empirical data. Highly applicable to a variety of computer science and robotics fields, this book offers lucid coverage of the theory as a whole. Presenting a method for determining the necessary and sufficient conditions for consistency of learning process, the author covers function estimates from small data pools, applying these estimations to real-life problems, and much more.","['Generalization', 'Statistical learning theory', 'Artificial intelligence', 'Consistency (knowledge bases)', 'Computer science', 'Machine learning', 'Statistical theory', 'Variety (cybernetics)', 'Process (computing)', 'Algorithmic learning theory', 'Learning theory', 'Function (biology)', 'Mathematics', 'Unsupervised learning', 'Statistics', 'Mathematics education', 'Support vector machine', 'Mathematical analysis', 'Evolutionary biology', 'Biology', 'Operating system']","learning, generalization theory, statistical theory, learning, generalization, computer science, robotics, function estimates"
Paper_00217,A Simplex Method for Function Minimization,"['J. A. Nelder', 'R. Mead']",1965,The Computer Journal,Journal,,308-313,7,4,10.1093/comjnl/7.4.308,"A method is described for the minimization of a function of n variables, which depends on the comparison of function values at the (n + 1) vertices of a general simplex, followed by the replacement of the vertex with the highest value by another point. The simplex adapts itself to the local landscape, and contracts on to the final minimum. The method is shown to be effective and computationally compact. A procedure is given for the estimation of the Hessian matrix in the neighbourhood of the minimum, needed in statistical estimation problems.","['Hessian matrix', 'Simplex', 'Minification', 'Neighbourhood (mathematics)', 'Vertex (graph theory)', 'Simplex algorithm', 'Mathematics', 'Mathematical optimization', 'Function (biology)', 'Computer science', 'Combinatorics', 'Algorithm', 'Applied mathematics', 'Linear programming', 'Graph', 'Mathematical analysis', 'Evolutionary biology', 'Biology']","hessian matrix, statistical estimation problems"
Paper_00218,Latent dirichlet allocation,"['David M. Blei', 'Andrew Y. Ng', 'Michael I. Jordan']",2003,Journal of Machine Learning Research,Journal,,993-1022,3,,10.5555/944919.944937,"We describe latent Dirichlet allocation (LDA), a generative probabilistic model for collections of discrete data such as text corpora. LDA is a three-level hierarchical Bayesian model, in which each item of a collection is modeled as a finite mixture over an underlying set of topics. Each topic is, in turn, modeled as an infinite mixture over an underlying set of topic probabilities. In the context of text modeling, the topic probabilities provide an explicit representation of a document. We present efficient approximate inference techniques based on variational methods and an EM algorithm for empirical Bayes parameter estimation. We report results in document modeling, text classification, and collaborative filtering, comparing to a mixture of unigrams model and the probabilistic LSI model.","['Latent Dirichlet allocation', 'Computer science', 'Topic model', 'Hierarchical Dirichlet process', 'Dirichlet distribution', 'Inference', 'Probabilistic logic', 'Mixture model', 'Artificial intelligence', 'Context (archaeology)', ""Bayes' theorem"", 'Generative model', 'Set (abstract data type)', 'Representation (politics)', 'Statistical model', 'Bayesian inference', 'Generative grammar', 'Bayesian probability', 'Machine learning', 'Mathematics', 'Mathematical analysis', 'Paleontology', 'Politics', 'Law', 'Political science', 'Programming language', 'Biology', 'Boundary value problem']","latent dirichlet allocation, ld, generative probabilistic model, discrete data, text corpora, text modeling, approximate inference techniques, variational methods, em algorithm, empirical bayes parameter estimation, document modeling, text classification, collaborative filtering, unigrams"
Paper_00219,Cutadapt removes adapter sequences from high-throughput sequencing reads,['Marcel Martin'],2011,EMBnet journal,Journal,,10-10,17,1,10.14806/ej.17.1.200,"When small RNA is sequenced on current sequencing machines, the resulting reads are usually longer than the RNA and therefore contain parts of the 3' adapter. That adapter must be found and removed error-tolerantly from each read before read mapping. Previous solutions are either hard to use or do not offer required features, in particular support for color space data. As an easy to use alternative, we developed the command-line tool cutadapt, which supports 454, Illumina and SOLiD (color space) data, offers two adapter trimming algorithms, and has other useful features. Cutadapt, including its MIT-licensed source code, is available for download at http://code.google.com/p/cutadapt/","['Adapter (computing)', 'Computer science', 'Trimming', 'Operating system']","sequencing, color space data, cutadapt, 45, illumina, color space, adapter trimming algorithms, cutadapt, cutadapt"
Paper_00220,Handbook of Qualitative Research,"['Gill Crozier', 'Norman K. Denzin', 'Yvonna S. Lincoln']",1994,British Journal of Educational Studies,Journal,,409-409,42,4,10.2307/3121684,"Introduction - Norman K Denzin and Yvonna S Lincoln The Discipline and Practice of Qualitative Research PART ONE: LOCATING THE FIELD Qualitative Methods - Arthur J Vidich and Stanford M Lyman Their History in Sociology and Anthropology Reconstructing the Relationships between Universities and Society through Action Research - Davydd J Greenwood and Morten Levin For Whom? Qualitative Research, Representations and Social Responsibilities - Michelle Fine et al Ethics and Politics in Qualitative Research - Clifford G Christians PART TWO: PARADIGMS AND PERSPECTIVES IN TRANSITION Paradigmatic Controversies, Contradictions and Emerging Confluences - Yvonna S Lincoln and Egon G Guba Three Epistemological Stances for Qualitative Inquiry - Thomas A Schwandt Interpretivism, Hermeneutics and Social Constructionism Feminisms and Qualitative Research at and into the Millennium - Virginia L Olesen Racialized Discourses and Ethnic Epistemologies - Gloria Ladson-Billings Rethinking Critical Theory and Qualitative Research - Joe L Kincheloe and Peter McLaren Cultural Studies - John Frow and Meaghan Morris Sexualities, Queer Theory and Qualitative Research - Joshua Gamson PART THREE: STRATEGIES OF INQUIRY The Choreography of Qualitative Research Design - Valerie J Janesick Minuets, Improvisations and Crystallization An Untold Story? Doing Funded Qualitative Research - Julianne Cheek Performance Ethnography - Michal M McCall A Brief History and Some Advice Case Studies - Robert E Stake Ethnography and Ethnographic Representation - Barbara Tedlock Analyzing Interpretive Practice - Jaber F Gubrium and James A Holstein Grounded Theory - Kathy Charmaz Objectivist and Constructivist Methods Undaunted Courage - William G Tierney Life History and the Postmodern Challenge Testimonio, Subalternity and Narrative Authority - John Beverley Participatory Action Research - Stephen Kemmis and Robin McTaggart Clinical Research - William L Miller and Benjamin F Crabtree PART FOUR: METHODS OF COLLECTING AND ANALYZING EMPIRICAL MATERIALS The Interview - Andrea Fontana and James H Frey From Structured Questions to Negotiated Text Rethinking Observation - Michael V Angrosino and Kimberly A Mays de Perez From Method to Context The Interpretation of Documents and Material Culture - Ian Hodder Re-Imagining Visual Methods - Douglas Harper Galileo to Neuromancer Auto-Ethnography, Personal Narrative, Reflexivity - Carolyn Ellis and Arthur P Bochner Researcher as Subject Data Management and Analysis Methods - Gery W Ryan and H Russell Bernard Software and Qualitative Research - Eben A Weitzman Analyzing Talk and Text - David Silverman Focus Groups in Feminist Research - Esther Madriz Applied Ethnography - Erve Chambers PART FIVE: THE ART AND PRACTICES OF INTERPRETATION, EVALUATION AND REPRESENTATION The Problem of Criteria in the Age of Relativism - John K Smith and Deborah K Deemer The Practices and Politics of Interpretation - Norman K Denzin Writing - Laurel Richardson A Method of Inquiry Anthropological Poetics - Ivan Brady Understanding Social Programs through Evaluation - Jennifer C Greene Influencing the Policy Process with Qualitative Research - Ray C Rist PART SIX: THE FUTURE OF QUALITATIVE RESEARCH Qualitative Inquiry - Mary M Gergen and Kenneth J Gergen Tensions and Transformations The Seventh Moment - Yvonna S Lincoln and Norman K Denzin Out of the Past","['Sociology', 'Qualitative research', 'Psychology', 'Social science']","qualitative research, anthropology, social responsibilities, ##istemological stances, ##tative, social constructionism, ##tative, racialized discourses, ethnic epistemologies, cultural studies, ##al, narrative authority, ##tory, material culture, personal narrative"
Paper_00223,KEGG: Kyoto Encyclopedia of Genes and Genomes,['Minoru Kanehisa'],2000,Nucleic Acids Research,Journal,,27-30,28,1,10.1093/nar/28.1.27,"KEGG (Kyoto Encyclopedia of Genes and Genomes) is a knowledge base for systematic analysis of gene functions, linking genomic information with higher order functional information. The genomic information is stored in the GENES database, which is a collection of gene catalogs for all the completely sequenced genomes and some partial genomes with up-to-date annotation of gene functions. The higher order functional information is stored in the PATHWAY database, which contains graphical representations of cellular processes, such as metabolism, membrane transport, signal transduction and cell cycle. The PATHWAY database is supplemented by a set of ortholog group tables for the information about conserved subpathways (pathway motifs), which are often encoded by positionally coupled genes on the chromosome and which are especially useful in predicting gene functions. A third database in KEGG is LIGAND for the information about chemical compounds, enzyme molecules and enzymatic reactions. KEGG provides Java graphics tools for browsing genome maps, comparing two genome maps and manipulating expression maps, as well as computational tools for sequence comparison, graph comparison and path computation. The KEGG databases are daily updated and made freely available (http://www.genome.ad.jp/kegg/ ).","['KEGG', 'Genome', 'Biology', 'Gene', 'Computational biology', 'Genome project', 'Genetics', 'Database', 'Gene expression', 'Transcriptome', 'Computer science']","kegg, gene functions, gen, genes database, partial genome, pathway database, metabolism, membrane transport, signal transduction, cell cycle, pathway database, ##tholog group tables, conserved subpathways, pathway motifs, positionally coupled, ##gg, enzyme molecules, enzymatic reactions, kegg, java graphics, expression maps, sequence comparison, graph comparison, path computation, [PAD] [PAD] [PAD] [PAD], [PAD] [PAD], [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD], [PAD], [PAD] [PAD] [PAD] [PAD], [PAD], [PAD] [PAD] [PAD], [PAD], [PAD]"
Paper_00224,Gender Trouble: Feminism and the Subversion of Identity,"['Mary McIntosh', 'Judith Butler']",1991,Feminist Review,Journal,,113-113,,38,10.2307/1395391,"Preface (1999) Preface (1990) 1. Subjects of Sex/Gender/Desire I. 'Women' as the Subject of Feminism II. The Compulsory Order of Sex/Gender/Desire III. Gender: The Circular Ruins of Contemporary Debate IV. Theorizing the Binary, the Unitary and Beyond V. Identity, Sex and the Metaphysics of Substance VI. Language, Power and the Strategies of Displacement 2. Prohibition, Psychoanalysis, and the Production of the Heterosexual Matrix I. Structuralism's Critical Exchange II. Lacan, Riviere, and the Strategies of Masquerade III. Freud and the Melancholia of Gender IV. Gender Complexity and the Limits of Identification V. Reformulating Prohibition as Power 3. Subversive Bodily Acts I. The Body Politics of Julia Kristeva II. Foucault, Herculine, and the Politics of Sexual Discontinuity III. Monique Wittig - Bodily Disintegration and Fictive Sex IV. Bodily Inscriptions, Performative Subversions Conclusion - From Parody to Politics","['Subversion', 'Feminism', 'Gender studies', 'Sociology', 'Performative utterance', 'Politics', 'Psychoanalysis', 'Identity politics', 'Identity (music)', 'Power (physics)', 'Metaphysics', 'Subjectivity', 'Philosophy', 'Psychology', 'Aesthetics', 'Epistemology', 'Law', 'Political science', 'Physics', 'Quantum mechanics']","women, feminism, compulsory order, gender, circular ruins, contemporary debate, meta, power, prohibition, ##analysis, structuralism, critical exchange, freud, ##cholia, gender complexity, subversive bodily acts, body politics, ##ult, her, ##line, sexual discontinuity, bodily disintegration, fictive sex, bodily inscriptions, performative subversions"
Paper_00226,Economic Action and Social Structure: The Problem of Embeddedness,['Mark Granovetter'],1985,American Journal of Sociology,Journal,,481-510,91,3,10.1086/228311,"How behavior and institutions are affected by social relations is one of the classic questions of social theory. This paper concerns the extent to which economic action is embedded in structures of social relations, in modern industrial society. Although the usual neoclasical accounts provide an undersocialized or atomized-actor explanation of such action, reformist economists who attempt to bring social structure back in do so in the way criticized by Dennis Wrong. Under-and oversocialized accounts are paradoxically similar in their neglect of ongoing structures of social relations, and a sophisticated account of economic action must consider its embeddedness in such structures. The argument in illustrated by a critique of Oliver Williamson's markets and hierarchies research program.","['Embeddedness', 'Action (physics)', 'Economics', 'Economic system', 'Business', 'Sociology', 'Social science', 'Physics', 'Quantum mechanics']","social relations, social theory, economic action, social relations, industrial society, ##cl, ##cal, social relations, economic action, [PAD]"
Paper_00227,Clinical diagnosis of Alzheimer's disease,"['Guy M. McKhann', 'David A. Drachman', 'Marshall Folstein', 'Robert Katzman', 'Donald D. Price', 'Emanuel M. Stadlan']",1984,Neurology,Journal,,939-939,34,7,10.1212/wnl.34.7.939,"Clinical criteria for the diagnosis of Alzheimer9s disease include insidious onset and progressive impairment of memory and other cognitive functions. There are no motor, sensory, or coordination deficits early in the disease. The diagnosis cannot be determined by laboratory tests. These tests are important primarily in identifying other possible causes of dementia that must be excluded before the diagnosis of Alzheimer9s disease may be made with confidence. Neuropsychological tests provide confirmatory evidence of the diagnosis of dementia and help to assess the course and response to therapy. The criteria proposed are intended to serve as a guide for the diagnosis of probable, possible, and definite Alzheimer9s disease; these criteria will be revised as more definitive information becomes available.","['Dementia', 'Disease', 'Neuropsychology', 'Memory clinic', 'Medicine', ""Alzheimer's disease"", 'Cognition', 'Psychology', 'Physical medicine and rehabilitation', 'Psychiatry', 'Physical therapy', 'Pediatrics', 'Pathology']","alzheimer9, insidious onset, progressive, cognitive functions, coordination deficits, neuropsychological tests, [PAD], [PAD] [PAD]"
Paper_00228,Clustal W and Clustal X version 2.0,"['Mark Larkin', 'Gordon Blackshields', 'Nigel P. Brown', 'Chenna Ramu', 'Paul McGettigan', 'Hamish McWilliam', 'F. Valentin', 'Iain M. Wallace', 'Andreas Wilm', 'Rodrigo López', 'Julie Thompson', 'Toby J. Gibson', 'Desmond G. Higgins']",2007,Bioinformatics,Journal,,2947-2948,23,21,10.1093/bioinformatics/btm404,"Abstract Summary: The Clustal W and Clustal X multiple sequence alignment programs have been completely rewritten in C++. This will facilitate the further development of the alignment algorithms in the future and has allowed proper porting of the programs to the latest versions of Linux, Macintosh and Windows operating systems. Availability: The programs can be run on-line from the EBI web server: http://www.ebi.ac.uk/tools/clustalw2. The source code and executables for Windows, Linux and Macintosh computers are available from the EBI ftp site ftp://ftp.ebi.ac.uk/pub/software/clustalw2/ Contact: clustalw@ucd.ie","['Porting', 'File Transfer Protocol', 'Executable', 'Computer science', 'Operating system', 'Windows NT', 'Software', 'Web site', 'Programming language', 'World Wide Web', 'The Internet']","clustal, clustal, multiple sequence alignment programs, alignment algorithms, windows, ##bi, macintosh"
Paper_00230,A Computational Approach to Edge Detection,['John Canny'],1986,IEEE Transactions on Pattern Analysis and Machine Intelligence,Journal,,679-698,PAMI-8,6,10.1109/tpami.1986.4767851,"This paper describes a computational approach to edge detection. The success of the approach depends on the definition of a comprehensive set of goals for the computation of edge points. These goals must be precise enough to delimit the desired behavior of the detector while making minimal assumptions about the form of the solution. We define detection and localization criteria for a class of edges, and present mathematical forms for these criteria as functionals on the operator impulse response. A third criterion is then added to ensure that the detector has only one response to a single edge. We use the criteria in numerical optimization to derive detectors for several common image features, including step edges. On specializing the analysis to step edges, we find that there is a natural uncertainty principle between detection and localization performance, which are the two main goals. With this principle we derive a single operator shape which is optimal at any scale. The optimal detector has a simple approximate implementation in which edges are marked at maxima in gradient magnitude of a Gaussian-smoothed image. We extend this simple detector using operators of several widths to cope with different signal-to-noise ratios in the image. We present a general method, called feature synthesis, for the fine-to-coarse integration of information from operators at different scales. Finally we show that step edge detector performance improves considerably as the operator point spread function is extended along the edge.","['Edge detection', 'Detector', 'Operator (biology)', 'Algorithm', 'Computation', 'Image gradient', 'Computer science', 'Mathematics', 'Gaussian', 'Deriche edge detector', 'Image processing', 'Artificial intelligence', 'Image (mathematics)', 'Telecommunications', 'Biochemistry', 'Chemistry', 'Physics', 'Repressor', 'Quantum mechanics', 'Transcription factor', 'Gene']","edge detection, edge points, localization criteria, operator impulse response, numerical optimization, step edges, step edges, uncertainty principle, localization performance, feature synthesis, step edge detector performance, operator point spread function"
Paper_00231,Econometric Analysis of Cross Section and Panel Data,['Jeffrey M. Wooldridge'],2001,['Contributions to Economics'],Unknown,,,1,,10.1007/978-981-99-4902-1,"This graduate text provides an intuitive but rigorous treatment of contemporary methods used in microeconometric research. The book makes clear that applied microeconometrics is about the estimation of marginal and treatment effects, and that parametric estimation is simply a means to this end. It also clarifies the distinction between causality and statistical association. The book focuses specifically on cross section and panel data methods. Population assumptions are stated separately from sampling assumptions, leading to simple statements as well as to important insights. The unified approach to linear and nonlinear models and to cross section and panel data enables straightforward coverage of more advanced methods. The numerous end-of-chapter problems are an important component of the book. Some problems contain important points not fully described in the text, and others cover new ideas that can be analyzed using tools presented in the current and previous chapters. Several problems require the use of the data sets located at the author's website.","['Econometrics', 'Panel data', 'Estimation', 'Section (typography)', 'Causality (physics)', 'Computer science', 'Cover (algebra)', 'Simple (philosophy)', 'Component (thermodynamics)', 'Cross-sectional data', 'Parametric statistics', 'Mathematics', 'Statistics', 'Economics', 'Engineering', 'Mechanical engineering', 'Philosophy', 'Physics', 'Management', 'Epistemology', 'Quantum mechanics', 'Thermodynamics', 'Operating system']","microeconometric research, applied microeconometrics, treatment effects, parametric estimation, causality, statistical association, panel data methods, population assumptions, sampling assumptions, nonlinear models, panel data, [PAD], [PAD] [PAD], [PAD]"
Paper_00232,The central role of the propensity score in observational studies for causal effects,"['Paul R. Rosenbaum', 'Donald B. Rubin']",1983,Biometrika,Journal,,41-55,70,1,10.1093/biomet/70.1.41,"The propensity score is the conditional probability of assignment to a particular treatment given a vector of observed covariates. Both large and small sample theory show that adjustment for the scalar propensity score is sufficient to remove bias due to all observed covariates. Applications include: (i) matched sampling on the univariate propensity score, which is a generalization of discriminant matching, (ii) multivariate adjustment by subclassification on the propensity score where the same subclasses are used to estimate treatment effects for all outcome variables and in all subpopulations, and (iii) visual representation of multivariate covariance adjustment by a two- dimensional plot.","['Propensity score matching', 'Mathematics', 'Covariate', 'Statistics', 'Univariate', 'Observational study', 'Multivariate statistics', 'Econometrics', 'Matching (statistics)']","propensity score, conditional probability, small sample theory, scalar propensity score, matched sampling, univariate propensity score, discriminant matching, multivariate adjustment, propensity score, treatment effects, visual representation, multivariate covariance adjustment, [PAD] [PAD] [PAD] [PAD] [PAD], [PAD], [PAD] [PAD] [PAD] [PAD], [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD], [PAD] [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD], [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD], [PAD], [PAD] [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD] [PAD], [PAD], [PAD], [PAD] [PAD]"
Paper_00233,Use of Dinitrosalicylic Acid Reagent for Determination of Reducing Sugar,['Gail Lorenz Miller'],1959,Analytical Chemistry,Journal,,426-428,31,3,10.1021/ac60147a030,"ADVERTISEMENT RETURN TO ISSUEPREVArticleNEXTUse of Dinitrosalicylic Acid Reagent for Determination of Reducing SugarG. L. MillerCite this: Anal. Chem. 1959, 31, 3, 426–428Publication Date (Print):March 1, 1959Publication History Published online1 May 2002Published inissue 1 March 1959https://pubs.acs.org/doi/10.1021/ac60147a030https://doi.org/10.1021/ac60147a030research-articleACS PublicationsRequest reuse permissionsArticle Views45222Altmetric-Citations19440LEARN ABOUT THESE METRICSArticle Views are the COUNTER-compliant sum of full text article downloads since November 2008 (both PDF and HTML) across all institutions and individuals. These metrics are regularly updated to reflect usage leading up to the last few days.Citations are the number of other articles citing this article, calculated by Crossref and updated daily. Find more information about Crossref citation counts.The Altmetric Attention Score is a quantitative measure of the attention that a research article has received online. Clicking on the donut icon will load a page at altmetric.com with additional details about the score and the social media presence for the given article. Find more information on the Altmetric Attention Score and how the score is calculated. Share Add toView InAdd Full Text with ReferenceAdd Description ExportRISCitationCitation and abstractCitation and referencesMore Options Share onFacebookTwitterWechatLinked InRedditEmail Other access optionsGet e-Alertsclose Get e-Alerts","['Citation', 'Altmetrics', 'Icon', 'Computer science', 'Social media', 'Information retrieval', 'World Wide Web', 'Programming language']","##varticlene, dinitrosalicylic acid, ##sar, ##le views, ##le, ##f, altmetric attention score, social, altmetric attention score, ##riscitation, abstract, ##ation, references"
Paper_00234,Statistical principles in experimental design.,['B. J. WINER'],1962,McGraw-Hill Book Company,Unknown,,,,,10.1037/11774-000,CHAPTER 1: Introduction to Design CHAPTER 2: Principles of Estimation and Inference: Means and Variance CHAPTER 3: Design and Analysis of Single-Factor Experiments: Completely Randomized Design CHAPTER 4: Single-Factor Experiments Having Repeated Measures on the Same Element CHAPTER 5: Design and Analysis of Factorial Experiments: Completely-Randomized Design CHAPTER 6: Factorial Experiments: Computational Procedures and Numerical Example CHAPTER 7: Multifactor Experiments Having Repeated Measures on the Same Element CHAPTER 8: Factorial Experiments in which Some of the Interactions are Confounded CHAPTER 9: Latin Squares and Related Designs CHAPTER 10: Analysis of Covariance,['Computer science'],"estimation, inference, means, completely, factorial experiments, factorial experiments, computational procedures, numerical example, multifactor experiments, factorial experiments, latin squares, covariance, [PAD] [PAD], [PAD] [PAD], [PAD]"
Paper_00235,The MOS 36-ltem Short-Form Health Survey (SF-36),"['John E. Ware', 'Cathy D. Sherbourne']",1992,Medical Care,Journal,,473-483,30,6,10.1097/00005650-199206000-00002,"A 36-item short-form (SF-36) was constructed to survey health status in the Medical Outcomes Study. The SF-36 was designed for use in clinical practice and research, health policy evaluations, and general population surveys. The SF-36 includes one multi-item scale that assesses eight health concepts: 1) limitations in physical activities because of health problems; 2) limitations in social activities because of physical or emotional problems; 3) limitations in usual role activities because of physical health problems; 4) bodily pain; 5) general mental health (psychological distress and well-being); 6) limitations in usual role activities because of emotional problems; 7) vitality (energy and fatigue); and 8) general health perceptions. The survey was constructed for self-administration by persons 14 years of age and older, and for administration by a trained interviewer in person or by telephone. The history of the development of the SF-36, the origin of specific items, and the logic underlying their selection are summarized. The content and features of the SF-36 are compared with the 20-item Medical Outcomes Study short-form.","['Vitality', 'SF-36', 'Mental health', 'Psychology', 'Scale (ratio)', 'Emotional distress', 'Gerontology', 'Population', 'Clinical psychology', 'Medicine', 'Psychiatry', 'Health related quality of life', 'Anxiety', 'Disease', 'Environmental health', 'Physics', 'Theology', 'Pathology', 'Quantum mechanics', 'Philosophy']","health status, medical outcomes study, clinical practice, health policy evaluations, general population surveys, social activities, bodily pain, general mental health, vitality, general health perceptions, medical outcomes"
Paper_00236,Particle mesh Ewald: An <i>N</i>⋅log(<i>N</i>) method for Ewald sums in large systems,"['Tom Darden', 'Darrin M. York', 'Lee G. Pedersen']",1993,The Journal of Chemical Physics,Journal,,10089-10092,98,12,10.1063/1.464397,An N⋅log(N) method for evaluating electrostatic energies and forces of large periodic systems is presented. The method is based on interpolation of the reciprocal space Ewald sums and evaluation of the resulting convolutions using fast Fourier transforms. Timings and accuracies are presented for three large crystalline ionic systems.,"['Ewald summation', 'Interpolation (computer graphics)', 'Fast Fourier transform', 'Space (punctuation)', 'Mathematics', 'Reciprocal lattice', 'Reciprocal', 'Physics', 'Mathematical analysis', 'Algorithm', 'Computer science', 'Classical mechanics', 'Optics', 'Molecular dynamics', 'Quantum mechanics', 'Diffraction', 'Philosophy', 'Operating system', 'Motion (physics)', 'Linguistics']","electrostatic energies, forces, large periodic systems, reciprocal space ewald sums, convolutions, fast fourier transforms, large crystalline ionic systems, [PAD], [PAD], [PAD], [PAD], [PAD] [PAD], [PAD], [PAD], [PAD] [PAD], [PAD] [PAD], [PAD], [PAD], [PAD], [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD], [PAD], [PAD] [PAD]"
Paper_00238,Semiempirical GGA‐type density functional constructed with a long‐range dispersion correction,['Stefan Grimme'],2006,Journal of Computational Chemistry,Journal,,1787-1799,27,15,10.1002/jcc.20495,"A new density functional (DF) of the generalized gradient approximation (GGA) type for general chemistry applications termed B97-D is proposed. It is based on Becke's power-series ansatz from 1997 and is explicitly parameterized by including damped atom-pairwise dispersion corrections of the form C(6) x R(-6). A general computational scheme for the parameters used in this correction has been established and parameters for elements up to xenon and a scaling factor for the dispersion part for several common density functionals (BLYP, PBE, TPSS, B3LYP) are reported. The new functional is tested in comparison with other GGAs and the B3LYP hybrid functional on standard thermochemical benchmark sets, for 40 noncovalently bound complexes, including large stacked aromatic molecules and group II element clusters, and for the computation of molecular geometries. Further cross-validation tests were performed for organometallic reactions and other difficult problems for standard functionals. In summary, it is found that B97-D belongs to one of the most accurate general purpose GGAs, reaching, for example for the G97/2 set of heat of formations, a mean absolute deviation of only 3.8 kcal mol(-1). The performance for noncovalently bound systems including many pure van der Waals complexes is exceptionally good, reaching on the average CCSD(T) accuracy. The basic strategy in the development to restrict the density functional description to shorter electron correlation lengths scales and to describe situations with medium to large interatomic distances by damped C(6) x R(-6) terms seems to be very successful, as demonstrated for some notoriously difficult reactions. As an example, for the isomerization of larger branched to linear alkanes, B97-D is the only DF available that yields the right sign for the energy difference. From a practical point of view, the new functional seems to be quite robust and it is thus suggested as an efficient and accurate quantum chemical method for large systems where dispersion forces are of general importance.","['Density functional theory', 'Parameterized complexity', 'Ansatz', 'London dispersion force', 'van der Waals force', 'Orbital-free density functional theory', 'Dispersion (optics)', 'Thermochemistry', 'Hybrid functional', 'Basis set', 'Scaling', 'Physics', 'Standard deviation', 'Computational chemistry', 'Chemistry', 'Range (aeronautics)', 'Type (biology)', 'Statistical physics', 'Thermodynamics', 'Molecule', 'Materials science', 'Quantum mechanics', 'Mathematics', 'Geometry', 'Algorithm', 'Ecology', 'Statistics', 'Biology', 'Composite material']","density functional, generalized gradient approximation, general chemistry, scaling factor, the, ##mic, noncovalently bound complexes, large stacked aromatic molecules, molecular geometries, organome, ##lic reactions, quantum chemical, dispersion forces"
Paper_00240,Rethinking the Inception Architecture for Computer Vision,"['Christian Szegedy', 'Vincent Vanhoucke', 'Sergey Ioffe', 'Jon Shlens', 'Zbigniew Wojna']",2016,Unknown,Unknown,,2818-2826,,,10.1109/cvpr.2016.308,"Convolutional networks are at the core of most state of-the-art computer vision solutions for a wide variety of tasks. Since 2014 very deep convolutional networks started to become mainstream, yielding substantial gains in various benchmarks. Although increased model size and computational cost tend to translate to immediate quality gains for most tasks (as long as enough labeled data is provided for training), computational efficiency and low parameter count are still enabling factors for various use cases such as mobile vision and big-data scenarios. Here we are exploring ways to scale up networks in ways that aim at utilizing the added computation as efficiently as possible by suitably factorized convolutions and aggressive regularization. We benchmark our methods on the ILSVRC 2012 classification challenge validation set demonstrate substantial gains over the state of the art: 21:2% top-1 and 5:6% top-5 error for single frame evaluation using a network with a computational cost of 5 billion multiply-adds per inference and with using less than 25 million parameters. With an ensemble of 4 models and multi-crop evaluation, we report 3:5% top-5 error and 17:3% top-1 error on the validation set and 3:6% top-5 error on the official test set.","['Computer science', 'Benchmark (surveying)', 'Inference', 'Computation', 'Artificial intelligence', 'Machine learning', 'Set (abstract data type)', 'Convolutional neural network', 'Test set', 'Computational complexity theory', 'Regularization (linguistics)', 'Benchmarking', 'Computer engineering', 'Algorithm', 'Geodesy', 'Programming language', 'Geography', 'Marketing', 'Business']","convolutional networks, computer, convolutional networks, computational cost, computational efficiency, parameter count, mobile vision, factorized con, aggressive regularization, ilsvr, classification challenge validation, single frame evaluation"
Paper_00241,"Cancer incidence and mortality worldwide: Sources, methods and major patterns in GLOBOCAN 2012","['Jacques Ferlay', 'Isabelle Soerjomataram', 'Rajesh Dikshit', 'Sultan Eser', 'Colin Mathers', 'Marise Souto Rebelo', 'Donald Maxwell Parkin', 'David Forman', 'Freddie Bray']",2014,International Journal of Cancer,Journal,,,136,5,10.1002/ijc.29210,"Estimates of the worldwide incidence and mortality from 27 major cancers and for all cancers combined for 2012 are now available in the GLOBOCAN series of the International Agency for Research on Cancer. We review the sources and methods used in compiling the national cancer incidence and mortality estimates, and briefly describe the key results by cancer site and in 20 large ""areas"" of the world. Overall, there were 14.1 million new cases and 8.2 million deaths in 2012. The most commonly diagnosed cancers were lung (1.82 million), breast (1.67 million), and colorectal (1.36 million); the most common causes of cancer death were lung cancer (1.6 million deaths), liver cancer (745,000 deaths), and stomach cancer (723,000 deaths).","['Cancer', 'Medicine', 'Incidence (geometry)', 'Lung cancer', 'Breast cancer', 'Colorectal cancer', 'International agency', 'Mortality rate', 'Demography', 'Stomach cancer', 'Cause of death', 'Causes of cancer', 'Cancer incidence', 'Cancer registry', 'Oncology', 'Internal medicine', 'Disease', 'Physics', 'Sociology', 'Optics']","globocan, national, breast, colorectal, lung cancer, liver cancer, stomach cancer, [PAD]"
Paper_00242,Reinforcement Learning: An Introduction,"['Richard S. Sutton', 'Andy Barto']",2005,IEEE Transactions on Neural Networks,Journal,,285-286,16,1,10.1109/tnn.2004.842673,"Reinforcement learning, one of the most active research areas in artificial intelligence, is a computational approach to learning whereby an agent tries to maximize the total amount of reward it receives when interacting with a complex, uncertain environment. In Reinforcement Learning, Richard Sutton and Andrew Barto provide a clear and simple account of the key ideas and algorithms of reinforcement learning. Their discussion ranges from the history of the field's intellectual foundations to the most recent developments and applications. The only necessary mathematical background is familiarity with elementary concepts of probability. The book is divided into three parts. Part I defines the reinforcement learning problem in terms of Markov decision processes. Part II provides basic solution methods: dynamic programming, Monte Carlo methods, and temporal-difference learning. Part III presents a unified view of the solution methods and incorporates artificial neural networks, eligibility traces, and planning; the two final chapters present case studies and consider the future of reinforcement learning.","['Reinforcement learning', 'Computer science', 'Artificial intelligence', 'Reinforcement', 'Machine learning', 'Engineering', 'Structural engineering']","reinforcement learning, artificial intelligence, reinforcement learning, reinforcement learning, probability, reinforcement learning problem, markov decision processes, dynamic programming, monte carlo methods, artificial neural networks, eligibility traces, planning, reinforcement learning, [PAD], [PAD] [PAD] [PAD], [PAD], [PAD] [PAD], [PAD], [PAD], [PAD], [PAD], [PAD] [PAD], [PAD] [PAD], [PAD] [PAD] [PAD] [PAD], [PAD], [PAD] [PAD], [PAD] [PAD] [PAD], [PAD]"
Paper_00243,Classification of Surgical Complications,"['Daniel Dindo', 'Nicolas Demartines', 'Pierre-Alain Clavien']",2004,Annals of Surgery,Journal,,205-213,240,2,10.1097/01.sla.0000133083.54934.ae,"In Brief Objective: Although quality assessment is gaining increasing attention, there is still no consensus on how to define and grade postoperative complications. This shortcoming hampers comparison of outcome data among different centers and therapies and over time. Patients and Methods: A classification of complications published by one of the authors in 1992 was critically re-evaluated and modified to increase its accuracy and its acceptability in the surgical community. Modifications mainly focused on the manner of reporting life-threatening and permanently disabling complications. The new grading system still mostly relies on the therapy used to treat the complication. The classification was tested in a cohort of 6336 patients who underwent elective general surgery at our institution. The reproducibility and personal judgment of the classification were evaluated through an international survey with 2 questionnaires sent to 10 surgical centers worldwide. Results: The new ranking system significantly correlated with complexity of surgery (P < 0.0001) as well as with the length of the hospital stay (P < 0.0001). A total of 144 surgeons from 10 different centers around the world and at different levels of training returned the survey. Ninety percent of the case presentations were correctly graded. The classification was considered to be simple (92% of the respondents), reproducible (91%), logical (92%), useful (90%), and comprehensive (89%). The answers of both questionnaires were not dependent on the origin of the reply and the level of training of the surgeons. Conclusions: The new complication classification appears reliable and may represent a compelling tool for quality assessment in surgery in all parts of the world. The lack of a uniform way of reporting complications hampers interpretation of surgical outcome data and quality assessment. The authors revisited a previously reported classification of complications and propose a new grading system. The new classification was tested in a cohort of 6336 patients undergoing general surgery and through an international survey.","['Medicine', 'Grading (engineering)', 'Complication', 'Cohort', 'Academic institution', 'Ranking (information retrieval)', 'MEDLINE', 'Surgery', 'General surgery', 'Internal medicine', 'Civil engineering', 'Library science', 'Computer science', 'Engineering', 'Machine learning', 'Law', 'Political science']","quality assessment, postoperative complications, elective general surgery, personal judgment, quality assessment, quality assessment"
Paper_00244,Econometric Analysis of Cross Section and Panel Data,['Jeffrey M. Wooldridge'],2001,['Contributions to Economics'],Unknown,,,,,10.1007/978-981-99-4902-1,"The second edition of this acclaimed graduate text provides a unified treatment of two methods used in contemporary econometric research, cross section and data panel methods. By focusing on assumptions that can be given behavioral content, the book maintains an appropriate level of rigor while emphasizing intuitive thinking. The analysis covers both linear and nonlinear models, including models with dynamics and/or individual heterogeneity. In addition to general estimation frameworks (particular methods of moments and maximum likelihood), specific linear and nonlinear methods are covered in detail, including probit and logit models and their multivariate, Tobit models, models for count data, censored and missing data schemes, causal (or treatment) effects, and duration analysis. Econometric Analysis of Cross Section and Panel Data was the first graduate econometrics text to focus on microeconomic data structures, allowing assumptions to be separated into population and sampling assumptions. This second edition has been substantially updated and revised. Improvements include a broader class of models for missing data problems; more detailed treatment of cluster problems, an important topic for empirical researchers; expanded discussion of generalized instrumental variables (GIV) estimation; new coverage (based on the author's own recent research) of inverse probability weighting; a more complete framework for estimating treatment effects with panel data, and a firmly established link between econometric approaches to nonlinear panel data and the generalized estimating equation literature popular in statistics and other fields. New attention is given to explaining when particular econometric methods can be applied; the goal is not only to tell readers what does work, but why certain obvious procedures do not. The numerous included exercises, both theoretical and computer-based, allow the reader to extend methods covered in the text and discover new insights.","['Econometrics', 'Logit', 'Econometric model', 'Panel data', 'Inverse probability weighting', 'Missing data', 'Probit', 'Computer science', 'Statistics', 'Economics', 'Mathematics', 'Estimator']","econometric research, cross, data panel methods, maximum likelihood, probit, logit, tobit, count data, causal, duration analysis, microeconomic data structures, sampling, missing data, cluster problems, generalized instrumental variables, gi, inverse probability weighting, nonlinear panel data, generalized estimating equation, [PAD], [PAD], [PAD], [PAD], [PAD]"
Paper_00246,The Presentation of Self in Everyday Life.,"['Kaspar D. Naegele', 'Erving Goffman']",1956,American Sociological Review,Journal,,631-631,21,5,10.2307/2089106,"hen an individual enters the presence of oth ers, they commonly seek to acquire information about him or to bring into play information about him already possessed. They will be interested in his general socio-economic status, his concep tion of self, his attitude toward them, his compe tence, his trustworthiness, etc. Although some of this information seems to be sought almost as an end in itself, there are usually quite practical reasons for acquiring it. Information about the individual helps to define the situation, enabling others to know in advance what he will expect of them and what they may expect of him. Informed in these ways, the others will know how best to act in order to call forth a desired response from him. For those present, many sources of information become accessible and many carriers (or “signvehicles”) become available for conveying this information. If unacquainted with the individual, observers can glean clues from his conduct and appearance which allow them to apply their previ ous experience with individuals roughly similar to the one before them or, more important, to apply untested stereotypes to him. They can also assume from past experience that only individuals of a par ticular kind are likely to be found in a given social setting. They can rely on what the individual says about himself or on documentary evidence he provides as to who and what he is. If they know, or know of, the individual by virtue of experience prior to the interaction, they can rely on assumptions as to the persistence and generality of psychological traits as a means of predicting his present and future behavior. However, during the period in which the indi vidual is in the immediate presence of the others, few events may occur which directly provide the others with the conclusive information they will need if they are to direct wisely their own activity . Many crucial facts lie beyond the time and place of interaction or lie concealed within it. For example, the “true” or “real” attitudes, beliefs, and emotions of the individual can be ascertained only indirectly , through his avowals or through what appears to be involuntary expressive behavior. Similarly , if the individual offers the others a product or service, they will often find that during the interaction there will be no time and place immediately available for eating the pudding that the proof can be found in. They will be forced to accept some events as con ventional or natural signs of something not directly available to the senses. In Ichheiser ’s terms, 1 the individual will have to act so that he intentionally or unintentionally expresses himself, and the others will in turn have to be impressed in some way by him.…","['Everyday life', 'Presentation (obstetrics)', 'Psychology', 'Sociology', 'Epistemology', 'Medicine', 'Philosophy', 'Radiology']","trust, signve, involuntary expressive behavior"
Paper_00247,"Institutions, Institutional Change and Economic Performance","['Michael C. Munger', 'Douglass C. North']",1991,Southern Economic Journal,Journal,,296-296,58,1,10.2307/1060065,"Examines the role that institutions, defined as the humanly devised constraints that shape human interaction, play in economic performance and how those institutions change and how a model of dynamic institutions explains the differential performance of economies through time. Institutions are separate from organizations, which are assemblages of people directed to strategically operating within institutional constraints. Institutions affect the economy by influencing, together with technology, transaction and production costs. They do this by reducing uncertainty in human interaction, albeit not always efficiently. Entrepreneurs accomplish incremental changes in institutions by perceiving opportunities to do better through altering the institutional framework of political and economic organizations. Importantly, the ability to perceive these opportunities depends on both the completeness of information and the mental constructs used to process that information. Thus, institutions and entrepreneurs stand in a symbiotic relationship where each gives feedback to the other. Neoclassical economics suggests that inefficient institutions ought to be rapidly replaced. This symbiotic relationship helps explain why this theoretical consequence is often not observed: while this relationship allows growth, it also allows inefficient institutions to persist. The author identifies changes in relative prices and prevailing ideas as the source of institutional alterations. Transaction costs, however, may keep relative price changes from being fully exploited. Transaction costs are influenced by institutions and institutional development is accordingly path-dependent. (CAR)","['Economics', 'Institutional change', 'Economic system', 'Business', 'Political science', 'Public administration']","institutions, economic performance, dynamic institutions, institutions, organizations, institutional constraints, institutions, production costs, institutional framework, entrepreneurs, neoclassical economics, inefficient institutions, ##nt, relative prices, transaction costs, transaction costs, institutional development"
Paper_00248,"The M06 suite of density functionals for main group thermochemistry, thermochemical kinetics, noncovalent interactions, excited states, and transition elements: two new functionals and systematic testing of four M06-class functionals and 12 other functionals","['Yan Zhao', 'Donald G. Truhlar']",2007,Theoretical Chemistry Accounts,Journal,,215-241,120,1-3,10.1007/s00214-007-0310-x,"We present two new hybrid meta exchange- correlation functionals, called M06 and M06-2X. The M06 functional is parametrized including both transition metals and nonmetals, whereas the M06-2X functional is a high-nonlocality functional with double the amount of nonlocal exchange (2X), and it is parametrized only for nonmetals.The functionals, along with the previously published M06-L local functional and the M06-HF full-Hartree–Fock functionals, constitute the M06 suite of complementary functionals. We assess these four functionals by comparing their performance to that of 12 other functionals and Hartree–Fock theory for 403 energetic data in 29 diverse databases, including ten databases for thermochemistry, four databases for kinetics, eight databases for noncovalent interactions, three databases for transition metal bonding, one database for metal atom excitation energies, and three databases for molecular excitation energies. We also illustrate the performance of these 17 methods for three databases containing 40 bond lengths and for databases containing 38 vibrational frequencies and 15 vibrational zero point energies. We recommend the M06-2X functional for applications involving main-group thermochemistry, kinetics, noncovalent interactions, and electronic excitation energies to valence and Rydberg states. We recommend the M06 functional for application in organometallic and inorganometallic chemistry and for noncovalent interactions.","['Thermochemistry', 'Density functional theory', 'Valence (chemistry)', 'Excited state', 'Hybrid functional', 'Chemistry', 'Transition metal', 'Non-covalent interactions', 'Coupled cluster', 'Computational chemistry', 'Atomic physics', 'Physical chemistry', 'Molecule', 'Physics', 'Hydrogen bond', 'Organic chemistry', 'Catalysis']","non, complementary functionals, thermochemistry, kinetics, noncovalent interactions, transition metal bonding, metal atom excitation energies, molecular excitation energies, bond, vibrational frequencies, vibrational zero point, noncovalent interactions, electronic excitation energies, rydberg states, organ, inorganometallic chemistry, noncovalent interactions"
Paper_00249,"Institutions, Institutional Change and Economic Performance",['Douglass C. North'],1990,Unknown,Unknown,,,,,10.1017/cbo9780511808678,"Continuing his groundbreaking analysis of economic structures, Douglass North develops an analytical framework for explaining the ways in which institutions and institutional change affect the performance of economies, both at a given time and over time. Institutions exist, he argues, due to the uncertainties involved in human interaction; they are the constraints devised to structure that interaction. Yet, institutions vary widely in their consequences for economic performance; some economies develop institutions that produce growth and development, while others develop institutions that produce stagnation. North first explores the nature of institutions and explains the role of transaction and production costs in their development. The second part of the book deals with institutional change. Institutions create the incentive structure in an economy, and organisations will be created to take advantage of the opportunities provided within a given institutional framework. North argues that the kinds of skills and knowledge fostered by the structure of an economy will shape the direction of change and gradually alter the institutional framework. He then explains how institutional development may lead to a path-dependent pattern of development. In the final part of the book, North explains the implications of this analysis for economic theory and economic history. He indicates how institutional analysis must be incorporated into neo-classical theory and explores the potential for the construction of a dynamic theory of long-term economic change. Douglass C. North is Director of the Center of Political Economy and Professor of Economics and History at Washington University in St. Louis. He is a past president of the Economic History Association and Western Economics Association and a Fellow, American Academy of Arts and Sciences. He has written over sixty articles for a variety of journals and is the author of The Rise of the Western World: A New Economic History (CUP, 1973, with R.P. Thomas) and Structure and Change in Economic History (Norton, 1981). Professor North is included in Great Economists Since Keynes edited by M. Blaug (CUP, 1988 paperback ed.)","['Incentive', 'Transaction cost', 'Institutional change', 'New institutional economics', 'Politics', 'Institutional analysis', 'Path dependence', 'Political science', 'Institutional economics', 'Economic system', 'Economics', 'Economy', 'Political economy', 'Neoclassical economics', 'Public administration', 'Market economy', 'Sociology', 'Social science', 'Finance', 'Law']","economic structures, institutions, institutional change, production costs, institutional change, incentive structure, institutional development, economic theory, economic history, institutional analysis, economic history, great economists"
Paper_00251,The PRISMA Statement for Reporting Systematic Reviews and Meta-Analyses of Studies That Evaluate Health Care Interventions: Explanation and Elaboration,"['Alessandro Liberati', 'Douglas G. Altman', 'Jennifer Tetzlaff', 'Cynthia D. Mulrow', 'Peter C Gøtzsche', 'John P. A. Ioannidis', 'Mike Clarke', 'P.J. Devereaux', 'Jos Kleijnen', 'David Moher']",2009,PLoS Medicine,Journal,,e1000100-e1000100,6,7,10.1371/journal.pmed.1000100,"Systematic reviews and meta-analyses are essential to summarize evidence relating to efficacy and safety of health care interventions accurately and reliably. The clarity and transparency of these reports, however, is not optimal. Poor reporting of systematic reviews diminishes their value to clinicians, policy makers, and other users.Since the development of the QUOROM (QUality Of Reporting Of Meta-analysis) Statement--a reporting guideline published in 1999--there have been several conceptual, methodological, and practical advances regarding the conduct and reporting of systematic reviews and meta-analyses. Also, reviews of published systematic reviews have found that key information about these studies is often poorly reported. Realizing these issues, an international group that included experienced authors and methodologists developed PRISMA (Preferred Reporting Items for Systematic reviews and Meta-Analyses) as an evolution of the original QUOROM guideline for systematic reviews and meta-analyses of evaluations of health care interventions.The PRISMA Statement consists of a 27-item checklist and a four-phase flow diagram. The checklist includes items deemed essential for transparent reporting of a systematic review. In this Explanation and Elaboration document, we explain the meaning and rationale for each checklist item. For each item, we include an example of good reporting and, where possible, references to relevant empirical studies and methodological literature. The PRISMA Statement, this document, and the associated Web site (http://www.prisma-statement.org/) should be helpful resources to improve reporting of systematic reviews and meta-analyses.","['Systematic review', 'Checklist', 'Psychological intervention', 'Guideline', 'MEDLINE', 'Health care', 'Medicine', 'CLARITY', 'Psychology', 'Management science', 'Nursing', 'Pathology', 'Political science', 'Law', 'Economics', 'Cognitive psychology', 'Biochemistry', 'Chemistry']","systematic reviews, health care interventions, systematic reviews, quorom, prisma, quo, health care interventions, prism, prism"
Paper_00254,"The ""What"" and ""Why"" of Goal Pursuits: Human Needs and the Self-Determination of Behavior","['Edward L. Deci', 'Richard M. Ryan']",2000,Psychological Inquiry,Journal,,227-268,11,4,10.1207/s15327965pli1104_01,"Abstract Self-determination theory (SDT) maintains that an understanding of human motivation requires a consideration of innate psychological needs for competence, autonomy, and relatedness. We discuss the SDT concept of needs as it relates to previous need theories, emphasizing that needs specify the necessary conditions for psychological growth, integrity, and well-being. This concept of needs leads to the hypotheses that different regulatory processes underlying goal pursuits are differentially associated with effective functioning and well-being and also that different goal contents have different relations to the quality of behavior and mental health, specifically because different regulatory processes and different goal contents are associated with differing degrees of need satisfaction. Social contexts and individual differences that support satisfaction of the basic needs facilitate natural growth processes including intrinsically motivated behavior and integration of extrinsic motivations, whereas those that forestall autonomy, competence, or relatedness are associated with poorer motivation, performance, and well-being. We also discuss the relation of the psychological needs to cultural values, evolutionary processes, and other contemporary motivation theories.","['Self-determination theory', 'Psychology', 'Autonomy', 'Competence (human resources)', 'Fundamental human needs', 'Social psychology', 'Need theory', 'Basic needs', ""Maslow's hierarchy of needs"", 'Natural (archaeology)', 'Poverty', 'Archaeology', 'Political science', 'Law', 'Economics', 'History', 'Economic growth']","human motivation, innate psychological needs, competence, autonomy, relatedness, sdt, needs, need, psychological growth, integrity, needs, regulatory processes, goal pursuits, mental health, social contexts, individual differences, intrinsically motivated behavior, extrinsic motivations, autonomy, competence, relatedness, performance, psychological needs, cultural values, evolutionary processes"
Paper_00255,Imagined Communities. Reflections on the Origin and Spread of Nationalism.,"['Anthony Reid', 'Benedict Anderson']",1985,Pacific Affairs,Journal,,497-497,58,3,10.2307/2759245,"What makes people love and die for nations, as well as hate and kill in their name? While many studies have been written on nationalist political movements, the sense of nationality - the personal and cultural feeling of belonging to the nation - has not received proportionate attention. In this widely acclaimed work, Benedict Anderson examines the creation and global spread of the 'imagined communities' of nationality. Anderson explores the processes that created these communities: the territorialisation of religious faiths, the decline of antique kingship, the interaction between capitalism and print, the development of vernacular languages-of-state, and changing conceptions of time. He shows how an originary nationalism born in the Americas was modularly adopted by popular movements in Europe, by the imperialist powers, and by the anti-imperialist resistances in Asia and Africa. This revised edition includes two new chapters, one of which discusses the complex role of the colonialist state's mindset in the development of Third World nationalism, while the other analyses the processes by which all over the world, nations came to imagine themselves as old.","['Nationalism', 'Political science', 'Geography', 'Economic geography', 'Law', 'Politics']","nationalist political movements, imagined communities, nationality, religious faiths, antique kingship, originary nationalism, americas, europe, imperial, third world nationalism"
Paper_00256,"Methods for Dietary Fiber, Neutral Detergent Fiber, and Nonstarch Polysaccharides in Relation to Animal Nutrition","['P.J. Van Soest', 'James B. Robertson', 'B.A. Lewis']",1991,Journal of Dairy Science,Journal,,3583-3597,74,10,10.3168/jds.s0022-0302(91)78551-2,"There is a need to standardize the NDF procedure.Procedures have varied because of the use of different amylases in attempts to remove starch interference.'Ihe original Bacillus subtilis enzyme Type IIIA (XIA) no longer is available and has been replaced by a less effective enzyme.For fiber work, a new enzyme' has received AOAC approval and is rapidly displacing other amylases in analyt- ical work.This enzyme is available from Sigma (Number A3306, Sigma Chemical Co., St. Louis, MO).The original publications for NDF and ADF (43, 53) and the Agricultural Handbook 379 (14) are obsolete and of historical interest only.Up to date procedures should be followed.Tnethylene glycol has replaced 2-ethoxyethanol because of reported toxicity.Considerable development in regard to fiber methods has occurred over the past 5 yr because of a redefinition of dietary fiber for man and monogastric animals that includes lignin and all polysaccharides resistant to mammalian digestive enzymes.In addition to NDF, new improved methods for total dietary fiber and nonstarch polysaccharides including pectin and B-glucans now are available.The latter are also of interest in rumen fermentation.Unlike starch.","['Polysaccharide', 'Pectin', 'Starch', 'Rumen', 'Dietary fiber', 'Amylase', 'Food science', 'Fermentation', 'Enzyme', 'Lignin', 'Fiber', 'Digestion (alchemy)', 'Bacillus subtilis', 'Monogastric', 'Biochemistry', 'Chemistry', 'Animal nutrition', 'Biology', 'Agronomy', 'Botany', 'Chromatography', 'Crop', 'Bacteria', 'Organic chemistry', 'Genetics']","ndf, ##lase, starch interference, bacillus subtilis enzyme, sigma, agricultural handbook, tnethylene glycol, fiber methods, dietary fiber, monogastric animals, lignin, mammalian digestive enzymes, total dietary fiber, nonstarch polysa, pectin, rumen fermentation, [PAD]"
Paper_00257,"Global cancer statistics, 2012","['Lindsey A. Torre', 'Freddie Bray', 'Rebecca L. Siegel', 'Jacques Ferlay', 'Joannie Lortet‐Tieulent', 'Ahmedin Jemal']",2015,CA A Cancer Journal for Clinicians,Journal,,87-108,65,2,10.3322/caac.21262,"Abstract Cancer constitutes an enormous burden on society in more and less economically developed countries alike. The occurrence of cancer is increasing because of the growth and aging of the population, as well as an increasing prevalence of established risk factors such as smoking, overweight, physical inactivity, and changing reproductive patterns associated with urbanization and economic development. Based on GLOBOCAN estimates, about 14.1 million new cancer cases and 8.2 million deaths occurred in 2012 worldwide. Over the years, the burden has shifted to less developed countries, which currently account for about 57% of cases and 65% of cancer deaths worldwide. Lung cancer is the leading cause of cancer death among males in both more and less developed countries, and has surpassed breast cancer as the leading cause of cancer death among females in more developed countries; breast cancer remains the leading cause of cancer death among females in less developed countries. Other leading causes of cancer death in more developed countries include colorectal cancer among males and females and prostate cancer among males. In less developed countries, liver and stomach cancer among males and cervical cancer among females are also leading causes of cancer death. Although incidence rates for all cancers combined are nearly twice as high in more developed than in less developed countries in both males and females, mortality rates are only 8% to 15% higher in more developed countries. This disparity reflects regional differences in the mix of cancers, which is affected by risk factors and detection practices, and/or the availability of treatment. Risk factors associated with the leading causes of cancer death include tobacco use (lung, colorectal, stomach, and liver cancer), overweight/obesity and physical inactivity (breast and colorectal cancer), and infection (liver, stomach, and cervical cancer). A substantial portion of cancer cases and deaths could be prevented by broadly applying effective prevention measures, such as tobacco control, vaccination, and the use of early detection tests. CA Cancer J Clin 2015;65: 87–108. © 2015 American Cancer Society.","['Medicine', 'Cancer', 'Statistics', 'Internal medicine', 'Mathematics']","abstract cancer, smoking, overweight, physical inactivity, economic development, lung cancer, breast cancer, breast cancer, colorectal cancer, prostate cancer, stomach cancer, cervical cancer, tobacco use, liver cancer, physical ina, cervical cancer, tobacco control, vaccination, early detection tests, american cancer society"
Paper_00258,The SILVA ribosomal RNA gene database project: improved data processing and web-based tools,"['Christian Quast', 'Elmar Pruesse', 'Pelin Yilmaz', 'Jan Gerken', 'Timmy Schweer', 'Pablo Yarza', 'Jörg Peplies', 'Frank Oliver Glöckner']",2012,Nucleic Acids Research,Journal,,D590-D596,41,D1,10.1093/nar/gks1219,"SILVA (from Latin silva, forest, http://www.arb-silva.de) is a comprehensive web resource for up to date, quality-controlled databases of aligned ribosomal RNA (rRNA) gene sequences from the Bacteria, Archaea and Eukaryota domains and supplementary online services. The referred database release 111 (July 2012) contains 3 194 778 small subunit and 288 717 large subunit rRNA gene sequences. Since the initial description of the project, substantial new features have been introduced, including advanced quality control procedures, an improved rRNA gene aligner, online tools for probe and primer evaluation and optimized browsing, searching and downloading on the website. Furthermore, the extensively curated SILVA taxonomy and the new non-redundant SILVA datasets provide an ideal reference for high-throughput classification of data from next-generation sequencing approaches.","['Biology', 'Ribosomal RNA', 'Upload', 'Gene', 'Computational biology', 'Archaea', 'Database', 'Genetics', 'Computer science', 'World Wide Web']","silva, aligned ribosomal rna, eukar, quality control procedures, ##na gene aligner, silva taxonomy"
Paper_00259,Adsorption of Gases in Multimolecular Layers,"['Stephen Brunauer', 'P. H. Emmett', 'Edward Teller']",1938,Journal of the American Chemical Society,Journal,,309-319,60,2,10.1021/ja01269a023,"ADVERTISEMENT RETURN TO ISSUEPREVArticleNEXTAdsorption of Gases in Multimolecular LayersStephen Brunauer, P. H. Emmett, and Edward TellerCite this: J. Am. Chem. Soc. 1938, 60, 2, 309–319Publication Date (Print):February 1, 1938Publication History Published online1 May 2002Published inissue 1 February 1938https://pubs.acs.org/doi/10.1021/ja01269a023https://doi.org/10.1021/ja01269a023research-articleACS PublicationsRequest reuse permissionsArticle Views46810Altmetric-Citations21813LEARN ABOUT THESE METRICSArticle Views are the COUNTER-compliant sum of full text article downloads since November 2008 (both PDF and HTML) across all institutions and individuals. These metrics are regularly updated to reflect usage leading up to the last few days.Citations are the number of other articles citing this article, calculated by Crossref and updated daily. Find more information about Crossref citation counts.The Altmetric Attention Score is a quantitative measure of the attention that a research article has received online. Clicking on the donut icon will load a page at altmetric.com with additional details about the score and the social media presence for the given article. Find more information on the Altmetric Attention Score and how the score is calculated. Share Add toView InAdd Full Text with ReferenceAdd Description ExportRISCitationCitation and abstractCitation and referencesMore Options Share onFacebookTwitterWechatLinked InRedditEmail Other access optionsGet e-Alertsclose Get e-Alerts","['Citation', 'Icon', 'Computer science', 'Social media', 'Altmetrics', 'Reuse', 'Information retrieval', 'Library science', 'World Wide Web', 'Engineering', 'Programming language', 'Waste management']","##varticlene, ##or, multimolecular layers, ##sar, ##le views, ##le, ##f, altmetric attention score, social, altmetric attention score, ##citation, abstract, ##ation, references"
Paper_00260,"<i>OLEX2</i>: a complete structure solution, refinement and analysis program","['Oleg V. Dolomanov', 'Luc J. Bourhis', 'Richard J. Gildea', 'Judith A. K. Howard', 'Horst Puschmann']",2009,Journal of Applied Crystallography,Journal,,339-341,42,2,10.1107/s0021889808042726,"New software, OLEX2 , has been developed for the determination, visualization and analysis of molecular crystal structures. The software has a portable mouse-driven workflow-oriented and fully comprehensive graphical user interface for structure solution, refinement and report generation, as well as novel tools for structure analysis. OLEX2 seamlessly links all aspects of the structure solution, refinement and publication process and presents them in a single workflow-driven package, with the ultimate goal of producing an application which will be useful to both chemists and crystallographers.","['Workflow', 'Computer science', 'Visualization', 'Software', 'Computational science', 'Graphical user interface', 'Interface (matter)', 'Process (computing)', 'Programming language', 'Software engineering', 'Data mining', 'Database', 'Operating system', 'Bubble', 'Maximum bubble pressure method']","olex2, molecular crystal structures, graphical user interface, structure solution, ##ment, report generation, structure analysis, olex2, publication"
Paper_00263,Features and development of <i>Coot</i>,"['Paul Emsley', 'Bernhard Lohkamp', 'W. G. Scott', 'Kevin Cowtan']",2010,Acta Crystallographica Section D Biological Crystallography,Journal,,486-501,66,4,10.1107/s0907444910007493,"Coot is a molecular-graphics application for model building and validation of biological macromolecules. The program displays electron-density maps and atomic models and allows model manipulations such as idealization, real-space refinement, manual rotation/translation, rigid-body fitting, ligand search, solvation, mutations, rotamers and Ramachandran idealization. Furthermore, tools are provided for model validation as well as interfaces to external programs for refinement, validation and graphics. The software is designed to be easy to learn for novice users, which is achieved by ensuring that tools for common tasks are 'discoverable' through familiar user-interface elements (menus and toolbars) or by intuitive behaviour (mouse controls). Recent developments have focused on providing tools for expert users, with customisable key bindings, extensions and an extensive scripting interface. The software is under rapid development, but has already achieved very widespread use within the crystallographic community. The current state of the software is presented, with a description of the facilities available and of some of the underlying methods employed.","['Computer science', 'Scripting language', 'Software', 'Interface (matter)', 'Human–computer interaction', 'Graphics', 'Computer graphics (images)', 'Programming language', 'Bubble', 'Maximum bubble pressure method', 'Parallel computing']","coot, biological macromo, atomic models, idealization, ligand search, solvation, mutations, rotamers, ramachandran idealization, model validation, tool, mouse controls, custom, ##ble key bindings, scripting interface"
Paper_00264,A Heteroskedasticity-Consistent Covariance Matrix Estimator and a Direct Test for Heteroskedasticity,['Halbert White'],1980,Econometrica,Journal,,817-817,48,4,10.2307/1912934,"This paper presents a parameter covariance matrix estimator which is consistent even when the disturbances of a linear regression model are heteroskedastic. This estimator does not depend on a formal model of the structure of the heteroskedasticity. By comparing the elements of the new estimator to those of the usual covariance estimator, one obtains a direct test for heteroskedasticity, since in the absence of heteroskedasticity, the two estimators will be approximately equal, but will generally diverge otherwise. The test has an appealing least squares interpretation.","['Heteroscedasticity', 'Mathematics', 'Econometrics', 'Estimator', 'Covariance matrix', 'Estimation of covariance matrices', 'Test (biology)', 'Statistics', 'Paleontology', 'Biology']","parameter covariance matrix estimator, linear regression model, heteroskedastic, covariance estimator, heteroskedasticity, heteros, least squares interpretation"
Paper_00265,Understanding Attitudes and Predicting Social Behavior,"['Icek Ajzen', 'Martin Fishbein']",1980,['Handbook of Social Network Technologies and Applications'],Unknown,,427-445,,,10.1007/978-1-4419-7142-5_20,Core text in attitude courses. Explains theory and reasoned action model and then applies the model to various cases.,"['Psychology', 'Social psychology', 'Political science']","attitude courses, reasoned action model, [PAD], [PAD] [PAD], [PAD]"
Paper_00266,"The Seventh Report of the Joint National Committee on Prevention, Detection, Evaluation, and Treatment of High Blood Pressure&lt;SUBTITLE&gt;The JNC 7 Report&lt;/SUBTITLE&gt;","['Aram V. Chobanian', 'George L. Bakris', 'Henry R. Black', 'William C. Cushman', 'Lee A. Green', 'Joseph L. Izzo', 'Daniel W. Jones', 'Barry J. Materson', 'Suzanne Oparil', 'Jackson T. Wright', 'Edward J. Roccella']",2003,JAMA,Journal,,2560-2560,289,19,10.1001/jama.289.19.2560,"""The Seventh Report of the Joint National Committee on Prevention, Detection, Evaluation, and Treatment of High Blood Pressure"" provides a new guideline for hypertension prevention and management. The following are the key messages(1) In persons older than 50 years, systolic blood pressure (BP) of more than 140 mm Hg is a much more important cardiovascular disease (CVD) risk factor than diastolic BP; (2) The risk of CVD, beginning at 115/75 mm Hg, doubles with each increment of 20/10 mm Hg; individuals who are normotensive at 55 years of age have a 90% lifetime risk for developing hypertension; (3) Individuals with a systolic BP of 120 to 139 mm Hg or a diastolic BP of 80 to 89 mm Hg should be considered as prehypertensive and require health-promoting lifestyle modifications to prevent CVD; (4) Thiazide-type diuretics should be used in drug treatment for most patients with uncomplicated hypertension, either alone or combined with drugs from other classes. Certain high-risk conditions are compelling indications for the initial use of other antihypertensive drug classes (angiotensin-converting enzyme inhibitors, angiotensin-receptor blockers, beta-blockers, calcium channel blockers); (5) Most patients with hypertension will require 2 or more antihypertensive medications to achieve goal BP (<140/90 mm Hg, or <130/80 mm Hg for patients with diabetes or chronic kidney disease); (6) If BP is more than 20/10 mm Hg above goal BP, consideration should be given to initiating therapy with 2 agents, 1 of which usually should be a thiazide-type diuretic; and (7) The most effective therapy prescribed by the most careful clinician will control hypertension only if patients are motivated. Motivation improves when patients have positive experiences with and trust in the clinician. Empathy builds trust and is a potent motivator. Finally, in presenting these guidelines, the committee recognizes that the responsible physician's judgment remains paramount.","['Medicine', 'Blood pressure', 'Guideline', 'Prehypertension', 'Thiazide', 'Internal medicine', 'Candesartan', 'Diuretic', 'Kidney disease', 'Hydrochlorothiazide', 'Diabetes mellitus', 'Cardiology', 'Endocrinology', 'Angiotensin II', 'Pathology']","high blood pressure, hyper, sy, ##lic blood pressure"
Paper_00268,clusterProfiler: an R Package for Comparing Biological Themes Among Gene Clusters,"['Guangchuang Yu', 'Li-Gen Wang', 'Yanyan Han', 'Qing‐Yu He']",2012,OMICS A Journal of Integrative Biology,Journal,,284-287,16,5,10.1089/omi.2011.0118,"Increasing quantitative data generated from transcriptomics and proteomics require integrative strategies for analysis. Here, we present an R package, clusterProfiler that automates the process of biological-term classification and the enrichment analysis of gene clusters. The analysis module and visualization module were combined into a reusable workflow. Currently, clusterProfiler supports three species, including humans, mice, and yeast. Methods provided in this package can be easily extended to other species and ontologies. The clusterProfiler package is released under Artistic-2.0 License within Bioconductor project. The source code and vignette are freely available at http://bioconductor.org/packages/release/bioc/html/clusterProfiler.html.","['Bioconductor', 'R package', 'Workflow', 'Computer science', 'Visualization', 'Source code', 'Process (computing)', 'Bespoke', 'Pipeline (software)', 'Data science', 'World Wide Web', 'Computational biology', 'Database', 'Data mining', 'Gene', 'Biology', 'Programming language', 'Genetics', 'Political science', 'Law']","transcript, proteomics, ##egrative strategies, clusterprofiler, enrichment analysis, gene clusters, analysis, visualization, clusterprofiler, humans, mice, clusterpro, bioconductor, ##gne, bioconductor, cluster, [PAD], [PAD], [PAD], [PAD], [PAD] [PAD], [PAD], [PAD], [PAD], [PAD] [PAD], [PAD], [PAD], [PAD], [PAD], [PAD]"
Paper_00270,Scoping studies: towards a methodological framework,"['Hilary Arksey', 'Lisa O’Malley']",2005,International Journal of Social Research Methodology,Journal,,19-32,8,1,10.1080/1364557032000119616,"This paper focuses on scoping studies, an approach to reviewing the literature which to date has received little attention in the research methods literature. We distinguish between different types of scoping studies and indicate where these stand in relation to full systematic reviews. We outline a framework for conducting a scoping study based on our recent experiences of reviewing the literature on services for carers for people with mental health problems. Where appropriate, our approach to scoping the field is contrasted with the procedures followed in systematic reviews. We emphasize how including a consultation exercise in this sort of study may enhance the results, making them more useful to policy makers, practitioners and service users. Finally, we consider the advantages and limitations of the approach and suggest that a wider debate is called for about the role of the scoping study in relation to other types of literature reviews.","['Systematic review', 'Relation (database)', 'Field (mathematics)', 'Management science', 'Psychology', 'Sociology', 'Applied psychology', 'Computer science', 'MEDLINE', 'Political science', 'Engineering', 'Mathematics', 'Database', 'Pure mathematics', 'Law']","scoping studies, research methods, scoping studies, systematic reviews, scoping study, mental health problems, systematic reviews, consultation exercise, service users, scoping study, literature"
Paper_00271,A Closed‐form Equation for Predicting the Hydraulic Conductivity of Unsaturated Soils,['Martinus Th. van Genuchten'],1980,Soil Science Society of America Journal,Journal,,892-898,44,5,10.2136/sssaj1980.03615995004400050002x,"Abstract A new and relatively simple equation for the soil‐water content‐pressure head curve, θ( h ), is described in this paper. The particular form of the equation enables one to derive closed‐form analytical expressions for the relative hydraulic conductivity, K r , when substituted in the predictive conductivity models of N.T. Burdine or Y. Mualem. The resulting expressions for K r ( h ) contain three independent parameters which may be obtained by fitting the proposed soil‐water retention model to experimental data. Results obtained with the closed‐form analytical expressions based on the Mualem theory are compared with observed hydraulic conductivity data for five soils with a wide range of hydraulic properties. The unsaturated hydraulic conductivity is predicted well in four out of five cases. It is found that a reasonable description of the soil‐water retention curve at low water contents is important for an accurated prediction of the unsaturated hydraulic conductivity.","['Hydraulic conductivity', 'Soil water', 'Conductivity', 'Pressure head', 'Soil science', 'Water retention', 'Range (aeronautics)', 'Water content', 'Materials science', 'Mathematics', 'Geotechnical engineering', 'Environmental science', 'Thermodynamics', 'Chemistry', 'Geology', 'Physics', 'Composite material', 'Physical chemistry']","soil, pressure head curve, closed, relative hydraulic conductivity, predictive conductivity models, closed, hydraulic conductivity, unsaturated hydraulic conductivity, unsaturated hydraulic conductivity"
Paper_00272,Manual for the State-Trait Anxiety Inventory,"['Charles D. Spielberger', 'Richard L. Gorsuch', 'Robert E. Lushene']",1970,['Definitions'],Unknown,,,,,10.32388/owdfr4,"The STAI serves as an indicator of two types of anxiety, the state and trait anxiety, and measure the severity of the overall anxiety level.The STAI, which is appropriate for those who have at least a sixth grade reading level, contains four-point Likert items. The instrument is divided into two sections, each having twenty questions. Approximately 15 minutes are required for adults to complete the both STAI. The number on the scale is positively correlated to the anxiety related to in the question.","['Anxiety', 'Likert scale', 'State-Trait Anxiety Inventory', 'Psychology', 'Trait', 'Clinical psychology', 'Trait anxiety', 'Psychiatry', 'Developmental psychology', 'Computer science', 'Programming language']","stai, anxiety, state, trait anxiety"
Paper_00273,Institutionalized Organizations: Formal Structure as Myth and Ceremony,"['John W. Meyer', 'Brian Rowan']",1977,American Journal of Sociology,Journal,,340-363,83,2,10.1086/226550,"Many formal organizational structures arise as reflections of rationalized institutional rules. The elaboration of such rules in modern states and societies accounts in part for the expansion and increased complexity of formal organizational structures. Institutional rules function as myths which organizations incorporate, gaining legitimacy, resources, stability, and enhanced survival prospects. Organizations whose structures become isomorphic with the myths of the institutional environment-in contrast with those primarily structured by the demands of technical production and exchange-decrease internal coordination and control in order to maintain legitimacy. Structures are decoupled from each other and from ongoing activities. In place of coordination, inspection, and evaluation, a logic of confidence and good faith is employed.","['Ceremony', 'Mythology', 'Psychology', 'Art', 'Philosophy', 'Theology', 'Literature']","formal organizational structures, rationalized institutional rules, formal organizational structures, institutional rules, legitimacy, stability, institutional environment, technical production, confidence, good"
Paper_00274,The ERA‐Interim reanalysis: configuration and performance of the data assimilation system,"['Dick Dee', 'S. Uppala', 'A. J. Simmons', 'Paul Berrisford', 'Paul Poli', 'S Kobayashi', 'Ulf Andrae', 'Magdalena Balmaseda', 'Gianpaolo Balsamo', 'Péter Bauer', 'Peter Bechtold', 'Anton Beljaars', 'Leo van de Berg', 'Jean‐Raymond Bidlot', 'Niels Bormann', 'C. Delsol', 'Rossana Dragani', 'Manuel Fuentes', 'Alan J. Geer', 'L. Haimberger', 'S. B. Healy', 'Hans Hersbach', 'Elías Hólm', 'Lars Isaksen', 'P. Kållberg', 'Martin Köhler', 'Marco Matricardi', 'A. P. McNally', 'Beatriz M. Monge-Sanz', 'J.‐J. Morcrette', 'Byoung-Kwon Park', 'Carole Peubey', 'Patricia de Rosnay', 'Christina Tavolato', 'Jean‐Noël Thépaut', 'Frédéric Vitart']",2011,Quarterly Journal of the Royal Meteorological Society,Journal,,553-597,137,656,10.1002/qj.828,"ERA-Interim is the latest global atmospheric reanalysis produced by the European Centre for Medium-Range Weather Forecasts (ECMWF). The ERA-Interim project was conducted in part to prepare for a new atmospheric reanalysis to replace ERA-40, which will extend back to the early part of the twentieth century. This article describes the forecast model, data assimilation method, and input datasets used to produce ERA-Interim, and discusses the performance of the system. Special emphasis is placed on various difficulties encountered in the production of ERA-40, including the representation of the hydrological cycle, the quality of the stratospheric circulation, and the consistency in time of the reanalysed fields. We provide evidence for substantial improvements in each of these aspects. We also identify areas where further work is needed and describe opportunities and objectives for future reanalysis projects at ECMWF. Copyright © 2011 Royal Meteorological Society","['Interim', 'Data assimilation', 'Environmental science', 'Meteorology', 'Climatology', 'General Circulation Model', 'Atmospheric circulation', 'Consistency (knowledge bases)', 'Computer science', 'Climate change', 'Geography', 'Geology', 'Oceanography', 'Archaeology', 'Artificial intelligence']","global atmospheric reanalysis, ##w, forecast model, data assimilation method, input datasets, hydrological cycle, stratospheric circulation, royal meteorological society"
Paper_00275,Social Learning Theory.,"['Jackson Kytle', 'Albert Bandura']",1978,Contemporary Sociology A Journal of Reviews,Journal,,84-84,7,1,10.2307/2065952,"Una exploracion de los avances contemporaneos en la teoria del aprendizaje social, con especial enfasis en los importantes roles que cumplen los procesos cognitivos, indirectos, y autoregulatorios.","['Sociology', 'Psychology']","[PAD], [PAD], [PAD]"
Paper_00282,Judgment under Uncertainty: Heuristics and Biases,"['Amos Tversky', 'Daniel Kahneman']",1974,Science,Journal,,1124-1131,185,4157,10.1126/science.185.4157.1124,"This article described three heuristics that are employed in making judgments under uncertainty: (i) representativeness, which is usually employed when people are asked to judge the probability that an object or event A belongs to class or process B; (ii) availability of instances or scenarios, which is often employed when people are asked to assess the frequency of a class or the plausibility of a particular development; and (iii) adjustment from an anchor, which is usually employed in numerical prediction when a relevant value is available. These heuristics are highly economical and usually effective, but they lead to systematic and predictable errors. A better understanding of these heuristics and of the biases to which they lead could improve judgments and decisions in situations of uncertainty.","['Heuristics', 'Representativeness heuristic', 'Computer science', 'Class (philosophy)', 'Process (computing)', 'Object (grammar)', 'Event (particle physics)', 'Artificial intelligence', 'Machine learning', 'Psychology', 'Social psychology', 'Operating system', 'Physics', 'Quantum mechanics']","heuristic, representativeness, anchor, numerical prediction, [PAD], [PAD]"
Paper_00283,Outline of a Theory of Practice,['Pierre Bourdieu'],1977,Unknown,Unknown,,,,,10.1017/cbo9780511812507,"Outline of a Theory of Practice is recognized as a major theoretical text on the foundations of anthropology and sociology. Pierre Bourdieu, a distinguished French anthropologist, develops a theory of practice which is simultaneously a critique of the methods and postures of social science and a general account of how human action should be understood. With his central concept of the habitus, the principle which negotiates between objective structures and practices, Bourdieu is able to transcend the dichotomies which have shaped theoretical thinking about the social world. The author draws on his fieldwork in Kabylia (Algeria) to illustrate his theoretical propositions. With detailed study of matrimonial strategies and the role of rite and myth, he analyses the dialectical process of the 'incorporation of structures' and the objectification of habitus, whereby social formations tend to reproduce themselves. A rigorous consistent materialist approach lays the foundations for a theory of symbolic capital and, through analysis of the different modes of domination, a theory of symbolic power.","['Habitus', 'Epistemology', 'Practice theory', 'Dialectic', 'Sociology', 'Dichotomy', 'Objectification', 'Social theory', 'Materialism', 'Social practice', 'Action (physics)', 'Doxa', 'Critical theory', 'Power (physics)', 'Social science', 'Cultural capital', 'Philosophy', 'Art', 'Physics', 'Quantum mechanics', 'Performance art', 'Art history']","anthropology, sociology, social science, habitus, matrimonial strategies, myth, dialectical, habitus, social, symbolic capital, symbolic power"
Paper_00284,THE USE OF LEAD CITRATE AT HIGH pH AS AN ELECTRON-OPAQUE STAIN IN ELECTRON MICROSCOPY,['Edward S. Reynolds'],1963,The Journal of Cell Biology,Journal,,208-212,17,1,10.1083/jcb.17.1.208,"Aqueous solutions of lead salts (1, 2) and saturated","['Biology', 'Electron microscope', 'Opacity', 'Stain', 'Biophysics', 'Microscopy', 'Staining', 'Optics', 'Genetics', 'Physics']","##que, lead, [PAD], [PAD], [PAD] [PAD], [PAD], [PAD], [PAD], [PAD]"
Paper_00286,QUANTUM ESPRESSO: a modular and open-source software project for quantum simulations of materials,"['Paolo Giannozzi', 'Stefano Baroni', 'Nicola Bonini', 'Matteo Calandra', 'Roberto Car', 'Carlo Cavazzoni', 'Davide Ceresoli', 'G. Chiarotti', 'Matteo Cococcioni', 'Ismaïla Dabo', 'Andrea Dal Corso', 'Stefano de Gironcoli', 'Stefano Fabris', 'Guido Fratesi', 'Ralph Gebauer', 'U. Gerstmann', 'Christos Gougoussis', 'Anton Kokalj', 'Michele Lazzeri', 'Layla Martin‐Samos', 'Nicola Marzari', 'Francesco Mauri', 'Riccardo Mazzarello', 'Stefano Paolini', 'Alfredo Pasquarello', 'Lorenzo Paulatto', 'Carlo Sbraccia', 'Sandro Scandolo', 'Gabriele Sclauzero', 'Ari P. Seitsonen', 'Alexander Smogunov', 'Paolo Umari', 'Renata M. Wentzcovitch']",2009,Journal of Physics Condensed Matter,Journal,,395502-395502,21,39,10.1088/0953-8984/21/39/395502,"QUANTUM ESPRESSO is an integrated suite of computer codes for electronic-structure calculations and materials modeling, based on density-functional theory, plane waves, and pseudopotentials (norm-conserving, ultrasoft, and projector-augmented wave). The acronym ESPRESSO stands for opEn Source Package for Research in Electronic Structure, Simulation, and Optimization. It is freely available to researchers around the world under the terms of the GNU General Public License. QUANTUM ESPRESSO builds upon newly-restructured electronic-structure codes that have been developed and tested by some of the original authors of novel electronic-structure algorithms and applied in the last twenty years by some of the leading materials modeling groups worldwide. Innovation and efficiency are still its main focus, with special attention paid to massively parallel architectures, and a great effort being devoted to user friendliness. QUANTUM ESPRESSO is evolving towards a distribution of independent and interoperable codes in the spirit of an open-source project, where researchers active in the field of electronic-structure calculations are encouraged to participate in the project by contributing their own codes or by implementing their own ideas into existing codes.","['Interoperability', 'Computer science', 'Computational science', 'Modular design', 'World Wide Web', 'Programming language']","quantum espresso, computer codes, materials modeling, plane waves, pseudopotentials, espresso, electronic structure, optimization, quantum espresso, ##ly parallel architectures, quantum espresso"
Paper_00288,Preferred Reporting Items for Systematic Reviews and Meta-Analyses: The PRISMA Statement,['David Moher'],2009,Annals of Internal Medicine,Journal,,264-264,151,4,10.7326/0003-4819-151-4-200908180-00135,"Academia and Clinic18 August 2009Preferred Reporting Items for Systematic Reviews and Meta-Analyses: The PRISMA StatementFREEDavid Moher, PhD, Alessandro Liberati, MD, DrPH, Jennifer Tetzlaff, BSc, and Douglas G. Altman, DSc, the PRISMA Group*David Moher, PhDFrom Ottawa Methods Centre, Ottawa Hospital Research Institute, University of Ottawa, Ottawa, Ontario, Canada; Università di Modena e Reggio Emilia, Modena, Italy; Centro Cochrane Italiano, Istituto Ricerche Farmacologiche Mario Negri, Milan, Italy; and Centre for Statistics in Medicine, University of Oxford, Oxford, United Kingdom.Search for more papers by this author, Alessandro Liberati, MD, DrPHFrom Ottawa Methods Centre, Ottawa Hospital Research Institute, University of Ottawa, Ottawa, Ontario, Canada; Università di Modena e Reggio Emilia, Modena, Italy; Centro Cochrane Italiano, Istituto Ricerche Farmacologiche Mario Negri, Milan, Italy; and Centre for Statistics in Medicine, University of Oxford, Oxford, United Kingdom.Search for more papers by this author, Jennifer Tetzlaff, BScFrom Ottawa Methods Centre, Ottawa Hospital Research Institute, University of Ottawa, Ottawa, Ontario, Canada; Università di Modena e Reggio Emilia, Modena, Italy; Centro Cochrane Italiano, Istituto Ricerche Farmacologiche Mario Negri, Milan, Italy; and Centre for Statistics in Medicine, University of Oxford, Oxford, United Kingdom.Search for more papers by this author, and Douglas G. Altman, DScFrom Ottawa Methods Centre, Ottawa Hospital Research Institute, University of Ottawa, Ottawa, Ontario, Canada; Università di Modena e Reggio Emilia, Modena, Italy; Centro Cochrane Italiano, Istituto Ricerche Farmacologiche Mario Negri, Milan, Italy; and Centre for Statistics in Medicine, University of Oxford, Oxford, United Kingdom.Search for more papers by this author, the PRISMA Group*Search for more papers by this authorAuthor, Article, and Disclosure Informationhttps://doi.org/10.7326/0003-4819-151-4-200908180-00135 SectionsSupplemental MaterialAboutVisual AbstractPDF ToolsAdd to favoritesDownload CitationsTrack CitationsPermissions ShareFacebookTwitterLinkedInRedditEmail Editor's Note: In order to encourage dissemination of the PRISMA Statement, this article is freely accessible on the Annals of Internal Medicine Web site (www.annals.org) and will be also published in PLOS Medicine, BMJ, Journal of Clinical Epidemiology, and Open Medicine. The authors jointly hold the copyright of this article. For details on further use, see the PRISMA Web site (www.prisma-statement.org).Systematic reviews and meta-analyses have become increasingly important in health care. Clinicians read them to keep up to date with their field (1, 2), and they are often used as a starting point for developing clinical practice guidelines. Granting agencies may require a systematic review to ensure there is justification for further research (3), and some health care journals are moving in this direction (4). As with all research, the value of a systematic review depends on what was done, what was found, and the clarity of reporting. As with other publications, the reporting quality of systematic reviews varies, limiting readers' ability to assess the strengths and weaknesses of those reviews.Several early studies evaluated the quality of review reports. In 1987, Mulrow examined 50 review articles published in four leading medical journals in 1985 and 1986 and found that none met all eight explicit scientific criteria, such as a quality assessment of included studies (5). In 1987, Sacks and colleagues (6) evaluated the adequacy of reporting of 83 meta-analyses on 23 characteristics in six domains. Reporting was generally poor; between one and 14 characteristics were adequately reported (mean = 7.7; standard deviation = 2.7). A 1996 update of this study found little improvement (7).In 1996, to address the suboptimal reporting of meta-analyses, an international group developed a guidance called the QUOROM Statement (QUality Of Reporting Of Meta-analyses), which focused on the reporting of meta-analyses of randomized, controlled trials (8). In this article, we summarize a revision of these guidelines, renamed PRISMA (Preferred Reporting Items for Systematic reviews and Meta-Analyses), which have been updated to address several conceptual and practical advances in the science of systematic reviews (Box 1).Box 1. Conceptual Issues in the Evolution From QUOROM to PRISMA Download figure Download PowerPoint TerminologyThe terminology used to describe a systematic review and meta-analysis has evolved over time. One reason for changing the name from QUOROM to PRISMA was the desire to encompass both systematic reviews and meta-analyses. We have adopted the definitions used by the Cochrane Collaboration (9). A systematic review is a review of a clearly formulated question that uses systematic and explicit methods to identify, select, and critically appraise relevant research, and to collect and analyze data from the studies that are included in the review. Statistical methods (meta-analysis) may or may not be used to analyze and summarize the results of the included studies. Meta-analysis refers to the use of statistical techniques in a systematic review to integrate the results of included studies.Developing the PRISMA StatementA three-day meeting was held in Ottawa, Ontario, Canada, in June 2005 with 29 participants, including review authors, methodologists, clinicians, medical editors, and a consumer. The objective of the Ottawa meeting was to revise and expand the QUOROM checklist and flow diagram, as needed.The executive committee completed the following tasks, prior to the meeting: a systematic review of studies examining the quality of reporting of systematic reviews, and a comprehensive literature search to identify methodological and other articles that might inform the meeting, especially in relation to modifying checklist items. An international survey of review authors, consumers, and groups commissioning or using systematic reviews and meta-analyses was completed, including the International Network of Agencies for Health Technology Assessment (INAHTA) and the Guidelines International Network (GIN). The survey aimed to ascertain views of QUOROM, including the merits of the existing checklist items. The results of these activities were presented during the meeting and are summarized on the PRISMA Web site (www.prisma-statement.org).Only items deemed essential were retained or added to the checklist. Some additional items are nevertheless desirable, and review authors should include these, if relevant (10). For example, it is useful to indicate whether the systematic review is an update (11) of a previous review, and to describe any changes in procedures from those described in the original protocol.Shortly after the meeting a draft of the PRISMA checklist was circulated to the group, including those invited to the meeting but unable to attend. A disposition file was created containing comments and revisions from each respondent, and the checklist was subsequently revised 11 times. The group approved the checklist, flow diagram, and this summary paper.Although no direct evidence was found to support retaining or adding some items, evidence from other domains was believed to be relevant. For example, Item 5 asks authors to provide registration information about the systematic review, including a registration number, if available. Although systematic review registration is not yet widely available (12, 13), the participating journals of the International Committee of Medical Journal Editors (ICMJE) (14) now require all clinical trials to be registered in an effort to increase transparency and accountability (15). Those aspects are also likely to benefit systematic reviewers, possibly reducing the risk of an excessive number of reviews addressing the same question (16, 17) and providing greater transparency when updating systematic reviews.The PRISMA StatementThe PRISMA Statement consists of a 27-item checklist (Table 1; see also Table S1, for a downloadable Word template for researchers to re-use) and a four-phase flow diagram (Figure 1; see also Figure S1, for a downloadable Word template for researchers to re-use). The aim of the PRISMA Statement is to help authors improve the reporting of systematic reviews and meta-analyses. We have focused on randomized trials, but PRISMA can also be used as a basis for reporting systematic reviews of other types of research, particularly evaluations of interventions. PRISMA may also be useful for critical appraisal of published systematic reviews. However, the PRISMA checklist is not a quality assessment instrument to gauge the quality of a systematic review.Table 1. Checklist of Items to Include When Reporting a Systematic Review or Meta-AnalysisFigure 1. Flow of information through the different phases of a systematic review. Download figure Download PowerPoint From QUOROM to PRISMAThe new PRISMA checklist differs in several respects from the QUOROM checklist, and the substantive specific changes are highlighted in Table 2. Generally, the PRISMA checklist “decouples” several items present in the QUOROM checklist and, where applicable, several checklist items are linked to improve consistency across the systematic review report.Table 2. Substantive Specific Changes Between the QUOROM Checklist and the PRISMA ChecklistThe flow diagram has also been modified. Before including studies and providing reasons for excluding others, the review team must first search the literature. This search results in records. Once these records have been screened and eligibility criteria applied, a smaller number of articles will remain. The number of included articles might be smaller (or larger) than the number of studies, because articles may report on multiple studies and results from a particular study may be published in several articles. To capture this information, the PRISMA flow diagram now requests information on these phases of the review process.EndorsementThe PRISMA Statement should replace the QUOROM Statement for those journals that have endorsed QUOROM. We hope that other journals will support PRISMA; they can do so by registering on the PRISMA Web site. To underscore to authors, and others, the importance of transparent reporting of systematic reviews, we encourage supporting journals to reference the PRISMA Statement and include the PRISMA Web address in their instructions to authors. We also invite editorial organizations to consider endorsing PRISMA and encourage authors to adhere to its principles.The PRISMA Explanation and Elaboration PaperIn addition to the PRISMA Statement, a supporting Explanation and Elaboration document has been produced (18) following the style used for other reporting guidelines (19–21). The process of completing this document included developing a large database of exemplars to highlight how best to report each checklist item, and identifying a comprehensive evidence base to support the inclusion of each checklist item. The Explanation and Elaboration document was completed after several face-to-face meetings and numerous iterations among several meeting participants, after which it was shared with the whole group for additional revisions and final approval. Finally, the group formed a dissemination subcommittee to help disseminate and implement PRISMA.DiscussionThe quality of reporting of systematic reviews is still not optimal (22–27). In a recent review of 300 systematic reviews, few authors reported assessing possible publication bias (22), even though there is overwhelming evidence both for its existence (28) and its impact on the results of systematic reviews (29). Even when the possibility of publication bias is assessed, there is no guarantee that systematic reviewers have assessed or interpreted it appropriately (30). Although the absence of reporting such an assessment does not necessarily indicate that it was not done, reporting an assessment of possible publication bias is likely to be a marker of the thoroughness of the conduct of the systematic review.Several approaches have been developed to conduct systematic reviews on a broader array of questions. For example, systematic reviews are now conducted to investigate cost-effectiveness (31), diagnostic (32) or prognostic questions (33), genetic associations (34), and policy making (35). The general concepts and topics covered by PRISMA are all relevant to any systematic review, not just those whose objective is to summarize the benefits and harms of a health care intervention. However, some modifications of the checklist items or flow diagram will be necessary in particular circumstances. For example, assessing the risk of bias is a key concept, but the items used to assess this in a diagnostic review are likely to focus on issues such as the spectrum of patients and the verification of disease status, which differ from reviews of interventions. The flow diagram will also need adjustments when reporting individual patient data meta-analysis (36).We have developed an explanatory document (18) to increase the usefulness of PRISMA. For each checklist item, this document contains an example of good reporting, a rationale for its inclusion, and supporting evidence, including references, whenever possible. We believe this document will also serve as a useful resource for those teaching systematic review methodology. We encourage journals to include reference to the explanatory document in their Instructions to Authors.Like any evidence-based endeavor, PRISMA is a living document. To this end we invite readers to comment on the revised version, particularly the new checklist and flow diagram, through the PRISMA Web site. We will use such information to inform PRISMA's continued development.References1. Oxman AD, Cook DJ, Guyatt GH. Users' guides to the medical literature. VI. How to use an overview. Evidence-Based Medicine Working Group. JAMA. 1994;272:1367-71. [PMID: 7933399] CrossrefMedlineGoogle Scholar2. Swingler GH, Volmink J, Ioannidis JP. Number of published systematic reviews and global burden of disease: database analysis. BMJ. 2003;327:1083-4. [PMID: 14604930] CrossrefMedlineGoogle Scholar3. Canadian Institutes of Health Research. Randomized controlled trials registration/application checklist. December 2006. Accessed at www.cihr-irsc.gc.ca/e/documents/rct_reg_e.pdf on 19 May 2009. Google Scholar4. Young C, Horton R. Putting clinical trials into context. Lancet. 2005;366:107-8. [PMID: 16005318] CrossrefMedlineGoogle Scholar5. Mulrow CD. The medical review article: state of the science. Ann Intern Med. 1987;106:485-8. [PMID: 3813259] LinkGoogle Scholar6. Sacks HS, Berrier J, Reitman D, Ancona-Berk VA, Chalmers TC. Meta-analyses of randomized controlled trials. N Engl J Med. 1987;316:450-5. [PMID: 3807986] CrossrefMedlineGoogle Scholar7. Sacks HS, Reitman D, Pagano D, Kupelnick B. Meta-analysis: an update. Mt Sinai J Med. 1996;63:216-24. [PMID: 8692168] MedlineGoogle Scholar8. Moher D, Cook DJ, Eastwood S, Olkin I, Rennie D, Stroup DF. Improving the quality of reports of meta-analyses of randomised controlled trials: the QUOROM statement. Quality of Reporting of Meta-analyses. Lancet. 1999;354:1896-900. [PMID: 10584742] CrossrefMedlineGoogle Scholar9. Green S, Higgins J, eds. Glossary. In: Cochrane Handbook for Systematic Reviews of Interventions 4.2.5. The Cochrane Collaboration; 2005. Accessed at www.cochrane.org/resources/glossary.htm on 19 May 2009. Google Scholar10. Strech D, Tilburt J. Value judgments in the analysis and synthesis of evidence. J Clin Epidemiol. 2008;61:521-4. [PMID: 18471654] CrossrefMedlineGoogle Scholar11. Moher D, Tsertsvadze A. Systematic reviews: when is an update an update? Lancet. 2006;367:881-3. [PMID: 16546523] CrossrefMedlineGoogle Scholar12. University of York Centre for Reviews and Dissemination. 2009. Accessed at www.york.ac.uk/inst/crd/ on 19 May 2009. Google Scholar13. The Joanna Briggs Institute protocols & work in progress. 2009. Accessed at www.joannabriggs.edu.au/pubs/systematic_reviews_prot.php on 19 May 2009. Google Scholar14. De Angelis C, Drazen JM, Frizelle FA, Haug C, Hoey J, Horton R, et al; International Committee of Medical Journal Editors. Clinical trial registration: a statement from the International Committee of Medical Journal Editors [Editorial]. CMAJ. 2004;171:606-7. [PMID: 15367465] CrossrefMedlineGoogle Scholar15. Whittington CJ, Kendall T, Fonagy P, Cottrell D, Cotgrove A, Boddington E. Selective serotonin reuptake inhibitors in childhood depression: systematic review of published versus unpublished data. Lancet. 2004;363:1341-5. [PMID: 15110490] CrossrefMedlineGoogle Scholar16. Bagshaw SM, McAlister FA, Manns BJ, Ghali WA. Acetylcysteine in the prevention of contrast-induced nephropathy: a case study of the pitfalls in the evolution of evidence. Arch Intern Med. 2006;166:161-6. [PMID: 16432083] CrossrefMedlineGoogle Scholar17. Biondi-Zoccai GG, Lotrionte M, Abbate A, Testa L, Remigi E, Burzotta F, et al. Compliance with QUOROM and quality of reporting of overlapping meta-analyses on the role of acetylcysteine in the prevention of contrast associated nephropathy: case study. BMJ. 2006;332:202-9. [PMID: 16415336] CrossrefMedlineGoogle Scholar18. Liberati A, Altman DG, Tetzlaff J, Mulrow C, Gøtzsche P, Ioannidis JP, et al. The PRISMA statement for reporting systematic reviews and meta-analyses of studies that evaluate health care interventions: explanation and elaboration. Ann Intern Med. 2009;151:W-65-94. LinkGoogle Scholar19. Altman DG, Schulz KF, Moher D, Egger M, Davidoff F, Elbourne D, et al; CONSORT GROUP (Consolidated Standards of Reporting Trials). The revised CONSORT statement for reporting randomized trials: explanation and elaboration. Ann Intern Med. 2001;134:663-94. [PMID: 11304107] LinkGoogle Scholar20. Bossuyt PM, Reitsma JB, Bruns DE, Gatsonis CA, Glasziou PP, Irwig LM, et al; Standards for Reporting of Diagnostic Accuracy. The STARD statement for reporting studies of diagnostic accuracy: explanation and elaboration. Ann Intern Med. 2003;138:W1-12. [PMID: 12513067] LinkGoogle Scholar21. Vandenbroucke JP, von Elm E, Altman DG, Gøtzsche PC, Mulrow CD, Pocock SJ, et al; STROBE Initiative. Strengthening the Reporting of Observational Studies in Epidemiology (STROBE): explanation and elaboration. Ann Intern Med. 2007;147:W163-94. [PMID: 17938389] LinkGoogle Scholar22. Moher D, Tetzlaff J, Tricco AC, Sampson M, Altman DG. Epidemiology and reporting characteristics of systematic reviews. PLoS Med. 2007;4:78. [PMID: 17388659] CrossrefMedlineGoogle Scholar23. Bhandari M, Morrow F, Kulkarni AV, Tornetta P. Meta-analyses in orthopaedic surgery. A systematic review of their methodologies. J Bone Joint Surg Am. 2001;83-A:15-24. [PMID: 11205853] CrossrefMedlineGoogle Scholar24. Kelly KD, Travers A, Dorgan M, Slater L, Rowe BH. Evaluating the quality of systematic reviews in the emergency medicine literature. Ann Emerg Med. 2001;38:518-26. [PMID: 11679863] CrossrefMedlineGoogle Scholar25. Richards D. The quality of systematic reviews in dentistry. Evid Based Dent. 2004;5:17. [PMID: 15238972] CrossrefMedlineGoogle Scholar26. Choi PT, Halpern SH, Malik N, Jadad AR, Tramèr MR, Walder B. Examining the evidence in anesthesia literature: a critical appraisal of systematic reviews. Anesth Analg. 2001;92:700-9. [PMID: 11226105] CrossrefMedlineGoogle Scholar27. Delaney A, Bagshaw SM, Ferland A, Manns B, Laupland KB, Doig CJ. A systematic evaluation of the quality of meta-analyses in the critical care literature. Crit Care. 2005;9:R575-82. [PMID: 16277721] CrossrefMedlineGoogle Scholar28. Dickersin K. Publication bias: recognizing the problem, understanding its origins and scope, and preventing harm.. In: Rothstein HR, Sutton AJ, Borenstein M, eds. Publication Bias in Meta-Analysis—Prevention, Assessment and Adjustments. Chichester, UK: J Wiley; 2005:11-33. Google Scholar29. Sutton AJ. Evidence concerning the consequences of publication and related biases.. In: Rothstein HR, Sutton AJ, Borenstein M, eds. Publication Bias in Meta-Analysis—Prevention, Assessment and Adjustments. Chichester, UK: J Wiley; 2005:175-92. Google Scholar30. Lau J, Ioannidis JP, Terrin N, Schmid CH, Olkin I. The case of the misleading funnel plot. BMJ. 2006;333:597-600. [PMID: 16974018] CrossrefMedlineGoogle Scholar31. Ladabaum U, Chopra CL, Huang G, Scheiman JM, Chernew ME, Fendrick AM. Aspirin as an adjunct to screening for prevention of sporadic colorectal cancer. A cost-effectiveness analysis. Ann Intern Med. 2001;135:769-81. [PMID: 11694102] LinkGoogle Scholar32. Deeks JJ. Systematic reviews in health care: Systematic reviews of evaluations of diagnostic and screening tests. BMJ. 2001;323:157-62. [PMID: 11463691] CrossrefMedlineGoogle Scholar33. Altman DG. Systematic reviews of evaluations of prognostic variables. BMJ. 2001;323:224-8. [PMID: 11473921] CrossrefMedlineGoogle Scholar34. Ioannidis JP, Ntzani EE, Trikalinos TA, Contopoulos-Ioannidis DG. Replication validity of genetic association studies. Nat Genet. 2001;29:306-9. [PMID: 11600885] CrossrefMedlineGoogle Scholar35. Lavis J, Davies H, Oxman A, Denis JL, Golden-Biddle K, Ferlie E. Towards systematic reviews that inform health care management and policy-making. J Health Serv Res Policy. 2005;10 Suppl 1 35-48. [PMID: 16053582] CrossrefMedlineGoogle Scholar36. Stewart LA, Clarke MJ. Practical methodology of meta-analyses (overviews) using updated individual patient data. Cochrane Working Group. Stat Med. 1995;14:2057-79. [PMID: 8552887] CrossrefMedlineGoogle Scholar37. Moja LP, Telaro E, D'Amico R, Moschetti I, Coe L, Liberati A. Assessment of methodological quality of primary studies by systematic reviews: results of the metaquality cross sectional study. BMJ. 2005;330:1053. [PMID: 15817526] CrossrefMedlineGoogle Scholar38. Guyatt GH, Oxman AD, Vist GE, Kunz R, Falck-Ytter Y, Alonso-Coello P, et al; GRADE Working Group. GRADE: an emerging consensus on rating quality of evidence and strength of recommendations. BMJ. 2008;336:924-6. [PMID: 18436948] CrossrefMedlineGoogle Scholar39. Schünemann HJ, Jaeschke R, Cook DJ, Bria WF, El-Solh AA, Ernst A, et al; ATS Documents Development and Implementation Committee. An official ATS statement: grading the quality of evidence and strength of recommendations in ATS guidelines and recommendations. Am J Respir Crit Care Med. 2006;174:605-14. [PMID: 16931644] CrossrefMedlineGoogle Scholar40. Chan AW, Hróbjartsson A, Haahr MT, Gøtzsche PC, Altman DG. Empirical evidence for selective reporting of outcomes in randomized trials: comparison of protocols to published articles. JAMA. 2004;291:2457-65. [PMID: 15161896] CrossrefMedlineGoogle Scholar41. Chan AW, Krleza-Jerić K, Schmid I, Altman DG. Outcome reporting bias in randomized trials funded by the Canadian Institutes of Health Research. CMAJ. 2004;171:735-40. [PMID: 15451835] CrossrefMedlineGoogle Scholar42. Silagy CA, Middleton P, Hopewell S. Publishing protocols of systematic reviews: comparing what was done to what was planned. JAMA. 2002;287:2831-4. [PMID: 12038926] CrossrefMedlineGoogle Scholar Comments0 CommentsSign In to Submit A Comment Author, Article, and Disclosure InformationAffiliations: From Ottawa Methods Centre, Ottawa Hospital Research Institute, University of Ottawa, Ottawa, Ontario, Canada; Università di Modena e Reggio Emilia, Modena, Italy; Centro Cochrane Italiano, Istituto Ricerche Farmacologiche Mario Negri, Milan, Italy; and Centre for Statistics in Medicine, University of Oxford, Oxford, United Kingdom.Acknowledgment: The following people contributed to the PRISMA Statement: Doug Altman, DSc, Centre for Statistics in Medicine (Oxford, United Kingdom); Gerd Antes, PhD, University Hospital Freiburg (Freiburg, Germany); David Atkins, MD, MPH, Health Services Research & Development Service, Veterans Health Administration (Washington, DC); Virginia Barbour, MRCP, DPhil, PLoS Medicine (Cambridge, United Kingdom); Nick Barrowman, PhD, Children's Hospital of Eastern Ontario (Ottawa, Ontario, Canada); Jesse A. Berlin, ScD, Johnson & Johnson Pharmaceutical Research and Development (Titusville, New Jersey); Jocalyn Clark, PhD, PLoS Medicine (at the time of writing, BMJ; London, United Kingdom); Mike Clarke, PhD, UK Cochrane Centre (Oxford, United Kingdom) and School of Nursing and Midwifery, Trinity College (Dublin, Ireland); Deborah Cook, MD, Departments of Medicine, Clinical Epidemiology and Biostatistics, McMaster University (Hamilton, Ontario, Canada); Roberto D'Amico, PhD, Università di Modena e Reggio Emilia (Modena, Italy) and Centro Cochrane Italiano, Istituto Ricerche Farmacologiche Mario Negri (Milan, Italy); Jonathan J. Deeks, PhD, University of Birmingham (Birmingham, United Kingdom); P.J. Devereaux, MD, PhD, Departments of Medicine, Clinical Epidemiology and Biostatistics, McMaster University (Hamilton, Ontario, Canada); Kay Dickersin, PhD, Johns Hopkins Bloomberg School of Public Health (Baltimore, Maryland); Matthias Egger, MD, Department of Social and Preventive Medicine, University of Bern (Bern, Switzerland); Edzard Ernst, MD, PhD, FRCP, FRCP(Edin), Peninsula Medical School (Exeter, United Kingdom); Peter C. Gøtzsche, MD, MSc, The Nordic Cochrane Centre (Copenhagen, Denmark); Jeremy Grimshaw, MBChB, PhD, FRCFP, Ottawa Hospital Research Institute (Ottawa, Ontario, Canada); Gordon Guyatt, MD, Departments of Medicine, Clinical Epidemiology and Biostatistics, McMaster University (Hamilton, Ontario, Canada); Julian Higgins, PhD, MRC Biostatistics Unit (Cambridge, United Kingdom); John P.A. Ioannidis, MD, University of Ioannina Campus (Ioannina, Greece); Jos Kleijnen, MD, PhD, Kleijnen Systematic Reviews Ltd (York, United Kingdom) and School for Public Health and Primary Care (CAPHRI), University of Maastricht (Maastricht, the Netherlands); Tom Lang, MA, Tom Lang Communications and Training (Davis, California); Alessandro Liberati, MD, Università di Modena e Reggio Emilia (Modena, Italy) and Centro Cochrane Italiano, Istituto Ricerche Farmacologiche Mario Negri (Milan, Italy); Nicola Magrini, MD, NHS Centre for the Evaluation of the Effectiveness of Health Care–CeVEAS (Modena, Italy); David McNamee, PhD, The Lancet (London, United Kingdom); Lorenzo Moja, MD, MSc, Centro Cochrane Italiano, Istituto Ricerche Farmacologiche Mario Negri (Milan, Italy); David Moher, PhD, Ottawa Methods Centre, Ottawa Hospital Research Institute (Ottawa, Ontario, Canada); Cynthia Mulrow, MD, MSc, Annals of Internal Medicine (Philadelphia, Pennsylvania); Maryann Napoli, Center for Medical Consumers (New York, New York); Andy Oxman, MD, Norwegian Health Services Research Centre (Oslo, Norway); Ba' Pham, MMath, Toronto Health Economics and Technology Assessment Collaborative (Toronto, Ontario, Canada; at the time of the first meeting of the group, GlaxoSmithKline Canada [Mississauga, Ontario, Canada]); Drummond Rennie, MD, FRCP, FACP, University of California, San Francisco (San Francisco, California); Margaret Sampson, MLIS, Children's Hospital of Eastern Ontario (Ottawa, Ontario, Canada); Kenneth F. Schulz, PhD, MBA, Family Health International (Durham, North Carolina); Paul G. Shekelle, MD, PhD, Southern California Evidence-Based Practice Center (Santa Monica, California); Jennifer Tetzlaff, BSc, Ottawa Methods Centre, Ottawa Hospital Research Institute (Ottawa, Ontario, Canada); David Tovey, FRCGP, The Cochrane Library, Cochrane Collaboration (Oxford, United Kingdom; at the time of the first meeting of the group, BMJ [London, United Kingdom]); and Peter Tugwell, MD, MSc, FRCPC, Institute of Population Health, University of Ottawa (Ottawa, Ontario, Canada).Grant Support: PRISMA was funded by the Canadian Institutes of Health Research; Università di Modena e Reggio Emilia, Italy; Cancer Research UK; Clinical Evidence BMJ Knowledge; The Cochrane Collaboration; and GlaxoSmithKline, Canada. Dr. Liberati is funded, in part, through grants of the Italian Ministry of University (COFIN-PRIN 2002 prot. 2002061749 and COFIN-PRIN 2006 prot. 2006062298). Dr. Altman is funded by Cancer Research UK. Dr. Moher is funded by a University of Ottawa Research Chair. None of the sponsors had any involvement in the planning, execution, or write-up of the PRISMA documents. Additionally, no funder played a role in drafting the manuscript.Disclosures: None disclosed.Corresponding Author: David Moher, PhD, Ottawa Methods Centre, Ottawa Hospital Research Institute, The Ottawa Hospital, General Campus, Critical Care Wing (Eye Institute), 6th Floor, 501 Smyth Road, Ottawa, Ontario K1H 8L6, Canada; e-mail, [email protected]ca.Current Author Addresses: Dr. Moher and Ms. Tetzlaff: Ottawa Methods Centre, Ottawa Hospital Research Institute, The Ottawa Hospital, General Campus, Critical Care Wing (Eye Institute), 6th Floor, 501 Smyth Road, Ottawa, Ontario K1H 8L6, Canada.Dr. Liberati: Università di Modena e Reggio Emilia and Centro Cochrane Italiano, Istituto Ricerche Farmacologiche Mario Negri, Via La Masa 19, 20156 Milan, Italy.Dr. Altman: Centre for Statistics in Medicine, University of Oxford, Wolfson College Annexe, Linton Road, Oxford OX2 6UD, United Kingdom.* Membership of the PRISMA Group is provided in the Acknowledgment. PreviousarticleNextarticle Advertisement FiguresReferencesRelatedDetailsSee AlsoThe PRISMA Statement for Reporting Systematic Reviews and Meta-Analyses of Studies That Evaluate Health Care Interventions: Explanation and Elaboration Alessandro Liberati , Douglas G. Altman , Jennifer Tet","['Medicine', 'Library science', 'Systematic review', 'Humanities', 'MEDLINE', 'Art', 'Political science', 'Computer science', 'Law']","prisma statement, prisma, statistics, ##a"
Paper_00290,The Genome Analysis Toolkit: A MapReduce framework for analyzing next-generation DNA sequencing data,"['Aaron McKenna', 'Matthew G. Hanna', 'Eric Banks', 'Andrey Sivachenko', 'Kristian Cibulskis', 'Andrew Kernytsky', 'Kiran Garimella', 'David Altshuler', 'Stacey Gabriel', 'Mark J. Daly', 'Mark A. DePristo']",2010,Genome Research,Journal,,1297-1303,20,9,10.1101/gr.107524.110,"Next-generation DNA sequencing (NGS) projects, such as the 1000 Genomes Project, are already revolutionizing our understanding of genetic variation among individuals. However, the massive data sets generated by NGS—the 1000 Genome pilot alone includes nearly five terabases—make writing feature-rich, efficient, and robust analysis tools difficult for even computationally sophisticated individuals. Indeed, many professionals are limited in the scope and the ease with which they can answer scientific questions by the complexity of accessing and manipulating the data produced by these machines. Here, we discuss our Genome Analysis Toolkit (GATK), a structured programming framework designed to ease the development of efficient and robust analysis tools for next-generation DNA sequencers using the functional programming philosophy of MapReduce. The GATK provides a small but rich set of data access patterns that encompass the majority of analysis tool needs. Separating specific analysis calculations from common data management infrastructure enables us to optimize the GATK framework for correctness, stability, and CPU and memory efficiency and to enable distributed and shared memory parallelization. We highlight the capabilities of the GATK by describing the implementation and application of robust, scale-tolerant tools like coverage calculators and single nucleotide polymorphism (SNP) calling. We conclude that the GATK programming framework enables developers and analysts to quickly and easily write efficient and robust NGS tools, many of which have already been incorporated into large-scale sequencing projects like the 1000 Genomes Project and The Cancer Genome Atlas.","['Computer science', 'Genome', 'Correctness', '1000 Genomes Project', 'Set (abstract data type)', 'DNA sequencing', 'Biology', 'Computational biology', 'Single-nucleotide polymorphism', 'Programming language', 'Genetics', 'DNA', 'Gene', 'Genotype']","1000 genomes, genetic variation, genome analysis toolkit, ga, structured programming framework, robust, functional programming philosophy, mapreduce, data access, data management, gatk, memory efficiency, shared memory parallelization, coverage calculators, single nucleotide polymorphism, s, ##k, 1000 genomes, cancer genome atlas, [PAD], [PAD], [PAD] [PAD] [PAD] [PAD], [PAD] [PAD], [PAD] [PAD], [PAD]"
Paper_00291,Content Analysis: An Introduction to its Methodology.,"['Mack Shelley', 'Klaus Krippendorff']",1984,Journal of the American Statistical Association,Journal,,240-240,79,385,10.2307/2288384,History Conceptual Foundations Uses and Kinds of Inference The Logic of Content Analysis Designs Unitizing Sampling Recording Data Languages Constructs for Inference Analytical Techniques The Use of Computers Reliability Validity A Practical Guide,['Computer science'],"history, content analysis, unitizing sampling recording data languages, inference, computers reliability validity, [PAD], [PAD]"
Paper_00292,"Educational Research: Planning, Conducting, and Evaluating Quantitative and Qualitative Research",['John W. Creswell'],2001,['Selected Styles in Web-Based Educational Research'],Unknown,,403-412,,,10.4018/978-1-59140-732-4.ch025,Part I: AN INTRODUCTION TO EDUCATIONAL RESEARCH. 1. The Process of Conducting Research. 2. Quantitative and Qualitative Approaches. Part II: THE STEPS IN THE PROCESS OF RESEARCH. 3. Identifying a Research Problem. 4. Reviewing the Literature. 5. Specifying a Purpose and Research Questions or Hypotheses. 6. Collecting Quantitative Data. 7. Analyzing and Interpreting Quantitative Data. 8. Collecting Qualitative Data. 9. Analyzing and Interpreting Qualitative Data. 10. Reporting and Evaluating Research. Part III: RESEARCH DESIGNS. 11. Experimental Designs. 12. Correlational Designs. 13. Survey Designs. 14. Grounded Theory Designs. 15. Ethnographic Designs. 16. Narrative Research Designs. 17. Mixed Methods Designs. 18. Action Research Designs. Appendix A: Answers to the Chapter Study Questions. Appendix B: Determine Size Using Sample Size Tables. Appendix C: Non-Normal Distribution. Appendix D: Strategies for Defending a Research Proposal. Glossary. References. Author Index. Subject Index.,"['Glossary', 'Research design', 'Index (typography)', 'Management science', 'Quantitative research', 'Subject (documents)', 'Computer science', 'Qualitative research', 'Sample (material)', 'Qualitative property', 'Process (computing)', 'Mathematics education', 'Statistics', 'Psychology', 'Mathematics', 'Engineering', 'Sociology', 'Social science', 'Library science', 'Linguistics', 'Philosophy', 'Chemistry', 'Chromatography', 'Machine learning', 'World Wide Web', 'Operating system']","educational research, ##tative, hypoth, research designs, experimental designs, correlational designs, survey designs, grounded theory designs, ethnographic designs, narrative research designs, mixed methods designs, action research designs, sample size tables, non - normal distribution"
Paper_00294,SMOTE: Synthetic Minority Over-sampling Technique,"['Nitesh V. Chawla', 'Kevin W. Bowyer', 'Lawrence Hall', 'W. Philip Kegelmeyer']",2002,Journal of Artificial Intelligence Research,Journal,,321-357,16,,10.1613/jair.953,"An approach to the construction of classifiers from imbalanced datasets is described. A dataset is imbalanced if the classification categories are not approximately equally represented. Often real-world data sets are predominately composed of ""normal"" examples with only a small percentage of ""abnormal"" or ""interesting"" examples. It is also the case that the cost of misclassifying an abnormal (interesting) example as a normal example is often much higher than the cost of the reverse error. Under-sampling of the majority (normal) class has been proposed as a good means of increasing the sensitivity of a classifier to the minority class. This paper shows that a combination of our method of over-sampling the minority (abnormal) class and under-sampling the majority (normal) class can achieve better classifier performance (in ROC space) than only under-sampling the majority class. This paper also shows that a combination of our method of over-sampling the minority class and under-sampling the majority class can achieve better classifier performance (in ROC space) than varying the loss ratios in Ripper or class priors in Naive Bayes. Our method of over-sampling the minority class involves creating synthetic minority class examples. Experiments are performed using C4.5, Ripper and a Naive Bayes classifier. The method is evaluated using the area under the Receiver Operating Characteristic curve (AUC) and the ROC convex hull strategy.","['Oversampling', 'Classifier (UML)', 'Naive Bayes classifier', 'Artificial intelligence', 'Receiver operating characteristic', 'Computer science', 'Pattern recognition (psychology)', 'Prior probability', 'Class (philosophy)', 'Convex hull', 'Sampling (signal processing)', 'Mathematics', 'Machine learning', 'Bayesian probability', 'Statistics', 'Support vector machine', 'Regular polygon', 'Bandwidth (computing)', 'Filter (signal processing)', 'Computer network', 'Geometry', 'Computer vision']","classifiers, imbalanced datasets, classification, classifier performance, classifier performance, loss ratios, class, naive bayes, synthetic minority class, ##per, naive bayes classifier, receiver operating characteristic curve, roc convex hull strategy"
Paper_00296,<i>Quantum Computation and Quantum Information</i>,"['Michael A. Nielsen', 'Isaac L. Chuang', 'Lov K. Grover']",2002,American Journal of Physics,Journal,,558-559,70,5,10.1119/1.1463744,First Page,"['Physics', 'Quantum computer', 'Quantum information', 'Quantum mechanics', 'Computation', 'Open quantum system', 'Quantum', 'Theoretical physics', 'Quantum technology', 'Quantum operation', 'Statistical physics', 'Algorithm', 'Computer science']",
Paper_00297,"Executive Summary of the Third Report of the National Cholesterol Education Program (NCEP) Expert Panel on Detection, Evaluation, and Treatment of High Blood Cholesterol in Adults (Adult Treatment Panel III)",['Evaluation Expert Panel on Detection'],2001,JAMA,Journal,,2486-2497,285,19,10.1001/jama.285.19.2486,"Our website uses cookies to enhance your experience. By continuing to use our site, or clicking ""Continue,"" you are agreeing to our Cookie Policy | Continue JAMA HomeNew OnlineCurrent IssueFor Authors Publications JAMA JAMA Network Open JAMA Cardiology JAMA Dermatology JAMA Health Forum JAMA Internal Medicine JAMA Neurology JAMA Oncology JAMA Ophthalmology JAMA Otolaryngology–Head & Neck Surgery JAMA Pediatrics JAMA Psychiatry JAMA Surgery Archives of Neurology & Psychiatry (1919-1959) Podcasts Clinical Reviews Editors' Summary Medical News Author Interviews More JN Learning / CMESubscribeJobsInstitutions / LibrariansReprints & Permissions Terms of Use | Privacy Policy | Accessibility Statement 2023 American Medical Association. All Rights Reserved Search All JAMA JAMA Network Open JAMA Cardiology JAMA Dermatology JAMA Forum Archive JAMA Health Forum JAMA Internal Medicine JAMA Neurology JAMA Oncology JAMA Ophthalmology JAMA Otolaryngology–Head & Neck Surgery JAMA Pediatrics JAMA Psychiatry JAMA Surgery Archives of Neurology & Psychiatry Input Search Term Sign In Individual Sign In Sign inCreate an Account Access through your institution Sign In Purchase Options: Buy this article Rent this article Subscribe to the JAMA journal","['Medicine', 'Family medicine', 'Otorhinolaryngology', 'MEDLINE', 'Psychiatry', 'Political science', 'Law']","cookies, privacy policy, american medical association"
Paper_00299,"Balanced basis sets of split valence, triple zeta valence and quadruple zeta valence quality for H to Rn: Design and assessment of accuracy","['Florian Weigend', 'Reinhart Ahlrichs']",2005,Physical Chemistry Chemical Physics,Journal,,3297-3297,7,18,10.1039/b508541a,"Gaussian basis sets of quadruple zeta valence quality for Rb–Rn are presented, as well as bases of split valence and triple zeta valence quality for H–Rn. The latter were obtained by (partly) modifying bases developed previously. A large set of more than 300 molecules representing (nearly) all elements—except lanthanides—in their common oxidation states was used to assess the quality of the bases all across the periodic table. Quantities investigated were atomization energies, dipole moments and structure parameters for Hartree–Fock, density functional theory and correlated methods, for which we had chosen Møller–Plesset perturbation theory as an example. Finally recommendations are given which type of basis set is used best for a certain level of theory and a desired quality of results.","['Valence (chemistry)', 'Basis set', 'Chemistry', 'Gaussian', 'Density functional theory', 'Dipole', 'Atomic physics', 'Computational chemistry', 'Molecular physics', 'Physics', 'Organic chemistry']","gaussian basis sets, quadruple zeta valence quality, split valence, triple zeta valence quality, lanthanides, oxidation states, atomization energies, dipole moments, structure parameters, hartree –, ##ock, density functional theory, correlated methods, [PAD], [PAD]"
Paper_00300,Learning Multiple Layers of Features from Tiny Images,['Alex Krizhevsky'],2009,"['Lecture Notes in Computer Science', 'Computer Vision — ECCV 2002']",Unknown,,487-501,,,10.1007/3-540-47977-5_32,"In this work we describe how to train a multi-layer generative model of natural images. We use a dataset of millions of tiny colour images, described in the next section. This has been attempted by several groups but without success. The models on which we focus are RBMs (Restricted Boltzmann Machines) and DBNs (Deep Belief Networks). These models learn interesting-looking filters, which we show are more useful to a classifier than the raw pixels. We train the classifier on a labeled subset that we have collected and call the CIFAR-10 dataset.","['Boltzmann machine', 'Artificial intelligence', 'Classifier (UML)', 'Computer science', 'Generative grammar', 'Deep learning', 'Pattern recognition (psychology)', 'Pixel', 'Deep belief network', 'Focus (optics)', 'Machine learning', 'Generative model', 'Restricted Boltzmann machine', 'Computer vision', 'Physics', 'Optics']","natural images, tiny colour images, rbms, restricted boltzmann machines, dbns, deep belief networks, [PAD] [PAD]"
Paper_00301,PRISMA Extension for Scoping Reviews (PRISMA-ScR): Checklist and Explanation,"['Andrea C. Tricco', 'Erin Lillie', 'Wasifa Zarin', 'Kelly K. O’Brien', 'Heather Colquhoun', 'Danielle Levac', 'David Moher', 'Micah D.J. Peters', 'Tanya Horsley', 'Laura Weeks', 'Susanne Hempel', 'Elie A. Akl', 'Christine Chang', 'Jessie McGowan', 'Lesley Stewart', 'Lisa Hartling', 'Adrian Aldcroft', 'Michael G. Wilson', 'Chantelle Garritty', 'Simon Lewin', 'Christina Godfrey', 'Marilyn Macdonald', 'Étienne V. Langlois', 'Karla Soares‐Weiser', 'Jo Moriarty', 'Tammy Clifford', 'Özge Tunçalp', 'Sharon E. Straus']",2018,Annals of Internal Medicine,Journal,,467-473,169,7,10.7326/m18-0850,"Scoping reviews, a type of knowledge synthesis, follow a systematic approach to map evidence on a topic and identify main concepts, theories, sources, and knowledge gaps. Although more scoping reviews are being done, their methodological and reporting quality need improvement. This document presents the PRISMA-ScR (Preferred Reporting Items for Systematic reviews and Meta-Analyses extension for Scoping Reviews) checklist and explanation. The checklist was developed by a 24-member expert panel and 2 research leads following published guidance from the EQUATOR (Enhancing the QUAlity and Transparency Of health Research) Network. The final checklist contains 20 essential reporting items and 2 optional items. The authors provide a rationale and an example of good reporting for each item. The intent of the PRISMA-ScR is to help readers (including researchers, publishers, commissioners, policymakers, health care providers, guideline developers, and patients or consumers) develop a greater understanding of relevant terminology, core concepts, and key items to report for scoping reviews.","['Checklist', 'Systematic review', 'Terminology', 'Medicine', 'Guideline', 'Health care', 'Quality (philosophy)', 'Medical education', 'MEDLINE', 'Management science', 'Knowledge management', 'Process management', 'Psychology', 'Computer science', 'Engineering', 'Linguistics', 'Philosophy', 'Epistemology', 'Pathology', 'Political science', 'Law', 'Economics', 'Cognitive psychology', 'Economic growth']","scoping reviews, knowledge synthesis, knowledge gaps, ##oping reviews, reporting, systematic, ##oping reviews, health research, publishers, policy, health care providers, guideline developers"
Paper_00302,C4.5: Programs for Machine Learning,['J. R. Quinlan'],1992,['Companion to the Proceedings of the 11th International Symposium on Open Collaboration'],Unknown,,1-1,,,10.1145/2789853.2789869,"From the Publisher:
Classifier systems play a major role in machine learning and knowledge-based systems, and Ross Quinlan's work on ID3 and C4.5 is widely acknowledged to have made some of the most significant contributions to their development. This book is a complete guide to the C4.5 system as implemented in C for the UNIX environment. It contains a comprehensive guide to the system's use , the source code (about 8,800 lines), and implementation notes. The source code and sample datasets are also available on a 3.5-inch floppy diskette for a Sun workstation.

C4.5 starts with large sets of cases belonging to known classes. The cases, described by any mixture of nominal and numeric properties, are scrutinized for patterns that allow the classes to be reliably discriminated. These patterns are then expressed as models, in the form of decision trees or sets of if-then rules, that can be used to classify new cases, with emphasis on making the models understandable as well as accurate. The system has been applied successfully to tasks involving tens of thousands of cases described by hundreds of properties. The book starts from simple core learning methods and shows how they can be elaborated and extended to deal with typical problems such as missing data and over hitting. Advantages and disadvantages of the C4.5 approach are discussed and illustrated with several case studies.

This book and software should be of interest to developers of classification-based intelligent systems and to students in machine learning and expert systems courses.","['Computer science', 'Unix', 'Classifier (UML)', 'Machine learning', 'Artificial intelligence', 'Source code', 'Workstation', 'Software', 'Decision tree', 'Sample (material)', 'Software engineering', 'Data mining', 'Programming language', 'Operating system', 'Chemistry', 'Chromatography']","classifier systems, machine learning, id3, unix environment, sun, decision trees, core learning, machine learning, expert systems courses"
Paper_00303,The iron cage revisited institutional isomorphism and collective rationality in organizational fields,"['Paul DiMaggio', 'Walter W. Powell']",2004,Advances in strategic management,Unknown,,143-166,,,10.1016/s0742-3322(00)17011-1,"What makes organizations so similar? We contend that the engine of rationalization and bureaucratization has moved from the competitive marketplace to the state and the professions. Once a set of organizations emerges as a field, a paradox arises: rational actors make their organizations increasingly similar as they try to change them. We describe three isomorphic processes-coercive, mimetic, and normative—leading to this outcome. We then specify hypotheses about the impact of resource centralization and dependency, goal ambiguity and technical uncertainty, and professionalization and structuration on isomorphic change. Finally, we suggest implications for theories of organizations and social change.","['Rationalization (economics)', 'Ambiguity', 'Normative', 'Bureaucracy', 'Organizational field', 'Rationality', 'Professionalization', 'Isomorphism (crystallography)', 'Field (mathematics)', 'Positive economics', 'Political science', 'Sociology', 'Institutional logic', 'Politics', 'Economics', 'Social science', 'Computer science', 'Law', 'Chemistry', 'Mathematics', 'Pure mathematics', 'Crystal structure', 'Crystallography', 'Programming language']","organizations, rationalization, bureaucratization, competitive marketplace, state, professions, rational actors, isomorphic processes, coercive, mi, ##ic, normative, resource centralization, dependency, goal ambiguity, technical uncertainty, professionalization, structuration, isomorphic change, organizations, social change, [PAD], [PAD] [PAD] [PAD], [PAD], [PAD], [PAD], [PAD] [PAD]"
Paper_00305,Classification and Regression Trees.,"['Alexander Gordon', 'Leo Breiman', 'Jerome H. Friedman', 'Richard A. Olshen', 'C. J. Stone']",1984,Biometrics,Journal,,874-874,40,3,10.2307/2530946,"The methodology used to construct tree structured rules is the focus of this monograph. Unlike many other statistical procedures, which moved from pencil and paper to calculators, this text's use of trees was unthinkable before computers. Both the practical and theoretical sides have been developed in the authors' study of tree methods. Classification and Regression Trees reflects these two sides, covering the use of trees as a data analysis method, and in a more mathematical framework, proving some of their fundamental properties.","['Computer science', 'Focus (optics)', 'Construct (python library)', 'Tree (set theory)', 'Regression', 'Regression analysis', 'Pencil (optics)', 'Mathematics', 'Machine learning', 'Statistics', 'Artificial intelligence', 'Programming language', 'Combinatorics', 'Engineering', 'Mechanical engineering', 'Physics', 'Optics']","tree structured rules, statistical, calculators, tree methods, classification, regression trees, data analysis method, [PAD], [PAD] [PAD] [PAD], [PAD] [PAD]"
Paper_00306,BEDTools: a flexible suite of utilities for comparing genomic features,"['Aaron R. Quinlan', 'Ira M. Hall']",2010,Bioinformatics,Journal,,841-842,26,6,10.1093/bioinformatics/btq033,"Testing for correlations between different sets of genomic features is a fundamental task in genomics research. However, searching for overlaps between features with existing web-based methods is complicated by the massive datasets that are routinely produced with current sequencing technologies. Fast and flexible tools are therefore required to ask complex questions of these data in an efficient manner.This article introduces a new software suite for the comparison, manipulation and annotation of genomic features in Browser Extensible Data (BED) and General Feature Format (GFF) format. BEDTools also supports the comparison of sequence alignments in BAM format to both BED and GFF features. The tools are extremely efficient and allow the user to compare large datasets (e.g. next-generation sequencing data) with both public and custom genome annotation tracks. BEDTools can be combined with one another as well as with standard UNIX commands, thus facilitating routine genomics tasks as well as pipelines that can quickly answer intricate questions of large genomic datasets.BEDTools was written in C++. Source code and a comprehensive user manual are freely available at http://code.google.com/p/bedtoolsaaronquinlan@gmail.com; imh4y@virginia.eduSupplementary data are available at Bioinformatics online.","['Computer science', 'Suite', 'Annotation', 'Unix', 'Source code', 'Software', 'Genomics', 'Data mining', 'Software suite', 'Information retrieval', 'Feature (linguistics)', 'Genome', 'Artificial intelligence', 'Programming language', 'Biology', 'Biochemistry', 'Linguistics', 'Philosophy', 'Archaeology', 'Gene', 'History']","gen, genomics, browser extensible data, general feature format, bedtools, sequence alignments, bam, bedtools, unix, bedtools, ##ment, bioinformatics"
Paper_00307,User Acceptance of Computer Technology: A Comparison of Two Theoretical Models,"['Fred D. Davis', 'Richard P. Bagozzi', 'Paul R. Warshaw']",1989,Management Science,Journal,,982-1003,35,8,10.1287/mnsc.35.8.982,"Computer systems cannot improve organizational performance if they aren't used. Unfortunately, resistance to end-user systems by managers and professionals is a widespread problem. To better predict, explain, and increase user acceptance, we need to better understand why people accept or reject computers. This research addresses the ability to predict peoples' computer acceptance from a measure of their intentions, and the ability to explain their intentions in terms of their attitudes, subjective norms, perceived usefulness, perceived ease of use, and related variables. In a longitudinal study of 107 users, intentions to use a specific system, measured after a one-hour introduction to the system, were correlated 0.35 with system use 14 weeks later. The intention-usage correlation was 0.63 at the end of this time period. Perceived usefulness strongly influenced peoples' intentions, explaining more than half of the variance in intentions at the end of 14 weeks. Perceived ease of use had a small but significant effect on intentions as well, although this effect subsided over time. Attitudes only partially mediated the effects of these beliefs on intentions. Subjective norms had no effect on intentions. These results suggest the possibility of simple but powerful models of the determinants of user acceptance, with practical value for evaluating systems and guiding managerial interventions aimed at reducing the problem of underutilized computer technology.","['Usability', 'Technology acceptance model', 'Variance (accounting)', 'Psychology', 'Value (mathematics)', 'Psychological intervention', 'Social psychology', 'Explained variation', 'Computer science', 'Applied psychology', 'Knowledge management', 'Human–computer interaction', 'Business', 'Accounting', 'Machine learning', 'Psychiatry']","computer systems, organizational performance, user acceptance, computer acceptance, subjective norms, perceived, subjective norms, user acceptance, managerial interventions, underutilized computer technology, [PAD], [PAD]"
Paper_00308,A Brief Measure for Assessing Generalized Anxiety Disorder,"['Robert L. Spitzer', 'Kurt Kroenke', 'Janet B. W. Williams', 'Bernd Löwe']",2006,Archives of Internal Medicine,Journal,,1092-1092,166,10,10.1001/archinte.166.10.1092,"Generalized anxiety disorder (GAD) is one of the most common mental disorders; however, there is no brief clinical measure for assessing GAD. The objective of this study was to develop a brief self-report scale to identify probable cases of GAD and evaluate its reliability and validity.A criterion-standard study was performed in 15 primary care clinics in the United States from November 2004 through June 2005. Of a total of 2740 adult patients completing a study questionnaire, 965 patients had a telephone interview with a mental health professional within 1 week. For criterion and construct validity, GAD self-report scale diagnoses were compared with independent diagnoses made by mental health professionals; functional status measures; disability days; and health care use.A 7-item anxiety scale (GAD-7) had good reliability, as well as criterion, construct, factorial, and procedural validity. A cut point was identified that optimized sensitivity (89%) and specificity (82%). Increasing scores on the scale were strongly associated with multiple domains of functional impairment (all 6 Medical Outcomes Study Short-Form General Health Survey scales and disability days). Although GAD and depression symptoms frequently co-occurred, factor analysis confirmed them as distinct dimensions. Moreover, GAD and depression symptoms had differing but independent effects on functional impairment and disability. There was good agreement between self-report and interviewer-administered versions of the scale.The GAD-7 is a valid and efficient tool for screening for GAD and assessing its severity in clinical practice and research.","['Generalized anxiety disorder', 'Clinical psychology', 'Anxiety', 'Psychology', 'Psychiatry', 'Construct validity', 'Mental health', 'Medical diagnosis', 'Convergent validity', 'Criterion validity', 'Psychometrics', 'Medicine', 'Pathology', 'Internal consistency']","generalized anxiety disorder, ga, mental disorders, primary care clinics, mental health, construct, mental health, functional status measures, disability days, health care, factor, procedural validity, specificity, functional impairment, disability, depression symptoms, depression, functional impairment"
Paper_00310,PROCHECK: a program to check the stereochemical quality of protein structures,"['Roman A. Laskowski', 'Malcolm W. MacArthur', 'D. S. Moss', 'Janet M. Thornton']",1993,Journal of Applied Crystallography,Journal,,283-291,26,2,10.1107/s0021889892009944,The PROCHECK suite of programs provides a detailed check on the stereochemistry of a protein structure. Its outputs comprise a number of plots in PostScript format and a comprehensive residue-by-residue listing. These give an assessment of the overall quality of the structure as compared with well refined structures of the same resolution and also highlight regions that may need further investigation. The PROCHECK programs are useful for assessing the quality not only of protein structures in the process of being solved but also of existing structures and of those being modelled on known structures.,"['Suite', 'Listing (finance)', 'Computer science', 'Residue (chemistry)', 'Quality (philosophy)', 'Chemistry', 'Physics', 'Biochemistry', 'Business', 'Geography', 'Quantum mechanics', 'Archaeology', 'Finance']","procheck, stereochemist, protein, postscript, pro"
Paper_00311,Climate change 2007: the physical science basis,"['Susan L. Solomon', 'Dahe Qin', 'Martin Manning', 'Melinda Marquis', 'Kristen Averyt', 'M Tignor', 'H. L. Miller', 'Zhenlin Chen']",2007,['South African Geographical Journal'],Unknown,,86-87,92,1,10.1080/03736245.2010.480842,"This report is the first volume of the IPCC's Fourth Assessment Report. It covers several topics including the extensive range of observations now available for the atmosphere and surface, changes in sea level, assesses the paleoclimatic perspective, climate change causes both natural and anthropogenic, and climate models for projections of global climate.","['Climate change', 'Climatology', 'Environmental science', 'Climate model', 'Climate commitment', 'Atmosphere (unit)', 'Global warming', 'Physical geography', 'Geography', 'Meteorology', 'Effects of global warming', 'Geology', 'Oceanography']","ipcc, sea level, paleoclimatic perspective, climate, climate models, global climate, [PAD], [PAD]"
Paper_00312,Accurate and simple analytic representation of the electron-gas correlation energy,"['John P. Perdew', 'Yue Wang']",1992,"Physical review. B, Condensed matter",Journal,,13244-13249,45,23,10.1103/physrevb.45.13244,"We propose a simple analytic representation of the correlation energy ${\mathrm{\ensuremath{\varepsilon}}}_{\mathit{c}}$ for a uniform electron gas, as a function of density parameter ${\mathit{r}}_{\mathit{s}}$ and relative spin polarization \ensuremath{\zeta}. Within the random-phase approximation (RPA), this representation allows for the ${\mathit{r}}_{\mathit{s}}^{\mathrm{\ensuremath{-}}3/4}$ behavior as ${\mathit{r}}_{\mathit{s}}$\ensuremath{\rightarrow}\ensuremath{\infty}. Close agreement with numerical RPA values for ${\mathrm{\ensuremath{\varepsilon}}}_{\mathit{c}}$(${\mathit{r}}_{\mathit{s}}$,0), ${\mathrm{\ensuremath{\varepsilon}}}_{\mathit{c}}$(${\mathit{r}}_{\mathit{s}}$,1), and the spin stiffness ${\mathrm{\ensuremath{\alpha}}}_{\mathit{c}}$(${\mathit{r}}_{\mathit{s}}$)=${\mathrm{\ensuremath{\partial}}}^{2}$${\mathrm{\ensuremath{\varepsilon}}}_{\mathit{c}}$(${\mathit{r}}_{\mathit{s}}$, \ensuremath{\zeta}=0)/\ensuremath{\delta}${\mathrm{\ensuremath{\zeta}}}^{2}$, and recovery of the correct ${\mathit{r}}_{\mathit{s}}$ln${\mathit{r}}_{\mathit{s}}$ term for ${\mathit{r}}_{\mathit{s}}$\ensuremath{\rightarrow}0, indicate the appropriateness of the chosen analytic form. Beyond RPA, different parameters for the same analytic form are found by fitting to the Green's-function Monte Carlo data of Ceperley and Alder [Phys. Rev. Lett. 45, 566 (1980)], taking into account data uncertainties that have been ignored in earlier fits by Vosko, Wilk, and Nusair (VWN) [Can. J. Phys. 58, 1200 (1980)] or by Perdew and Zunger (PZ) [Phys. Rev. B 23, 5048 (1981)]. While we confirm the practical accuracy of the VWN and PZ representations, we eliminate some minor problems with these forms. We study the \ensuremath{\zeta}-dependent coefficients in the high- and low-density expansions, and the ${\mathit{r}}_{\mathit{s}}$-dependent spin susceptibility. We also present a conjecture for the exact low-density limit. The correlation potential ${\mathrm{\ensuremath{\mu}}}_{\mathit{c}}^{\mathrm{\ensuremath{\sigma}}}$(${\mathit{r}}_{\mathit{s}}$,\ensuremath{\zeta}) is evaluated for use in self-consistent density-functional calculations.","['Physics', 'Energy (signal processing)', 'Mathematical physics', 'Combinatorics', 'Condensed matter physics', 'Quantum mechanics', 'Mathematics']","analytic representation, correlation energy, uniform electron gas, relative spin polarization, spin stiffness"
Paper_00313,The “Golden Age” of Probiotics: A Systematic Review and Meta-Analysis of Randomized and Observational Studies in Preterm Infants,"['Elda Dermyshi', 'Yizhong Wang', 'Chongbing Yan', 'Wenchao Hong', 'Gang Qiu', 'Xiaohui Gong', 'Ting Zhang']",2017,Neonatology,Journal,,9-23,112,1,10.1159/000454668,Our study showed that enteral administration of prophylactic probiotics in neonatal intensive care setup could significantly reduce morbidity due to necrotising enterocolitis in very low birth weight newborn. It also helps in establishing early full enteral feeding and reduces hospital stay.,"['Observational study', 'Randomized controlled trial', 'Meta-analysis', 'Medicine', 'Pediatrics', 'Intensive care medicine', 'Internal medicine']","enteral administration, ##actic probiotics, neonatal intensive care setup, ##bid, ##rot, hospital stay, [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD]"
Paper_00314,A resource‐based view of the firm,['Birger Wernerfelt'],1984,Strategic Management Journal,Journal,,171-180,5,2,10.1002/smj.4250050207,"Abstract The paper explores the usefulness of analysing firms from the resource side rather than from the product side. In analogy to entry barriers and growth‐share matrices, the concepts of resource position barrier and resource‐product matrices are suggested. These tools are then used to highlight the new strategic options which naturally emerge from the resource perspective.","['Resource (disambiguation)', 'Perspective (graphical)', 'Analogy', 'Resource-based view', 'Business', 'Industrial organization', 'Product (mathematics)', 'Position (finance)', 'New product development', 'Knowledge management', 'Marketing', 'Computer science', 'Competitive advantage', 'Mathematics', 'Epistemology', 'Artificial intelligence', 'Computer network', 'Philosophy', 'Geometry', 'Finance']","entry barriers, growth ‐ share matrices, resource position barrier, resource ‐ product matrices, [PAD] [PAD], [PAD], [PAD] [PAD] [PAD] [PAD], [PAD]"
Paper_00315,Mask R-CNN,"['Kaiming He', 'Georgia Gkioxari', 'Piotr Dollár', 'Ross Girshick']",2017,Unknown,Unknown,,,,,10.1109/iccv.2017.322,"We present a conceptually simple, flexible, and general framework for object instance segmentation. Our approach efficiently detects objects in an image while simultaneously generating a high-quality segmentation mask for each instance. The method, called Mask R-CNN, extends Faster R-CNN by adding a branch for predicting an object mask in parallel with the existing branch for bounding box recognition. Mask R-CNN is simple to train and adds only a small overhead to Faster R-CNN, running at 5 fps. Moreover, Mask R-CNN is easy to generalize to other tasks, e.g., allowing us to estimate human poses in the same framework. We show top results in all three tracks of the COCO suite of challenges, including instance segmentation, bounding-box object detection, and person keypoint detection. Without tricks, Mask R-CNN outperforms all existing, single-model entries on every task, including the COCO 2016 challenge winners. We hope our simple and effective approach will serve as a solid baseline and help ease future research in instance-level recognition. Code will be made available.","['Computer science', 'Minimum bounding box', 'Segmentation', 'Artificial intelligence', 'Object detection', 'Bounding overwatch', 'Overhead (engineering)', 'Object (grammar)', 'Task (project management)', 'Code (set theory)', 'Simple (philosophy)', 'Suite', 'Pattern recognition (psychology)', 'Computer vision', 'Image (mathematics)', 'Image segmentation', 'Set (abstract data type)', 'Philosophy', 'Management', 'Epistemology', 'Archaeology', 'Economics', 'History', 'Programming language', 'Operating system']","object instance segmentation, bounding box recognition, instance segmentation, person keypoint detection, coco"
Paper_00316,The Effect of Intensive Treatment of Diabetes on the Development and Progression of Long-Term Complications in Insulin-Dependent Diabetes Mellitus,"['David M. Nathan', 'Saul Genuth', 'John M. Lachin', 'Patricia A. Cleary', 'Oscar B. Crofford', 'Janet L. Davis', 'Larry Rand', 'Carolyn Siebert']",1993,New England Journal of Medicine,Journal,,977-986,329,14,10.1056/nejm199309303291401,Long-term microvascular and neurologic complications cause major morbidity and mortality in patients with insulin-dependent diabetes mellitus (IDDM). We examined whether intensive treatment with the goal of maintaining blood glucose concentrations close to the normal range could decrease the frequency and severity of these complications.,"['Medicine', 'Diabetes mellitus', 'Insulin', 'Complication', 'Intensive care medicine', 'Internal medicine', 'Endocrinology']",
Paper_00317,"Self-determination theory and the facilitation of intrinsic motivation, social development, and well-being.","['Richard M. Ryan', 'Edward L. Deci']",2000,American Psychologist,Journal,,68-78,55,1,10.1037//0003-066x.55.1.68,"Human beings can be proactive and engaged or, alternatively, passive and alienated, largely as a function of the social conditions in which they develop and function. Accordingly, research guided by self-determination theory has focused on the social-contextual conditions that facilitate versus forestall the natural processes of self-motivation and healthy psychological development. Specifically, factors have been examined that enhance versus undermine intrinsic motivation, self-regulation, and well-being. The findings have led to the postulate of three innate psychological needs--competence, autonomy, and relatedness--which when satisfied yield enhanced self-motivation and mental health and when thwarted lead to diminished motivation and well-being. Also considered is the significance of these psychological needs and processes within domains such as health care, education, work, sport, religion, and psychotherapy.","['Self-determination theory', 'Psychology', 'Autonomy', 'Competence (human resources)', 'Intrinsic motivation', 'Social psychology', 'Cognitive evaluation theory', 'Facilitation', 'Function (biology)', ""Maslow's hierarchy of needs"", 'Self-actualization', 'Evolutionary biology', 'Political science', 'Law', 'Biology', 'Neuroscience']","healthy psychological development, intrinsic motivation, innate psychological needs, competence, autonomy, relatedness, health care, education, work, sport, religion, psychotherapy"
Paper_00318,Initial sequencing and analysis of the human genome,"['Eric S. Lander', 'Lauren Linton', 'Bruce W. Birren', 'Chad Nusbaum', 'Michael C. Zody', 'Jennifer N. Baldwin', 'Keri Devon', 'Ken Dewar', 'Michael P. Doyle', 'William W. Fitzhugh', 'Roel Funke', 'Diane Gage', 'Katrina L. Harris', 'Andrew Heaford', 'John G. Howland', 'Lisa Kann', 'Jessica A. Lehoczky', 'R Paul Levine', 'Paul McEwan', 'Kevin McKernan', 'James C. Meldrim', 'Jill P. Mesirov', 'Cher Miranda', 'William Morris', 'Jerome W. Naylor', 'Christina Raymond', 'Mark Rosetti', 'Ralph Santos', 'Andrew Sheridan', 'Carrie Sougnez', 'Nicole Stange-Thomann', 'Nikola M. Stojanović', 'Aravind Subramanian', 'Dudley Wyman', 'Jane Rogers', 'John Sulston', 'R. Ainscough', 'Stephan Beck', 'David Bentley', 'John H. Burton', 'Christopher Clee', 'Nigel Carter', 'Alan Coulson', 'Rebecca Deadman', 'Panos Deloukas', 'Andrew Dunham', 'Ian Dunham', 'Richard Durbin', 'Lisa French', 'Darren Grafham', 'Simon G. Gregory', 'Tim Hubbard', 'Sean Humphray', 'Adrienne Hunt', 'Matthew C. Jones', 'Christine Lloyd', 'Amanda A. McMurray', 'Lucy Matthews', 'Simon Mercer', 'Sarah Milne', 'James C. Mullikin', 'Andrew J. Mungall', 'R. W. Plumb', 'Mark T. Ross', 'R. Shownkeen', 'Sarah Sims', 'R Waterston', 'Richard K. Wilson', 'LaDeana W. Hillier', 'John D. McPherson', 'Marco A. Marra', 'Elaine R. Mardis', 'Lucinda A. Fulton', 'Asif Chinwalla', 'Kymberlie Pepin', 'Warren Gish', 'Stephanie L. Chissoe', 'Michael C. Wendl', 'Kim D. Delehaunty', 'Tracie L. Miner', 'Andrew Delehaunty', 'Jason Kramer', 'Lisa L. Cook', 'Robert S. Fulton', 'D. Johnson', 'Patrick Minx', 'Sandra W. Clifton', 'Trevor Hawkins', 'Elbert Branscomb', 'Paul Predki', 'Paul Richardson', 'Sarah Wenning', 'Tom Slezak', 'Norman A. Doggett', 'Jan‐Fang Cheng', 'Anne S. Olsen', 'Susan Lucas', 'Christopher J. Elkin', 'Edward C. Uberbacher', 'M.E. Frazier']",2001,Nature,Journal,,860-921,409,6822,10.1038/35057062,"The human genome holds an extraordinary trove of information about human development, physiology, medicine and evolution. Here we report the results of an international collaboration to produce and make freely available a draft sequence of the human genome. We also present an initial analysis of the data, describing some of the insights that can be gleaned from the sequence.","['Human genome', 'Genome', 'Sequence (biology)', 'Computational biology', 'Whole genome sequencing', 'Biology', 'DNA sequencing', 'Evolutionary biology', 'Data science', 'Genetics', 'Computer science', 'Gene']","human genome, human development, medicine, evolution, human genome"
Paper_00319,Chemical and isotopic systematics of oceanic basalts: implications for mantle composition and processes,"['Shen‐Su Sun', 'W. F. McDonough']",1989,Geological Society London Special Publications,Journal,,313-345,42,1,10.1144/gsl.sp.1989.042.01.19,"Summary Trace-element data for mid-ocean ridge basalts (MORBs) and ocean island basalts (OIB) are used to formulate chemical systematics for oceanic basalts. The data suggest that the order of trace-element incompatibility in oceanic basalts is Cs ≈ Rb ≈ (≈ Tl) ≈ Ba(≈ W) &gt; Th &gt; U ≈ Nb = Ta ≈ K &gt; La &gt; Ce ≈ Pb &gt; Pr (≈ Mo) ≈ Sr &gt; P ≈ Nd (&gt; F) &gt; Zr = Hf ≈ Sm &gt; Eu ≈ Sn (≈ Sb) ≈ Ti &gt; Dy ≈ (Li) &gt; Ho = Y &gt; Yb. This rule works in general and suggests that the overall fractionation processes operating during magma generation and evolution are relatively simple, involving no significant change in the environment of formation for MORBs and OIBs. In detail, minor differences in element ratios correlate with the isotopic characteristics of different types of OIB components (HIMU, EM, MORB). These systematics are interpreted in terms of partial-melting conditions, variations in residual mineralogy, involvement of subducted sediment, recycling of oceanic lithosphere and processes within the low velocity zone. Niobium data indicate that the mantle sources of MORB and OIB are not exact complementary reservoirs to the continental crust. Subduction of oceanic crust or separation of refractory eclogite material from the former oceanic crust into the lower mantle appears to be required. The negative europium anomalies observed in some EM-type OIBs and the systematics of their key element ratios suggest the addition of a small amount (⩽1% or less) of subducted sediment to their mantle sources. However, a general lack of a crustal signature in OIBs indicates that sediment recycling has not been an important process in the convecting mantle, at least not in more recent times (⩽2 Ga). Upward migration of silica-undersaturated melts from the low velocity zone can generate an enriched reservoir in the continental and oceanic lithospheric mantle. We propose that the HIMU type ( eg St Helena) OIB component can be generated in this way. This enriched mantle can be re-introduced into the convective mantle by thermal erosion of the continental lithosphere and by the recycling of the enriched oceanic lithosphere back into the mantle.","['Geology', 'Systematics', 'Mantle (geology)', 'Basalt', 'Geochemistry', 'Earth science', 'Oceanic crust', 'Subduction', 'Paleontology', 'Tectonics', 'Taxonomy (biology)', 'Botany', 'Biology']","ocean island basalts, chemical systematics, oceanic basalts, oceanic basalts, fractionation, ##ic characteristics, low velocity zone, sediment recycling, low, thermal erosion, continental lithosphere"
Paper_00320,Matrix Analysis,"['Roger A. Horn', 'Charles R. Johnson']",1985,['Exchange In Oceania'],Unknown,,115-155,,,10.1093/oso/9780198277606.003.0004,"Linear algebra and matrix theory are fundamental tools in mathematical and physical science, as well as fertile fields for research. This new edition of the acclaimed text presents results of both classic and recent matrix analyses using canonical forms as a unifying theme, and demonstrates their importance in a variety of applications. The authors have thoroughly revised, updated, and expanded on the first edition. The book opens with an extended summary of useful concepts and facts and includes numerous new topics and features, such as: - New sections on the singular value and CS decompositions - New applications of the Jordan canonical form - A new section on the Weyr canonical form - Expanded treatments of inverse problems and of block matrices - A central role for the Von Neumann trace theorem - A new appendix with a modern list of canonical forms for a pair of Hermitian matrices and for a symmetric-skew symmetric pair - Expanded index with more than 3,500 entries for easy reference - More than 1,100 problems and exercises, many with hints, to reinforce understanding and develop auxiliary themes such as finite-dimensional quantum systems, the compound and adjugate matrices, and the Loewner ellipsoid - A new appendix provides a collection of problem-solving hints.","['Canonical form', 'Algebra over a field', 'Mathematics', 'Matrix (chemical analysis)', 'Variety (cybernetics)', 'Section (typography)', 'TRACE (psycholinguistics)', 'Linear algebra', 'Von Neumann architecture', 'Hermitian matrix', 'Pure mathematics', 'Computer science', 'Geometry', 'Linguistics', 'Statistics', 'Materials science', 'Philosophy', 'Composite material', 'Operating system']","linear algebra, matrix theory, matrix analyses, canonical forms, singular value, cs decompositions, jordan canonical form, weyr canonical form, inverse problems, block matrices, von neumann trace theorem, hermitian matrices, adjugate matrices, loewner ellipsoid"
Paper_00321,Alternative Ways of Assessing Model Fit,"['Michael W. Browne', 'Robert Cudeck']",1992,Sociological Methods & Research,Journal,,230-258,21,2,10.1177/0049124192021002005,"This article is concerned with measures of fit of a model. Two types of error involved in fitting a model are considered. The first is error of approximation which involves the fit of the model, with optimally chosen but unknown parameter values, to the population covariance matrix. The second is overall error which involves the fit of the model, with parameter values estimated from the sample, to the population covariance matrix. Measures of the two types of error are proposed and point and interval estimates of the measures are suggested. These measures take the number of parameters in the model into account in order to avoid penalizing parsimonious models. Practical difficulties associated with the usual tests of exact fit or a model are discussed and a test of “close fit” of a model is suggested.","['Mathematics', 'Covariance', 'Statistics', 'Covariance matrix', 'Population', 'Type I and type II errors', 'Errors-in-variables models', 'Standard error', 'Population model', 'Applied mathematics', 'Point (geometry)', 'Econometrics', 'Demography', 'Geometry', 'Sociology']","measures of fit, error of approximation, population covariance matrix, overall error, population covariance matrix, interval estimates, parsimonious models, close fit, [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD], [PAD], [PAD]"
Paper_00322,Fast R-CNN,['Ross Girshick'],2015,Unknown,Unknown,,,,,10.1109/iccv.2015.169,"This paper proposes a Fast Region-based Convolutional Network method (Fast R-CNN) for object detection. Fast R-CNN builds on previous work to efficiently classify object proposals using deep convolutional networks. Compared to previous work, Fast R-CNN employs several innovations to improve training and testing speed while also increasing detection accuracy. Fast R-CNN trains the very deep VGG16 network 9x faster than R-CNN, is 213x faster at test-time, and achieves a higher mAP on PASCAL VOC 2012. Compared to SPPnet, Fast R-CNN trains VGG16 3x faster, tests 10x faster, and is more accurate. Fast R-CNN is implemented in Python and C++ (using Caffe) and is available under the open-source MIT License at https://github.com/rbgirshick/fast-rcnn.","['Computer science', 'Convolutional neural network', 'Pascal (unit)', 'Python (programming language)', 'Artificial intelligence', 'Object detection', 'Deep learning', 'Pattern recognition (psychology)', 'Programming language', 'Operating system']","##tional network, object detection, deep convolutional networks, testing speed, detection accuracy, vgg16, pascal voc, sppnet, caffe"
Paper_00324,MrBayes 3.2: Efficient Bayesian Phylogenetic Inference and Model Choice Across a Large Model Space,"['Fredrik Ronquist', 'Maxim Teslenko', 'Paul van der Mark', 'Daniel L. Ayres', 'Aaron E. Darling', 'Sebastian Höhna', 'Bret Larget', 'Liang Liu', 'Marc A. Suchard', 'John P. Huelsenbeck']",2012,Systematic Biology,Journal,,539-542,61,3,10.1093/sysbio/sys029,"Since its introduction in 2001, MrBayes has grown in popularity as a software package for Bayesian phylogenetic inference using Markov chain Monte Carlo (MCMC) methods. With this note, we announce the release of version 3.2, a major upgrade to the latest official release presented in 2003. The new version provides convergence diagnostics and allows multiple analyses to be run in parallel with convergence progress monitored on the fly. The introduction of new proposals and automatic optimization of tuning parameters has improved convergence for many problems. The new version also sports significantly faster likelihood calculations through streaming single-instruction-multiple-data extensions (SSE) and support of the BEAGLE library, allowing likelihood calculations to be delegated to graphics processing units (GPUs) on compatible hardware. Speedup factors range from around 2 with SSE code to more than 50 with BEAGLE for codon problems. Checkpointing across all models allows long runs to be completed even when an analysis is prematurely terminated. New models include relaxed clocks, dating, model averaging across time-reversible substitution models, and support for hard, negative, and partial (backbone) tree constraints. Inference of species trees from gene trees is supported by full incorporation of the Bayesian estimation of species trees (BEST) algorithms. Marginal model likelihoods for Bayes factor tests can be estimated accurately across the entire model space using the stepping stone method. The new version provides more output options than previously, including samples of ancestral states, site rates, site dN/dS rations, branch rates, and node dates. A wide range of statistics on tree parameters can also be output for visualization in FigTree and compatible software.","['Markov chain Monte Carlo', 'Computer science', 'Tree (set theory)', 'Speedup', 'Marginal likelihood', 'Range (aeronautics)', 'Bayesian probability', 'Algorithm', 'Bayesian inference', 'Markov chain', 'Inference', 'Parallel computing', 'Mathematics', 'Artificial intelligence', 'Machine learning', 'Mathematical analysis', 'Materials science', 'Composite material']","##es, bayesian phylogenetic inference, markov chain monte carlo, convergence diagnostics, beagle library, graphics processing units, gp, ##up, ##on, relaxed clocks, dating, model averaging, species trees, gene trees, bayesian estimation, species trees, marginal model likelihoods, bayes factor tests, stepping stone method, ancestral states, site rates, branch rates, node dates"
Paper_00325,Random sample consensus,"['Martin A. Fischler', 'Robert C. Bolles']",1981,Communications of the ACM,Journal,,381-395,24,6,10.1145/358669.358692,"A new paradigm, Random Sample Consensus (RANSAC), for fitting a model to experimental data is introduced. RANSAC is capable of interpreting/smoothing data containing a significant percentage of gross errors, and is thus ideally suited for applications in automated image analysis where interpretation is based on the data provided by error-prone feature detectors. A major portion of this paper describes the application of RANSAC to the Location Determination Problem (LDP): Given an image depicting a set of landmarks with known locations, determine that point in space from which the image was obtained. In response to a RANSAC requirement, new results are derived on the minimum number of landmarks needed to obtain a solution, and algorithms are presented for computing these minimum-landmark solutions in closed form. These results provide the basis for an automatic system that can solve the LDP under difficult viewing","['RANSAC', 'Smoothing', 'Computer science', 'Artificial intelligence', 'Landmark', 'Sample (material)', 'Feature (linguistics)', 'Computer vision', 'Set (abstract data type)', 'Basis (linear algebra)', 'Image (mathematics)', 'Point (geometry)', 'Pattern recognition (psychology)', 'Algorithm', 'Data mining', 'Mathematics', 'Linguistics', 'Chemistry', 'Philosophy', 'Geometry', 'Chromatography', 'Programming language']","random sample consensus, ransac, ransac, automated image analysis, ransac, location determination problem, ransac, automatic system, [PAD], [PAD] [PAD] [PAD] [PAD], [PAD], [PAD]"
Paper_00327,Social Capital in the Creation of Human Capital,['James S. Coleman'],1988,American Journal of Sociology,Journal,,S95-S120,94,,10.1086/228943,"There are two broad intellectual streams in the description and explanation of social action. One, characteristic of the work of most sociologists, sees the actor as socialized and action as governed by social norms, rules, and obligations. The principal virtues of this intellectual stream lie in its ability to describe action in social context and to explain the way action is shaped, constrained, and redirected by the social context. The other intellectual stream, characteristic of the work of most economists, sees the actor as having goals independently arrived at, as acting independently, and as wholly self-interested. Its principal virtue lies in having a principle of action, that of maximizing utility. This principle of action, together with a single empirical generalization (declining marginal utility), has generated the extensive growth of neoclassical economic theory, as well as the growth of political philosophy of several varieties: utilitarianism, contractarianism, and natural rights. In earlier works (Coleman 1986a, 1986b), I have argued for and engaged in the development of a theoretical orientation in sociology that includes components from both these intellectual streams. It accepts the principle of rational or purposive action and attempts to show how that principle, in conjunction with particular social contexts, can account not only for the actions of individuals in particular contexts but also for the development of social organization. In the present paper, I introduce a conceptual tool for use in this theoretical enterprise: social capital. As background for introducing this concept, it is useful to see some of the criticisms of and attempts to modify the two intellectual streams. Both these intellectual streams have serious defects. The sociological stream has what may be a fatal flaw as a theoretical enterprise: the actor has no “engine of action.” The actor is shaped by the environment, but there are no internal springs of action that give the actor a purpose or direction. The very conception of action as wholly a product of the environment has led sociologists themselves to criticize this intellectual stream, as in Dennis Wrong’s (1961) “Oversocialized Conception of Man in Modern Sociology.”","['Social capital', 'Business', 'Human capital', 'Financial capital', 'Capital (architecture)', 'Natural resource economics', 'Economics', 'Market economy', 'Sociology', 'Geography', 'Social science', 'Archaeology']","social action, social norms, obligations, utility, marginal utility, neoclassical economic theory, political philosophy, utilitarianism, contractarianism, natural rights, social organization, social capital, man"
Paper_00328,GAN（Generative Adversarial Nets）,"['Ian Goodfellow', 'Jean Pouget-Abadie', 'Mehdi Mirza', 'Bing Xu', 'David Warde-Farley', 'Sherjil Ozair', 'Aaron Courville', 'Yoshua Bengio']",2017,Journal of Japan Society for Fuzzy Theory and Intelligent Informatics,Journal,,177-177,29,5,10.3156/jsoft.29.5_177_2,"We propose a new framework for estimating generative models via an adversarial process, in which we simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D, a unique solution exists, with G recovering the training data distribution and D equal to ½ everywhere. In the case where G and D are defined by multilayer perceptrons, the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitative evaluation of the generated samples.","['Adversarial system', 'Generative grammar', 'Computer science', 'Artificial intelligence']","generative models, adversarial process, generative model, data distribution, discriminative model, training data distribution, multilayer perceptrons, backpropagation, markov chains, ##rolled approximate inference networks"
Paper_00271,Numerical Heat Transfer and Fluid Flow,['Suhas V. Patankar'],2018,CRC Press eBooks,Unknown,,,,,10.1201/9781482234213,"This book focuses on heat and mass transfer, fluid flow, chemical reaction, and other related processes that occur in engineering equipment, the natural environment, and living organisms. Using simple algebra and elementary calculus, the author develops numerical methods for predicting these processes mainly based on physical considerations. Through this approach, readers will develop a deeper understanding of the underlying physical aspects of heat transfer and fluid flow as well as improve their ability to analyze and interpret computed results.","['Mechanics', 'Heat transfer', 'Fluid dynamics', 'Flow (mathematics)', 'Materials science', 'Physics']","mass transfer, fluid flow, chemical reaction, engineering equipment, living organisms, simple algebra, elementary calculus, numerical methods, heat transfer, fluid flow, [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD], [PAD] [PAD], [PAD] [PAD]"
Paper_00272,Strategic Management: A Stakeholder Approach,['R. Edward Freeman'],1984,['SSRN Electronic Journal'],Unknown,,,,,10.2139/ssrn.263511,Part I. The Stakeholder Approach: 1. Managing in turbulent times 2. The stakeholder concept and strategic management 3. Stakeholder management: framework and philosophy Part II. Strategic Management Processes: 4. Setting strategic direction 5. Formulating strategies for stakeholders 6. Implementing and monitoring stakeholder strategies Part III. Implications for Theory and Practice: 7. Conflict at the board level 8. The functional disciplines of management 9. The role of the executive.,"['Stakeholder', 'Stakeholder analysis', 'Stakeholder management', 'Business', 'Stakeholder theory', 'Strategic management', 'Process management', 'Strategic planning', 'Management philosophy', 'Strategic thinking', 'Knowledge management', 'Management', 'Political science', 'Public relations', 'Computer science', 'Marketing', 'Economics']","stakeholder approach, turbulent times, stakeholder concept, strategic management, stakeholder management, strategic management processes, strategic direction, stakeholder strategies, functional disciplines, executive, [PAD], [PAD], [PAD], [PAD], [PAD] [PAD], [PAD] [PAD] [PAD], [PAD] [PAD], [PAD] [PAD] [PAD], [PAD], [PAD]"
Paper_00273,<i>SHELXT</i>– Integrated space-group and crystal-structure determination,['George M. Sheldrick'],2014,Acta Crystallographica Section A Foundations and Advances,Journal,,3-8,71,1,10.1107/s2053273314026370,"The new computer program SHELXT employs a novel dual-space algorithm to solve the phase problem for single-crystal reflection data expanded to the space group P1. Missing data are taken into account and the resolution extended if necessary. All space groups in the specified Laue group are tested to find which are consistent with the P1 phases. After applying the resulting origin shifts and space-group symmetry, the solutions are subject to further dual-space recycling followed by a peak search and summation of the electron density around each peak. Elements are assigned to give the best fit to the integrated peak densities and if necessary additional elements are considered. An isotropic refinement is followed for non-centrosymmetric space groups by the calculation of a Flack parameter and, if appropriate, inversion of the structure. The structure is assembled to maximize its connectivity and centred optimally in the unit cell. SHELXT has already solved many thousand structures with a high success rate, and is optimized for multiprocessor computers. It is, however, unsuitable for severely disordered and twinned structures because it is based on the assumption that the structure consists of atoms.","['Group (periodic table)', 'Space (punctuation)', 'Space group', 'Crystal structure', 'Isotropy', 'Data structure', 'Unit (ring theory)', 'Inversion (geology)', 'Reflection (computer programming)', 'Crystallography', 'Group structure', 'Mathematics', 'Computer science', 'Physics', 'Chemistry', 'Optics', 'Quantum mechanics', 'Diffraction', 'X-ray crystallography', 'Psychology', 'Paleontology', 'Programming language', 'Mathematics education', 'Structural basin', 'Psychotherapist', 'Biology', 'Operating system']","shelxt, phase problem, laue group, origin, peak search, electron density, integrated peak densities, isotropic refinement, - centrosymmetric, flack parameter, ##xt, multiprocessor computers"
Paper_00274,The Nature of the Firm,['Ronald H. Coase'],1937,Economica,Journal,,386-405,4,16,10.1111/j.1468-0335.1937.tb00002.x,"Economic theory has suffered in the past from a failure to state clearly its assumptions. Economists in building up a theory have often omitted to examine the foundations on which it was erected. This examination is, however, essential not only to prevent the misunderstanding and needless controversy which arise from a lack of knowledge of the assumptions on which a theory is based, but also because of the extreme importance for economics of good judgment in choosing between rival sets of assumptions. For instance, it is suggested that the use of the word “firm” in economics may be different from the use of the term by the “plain man.”11 Joan Robinson, Economics is a Serious Subject, p. 12. Since there is apparently a trend in economic theory towards starting analysis with the individual firm and not with the industry,22 See N. Kaldor, “The Equilibrium of the Firm,”Economic Journal, March, 1934. it is all the more necessary not only that a clear definition of the word “firm” should be given but that its difference from a firm in the “real world,” if it exists, should be made clear. Mrs. Robinson has said that “the two questions to be asked of a set of assumptions in economics are : Are they tractable? and : Do they correspond with the real world?”33 Op. cit., p. 6. Though, as Mrs. Robinson points out, “more often one set will be manageable and the other realistic,” yet there may well be branches of theory where assumptions may be both manageable and realistic. It is hoped to show in the following paper that a definition of a firm may be obtained which is not only realistic in that it corresponds to what is meant by a firm in the real world, but is tractable by two of the most powerful instruments of economic analysis developed by Marshall, the idea of the margin and that of substitution, together giving the idea of substitution at the margin.11 J. M. Keynes, Essays in Biography, pp. 223–4. Our definition must, of course, “relate to formal relations which are capable of being conceived exactly.”22 L. Robbins, Nature and Significance of Economic Science, p. 63. It is convenient if, in searching for a definition of a firm, we first consider the economic system as it is normally treated by the economist. Let us consider the description of the economic system given by Sir Arthur Salter.33 This description is quoted with approval by D. H. Robertson, Control of Industry, p. 85, and by Professor Arnold Plant, “Trends in Business Administration,” Economica, February, 1932. It appears in Allied Shipping Control, pp. 16–17. “The normal economic system works itself. For its current operation it is under no central control, it needs no central survey. Over the whole range of human activity and human need, supply is adjusted to demand, and production to consumption, by a process that is automatic, elastic and responsive.” An economist thinks of the economic system as being co-ordinated by the price mechanism and society becomes not an organisation but an organism.44 See F. A. Hayek, “The Trend of Economic Thinking,” Economica, May, 1933. The economic system “works itself.” This does not mean that there is no planning by individuals. These exercise foresight and choose between alternatives. This is necessarily so if there is to be order in the system. But this theory assumes that the direction of resources is dependent directly on the price mechanism. Indeed, it is often considered to be an objection to economic planning that it merely tries to do what is already done by the price mechanism.55 See F. A. Hayek, op. cit. Sir Arthur Salter's description, however, gives a very incomplete picture of our economic system. Within a firm, the description does not fit at all. For instance, in economic theory we find that the allocation of factors of production between different uses is determined by the price mechanism. The price of factor A becomes higher in X than in Y. As a result, A moves from Y to X until the difference between the prices in X and Y, except in so far as it compensates for other differential advantages, disappears. Yet in the real world, we find that there are many areas where this does not apply. If a workman moves from department Y to department X, he does not go because of a change in relative prices, but because he is ordered to do so. Those who object to economic planning on the grounds that the problem is solved by price movements can be answered by pointing out that there is planning within our economic system which is quite different from the individual planning mentioned above and which is akin to what is normally called economic planning. The example given above is typical of a large sphere in our modern economic system. Of course, this fact has not been ignored by economists. Marshall introduces organisation as a fourth factor of production; J. B. Clark gives the co-ordinating function to the entrepreneur; Professor Knight introduces managers who co-ordinate. As D. H. Robertson points out, we find “islands of conscious power in this ocean of unconscious co-operation like lumps of butter coagulating in a pail of buttermilk.”11 Op. cit., p. 85. But in view of the fact that it is usually argued that co-ordination will be done by the price mechanism, why is such organisation necessary? Why are there these “islands of conscious power”? Outside the firm, price movements direct production, which is co-ordinated through a series of exchange transactions on the market. Within a firm, these market transactions are eliminated and in place of the complicated market structure with exchange transactions is substituted the entrepreneur-co-ordinator, who directs production.22 In the rest of this paper I shall use the term entrepreneur to refer to the person or persons who, in a competitive system, take the place of the price mechanism in the direction of resources. It is clear that these are alternative methods of co-ordinating production. Yet, having regard to the fact that if production is regulated by price movements, production could be carried on without any organisation at all, well might we ask, why is there any organisation? Of course, the degree to which the price mechanism is superseded varies greatly. In a department store, the allocation of the different sections to the various locations in the building may be done by the controlling authority or it may be the result of competitive price bidding for space. In the Lancashire cotton industry, a weaver can rent power and shop-room and can obtain looms and yarn on credit.33 Survey of Textile Industries, p. 26. This co-ordination of the various factors of production is, however, normally carried out without the intervention of the price mechanism. As is evident, the amount of “vertical” integration, involving as it does the supersession of the price mechanism, varies greatly from industry to industry and from firm to firm. It can, I think, be assumed that the distinguishing mark of the firm is the supersession of the price mechanism. It is, of course, as Professor Robbins points out, “related to an outside network of relative prices and costs,”11 Op. cit., p. 71. but it is important to discover the exact nature of this relationship. This distinction between the allocation of resources in a firm and the allocation in the economic system has been very vividly described by Mr. Maurice Dobb when discussing Adam Smith's conception of the capitalist: “It began to be seen that there was something more important than the relations inside each factory or unit captained by an undertaker; there were the relations of the undertaker with the rest of the economic world outside his immediate sphere…. the undertaker busies himself with the division of labour inside each firm and he plans and organises consciously,” but “he is related to the much larger economic specialisation, of which he himself is merely one specialised unit. Here, he plays his part as a single cell in a larger organism, mainly unconscious of the wider rôle he fills.”22 Capitalist Enterprise and Social Progress, p. 20. Cf., also, Henderson, Supply and Demand, pp. 3–5. In view of the fact that while economists treat the price mechanism as a co-ordinating instrument, they also admit the co-ordinating function of the “entrepreneur,” it is surely important to enquire why co-ordination is the work of the price mechanism in one case and of the entrepreneur in another. The purpose of this paper is to bridge what appears to be a gap in economic theory between the assumption (made for some purposes) that resources are allocated by means of the price mechanism and the assumption (made for other purposes) that this allocation is dependent on the entrepreneur-co-ordinator. We have to explain the basis on which, in practice, this choice between alternatives is effected.33 It is easy to see when the State takes over the direction of an industry that, in planning it, it is doing something which was previously done by the price mechanism. What is usually not realised is that any business man in organising the relations between his departments is also doing something which could be organised through the price mechanism. There is therefore point in Mr. Durbin's answer to those who emphasise the problems involved in economic planning that the same problems have to be solved by business men in the competitive system. (See “Economic Calculus in a Planned Economy,”Economic Journal, December, 1936.) The important difference between these two cases is that economic planning is imposed on industry while firms arise voluntarily because they represent a more efficient method of organising production. In a competitive system, there is an “optimum” amount of planning! Our task is to attempt to discover why a firm emerges at all in a specialised exchange economy. The price mechanism (considered purely from the side of the direction of resources) might be superseded if the relationship which replaced it was desired for its own sake. This would be the case, for example, if some people preferred to work under the direction of some other person. Such individuals would accept less in order to work under someone, and firms would arise naturally from this. But it would appear that this cannot be a very important reason, for it would rather seem that the opposite tendency is operating if one judges from the stress normally laid on the advantage of “being one's own master.”11 Cf. Harry Dawes, “Labour Mobility in the Steel Industry,”Economic Journal, March, 1934, who instances “the trek to retail shopkeeping and insurance work by the better paid of skilled men due to the desire (often the main aim in life of a worker) to be independent” (p. 86). Of course, if the desire was not to be controlled but to control, to exercise power over others, then people might be willing to give up something in order to direct others; that is, they would be willing to pay others more than they could get under the price mechanism in order to be able to direct them. But this implies that those who direct pay in order to be able to do this and are not paid to direct, which is clearly not true in the majority of cases.22 None the less, this is not altogether fanciful. Some small shopkeepers are said to earn less than their assistants. Firms might also exist if purchasers preferred commodities which are produced by firms to those not so produced; but even in spheres where one would expect such preferences (if they exist) to be of negligible importance, firms are to be found in the real world.33 G. F. Shove, “The Imperfection of the Market: a Further Note,”Economic Journal, March, 1933, p. 116, note 1, points out that such preferences may exist, although the example he gives is almost the reverse of the instance given in the text. Therefore there must be other elements involved. The main reason why it is profitable to establish a firm would seem to be that there is a cost of using the price mechanism. The most obvious cost of “organising” production through the price mechanism is that of discovering what the relevant prices are.44 According to N. Kaldor, “A Classificatory Note of the Determinateness of Equilibrium,”Review of Economic Studies, February, 1934, it is one of the assumptions of static theory that “All the relevant prices are known to all individuals.” But this is clearly not true of the real world. This cost may be reduced but it will not be eliminated by the emergence of specialists who will sell this information. The costs of negotiating and concluding a separate contract for each exchange transaction which takes place on a market must also be taken into account.11 This influence was noted by Professor Usher when discussing the development of capitalism. He says: “The successive buying and selling of partly finished products were sheer waste of energy.” (Introduction to the Industrial History of England, p. 13). But he does not develop the idea nor consider why it is that buying and selling operations still exist. Again, in certain markets, e.g., produce exchanges, a technique is devised for minimising these contract costs; but they are not eliminated. It is true that contracts are not eliminated when there is a firm but they are greatly reduced. A factor of production (or the owner thereof) does not have to make a series of contracts with the factors with whom he is co-operating within the firm, as would be necessary, of course, if this co-operation were as a direct result of the working of the price mechanism. For this series of contracts is substituted one. At this stage, it is important to note the character of the contract into which a factor enters that is employed within a firm. The contract is one whereby the factor, for a certain remuneration (which may be fixed or fluctuating), agrees to obey the directions of an entrepreneur within certain limits.22 It would be possible for no limits to the powers of the entrepreneur to be fixed. This would be voluntary slavery. According to Professor Batt, The Law of Master and Servant, p. 18, such a contract would be void and unenforceable. The essence of the contract is that it should only state the limits to the powers of the entrepreneur. Within these limits, he can therefore direct the other factors of production. There are, however, other disadvantages—or costs—of using the price mechanism. It may be desired to make a long-term contract for the supply of some article or service. This may be due to the fact that if one contract is made for a longer period, instead of several shorter ones, then certain costs of making each contract will be avoided. Or, owing to the risk attitude of the people concerned, they may prefer to make a long rather than a short-term contract. Now, owing to the difficulty of forecasting, the longer the period of the contract is for the supply of the commodity or service, the less possible, and indeed, the less desirable it is for the person purchasing to specify what the other contracting party is expected to do. It may well be a matter of indifference to the person supplying the service or commodity which of several courses of action is taken, but not to the purchaser of that service or commodity. But the purchaser will not know which of these several courses he will want the supplier to take. Therefore, the service which is being provided is expressed in general terms, the exact details being left until a later date. All that is stated in the contract is the limits to what the persons supplying the commodity or service is expected to do. The details of what the supplier is expected to do is not stated in the contract but is decided later by the purchaser. When the direction of resources (within the limits of the contract) becomes dependent on the buyer in this way, that relationship which I term a “firm” may be obtained.11 Of course, it is not possible to draw a hard and fast line which determines whether there is a firm or not. There may be more or less direction. It is similar to the legal question of whether there is the relationship of master and servant or principal and agent. See the discussion of this problem below. A firm is likely therefore to emerge in those cases where a very short term contract would be unsatisfactory. It is obviously of more importance in the case of services—labour—than it is in the case of the buying of commodities. In the case of commodities, the main items can be stated in advance and the details which will be decided later will be of minor significance. We may sum up this section of the argument by saying that the operation of a market costs something and by forming an organisation and allowing some authority (an “entrepreneur”) to direct the resources, certain marketing costs are saved. The entrepreneur has to carry out his function at less cost, taking into account the fact that he may get factors of production at a lower price than the market transactions which he supersedes, because it is always possible to revert to the open market if he fails to do this. The question of uncertainty is one which is often considered to be very relevant to the study of the equilibrium of the firm. It seems improbable that a firm would emerge without the existence of uncertainty. But those, for instance, Professor Knight, who make the mode of payment the distinguishing mark of the firm—fixed incomes being guaranteed to some of those engaged in production by a person who takes the residual, and fluctuating, income—would appear to be introducing a point which is irrelevant to the problem we are considering. One entrepreneur may sell his services to another for a certain sum of money, while the payment to his employees may be mainly or wholly a share in profits.22 The views of Professor Knight are examined below in more detail. The significant question would appear to be why the allocation of resources is not done directly by the price mechanism. Another factor that should be noted is that exchange transactions on a market and the same transactions organised within a firm are often treated differently by Governments or other bodies with regulatory powers. If we consider the operation of a sales tax, it is clear that it is a tax on market transactions and not on the same transactions organised within the firm. Now since these are alternative methods of “organisation”—by the price mechanism or by the entrepreneur—such a regulation would bring into existence firms which otherwise would have no raison d'être. It would furnish a reason for the emergence of a firm in a specialised exchange economy. Of course, to the extent that firms already exist, such a measure as a sales tax would merely tend to make them larger than they would otherwise be. Similarly, quota schemes, and methods of price control which imply that there is rationing, and which do not apply to firms producing such products for themselves, by allowing advantages to those who organise within the firm and not through the market, necessarily encourage the growth of firms. But it is difficult to believe that it is measures such as have been mentioned in this paragraph which have brought firms into existence. Such measures would, however, tend to have this result if they did not exist for other reasons. These, then, are the reasons why organisations such as firms exist in a specialised exchange economy in which it is generally assumed that the distribution of resources is “organised” by the price mechanism. A firm, therefore, consists of the system of relationships which comes into existence when the direction of resources is dependent on an entrepreneur. The approach which has just been sketched would appear to offer an advantage in that it is possible to give a scientific meaning to what is meant by saying that a firm gets larger or smaller. A firm becomes larger as additional transactions (which could be exchange transactions co-ordinated through the price mechanism) are organised by the entrepreneur and becomes smaller as he abandons the organisation of such transactions. The question which arises is whether it is possible to study the forces which determine the size of the firm. Why does the entrepreneur not organise one less transaction or one more? It is interesting to note that Professor Knight considers that: “the relation between efficiency and size is one of the most serious problems of theory, being, in contrast with the relation for a plant, largely a matter of personality and historical accident rather than of intelligible general principles. But the question is peculiarly vital because the possibility of monopoly gain offers a powerful incentive to continuous and unlimited expansion of the firm, which force must be offset by some equally powerful one making for decreased efficiency (in the production of money income) with growth in size, if even boundary competition is to exist.”11 Risk, Uncertainty and Profit, Preface to the Re-issue, London School of Economics Series of Reprints, No. 16, 1933. Professor Knight would appear to consider that it is impossible to treat scientifically the determinants of the size of the firm. On the basis of the concept of the firm developed above, this task will now be attempted. It was suggested that the introduction of the firm was due primarily to the existence of marketing costs. A pertinent question to ask would appear to be (quite apart from the monopoly considerations raised by Professor Knight), why, if by organising one can eliminate certain costs and in fact reduce the cost of production, are there any market transactions at all?22 There are certain marketing costs which could only be eliminated by the abolition of “consumers' choice” and these are the costs of retailing. It is conceivable that these costs might be so high that people would be willing to accept rations because the extra product obtained was worth the loss of their choice. Why is not all production carried on by one big firm? There would appear to be certain possible explanations. First, as a firm gets larger, there may be decreasing returns to the entrepreneur function, that is, the costs of organising additional transactions within the firm may rise.33 This argument assumes that exchange transactions on a market can be considered as homogeneous; which is clearly untrue in fact. This complication is taken into account below. Naturally, a point must be reached where the costs of organising an extra transaction within the firm are equal to the costs involved in carrying out the transaction in the open market, or, to the costs of organising by another entrepreneur. Secondly, it may be that as the transactions which are organised increase, the entrepreneur fails to place the factors of production in the uses where their value is greatest, that is, fails to make the best use of the factors of production. Again, a point must be reached where the loss through the waste of resources is equal to the marketing costs of the exchange transaction in the open market or to the loss if the transaction was organised by another entrepreneur. Finally, the supply price of one or more of the factors of production may rise, because the “other advantages” of a small firm are greater than those of a large firm.11 For a discussion of the variation of the supply price of factors of production to firms of varying size, see E. A. G. Robinson, The Structure of Competitive Industry. It is sometimes said that the supply price of organising ability increases as the size of the firm increases because men prefer to be the heads of small independent businesses rather than the heads of departments in a large business. See Jones, The Trust Problem, p. 531, and Macgregor, Industrial Combination, p. 63. This is a common argument of those who advocate Rational-sation. It is said that larger units would be more efficient, but owing to the individualistic spirit of the smaller entrepreneurs, they prefer to remain independent, apparently in spite of the higher income which their increased efficiency under Rationalisation makes possible. Of course, the actual point where the expansion of the firm ceases might be determined by a combination of the factors mentioned above. The first two reasons given most probably correspond to the economists' phrase of “diminishing returns to management.”22 This discussion is, of course, brief and incomplete. For a more thorough discussion of this particular problem, see N. Kaldor, “The Equilibrium of the Firm,”Economic Journal, March, 1934, and E. A. G. Robinson, “The Problem of Management and the Size of the Firm,”Economic Journal, June, 1934. The point has been made in the previous paragraph that a firm will tend to expand until the costs of organising an extra transaction within the firm become equal to the costs of carrying out the same transaction by means of an exchange on the open market or the costs of organising in another firm. But if the firm stops its expansion at a point below the costs of marketing in the open market and at a point equal to the costs of organising in another firm, in most cases (excluding the case of “combination”3), this will imply that there is a market transaction between these two producers, each of whom could organise it at less than the actual marketing costs. How is the paradox to be resolved? If we consider an example the reason for this will become clear. Suppose A is buying a product from B and that both A and B could organise this marketing transaction at less than its present cost. B, we can assume, is not organising one process or stage of production, but several. If A therefore wishes to avoid a market transaction, he will have to take over all the processes of production controlled by B. Unless A takes over all the processes of production, a market transaction will still remain, although it is a different product that is bought. But we have previously assumed that as each producer expands he becomes less efficient; the additional costs of organising extra transactions increase. It is probable that A's cost of organising the transactions previously organised by B will be greater than B's cost of doing the same thing. A therefore will take over the whole of B's organisation only if his cost of organising B's work is not greater than B's cost by an amount equal to the costs of carrying out an exchange transaction on the open market. But once it becomes economical to have a market transaction, it also pays to divide production in such a way that the cost of organising an extra transaction in each firm is the same. Up to now it has been assumed that the exchange transactions which take place through the price mechanism are homogeneous. In fact, nothing could be more diverse than the actual transactions which take place in our modern world. This would seem to imply that the costs of carrying out exchange transactions through the price mechanism will vary considerably as will also the costs of organising these transactions within the firm. It seems therefore possible that quite apart from the question of diminishing returns the costs of organising certain transactions within the firm may be greater than the costs of carrying out the exchange transactions in the open market. This would necessarily imply that there were exchange transactions carried out through the price mechanism, but would it mean that there would have to be more than one firm? Clearly not, for all those areas in the economic system where the direction of resources was not dependent directly on the price mechanism could be organised within one firm. The factors which were discussed earlier would seem to be the important ones, though it is difficult to say whether “diminishing returns to management” or the rising supply price of factors is likely to be the more important. Other things being equal, therefore, a firm will tend to be larger: the less the costs of organising and the slower these costs rise with an increase in the transactions organised. the less likely the entrepreneur is to make mistakes and the smaller the increase in mistakes with an increase in the transactions organised. the greater the lowering (or the less the rise) in the supply price of factors of production to firms of larger size. Apart from variations in the supply price of factors of production to firms of different sizes, it would appear that the costs of organising and the losses through mistakes will increase with an increase in the spatial distribution of the transactions organised, in the diss","['Set (abstract data type)', 'Economics', 'Theory of the firm', 'Positive economics', 'Subject (documents)', 'Neoclassical economics', 'Term (time)', 'Mathematical economics', 'Computer science', 'Physics', 'Quantum mechanics', 'Library science', 'Programming language']","economic theory, economic analysis, margin, substitution, substitution, formal relations, economic science"
Paper_00275,Feature Pyramid Networks for Object Detection,"['Tsung-Yi Lin', 'Piotr Dollár', 'Ross Girshick', 'Kaiming He', 'Bharath Hariharan', 'Serge Belongie']",2017,Unknown,Unknown,,,,,10.1109/cvpr.2017.106,"Feature pyramids are a basic component in recognition systems for detecting objects at different scales. But pyramid representations have been avoided in recent object detectors that are based on deep convolutional networks, partially because they are slow to compute and memory intensive. In this paper, we exploit the inherent multi-scale, pyramidal hierarchy of deep convolutional networks to construct feature pyramids with marginal extra cost. A top-down architecture with lateral connections is developed for building high-level semantic feature maps at all scales. This architecture, called a Feature Pyramid Network (FPN), shows significant improvement as a generic feature extractor in several applications. Using a basic Faster R-CNN system, our method achieves state-of-the-art single-model results on the COCO detection benchmark without bells and whistles, surpassing all existing single-model entries including those from the COCO 2016 challenge winners. In addition, our method can run at 5 FPS on a GPU and thus is a practical and accurate solution to multi-scale object detection. Code will be made publicly available.","['Pyramid (geometry)', 'Computer science', 'Feature (linguistics)', 'Object detection', 'Benchmark (surveying)', 'Artificial intelligence', 'Feature extraction', 'Convolutional neural network', 'Pattern recognition (psychology)', 'Construct (python library)', 'Exploit', 'Semantic feature', 'Object (grammar)', 'Hierarchy', 'Mathematics', 'Programming language', 'Philosophy', 'Linguistics', 'Geometry', 'Computer security', 'Geodesy', 'Geography', 'Economics', 'Market economy']","feature pyramids, recognition systems, pyramid representations, object detectors, deep convolutional networks, deep convolutional networks, feature pyramids, lateral connections, semantic feature maps, feature pyramid network, coco detection, whistle, coco, [PAD], [PAD] [PAD] [PAD], [PAD] [PAD], [PAD], [PAD], [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD] [PAD], [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"
Paper_00277,The electronic properties of graphene,"['A. H. Castro Neto', 'F. Guinea', 'N. M. R. Peres', 'Kostya S. Novoselov', 'A. K. Geǐm']",2009,Reviews of Modern Physics,Journal,,109-162,81,1,10.1103/revmodphys.81.109,"This article reviews the basic theoretical aspects of graphene, a one-atom-thick allotrope of carbon, with unusual two-dimensional Dirac-like electronic excitations. The Dirac electrons can be controlled by application of external electric and magnetic fields, or by altering sample geometry and/or topology. The Dirac electrons behave in unusual ways in tunneling, confinement, and the integer quantum Hall effect. The electronic properties of graphene stacks are discussed and vary with stacking order and number of layers. Edge (surface) states in graphene depend on the edge termination (zigzag or armchair) and affect the physical properties of nanoribbons. Different types of disorder modify the Dirac equation leading to unusual spectroscopic and transport properties. The effects of electron-electron and electron-phonon interactions in single layer and multilayer graphene are also presented.","['Graphene', 'Physics', 'Condensed matter physics', 'Zigzag', 'Electron', 'Dirac (video compression format)', 'Quantum tunnelling', 'Quantum Hall effect', 'Stacking', 'Bilayer graphene', 'Electronic structure', 'Graphene nanoribbons', 'Quantum mechanics', 'Geometry', 'Mathematics', 'Nuclear magnetic resonance', 'Neutrino']","graphene, ##rop, dirac, magnetic fields, sample geometry, dirac, tunneling, confinement, integer quantum hall effect, graphene stacks, ##ing, graph, edge termination, nanoribbons, ##ac, multilayer graphene"
Paper_00279,The Discovery of Grounded Theory,"['Barney G. Glaser', 'Anselm L. Strauss']",2017,Routledge eBooks,Unknown,,,,,10.4324/9780203793206,"The discovery of grounded theory , The discovery of grounded theory , کتابخانه مرکزی دانشگاه علوم پزشکی تهران","['Grounded theory', 'Computer science', 'Sociology', 'Social science', 'Qualitative research']","grounded theory, grounded theory, [PAD] [PAD]"
Paper_00281,A Contribution to the Theory of Economic Growth,['Robert M. Solow'],1956,The Quarterly Journal of Economics,Journal,,65-65,70,1,10.2307/1884513,"Journal Article A Contribution to the Theory of Economic Growth Get access Robert M. Solow Robert M. Solow Massachusetts Institute of Technology Search for other works by this author on: Oxford Academic Google Scholar The Quarterly Journal of Economics, Volume 70, Issue 1, February 1956, Pages 65–94, https://doi.org/10.2307/1884513 Published: 01 February 1956","['Growth theory', 'Mathematical economics', 'Economics', 'Library science', 'Regional science', 'Economic history', 'Sociology', 'Neoclassical economics', 'Computer science']","economic growth, massachusetts, quarterly, economics, [PAD]"
Paper_00284,The Ecological Approach to Visual Perception,"['Marc H. Bornstein', 'James J. Gibson']",1980,Journal of Aesthetics and Art Criticism,Journal,,203-203,39,2,10.2307/429816,"Contents: Preface. Introduction. Part I: The Environment To Be Perceived.The Animal And The Environment. Medium, Substances, Surfaces. The Meaningful Environment. Part II: The Information For Visual Perception.The Relationship Between Stimulation And Stimulus Information. The Ambient Optic Array. Events And The Information For Perceiving Events. The Optical Information For Self-Perception. The Theory Of Affordances. Part III: Visual Perception.Experimental Evidence For Direct Perception: Persisting Layout. Experiments On The Perception Of Motion In The World And Movement Of The Self. The Discovery Of The Occluding Edge And Its Implications For Perception. Looking With The Head And Eyes. Locomotion And Manipulation. The Theory Of Information Pickup And Its Consequences. Part IV: Depiction.Pictures And Visual Awareness. Motion Pictures And Visual Awareness. Conclusion. Appendixes: The Principal Terms Used in Ecological Optics. The Concept of Invariants in Ecological Optics.","['Perception', 'Geography', 'Ecological psychology', 'Ecology', 'Psychology', 'Environmental resource management', 'Computer science', 'Environmental science', 'Cognitive psychology', 'Biology', 'Neuroscience']","meaningful environment, visual perception, stimulus information, ambient optic array, optical information, affordances, visual perception, direct perception, persisting layout, occluding edge, locomotion, manipulation, information pickup, visual awareness, motion pictures, visual awareness, ecological optics, invariants, ecological optics"
Paper_00285,Greedy function approximation: A gradient boosting machine.,['Jerome H. Friedman'],2001,The Annals of Statistics,Journal,,,29,5,10.1214/aos/1013203451,"Function estimation/approximation is viewed from the perspective of numerical optimization in function space, rather than parameter space. A connection is made between stagewise additive expansions and steepest-descent minimization. A general gradient descent “boosting” paradigm is developed for additive expansions based on any fitting criterion.Specific algorithms are presented for least-squares, least absolute deviation, and Huber-M loss functions for regression, and multiclass logistic likelihood for classification. Special enhancements are derived for the particular case where the individual additive components are regression trees, and tools for interpreting such “TreeBoost” models are presented. Gradient boosting of regression trees produces competitive, highly robust, interpretable procedures for both regression and classification, especially appropriate for mining less than clean data. Connections between this approach and the boosting methods of Freund and Shapire and Friedman, Hastie and Tibshirani are discussed.","['Mathematics', 'Gradient boosting', 'Boosting (machine learning)', 'Gradient descent', 'Regression', 'Mathematical optimization', 'Minification', 'Logistic regression', 'Applied mathematics', 'Statistics', 'Artificial intelligence', 'Artificial neural network', 'Computer science', 'Random forest']","numerical optimization, function space, parameter space, stagewise additive expansions, boosting ”, additive expansions, multiclass logistic likelihood, regression trees, treeboost ”, gradient boosting, regression trees, boosting methods"
Paper_00286,Pattern Recognition and Machine Learning,['Christopher Bishop'],2007,Journal of Electronic Imaging,Journal,,049901-049901,16,4,10.1117/1.2819119,"The <i>Journal of Electronic Imaging</i> (JEI), copublished bimonthly with the Society for Imaging Science and Technology, publishes peer-reviewed papers that cover research and applications in all areas of electronic imaging science and technology.","['Computer science', 'Imaging science', 'Cover (algebra)', 'Data science', 'Artificial intelligence', 'Engineering', 'Mechanical engineering']","electronic imaging, imaging science, electronic imaging, [PAD] [PAD] [PAD]"
Paper_00287,Case study research: design and methods,['Simon Phelan'],2011,Evaluation & Research in Education,Journal,,221-222,24,3,10.1080/09500790.2011.582317,"""Case study research: design and methods."" Evaluation & Research in Education, 24(3), pp. 221–222","['Mathematics education', 'Research design', 'Sociology', 'Psychology', 'Pedagogy', 'Social science']","case study research, evaluation, education, [PAD] [PAD] [PAD]"
Paper_00290,An Evolutionary Theory of Economic Change.,"['Brian J. Loasby', 'Richard R. Nelson', 'Sidney G. Winter']",1983,The Economic Journal,Journal,,652-652,93,371,10.2307/2232409,"Journal Article An Evolutionary Theory of Economic Change Get access An Evolutionary Theory of Economic Change. By Richard R. Nelson and Sidney G. Winter. (Cambridge, Massachusetts & London: Harvard University Press, 1982. Pp. xi +437. £17.50.) Brian J. Loasby Brian J. Loasby University of Stirling Search for other works by this author on: Oxford Academic Google Scholar The Economic Journal, Volume 93, Issue 371, 1 September 1983, Pages 652–654, https://doi.org/10.2307/2232409 Published: 01 September 1983","['Evolutionary theory', 'Evolutionary economics', 'Economic history', 'Sociology', 'Economics', 'Philosophy', 'Neoclassical economics', 'Epistemology']","evolutionary theory, economic change, evolutionary theory, economic change, economic"
Paper_00291,Building Theories from Case Study Research,['Kathleen M. Eisenhardt'],1989,Academy of Management Review,Journal,,532-550,14,4,10.5465/amr.1989.4308385,"�Traditional, hierarchical views of leadership are less and less useful given the complexities of our modern world. Leadership theory must transition to new perspectives that account for the complex adaptive needs of organizations. In this paper, we propose that leadership (as opposed to leaders) can be seen as a complex dynamic process that emerges in the interactive “spaces between” people and ideas. That is, leadership is a dynamic that transcends the capabilities of individuals alone; it is the product of interaction, tension, and exchange rules governing changes in perceptions and understanding. We label this a dynamic of adaptive leadership, and we show how this dynamic provides important insights about the nature of leadership and its outcomes in organizational fields. We define a leadership event as a perceived segment of action whose meaning is created by the interactions of actors involved in producing it, and we present a set of innovative methods for capturing and analyzing these contextually driven processes. We provide theoretical and practical implications of these ideas for organizational behavior and organization and management theory.","['Organizational behavior', 'Sociology', 'Management', 'Economics']","leadership, leadership theory, organizations, leadership, leaders, leadership, exchange rules, adaptive leadership, leadership, leadership, organizational behavior, organization, management theory"
Paper_00294,"Mapping the Margins: Intersectionality, Identity Politics, and Violence against Women of Color",['Kimberlé W. Crenshaw'],1991,Stanford Law Review,Journal,,1241-1241,43,6,10.2307/1229039,"Over the last two decades, women have organized against the almost routine violence that shapes their lives. Drawing from the strength of shared experience, women have recognized that the political demands of millions speak more powerfully than the pleas of a few isolated voices. This politicization in turn has transformed the way we understand violence against women. For example, battering and rape, once seen as private (family matters) and aberrational (errant sexual aggression), are now largely recognized as part of a broad-scale system of domination that affects women as a class. This process of recognizing as social and systemic what was formerly perceived as isolated and individual has also characterized the identity politics of people of and gays and lesbians, among others. For all these groups, identity-based politics has been a source of strength, community, and intellectual development. The embrace of identity politics, however, has been in tension with dominant conceptions of social justice. Race, gender, and other identity categories are most often treated in mainstream liberal discourse as vestiges of bias or domination-that is, as intrinsically negative frameworks in which social power works to exclude or marginalize those who are different. According to this understanding, our liberatory objective should be to empty such categories of any social significance. Yet implicit in certain strands of feminist and racial liberation movements, for example, is the view that the social power in delineating difference need not be the power of domination; it can instead be the source of political empowerment and social reconstruction. The problem with identity politics is not that it fails to transcend difference, as some critics charge, but rather the opposite- that it frequently conflates or ignores intra group differences. In the context of violence against women, this elision of difference is problematic, fundamentally because the violence that many women experience is often shaped by other dimensions of their identities, such as race and class. Moreover, ignoring differences within groups frequently contributes to tension among groups, another problem of identity politics that frustrates efforts to politicize violence against women. Feminist efforts to politicize experiences of women and antiracist efforts to politicize experiences of people of color' have frequently proceeded as though the issues and experiences they each detail occur on mutually exclusive terrains. Al-though racism and sexism readily intersect in the lives of real people, they seldom do in feminist and antiracist practices. And so, when the practices expound identity as woman or person of color as an either/or proposition, they relegate the identity of women of to a location that resists telling. My objective here is to advance the telling of that location by exploring the race and gender dimensions of violence against women of color. Contemporary feminist and antiracist discourses have failed to consider the intersections of racism and patriarchy. Focusing on two dimensions of male violence against women-battering and rape-I consider how the experiences of women of are frequently the product of intersecting patterns of racism and sexism, and how these experiences tend not to be represented within the discourse of either feminism or antiracism... Language: en","['Intersectionality', 'Politics', 'Women of color', 'Identity (music)', 'Gender studies', 'Sociology', 'Political science', 'Race (biology)', 'Art', 'Law', 'Aesthetics']","batter, identity politics, lesbian, intellectual development, identity politics, social justice, racial liberation, political empowerment, social reconstruction, identity politics, women, women, feminist, racism, sexism, ##rac"
Paper_00296,A new criterion for assessing discriminant validity in variance-based structural equation modeling,"['Jörg Henseler', 'Christian M. Ringle', 'Marko Sarstedt']",2014,Journal of the Academy of Marketing Science,Journal,,115-135,43,1,10.1007/s11747-014-0403-8,"Discriminant validity assessment has become a generally accepted prerequisite for analyzing relationships between latent variables. For variance-based structural equation modeling, such as partial least squares, the Fornell-Larcker criterion and the examination of cross-loadings are the dominant approaches for evaluating discriminant validity. By means of a simulation study, we show that these approaches do not reliably detect the lack of discriminant validity in common research situations. We therefore propose an alternative approach, based on the multitrait-multimethod matrix, to assess discriminant validity: the heterotrait-monotrait ratio of correlations. We demonstrate its superior performance by means of a Monte Carlo simulation study, in which we compare the new approach to the Fornell-Larcker criterion and the assessment of (partial) cross-loadings. Finally, we provide guidelines on how to handle discriminant validity issues in variance-based structural equation modeling.","['Structural equation modeling', 'Discriminant validity', 'Discriminant', 'Latent variable', 'Variance (accounting)', 'Linear discriminant analysis', 'Partial least squares regression', 'Statistics', 'Mathematics', 'Monte Carlo method', 'Econometrics', 'Computer science', 'Artificial intelligence', 'Psychometrics', 'Accounting', 'Internal consistency', 'Business']","discriminant validity assessment, latent variables, structural, partial least squares, discriminant validity, ##ina, ##inant validity, monte carlo simulation study, [PAD] [PAD]"
Paper_00298,Comparative fit indexes in structural models.,['Peter M. Bentler'],1990,Psychological Bulletin,Journal,,238-246,107,2,10.1037/0033-2909.107.2.238,"Normed and nonnormed fit indexes are frequently used as adjuncts to chi-square statistics for evaluating the fit of a structural model. A drawback of existing indexes is that they estimate no known population parameters. A new coefficient is proposed to summarize the relative reduction in the noncentrality parameters of two nested models. Two estimators of the coefficient yield new normed (CFI) and nonnormed (FI) fit indexes. CFI avoids the underestimation of fit often noted in small samples for Bentler and Bonett's (1980) normed fit index (NFI). FI is a linear function of Bentler and Bonett's non-normed fit index (NNFI) that avoids the extreme underestimation and overestimation often found in NNFI. Asymptotically, CFI, FI, NFI, and a new index developed by Bollen are equivalent measures of comparative fit, whereas NNFI measures relative fit by comparing noncentrality per degree of freedom. All of the indexes are generalized to permit use of Wald and Lagrange multiplier statistics. An example illustrates the behavior of these indexes under conditions of correct specification and misspecification. The new fit indexes perform very well at all sample sizes.","['Mathematics', 'Statistics', 'Estimator', 'Econometrics', 'Index (typography)', 'Computer science', 'World Wide Web']","nonnormed fit indexes, structural model, population parameters, noncentrality parameters, ##ed models, ##i, underestimation, normed fit index, non - normed, overestimation, ##fi, ##i, ##fi, comparative fit, ##fi, relative fit, noncentrality, wald, lagrange multiplier statistics, misspeci"
Paper_00299,Introduction to Quantitative Genetics.,"['A. W. F. Edwards', 'D. S. Falconer']",1982,Biometrics,Journal,,1128-1128,38,4,10.2307/2529912,Part 1 Genetic constitution of a population: Hardy-Weinberg equilibrium. Part 2 Changes in gene frequency: migration mutation. Part 3 Small populations - changes in gene frequency under simplified conditions. Part 4 Small populations - less simplified conditions. Part 5 Small populations - pedigreed populations and close inbreeding. Part 6 Continuous variation. Part 7 Values and means. Part 8 Variance. Part 9 Resemblance between relatives. Part 10 Heritability. Part 11 Selection - the response and its prediction. Part 12 Selection - the results of experiments. Part 13 Selection - information from relatives. Part 14 Inbreeding and crossbreeding - changes of mean value. Part 15 Inbreeding and crossbreeding - changes of variance. Part 16 Inbreeding and crossbreeding - applications. Part 17 Scale. Part 18 Threshold characters. Part 19 Correlated characters. Part 20 Metric characters under natural selection.,"['Inbreeding', 'Selection (genetic algorithm)', 'Crossbreed', 'Heritability', 'Biology', 'Population', 'Evolutionary biology', 'Variance (accounting)', 'Genetics', 'Statistics', 'Mathematics', 'Demography', 'Sociology', 'Computer science', 'Accounting', 'Artificial intelligence', 'Business']","genetic constitution, gene frequency, migration mutation, small populations, gene frequency, simplified conditions, small populations, small populations, pedigreed populations, close inbreeding, continuous variation, values, variance, heritability, inbreeding, crossbreeding, mean value, inbreeding, crossbreeding, inbreeding, crossbreeding, scale, threshold characters, correlated characters, metric characters, natural selection, [PAD], [PAD] [PAD] [PAD], [PAD] [PAD], [PAD] [PAD] [PAD], [PAD], [PAD] [PAD] [PAD], [PAD] [PAD], [PAD], [PAD], [PAD] [PAD], [PAD], [PAD], [PAD] [PAD], [PAD], [PAD], [PAD] [PAD], [PAD], [PAD], [PAD] [PAD], [PAD]"
Paper_00300,Isolation of biologically active ribonucleic acid from sources enriched in ribonuclease,"['John M. Chirgwin', 'Alan Przybyla', 'Raymond J. MacDonald', 'William J. Rutter']",1979,Biochemistry,Journal,,5294-5299,18,24,10.1021/bi00591a005,"ADVERTISEMENT RETURN TO ISSUEPREVArticleNEXTIsolation of biologically active ribonucleic acid from sources enriched in ribonucleaseJohn M. Chirgwin, Alan E. Przybyla, Raymond J. MacDonald, and William J. RutterCite this: Biochemistry 1979, 18, 24, 5294–5299Publication Date (Print):November 1, 1979Publication History Published online1 May 2002Published inissue 1 November 1979https://pubs.acs.org/doi/10.1021/bi00591a005https://doi.org/10.1021/bi00591a005research-articleACS PublicationsRequest reuse permissionsArticle Views5709Altmetric-Citations14814LEARN ABOUT THESE METRICSArticle Views are the COUNTER-compliant sum of full text article downloads since November 2008 (both PDF and HTML) across all institutions and individuals. These metrics are regularly updated to reflect usage leading up to the last few days.Citations are the number of other articles citing this article, calculated by Crossref and updated daily. Find more information about Crossref citation counts.The Altmetric Attention Score is a quantitative measure of the attention that a research article has received online. Clicking on the donut icon will load a page at altmetric.com with additional details about the score and the social media presence for the given article. Find more information on the Altmetric Attention Score and how the score is calculated. Share Add toView InAdd Full Text with ReferenceAdd Description ExportRISCitationCitation and abstractCitation and referencesMore Options Share onFacebookTwitterWechatLinked InRedditEmail Other access optionsGet e-Alertsclose Get e-Alerts","['RNA', 'Ribonuclease', 'RNase P', 'Chemistry', 'Biochemistry', 'Homogenization (climate)', 'Pancreatic ribonuclease', 'Molecular biology', 'Biology', 'Biodiversity', 'Ecology', 'Gene']","##varticlenextisolation, ##ly, ribon, ##leic acid, ##on, permissionsar, ##le, ##f, altmetric attention score, social, altmetric, reference, ##d, ##ation, abstractcitation, references"
Paper_00302,Electrochemical Methods: Fundamentals and Applications,"['Allen J. Bard', 'Larry R. Faulkner']",1980,['Journal of Chemical Education'],Unknown,,A25,60,1,10.1021/ed060pa25.1,Major Symbols. Standard Abbreviations. Introduction and Overview of Electrode Processes. Potentials and Thermodynamics of Cells. Kinetics of Electrode Reactions. Mass Transfer by Migration and Diffusion. Basic Potential Step Methods. Potential Sweep Methods. Polarography and Pulse Voltammetry. Controlled--Current Techniques. Method Involving Forced Convention--Hydrodynamic Methods. Techniques Based on Concepts of Impedance. Bulk Electrolysis Methods. Electrode Reactions with Coupled Homogeneous Chemical Reactions. Double--Layer Structure and Adsorption. Electroactive Layers and Modified Electrodes. Electrochemical Instrumentation. Scanning Probe Techniques. Spectroelectrochemistry and Other Coupled Characterization Methods. Photoelectrochemistry and Electrogenerated Chemiluminescence. Appendix A: Mathematical Methods. Appendix B: Digital Simulations of Electrochemical Problems. Appendix C: Reference Tables. Index.,"['Electrolysis', 'Polarography', 'Electrode', 'Diffusion layer', 'Chronoamperometry', 'Electrochemistry', 'Voltammetry', 'Chemistry', 'Analytical Chemistry (journal)', 'Chemically modified electrode', 'Charge transfer coefficient', 'Linear sweep voltammetry', 'Diffusion', 'Cyclic voltammetry', 'Reference electrode', 'Inorganic chemistry', 'Thermodynamics', 'Electrolyte', 'Physical chemistry', 'Chromatography', 'Physics']","potentials, the, ##odynamics, electrode reactions, mass transfer, potential step methods, potential sweep methods, polarography, pulse voltammetry, forced convention, impedance, bulk electrolysis methods, electrode reactions, coupled homogeneous chemical reactions, electro, modified electrodes, electro, scanning probe techniques, spectroelectrochemistry, coupled characterization, photoelectrochemistry, electrogenerated chemiluminescence, digital simulations, electro"
Paper_00303,Reporting physisorption data for gas/solid systems with special reference to the determination of surface area and porosity (Recommendations 1984),['K. S. W. Sing'],1985,Pure and Applied Chemistry,Journal,,603-619,57,4,10.1351/pac198557040603,Abstract,"['Physisorption', 'Chemistry', 'Porosity', 'Surface (topology)', 'Specific surface area', 'Solid surface', 'Chemical engineering', 'Physical chemistry', 'Adsorption', 'Chemical physics', 'Organic chemistry', 'Geometry', 'Mathematics', 'Engineering', 'Catalysis']",
Paper_00304,<i>PHENIX</i>: a comprehensive Python-based system for macromolecular structure solution,"['Paul D. Adams', 'Pavel V. Afonine', 'G. Bunkóczi', 'Vincent B. Chen', 'Ian Davis', 'Nathaniel Echols', 'Jeffrey J. Headd', 'Li‐Wei Hung', 'Gary J. Kapral', 'Ralf W. Grosse‐Kunstleve', 'Airlie J. McCoy', 'Nigel W. Moriarty', 'Robert D. Oeffner', 'Randy J. Read', 'David Richardson', 'Jane S. Richardson', 'Thomas C. Terwilliger', 'Peter H. Zwart']",2010,Acta Crystallographica Section D Biological Crystallography,Journal,,213-221,66,2,10.1107/s0907444909052925,"Macromolecular X-ray crystallography is routinely applied to understand biological processes at a molecular level. However, significant time and effort are still required to solve and complete many of these structures because of the need for manual interpretation of complex numerical data using many software packages and the repeated use of interactive three-dimensional graphics. PHENIX has been developed to provide a comprehensive system for macromolecular crystallographic structure solution with an emphasis on the automation of all procedures. This has relied on the development of algorithms that minimize or eliminate subjective input, the development of algorithms that automate procedures that are traditionally performed by hand and, finally, the development of a framework that allows a tight integration between the algorithms.","['Python (programming language)', 'Computer science', 'Automation', 'Graphics', 'Software', 'Computational science', 'Algorithm', 'Software engineering', 'Programming language', 'Computer graphics (images)', 'Engineering', 'Mechanical engineering']","biological processes, phenix, ##raphic structure solution, subjective input"
Paper_00305,Design Patterns: Elements of Reusable Object-Oriented Software,"['Erich Gamma', 'Richard F. Helm', 'Ralph E. Johnson', 'John Vlissides']",1994,['Communications of the ACM'],Unknown,,65-74,38,10,10.1145/226239.226255,"The book is an introduction to the idea of design patterns in software engineering, and a catalog of twenty-three common patterns. The nice thing is, most experienced OOP designers will find out they've known about patterns all along. It's just that they've never considered them as such, or tried to centralize the idea behind a given pattern so that it will be easily reusable.","['Software design pattern', 'Computer science', 'Software engineering', 'Software', 'Object-oriented design', 'Object-oriented programming', 'Design pattern', 'Object (grammar)', 'Programming language', 'Artificial intelligence']","design patterns, software engineering, oop, [PAD] [PAD], [PAD]"
Paper_00306,A Thousand Plateaus: Capitalism and Schizophrenia,"['Sander L. Gilman', 'Gilles Deleuze', 'Félix Guattari', 'Brian Massumi']",1989,The Journal of Interdisciplinary History,Journal,,657-657,19,4,10.2307/203963,"Translator's Foreword: Pleasures of Philosophy Notes on the Translation and Acknowledgements Author's Note 1. Introduction: Rhizome 2. 1914: One or Several Wolves? 3. 10,000 BC: The Geology of Morals (Who Does the Earth Think It Is?) 4. November 20th, 1923: Postulates of Linguistics 5. 587BC-AD70: On Several Regimes of Signs 6. November 28th, 1947: How Do You Make Yourself a Body Without Organs? 7. Year Zero: Faciality 8. 1874: Three Novellas, or What Happened? 9. 1933: Micropolitics and Segmentarity 10. 1730: Becoming Intense, Becoming-Animal, Becoming Imperceptible... 11. 1837: Of the Refrain 12. 1227: Treatise on Nomadology - The War Machine 13. 7000BC: Apparatus of Capture 14. 1440: The Smooth and the Striated 15. Conclusion: Concrete Rules and Abstract Machines Notes Bibliography List of Illustrations Index","['Capitalism', 'Schizophrenia (object-oriented programming)', 'Political science', 'Psychology', 'Psychiatry', 'Law', 'Politics']","philosophy, morals, postulates, linguistics, faciality, micropolitics, segmentarity, nomadology, war machine, smooth, striated, concrete rules, abstract machines"
Paper_00308,Summary for Policymakers,"['Facultad De', 'Negocios Programa', 'Académico De', 'Administración De', ""Para Perros -Dog'"", 'SE Garden', 'Trabajo De Investigación', 'Alzamora Laura', 'Aquino Quispe', 'Cebreros Vizcarra', 'Daniel Fernando', 'Muñoz Acuña', 'Fernando Pedro', 'Asesor Morales', 'Guzmán Barrón', 'Alex Nicolas']",2014,Cambridge University Press eBooks,Unknown,,1-30,,,10.1017/cbo9781107415324.004,"The Working Group I contribution to the IPCC's Fifth Assessment Report (AR5) considers new evidence of climate change based on many independent scientific analyses from observations of the climate system, paleoclimate archives, theoretical studies of climate processes and simulations using climate models. It builds upon the Working Group I contribution to the IPCC's Fourth Assessment Report (AR4), and incorporates subsequent new findings of research. As a component of the fifth assessment cycle, the IPCC Special Report on Managing the Risks of Extreme Events and Disasters to Advance Climate Change Adaptation (SREX) is an important basis for information on changing weather and climate extremes.","['Climate change', 'Climatology', 'Adaptation (eye)', 'Climate extremes', 'Geography', 'Climate change adaptation', 'Environmental science', 'Environmental resource management', 'Psychology', 'Geology', 'Oceanography', 'Neuroscience']","ip, climate change, climate, paleoclimate archives, climate processes, climate models, climate change adaptation, sr, [PAD], [PAD], [PAD] [PAD]"
Paper_00309,A tutorial on hidden Markov models and selected applications in speech recognition,['L. R. Rabiner'],1989,Proceedings of the IEEE,Journal,,257-286,77,2,10.1109/5.18626,"This tutorial provides an overview of the basic theory of hidden Markov models (HMMs) as originated by L.E. Baum and T. Petrie (1966) and gives practical details on methods of implementation of the theory along with a description of selected applications of the theory to distinct problems in speech recognition. Results from a number of original sources are combined to provide a single source of acquiring the background required to pursue further this area of research. The author first reviews the theory of discrete Markov chains and shows how the concept of hidden states, where the observation is a probabilistic function of the state, can be used effectively. The theory is illustrated with two simple examples, namely coin-tossing, and the classic balls-in-urns system. Three fundamental problems of HMMs are noted and several practical techniques for solving these problems are given. The various types of HMMs that have been studied, including ergodic as well as left-right models, are described.< <ETX xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">&gt;</ETX>","['Hidden Markov model', 'Computer science', 'Ergodic theory', 'Simple (philosophy)', 'Probabilistic logic', 'Markov chain', 'Artificial intelligence', 'Markov model', 'State (computer science)', 'Function (biology)', 'Theoretical computer science', 'Machine learning', 'Speech recognition', 'Pattern recognition (psychology)', 'Natural language processing', 'Algorithm', 'Mathematics', 'Pure mathematics', 'Epistemology', 'Philosophy', 'Evolutionary biology', 'Biology']","hidden markov models, hmms, speech recognition, discrete markov chains, hidden states, probabilistic, er"
Paper_00310,SPAdes: A New Genome Assembly Algorithm and Its Applications to Single-Cell Sequencing,"['Anton Bankevich', 'Sergey Nurk', 'Dmitry Antipov', 'Alexey Gurevich', 'Mikhail Dvorkin', 'Alexander S. Kulikov', 'Valery M. Lesin', 'Sergey Nikolenko', 'Son Pham', 'Andrey D. Prjibelski', 'Alexey Pyshkin', 'Alexander Sirotkin', 'Nikolay Vyahhi', 'Glenn Tesler', 'Max A. Alekseyev', 'Pavel A. Pevzner']",2012,Journal of Computational Biology,Journal,,455-477,19,5,10.1089/cmb.2012.0021,"The lion's share of bacteria in various environments cannot be cloned in the laboratory and thus cannot be sequenced using existing technologies. A major goal of single-cell genomics is to complement gene-centric metagenomic data with whole-genome assemblies of uncultivated organisms. Assembly of single-cell data is challenging because of highly non-uniform read coverage as well as elevated levels of sequencing errors and chimeric reads. We describe SPAdes, a new assembler for both single-cell and standard (multicell) assembly, and demonstrate that it improves on the recently released E+V−SC assembler (specialized for single-cell data) and on popular assemblers Velvet and SoapDeNovo (for multicell data). SPAdes generates single-cell assemblies, providing information about genomes of uncultivatable bacteria that vastly exceeds what may be obtained via traditional metagenomics studies. SPAdes is available online (http://bioinf.spbau.ru/spades). It is distributed as open source software.","['Metagenomics', 'Sequence assembly', 'Genome', 'Software', 'Genomics', 'Computational biology', 'Biology', 'Computer science', 'Contig', 'Gene', 'Genetics', 'Transcriptome', 'Programming language', 'Gene expression']","un, ##ltivated organisms, sequencing errors, chimeric, spades, assemble, velvet, soapdenovo, multicell, spades, un, ##lt, ##table, spades, ##s"
Paper_00311,Colorimetry of Total Phenolics with Phosphomolybdic-Phosphotungstic Acid Reagents,"['Vernon L. Singleton', 'Joseph A. Rossi']",1965,American Journal of Enology and Viticulture,Journal,,144-158,16,3,10.5344/ajev.1965.16.3.144,"Several details of the assay of total phenolic substances have been investigated and an improved procedure developed. The improvements include the use of Folin-Ciocalteu reagent rather than the Folin-Denis reagent, gallic acid as a reference standard, and a more reproducible time-temperature color development period. The values obtained are less subject to variation and interference from several nonphenols, yet are directly comparable to the ""tannin"" values obtained by the previously standard method.","['Phosphomolybdic acid', 'Reagent', 'Gallic acid', 'Chemistry', 'Phosphotungstic acid', 'Tannin', 'Colorimetry', 'Chromatography', 'Organic chemistry', 'Food science', 'Antioxidant', 'Catalysis']","total phenolic substances, gallic, ##enols, tannin"
Paper_00312,Introduction to Solid State Physics,"['C. Kittel', 'Heng Fan']",1957,American Journal of Physics,Journal,,330-330,25,5,10.1119/1.1934457,First Page,"['Physics', 'State (computer science)', 'Physics education', 'Theoretical physics', 'Statistical physics', 'Engineering physics', 'Nuclear physics', 'Quantum mechanics', 'Algorithm', 'Computer science']",
Paper_00314,A New Equation to Estimate Glomerular Filtration Rate,"['Andrew S. Levey', 'Lesley A. Stevens', 'Christopher H. Schmid', 'Yaping Zhang', 'Alejandro Castro', 'Harold I. Feldman', 'John W. Kusek', 'Paul W. Eggers', 'Frederick Van Lente', 'Tom Greene', 'Josef Coresh']",2009,Annals of Internal Medicine,Journal,,604-604,150,9,10.7326/0003-4819-150-9-200905050-00006,"Background: Equations to estimate glomerular filtration rate (GFR) are routinely used to assess kidney function. Current equations have limited precision and systematically underestimate measured GFR at higher values. Objective: To develop a new estimating equation for GFR: the Chronic Kidney Disease Epidemiology Collaboration (CKD-EPI) equation. Design: Cross-sectional analysis with separate pooled data sets for equation development and validation and a representative sample of the U.S. population for prevalence estimates. Setting: Research studies and clinical populations (“studies”) with measured GFR and NHANES (National Health and Nutrition Examination Survey), 1999 to 2006. Participants: 8254 participants in 10 studies (equation development data set) and 3896 participants in 16 studies (validation data set). Prevalence estimates were based on 16 032 participants in NHANES. Measurements: GFR, measured as the clearance of exogenous filtration markers (iothalamate in the development data set; iothalamate and other markers in the validation data set), and linear regression to estimate the logarithm of measured GFR from standardized creatinine levels, sex, race, and age. Results: In the validation data set, the CKD-EPI equation performed better than the Modification of Diet in Renal Disease Study equation, especially at higher GFR (P < 0.001 for all subsequent comparisons), with less bias (median difference between measured and estimated GFR, 2.5 vs. 5.5 mL/min per 1.73 m2), improved precision (interquartile range [IQR] of the differences, 16.6 vs. 18.3 mL/min per 1.73 m2), and greater accuracy (percentage of estimated GFR within 30% of measured GFR, 84.1% vs. 80.6%). In NHANES, the median estimated GFR was 94.5 mL/min per 1.73 m2 (IQR, 79.7 to 108.1) vs. 85.0 (IQR, 72.9 to 98.5) mL/min per 1.73 m2, and the prevalence of chronic kidney disease was 11.5% (95% CI, 10.6% to 12.4%) versus 13.1% (CI, 12.1% to 14.0%). Limitation: The sample contained a limited number of elderly people and racial and ethnic minorities with measured GFR. Conclusion: The CKD-EPI creatinine equation is more accurate than the Modification of Diet in Renal Disease Study equation and could replace it for routine clinical use. Primary Funding Source: National Institute of Diabetes and Digestive and Kidney Diseases.","['Renal function', 'Medicine', 'National Health and Nutrition Examination Survey', 'Kidney disease', 'Interquartile range', 'Urology', 'Creatinine', 'Population', 'Cystatin C', 'Estimating equations', 'Linear regression', 'Confidence interval', 'Internal medicine', 'Statistics', 'Mathematics', 'Environmental health', 'Maximum likelihood']","glomerular filtration rate, kidney function, chronic kidney disease epide, prevalence, clinical populations, national health, prevalence, exogenous filtration markers, iothal, ##te, linear regression, ##le range, chronic kidney disease"
Paper_00316,<i>The Fractal Geometry of Nature</i>,"['Benoît B. Mandelbrot', 'John Wheeler']",1983,American Journal of Physics,Journal,,286-287,51,3,10.1119/1.13295,First Page,"['Physics', 'Fractal', 'Geometry', 'Classical mechanics', 'Theoretical physics', 'Mathematical analysis', 'Mathematics']",
Paper_00319,Artificial intelligence: a modern approach,"['Stuart Russell', 'Peter Norvig']",1995,Choice Reviews Online,Journal,,33-1577,33,03,10.5860/choice.33-1577,"The long-anticipated revision of this #1 selling book offers the most comprehensive, state of the art introduction to the theory and practice of artificial intelligence for modern applications. Intelligent Agents. Solving Problems by Searching. Informed Search Methods. Game Playing. Agents that Reason Logically. First-order Logic. Building a Knowledge Base. Inference in First-Order Logic. Logical Reasoning Systems. Practical Planning. Planning and Acting. Uncertainty. Probabilistic Reasoning Systems. Making Simple Decisions. Making Complex Decisions. Learning from Observations. Learning with Neural Networks. Reinforcement Learning. Knowledge in Learning. Agents that Communicate. Practical Communication in English. Perception. Robotics. For computer professionals, linguists, and cognitive scientists interested in artificial intelligence.","['Artificial intelligence', 'Computer science', 'Inference', 'Artificial intelligence, situated approach', 'Probabilistic logic', 'Cognitive robotics', 'Symbolic artificial intelligence', 'Reinforcement learning', 'Cognitive science', 'Robot', 'Psychology']","artificial intelligence, intelligent agents, informed search methods, game playing, knowledge base, logical reasoning systems, practical planning, uncertainty, probabilistic reasoning systems, neural networks, reinforcement learning, perception, robotics, computer professionals, cognitive scientists, artificial intelligence, [PAD] [PAD] [PAD], [PAD] [PAD], [PAD], [PAD]"
Paper_00320,A pneumonia outbreak associated with a new coronavirus of probable bat origin,"['Peng Zhou', 'Xing‐Lou Yang', 'Xian-Guang Wang', 'Ben Hu', 'Lei Zhang', 'Wei Zhang', 'Hao-Rui Si', 'Yan Zhu', 'Bei Li', 'Chao-Lin Huang', 'Huidong Chen', 'Jing Chen', 'Yun Luo', 'Hua Guo', 'Ren-Di Jiang', 'Mei-Qin Liu', 'Ying Chen', 'Xu-Rui Shen', 'Xi Wang', 'Xiao-Shuang Zheng', 'Kai Zhao', 'Quan-Jiao Chen', 'Fēi Dèng', 'Linlin Liu', 'Bing Yan', 'Fa-Xian Zhan', 'Yan-Yi Wang', 'Geng-Fu Xiao', 'Zheng‐Li Shi']",2020,Nature,Journal,,270-273,579,7798,10.1038/s41586-020-2012-7,"Abstract Since the outbreak of severe acute respiratory syndrome (SARS) 18 years ago, a large number of SARS-related coronaviruses (SARSr-CoVs) have been discovered in their natural reservoir host, bats 1–4 . Previous studies have shown that some bat SARSr-CoVs have the potential to infect humans 5–7 . Here we report the identification and characterization of a new coronavirus (2019-nCoV), which caused an epidemic of acute respiratory syndrome in humans in Wuhan, China. The epidemic, which started on 12 December 2019, had caused 2,794 laboratory-confirmed infections including 80 deaths by 26 January 2020. Full-length genome sequences were obtained from five patients at an early stage of the outbreak. The sequences are almost identical and share 79.6% sequence identity to SARS-CoV. Furthermore, we show that 2019-nCoV is 96% identical at the whole-genome level to a bat coronavirus. Pairwise protein sequence analysis of seven conserved non-structural proteins domains show that this virus belongs to the species of . In addition, 2019-nCoV virus isolated from the bronchoalveolar lavage fluid of a critically ill patient could be neutralized by sera from several patients. Notably, we confirmed that 2019-nCoV uses the same cell entry receptor—angiotensin converting enzyme II (ACE2)—as SARS-CoV.","['Outbreak', 'Pneumonia', 'Coronavirus', 'Virology', 'Biology', 'Severe acute respiratory syndrome', 'Virus', 'Severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2)', 'Betacoronavirus', 'Genome', 'Bronchoalveolar lavage', 'Coronavirus disease 2019 (COVID-19)', 'Immunology', 'Medicine', 'Gene', 'Genetics', 'Lung', 'Infectious disease (medical specialty)', 'Pathology', 'Internal medicine', 'Disease']","severe acute respiratory syndrome, acute respiratory syndrome, bronchoal, cell entry receptor, angiotensin converting enzyme ii"
Paper_00322,A new generation of Ca2+ indicators with greatly improved fluorescence properties.,"['Grzegorz Grynkiewicz', 'Martin Poenie', 'Roger Y. Tsien']",1985,Journal of Biological Chemistry,Journal,,3440-3450,260,6,10.1016/s0021-9258(19)83641-4,"A new family of highly fluorescent indicators has been synthesized for biochemical studies of the physiological role of cytosolic free Ca2+. The compounds combine an 8-coordinate tetracarboxylate chelating site with stilbene chromophores. Incorporation of the ethylenic linkage of the stilbene into a heterocyclic ring enhances the quantum efficiency and photochemical stability of the fluorophore. Compared to their widely used predecessor, quin2, the new dyes offer up to 30-fold brighter fluorescence, major changes in wavelength not just intensity upon Ca2+ binding, slightly lower affinities for Ca2+, slightly longer wavelengths of excitation, and considerably improved selectivity for Ca2+ over other divalent cations. These properties, particularly the wavelength sensitivity to Ca2+, should make these dyes the preferred fluorescent indicators for many intracellular applications, especially in single cells, adherent cell layers, or bulk tissues.","['Fluorescence', 'Chemistry', 'Biophysics', 'Biology', 'Physics', 'Optics']","highly fluorescent indicators, bio, cytosolic free, stil, quantum efficiency, photochemical stability, quin, diva, wavelength sensitivity, fluorescent indicators, single cells, adherent cell layers, bulk tissues"
Paper_00324,"The Market for ""Lemons"": Quality Uncertainty and the Market Mechanism",['George A. Akerlof'],1970,The Quarterly Journal of Economics,Journal,,488-488,84,3,10.2307/1879431,"Journal Article The Market for “Lemons”: Quality Uncertainty and the Market Mechanism Get access George A. Akerlof George A. Akerlof Search for other works by this author on: Oxford Academic Google Scholar The Quarterly Journal of Economics, Volume 84, Issue 3, August 1970, Pages 488–500, https://doi.org/10.2307/1879431 Published: 01 August 1970","['Mechanism (biology)', 'Quality (philosophy)', 'Business', 'Market mechanism', 'Economics', 'Industrial organization', 'Market economy', 'Physics', 'Quantum mechanics']","quality uncertainty, market mechanism, quarterly, economics, [PAD], [PAD], [PAD] [PAD] [PAD], [PAD]"
Paper_00325,Power/Knowledge: Selected Interviews and Other Writings 1972-1977,"['Michel Foucault', 'Colin Gordon']",1980,['The American Historical Review'],Unknown,,776,95,3,10.2307/2164287,* On Popular Justice: A Discussion with Maoists * Prison Talk * Body/ Power * Questions on Georgraphy * Two Lectures * Truth and Power * Power and Strategies * The Eye of Power * The Politics of Health in the Eighteenth Century * The history of Sexuality * The Confession of the Flesh,"['Confession (law)', 'Power (physics)', 'Human sexuality', 'Prison', 'Politics', 'Economic Justice', 'Panopticon', 'Sociology', 'Psychoanalysis', 'Political science', 'Psychology', 'Criminology', 'Gender studies', 'Law', 'Physics', 'Quantum mechanics']","popular justice, mao, prison talk, georgraphy, health, eighteenth, sexuality"
Paper_00326,"Culture's Consequences: Comparing Values, Behaviors, Institutions, and Organizations across Nations","['Rabi S. Bhagat', 'Geert Hofstede']",2002,Academy of Management Review,Journal,,460-460,27,3,10.2307/4134391,"Values and Culture Data Collection, Treatment and Validation Power Distance Uncertainty Avoidance Individualism and Collectivism Masculinity and Femininity Long versus Short-Term Orientation Cultures in Organizations Intercultural Encounters Using Culture Dimension Scores in Theory and Research","['Organizational culture', 'Organizational behavior', 'Cultural values', 'Public relations', 'Sociology', 'Psychology', 'Political science', 'Management', 'Business', 'Social psychology', 'Social science', 'Economics']","values, culture, validation power distance uncertainty avoidance individualism, collectivism masculinity, femininity, organizations intercultural encounters, culture dimension scores, [PAD]"
Paper_00329,The Tragedy of the Commons,['Garrett Hardin'],1968,Science,Journal,,1243-1248,162,3859,10.1126/science.162.3859.1243,The population problem has no technical solution; it requires a fundamental extension in morality.,"['Tragedy of the commons', 'Tragedy (event)', 'Commons', 'Environmental ethics', 'Political science', 'Law and economics', 'Philosophy', 'Law', 'Sociology', 'Art', 'Literature']","population problem, morality"
Paper_00330,Soft self-consistent pseudopotentials in a generalized eigenvalue formalism,['David Vanderbilt'],1990,"Physical review. B, Condensed matter",Journal,,7892-7895,41,11,10.1103/physrevb.41.7892,"A new approach to the construction of first-principles pseudopotentials is described. The method allows transferability to be improved systematically while holding the cutoff radius fixed, even for large cutoff radii. Novel features are that the pseudopotential itself becomes charge-state dependent, the usual norm-conservation constraint does not apply, and a generalized eigenproblem is introduced. The potentials have a separable form well suited for plane-wave solid-state calculations, and show promise for application to first-row and transition-metal systems.","['Pseudopotential', 'Cutoff', 'Eigenvalues and eigenvectors', 'Separable space', 'Physics', 'Transferability', 'Formalism (music)', 'Norm (philosophy)', 'Quantum mechanics', 'Mathematics', 'Mathematical analysis', 'Art', 'Musical', 'Visual arts', 'Statistics', 'Logit', 'Political science', 'Law']","pseudo, transferability, cutoff radius, ##off radii, pseudopot, generalized eigenproblem, ##arable"
Paper_00331,A Theory of Cognitive Dissonance,['Léon Festinger'],1957,Stanford University Press eBooks,Unknown,,,,,10.1515/9781503620766,"Leon Festinger's theory of cognitive dissonance has been widely recognized for its important and influential concepts in areas of motivation and social psychology. The theory of dissonance is here applied to the problem of why partial reward, delay of reward , and effort expenditure during training result in increased resistance to extinction. The author contends that a state of impasse exists within learning theory largely because some of its major assumptions stand in apparent opposition to cetain well-established experimental results. The book puts forward a new theory that seems to reconcile these data and assumptions. This new theory can account for data with which other theories have difficulty: it integrates empirical phenomena that have been regarded as unrelated, and it is supported by the results of experiments designed specifically to test its implications. These experiments are fully described in the text.","['Cognitive dissonance', 'Opposition (politics)', 'Self-perception theory', 'Psychology', 'Social psychology', 'Cognition', 'Empirical research', 'Epistemology', 'Cognitive psychology', 'Philosophy', 'Political science', 'Politics', 'Law', 'Neuroscience']","cognitive dissonance, motivation, social psychology, dissonance, partial reward, effort expenditure, training, learning theory"
Paper_00332,Atherosclerosis — An Inflammatory Disease,['Russell Ross'],1999,New England Journal of Medicine,Journal,,115-126,340,2,10.1056/nejm199901143400207,"Atherosclerosis is an inflammatory disease. Because high plasma concentrations of cholesterol, in particular those of low-density lipoprotein (LDL) cholesterol, are one of the principal risk factors for atherosclerosis,1 the process of atherogenesis has been considered by many to consist largely of the accumulation of lipids within the artery wall; however, it is much more than that. Despite changes in lifestyle and the use of new pharmacologic approaches to lower plasma cholesterol concentrations,2,3 cardiovascular disease continues to be the principal cause of death in the United States, Europe, and much of Asia.4,5 In fact, the lesions of atherosclerosis represent . . .","['Medicine', 'Cholesterol', 'Disease', 'Atherosclerotic cardiovascular disease', 'Inflammation', 'Arteriosclerosis', 'High-density lipoprotein', 'Lipoprotein', 'Internal medicine', 'Cardiology']","atherosclerosis, inflammatory disease, atheroscle, atherogen, ather"
Paper_00334,Diagnostic and Statistical Manual of Mental Disorders,['Craig A. Harper'],2012,SpringerReference,Journal,,,,,10.1007/springerreference_121117,This chapter provides a brief critical overview of the Diagnostic and Statistical Manual of Mental Disorders,"['Classification of mental disorders', 'Psychology', 'Computer science', 'Psychiatry', 'Medicine', 'Prevalence of mental disorders', 'Mental health']","statistical manual, mental disorders"
Paper_00335,World Medical Association Declaration of Helsinki,[],2013,JAMA,Journal,,2191-2191,310,20,10.1001/jama.2013.281053,"1. The World Medical Association (WMA) has developed the Declaration of Helsinki as a statement of ethical principles for medical research involving human subjects, including research on identifiable human material and data.","['Medicine', 'Declaration of Helsinki', 'Family medicine', 'Declaration', 'Association (psychology)', 'Library science', 'Law', 'Informed consent', 'Alternative medicine', 'Pathology', 'Epistemology', 'Political science', 'Computer science', 'Philosophy']","world medical association, wma, medical, human subjects, identifiable human material"
Paper_00338,A RAPID METHOD OF TOTAL LIPID EXTRACTION AND PURIFICATION,"['E. G. Bligh', 'W. J. Dyer']",1959,Canadian Journal of Biochemistry and Physiology,Journal,,911-917,37,1,10.1139/y59-099,"Lipid decomposition studies in frozen fish have led to the development of a simple and rapid method for the extraction and purification of lipids from biological materials. The entire procedure can be carried out in approximately 10 minutes; it is efficient, reproducible, and free from deleterious manipulations. The wet tissue is homogenized with a mixture of chloroform and methanol in such proportions that a miscible system is formed with the water in the tissue. Dilution with chloroform and water separates the homogenate into two layers, the chloroform layer containing all the lipids and the methanolic layer containing all the non-lipids. A purified lipid extract is obtained merely by isolating the chloroform layer. The method has been applied to fish muscle and may easily be adapted to use with other tissues.","['Chloroform', 'Chromatography', 'Extraction (chemistry)', 'Chemistry', 'Dilution', 'Methanol', 'Organic chemistry', 'Physics', 'Thermodynamics']","lipid decomposition, frozen fish, lip, wet, chloroform layer, lip, lip, purified lipid extract, fish muscle"
Paper_00339,Preferred reporting items for systematic review and meta-analysis protocols (PRISMA-P) 2015 statement,"['David Moher', 'Larissa Shamseer', 'Mike Clarke', 'Davina Ghersi', 'Alessandro Liberati', 'Mark Petticrew', 'Paul Shekelle', 'Lesley Stewart']",2015,Systematic Reviews,Journal,,,4,1,10.1186/2046-4053-4-1,"Systematic reviews should build on a protocol that describes the rationale, hypothesis, and planned methods of the review; few reviews report whether a protocol exists. Detailed, well-described protocols can facilitate the understanding and appraisal of the review methods, as well as the detection of modifications to methods and selective reporting in completed reviews. We describe the development of a reporting guideline, the Preferred Reporting Items for Systematic reviews and Meta-Analyses for Protocols 2015 (PRISMA-P 2015). PRISMA-P consists of a 17-item checklist intended to facilitate the preparation and reporting of a robust protocol for the systematic review. Funders and those commissioning reviews might consider mandating the use of the checklist to facilitate the submission of relevant protocol information in funding applications. Similarly, peer reviewers and editors can use the guidance to gauge the completeness and transparency of a systematic review protocol submitted for publication in a journal or other medium.","['Systematic review', 'Checklist', 'Protocol (science)', 'Medicine', 'Guideline', 'Transparency (behavior)', 'Critical appraisal', 'Meta-analysis', 'MEDLINE', 'Alternative medicine', 'Computer science', 'Pathology', 'Psychology', 'Computer security', 'Political science', 'Law', 'Cognitive psychology']","systematic reviews, selective reporting, reporting, peer reviewers, editors, systematic review"
Paper_00340,Learning Phrase Representations using RNN Encoder–Decoder for Statistical Machine Translation,"['Kyunghyun Cho', 'Bart van Merriënboer', 'Çağlar Gülçehre', 'Dzmitry Bahdanau', 'Fethi Bougares', 'Holger Schwenk', 'Yoshua Bengio']",2014,Unknown,Unknown,,,,,10.3115/v1/d14-1179,"Kyunghyun Cho, Bart van Merriënboer, Caglar Gulcehre, Dzmitry Bahdanau, Fethi Bougares, Holger Schwenk, Yoshua Bengio. Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP). 2014.","['Machine translation', 'Computer science', 'Phrase', 'Natural language processing', 'Artificial intelligence', 'Encoder', 'Translation (biology)', 'Statistical learning', 'Speech recognition', 'Biochemistry', 'Chemistry', 'Messenger RNA', 'Gene', 'Operating system']","empirical methods, natural language processing"
Paper_00341,Investigating Causal Relations by Econometric Models and Cross-spectral Methods,['Clive W. J. Granger'],1969,Econometrica,Journal,,424-424,37,3,10.2307/1912791,"There occurs on some occasions a difficulty in deciding the direction of causality between two related variables and also whether or not feedback is occurring. Testable definitions of causality and feedback are proposed and illustrated by use of simple two-variable models. The important problem of apparent instantaneous causality is discussed and it is suggested that the problem often arises due to slowness in recording information or because a sufficiently wide class of possible causal variables has not been used. It can be shown that the cross spectrum between two variables can be decomposed into two parts, each relating to a single causal arm of a feedback situation. Measures of causal lag and causal strength can then be constructed. A generalisation of this result with the partial cross spectrum is suggested.","['Econometrics', 'Economics', 'Econometric model', 'Causal model', 'Mathematical economics', 'Mathematics', 'Statistics']","causality, feedback, causality, feedback, apparent instantaneous causality, causal, cross spectrum, causal lag, causal strength, partial cross spectrum"
Paper_00342,Prosedur Penelitian Suatu Pendekatan Praktik,['Suharsimi Arikunto'],2006,['Arif: Jurnal Sastra dan Kearifan Lokal'],Unknown,,58-87,3,1,10.21009/arif.031.04,"Agak berbeda dengan buku-buku Metodologi Riset yang sudah ada. Buku ini disajikan sesuai dengan urutan langkah dalam mengadakan penelitian. Oleh karena langkah penelitian yang membentuk pola ini pun bervariasi menurut pendapat orang yang berbeda. Buku ini mengalami perubahan yang agak signifikan. Perubahan tersebut ialah adanya tambahan bab, yaitu bab III, bab ini menguraikan tentang Penelitian Evaluasi atau mungkin ada yang merasa lebih cocok menggunakan istilah penelitian evaluasi. Pembenahan lain berupa tambahan penjelasan untuk penelitian kualitatif. hal ini dirasa perlu karena di lapangan sering terjadi penyederhanaan prinsip penelitian kualitatif menjadi penelitian deskriptif. Buku ini disajikan untuk membantu para mahasiswa dan calon peneliti dalam menemukan sumber informasi tentang cara mengadakan penelitian.","['Humanities', 'Political science', 'Sociology', 'Art']",
Paper_00343,Intraclass correlations: Uses in assessing rater reliability.,"['Patrick E. Shrout', 'Joseph L. Fleiss']",1979,Psychological Bulletin,Journal,,420-428,86,2,10.1037/0033-2909.86.2.420,"Reliability coefficients often take the form of intraclass correlation coefficients. In this article, guidelines are given for choosing among six different forms of the intraclass correlation for reliability studies in which n target are rated by k judges. Relevant to the choice of the coefficient are the appropriate statistical model for the reliability and the application to be made of the reliability results. Confidence intervals for each of the forms are reviewed.","['Intraclass correlation', 'Reliability (semiconductor)', 'Inter-rater reliability', 'Psychology', 'Statistics', 'Psychometrics', 'Reliability engineering', 'Clinical psychology', 'Mathematics', 'Developmental psychology', 'Rating scale', 'Power (physics)', 'Physics', 'Quantum mechanics', 'Engineering']","reliability coefficients, intraclass correlation coefficients, intraclass correlation, reliability studies, statistical model, reliability, confidence intervals, [PAD], [PAD] [PAD] [PAD], [PAD], [PAD] [PAD] [PAD] [PAD] [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD]"
Paper_00345,Estimates of worldwide burden of cancer in 2008: GLOBOCAN 2008,"['Jacques Ferlay', 'Hai‐Rim Shin', 'Freddie Bray', 'David Forman', 'Colin Mathers', 'Donald Maxwell Parkin']",2010,International Journal of Cancer,Journal,,2893-2917,127,12,10.1002/ijc.25516,"Estimates of the worldwide incidence and mortality from 27 cancers in 2008 have been prepared for 182 countries as part of the GLOBOCAN series published by the International Agency for Research on Cancer. In this article, we present the results for 20 world regions, summarizing the global patterns for the eight most common cancers. Overall, an estimated 12.7 million new cancer cases and 7.6 million cancer deaths occur in 2008, with 56% of new cancer cases and 63% of the cancer deaths occurring in the less developed regions of the world. The most commonly diagnosed cancers worldwide are lung (1.61 million, 12.7% of the total), breast (1.38 million, 10.9%) and colorectal cancers (1.23 million, 9.7%). The most common causes of cancer death are lung cancer (1.38 million, 18.2% of the total), stomach cancer (738,000 deaths, 9.7%) and liver cancer (696,000 deaths, 9.2%). Cancer is neither rare anywhere in the world, nor mainly confined to high-resource countries. Striking differences in the patterns of cancer from region to region are observed.","['Cancer', 'Lung cancer', 'Medicine', 'Breast cancer', 'Colorectal cancer', 'Stomach cancer', 'International agency', 'Demography', 'Causes of cancer', 'Liver cancer', 'Incidence (geometry)', 'Mortality rate', 'Cause of death', 'Disease', 'Internal medicine', 'Physics', 'Sociology', 'Optics']","globocan, breast, colorectal cancers, lung cancer, stomach cancer, liver cancer"
Paper_00346,MRBAYES: Bayesian inference of phylogenetic trees,"['John P. Huelsenbeck', 'Fredrik Ronquist']",2001,Bioinformatics,Journal,,754-755,17,8,10.1093/bioinformatics/17.8.754,"Abstract Summary: The program MRBAYES performs Bayesian inference of phylogeny using a variant of Markov chain Monte Carlo. Availability: MRBAYES, including the source code, documentation, sample data files, and an executable, is available at http://brahms.biology.rochester.edu/software.html. Contact: johnh@brahms.biology.rochester.edu","['Markov chain Monte Carlo', 'Executable', 'Computer science', 'Source code', 'Bayesian probability', 'Inference', 'Sample (material)', 'Phylogenetic tree', 'Software', 'Biology', 'Artificial intelligence', 'Programming language', 'Genetics', 'Chemistry', 'Chromatography', 'Gene']","mrbayes, bayesian inference, phylogeny, markov chain monte carlo, sample data files, [PAD] [PAD], [PAD], [PAD] [PAD], [PAD], [PAD] [PAD] [PAD], [PAD], [PAD] [PAD], [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD], [PAD], [PAD], [PAD]"
Paper_00347,Compressed sensing,['David L. Donoho'],2006,IEEE Transactions on Information Theory,Journal,,1289-1306,52,4,10.1109/tit.2006.871582,"Suppose x is an unknown vector in Ropf <sup xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">m</sup> (a digital image or signal); we plan to measure n general linear functionals of x and then reconstruct. If x is known to be compressible by transform coding with a known transform, and we reconstruct via the nonlinear procedure defined here, the number of measurements n can be dramatically smaller than the size m. Thus, certain natural classes of images with m pixels need only n=O(m <sup xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">1/4</sup> log <sup xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">5/2</sup> (m)) nonadaptive nonpixel samples for faithful recovery, as opposed to the usual m pixel samples. More specifically, suppose x has a sparse representation in some orthonormal basis (e.g., wavelet, Fourier) or tight frame (e.g., curvelet, Gabor)-so the coefficients belong to an lscr <sub xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">p</sub> ball for 0<ples1. The N most important coefficients in that expansion allow reconstruction with lscr <sub xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">2</sub> error O(N <sup xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">1/2-1</sup> p/). It is possible to design n=O(Nlog(m)) nonadaptive measurements allowing reconstruction with accuracy comparable to that attainable with direct knowledge of the N most important coefficients. Moreover, a good approximation to those N important coefficients is extracted from the n measurements by solving a linear program-Basis Pursuit in signal processing. The nonadaptive measurements have the character of ""random"" linear combinations of basis/frame elements. Our results use the notions of optimal recovery, of n-widths, and information-based complexity. We estimate the Gel'fand n-widths of lscr <sub xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">p</sub> balls in high-dimensional Euclidean space in the case 0<ples1, and give a criterion identifying near- optimal subspaces for Gel'fand n-widths. We show that ""most"" subspaces are near-optimal, and show that convex optimization (Basis Pursuit) is a near-optimal way to extract information derived from these near-optimal subspaces","['Compressed sensing', 'Orthonormal basis', 'Artificial intelligence', 'Pixel', 'Computer science', 'Combinatorics', 'Algorithm', 'Mathematics', 'Physics', 'Quantum mechanics']","unknown vector, linear functionals, transform coding, nonlinear procedure, nonadaptive nonpixel samples, faithful recovery, sparse representation, orthonormal basis, wavelet, fourier, tight frame, curvelet, gabor, lscr"
Paper_00350,Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift,"['Sergey Ioffe', 'Christian Szegedy']",2015,arXiv (Cornell University),Unknown,,,,,10.48550/arxiv.1502.03167,"Training Deep Neural Networks is complicated by the fact that the distribution of each layer's inputs changes during training, as the parameters of the previous layers change. This slows down the training by requiring lower learning rates and careful parameter initialization, and makes it notoriously hard to train models with saturating nonlinearities. We refer to this phenomenon as internal covariate shift, and address the problem by normalizing layer inputs. Our method draws its strength from making normalization a part of the model architecture and performing the normalization for each training mini-batch. Batch Normalization allows us to use much higher learning rates and be less careful about initialization. It also acts as a regularizer, in some cases eliminating the need for Dropout. Applied to a state-of-the-art image classification model, Batch Normalization achieves the same accuracy with 14 times fewer training steps, and beats the original model by a significant margin. Using an ensemble of batch-normalized networks, we improve upon the best published result on ImageNet classification: reaching 4.9% top-5 validation error (and 4.8% test error), exceeding the accuracy of human raters.","['Covariate', 'Normalization (sociology)', 'Computer science', 'Training (meteorology)', 'Econometrics', 'Statistics', 'Artificial intelligence', 'Mathematics', 'Geography', 'Sociology', 'Meteorology', 'Anthropology']","learning rates, parameter initialization, internal covariate shift, normalization, batch normalization, image classification, batch normalization, imagenet classification, human rate, [PAD], [PAD], [PAD] [PAD], [PAD], [PAD] [PAD], [PAD] [PAD]"
Paper_00351,Textural Features for Image Classification,"['Robert M. Haralick', 'Karthikeyan Shanmugam', 'I. Dinstein']",1973,IEEE Transactions on Systems Man and Cybernetics,Journal,,610-621,SMC-3,6,10.1109/tsmc.1973.4309314,"Texture is one of the important characteristics used in identifying objects or regions of interest in an image, whether the image be a photomicrograph, an aerial photograph, or a satellite image. This paper describes some easily computable textural features based on gray-tone spatial dependancies, and illustrates their application in category-identification tasks of three different kinds of image data: photomicrographs of five kinds of sandstones, 1:20 000 panchromatic aerial photographs of eight land-use categories, and Earth Resources Technology Satellite (ERTS) multispecial imagery containing seven land-use categories. We use two kinds of decision rules: one for which the decision regions are convex polyhedra (a piecewise linear decision rule), and one for which the decision regions are rectangular parallelpipeds (a min-max decision rule). In each experiment the data set was divided into two parts, a training set and a test set. Test set identification accuracy is 89 percent for the photomicrographs, 82 percent for the aerial photographic imagery, and 83 percent for the satellite imagery. These results indicate that the easily computable textural features probably have a general applicability for a wide variety of image-classification applications.","['Panchromatic film', 'Artificial intelligence', 'Set (abstract data type)', 'Computer science', 'Pattern recognition (psychology)', 'Decision rule', 'Identification (biology)', 'Test set', 'Image (mathematics)', 'Computer vision', 'Botany', 'Biology', 'Programming language']","texture, photomicrograph, aerial photograph, satellite image, ##ural features, ##micro, ##ch, earth resources technology satellite, decision rules, convex polyhedra, piecewise linear decision rule, rectangular parallelpipeds, aerial photographic imagery, satellite"
Paper_00352,The empirical mode decomposition and the Hilbert spectrum for nonlinear and non-stationary time series analysis,"['Norden E. Huang', 'Zhengwei Shen', 'Steven Long', 'Man‐Li C. Wu', 'Hsing H. Shih', 'Quanan Zheng', 'Nai-chyuan Yen', 'C. C. Tung', 'Henry H. Liu']",1998,Proceedings of the Royal Society A Mathematical Physical and Engineering Sciences,Journal,,903-995,454,1971,10.1098/rspa.1998.0193,"A new method for analysing nonlinear and non-stationary data has been developed.The key part of the method is the 'empirical mode decomposition' method with which any complicated data set can be decomposed into a finite and often small number of 'intrinsic mode functions' that admit well-behaved Hilbert transforms.This decomposition method is adaptive, and, therefore, highly efficient.Since the decomposition is based on the local characteristic time scale of the data, it is applicable to nonlinear and non-stationary processes.With the Hilbert transform, the 'instrinic mode functions' yield instantaneous frequencies as functions of time that give sharp identifications of imbedded structures.The final presentation of the results is an energy-frequency-time distribution, designated as the Hilbert spectrum.In this method, the main conceptual innovations are the introduction of 'intrinsic mode functions' based on local properties of the signal, which makes the instantaneous frequency meaningful; and the introduction of the instantaneous frequencies for complicated data sets, which eliminate the need for spurious harmonics to represent nonlinear and non-stationary signals.Examples from the numerical results of the classical nonlinear equation systems and data representing natural phenomena are given to demonstrate the power of this new method.Classical nonlinear system data are especially interesting, for they serve to illustrate the roles played by the nonlinear and non-stationary effects in the energy-frequency-time distribution.","['Hilbert–Huang transform', 'Series (stratigraphy)', 'Singular spectrum analysis', 'Nonlinear system', 'Hilbert spectral analysis', 'Mathematics', 'Time series', 'Spectrum (functional analysis)', 'Spectral analysis', 'Applied mathematics', 'Statistical physics', 'Physics', 'Statistics', 'Algorithm', 'Singular value decomposition', 'White noise', 'Quantum mechanics', 'Geology', 'Paleontology', 'Spectroscopy']","empirical mode decomposition, intrinsic mode functions, local characteristic time scale, hilbert transform, instrinic mode functions, instant, hilbert spectrum, intrinsic mode functions, instant, instantaneous frequencies"
Paper_00353,Some methods for classification and analysis of multivariate observations,['James B. MacQueen'],1967,['Technometrics'],Unknown,,85,28,1,10.2307/1269608,"The main purpose of this paper is to describe a process for partitioning an N-dimensional population into k sets on the basis of a sample. The process, which is called 'k-means,' appears to give partitions which are reasonably efficient in the sense of within-class variance. That is, if p is the probability mass function for the population, S = {S1, S2, * *, Sk} is a partition of EN, and ui, i = 1, 2, * , k, is the conditional mean of p over the set Si, then W2(S) = ff=ISi f z u42 dp(z) tends to be low for the partitions S generated by the method. We say 'tends to be low,' primarily because of intuitive considerations, corroborated to some extent by mathematical analysis and practical computational experience. Also, the k-means procedure is easily programmed and is computationally economical, so that it is feasible to process very large samples on a digital computer. Possible applications include methods for similarity grouping, nonlinear prediction, approximating multivariate distributions, and nonparametric tests for independence among several variables. In addition to suggesting practical classification methods, the study of k-means has proved to be theoretically interesting. The k-means concept represents a generalization of the ordinary sample mean, and one is naturally led to study the pertinent asymptotic behavior, the object being to establish some sort of law of large numbers for the k-means. This problem is sufficiently interesting, in fact, for us to devote a good portion of this paper to it. The k-means are defined in section 2.1, and the main results which have been obtained on the asymptotic behavior are given there. The rest of section 2 is devoted to the proofs of these results. Section 3 describes several specific possible applications, and reports some preliminary results from computer experiments conducted to explore the possibilities inherent in the k-means idea. The extension to general metric spaces is indicated briefly in section 4. The original point of departure for the work described here was a series of problems in optimal classification (MacQueen [9]) which represented special","['Mathematics', 'Generalization', 'Population', 'Nonparametric statistics', 'Independence (probability theory)', 'Multivariate statistics', 'Set (abstract data type)', 'sort', 'Sample (material)', 'Partition (number theory)', 'Function (biology)', 'Algorithm', 'Statistics', 'Combinatorics', 'Computer science', 'Arithmetic', 'Mathematical analysis', 'Chemistry', 'Demography', 'Chromatography', 'Evolutionary biology', 'Sociology', 'Biology', 'Programming language']","probability mass function, conditional mean, mathematical analysis, computational, similarity grouping, nonlinear prediction, ##imating multivariate distributions, nonparametric tests, classification, pertinent asymptotic behavior, asymptotic behavior, optimal classification"
Paper_00354,Biometry: The Principles and Practice of Statistics in Biological Research,"['Robert R. Sokal', 'F. James Rohlf']",1969,['Journal of the Royal Statistical Society. Series A (General)'],Unknown,,102,133,1,10.2307/2343822,1. Introduction 2. Data in Biology 3. Computers and Data Analysis 4. Descriptive Statistics 5. Introduction to Probability Distributions 6. The Normal Probability Distribution 7. Hypothesis Testing and Interval Estimation 8. Introduction to Analysis of Variance 9. Single-Classification Analysis of Variance 10. Nested Analysis of Variance 11. Two-Way and Multiway Analysis of Variance 12. Statistical Power and Sample Size in the Analysis of Variance 13. Assumptions of Analysis of Variance 14. Linear Regression 15. Correlation 16. Multiple and Curvilinear Regression 17. Analysis of Frequencies 18. Meta-Analysis and Miscellaneous Methods,"['Statistics', 'Descriptive statistics', 'Analysis of variance', 'One-way analysis of variance', 'Variance (accounting)', 'Regression analysis', 'Sample size determination', 'Mathematics', 'Econometrics', 'Accounting', 'Business']","biology, computers, data analysis, descriptive statistics, probability distributions, normal probability distribution, hypothesis testing, interval estimation, nested analysis, statistical power, sample size, assumptions, linear regression, correlation, multiple, curvilinear regression, [PAD] [PAD], [PAD] [PAD] [PAD] [PAD] [PAD], [PAD], [PAD] [PAD], [PAD] [PAD], [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD] [PAD], [PAD] [PAD], [PAD] [PAD], [PAD] [PAD] [PAD], [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD], [PAD], [PAD] [PAD], [PAD], [PAD], [PAD] [PAD], [PAD], [PAD], [PAD], [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD], [PAD], [PAD] [PAD], [PAD] [PAD] [PAD], [PAD] [PAD], [PAD] [PAD], [PAD] [PAD] [PAD] [PAD]"
Paper_00355,Attention is All you Need,"['Ashish Vaswani', 'Noam Shazeer', 'Niki Parmar', 'Jakob Uszkoreit', 'Llion Jones', 'Aidan N. Gomez', 'Łukasz Kaiser', 'Illia Polosukhin']",2017,['Structural Survey'],Unknown,,31-34,12,5,10.1108/02630809410074466,"The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms. We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.","['Machine translation', 'BLEU', 'Computer science', 'Encoder', 'Parallelizable manifold', 'Artificial intelligence', 'Translation (biology)', 'Natural language processing', 'Sequence (biology)', 'Speech recognition', 'Decoding methods', 'Algorithm', 'Biochemistry', 'Chemistry', 'Genetics', 'Biology', 'Messenger RNA', 'Gene', 'Operating system']","dominant sequence transduction models, complex recurrent orconvolutional neural networks, decoder configuration, attentionm echanisms, attention mechanism, machine translation tasks"
Paper_00357,Applied Multiple Regression/Correlation Analysis for the Behavioral Sciences,"['Patricia Cohen', 'Patricia Cohen', 'Stephen G. West', 'Leona S. Aiken']",2014,Psychology Press eBooks,Unknown,,,,,10.4324/9781410606266,"Contents: Preface. Introduction. Bivariate Correlation and Regression. Multiple Regression/Correlation With Two or More Independent Variables. Data Visualization, Exploration, and Assumption Checking: Diagnosing and Solving Regression Problems I. Data-Analytic Strategies Using Multiple Regression/Correlation. Quantitative Scales, Curvilinear Relationships, and Transformations. Interactions Among Continuous Variables. Categorical or Nominal Independent Variables. Interactions With Categorical Variables. Outliers and Multicollinearity: Diagnosing and Solving Regression Problems II. Missing Data. Multiple Regression/Correlation and Causal Models. Alternative Regression Models: Logistic, Poisson Regression, and the Generalized Linear Model. Random Coefficient Regression and Multilevel Models. Longitudinal Regression Methods. Multiple Dependent Variables: Set Correlation. Appendices: The Mathematical Basis for Multiple Regression/Correlation and Identification of the Inverse Matrix Elements. Determination of the Inverse Matrix and Applications Thereof.","['Correlation', 'Statistics', 'Regression analysis', 'Psychology', 'Mathematics', 'Geometry']","bivariate correlation, regression, multiple regression, data visualization, exploration, assumption checking, quantitative scales, curvilinear relationships, transformations, continuous variables, nominal independent variables, categorical, outliers, multicollinearity, causal models, log, poisson regression, generalized linear model, random coefficient regression, multilevel models, longitudinal regression methods, multiple dependent variables, set correlation, mathematical basis, inverse matrix, inverse matrix"
Paper_00358,"THE ADSORPTION OF GASES ON PLANE SURFACES OF GLASS, MICA AND PLATINUM.",['Irving Langmuir'],1918,Journal of the American Chemical Society,Journal,,1361-1403,40,9,10.1021/ja02242a004,"ADVERTISEMENT RETURN TO ISSUEPREVArticleNEXTTHE ADSORPTION OF GASES ON PLANE SURFACES OF GLASS, MICA AND PLATINUM.Irving LangmuirCite this: J. Am. Chem. Soc. 1918, 40, 9, 1361–1403Publication Date (Print):September 1, 1918Publication History Published online1 May 2002Published inissue 1 September 1918https://pubs.acs.org/doi/10.1021/ja02242a004https://doi.org/10.1021/ja02242a004research-articleACS PublicationsRequest reuse permissionsArticle Views24474Altmetric-Citations17033LEARN ABOUT THESE METRICSArticle Views are the COUNTER-compliant sum of full text article downloads since November 2008 (both PDF and HTML) across all institutions and individuals. These metrics are regularly updated to reflect usage leading up to the last few days.Citations are the number of other articles citing this article, calculated by Crossref and updated daily. Find more information about Crossref citation counts.The Altmetric Attention Score is a quantitative measure of the attention that a research article has received online. Clicking on the donut icon will load a page at altmetric.com with additional details about the score and the social media presence for the given article. Find more information on the Altmetric Attention Score and how the score is calculated. Share Add toView InAdd Full Text with ReferenceAdd Description ExportRISCitationCitation and abstractCitation and referencesMore Options Share onFacebookTwitterWechatLinked InRedditEmail Other access optionsGet e-Alertsclose Get e-Alerts","['Citation', 'Mica', 'Icon', 'Adsorption', 'Social media', 'Computer science', 'Information retrieval', 'World Wide Web', 'Materials science', 'Chemistry', 'Composite material', 'Physical chemistry', 'Programming language']","##var, plane surfaces, glass, mica, platinum, permissionsarticle views, metric, ##le, ##f, altmetric attention score, social, altmetric attention score, ##riscitation, abstract, ##ation, references"
Paper_00359,Distribution of the Estimators for Autoregressive Time Series with a Unit Root,"['David A. Dickey', 'Wayne A. Fuller']",1979,Journal of the American Statistical Association,Journal,,427-431,74,366a,10.1080/01621459.1979.10482531,"Abstract Let n observations Y 1, Y 2, ···, Y n be generated by the model Y t = pY t−1 + e t , where Y 0 is a fixed constant and {e t } t-1 n is a sequence of independent normal random variables with mean 0 and variance σ2. Properties of the regression estimator of p are obtained under the assumption that p = ±1. Representations for the limit distributions of the estimator of p and of the regression t test are derived. The estimator of p and the regression t test furnish methods of testing the hypothesis that p = 1.","['Mathematics', 'Autoregressive model', 'Estimator', 'Statistics', 'Series (stratigraphy)', 'Regression analysis', 'Combinatorics', 'Biology', 'Paleontology']","fixed constant, independent normal random variables, regression estimator, limit distributions, regression t test, regression t test, [PAD], [PAD] [PAD] [PAD] [PAD], [PAD], [PAD] [PAD] [PAD], [PAD], [PAD] [PAD], [PAD]"
Paper_00360,Ultrafast and memory-efficient alignment of short DNA sequences to the human genome,"['Ben Langmead', 'Cole Trapnell', 'Mihai Pop', 'Steven L. Salzberg']",2009,Genome biology,Journal,,,10,3,10.1186/gb-2009-10-3-r25,"Abstract Bowtie is an ultrafast, memory-efficient alignment program for aligning short DNA sequence reads to large genomes. For the human genome, Burrows-Wheeler indexing allows Bowtie to align more than 25 million reads per CPU hour with a memory footprint of approximately 1.3 gigabytes. Bowtie extends previous Burrows-Wheeler techniques with a novel quality-aware backtracking algorithm that permits mismatches. Multiple processor cores can be used simultaneously to achieve even greater alignment speeds. Bowtie is open source http://bowtie.cbcb.umd.edu .","['Biology', 'Human genetics', 'Human genome', 'Genome', 'Computational biology', 'Genetics', 'Genome Biology', 'Computational genomics', 'DNA', 'DNA sequencing', 'Evolutionary biology', 'Genomics', 'Gene']","abstract bowtie, short, human, bowtie, bowtie, bowtie"
Paper_00363,"Research Design: Qualitative, Quantitative, and Mixed Methods Approaches",['John W. Creswell'],1994,['Revista de Administração Contemporânea'],Unknown,,223-223,7,1,10.1590/s1415-65552003000100015,"The eagerly anticipated fourth edition of the title that pioneered the comparison of qualitative, quantitative, and mixed methods research design. for all three approaches, John W, Creswell includes a preliminary consideration of philosophical assumptions, a review of the literature, an assessment of the use of theory in research approaches, and reflections about the importance writing and ethics in scholarly inquiry.","['Multimethodology', 'Management science', 'Qualitative research', 'Engineering ethics', 'Epistemology', 'Sociology', 'Research design', 'Social science', 'Engineering', 'Philosophy']","qu, mixed methods research design, philosophical assumptions, theory, research approaches, writing, ethics, scholarly inquiry, [PAD] [PAD], [PAD]"
Paper_00364,The Constitution of Society. Outline of the Theory of Structuration,['Anthony Giddens'],1984,['Political Geography Quarterly'],Unknown,,288-289,5,3,10.1016/0260-9827(86)90040-6,"Anthony Giddens has been in the forefront of developments in social theory for the past decade. In The Constitution of Society he outlines the distinctive position he has evolved during that period and offers a full statement of a major new perspective in social thought, a synthesis and elaboration of ideas touched on in previous works but described here for the first time in an integrated and comprehensive form. A particular feature is Giddens' concern to connect abstract problems of theory to an interpretation of the nature of empirical method in the social sciences. In presenting his own ideas, Giddens mounts a critical attack on some of the more orthodox sociological views. The Constitution of Society is an invaluable reference book for all those concerned with the basic issues in contemporary social theory.","['Constitution', 'Epistemology', 'Interpretation (philosophy)', 'Structuration theory', 'Sociology', 'Sociological theory', 'Social theory', 'Perspective (graphical)', 'Social science', 'Contemporary society', 'Political science', 'Law', 'Philosophy', 'Computer science', 'Linguistics', 'Artificial intelligence']","social theory, constitution of society, social thought, empirical method, social, constitution of, social theory"
Paper_00365,COPPER ENZYMES IN ISOLATED CHLOROPLASTS. POLYPHENOLOXIDASE IN <i>BETA VULGARIS</i>,['Daniel I. Arnon'],1949,PLANT PHYSIOLOGY,Journal,,1-15,24,1,10.1104/pp.24.1.1,"The chloroplast, as the seat of chlorophyll pigments in plants, occupies a unique position in the economy of the green cell.In recent years there has been a renewed interest in the reactions and properties of chloroplasts as a result of the work of HIL (11, 12) and HIL and SCARISBRICK (13,14) who demonstrated that the reaction characteristic of photosynthesis in green plants, the evolution of oxygen, occurs in appreciable quantities in isolated chloroplasts under the influence of light and in the presence of suitable oxidants (2, 7, 8, 26).In the course of an investigation of oxygen evolution by isolated chloro- plasts it was deemed important to explore their enzymatic composition.Of special interest were considered enzymes capable of participating in oxida- tion-reduction reactions, and more particularly, those localized principally, if not entirely, in the chloroplasts.This paper presents evidence that a copper enzyme, polyphenoloxidase (otherwise known as tyrosinase or cate- cholase), is localized in the chloroplasts of spinach beet (chard), Beta vu.'- garis.Methods GROWING OF PLANTS.-Seeds of spinach beet were germinated and grown in sand in flower pots in a greenhouse, heated to prevent the tem- perature from falling below freezing in winter.The pots were watered with a nutrient solution of the following composition (made with local tap water): KNO3-0.01M;Ca(NO3)2-0.002M;NH4H2PO4-0.002M;MgSO4 -0.002M; and A4, a combination of the micronutrients Mn, B, Ca, Zn","['BETA (programming language)', 'Enzyme', 'Botany', 'Chloroplast', 'Copper', 'Biology', 'Chemistry', 'Biochemistry', 'Gene', 'Organic chemistry', 'Computer science', 'Programming language']","##l pigments, ##las, oxygen evolution, copper enzyme, ##loxidase, ##ach bee, nutrient solution"
Paper_00366,Frailty in Older Adults: Evidence for a Phenotype,"['Linda P. Fried', 'Catherine M. Tangen', 'Jeremy Walston', 'Anne B. Newman', 'Calvin H. Hirsch', 'John S. Gottdiener', 'Teresa E. Seeman', 'Russell P. Tracy', 'Willem J. Kop', 'Gregory L. Burke', 'Mary Ann McBurnie']",2001,The Journals of Gerontology Series A,Journal,,M146-M157,56,3,10.1093/gerona/56.3.m146,"Background. Frailty is considered highly prevalent in old age and to confer high risk for falls, disability, hospitalization, and mortality. Frailty has been considered synonymous with disability, comorbidity, and other characteristics, but it is recognized that it may have a biologic basis and be a distinct clinical syndrome. A standardized definition has not yet been established.","['Medicine', 'Comorbidity', 'Concordance', 'Gerontology', 'Cohort', 'Grip strength', 'Population', 'Cohort study', 'Incidence (geometry)', 'Disease', 'Demography', 'Physical therapy', 'Internal medicine', 'Environmental health', 'Physics', 'Sociology', 'Optics']","frailty, frailty, disability, comorbidity, [PAD], [PAD], [PAD] [PAD]"
Paper_00367,The calculation of small molecular interactions by the differences of separate total energies. Some procedures with reduced errors,"['Samuel Francis Boys', 'Fernando Bernardi']",1970,Molecular Physics,Journal,,553-566,19,4,10.1080/00268977000101561,"A new direct difference method for the computation of molecular interactions has been based on a bivariational transcorrelated treatment, together with special methods for the balancing of other errors. It appears that these new features can give a strong reduction in the error of the interaction energy, and they seem to be particularly suitable for computations in the important region near the minimum energy. It has been generally accepted that this problem is dominated by unresolved difficulties and the relation of the new methods to these apparent difficulties is analysed here.","['Computation', 'Reduction (mathematics)', 'Energy (signal processing)', 'Relation (database)', 'Total energy', 'Computer science', 'Algorithm', 'Statistical physics', 'Mathematics', 'Statistics', 'Physics', 'Data mining', 'Geometry', 'Psychology', 'Displacement (psychology)', 'Psychotherapist']","direct difference method, molecular interactions, bivariational transcorrelated treatment, interaction energy, minimum energy"
Paper_00368,featureCounts: an efficient general purpose program for assigning sequence reads to genomic features,"['Yang Liao', 'Gordon K. Smyth', 'Wei Shi']",2013,Bioinformatics,Journal,,923-930,30,7,10.1093/bioinformatics/btt656,"Motivation: Next-generation sequencing technologies generate millions of short sequence reads, which are usually aligned to a reference genome. In many applications, the key information required for downstream analysis is the number of reads mapping to each genomic feature, for example to each exon or each gene. The process of counting reads is called read summarization. Read summarization is required for a great variety of genomic analyses but has so far received relatively little attention in the literature. Results: We present featureCounts, a read summarization program suitable for counting reads generated from either RNA or genomic DNA sequencing experiments. featureCounts implements highly efficient chromosome hashing and feature blocking techniques. It is considerably faster than existing methods (by an order of magnitude for gene-level summarization) and requires far less computer memory. It works with either single or paired-end reads and provides a wide range of options appropriate for different sequencing applications. Availability and implementation: featureCounts is available under GNU General Public License as part of the Subread (http://subread.sourceforge.net) or Rsubread (http://www.bioconductor.org) software packages. Contact: shi@wehi.edu.au","['Automatic summarization', 'Computer science', 'Bioconductor', 'MIT License', 'Software', 'DNA sequencing', 'Genome', 'Computational biology', 'Biology', 'Genetics', 'Artificial intelligence', 'Gene', 'Programming language']","read summarization, read summarization, featurecounts, read summarization program, featurecounts, chromosome hashing, feature blocking techniques, featurecounts"
Paper_00369,A Simple Sequentially Rejective Multiple Test Procedure,['Sture Holm'],1979,Scandinavian Journal of Statistics,Journal,,65-70,6,,10.2307/4615733,"This paper presents a simple and widely ap- plicable multiple test procedure of the sequentially rejective type, i.e. hypotheses are rejected one at a tine until no further rejections can be done. It is shown that the test has a prescribed level of significance protection against error of the first kind for any combination of true hypotheses. The power properties of the test and a number of possible applications are also discussed.","['Mathematics', 'Simple (philosophy)', 'Type I and type II errors', 'Test (biology)', 'Statistics', 'Paleontology', 'Philosophy', 'Epistemology', 'Biology']","multiple test, sequential, significance protection, power properties"
Paper_00370,Ab Initio Calculation of Vibrational Absorption and Circular Dichroism Spectra Using Density Functional Force Fields,"['Philip J. Stephens', 'F. J. Devlin', 'Cary F. Chabalowski', 'Michael J. Frisch']",1994,The Journal of Physical Chemistry,Journal,,11623-11627,98,45,10.1021/j100096a001,"ADVERTISEMENT RETURN TO ISSUEArticleNEXTAb Initio Calculation of Vibrational Absorption and Circular Dichroism Spectra Using Density Functional Force FieldsP. J. Stephens, F. J. Devlin, C. F. Chabalowski, and M. J. FrischCite this: J. Phys. Chem. 1994, 98, 45, 11623–11627Publication Date (Print):November 1, 1994Publication History Published online1 May 2002Published inissue 1 November 1994https://pubs.acs.org/doi/10.1021/j100096a001https://doi.org/10.1021/j100096a001research-articleACS PublicationsRequest reuse permissionsArticle Views22554Altmetric-Citations18558LEARN ABOUT THESE METRICSArticle Views are the COUNTER-compliant sum of full text article downloads since November 2008 (both PDF and HTML) across all institutions and individuals. These metrics are regularly updated to reflect usage leading up to the last few days.Citations are the number of other articles citing this article, calculated by Crossref and updated daily. Find more information about Crossref citation counts.The Altmetric Attention Score is a quantitative measure of the attention that a research article has received online. Clicking on the donut icon will load a page at altmetric.com with additional details about the score and the social media presence for the given article. Find more information on the Altmetric Attention Score and how the score is calculated. Share Add toView InAdd Full Text with ReferenceAdd Description ExportRISCitationCitation and abstractCitation and referencesMore Options Share onFacebookTwitterWechatLinked InRedditEmail Other access options Get e-Alerts","['Ab initio', 'Icon', 'Density functional theory', 'Citation', 'Absorption (acoustics)', 'Physics', 'Spectral line', 'Information retrieval', 'Computer science', 'World Wide Web', 'Optics', 'Quantum mechanics', 'Programming language']","##o, vibrational absorption, circular dichroism spectra, density functional force fields, permissionsarticle views, altmetric attention score, social, altmetric attention score, ##d, ##riscitation, ##ation, abstract, ##ation, references"
Paper_00371,Canonical dynamics: Equilibrium phase-space distributions,['William G. Hoover'],1985,"Physical review. A, General physics",Journal,,1695-1697,31,3,10.1103/physreva.31.1695,"Nos\'e has modified Newtonian dynamics so as to reproduce both the canonical and the isothermal-isobaric probability densities in the phase space of an N-body system. He did this by scaling time (with s) and distance (with ${V}^{1/D}$ in D dimensions) through Lagrangian equations of motion. The dynamical equations describe the evolution of these two scaling variables and their two conjugate momenta ${p}_{s}$ and ${p}_{v}$. Here we develop a slightly different set of equations, free of time scaling. We find the dynamical steady-state probability density in an extended phase space with variables x, ${p}_{x}$, V, \ensuremath{\epsilon}\ifmmode \dot{}\else \.{}\fi{}, and \ensuremath{\zeta}, where the x are reduced distances and the two variables \ensuremath{\epsilon}\ifmmode \dot{}\else \.{}\fi{} and \ensuremath{\zeta} act as thermodynamic friction coefficients. We find that these friction coefficients have Gaussian distributions. From the distributions the extent of small-system non-Newtonian behavior can be estimated. We illustrate the dynamical equations by considering their application to the simplest possible case, a one-dimensional classical harmonic oscillator.","['Physics', 'Phase space', 'Scaling', 'Harmonic oscillator', 'Mathematical physics', 'Equations of motion', 'Dynamical systems theory', 'Probability distribution', 'Classical mechanics', 'Quantum mechanics', 'Mathematics', 'Statistics', 'Geometry']","newtonian dynamics, phase space, scaling time, lagrangian equations of motion, time scaling, thermodynamic friction coefficients, friction coefficients, gaussian distributions, classical harmonic oscillator"
Paper_00372,Computer Simulation of Liquids,"['Michael P. Allen', 'Dominic J. Tildesley']",2017,Oxford University Press eBooks,Unknown,,,,,10.1093/oso/9780198803195.001.0001,"Abstract This book provides a practical guide to molecular dynamics and Monte Carlo simulation techniques used in the modelling of simple and complex liquids. Computer simulation is an essential tool in studying the chemistry and physics of condensed matter, complementing and reinforcing both experiment and theory. Simulations provide detailed information about structure and dynamics, essential to understand the many fluid systems that play a key role in our daily lives: polymers, gels, colloidal suspensions, liquid crystals, biological membranes, and glasses. The second edition of this pioneering book aims to explain how simulation programs work, how to use them, and how to interpret the results, with examples of the latest research in this rapidly evolving field. Accompanying programs in Fortran and Python provide practical, hands-on, illustrations of the ideas in the text.","['Python (programming language)', 'Molecular dynamics', 'Fortran', 'Computer science', 'Monte Carlo method', 'Computational science', 'Statistical physics', 'Chemistry', 'Physics', 'Programming language', 'Computational chemistry', 'Mathematics', 'Statistics']","molecular dynamics, monte carlo simulation techniques, computer simulation, condensed matter, polymers, gels, colloidal suspensions, liquid crystals, biological membranes, glasses, simulation, fortran, python"
Paper_00373,Distinction: A Social Critique of the Judgement of Taste*,['Pierre Bourdieu'],2018,Routledge eBooks,Unknown,,141-150,,,10.4324/9781315680347-10,"The basic opposition between the tastes of luxury and the tastes of necessity is specified in as many oppositions as there are different ways of asserting one's distinction vis-a-vis the working class and its primary needs, or-which amounts to the same thing-different powers whereby necessity can be kept at a distance. The taste for rare, aristocratic foods points to a traditional cuisine, rich in expensive or rare product. The system of differences becomes clearer when one looks more closely at the patterns of spending on food. The quasi-conscious representation of the approved form of the perceived body, and in particular its thinness or fatness, is not the only mediation through which the social definition of appropriate foods is established. The relation to food-the primary need and pleasure-is only one dimension of the bourgeois relation to the social world.","['Judgement', 'Taste', 'Epistemology', 'Aesthetics', 'Psychology', 'Sociology', 'Social psychology', 'Philosophy', 'Neuroscience']","luxury, necessity, working, aristocratic foods, fat"
Paper_00374,The ERA5 global reanalysis,"['Hans Hersbach', 'Bill Bell', 'Paul Berrisford', 'Shoji Hirahara', 'Ándrás Horányi', 'Joaquı́n Muñoz-Sabater', 'Julien P. Nicolas', 'Carole Peubey', 'Raluca Radu', 'Dinand Schepers', 'A. J. Simmons', 'Cornel Soci', 'Saleh Abdalla', 'Xavier Abellan', 'Gianpaolo Balsamo', 'Peter Bechtold', 'G. Biavati', 'Jean‐Raymond Bidlot', 'Massimo Bonavita', 'Giovanna De Chiara', 'Per Dahlgren', 'Dick Dee', 'Michail Diamantakis', 'Rossana Dragani', 'Johannes Flemming', 'Richard Forbes', 'Manuel Fuentes', 'Alan J. Geer', 'Leo Haimberger', 'S. B. Healy', 'Robin J. Hogan', 'Elías Hólm', 'Marta Janisková', 'Sarah Keeley', 'Patrick Laloyaux', 'Philippe Lopez', 'Cristina Lupu', 'Gábor Radnóti', 'Patricia de Rosnay', 'I. Rozum', 'Freja Vamborg', 'Sébastien Villaume', 'Jean‐Noël Thépaut']",2020,Quarterly Journal of the Royal Meteorological Society,Journal,,1999-2049,146,730,10.1002/qj.3803,"Abstract Within the Copernicus Climate Change Service (C3S), ECMWF is producing the ERA5 reanalysis which, once completed, will embody a detailed record of the global atmosphere, land surface and ocean waves from 1950 onwards. This new reanalysis replaces the ERA‐Interim reanalysis (spanning 1979 onwards) which was started in 2006. ERA5 is based on the Integrated Forecasting System (IFS) Cy41r2 which was operational in 2016. ERA5 thus benefits from a decade of developments in model physics, core dynamics and data assimilation. In addition to a significantly enhanced horizontal resolution of 31 km, compared to 80 km for ERA‐Interim, ERA5 has hourly output throughout, and an uncertainty estimate from an ensemble (3‐hourly at half the horizontal resolution). This paper describes the general set‐up of ERA5, as well as a basic evaluation of characteristics and performance, with a focus on the dataset from 1979 onwards which is currently publicly available. Re‐forecasts from ERA5 analyses show a gain of up to one day in skill with respect to ERA‐Interim. Comparison with radiosonde and PILOT data prior to assimilation shows an improved fit for temperature, wind and humidity in the troposphere, but not the stratosphere. A comparison with independent buoy data shows a much improved fit for ocean wave height. The uncertainty estimate reflects the evolution of the observing systems used in ERA5. The enhanced temporal and spatial resolution allows for a detailed evolution of weather systems. For precipitation, global‐mean correlation with monthly‐mean GPCP data is increased from 67% to 77%. In general, low‐frequency variability is found to be well represented and from 10 hPa downwards general patterns of anomalies in temperature match those from the ERA‐Interim, MERRA‐2 and JRA‐55 reanalyses.","['Climatology', 'Data assimilation', 'Environmental science', 'Meteorology', 'Buoy', 'Radiosonde', 'Troposphere', 'Horizontal resolution', 'Geology', 'Geography', 'Oceanography']","copernicus climate change service, ##w, era, global atmosphere, land surface, ocean waves, era, integrated forecasting system, era, model physics, core dynamics, data assimilation, horizontal resolution, era, uncertainty estimate, horizontal resolution, era, era, radiosonde, pilot, ##rat, buoy data, ocean wave height, uncertainty estimate, spatial resolution, global, low ‐ frequency variability, merra, jr, [PAD], [PAD]"
Paper_00375,The Third International Consensus Definitions for Sepsis and Septic Shock (Sepsis-3),"['Mervyn Singer', 'Clifford S. Deutschman', 'Christopher W. Seymour', 'Manu Shankar‐Hari', 'Djillali Annane', 'Michael Bauer', 'Rinaldo Bellomo', 'Gordon R. Bernard', 'Jean‐Daniel Chiche', 'Craig M. Coopersmith', 'Richard S. Hotchkiss', 'Mitchell M. Levy', 'John C. Marshall', 'Greg S. Martin', 'Steven M. Opal', 'Gordon D. Rubenfeld', 'Tom van der Poll', 'Jean‐Louis Vincent', 'Derek C. Angus']",2016,JAMA,Journal,,801-801,315,8,10.1001/jama.2016.0287,"<h3>Importance</h3> Definitions of sepsis and septic shock were last revised in 2001. Considerable advances have since been made into the pathobiology (changes in organ function, morphology, cell biology, biochemistry, immunology, and circulation), management, and epidemiology of sepsis, suggesting the need for reexamination. <h3>Objective</h3> To evaluate and, as needed, update definitions for sepsis and septic shock. <h3>Process</h3> A task force (n = 19) with expertise in sepsis pathobiology, clinical trials, and epidemiology was convened by the Society of Critical Care Medicine and the European Society of Intensive Care Medicine. Definitions and clinical criteria were generated through meetings, Delphi processes, analysis of electronic health record databases, and voting, followed by circulation to international professional societies, requesting peer review and endorsement (by 31 societies listed in the Acknowledgment). <h3>Key Findings From Evidence Synthesis</h3> Limitations of previous definitions included an excessive focus on inflammation, the misleading model that sepsis follows a continuum through severe sepsis to shock, and inadequate specificity and sensitivity of the systemic inflammatory response syndrome (SIRS) criteria. Multiple definitions and terminologies are currently in use for sepsis, septic shock, and organ dysfunction, leading to discrepancies in reported incidence and observed mortality. The task force concluded the term<i>severe sepsis</i>was redundant. <h3>Recommendations</h3> Sepsis should be defined as life-threatening organ dysfunction caused by a dysregulated host response to infection. For clinical operationalization, organ dysfunction can be represented by an increase in the Sequential [Sepsis-related] Organ Failure Assessment (SOFA) score of 2 points or more, which is associated with an in-hospital mortality greater than 10%. Septic shock should be defined as a subset of sepsis in which particularly profound circulatory, cellular, and metabolic abnormalities are associated with a greater risk of mortality than with sepsis alone. Patients with septic shock can be clinically identified by a vasopressor requirement to maintain a mean arterial pressure of 65 mm Hg or greater and serum lactate level greater than 2 mmol/L (&gt;18 mg/dL) in the absence of hypovolemia. This combination is associated with hospital mortality rates greater than 40%. In out-of-hospital, emergency department, or general hospital ward settings, adult patients with suspected infection can be rapidly identified as being more likely to have poor outcomes typical of sepsis if they have at least 2 of the following clinical criteria that together constitute a new bedside clinical score termed quickSOFA (qSOFA): respiratory rate of 22/min or greater, altered mentation, or systolic blood pressure of 100 mm Hg or less. <h3>Conclusions and Relevance</h3> These updated definitions and clinical criteria should replace previous definitions, offer greater consistency for epidemiologic studies and clinical trials, and facilitate earlier recognition and more timely management of patients with sepsis or at risk of developing sepsis.","['Sepsis', 'Medicine', 'Septic shock', 'Intensive care medicine', 'Organ dysfunction', 'Systemic inflammatory response syndrome', 'SOFA score', 'Epidemiology', 'Shock (circulatory)', 'Immunology', 'Internal medicine']","sepsis, septic shock, ##obiology, organ function, cell biology, biochemistry, immun, circulation, sep, sep, septic shock, sepsis pathobiology, clinical trials, epidemiology, critical care medicine, european society, intensive care medicine, delphi processes, electronic health record databases, sep, systemic inflammatory response syndrome, septic shock, organ dysfunction, d, ##gulated host response, organ failure assessment, septic shock, sep, profound ci, metabolic abnormalities, sept, vasopressor requirement, mean, ##yp"
Paper_00376,IQ-TREE: A Fast and Effective Stochastic Algorithm for Estimating Maximum-Likelihood Phylogenies,"['Lam-Tung Nguyen', 'Heiko A. Schmidt', 'Arndt von Haeseler', 'Bùi Quang Minh']",2014,Molecular Biology and Evolution,Journal,,268-274,32,1,10.1093/molbev/msu300,"Large phylogenomics data sets require fast tree inference methods, especially for maximum-likelihood (ML) phylogenies. Fast programs exist, but due to inherent heuristics to find optimal trees, it is not clear whether the best tree is found. Thus, there is need for additional approaches that employ different search strategies to find ML trees and that are at the same time as fast as currently available ML programs. We show that a combination of hill-climbing approaches and a stochastic perturbation method can be time-efficiently implemented. If we allow the same CPU time as RAxML and PhyML, then our software IQ-TREE found higher likelihoods between 62.2% and 87.1% of the studied alignments, thus efficiently exploring the tree-space. If we use the IQ-TREE stopping rule, RAxML and PhyML are faster in 75.7% and 47.1% of the DNA alignments and 42.2% and 100% of the protein alignments, respectively. However, the range of obtaining higher likelihoods with IQ-TREE improves to 73.3–97.1%. IQ-TREE is freely available at http://www.cibiv.at/software/iqtree.","['Tree (set theory)', 'Inference', 'Heuristics', 'Biology', 'Computer science', 'Software', 'Phylogenomics', 'Algorithm', 'Maximum likelihood', 'Phylogenetic tree', 'Machine learning', 'Mathematics', 'Statistics', 'Artificial intelligence', 'Combinatorics', 'Clade', 'Biochemistry', 'Gene', 'Programming language', 'Operating system']","phylogenomics, stochastic perturbation method, ph, ##l, raxml, phyml, dna, protein alignments, iq"
Paper_00377,Qualitative Inquiry and Research Design: Choosing Among Five Approaches,['Sarah Lewis'],2015,Health Promotion Practice,Journal,,473-475,16,4,10.1177/1524839915580941,"Qualitative Inquiry and Research Design provides an overview of the five main traditions of qualitative research. The author explains the uniqueness of each approach and its applicability to different types of inquiry. Illustrative examples from public health and social science fields are provided. The book details study design, question development, data collection and analysis, and summarizing and interpreting results, and how the research process differs according to each approach. This resource can serve as a useful guide for public health practitioners and graduate-level students interested in the theory and practice of rigorous qualitative research.","['Qualitative research', 'Research design', 'Resource (disambiguation)', 'Data collection', 'Management science', 'Public health', 'Process (computing)', 'Sociology', 'Engineering ethics', 'Computer science', 'Medicine', 'Social science', 'Engineering', 'Nursing', 'Computer network', 'Operating system']","qualitative inquiry, research design, qualitative research, public health, social science, study design, question development, data collection, public health practitioners, qualitative research, [PAD] [PAD], [PAD], [PAD] [PAD], [PAD]"
Paper_00378,Effect of the damping function in dispersion corrected density functional theory,"['Stefan Grimme', 'Stephan Ehrlich', 'Lars Goerigk']",2011,Journal of Computational Chemistry,Journal,,1456-1465,32,7,10.1002/jcc.21759,"It is shown by an extensive benchmark on molecular energy data that the mathematical form of the damping function in DFT-D methods has only a minor impact on the quality of the results. For 12 different functionals, a standard ""zero-damping"" formula and rational damping to finite values for small interatomic distances according to Becke and Johnson (BJ-damping) has been tested. The same (DFT-D3) scheme for the computation of the dispersion coefficients is used. The BJ-damping requires one fit parameter more for each functional (three instead of two) but has the advantage of avoiding repulsive interatomic forces at shorter distances. With BJ-damping better results for nonbonded distances and more clear effects of intramolecular dispersion in four representative molecular structures are found. For the noncovalently-bonded structures in the S22 set, both schemes lead to very similar intermolecular distances. For noncovalent interaction energies BJ-damping performs slightly better but both variants can be recommended in general. The exception to this is Hartree-Fock that can be recommended only in the BJ-variant and which is then close to the accuracy of corrected GGAs for non-covalent interactions. According to the thermodynamic benchmarks BJ-damping is more accurate especially for medium-range electron correlation problems and only small and practically insignificant double-counting effects are observed. It seems to provide a physically correct short-range behavior of correlation/dispersion even with unmodified standard functionals. In any case, the differences between the two methods are much smaller than the overall dispersion effect and often also smaller than the influence of the underlying density functional.","['Dispersion (optics)', 'Intermolecular force', 'Intramolecular force', 'London dispersion force', 'Function (biology)', 'Benchmark (surveying)', 'Density functional theory', 'Range (aeronautics)', 'Statistical physics', 'Computation', 'Physics', 'van der Waals force', 'Quantum mechanics', 'Mathematics', 'Materials science', 'Molecule', 'Algorithm', 'Geodesy', 'Evolutionary biology', 'Composite material', 'Biology', 'Geography']","molecular energy data, damping function, rational damping, dispersion coefficients, repulsive interatomic forces, nonbonded distances, intramolecular dispersion, noncovalent"
Paper_00379,Multilineage Potential of Adult Human Mesenchymal Stem Cells,"['Mark F. Pittenger', 'Alastair M. Mackay', 'Stephen C. Beck', 'Rama K. Jaiswal', 'R. Gordon Douglas', 'Joseph D. Mosca', 'Mark A. Moorman', 'Donald W. Simonetti', 'Stewart Craig', 'Daniel R. Marshak']",1999,Science,Journal,,143-147,284,5411,10.1126/science.284.5411.143,"Human mesenchymal stem cells are thought to be multipotent cells, which are present in adult marrow, that can replicate as undifferentiated cells and that have the potential to differentiate to lineages of mesenchymal tissues, including bone, cartilage, fat, tendon, muscle, and marrow stroma. Cells that have the characteristics of human mesenchymal stem cells were isolated from marrow aspirates of volunteer donors. These cells displayed a stable phenotype and remained as a monolayer in vitro. These adult stem cells could be induced to differentiate exclusively into the adipocytic, chondrocytic, or osteocytic lineages. Individual stem cells were identified that, when expanded to colonies, retained their multilineage potential.","['Mesenchymal stem cell', 'Stem cell transplantation for articular cartilage repair', 'Stem cell', 'Adult stem cell', 'Clinical uses of mesenchymal stem cells', 'Amniotic stem cells', 'Biology', 'Cell biology', 'Bone marrow', 'Multipotent Stem Cell', 'Endothelial stem cell', 'In vitro', 'Immunology', 'Progenitor cell', 'Genetics']","human mesenchymal stem cells, multipotent cells, adult marrow, undifferentiated cells, ##mal tissues, cartila, tend, marrow stroma, human, ##mal stem cells, marrow aspirates, volunteer donors, ##ro, oste, ##ytic, ##line, [PAD] [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD]"
Paper_00380,Quantum computation and quantum information,['Jim Law'],2001,ACM SIGSOFT Software Engineering Notes,Journal,,91-91,26,4,10.1145/505482.505499,No abstract available.,"['Quantum computer', 'Computer science', 'Quantum', 'Quantum information', 'Computation', 'Theoretical computer science', 'Programming language', 'Physics', 'Quantum mechanics']",
Paper_00381,WGCNA: an R package for weighted correlation network analysis,"['Peter Langfelder', 'Steve Horvath']",2008,BMC Bioinformatics,Journal,,,9,1,10.1186/1471-2105-9-559,"Correlation networks are increasingly being used in bioinformatics applications. For example, weighted gene co-expression network analysis is a systems biology method for describing the correlation patterns among genes across microarray samples. Weighted correlation network analysis (WGCNA) can be used for finding clusters (modules) of highly correlated genes, for summarizing such clusters using the module eigengene or an intramodular hub gene, for relating modules to one another and to external sample traits (using eigengene network methodology), and for calculating module membership measures. Correlation networks facilitate network based gene screening methods that can be used to identify candidate biomarkers or therapeutic targets. These methods have been successfully applied in various biological contexts, e.g. cancer, mouse genetics, yeast genetics, and analysis of brain imaging data. While parts of the correlation network methodology have been described in separate publications, there is a need to provide a user-friendly, comprehensive, and consistent software implementation and an accompanying tutorial.The WGCNA R software package is a comprehensive collection of R functions for performing various aspects of weighted correlation network analysis. The package includes functions for network construction, module detection, gene selection, calculations of topological properties, data simulation, visualization, and interfacing with external software. Along with the R package we also present R software tutorials. While the methods development was motivated by gene expression data, the underlying data mining approach can be applied to a variety of different settings.The WGCNA package provides R functions for weighted correlation network analysis, e.g. co-expression network analysis of gene expression data. The R package along with its source code and additional material are freely available at http://www.genetics.ucla.edu/labs/horvath/CoexpressionNetwork/Rpackages/WGCNA.","['Gene co-expression network', 'R package', 'Computer science', 'Software', 'Data mining', 'Correlation', 'Network analysis', 'Computational biology', 'DNA microarray', 'Gene regulatory network', 'Interfacing', 'Biological network', 'Biology', 'Gene', 'Gene expression', 'Genetics', 'Gene ontology', 'Mathematics', 'Geometry', 'Computational science', 'Physics', 'Quantum mechanics', 'Computer hardware', 'Programming language']","correlation networks, ##formatics, systems biology, correlation, weighted correlation network analysis, wgcna, highly correlated genes, ##lar hub, eigengene network methodology, module membership measures, correlation networks, gene screening, therapeutic, cancer, mouse genetics, yeast genetics, brain imaging, correlation, wgcna, weighted correlation network analysis, network construction, module detection, gene selection, topological properties, data simulation, visual, gene, ##na, weighted correlation network analysis, gene, ##ion"
Paper_00382,"The Montreal Cognitive Assessment, MoCA: A Brief Screening Tool For Mild Cognitive Impairment","['Ziad Nasreddine', 'Natalie A. Phillips', 'Valérie Bédirian', 'Simon Charbonneau', 'Victor Whitehead', 'Isabelle Collin', 'Jeffrey L. Cummings', 'Howard Chertkow']",2005,Journal of the American Geriatrics Society,Journal,,695-699,53,4,10.1111/j.1532-5415.2005.53221.x,"To develop a 10-minute cognitive screening tool (Montreal Cognitive Assessment, MoCA) to assist first-line physicians in detection of mild cognitive impairment (MCI), a clinical state that often progresses to dementia. Validation study. A community clinic and an academic center. Ninety-four patients meeting MCI clinical criteria supported by psychometric measures, 93 patients with mild Alzheimer's disease (AD) (Mini-Mental State Examination (MMSE) score > or =17), and 90 healthy elderly controls (NC). The MoCA and MMSE were administered to all participants, and sensitivity and specificity of both measures were assessed for detection of MCI and mild AD. Using a cutoff score 26, the MMSE had a sensitivity of 18% to detect MCI, whereas the MoCA detected 90% of MCI subjects. In the mild AD group, the MMSE had a sensitivity of 78%, whereas the MoCA detected 100%. Specificity was excellent for both MMSE and MoCA (100% and 87%, respectively). MCI as an entity is evolving and somewhat controversial. The MoCA is a brief cognitive screening tool with high sensitivity and specificity for detecting MCI as currently conceptualized in patients performing in the normal range on the MMSE.","['Montreal Cognitive Assessment', 'Medicine', 'Dementia', 'Cognitive impairment', 'Cognition', 'Mini–Mental State Examination', 'Gerontology', 'Physical therapy', 'Internal medicine', 'Disease', 'Psychiatry']","cognitive screening, montreal cognitive assessment, moca, mild cognitive impairment, community clinic, psycho, mild alzheimer, healthy elderly controls, cutoff score, ##ca, mci, moca, brief cognitive screening"
Paper_00383,<b>Floral dip: a simplified method for</b><i><b>Agrobacterium</b></i><b>‐mediated transformation of</b><i><b>Arabidopsis thaliana</b></i>,"['Steven J. Clough', 'Andrew F. Bent']",1998,The Plant Journal,Journal,,735-743,16,6,10.1046/j.1365-313x.1998.00343.x,"Summary The Agrobacterium vacuum infiltration method has made it possible to transform Arabidopsis thaliana without plant tissue culture or regeneration. In the present study, this method was evaluated and a substantially modified transformation method was developed. The labor‐intensive vacuum infiltration process was eliminated in favor of simple dipping of developing floral tissues into a solution containing Agrobacterium tumefaciens , 5% sucrose and 500 microliters per litre of surfactant Silwet L‐77. Sucrose and surfactant were critical to the success of the floral dip method. Plants inoculated when numerous immature floral buds and few siliques were present produced transformed progeny at the highest rate. Plant tissue culture media, the hormone benzylamino purine and pH adjustment were unnecessary, and Agrobacterium could be applied to plants at a range of cell densities. Repeated application of Agrobacterium improved transformation rates and overall yield of transformants approximately twofold. Covering plants for 1 day to retain humidity after inoculation also raised transformation rates twofold. Multiple ecotypes were transformable by this method. The modified method should facilitate high‐throughput transformation of Arabidopsis for efforts such as T‐DNA gene tagging, positional cloning, or attempts at targeted gene replacement.","['Agrobacterium', 'Silique', 'Agrobacterium tumefaciens', 'Transformation (genetics)', 'Biology', 'Arabidopsis thaliana', 'Arabidopsis', 'Mutant', 'Botany', 'Horticulture', 'Gene', 'Genetics']","agrobacter, arabidopsis, plant tissue culture, floral tissues, floral dip method, plant tissue culture media, ph adjustment, arab, positional cloning"
Paper_00384,"Atoms, molecules, solids, and surfaces: Applications of the generalized gradient approximation for exchange and correlation","['John P. Perdew', 'J. A. Chevary', 'S. H. Vosko', 'Koblar Alan Jackson', 'Mark R. Pederson', 'David J. Singh', 'Carlos Fiolhais']",1992,"Physical review. B, Condensed matter",Journal,,6671-6687,46,11,10.1103/physrevb.46.6671,"Generalized gradient approximations (GGA's) seek to improve upon the accuracy of the local-spin-density (LSD) approximation in electronic-structure calculations. Perdew and Wang have developed a GGA based on real-space cutoff of the spurious long-range components of the second-order gradient expansion for the exchange-correlation hole. We have found that this density functional performs well in numerical tests for a variety of systems: (1) Total energies of 30 atoms are highly accurate. (2) Ionization energies and electron affinities are improved in a statistical sense, although significant interconfigurational and interterm errors remain. (3) Accurate atomization energies are found for seven hydrocarbon molecules, with a rms error per bond of 0.1 eV, compared with 0.7 eV for the LSD approximation and 2.4 eV for the Hartree-Fock approximation. (4) For atoms and molecules, there is a cancellation of error between density functionals for exchange and correlation, which is most striking whenever the Hartree-Fock result is furthest from experiment. (5) The surprising LSD underestimation of the lattice constants of Li and Na by 3--4 % is corrected, and the magnetic ground state of solid Fe is restored. (6) The work function, surface energy (neglecting the long-range contribution), and curvature energy of a metallic surface are all slightly reduced in comparison with LSD. Taking account of the positive long-range contribution, we find surface and curvature energies in good agreement with experimental or exact values. Finally, a way is found to visualize and understand the nonlocality of exchange and correlation, its origins, and its physical effects.","['Physics', 'Local-density approximation', 'Curvature', 'Spurious relationship', 'Atomic physics', 'Electronic correlation', 'Range (aeronautics)', 'Density functional theory', 'Ionization', 'Molecular physics', 'Quantum mechanics', 'Molecule', 'Materials science', 'Ion', 'Geometry', 'Mathematics', 'Statistics', 'Composite material']","generalized gradient approximations, density functional, ionization energies, electron affinities, ##term, atomization energies, rms, ##sd, density, correlation, lattice constants, magnetic ground state, work, surface energy, curvature energy, metallic surface, curvature energies"
Paper_00385,The Reliability of Molecular Weight Determinations by Dodecyl Sulfate-Polyacrylamide Gel Electrophoresis,"['K. Weber', 'Mary Osborn']",1969,Journal of Biological Chemistry,Journal,,4406-4412,244,16,10.1016/s0021-9258(18)94333-4,"Forty proteins with polypeptide chains of well characterized molecular weights have been studied by polyacrylamide gel electrophoresis in the presence of sodium dodecyl sulfate following the procedure of Shapiro, Vinuela, and Maizel (Biochem. Biophys. Res. Commun., 28, 815 (1967)). When the electrophoretic mobilities were plotted against the logarithm of the known polypeptide chain molecular weights, a smooth curve was obtained. The results show that the method can be used with great confidence to determine the molecular weights of polypeptide chains for a wide variety of proteins.","['Polyacrylamide gel electrophoresis', 'Sodium dodecyl sulfate', 'Gel electrophoresis of proteins', 'Chemistry', 'Polyacrylamide', 'Gel electrophoresis', 'Chromatography', 'Reliability (semiconductor)', 'Electrophoresis', 'Biochemistry', 'Enzyme', 'Polymer chemistry', 'Power (physics)', 'Physics', 'Quantum mechanics']","polype, ##ide chains, polyacrylamide gel electrophoresis, sodium, electrophoretic mobilities, ##th, ##ide, [PAD] [PAD], [PAD], [PAD], [PAD] [PAD] [PAD], [PAD] [PAD], [PAD]"
Paper_00387,AutoDock4 and AutoDockTools4: Automated docking with selective receptor flexibility,"['Garrett M. Morris', 'Ruth Huey', 'William Lindstrom', 'Michel F. Sanner', 'Richard K. Belew', 'David S. Goodsell', 'Arthur J. Olson']",2009,Journal of Computational Chemistry,Journal,,2785-2791,30,16,10.1002/jcc.21256,"Abstract We describe the testing and release of AutoDock4 and the accompanying graphical user interface AutoDockTools. AutoDock4 incorporates limited flexibility in the receptor. Several tests are reported here, including a redocking experiment with 188 diverse ligand‐protein complexes and a cross‐docking experiment using flexible sidechains in 87 HIV protease complexes. We also report its utility in analysis of covalently bound ligands, using both a grid‐based docking method and a modification of the flexible sidechain technique. © 2009 Wiley Periodicals, Inc. J Comput Chem, 2009","['Docking (animal)', 'Searching the conformational space for docking', 'Chemistry', 'Protein–ligand docking', 'Computer science', 'Grid', 'Flexibility (engineering)', 'Covalent bond', 'Graphical user interface', 'Combinatorial chemistry', 'Computational biology', 'Virtual screening', 'Molecular dynamics', 'Binding site', 'Computational chemistry', 'Biochemistry', 'Mathematics', 'Biology', 'Organic chemistry', 'Programming language', 'Medicine', 'Statistics', 'Nursing', 'Geometry']","autodock, graphical user interface, autodock, ##ocking, cross ‐ docking, flexible sidechains, hiv protease complexes, covalently bound, grid ‐, flexible sidechain technique, wiley, [PAD] [PAD], [PAD] [PAD], [PAD], [PAD]"
Paper_00389,A Survey on Transfer Learning,"['Sinno Jialin Pan', 'Qiang Yang']",2009,IEEE Transactions on Knowledge and Data Engineering,Journal,,1345-1359,22,10,10.1109/tkde.2009.191,"A major assumption in many machine learning and data mining algorithms is that the training and future data must be in the same feature space and have the same distribution. However, in many real-world applications, this assumption may not hold. For example, we sometimes have a classification task in one domain of interest, but we only have sufficient training data in another domain of interest, where the latter data may be in a different feature space or follow a different data distribution. In such cases, knowledge transfer, if done successfully, would greatly improve the performance of learning by avoiding much expensive data-labeling efforts. In recent years, transfer learning has emerged as a new learning framework to address this problem. This survey focuses on categorizing and reviewing the current progress on transfer learning for classification, regression, and clustering problems. In this survey, we discuss the relationship between transfer learning and other related machine learning techniques such as domain adaptation, multitask learning and sample selection bias, as well as covariate shift. We also explore some potential future issues in transfer learning research.","['Transfer of learning', 'Computer science', 'Inductive transfer', 'Machine learning', 'Artificial intelligence', 'Multi-task learning', 'Cluster analysis', 'Semi-supervised learning', 'Feature (linguistics)', 'Domain (mathematical analysis)', 'Instance-based learning', 'Online machine learning', 'Feature vector', 'Task (project management)', 'Robot learning', 'Mathematical analysis', 'Linguistics', 'Philosophy', 'Mathematics', 'Management', 'Robot', 'Economics', 'Mobile robot']","machine learning, data mining algorithms, classification task, training, knowledge transfer, transfer learning, transfer learning, classification, regression, clustering, transfer learning, machine learning, domain adaptation, multitask learning, sample selection bias, covariate shift, transfer learning"
Paper_00390,A smooth particle mesh Ewald method,"['Ulrich Essmann', 'L. Perera', 'Max L. Berkowitz', 'Tom Darden', 'Hsing Lee', 'Lee G. Pedersen']",1995,The Journal of Chemical Physics,Journal,,8577-8593,103,19,10.1063/1.470117,"The previously developed particle mesh Ewald method is reformulated in terms of efficient B-spline interpolation of the structure factors. This reformulation allows a natural extension of the method to potentials of the form 1/rp with p≥1. Furthermore, efficient calculation of the virial tensor follows. Use of B-splines in place of Lagrange interpolation leads to analytic gradients as well as a significant improvement in the accuracy. We demonstrate that arbitrary accuracy can be achieved, independent of system size N, at a cost that scales as N log(N). For biomolecular systems with many thousands of atoms this method permits the use of Ewald summation at a computational cost comparable to that of a simple truncation method of 10 Å or less.","['Ewald summation', 'Interpolation (computer graphics)', 'Simple (philosophy)', 'Spline interpolation', 'Mathematics', 'Applied mathematics', 'Spline (mechanical)', 'Algorithm', 'Physics', 'Classical mechanics', 'Molecular dynamics', 'Motion (physics)', 'Philosophy', 'Statistics', 'Epistemology', 'Bilinear interpolation', 'Thermodynamics', 'Quantum mechanics']","particle mesh ewald method, structure factors, virial tensor, lagrange interpolation, analytic gradients, biomolecular systems, ewald summation, truncation method"
Paper_00393,The meaning and use of the area under a receiver operating characteristic (ROC) curve.,"['J A Hanley', 'Barbara J. McNeil']",1982,Radiology,Journal,,29-36,143,1,10.1148/radiology.143.1.7063747,"A representation and interpretation of the area under a receiver operating characteristic (ROC) curve obtained by the ""rating"" method, or by mathematical predictions based on patient characteristics, is presented. It is shown that in such a setting the area represents the probability that a randomly chosen diseased subject is (correctly) rated or ranked with greater suspicion than a randomly chosen non-diseased subject. Moreover, this probability of a correct ranking is the same quantity that is estimated by the already well-studied nonparametric Wilcoxon statistic. These two relationships are exploited to (a) provide rapid closed-form expressions for the approximate magnitude of the sampling variability, i.e., standard error that one uses to accompany the area under a smoothed ROC curve, (b) guide in determining the size of the sample required to provide a sufficiently reliable estimate of this area, and (c) determine how large sample sizes should be to ensure that one can statistically detect differences in the accuracy of diagnostic techniques.","['Receiver operating characteristic', 'Statistics', 'Nonparametric statistics', 'Medicine', 'Ranking (information retrieval)', 'Sample size determination', 'Statistic', 'Wilcoxon signed-rank test', 'Sampling (signal processing)', 'Sample (material)', 'Mathematics', 'Artificial intelligence', 'Computer science', 'Chemistry', 'Filter (signal processing)', 'Chromatography', 'Computer vision', 'Mann–Whitney U test']","receiver operating characteristic, mathematical predictions, patient characteristics, nonparametric wilcoxon statistic, sampling variability"
Paper_00395,ggplot2: Elegant Graphics for Data Analysis,['Hadley Wickham'],2009,['Journal of the Royal Statistical Society Series A: Statistics in Society'],Unknown,,245-246,174,1,10.1111/j.1467-985x.2010.00676_9.x,"This book describes ggplot2, a new data visualization package for R that uses the insights from Leland Wilkisons Grammar of Graphics to create a powerful and flexible system for creating data graphics. With ggplot2, its easy to: produce handsome, publication-quality plots, with automatic legends created from the plot specification superpose multiple layers (points, lines, maps, tiles, box plots to name a few) from different data sources, with automatically adjusted common scales add customisable smoothers that use the powerful modelling capabilities of R, such as loess, linear models, generalised additive models and robust regression save any ggplot2 plot (or part thereof) for later modification or reuse create custom themes that capture in-house or journal style requirements, and that can easily be applied to multiple plots approach your graph from a visual perspective, thinking about how each component of the data is represented on the final plot. This book will be useful to everyone who has struggled with displaying their data in an informative and attractive way. You will need some basic knowledge of R (i.e. you should be able to get your data into R), but ggplot2 is a mini-language specifically tailored for producing graphics, and youll learn everything you need in the book. After reading this book youll be able to produce graphics customized precisely for your problems,and youll find it easy to get graphics out of your head and on to the screen or page.","['Graphics', 'Plot (graphics)', 'Computer science', 'Computer graphics (images)', 'Reuse', 'Graph', 'Data visualization', 'Statistical graphics', 'Visualization', 'Information retrieval', 'Data mining', 'Engineering', 'Theoretical computer science', 'Statistics', 'Mathematics', 'Waste management']","ggplot2, data visualization package, graphics, data graphics, ggplot2, automatic legends, box plots, custom, ##ble smoothers, loess, linear models, generalised additive models, robust regression, ggplot2"
Paper_00396,Normative data on a battery of neuropsychological tests in the Han Chinese population,"['Qiang Wang', 'Jinhua Sun', 'Xiaohong Ma', 'Yingcheng Wang', 'Jing Yao', 'Wei Deng', 'Xiehe Liu', 'David Collier', 'Tao Li']",2010,Journal of Neuropsychology,Journal,,126-142,5,1,10.1348/174866410x516803,"The purpose of this study was to determine the brain regions associated with anosognosia in Alzheimer's disease (AD). Anosognosia for memory disturbance was assessed in 29 probable AD patients, based on the discrepancy between questionnaire scores of the patients and their caregivers. In I-123-IMP single photon emission computed tomography (SPECT), a significant association was found between anosognosia and decreased perfusion in the orbitofrontal cortex, using regression analysis. This result is consistent with the previous studies that have reported an association between frontal dysfunction and anosognosia, and further suggests that the orbitofrontal cortex specifically associates with anosognosia in AD within the frontal cortex.","['Anosognosia', 'Orbitofrontal cortex', 'Psychology', 'Neuropsychology', 'Association (psychology)', 'Frontal cortex', 'Audiology', 'Population', 'Clinical psychology', 'Psychiatry', 'Neuroscience', 'Cognition', 'Medicine', 'Prefrontal cortex', 'Environmental health', 'Psychotherapist']","anosognosia, alzheimer, anosognosia, memory disturbance, probable, an, orbitofrontal cortex, regression analysis, frontal dysfunction, orbitofrontal cortex, frontal cortex, [PAD] [PAD], [PAD] [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD], [PAD], [PAD] [PAD], [PAD], [PAD] [PAD], [PAD] [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD], [PAD], [PAD]"
Paper_00397,Detecting the number of clusters of individuals using the software <scp>structure</scp>: a simulation study,"['Guillaume Evanno', 'Sébastien Regnaut', 'Jérôme Goudet']",2005,Molecular Ecology,Journal,,2611-2620,14,8,10.1111/j.1365-294x.2005.02553.x,"Abstract The identification of genetically homogeneous groups of individuals is a long standing issue in population genetics. A recent Bayesian algorithm implemented in the software structure allows the identification of such groups. However, the ability of this algorithm to detect the true number of clusters ( K ) in a sample of individuals when patterns of dispersal among populations are not homogeneous has not been tested. The goal of this study is to carry out such tests, using various dispersal scenarios from data generated with an individual‐based model. We found that in most cases the estimated ‘log probability of data’ does not provide a correct estimation of the number of clusters, K . However, using an ad hoc statistic Δ K based on the rate of change in the log probability of data between successive K values, we found that structure accurately detects the uppermost hierarchical level of structure for the scenarios we tested. As might be expected, the results are sensitive to the type of genetic marker used (AFLP vs. microsatellite), the number of loci scored, the number of populations sampled, and the number of individuals typed in each sample.","['Biology', 'Statistic', 'Bayesian probability', 'Homogeneous', 'Biological dispersal', 'Statistics', 'Identification (biology)', 'Microsatellite', 'Software', 'Population', 'Sample (material)', 'Sample size determination', 'Evolutionary biology', 'Genetics', 'Computer science', 'Mathematics', 'Ecology', 'Demography', 'Gene', 'Allele', 'Chemistry', 'Chromatography', 'Combinatorics', 'Sociology', 'Programming language']","genetically homogeneous groups, population genetics, bayesian algorithm, software structure, dispersal scenarios, ad hoc statistic, log probability, genetic marker, microsatellite, [PAD]"
Paper_00399,A theory for multiresolution signal decomposition: the wavelet representation,['Stéphane Mallat'],1989,IEEE Transactions on Pattern Analysis and Machine Intelligence,Journal,,674-693,11,7,10.1109/34.192463,"Multiresolution representations are effective for analyzing the information content of images. The properties of the operator which approximates a signal at a given resolution were studied. It is shown that the difference of information between the approximation of a signal at the resolutions 2/sup j+1/ and 2/sup j/ (where j is an integer) can be extracted by decomposing this signal on a wavelet orthonormal basis of L/sup 2/(R/sup n/), the vector space of measurable, square-integrable n-dimensional functions. In L/sup 2/(R), a wavelet orthonormal basis is a family of functions which is built by dilating and translating a unique function psi (x). This decomposition defines an orthogonal multiresolution representation called a wavelet representation. It is computed with a pyramidal algorithm based on convolutions with quadrature mirror filters. Wavelet representation lies between the spatial and Fourier domains. For images, the wavelet representation differentiates several spatial orientations. The application of this representation to data compression in image coding, texture discrimination and fractal analysis is discussed.< <ETX xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">&gt;</ETX>","['Orthonormal basis', 'Wavelet', 'Wavelet transform', 'Mathematics', 'Multiresolution analysis', 'Pattern recognition (psychology)', 'Artificial intelligence', 'Representation (politics)', 'Basis function', 'Square-integrable function', 'Algorithm', 'Discrete wavelet transform', 'Computer science', 'Mathematical analysis', 'Physics', 'Politics', 'Political science', 'Law', 'Quantum mechanics']","multiresolution representations, information content, ##thonormal basis, wavelet orthonormal basis, orthogonal multiresolution representation, wavelet representation, pyramidal algorithm, con, quadrature mirror filters, wavelet representation, spatial orientations, data compression, image coding, texture discrimination, fractal analysis"
Paper_00401,The Evolution of Cooperation,"['Robert Axelrod', 'W D Hamilton']",1981,Science,Journal,,1390-1396,211,4489,10.1126/science.7466396,"Cooperation in organisms, whether bacteria or primates, has been a difficulty for evolutionary theory since Darwin. On the assumption that interactions between pairs of individuals occur on a probabilistic basis, a model is developed based on the concept of an evolutionarily stable strategy in the context of the Prisoner's Dilemma game. Deductions from the model, and the results of a computer tournament show how cooperation based on reciprocity can get started in an asocial world, can thrive while interacting with a wide range of other strategies, and can resist invasion once fully established. Potential applications include specific aspects of territoriality, mating, and disease.","['Reciprocity (cultural anthropology)', 'Dilemma', 'Territoriality', ""Prisoner's dilemma"", 'Context (archaeology)', 'Probabilistic logic', 'Game theory', 'Computer science', 'Biology', 'Evolutionary biology', 'Mathematical economics', 'Artificial intelligence', 'Social psychology', 'Psychology', 'Ecology', 'Epistemology', 'Economics', 'Philosophy', 'Paleontology']","cooperation, evolutionary, ##arily, prisoner ' s dilemma game, computer tournament, rec, ##rocity, asocial world, territoriality, mating"
Paper_00402,MODELTEST: testing the model of DNA substitution.,"['David Posada', 'Keith A. Crandall']",1998,Bioinformatics,Journal,,817-818,14,9,10.1093/bioinformatics/14.9.817,"The program MODELTEST uses log likelihood scores to establish the model of DNA evolution that best fits the data.The MODELTEST package, including the source code and some documentation is available at http://bioag.byu. edu/zoology/crandall_lab/modeltest.html.","['Documentation', 'Substitution (logic)', 'Source code', 'Computer science', 'Code (set theory)', 'R package', 'Programming language', 'Computational biology', 'Biology', 'Set (abstract data type)']","program modeltest, log likelihood scores, dna evolution, [PAD] [PAD] [PAD]"
Paper_00403,Multiple View Geometry in Computer Vision,"['Richard Hartley', 'Andrew Zisserman']",2004,Unknown,Unknown,,,,,10.1017/cbo9780511811685,"A basic problem in computer vision is to understand the structure of a real world scene given several images of it. Techniques for solving this problem are taken from projective geometry and photogrammetry. Here, the authors cover the geometric principles and their algebraic representation in terms of camera projection matrices, the fundamental matrix and the trifocal tensor. The theory and methods of computation of these entities are discussed with real examples, as is their use in the reconstruction of scenes from multiple images. The new edition features an extended introduction covering the key ideas in the book (which itself has been updated with additional examples and appendices) and significant new results which have appeared since the first edition. Comprehensive background material is provided, so readers familiar with linear algebra and basic numerical methods can understand the projective geometry and estimation algorithms presented, and implement the algorithms directly from the book.","['Fundamental matrix (linear differential equation)', 'Photogrammetry', 'Projective geometry', 'Computer science', 'Epipolar geometry', 'Projection (relational algebra)', 'Orthographic projection', 'Computation', 'Representation (politics)', 'Tensor (intrinsic definition)', 'Algebra over a field', 'Key (lock)', 'Computer vision', 'Artificial intelligence', 'Geometry', 'Algebraic geometry', 'Mathematics', 'Algorithm', 'Image (mathematics)', 'Pure mathematics', 'Mathematical analysis', 'Computer security', 'Politics', 'Political science', 'Law']","computer vision, real world scene, projective geometry, photogrammetry, geometric principles, algebraic representation, camera projection matrices, fundamental matrix, trifocal tensor, linear algebra, projective geometry, estimation algorithms, [PAD], [PAD], [PAD], [PAD], [PAD] [PAD], [PAD], [PAD] [PAD], [PAD], [PAD] [PAD] [PAD] [PAD], [PAD], [PAD] [PAD] [PAD], [PAD] [PAD] [PAD], [PAD] [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"
Paper_00404,"Special Care Units and Traditional Care in Dementia: Relationship with Behavior, Cognition, Functional Status and Quality of Life - A Review","['Jeroen S. Kok', 'Ina J. Berg', 'Erik Scherder']",2013,Dementia and Geriatric Cognitive Disorders Extra,Journal,,360-375,3,1,10.1159/000353441,"Behavioral and psychological symptoms associated with dementia are common in nursing home residents. Quality indicators (QI) assessing quality of care for these residents are minimally risk adjusted and can provide inaccurate information regarding the quality of care provided by the facility.Evaluate the performance of a new QI for the incidence of worsening behaviors in nursing home residents with behavioral and psychological symptoms association with dementia.Retrospective cohort study.A total of 381 Minnesota nursing homes with 26,165 residents.Minimum Data Set records for the first 2 calendar quarters of 2008.We calculated incidence of worsening behaviors QI by comparing items from the ""behavior"" section of the Minimum Data Set records from 2 consecutive quarters and reported the incidence rates by both the residents' level of cognitive impairment and the presence or absence of special care unit for dementia (SCU).The incidence rates of the worsening behavior QI in SCU ranged from 14% in residents with very severe cognitive impairment (a cognitive performance score = 6) to 30% in those with moderate cognitive impairment (a cognitive performance score = 3). The incidence QI rates among residents residing in conventional unit ranged from 15% among those with very severe cognitive impairment to 20% among those with moderate cognitive impairment. These differences in QI rates between the 2 units were statistically significant with a P value = .001. After risk adjustment for level of cognitive impairment, number of facilities with SCUs that flagged for problem behaviors dropped from 18.4% to 12.4% and the number of conventional units in the low-risk category from 16.8% to 4.7%.Resident cognitive function and the facility utility of SCU are associated with worsening behavior QI and should be adjusted for in any nursing home quality reporting measure.","['Dementia', 'Residence', 'Gerontology', 'Nursing homes', 'Medicine', 'Quality of life (healthcare)', 'Cognition', 'Activities of daily living', 'Health and Retirement Study', 'Cohort', 'Longitudinal study', 'Cohort study', 'Psychiatry', 'Nursing', 'Demography', 'Disease', 'Pathology', 'Sociology', 'Internal medicine']","dementia, nursing home residents, quality indicators, nursing home residents, minnesota, cognitive performance score, moderate cognitive impairment, cognitive performance score, incidence qi, moderate, resident cognitive function, facility, nursing home quality reporting"
Paper_00407,Methods of Enzymatic Analysis,['Hans Ulrich Bergmeyer'],1975,Journal of AOAC INTERNATIONAL,Journal,,1085-1085,58,5,10.1093/jaoac/58.5.1085,"Journal Article Methods of Enzymatic Analysis Get access Methods of Enzymatic Analysis. Vols. 1, 2, 3, and 4. H. U. Bergmeyer(ed.). Verlag Chemie Weinheim, Academic Press Inc., New York and London, 1974. Vol. 1, 565 pp. Vol. 2, 555 pp. Vol. 3, 497 pp. Vol. 4, 677 pp. Price $56.00 per volume. Journal of Association of Official Analytical Chemists, Volume 58, Issue 5, 1 September 1975, Page 1085, https://doi.org/10.1093/jaoac/58.5.1085 Published: 29 January 2020","['Library science', 'Volume (thermodynamics)', 'Computer science', 'Physics', 'Thermodynamics']","enzymatic analysis, enzymatic analysis, academic, analytical chemists"
Paper_00408,"<i>VESTA 3</i>for three-dimensional visualization of crystal, volumetric and morphology data","['Koichi Momma', 'Fujio Izumi']",2011,Journal of Applied Crystallography,Journal,,1272-1276,44,6,10.1107/s0021889811038970,"VESTA is a three-dimensional visualization system for crystallographic studies and electronic state calculations. It has been upgraded to the latest version, VESTA 3, which implements many new features.","['Undo', 'Visualization', 'Voronoi diagram', 'Computer science', 'Computer graphics (images)', 'Rendering (computer graphics)', 'Subdivision', 'Interactive visualization', 'Computational science', 'Data visualization', 'Crystallography', 'Geometry', 'Artificial intelligence', 'Chemistry', 'Mathematics', 'Geography', 'Archaeology', 'Operating system']","vesta, visual, crystallographic studies, electronic state calculations, vesta, [PAD] [PAD] [PAD]"
Paper_00409,Organometal Halide Perovskites as Visible-Light Sensitizers for Photovoltaic Cells,"['Akihiro Kojima', 'Kenjiro Teshima', 'Yasuo Shirai', 'Tsutomu Miyasaka']",2009,Journal of the American Chemical Society,Journal,,6050-6051,131,17,10.1021/ja809598r,"Two organolead halide perovskite nanocrystals, CH(3)NH(3)PbBr(3) and CH(3)NH(3)PbI(3), were found to efficiently sensitize TiO(2) for visible-light conversion in photoelectrochemical cells. When self-assembled on mesoporous TiO(2) films, the nanocrystalline perovskites exhibit strong band-gap absorptions as semiconductors. The CH(3)NH(3)PbI(3)-based photocell with spectral sensitivity of up to 800 nm yielded a solar energy conversion efficiency of 3.8%. The CH(3)NH(3)PbBr(3)-based cell showed a high photovoltage of 0.96 V with an external quantum conversion efficiency of 65%.","['Chemistry', 'Halide', 'Nanocrystalline material', 'Perovskite (structure)', 'Energy conversion efficiency', 'Optoelectronics', 'Semiconductor', 'Nanocrystal', 'Band gap', 'Photovoltaic system', 'Mesoporous material', 'Solar cell', 'Energy transformation', 'Visible spectrum', 'Quantum efficiency', 'Photoelectrochemical cell', 'Photochemistry', 'Nanotechnology', 'Inorganic chemistry', 'Electrode', 'Catalysis', 'Materials science', 'Physical chemistry', 'Crystallography', 'Electrolyte', 'Ecology', 'Biochemistry', 'Biology', 'Thermodynamics', 'Physics']","organolead halide perovskite nanocrystals, ##ele, ##rochemical cells, spectral sensitivity, solar energy conversion efficiency, external quantum conversion efficiency"
Paper_00410,Exploration and Exploitation in Organizational Learning,['James G. March'],1991,Organization Science,Journal,,71-87,2,1,10.1287/orsc.2.1.71,"This paper considers the relation between the exploration of new possibilities and the exploitation of old certainties in organizational learning. It examines some complications in allocating resources between the two, particularly those introduced by the distribution of costs and benefits across time and space, and the effects of ecological interaction. Two general situations involving the development and use of knowledge in organizations are modeled. The first is the case of mutual learning between members of an organization and an organizational code. The second is the case of learning and competitive advantage in competition for primacy. The paper develops an argument that adaptive processes, by refining exploitation more rapidly than exploration, are likely to become effective in the short run but self-destructive in the long run. The possibility that certain common organizational practices ameliorate that tendency is assessed.","['Organizational learning', 'Argument (complex analysis)', 'Competition (biology)', 'Competitive advantage', 'Knowledge management', 'Relation (database)', 'Space (punctuation)', 'Computer science', 'Business', 'Industrial organization', 'Marketing', 'Ecology', 'Biochemistry', 'Chemistry', 'Database', 'Biology', 'Operating system']","organizational learning, ecological interaction, mutual learning, organizational code, learning, competitive advantage, primacy, adaptive processes"
Paper_00414,Statistical mechanics of complex networks,"['Réka Albert', 'Albert‐László Barabási']",2002,Reviews of Modern Physics,Journal,,47-97,74,1,10.1103/revmodphys.74.47,"Complex networks describe a wide range of systems in nature and society, much quoted examples including the cell, a network of chemicals linked by chemical reactions, or the Internet, a network of routers and computers connected by physical links. While traditionally these systems were modeled as random graphs, it is increasingly recognized that the topology and evolution of real networks is governed by robust organizing principles. Here we review the recent advances in the field of complex networks, focusing on the statistical mechanics of network topology and dynamics. After reviewing the empirical data that motivated the recent interest in networks, we discuss the main models and analytical tools, covering random graphs, small-world and scale-free networks, as well as the interplay between topology and the network's robustness against failures and attacks.","['Complex network', 'Statistical mechanics', 'Network topology', 'Random graph', 'Interdependent networks', 'Evolving networks', 'Robustness (evolution)', 'Scale-free network', 'Network formation', 'Topology (electrical circuits)', 'Hierarchical network model', 'Network science', 'Network dynamics', 'Computer science', 'Preferential attachment', 'Theoretical computer science', 'The Internet', 'Distributed computing', 'Physics', 'Statistical physics', 'Computer network', 'Graph', 'World Wide Web', 'Mathematics', 'Biochemistry', 'Chemistry', 'Combinatorics', 'Discrete mathematics', 'Gene']","complex networks, cell, chemical reactions, internet, routers, physical links, random graphs, real networks, robust organizing principles, complex networks, statistical mechanics, network topology, dynamics, random graphs"
Paper_00415,Crop evapotranspiration : guidelines for computing crop water requirements,"['Richard G. Allen', 'L. S. Pereira', 'Dirk Raes', 'Martin Smith']",1998,['Principles of Agronomy for Sustainable Agriculture'],Unknown,,119-137,,1,10.1007/978-3-319-46116-8_10,"(First edition: 1998, this reprint: 2004). This publication presents an updated procedure for calculating reference and crop evapotranspiration from meteorological data and crop coefficients. The procedure, first presented in FAO Irrigation and Drainage Paper No. 24, Crop water requirements, in 1977, allows estimation of the amount of water used by a crop, taking into account the effect of the climate and the crop characteristics. The publication incorporates advances in research and more accurate procedures for determining crop water use as recommended by a panel of high-level experts organised by FAO in May 1990. The first part of the guidelines includes procedures for determining reference crop evapotranspiration according to the FAO Penman-Monteith method. These are followed by updated procedures for estimating the evapotranspiration of different crops for different growth stages and ecological conditions.","['Evapotranspiration', 'Crop coefficient', 'Crop', 'Agricultural engineering', 'Environmental science', 'Irrigation', 'Drainage', 'Water resource management', 'Hydrology (agriculture)', 'Agronomy', 'Geography', 'Engineering', 'Forestry', 'Ecology', 'Geotechnical engineering', 'Biology']","crop evapotranspiration, meteorological data, crop coefficients, fao, crop water requirements, ecological conditions"
Paper_00416,Research Methods in Education,"['Louis Cohen', 'Lawrence Manion', 'Keith Morrison']",2007,Routledge eBooks,Unknown,,,,,10.4324/9780203029053,"This fully updated sixth edition of the international bestseller Research Methods in Education covers the whole range of methods currently employed by educational research at all stages. It is divided into five main parts: the context of educational research; planning educational research; styles of educational research; strategies for data collection and researching; and data analysis. The book also contains references to a comprehensive dedicated website of accompanying materials. The sixth edition includes new material on: complexity theory, ethics, sampling and sensitive educational research experimental research, questionnaire design and administration with practical guidance qualitative and quantitative data analysis, with practical examples internet based research. Research Methods in Education is essential reading for the professional researcher and continues to be the standard text for students and lecturers in educational research. To access the dedicated website of accompanying materials, please visit: www.routledge.com/textbooks/9780415368780.",['Psychology'],"research methods, education, educational research, educational research, planning educational research, educational research, data collection, data analysis, complexity theory, ethics, sensitive educational research experimental research, questionnaire design, administration, quantitative data analysis, internet based research, research methods, education, professional researcher, educational research, [PAD], [PAD], [PAD]"
Paper_00420,The Strengthening the Reporting of Observational Studies in Epidemiology (STROBE) Statement: Guidelines for Reporting Observational Studies,"['Erik von Elm', 'Douglas G. Altman', 'Matthias Egger', 'Stuart J. Pocock', 'Peter C Gøtzsche', 'Jan P. Vandenbroucke']",2007,PLoS Medicine,Journal,,e296-e296,4,10,10.1371/journal.pmed.0040296,"Much biomedical research is observational. The reporting of such research is often inadequate, which hampers the assessment of its strengths and weaknesses and of a study's generalisability. The Strengthening the Reporting of Observational Studies in Epidemiology (STROBE) Initiative developed recommendations on what should be included in an accurate and complete report of an observational study. We defined the scope of the recommendations to cover three main study designs: cohort, case-control, and cross-sectional studies. We convened a 2-day workshop in September 2004, with methodologists, researchers, and journal editors to draft a checklist of items. This list was subsequently revised during several meetings of the coordinating group and in e-mail discussions with the larger group of STROBE contributors, taking into account empirical evidence and methodological considerations. The workshop and the subsequent iterative process of consultation and revision resulted in a checklist of 22 items (the STROBE Statement) that relate to the title, abstract, introduction, methods, results, and discussion sections of articles. 18 items are common to all three study designs and four are specific for cohort, case-control, or cross-sectional studies. A detailed Explanation and Elaboration document is published separately and is freely available on the Web sites of PLoS Medicine, Annals of Internal Medicine, and Epidemiology. We hope that the STROBE Statement will contribute to improving the quality of reporting of observational studies.","['Strengthening the reporting of observational studies in epidemiology', 'Observational study', 'Checklist', 'Medicine', 'Family medicine', 'MEDLINE', 'Scope (computer science)', 'Epidemiology', 'Cohort study', 'Consolidated Standards of Reporting Trials', 'Evidence-based medicine', 'Medical education', 'Systematic review', 'Psychology', 'Alternative medicine', 'Computer science', 'Pathology', 'Political science', 'Law', 'Cognitive psychology', 'Programming language']","biomedical, observational studies, epidemiology, ##be, method, strobe, plos medicine, annals, internal medicine, epidemiology"
Paper_00421,The Positive and Negative Syndrome Scale (PANSS) for Schizophrenia,"['Stanley R. Kay', 'Abraham Fiszbein', 'Lewis A. Opler']",1987,Schizophrenia Bulletin,Journal,,261-276,13,2,10.1093/schbul/13.2.261,"The variable results of positive-negative research with schizophrenics underscore the importance of well-characterized, standardized measurement techniques. We report on the development and initial standardization of the Positive and Negative Syndrome Scale (PANSS) for typological and dimensional assessment. Based on two established psychiatric rating systems, the 30-item PANSS was conceived as an operationalized, drug-sensitive instrument that provides balanced representation of positive and negative symptoms and gauges their relationship to one another and to global psychopathology. It thus constitutes four scales measuring positive and negative syndromes, their differential, and general severity of illness. Study of 101 schizophrenics found the four scales to be normally distributed and supported their reliability and stability. Positive and negative scores were inversely correlated once their common association with general psychopathology was extracted, suggesting that they represent mutually exclusive constructs. Review of five studies involving the PANSS provided evidence of its criterion-related validity with antecedent, genealogical, and concurrent measures, its predictive validity, its drug sensitivity, and its utility for both typological and dimensional assessment.","['Positive and Negative Syndrome Scale', 'Psychopathology', 'Psychology', 'Concurrent validity', 'Schizophrenia (object-oriented programming)', 'Clinical psychology', 'Rating scale', 'Predictive validity', 'Psychiatry', 'Psychometrics', 'Test validity', 'Psychosis', 'Developmental psychology', 'Internal consistency']","schizophrenics, pan, dimensional assessment, psychiatric rating, global psychopathology, schizophrenics, general psychopathology, concurrent measures, predictive validity, drug sensitivity, dimensional assessment"
Paper_00422,Autoregressive Conditional Heteroscedasticity with Estimates of the Variance of United Kingdom Inflation,['Robert F. Engle'],1982,Econometrica,Journal,,987-987,50,4,10.2307/1912773,"Traditional econometric models assume a constant one-period forecast variance. To generalize this implausible assumption, a new class of stochastic processes called autoregressive conditional heteroscedastic (ARCH) processes are introduced in this paper. These are mean zero, serially uncorrelated processes with nonconstant variances conditional on the past, but constant unconditional variances. For such processes, the recent past gives information about the one-period forecast variance. A regression model is then introduced with disturbances following an ARCH process. Maximum likelihood estimators are described and a simple scoring iteration formulated. Ordinary least squares maintains its optimality properties in this set-up, but maximum likelihood is more efficient. The relative efficiency is calculated and can be infinite. To test whether the disturbances follow an ARCH process, the Lagrange multiplier procedure is employed. The test is based simply on the autocorrelation of the squared OLS residuals. This model is used to estimate the means and variances of inflation in the U.K. The ARCH effect is found to be significant and the estimated variances increase substantially during the chaotic seventies.","['Heteroscedasticity', 'Inflation (cosmology)', 'Econometrics', 'Economics', 'Autoregressive model', 'Conditional variance', 'Variance (accounting)', 'Autoregressive conditional heteroskedasticity', 'Statistics', 'Mathematics', 'Volatility (finance)', 'Physics', 'Accounting', 'Theoretical physics']","econometric models, stochastic processes, autoregressive conditional heteroscedastic, nonconstant variances, regression model, maximum likelihood estimators, scoring iteration, ordinary least squares, maximum, lagrange multiplier procedure, ##rel, squared ols residuals"
Paper_00424,Power System Stability and Control,['P. Kundur'],1994,Unknown,Unknown,,,,,10.3403/30436268u,"Part I: Characteristics of Modern Power Systems. Introduction to the Power System Stability Problem. Part II: Synchronous Machine Theory and Modelling. Synchronous Machine Parameters. Synchronous Machine Representation in Stability Studies. AC Transmission. Power System Loads. Excitation in Stability Studies. Prime Mover and Energy Supply Systems. High-Voltage Direct-Current Transmission. Control of Active Power and Reactive Power. Part III: Small Signal Stability. Transient Stability. Voltage Stability. Subsynchronous Machine Representation in Stability Studies. AC Transmission. Power System Loads. Excitation in Stability Studies. Prime Mover and Energy Supply Systems, High-Voltage Direct-Current Transmission. Control of Active Power and Reactive Power. Part III: Small Signal Stability. Transient Stability. Voltage Stability. Subsynchronous Oscillations. Mid-Term and Long-Term Stability. Methods of Improving System Stability.","['Prime mover', 'Electric power system', 'Control theory (sociology)', 'AC power', 'Transient (computer programming)', 'Engineering', 'Stability (learning theory)', 'Transmission system', 'Voltage optimisation', 'Voltage', 'Power (physics)', 'Transmission (telecommunications)', 'Computer science', 'Physics', 'Automotive engineering', 'Electrical engineering', 'Control (management)', 'Quantum mechanics', 'Artificial intelligence', 'Machine learning', 'Operating system']","power system stability problem, synchronous machine theory, synchronous machine parameters, synchronous machine representation, stability studies, ac, power system loads, excitation, stability studies, prime move, energy supply systems, reactive power, small signal stability, transient stability, voltage stability, subsynchronous machine representation, stability, power, stability, energy, reactive power, small signal stability, transient stability, voltage stability, subsynchronous oscillations, [PAD] [PAD], [PAD] [PAD] [PAD], [PAD], [PAD]"
Paper_00425,<i>Ab initio</i>molecular-dynamics simulation of the liquid-metal–amorphous-semiconductor transition in germanium,"['Georg Kresse', 'J. Häfner']",1994,"Physical review. B, Condensed matter",Journal,,14251-14269,49,20,10.1103/physrevb.49.14251,"We present ab initio quantum-mechanical molecular-dynamics simulations of the liquid-metal--amorphous-semiconductor transition in Ge. Our simulations are based on (a) finite-temperature density-functional theory of the one-electron states, (b) exact energy minimization and hence calculation of the exact Hellmann-Feynman forces after each molecular-dynamics step using preconditioned conjugate-gradient techniques, (c) accurate nonlocal pseudopotentials, and (d) Nos\'e dynamics for generating a canonical ensemble. This method gives perfect control of the adiabaticity of the electron-ion ensemble and allows us to perform simulations over more than 30 ps. The computer-generated ensemble describes the structural, dynamic, and electronic properties of liquid and amorphous Ge in very good agreement with experiment. The simulation allows us to study in detail the changes in the structure-property relationship through the metal-semiconductor transition. We report a detailed analysis of the local structural properties and their changes induced by an annealing process. The geometrical, bonding, and spectral properties of defects in the disordered tetrahedral network are investigated and compared with experiment.","['Molecular dynamics', 'Ab initio', 'Materials science', 'Amorphous solid', 'Semiconductor', 'Tetrahedron', 'Density functional theory', 'Physics', 'Condensed matter physics', 'Statistical physics', 'Molecular physics', 'Quantum mechanics', 'Chemistry', 'Crystallography', 'Optoelectronics']","exact energy minimization, nonlocal pseudopotentials, adi, annealing, disordered tetrahedral network"
Paper_00426,Self-interaction correction to density-functional approximations for many-electron systems,"['John P. Perdew', 'Alex Zunger']",1981,"Physical review. B, Condensed matter",Journal,,5048-5079,23,10,10.1103/physrevb.23.5048,"The exact density functional for the ground-state energy is strictly self-interaction-free (i.e., orbitals demonstrably do not self-interact), but many approximations to it, including the local-spin-density (LSD) approximation for exchange and correlation, are not. We present two related methods for the self-interaction correction (SIC) of any density functional for the energy; correction of the self-consistent one-electron potenial follows naturally from the variational principle. Both methods are sanctioned by the Hohenberg-Kohn theorem. Although the first method introduces an orbital-dependent single-particle potential, the second involves a local potential as in the Kohn-Sham scheme. We apply the first method to LSD and show that it properly conserves the number content of the exchange-correlation hole, while substantially improving the description of its shape. We apply this method to a number of physical problems, where the uncorrected LSD approach produces systematic errors. We find systematic improvements, qualitative as well as quantitative, from this simple correction. Benefits of SIC in atomic calculations include (i) improved values for the total energy and for the separate exchange and correlation pieces of it, (ii) accurate binding energies of negative ions, which are wrongly unstable in LSD, (iii) more accurate electron densities, (iv) orbital eigenvalues that closely approximate physical removal energies, including relaxation, and (v) correct longrange behavior of the potential and density. It appears that SIC can also remedy the LSD underestimate of the band gaps in insulators (as shown by numerical calculations for the rare-gas solids and CuCl), and the LSD overestimate of the cohesive energies of transition metals. The LSD spin splitting in atomic Ni and $s\ensuremath{-}d$ interconfigurational energies of transition elements are almost unchanged by SIC. We also discuss the admissibility of fractional occupation numbers, and present a parametrization of the electron-gas correlation energy at any density, based on the recent results of Ceperley and Alder.","['Atomic orbital', 'Density functional theory', 'Exchange interaction', 'Physics', 'Electron', 'Orbital-free density functional theory', 'Eigenvalues and eigenvectors', 'Statistical physics', 'Simple (philosophy)', 'Quantum mechanics', 'Local-density approximation', 'Philosophy', 'Epistemology', 'Ferromagnetism']","density functional, correlation, density, number, binding energies, electron densities, orbital eigenvalues, longrange behavior, band gaps, insulator, cohesive energies, transition metals, lsd spin splitting, interconfigurational energies"
Paper_00427,Squeeze-and-Excitation Networks,"['Jie Hu', 'Li Shen', 'Gang Sun']",2018,Unknown,Unknown,,,,,10.1109/cvpr.2018.00745,"Convolutional neural networks are built upon the convolution operation, which extracts informative features by fusing spatial and channel-wise information together within local receptive fields. In order to boost the representational power of a network, several recent approaches have shown the benefit of enhancing spatial encoding. In this work, we focus on the channel relationship and propose a novel architectural unit, which we term the ""Squeeze-and-Excitation"" (SE) block, that adaptively recalibrates channel-wise feature responses by explicitly modelling interdependencies between channels. We demonstrate that by stacking these blocks together, we can construct SENet architectures that generalise extremely well across challenging datasets. Crucially, we find that SE blocks produce significant performance improvements for existing state-of-the-art deep architectures at minimal additional computational cost. SENets formed the foundation of our ILSVRC 2017 classification submission which won first place and significantly reduced the top-5 error to 2.251%, achieving a ~25% relative improvement over the winning entry of 2016. Code and models are available at https://github.com/hujie-frank/SENet.","['Computer science', 'Convolution (computer science)', 'Block (permutation group theory)', 'Convolutional neural network', 'Code (set theory)', 'Encoding (memory)', 'Focus (optics)', 'Construct (python library)', 'Channel (broadcasting)', 'Feature (linguistics)', 'Decoding methods', 'Artificial intelligence', 'Theoretical computer science', 'Pattern recognition (psychology)', 'Computer engineering', 'Algorithm', 'Artificial neural network', 'Programming language', 'Telecommunications', 'Linguistics', 'Philosophy', 'Physics', 'Geometry', 'Mathematics', 'Set (abstract data type)', 'Optics']","convolutional neural networks, convolution operation, ##ative, local receptive fields, representational power, spatial encoding, channel relationship, inter, ##penden, senet architectures, ilsvr, [PAD]"
Paper_00429,Governing the Commons: The Evolution of Institutions for Collective Action,"['Barry C. Field', 'Элинор Остром']",1992,Land Economics,Journal,,354-354,68,3,10.2307/3146384,"Preface 1. Reflections on the commons 2. An institutional approach to the study of self-organization and self-governance in CPR situations 3. Analyzing long-enduring, self-organized and self-governed CPRs 4. Analyzing institutional change 5. Analyzing institutional failures and fragilities 6. A framework for analysis of self-organizing and self-governing CPRs Notes References Index.","['Commons', 'Collective action', 'Action (physics)', 'Law and economics', 'Political science', 'Environmental ethics', 'Political economy', 'Sociology', 'Law', 'Politics', 'Philosophy', 'Physics', 'Quantum mechanics']","institutional approach, cpr, institutional change, institutional failures, fragilities"
Paper_00431,Accurate spin-dependent electron liquid correlation energies for local spin density calculations: a critical analysis,"['S. H. Vosko', 'L. Wilk', 'Marwan Nusair']",1980,Canadian Journal of Physics,Journal,,1200-1211,58,8,10.1139/p80-159,"We assess various approximate forms for the correlation energy per particle of the spin-polarized homogeneous electron gas that have frequently been used in applications of the local spin density approximation to the exchange-correlation energy functional. By accurately recalculating the RPA correlation energy as a function of electron density and spin polarization we demonstrate the inadequacies of the usual approximation for interpolating between the para- and ferro-magnetic states and present an accurate new interpolation formula. A Padé approximant technique is used to accurately interpolate the recent Monte Carlo results (para and ferro) of Ceperley and Alder into the important range of densities for atoms, molecules, and metals. These results can be combined with the RPA spin-dependence so as to produce a correlation energy for a spin-polarized homogeneous electron gas with an estimated maximum error of 1 mRy and thus should reliably determine the magnitude of non-local corrections to the local spin density approximation in real systems.","['Physics', 'Spin (aerodynamics)', 'Fermi gas', 'Spin polarization', 'Electron', 'Local-density approximation', 'Range (aeronautics)', 'Monte Carlo method', 'Interpolation (computer graphics)', 'Condensed matter physics', 'Quantum mechanics', 'Density functional theory', 'Classical mechanics', 'Mathematics', 'Thermodynamics', 'Motion (physics)', 'Statistics', 'Materials science', 'Composite material']","correlation energy, local spin density approximation, ##pa correlation energy, spin polarization, pade approximant technique, correlation, local spin density approximation"
Paper_00434,<i>ORTEP</i>-3 for Windows - a version of<i>ORTEP</i>-III with a Graphical User Interface (GUI),['Louis J. Farrugia'],1997,Journal of Applied Crystallography,Journal,,565-565,30,5,10.1107/s0021889897003117,"Computer Program Abstracts The category Computer Program Abstracts provides a rapid means of communicating up-to-date information concerning both new programs or systems and significant updates to existing ones. Following normal submission, a Computer Program Abstract will be reviewed by one or two members of the IUCr Commission on Crystallographic Computing. It should not exceed 500 words in length and should follow the standard format given on page 189 of the June 1985 issue of the Journal [J. Appl. CrysL (1985). 18, 189190] and on the World Wide Web at http://www.iucr. ac. uk/journals/jac/software/. Lists of software presented and~or reviewed in the Journal of Applied Crystallography are available on the World Wide Web at the above address, together with information about the availability of the software where this is known. J. App/. CrysL (1997). 30, 565 ORTEP-3 for Windows a version of ORTEP-III with a Graphical User Interface (GUI)","['Graphical user interface', 'Computer science', 'Graphical user interface testing', 'User interface', 'Operating system', 'Computer graphics (images)', 'Interface (matter)', 'User interface design', 'Bubble', 'Maximum bubble pressure method']","computer program abstracts, computer program abstracts, computer program, iuc, crystallographic computing, applied crystallography, graphical user interface"
Paper_00435,General atomic and molecular electronic structure system,"['Michael W. Schmidt', 'Kim K. Baldridge', 'Jerry A. Boatz', 'Stephen T. Elbert', 'Mark S. Gordon', 'Jan H. Jensen', 'Shiro Koseki', 'Nikita Matsunaga', 'Kiet A. Nguyen', 'Shujun Su', 'Theresa L. Windus', 'Michel Dupuis', 'John A. Montgomery']",1993,Journal of Computational Chemistry,Journal,,1347-1363,14,11,10.1002/jcc.540141112,"Abstract A description of the ab initio quantum chemistry package GAMESS is presented. Chemical systems containing atoms through radon can be treated with wave functions ranging from the simplest closed‐shell case up to a general MCSCF case, permitting calculations at the necessary level of sophistication. Emphasis is given to novel features of the program. The parallelization strategy used in the RHF, ROHF, UHF, and GVB sections of the program is described, and detailed speecup results are given. Parallel calculations can be run on ordinary workstations as well as dedicated parallel machines. © John Wiley &amp; Sons, Inc.","['Computer science', 'Ab initio', 'Electronic structure', 'Workstation', 'Sophistication', 'Wave function', 'Computational chemistry', 'Computational science', 'Chemistry', 'Atomic physics', 'Physics', 'Social science', 'Sociology', 'Operating system', 'Organic chemistry']","quantum chemistry package gamess, chemical systems, radon, wave functions, closed, parallelization strategy, ##hf, uhf, gvb, ##ee, parallel machines"
Paper_00438,The american rheumatism association 1987 revised criteria for the classification of rheumatoid arthritis,"['Frank C. Arnett', 'Steven M. Edworthy', 'D. Blöch', 'Dennis J. McShane', 'James F. Fries', 'Norman S. Cooper', 'Louis A. Healey', 'Stephen R. Kaplan', 'Matthew H. Liang', 'Harvinder S. Luthra', 'Thomas A. Medsger', 'Donald M. Mitchell', 'David H. Neustadt', 'Robert S. Pinals', 'Jane G. Schaller', 'John T. Sharp', 'Ronald L. Wilder', 'Gene G. Hunder']",1988,Arthritis & Rheumatism,Journal,,315-324,31,3,10.1002/art.1780310302,"Abstract The revised criteria for the classification of rheumatoid arthritis (RA) were formulated from a computerized analysis of 262 contemporary, consecutively studied patients with RA and 262 control subjects with rheumatic diseases other than RA (non‐RA). The new criteria are as follows: 1) morning stiffness in and around joints lasting at least 1 hour before maximal improvement; 2) soft tissue swelling (arthritis) of 3 or more joint areas observed by a physician; 3) swelling (arthritis) of the proximal interphalangeal, metacarpophalangeal, or wrist joints; 4) symmetric swelling (arthritis); 5) rheumatoid nodules; 6) the presence of rheumatoid factor; and 7) radiographic erosions and/or periarticular osteopenia in hand and/or wrist joints. Criteria 1 through 4 must have been present for at least 6 weeks. Rheumatoid arthritis is defined by the presence of 4 or more criteria, and no further qualifications (classic, definite, or probable) or list of exclusions are required. In addition, a “classification tree” schema is presented which performs equally as well as the traditional (4 of 7) format. The new criteria demonstrated 91–94% sensitivity and 89% specificity for RA when compared with non‐RA rheumatic disease control subjects.","['Medicine', 'Rheumatoid arthritis', 'Wrist', 'Rheumatism', 'Rheumatoid factor', 'Internal medicine', 'Arthritis', 'Metacarpophalangeal joint', 'Morning stiffness', 'Interphalangeal Joint', 'Dermatology', 'Rheumatology', 'Physical therapy', 'Surgery', 'Psoriatic arthritis', 'Thumb']","rheumatoid arthritis, ##heumatic diseases, morning stiffness, soft tissue swelling, symmetric swelling, rheumatoid nodules, radiographic erosions, periarticular osteopenia, wrist joints, rheumatoid arthritis, ##umatic disease"
Paper_00439,The consequences of modernity,['Anthony Giddens'],1990,Choice Reviews Online,Journal,,28-1843,28,03,10.5860/choice.28-1843,"Part I:. Introduction. The Discontinuities of Modernity. Security and Danger, Trust and Risk. Sociology and Modernity. Modernity, Time and Space. Disembedding. Trust. The Reflexivity of Modernity. Modernity and Post-- Modernity?. Summary. Part II:. The Institutional Dimensions of Modernity. The Globalizing of Modernity. Two Theoretical Perspectives. Dimensions of Globalization. Part III:. Trust and Modernity. Trust in Abstract Systems. Trust and Expertise. Trust and Ontological Security. The Pre--Modern and Modern. Part IV:. Abstract Systems and the Transformation of Intimacy. Trust and Personal Relations. Trust and Personal Identity. Risk and Danger in the Modern World. Risk and Ontological Security. Adaptive Reactions. A Phenomonology of Modernity. Deskilling and Reskilling in Everyday Life. Objections to Post--Modernity. Part V:. Riding the Juggernaut. Utopian Realism. Future Orientations. The Role of Social Movements. Post--Modernity. Part VI: . Is Modernity and Western Project?. Concluding Observations. Notes.","['Modernity', 'History', 'Art', 'Aesthetics', 'Philosophy', 'Epistemology']","discontinuities, modernity, security, danger, trust, risk, sociology, modernity, di, ##dding, trust, reflexivity, modern, institutional dimensions, global, globalization, trust, modernity, trust, abstract, trust, expertise, trust, ontological security, abstract systems, intimacy, trust, personal relations, trust, personal identity, risk, danger, risk, ontological security, adaptive reactions, phenomonology, modern, ##ing, reskilling, everyday life, ##ger, utopian realism, social movements"
Paper_00440,Communities of Practice,['Étienne Wenger'],1998,Unknown,Unknown,,,,,10.1017/cbo9780511803932,"This book presents a theory of learning that starts with the assumption that engagement in social practice is the fundamental process by which we get to know what we know and by which we become who we are. The primary unit of analysis of this process is neither the individual nor social institutions, but the informal 'communities of practice' that people form as they pursue shared enterprises over time. To give a social account of learning, the theory explores in a systematic way the intersection of issues of community, social practice, meaning, and identity. The result is a broad framework for thinking about learning as a process of social participation. This ambitious but thoroughly accessible framework has relevance for the practitioner as well as the theoretician, presented with all the breadth, depth, and rigor necessary to address such a complex and yet profoundly human topic.","['Process (computing)', 'Identity (music)', 'Relevance (law)', 'Meaning (existential)', 'Intersection (aeronautics)', 'Sociology', 'Epistemology', 'Social practice', 'Political science', 'Computer science', 'Engineering', 'Aesthetics', 'Art', 'Philosophy', 'Performance art', 'Law', 'Art history', 'Operating system', 'Aerospace engineering']","learning, social practice, social institutions, community, social practice, meaning, social participation"
Paper_00441,Increasing Returns and Long-Run Growth,['Paul Romer'],1986,Journal of Political Economy,Journal,,1002-1037,94,5,10.1086/261420,"This paper presents a fully specified model of long-run growth in which knowledge is assumed to be an input in production that has increasing marginal productivity. It is essentially a competitive equilibrium model with endogenous technological change. In contrast to models based on diminishing returns, growth rates can be increasing over time, the effects of small disturbances can be amplified by the actions of private agents, and large countries may always grow faster than small countries. Long-run evidence is offered in support of the empirical relevance of these possibilities.","['Economics', 'Econometrics']","marginal productivity, competitive equilibrium model, endogenous technological change, private agents"
Paper_00442,"Introducing mothur: Open-Source, Platform-Independent, Community-Supported Software for Describing and Comparing Microbial Communities","['Patrick D. Schloss', 'Sarah L. Westcott', 'Thomas Ryabin', 'Justine R. Hall', 'Martin Hartmann', 'Emily B. Hollister', 'Ryan A. Lesniewski', 'Brian B. Oakley', 'Donovan H. Parks', 'Courtney J. Robinson', 'Jason W. Sahl', 'Blaž Stres', 'Gerhard Thallinger', 'David J. Horn', 'Carolyn F. Weber']",2009,Applied and Environmental Microbiology,Journal,,7537-7541,75,23,10.1128/aem.01541-09,"ABSTRACT mothur aims to be a comprehensive software package that allows users to use a single piece of software to analyze community sequence data. It builds upon previous tools to provide a flexible and powerful software package for analyzing sequencing data. As a case study, we used mothur to trim, screen, and align sequences; calculate distances; assign sequences to operational taxonomic units; and describe the α and β diversity of eight marine samples previously characterized by pyrosequencing of 16S rRNA gene fragments. This analysis of more than 222,000 sequences was completed in less than 2 h with a laptop computer.","['Laptop', 'Software', 'Pyrosequencing', 'Computer science', 'Metagenomics', 'Data mining', 'Computational biology', 'Biology', 'Software engineering', 'Genetics', 'Gene', 'Programming language', 'Operating system']","abstract mothur, community sequence data, mothur, operational taxonomic units, [PAD]"
Paper_00445,A Theoretical Extension of the Technology Acceptance Model: Four Longitudinal Field Studies,"['Viswanath Venkatesh', 'Fred D. Davis']",2000,Management Science,Journal,,186-204,46,2,10.1287/mnsc.46.2.186.11926,"The present research develops and tests a theoretical extension of the Technology Acceptance Model (TAM) that explains perceived usefulness and usage intentions in terms of social influence and cognitive instrumental processes. The extended model, referred to as TAM2, was tested using longitudinal data collected regarding four different systems at four organizations (N = 156), two involving voluntary usage and two involving mandatory usage. Model constructs were measured at three points in time at each organization: preimplementation, one month postimplementation, and three months postimplementation. The extended model was strongly supported for all four organizations at all three points of measurement, accounting for 40%–60% of the variance in usefulness perceptions and 34%–52% of the variance in usage intentions. Both social influence processes (subjective norm, voluntariness, and image) and cognitive instrumental processes (job relevance, output quality, result demonstrability, and perceived ease of use) significantly influenced user acceptance. These findings advance theory and contribute to the foundation for future research aimed at improving our understanding of user adoption behavior.","['Voluntariness', 'Technology acceptance model', 'Psychology', 'Variance (accounting)', 'Usability', 'Perception', 'Cognition', 'Applied psychology', 'Structural equation modeling', 'Social psychology', 'Computer science', 'Business', 'Accounting', 'Human–computer interaction', 'Neuroscience', 'Machine learning', 'Political science', 'Law']","technology acceptance model, perceived usefulness, usage intentions, social influence, cognitive instrumental processes, tam, voluntary usage, mandatory usage, preimplementation, ##im, ##implement, usefulness perceptions, usage intentions, social influence, subjective norm, voluntariness, image, cognitive instrumental processes, job relevance, output quality, result demonstrability, perceived, user acceptance, user adoption behavior"
Paper_00446,Search and clustering orders of magnitude faster than BLAST,['R. C. Edgar'],2010,Bioinformatics,Journal,,2460-2461,26,19,10.1093/bioinformatics/btq461,"Motivation: Biological sequence data is accumulating rapidly, motivating the development of improved high-throughput methods for sequence classification. Results: UBLAST and USEARCH are new algorithms enabling sensitive local and global search of large sequence databases at exceptionally high speeds. They are often orders of magnitude faster than BLAST in practical applications, though sensitivity to distant protein relationships is lower. UCLUST is a new clustering method that exploits USEARCH to assign sequences to clusters. UCLUST offers several advantages over the widely used program CD-HIT, including higher speed, lower memory use, improved sensitivity, clustering at lower identities and classification of much larger datasets. Availability: Binaries are available at no charge for non-commercial use at http://www.drive5.com/usearch Contact: robert@drive5.com Supplementary information: Supplementary data are available at Bioinformatics online.","['Cluster analysis', 'Computer science', 'Sequence (biology)', 'Sensitivity (control systems)', 'Data mining', 'Exploit', 'Pattern recognition (psychology)', 'Machine learning', 'Artificial intelligence', 'Biology', 'Genetics', 'Computer security', 'Electronic engineering', 'Engineering']","biological sequence data, sequence classification, ublast, usearch, global search, distant protein relationships, uclust, clustering, usearch, uclust, binaries, bioinformatics"
Paper_00449,High resolution two-dimensional electrophoresis of proteins.,['Patrick H. O’Farrell'],1975,Journal of Biological Chemistry,Journal,,4007-4021,250,10,10.1016/s0021-9258(19)41496-8,"METHODS ChemicalsAmpholines were obtained from LKB.Several different batch numbers were used during the course of this work.The quality of the gels varied only slightly, but precise reproduction of a separation should not be expected when the Ampholines are changed.Nonidet P-40 (HP-40) was purchased from Imperial Shell.SDS, manufactured by British Drug House Chemical Ltd., was purchased from Gallard-Schlesinger.Acrylamide, N,N'-methylenebisacrvlamide and N.N.N'.N'-tetramethvlethvlenediamine (TEMED)were purchased'frdm Eastman-Kodak.","['Chromatography', 'Electrophoresis', 'Acrylamide', 'Chemistry', 'Polyacrylamide gel electrophoresis', 'Biochemistry', 'Enzyme', 'Organic chemistry', 'Polymer', 'Monomer']","##ines, nonide, imperial shell, ##s, british, ac, ##diamine, ##med"
Paper_00450,Focal Loss for Dense Object Detection,"['Tsung-Yi Lin', 'Priya Goyal', 'Ross Girshick', 'Kaiming He', 'Piotr Dollár']",2017,Unknown,Unknown,,,,,10.1109/iccv.2017.324,"The highest accuracy object detectors to date are based on a two-stage approach popularized by R-CNN, where a classifier is applied to a sparse set of candidate object locations. In contrast, one-stage detectors that are applied over a regular, dense sampling of possible object locations have the potential to be faster and simpler, but have trailed the accuracy of two-stage detectors thus far. In this paper, we investigate why this is the case. We discover that the extreme foreground-background class imbalance encountered during training of dense detectors is the central cause. We propose to address this class imbalance by reshaping the standard cross entropy loss such that it down-weights the loss assigned to well-classified examples. Our novel Focal Loss focuses training on a sparse set of hard examples and prevents the vast number of easy negatives from overwhelming the detector during training. To evaluate the effectiveness of our loss, we design and train a simple dense detector we call RetinaNet. Our results show that when trained with the focal loss, RetinaNet is able to match the speed of previous one-stage detectors while surpassing the accuracy of all existing state-of-the-art two-stage detectors.","['Detector', 'Computer science', 'Artificial intelligence', 'Object detection', 'Classifier (UML)', 'Object (grammar)', 'Training set', 'Set (abstract data type)', 'Computer vision', 'Pattern recognition (psychology)', 'Telecommunications', 'Programming language']","classifier, dense detectors, cross entropy loss, focal loss, dense detector, retinanet, focal loss, retinanet"
Paper_00451,Conduction of Heat in Solids,"['H. S. Carslaw', 'J. C. Jaeger']",1959,['Thermal Effects of High Power Laser Energy on Materials'],Unknown,,53-80,,,10.1007/978-3-030-63064-5_3,"This classic account describes the known exact solutions of problems of heat flow, with detailed discussion of all the most important boundary value problems.","['Thermal conduction', 'Materials science', 'Thermodynamics', 'Mechanics', 'Environmental science', 'Physics']","heat flow, boundary value problems"
Paper_00452,MobileNetV2: Inverted Residuals and Linear Bottlenecks,"['Mark Sandler', 'Andrew Howard', 'Menglong Zhu', 'Andrey Zhmoginov', 'Liang-Chieh Chen']",2018,Unknown,Unknown,,4510-4520,,,10.1109/cvpr.2018.00474,"In this paper we describe a new mobile architecture, MobileNetV2, that improves the state of the art performance of mobile models on multiple tasks and benchmarks as well as across a spectrum of different model sizes. We also describe efficient ways of applying these mobile models to object detection in a novel framework we call SSDLite. Additionally, we demonstrate how to build mobile semantic segmentation models through a reduced form of DeepLabv3 which we call Mobile DeepLabv3. is based on an inverted residual structure where the shortcut connections are between the thin bottleneck layers. The intermediate expansion layer uses lightweight depthwise convolutions to filter features as a source of non-linearity. Additionally, we find that it is important to remove non-linearities in the narrow layers in order to maintain representational power. We demonstrate that this improves performance and provide an intuition that led to this design. Finally, our approach allows decoupling of the input/output domains from the expressiveness of the transformation, which provides a convenient framework for further analysis. We measure our performance on ImageNet [1] classification, COCO object detection [2], VOC image segmentation [3]. We evaluate the trade-offs between accuracy, and number of operations measured by multiply-adds (MAdd), as well as actual latency, and the number of parameters.","['Computer science', 'Object detection', 'Segmentation', 'Bottleneck', 'Artificial intelligence', 'Residual', 'Pattern recognition (psychology)', 'Distributed computing', 'Computer engineering', 'Data mining', 'Algorithm', 'Embedded system']","mobile architecture, mobilenetv2, object detection, ssdlite, deeplab, mobile deeplab, inverted residual structure, shortcut connections, thin bottleneck layers, intermediate expansion layer, lightweight depthwise convolutions, ##ity, representational power, imagenet, coco object detection, voc image segmentation, latency"
Paper_00453,"AN EXAMINATION OF THE DEGTJAREFF METHOD FOR DETERMINING SOIL ORGANIC MATTER, AND A PROPOSED MODIFICATION OF THE CHROMIC ACID TITRATION METHOD","['Allan Walkley', 'I. ARMSTRONG BLACK']",1934,Soil Science,Journal,,29-38,37,1,10.1097/00010694-193401000-00003,"AN EXAMINATION OF THE DEGTJAREFF METHOD FOR DETERMINING SOIL ORGANIC MATTER, AND A PROPOSED MODIFICATION OF THE CHROMIC ACID TITRATION METHOD A. WALKLEY;I. BLACK; Soil Science","['Titration', 'Chromic acid', 'Organic matter', 'Chemistry', 'Environmental chemistry', 'Environmental science', 'Inorganic chemistry', 'Organic chemistry']","soil organic matter, chromic acid titration method, soil science, [PAD] [PAD] [PAD] [PAD], [PAD] [PAD], [PAD], [PAD] [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD], [PAD] [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"
Paper_00454,Comparing the Areas under Two or More Correlated Receiver Operating Characteristic Curves: A Nonparametric Approach,"['Elizabeth R. DeLong', 'David M. DeLong', 'Daniel L. Clarke‐Pearson']",1988,Biometrics,Journal,,837-837,44,3,10.2307/2531595,"Methods of evaluating and comparing the performance of diagnostic tests are of increasing importance as new tests are developed and marketed. When a test is based on an observed variable that lies on a continuous or graded scale, an assessment of the overall value of the test can be made through the use of a receiver operating characteristic (ROC) curve. The curve is constructed by varying the cutpoint used to determine which values of the observed variable will be considered abnormal and then plotting the resulting sensitivities against the corresponding false positive rates. When two or more empirical curves are constructed based on tests performed on the same individuals, statistical analysis on differences between curves must take into account the correlated nature of the data. This paper presents a nonparametric approach to the analysis of areas under correlated ROC curves, by using the theory on generalized U-statistics to generate an estimated covariance matrix.","['Receiver operating characteristic', 'Nonparametric statistics', 'Statistics', 'Mathematics', 'Variable (mathematics)', 'Covariance matrix', 'Scale (ratio)', 'Covariance', 'Statistical hypothesis testing', 'Econometrics', 'Mathematical analysis', 'Physics', 'Quantum mechanics']","diagnostic tests, graded, receiver operating characteristic, false positive rates, statistical analysis, nonparametric, correlated roc curves, estimated covariance matrix, [PAD], [PAD] [PAD] [PAD]"
Paper_00455,<i>Phaser</i>crystallographic software,"['Airlie J. McCoy', 'Ralf W. Grosse‐Kunstleve', 'Paul D. Adams', 'Martyn Winn', 'Laurent C. Storoni', 'Randy J. Read']",2007,Journal of Applied Crystallography,Journal,,658-674,40,4,10.1107/s0021889807021206,"Phaser is a program for phasing macromolecular crystal structures by both molecular replacement and experimental phasing methods. The novel phasing algorithms implemented in Phaser have been developed using maximum likelihood and multivariate statistics. For molecular replacement, the new algorithms have proved to be significantly better than traditional methods in discriminating correct solutions from noise, and for single-wavelength anomalous dispersion experimental phasing, the new algorithms, which account for correlations between F + and F − , give better phases (lower mean phase error with respect to the phases given by the refined structure) than those that use mean F and anomalous differences Δ F . One of the design concepts of Phaser was that it be capable of a high degree of automation. To this end, Phaser (written in C++) can be called directly from Python, although it can also be called using traditional CCP4 keyword-style input. Phaser is a platform for future development of improved phasing methods and their release, including source code, to the crystallographic community.","['Phaser', 'Molecular replacement', 'Python (programming language)', 'Computer science', 'Algorithm', 'Software', 'Crystallography', 'Crystal structure', 'Optics', 'Physics', 'Chemistry', 'Programming language']","phaser, ##lecular crystal structures, molecular replacement, experimental phasing methods, phasing algorithms, phaser, maximum likelihood, multivariate statistics, anomalous differences, phaser, phaser, phaser, phasing"
Paper_00456,<b>lavaan</b>: An<i>R</i>Package for Structural Equation Modeling,['Yves Rosseel'],2012,Journal of Statistical Software,Journal,,,48,2,10.18637/jss.v048.i02,"Structural equation modeling (SEM) is a vast field and widely used by many applied researchers in the social and behavioral sciences. Over the years, many software packages for structural equation modeling have been developed, both free and commercial. However, perhaps the best state-of-the-art software packages in this field are still closed-source and/or commercial. The R package lavaan has been developed to provide applied researchers, teachers, and statisticians, a free, fully open-source, but commercial-quality package for latent variable modeling. This paper explains the aims behind the development of the package, gives an overview of its most important features, and provides some examples to illustrate how lavaan works in practice.","['Structural equation modeling', 'Computer science', 'Latent variable', 'Software package', 'Field (mathematics)', 'Open source', 'R package', 'Variable (mathematics)', 'Software', 'Open source software', 'Quality (philosophy)', 'Software engineering', 'Industrial engineering', 'Data science', 'Computational science', 'Mathematics', 'Artificial intelligence', 'Programming language', 'Engineering', 'Machine learning', 'Mathematical analysis', 'Philosophy', 'Epistemology', 'Pure mathematics']","structural equation modeling, structural equation modeling, lavaan, statistic, latent variable modeling, lavaan, [PAD] [PAD], [PAD] [PAD] [PAD], [PAD] [PAD] [PAD]"
Paper_00457,Very high resolution interpolated climate surfaces for global land areas,"['Robert J. Hijmans', 'Susan E. Cameron', 'Juan L. Parra', 'Peter G. Jones', 'Andy Jarvis']",2005,International Journal of Climatology,Journal,,1965-1978,25,15,10.1002/joc.1276,"We developed interpolated climate surfaces for global land areas (excluding Antarctica) at a spatial resolution of 30 arc s (often referred to as 1-km spatial resolution). The climate elements considered were monthly precipitation and mean, minimum, and maximum temperature. Input data were gathered from a variety of sources and, where possible, were restricted to records from the 1950–2000 period. We used the thin-plate smoothing spline algorithm implemented in the ANUSPLIN package for interpolation, using latitude, longitude, and elevation as independent variables. We quantified uncertainty arising from the input data and the interpolation by mapping weather station density, elevation bias in the weather stations, and elevation variation within grid cells and through data partitioning and cross validation. Elevation bias tended to be negative (stations lower than expected) at high latitudes but positive in the tropics. Uncertainty is highest in mountainous and in poorly sampled areas. Data partitioning showed high uncertainty of the surfaces on isolated islands, e.g. in the Pacific. Aggregating the elevation and climate data to 10 arc min resolution showed an enormous variation within grid cells, illustrating the value of high-resolution surfaces. A comparison with an existing data set at 10 arc min resolution showed overall agreement, but with significant variation in some regions. A comparison with two high-resolution data sets for the United States also identified areas with large local differences, particularly in mountainous areas. Compared to previous global climatologies, ours has the following advantages: the data are at a higher spatial resolution (400 times greater or more); more weather station records were used; improved elevation data were used; and more information about spatial patterns of uncertainty in the data is available. Owing to the overall low density of available climate stations, our surfaces do not capture of all variation that may occur at a resolution of 1 km, particularly of precipitation in mountainous areas. In future work, such variation might be captured through knowledge-based methods and inclusion of additional co-variates, particularly layers obtained through remote sensing. Copyright © 2005 Royal Meteorological Society.","['Elevation (ballistics)', 'Latitude', 'Longitude', 'Climatology', 'Environmental science', 'Multivariate interpolation', 'Precipitation', 'Data set', 'Smoothing', 'Interpolation (computer graphics)', 'Meteorology', 'Geography', 'Geology', 'Geodesy', 'Mathematics', 'Statistics', 'Animation', 'Geometry', 'Computer graphics (images)', 'Computer science', 'Bilinear interpolation']","inter, ##ated climate surfaces, global land areas, an, weather station density, elevation bias, elevation variation, data partitioning, cross validation, elevation bias, ##opics, data partitioning, pacific, remote sensing"
Paper_00460,Qualitative Research: A Guide to Design and Implementation,['Sharan B. Merriam'],2009,['The Qualitative Report'],Unknown,,,,,10.46743/2160-3715/2022.5748,"Preface vii The Author xv PART ONE: THE DESIGN OF QUALITATIVE RESEARCH 1 1 What is Qualitative Research? 3 2 Types of Qualitative Research 21 3 Qualitative Case Study Research 39 4 Designing Your Study and Selecting a Sample 55 PART TWO: COLLECTING QUALITATIVE DATA 85 5 Conducting Effective Interviews 87 6 Being a Careful Observer 117 7 Mining Data from Documents 139 PART THREE: ANALYZING AND REPORTING QUALITATIVE DATA 165 8 Qualitative Data Analysis 169 9 Dealing with Validity, Reliability, and Ethics 209 10 Writing Qualitative Research Reports 237 Appendix: The Methodology Section of a Qualitative Research Study 265 References 271 Name Index 287 Subject Index 293","['Qualitative research', 'Qualitative property', 'Research design', 'Qualitative analysis', 'Index (typography)', 'Reliability (semiconductor)', 'Computer science', 'Psychology', 'Sociology', 'Social science', 'World Wide Web', 'Power (physics)', 'Physics', 'Quantum mechanics', 'Machine learning']","qualitative research, qualitative, qualitative research, qualitative case study research, qualitative data, qualitative data analysis, validity, reliability, ethics, qualitative research reports, methodology, qualitative research"
Paper_00461,A SIMPLE METHOD OF ESTIMATING FIFTY PER CENT ENDPOINTS12,"['Linda Reed', 'Hugo Muench']",1938,American Journal of Epidemiology,Journal,,493-497,27,3,10.1093/oxfordjournals.aje.a118408,"Journal Article A SIMPLE METHOD OF ESTIMATING FIFTY PER CENT ENDPOINTS Get access L.J. REED, L.J. REED Search for other works by this author on: Oxford Academic PubMed Google Scholar H. MUENCH H. MUENCH Search for other works by this author on: Oxford Academic PubMed Google Scholar American Journal of Epidemiology, Volume 27, Issue 3, May 1938, Pages 493–497, https://doi.org/10.1093/oxfordjournals.aje.a118408 Published: 01 May 1938 Article history Received: 26 October 1937 Published: 01 May 1938","['Simple (philosophy)', 'Epidemiology', 'Classics', 'Medicine', 'MEDLINE', 'History', 'Library science', 'Philosophy', 'Computer science', 'Internal medicine', 'Political science', 'Epistemology', 'Law']","fifty, epidemiology"
Paper_00462,Neural networks for pattern recognition,['Chris Bishop'],1994,Choice Reviews Online,Journal,,31-5500,31,10,10.5860/choice.31-5500,"From the Publisher:
This is the first comprehensive treatment of feed-forward neural networks from the perspective of statistical pattern recognition. After introducing the basic concepts, the book examines techniques for modelling probability density functions and the properties and merits of the multi-layer perceptron and radial basis function network models. Also covered are various forms of error functions, principal algorithms for error function minimalization, learning and generalization in neural networks, and Bayesian techniques and their applications. Designed as a text, with over 100 exercises, this fully up-to-date work will benefit anyone involved in the fields of neural computation and pattern recognition.","['Computer science', 'Pattern recognition (psychology)', 'Artificial intelligence']","statistical pattern recognition, probability density functions, radial basis function network models, error functions, principal algorithms, error function minimalization, ##ization, neural networks, bayesian techniques, neural computation, pattern recognition"
Paper_00463,Measurement of the Elastic Properties and Intrinsic Strength of Monolayer Graphene,"['Changgu Lee', 'Xiaoding Wei', 'Jeffrey W. Kysar', 'James Hone']",2008,Science,Journal,,385-388,321,5887,10.1126/science.1157996,"We measured the elastic properties and intrinsic breaking strength of free-standing monolayer graphene membranes by nanoindentation in an atomic force microscope. The force-displacement behavior is interpreted within a framework of nonlinear elastic stress-strain response, and yields second- and third-order elastic stiffnesses of 340 newtons per meter (N m(-1)) and -690 Nm(-1), respectively. The breaking strength is 42 N m(-1) and represents the intrinsic strength of a defect-free sheet. These quantities correspond to a Young's modulus of E = 1.0 terapascals, third-order elastic stiffness of D = -2.0 terapascals, and intrinsic strength of sigma(int) = 130 gigapascals for bulk graphite. These experiments establish graphene as the strongest material ever measured, and show that atomically perfect nanoscale materials can be mechanically tested to deformations well beyond the linear regime.","['Nanoindentation', 'Elastic modulus', 'Graphene', 'Materials science', 'Stiffness', 'Monolayer', 'Linear elasticity', 'Elasticity (physics)', 'Composite material', 'Graphite', 'Nanomechanics', 'Condensed matter physics', 'Atomic force microscopy', 'Nanotechnology', 'Physics', 'Thermodynamics', 'Finite element method']","elastic properties, intrinsic breaking strength, graphene membranes, nano, ##entation, atomic force microscope, intrinsic, bulk graphite, graphene, atomic"
Paper_00464,Principles of Optics,"['Max Born', 'Emil Wolf']",1959,['Journal of the Franklin Institute'],Unknown,,68,269,1,10.1016/0016-0032(60)90259-3,"The book is comprised of 15 chapters that discuss various topics about optics, such as geometrical theories, image forming instruments, and optics of metals and crystals. The text covers the elements of the theories of interference, interferometers, and diffraction. The book tackles several behaviors of light, including its diffraction when exposed to ultrasonic waves.","['Optics', 'Diffraction', 'Interference (communication)', 'Astronomical interferometer', 'Physical optics', 'Physics', 'Geometrical optics', 'Crystal optics', 'Interferometry', 'Theoretical physics', 'Computer science', 'Telecommunications', 'Laser', 'Channel (broadcasting)']","optics, geometrical theories, image forming instruments, metals, crystals, interference, interferometers, diffraction, ##ff, ultrasonic waves, [PAD]"
Paper_00465,An Economic Theory of Democracy.,"['Edward C. Banfield', 'Anthony J. Downs']",1958,Midwest Journal of Political Science,Journal,,324-324,2,3,10.2307/2109186,"Downs presents a rational calculus of voting that has inspired much of the later work on voting and turnout. Particularly significant was his conclusion that a rational voter should almost never bother to vote. This conclusion, especially as elaborated on by Riker and Ordeshook (1968) has shifted the attention of modern political scientists from explaining why people don't vote to explaining why they do.","['Democracy', 'Economics', 'Political science', 'Economic system', 'Neoclassical economics', 'Mathematical economics', 'Positive economics', 'Politics', 'Law']","rational calculus, voting, voting, turnout, rational voter, political"
Paper_00466,Discipline and Punish: The Birth of the Prison,['Roberto D’Amico'],1978,Telos,Journal,,169-183,1978,36,10.3817/0678036169,"Michel Foucault. Discipline and Punish: The Birth of the Prison. New York: Pantheon, 1977. $10.95. 333 pages.","['Prison', 'Michel foucault', 'Criminology', 'Sociology', 'Law', 'Political science', 'Politics']",
Paper_00467,BLEU,"['Kishore Papineni', 'Salim Roukos', 'Todd J. Ward', 'Wei-Jing Zhu']",2001,Unknown,Unknown,,311-311,,,10.3115/1073083.1073135,"Human evaluations of machine translation are extensive but expensive. Human evaluations can take months to finish and involve human labor that can not be reused. We propose a method of automatic machine translation evaluation that is quick, inexpensive, and language-independent, that correlates highly with human evaluation, and that has little marginal cost per run. We present this method as an automated understudy to skilled human judges which substitutes for them when there is need for quick or frequent evaluations.","['Computer science', 'Machine translation', 'BLEU', 'Artificial intelligence', 'Translation (biology)', 'Natural language processing', 'Human–machine system', 'Machine learning', 'Biochemistry', 'Chemistry', 'Messenger RNA', 'Gene']","human evaluations, machine translation, human evaluations, automatic machine translation evaluation, human evaluation, skilled human judges"
Paper_00468,Older Adults' Reasons for Using Technology while Aging in Place,"['Sebastiaan Theodorus Michaël Peek', 'Katrien Luijkx', 'M. D. Rijnaard', 'Marianne Nieboer', 'C. S. van der Voort', 'Sil Aarts', 'Joost van Hoof', 'Hubertus JM Vrijhoef', 'Eveline Wouters']",2015,Gerontology,Journal,,226-237,62,2,10.1159/000430949,"Background: Most older adults prefer to age in place, and supporting older adults to remain in their own homes and communities is also favored by policy makers. Technology can play a role in staying independent, active and healthy. However, the use of technology varies considerably among older adults. Previous research indicates that current models of technology acceptance are missing essential predictors specific to community-dwelling older adults. Furthermore, in situ research within the specific context of aging in place is scarce, while this type of research is needed to better understand how and why community-dwelling older adults are using technology. Objective: To explore which factors influence the level of use of various types of technology by older adults who are aging in place and to describe these factors in a comprehensive model. Methods: A qualitative explorative field study was set up, involving home visits to 53 community-dwelling older adults, aged 68-95, living in the Netherlands. Purposive sampling was used to include participants with different health statuses, living arrangements, and levels of technology experience. During each home visit: (1) background information on the participants' chronic conditions, major life events, frailty, cognitive functioning, subjective health, ownership and use of technology was gathered, and (2) a semistructured interview was conducted regarding reasons for the level of use of technology. The study was designed to include various types of technology that could support activities of daily living, personal health or safety, mobility, communication, physical activity, personal development, and leisure activities. Thematic analysis was employed to analyze interview transcripts. Results: The level of technology use in the context of aging in place is influenced by six major themes: challenges in the domain of independent living; behavioral options; personal thoughts on technology use; influence of the social network; influence of organizations, and the role of the physical environment. Conclusion: Older adults' perceptions and use of technology are embedded in their personal, social, and physical context. Awareness of these psychological and contextual factors is needed in order to facilitate aging in place through the use of technology. A conceptual model covering these factors is presented.","['Gerontology', 'Aging in place', 'Thematic analysis', 'Context (archaeology)', 'Nonprobability sampling', 'Qualitative research', 'Activities of daily living', 'Psychology', 'Independent living', 'Successful aging', 'Medicine', 'Population', 'Environmental health', 'Sociology', 'Social science', 'Paleontology', 'Psychiatry', 'Biology']","technology, qualitative, ##ve sampling, health statuses, living arrangements, frailty, cognitive functioning, subjective health, personal development, leisure activities, independent living, behavioral options, personal thoughts, social network, organizations"
Paper_00469,Multiple Imputation for Nonresponse in Surveys,['Donald B. Rubin'],1987,Wiley series in probability and statistics,Unknown,,,,,10.1002/9780470316696,"Tables and Figures. Glossary. 1. Introduction. 1.1 Overview. 1.2 Examples of Surveys with Nonresponse. 1.3 Properly Handling Nonresponse. 1.4 Single Imputation. 1.5 Multiple Imputation. 1.6 Numerical Example Using Multiple Imputation. 1.7 Guidance for the Reader. 2. Statistical Background. 2.1 Introduction. 2.2 Variables in the Finite Population. 2.3 Probability Distributions and Related Calculations. 2.4 Probability Specifications for Indicator Variables. 2.5 Probability Specifications for (X,Y). 2.6 Bayesian Inference for a Population Quality. 2.7 Interval Estimation. 2.8 Bayesian Procedures for Constructing Interval Estimates, Including Significance Levels and Point Estimates. 2.9 Evaluating the Performance of Procedures. 2.10 Similarity of Bayesian and Randomization--Based Inferences in Many Practical Cases. 3. Underlying Bayesian Theory. 3.1 Introduction and Summary of Repeated--Imputation Inferences. 3.2 Key Results for Analysis When the Multiple Imputations are Repeated Draws from the Posterior Distribution of the Missing Values. 3.3 Inference for Scalar Estimands from a Modest Number of Repeated Completed--Data Means and Variances. 3.4 Significance Levels for Multicomponent Estimands from a Modest Number of Repeated Completed--Data Means and Variance--Covariance Matrices. 3.5 Significance Levels from Repeated Completed--Data Significance Levels. 3.6 Relating the Completed--Data and Completed--Data Posterior Distributions When the Sampling Mechanism is Ignorable. 4. Randomization--Based Evaluations. 4.1 Introduction. 4.2 General Conditions for the Randomization--Validity of Infinite--m Repeated--Imputation Inferences. 4.3Examples of Proper and Improper Imputation Methods in a Simple Case with Ignorable Nonresponse. 4.4 Further Discussion of Proper Imputation Methods. 4.5 The Asymptotic Distibution of (Qm,Um,Bm) for Proper Imputation Methods. 4.6 Evaluations of Finite--m Inferences with Scalar Estimands. 4.7 Evaluation of Significance Levels from the Moment--Based Statistics Dm and Dm with Multicomponent Estimands. 4.8 Evaluation of Significance Levels Based on Repeated Significance Levels. 5. Procedures with Ignorable Nonresponse. 5.1 Introduction. 5.2 Creating Imputed Values under an Explicit Model. 5.3 Some Explicit Imputation Models with Univariate YI and Covariates. 5.4 Monotone Patterns of Missingness in Multivariate YI. 5.5 Missing Social Security Benefits in the Current Population Survey. 5.6 Beyond Monotone Missingness. 6. Procedures with Nonignorable Nonresponse. 6.1 Introduction. 6.2 Nonignorable Nonresponse with Univariate YI and No XI. 6.3 Formal Tasks with Nonignorable Nonresponse. 6.4 Illustrating Mixture Modeling Using Educational Testing Service Data. 6.5 Illustrating Selection Modeling Using CPS Data. 6.6 Extensions to Surveys with Follow--Ups. 6.7 Follow--Up Response in a Survey of Drinking Behavior Among Men of Retirement Age. References. Author Index. Subject Index. Appendix I. Report Written for the Social Security Administration in 1977. Appendix II. Report Written for the Census Bureau in 1983.","['Imputation (statistics)', 'Statistics', 'Econometrics', 'Missing data', 'Mathematics']","nonresponse, single imputation, multiple imputation, multiple imputation, statistical background, finite population, probability distributions, probability specifications, indicator variables, probability specifications, bayesian inference, population quality, interval estimation, bayesian procedures, interval estimates, significance levels, point estimates, random, posterior distribution, scalar estimands, data means, variance, multi, ##nt est, covariance matrices, ##utation, improper imputation methods, ##ble non, ##utation methods, asymptotic di, scalar estimands, significance levels, multicomponent estimands, significance, ign, ##ble nonres"
Paper_00411,"Research design: qualitative, quantitative, and mixed methods approaches",['Miguel Caldas'],2003,Revista de Administração Contemporânea,Journal,,223-223,7,1,10.1590/s1415-65552003000100015,"Nova edicao do conhecido livro sobre metodologia de pesquisa de Creswell. Originalmente pensado no campo da Educacao, o autor ficou muito conhecido tambem em Administracao. Nesta nova edicao, ele procura sair da dicotomia metodos quantitativos x qualitativos, com uma otima discussao adicional sobre metodos mistos. Como um todo, e uma obra excelente de referencia para cursos introdutorios de metodologia de pesquisa em programas de pos-graduacao.","['Humanities', 'Philosophy', 'Sociology']",
Paper_00414,Applied Nonlinear Control,"['Jean-Jacques Slotine', 'Weiping Li']",1991,Unknown,Unknown,,,,,10.21236/ada413514,"Covers in a progressive fashion a number of analysis tools and design techniques directly applicable to nonlinear control problems in high performance systems (in aerospace, robotics and automotive areas).","['Control (management)', 'Nonlinear system', 'Computer science', 'Control theory (sociology)', 'Physics', 'Artificial intelligence', 'Quantum mechanics']","analysis tools, design techniques, nonlinear control problems, high performance systems, aerospace, robotics, automotive, [PAD], [PAD], [PAD] [PAD], [PAD]"
Paper_00417,2016 ESC Guidelines for the diagnosis and treatment of acute and chronic heart failure,"['Piotr Ponikowski', 'Adriaan A. Voors', 'Stefan D. Anker', 'Héctor Bueno', 'John G.F. Cleland', 'Andrew J.S. Coats', 'Volkmar Falk', 'José Ramón González‐Juanatey', 'Veli‐Pekka Harjola', 'Ewa A. Jankowska', 'Mariell Jessup', 'Cecilia Linde', 'Petros Nihoyannopoulos', 'John Parissis', 'Burkert Pieske', 'Jillian Riley', 'Giuseppe Rosano', 'Luís M. Ruilope', 'Frank Ruschitzka', 'Frans H. Rutten', 'Peter van der Meer']",2016,European Heart Journal,Journal,,2129-2200,37,27,10.1093/eurheartj/ehw128,ESC Guidelines for the diagnosis and,"['Medicine', 'Heart failure', 'Intensive care medicine', 'Cardiology', 'Internal medicine']",es
Paper_00419,Lifetime Prevalence and Age-of-Onset Distributions of DSM-IV Disorders in the National Comorbidity Survey Replication,"['Ronald C. Kessler', 'Patricia A. Berglund', 'Olga Demler', 'Robert Jin', 'Kathleen R. Merikangas', 'Ellen E. Walters']",2005,Archives of General Psychiatry,Journal,,593-593,62,6,10.1001/archpsyc.62.6.593,"Little is known about lifetime prevalence or age of onset of DSM-IV disorders.To estimate lifetime prevalence and age-of-onset distributions of DSM-IV disorders in the recently completed National Comorbidity Survey Replication.Nationally representative face-to-face household survey conducted between February 2001 and April 2003 using the fully structured World Health Organization World Mental Health Survey version of the Composite International Diagnostic Interview.Nine thousand two hundred eighty-two English-speaking respondents aged 18 years and older.Lifetime DSM-IV anxiety, mood, impulse-control, and substance use disorders.Lifetime prevalence estimates are as follows: anxiety disorders, 28.8%; mood disorders, 20.8%; impulse-control disorders, 24.8%; substance use disorders, 14.6%; any disorder, 46.4%. Median age of onset is much earlier for anxiety (11 years) and impulse-control (11 years) disorders than for substance use (20 years) and mood (30 years) disorders. Half of all lifetime cases start by age 14 years and three fourths by age 24 years. Later onsets are mostly of comorbid conditions, with estimated lifetime risk of any disorder at age 75 years (50.8%) only slightly higher than observed lifetime prevalence (46.4%). Lifetime prevalence estimates are higher in recent cohorts than in earlier cohorts and have fairly stable intercohort differences across the life course that vary in substantively plausible ways among sociodemographic subgroups.About half of Americans will meet the criteria for a DSM-IV disorder sometime in their life, with first onset usually in childhood or adolescence. Interventions aimed at prevention or early treatment need to focus on youth.","['National Comorbidity Survey', 'Comorbidity', 'Anxiety', 'Mood disorders', 'Psychiatry', 'Mood', 'Age of onset', 'Prevalence of mental disorders', 'Medicine', 'Psychological intervention', 'Anxiety disorder', 'Prevalence', 'Psychology', 'Demography', 'Epidemiology', 'Clinical psychology', 'Disease', 'Internal medicine', 'Sociology']","lifetime prevalence, national comorbidity survey, substance use, anxiety disorders, mood disorders, substance use disorders, any, comorbid, lifetime prevalence"
Paper_00421,Image-to-Image Translation with Conditional Adversarial Networks,"['Phillip Isola', 'Jun-Yan Zhu', 'Tinghui Zhou', 'Alexei A. Efros']",2017,Unknown,Unknown,,5967-5976,,,10.1109/cvpr.2017.632,"We investigate conditional adversarial networks as a general-purpose solution to image-to-image translation problems. These networks not only learn the mapping from input image to output image, but also learn a loss function to train this mapping. This makes it possible to apply the same generic approach to problems that traditionally would require very different loss formulations. We demonstrate that this approach is effective at synthesizing photos from label maps, reconstructing objects from edge maps, and colorizing images, among other tasks. Moreover, since the release of the pi×2pi× software associated with this paper, hundreds of twitter users have posted their own artistic experiments using our system. As a community, we no longer hand-engineer our mapping functions, and this work suggests we can achieve reasonable results without handengineering our loss functions either.","['Adversarial system', 'Image translation', 'Image (mathematics)', 'Computer science', 'Translation (biology)', 'Artificial intelligence', 'Enhanced Data Rates for GSM Evolution', 'Function (biology)', 'Computer vision', 'Software', 'Programming language', 'Biochemistry', 'Chemistry', 'Evolutionary biology', 'Biology', 'Messenger RNA', 'Gene']","conditional adversarial networks, loss function, label maps, edge maps"
Paper_00422,Radiotherapy plus Concomitant and Adjuvant Temozolomide for Glioblastoma,"['Roger Stupp', 'Warren Mason', 'Martin J. van den Bent', 'Michael Weller', 'Barbara Fisher', 'Martin Taphoorn', 'Karl Bélanger', 'Alba A. Brandes', 'Christine Marosi', 'Ulrich Bogdahn', 'Jürgen Curschmann', 'Robert C. Janzer', 'Samuel K. Ludwin', 'Thierry Gorlia', 'Anouk Allgeier', 'Denis Lacombe', 'J. Gregory Cairncross', 'Elizabeth A. Eisenhauer', 'R.O. Mirimanoff']",2005,New England Journal of Medicine,Journal,,987-996,352,10,10.1056/nejmoa043330,"Glioblastoma, the most common primary brain tumor in adults, is usually rapidly fatal. The current standard of care for newly diagnosed glioblastoma is surgical resection to the extent feasible, followed by adjuvant radiotherapy. In this trial we compared radiotherapy alone with radiotherapy plus temozolomide, given concomitantly with and after radiotherapy, in terms of efficacy and safety.Patients with newly diagnosed, histologically confirmed glioblastoma were randomly assigned to receive radiotherapy alone (fractionated focal irradiation in daily fractions of 2 Gy given 5 days per week for 6 weeks, for a total of 60 Gy) or radiotherapy plus continuous daily temozolomide (75 mg per square meter of body-surface area per day, 7 days per week from the first to the last day of radiotherapy), followed by six cycles of adjuvant temozolomide (150 to 200 mg per square meter for 5 days during each 28-day cycle). The primary end point was overall survival.A total of 573 patients from 85 centers underwent randomization. The median age was 56 years, and 84 percent of patients had undergone debulking surgery. At a median follow-up of 28 months, the median survival was 14.6 months with radiotherapy plus temozolomide and 12.1 months with radiotherapy alone. The unadjusted hazard ratio for death in the radiotherapy-plus-temozolomide group was 0.63 (95 percent confidence interval, 0.52 to 0.75; P<0.001 by the log-rank test). The two-year survival rate was 26.5 percent with radiotherapy plus temozolomide and 10.4 percent with radiotherapy alone. Concomitant treatment with radiotherapy plus temozolomide resulted in grade 3 or 4 hematologic toxic effects in 7 percent of patients.The addition of temozolomide to radiotherapy for newly diagnosed glioblastoma resulted in a clinically meaningful and statistically significant survival benefit with minimal additional toxicity.","['Temozolomide', 'Medicine', 'Radiation therapy', 'Concomitant', 'Glioblastoma', 'Adjuvant', 'Adjuvant radiotherapy', 'Oncology', 'Internal medicine', 'Surgery', 'Cancer research']","glioblasto, primary brain tumor, surgical resection, adjuvant radiotherapy, ##ated focal irradiation, ##logic"
Paper_00424,Reducing the Dimensionality of Data with Neural Networks,"['Geoffrey E. Hinton', 'Ruslan Salakhutdinov']",2006,Science,Journal,,504-507,313,5786,10.1126/science.1127647,"High-dimensional data can be converted to low-dimensional codes by training a multilayer neural network with a small central layer to reconstruct high-dimensional input vectors. Gradient descent can be used for fine-tuning the weights in such “autoencoder” networks, but this works well only if the initial weights are close to a good solution. We describe an effective way of initializing the weights that allows deep autoencoder networks to learn low-dimensional codes that work much better than principal components analysis as a tool to reduce the dimensionality of data.","['Autoencoder', 'Curse of dimensionality', 'Initialization', 'Gradient descent', 'Artificial neural network', 'Computer science', 'Principal component analysis', 'Artificial intelligence', 'Pattern recognition (psychology)', 'Layer (electronics)', 'High dimensional', 'Principal (computer security)', 'Algorithm', 'Materials science', 'Nanotechnology', 'Programming language', 'Operating system']","multilayer neural network, central layer, gradient descent, autoencoder ” networks, deep autoencoder networks, principal components analysis, [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD], [PAD], [PAD], [PAD], [PAD] [PAD], [PAD] [PAD], [PAD] [PAD]"
Paper_00425,"The Elements of Statistical Learning: Data Mining, Inference, and Prediction","['Trevor Hastie', 'Robert Tibshirani', 'Jerome H. Friedman']",2013,['The Mathematical Intelligencer'],Unknown,,83-85,27,2,10.1007/bf02985802,"During the past decade there has been an explosion in computation and information technology. With it have come vast amounts of data in a variety of fields such as medicine, biology, finance, and marketing. The challenge of understanding these data has led to the development of new tools in the field of statistics, and spawned new areas such as data mining, machine learning, and bioinformatics. Many of these tools have common underpinnings but are often expressed with different terminology. This book describes the important ideas in these areas in a common conceptual framework. While the approach is statistical, the emphasis is on concepts rather than mathematics. Many examples are given, with a liberal use of color graphics. It is a valuable resource for statisticians and anyone interested in data mining in science or industry. The book's coverage is broad, from supervised learning (prediction) to unsupervised learning. The many topics include neural networks, support vector machines, classification trees and boosting---the first comprehensive treatment of this topic in any book.

This major new edition features many topics not covered in the original, including graphical models, random forests, ensemble methods, least angle regression and path algorithms for the lasso, non-negative matrix factorization, and spectral clustering. There is also a chapter on methods for ``wide'' data (p bigger than n), including multiple testing and false discovery rates.

Trevor Hastie, Robert Tibshirani, and Jerome Friedman are professors of statistics at Stanford University. They are prominent researchers in this area: Hastie and Tibshirani developed generalized additive models and wrote a popular book of that title. Hastie co-developed much of the statistical modeling software and environment in R/S-PLUS and invented principal curves and surfaces. Tibshirani proposed the lasso and is co-author of the very successful An Introduction to the Bootstrap. Friedman is the co-inventor of many data-mining tools including CART, MARS, projection pursuit and gradient boosting.","['Artificial intelligence', 'Computer science', 'Machine learning', 'Cluster analysis', 'Data science', 'Terminology', 'Field (mathematics)', 'Random forest', 'Topic model', 'Statistical inference', 'Mathematics', 'Statistics', 'Philosophy', 'Linguistics', 'Pure mathematics']","information technology, medicine, marketing, statistics, data mining, machine learning, bioinformatics, color graphics, supervised learning, unsupervised learning, neural networks, support vector machines, classification trees, boosting, graphical models, random forests, ensemble methods, least angle regression, path algorithms, lasso, non - negative matrix factorization, spectral clustering, multiple testing, false discovery rates, generalized additive models, statistical modeling, principal curves, ##o, ##trap, cart, mars, projection pursuit, gradient boosting"
Paper_00427,Smoothing and Differentiation of Data by Simplified Least Squares Procedures.,"['Abraham. Savitzky', 'Marcel J. E. Golay']",1964,Analytical Chemistry,Journal,,1627-1639,36,8,10.1021/ac60214a047,"ADVERTISEMENT RETURN TO ISSUEPREVArticleNEXTSmoothing and Differentiation of Data by Simplified Least Squares Procedures.Abraham. Savitzky and M. J. E. GolayCite this: Anal. Chem. 1964, 36, 8, 1627–1639Publication Date (Print):July 1, 1964Publication History Published online1 May 2002Published inissue 1 July 1964https://pubs.acs.org/doi/10.1021/ac60214a047https://doi.org/10.1021/ac60214a047research-articleACS PublicationsRequest reuse permissionsArticle Views36629Altmetric-Citations14831LEARN ABOUT THESE METRICSArticle Views are the COUNTER-compliant sum of full text article downloads since November 2008 (both PDF and HTML) across all institutions and individuals. These metrics are regularly updated to reflect usage leading up to the last few days.Citations are the number of other articles citing this article, calculated by Crossref and updated daily. Find more information about Crossref citation counts.The Altmetric Attention Score is a quantitative measure of the attention that a research article has received online. Clicking on the donut icon will load a page at altmetric.com with additional details about the score and the social media presence for the given article. Find more information on the Altmetric Attention Score and how the score is calculated. Share Add toView InAdd Full Text with ReferenceAdd Description ExportRISCitationCitation and abstractCitation and referencesMore Options Share onFacebookTwitterWechatLinked InRedditEmail Other access optionsGet e-Alertsclose Get e-Alerts","['Citation', 'Icon', 'Social media', 'Computer science', 'Altmetrics', 'Smoothing', 'Information retrieval', 'Data science', 'World Wide Web', 'Computer vision', 'Programming language']","advertisement return, ##varticlenextsmo, simplified least squares procedures, permissionsarticle views, ##le, ##f, altmetric attention score, social, altmetric attention score, ##d, ##riscitation, abstract, ##ation, references"
Paper_00428,Cochrane Handbook for Systematic Reviews of Interventions,"['Julian P. T. Higgins', 'Sally Green']",2008,Wiley eBooks,Unknown,,,,,10.1002/9780470712184,The Cochrane Handbook for Systematic Reviews of Interventions is the official document that describes in detail the process of preparing and maintaining Cochrane systematic reviews on the effects of healthcare interventions.,"['Systematic review', 'Psychological intervention', 'Psychology', 'MEDLINE', 'Biology', 'Psychiatry', 'Biochemistry']","cochrane handbook, systematic reviews, interventions, cochrane systematic reviews, healthcare interventions, [PAD], [PAD], [PAD] [PAD], [PAD] [PAD] [PAD], [PAD], [PAD] [PAD]"
Paper_00429,A Theory of Cognitive Dissonance,['Léon Festinger'],2017,Macat Library eBooks,Unknown,,,,,10.4324/9781912282432,"Leon Festinger's 1957 A Theory of Cognitive Dissonance is a key text in the history of psychology – one that made its author one of the most influential social psychologists of his time. It is also a prime example of how creative thinking and problem solving skills can come together to produce work that changes the way people look at questions for good. Strong creative thinkers are able to look at things from a new perspective, often to the point of challenging the very frames in which those around them see things. Festinger was such a creative thinker, leading what came to be known as the ""cognitive revolution"" in social psychology. When Festinger was carrying out his research, the dominant school of thought – behaviorism – focused on outward behaviors and their effects. Festinger, however, turned his attention elsewhere, looking at ""cognition:"" the mental processes behind behaviors. In the case of ""cognitive dissonance"", for example, he hypothesized that apparently incomprehensible or illogical behaviors might be caused by a cognitive drive away from dissonance, or internal contradiction. This perspective, however, raised a problem: how to examine and test out cognitive processes. Festinger's book records the results of the psychological experiments he designed to solve that problem. The results helped prove the existence for what is now a fundamental theory in social psychology.","['Cognitive dissonance', 'Cognition', 'Psychology', 'Self-justification', 'Self-perception theory', 'Function (biology)', 'Cognitive psychology', 'Social psychology', 'Neuroscience', 'Evolutionary biology', 'Biology']","cognitive dissonance, psychology, social psychologists, creative thinking, problem solving skills, cognitive revolution, social psychology, behaviorism, outward behaviors, cognition, cognitive dissonance, social psychology"
Paper_00431,DISC ELECTROPHORESIS – II METHOD AND APPLICATION TO HUMAN SERUM PROTEINS*,['B. J. Davis'],1964,Annals of the New York Academy of Sciences,Journal,,404-427,121,2,10.1111/j.1749-6632.1964.tb14213.x,"S ummary The technique of disc electrophoresis has been presented, including a discussion of the technical variables with special reference to the separation of protein fractions of normal human serum.","['Electrophoresis', 'Chemistry', 'Gel electrophoresis of proteins', 'Blood proteins', 'Chromatography', 'Biochemistry', 'Polyacrylamide gel electrophoresis', 'Enzyme']","disc electrophoresis, protein fractions, human serum, [PAD], [PAD] [PAD] [PAD], [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD], [PAD] [PAD], [PAD] [PAD] [PAD]"
Paper_00432,Unpaired Image-to-Image Translation Using Cycle-Consistent Adversarial Networks,"['Jun-Yan Zhu', 'Taesung Park', 'Phillip Isola', 'Alexei A. Efros']",2017,Unknown,Unknown,,2242-2251,,,10.1109/iccv.2017.244,"Image-to-image translation is a class of vision and graphics problems where the goal is to learn the mapping between an input image and an output image using a training set of aligned image pairs. However, for many tasks, paired training data will not be available. We present an approach for learning to translate an image from a source domain X to a target domain Y in the absence of paired examples. Our goal is to learn a mapping G : X → Y such that the distribution of images from G(X) is indistinguishable from the distribution Y using an adversarial loss. Because this mapping is highly under-constrained, we couple it with an inverse mapping F : Y → X and introduce a cycle consistency loss to push F(G(X)) ≈ X (and vice versa). Qualitative results are presented on several tasks where paired training data does not exist, including collection style transfer, object transfiguration, season transfer, photo enhancement, etc. Quantitative comparisons against several prior methods demonstrate the superiority of our approach.","['Image translation', 'Image (mathematics)', 'Computer science', 'Translation (biology)', 'Artificial intelligence', 'Consistency (knowledge bases)', 'Adversarial system', 'Domain (mathematical analysis)', 'Set (abstract data type)', 'Object (grammar)', 'Computer vision', 'Computer graphics', 'Pattern recognition (psychology)', 'Mathematics', 'Mathematical analysis', 'Biochemistry', 'Chemistry', 'Messenger RNA', 'Gene', 'Programming language']","graphics problems, aligned image pairs, paired training data, adversarial loss, inverse mapping, cycle consistency loss, paired training data, collection style transfer, object transfiguration, season transfer, photo enhancement, [PAD] [PAD], [PAD] [PAD] [PAD], [PAD], [PAD]"
Paper_00434,Meta-analysis of Observational Studies in Epidemiology&lt;SUBTITLE&gt;A Proposal for Reporting&lt;/SUBTITLE&gt;,['Donna F. Stroup'],2000,JAMA,Journal,,2008-2008,283,15,10.1001/jama.283.15.2008,"Because of the pressure for timely, informed decisions in public health and clinical practice and the explosion of information in the scientific literature, research results must be synthesized. Meta-analyses are increasingly used to address this problem, and they often evaluate observational studies. A workshop was held in Atlanta, Ga, in April 1997, to examine the reporting of meta-analyses of observational studies and to make recommendations to aid authors, reviewers, editors, and readers.Twenty-seven participants were selected by a steering committee, based on expertise in clinical practice, trials, statistics, epidemiology, social sciences, and biomedical editing. Deliberations of the workshop were open to other interested scientists. Funding for this activity was provided by the Centers for Disease Control and Prevention.We conducted a systematic review of the published literature on the conduct and reporting of meta-analyses in observational studies using MEDLINE, Educational Research Information Center (ERIC), PsycLIT, and the Current Index to Statistics. We also examined reference lists of the 32 studies retrieved and contacted experts in the field. Participants were assigned to small-group discussions on the subjects of bias, searching and abstracting, heterogeneity, study categorization, and statistical methods.From the material presented at the workshop, the authors developed a checklist summarizing recommendations for reporting meta-analyses of observational studies. The checklist and supporting evidence were circulated to all conference attendees and additional experts. All suggestions for revisions were addressed.The proposed checklist contains specifications for reporting of meta-analyses of observational studies in epidemiology, including background, search strategy, methods, results, discussion, and conclusion. Use of the checklist should improve the usefulness of meta-analyses for authors, reviewers, editors, readers, and decision makers. An evaluation plan is suggested and research areas are explored.","['Observational study', 'Checklist', 'Strengthening the reporting of observational studies in epidemiology', 'Medicine', 'Systematic review', 'MEDLINE', 'Medical education', 'Meta-analysis', 'Family medicine', 'Subtitle', 'Categorization', 'Psychology', 'Pathology', 'Computer science', 'Political science', 'Artificial intelligence', 'Law', 'Cognitive psychology', 'Operating system']","public health, clinical practice, observational studies, ##al studies, clinical practice, statistics, epidemi, social sciences, biomedical editing, observational studies, medline, educational research information center, psyclit, bias, heterogeneity, study categorization, statistical methods, epidemiology, search"
Paper_00437,"Culture and the self: Implications for cognition, emotion, and motivation.","['Hazel Rose Markus', 'Shinobu Kitayama']",1991,Psychological Review,Journal,,224-253,98,2,10.1037/0033-295x.98.2.224,"People in different cultures have strikingly different construals of the self, of others, and of the interdependence of the 2. These construals can influence, and in many cases determine, the very nature of individual experience, including cognition, emotion, and motivation. Many Asian cultures have distinct conceptions of individuality that insist on the fundamental relatedness of individuals to each other. The emphasis is on attending to others, fitting in, and harmonious interdependence with them. American culture neither assumes nor values such an overt connectedness among individuals. In contrast, individuals seek to maintain their independence from others by attending to the self and by discovering and expressing their unique inner attributes. As proposed herein, these construals are even more powerful than previously imagined. Theories of the self from both psychology and anthropology are integrated to define in detail the difference between a construal of the self as independent and a construal of the self as interdependent. Each of these divergent construals should have a set of specific consequences for cognition, emotion, and motivation; these consequences are proposed and relevant empirical literature is reviewed. Focusing on differences in self-construals enables apparently inconsistent empirical findings to be reconciled, and raises questions about what have been thought to be culture-free aspects of cognition, emotion, and motivation.","['Psychology', 'Cognition', 'Cognitive psychology', 'Perception', 'Social psychology', 'Neuroscience']","individual experience, emotion, motivation, asian cultures, individual, american culture, self, psychology, anthropology"
Paper_00439,Qualitative Data Analysis: A Methods Sourcebook,"['Matthew B. Miles', 'A. Michael Huberman', 'Johnny Saldaña']",1988,['German Journal of Human Resource Management: Zeitschrift für Personalforschung'],Unknown,,485-487,28,4,10.1177/239700221402800402,Contents List of Displays Preface to the Third Edition by Johnny Saldana Acknowledgements from the Second Edition by Matthew B. Miles and A. Michael Huberman About the Authors PART I. THE SUBSTANTIVE START 1. Introduction 2. Research Design and Management 3. Ethical Issues in Analysis 4. Fundamentals of Qualitative Data Analysis PART II. DISPLAYING THE DATA 5. Designing Matrix and Network Displays 6. Methods of Exploring 7. Methods of Describing 8. Methods of Ordering 9. Methods of Explaining 10. Methods of Predicting PART III: MAKING GOOD SENSE 11. Drawing and Verifying Conclusions 12. Writing About Qualitative Research 13. Closure Appendix - An Annotated Bibliography of Qualitative Research Resources References Index,"['Qualitative research', 'Qualitative property', 'Index (typography)', 'Qualitative analysis', 'Computer science', 'Closure (psychology)', 'Sociology', 'Social science', 'World Wide Web', 'Political science', 'Law', 'Machine learning']","substantive, research design, management, ethical issues, analysis, qualitative data analysis, network displays, qualitative research, closure, ##ted, qualitative research resources, [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"
Paper_00441,"Cancer statistics, 2019","['Rebecca L. Siegel', 'Kimberly D. Miller', 'Ahmedin Jemal']",2019,CA A Cancer Journal for Clinicians,Journal,,7-34,69,1,10.3322/caac.21551,"Each year, the American Cancer Society estimates the numbers of new cancer cases and deaths that will occur in the United States and compiles the most recent data on cancer incidence, mortality, and survival. Incidence data, available through 2015, were collected by the Surveillance, Epidemiology, and End Results Program; the National Program of Cancer Registries; and the North American Association of Central Cancer Registries. Mortality data, available through 2016, were collected by the National Center for Health Statistics. In 2019, 1,762,450 new cancer cases and 606,880 cancer deaths are projected to occur in the United States. Over the past decade of data, the cancer incidence rate (2006-2015) was stable in women and declined by approximately 2% per year in men, whereas the cancer death rate (2007-2016) declined annually by 1.4% and 1.8%, respectively. The overall cancer death rate dropped continuously from 1991 to 2016 by a total of 27%, translating into approximately 2,629,200 fewer cancer deaths than would have been expected if death rates had remained at their peak. Although the racial gap in cancer mortality is slowly narrowing, socioeconomic inequalities are widening, with the most notable gaps for the most preventable cancers. For example, compared with the most affluent counties, mortality rates in the poorest counties were 2-fold higher for cervical cancer and 40% higher for male lung and liver cancers during 2012-2016. Some states are home to both the wealthiest and the poorest counties, suggesting the opportunity for more equitable dissemination of effective cancer prevention, early detection, and treatment strategies. A broader application of existing cancer control knowledge with an emphasis on disadvantaged groups would undoubtedly accelerate progress against cancer.","['Cancer', 'Medicine', 'Demography', 'Mortality rate', 'Epidemiology', 'Cervical cancer', 'Lung cancer', 'Socioeconomic status', 'Incidence (geometry)', 'Cancer incidence', 'Liver cancer', 'Epidemiology of cancer', 'Cause of death', 'Gerontology', 'Population', 'Environmental health', 'Surgery', 'Oncology', 'Disease', 'Internal medicine', 'Breast cancer', 'Physics', 'Sociology', 'Optics']","american cancer society, end results, cancer registries, central cancer registries, women, cancer death, racial, cancer mortality, socio, cervical cancer, cancer control"
Paper_00442,"Black Feminist Thought: Knowledge, Consciousness, and the Politics of Empowerment.","['Rose M. Brewer', 'Patrícia Hill Collins']",1992,Contemporary Sociology A Journal of Reviews,Journal,,132-132,21,1,10.2307/2074808,"In spite of the double burden of racial and gender discrimination, African-American women have developed a rich intellectual tradition that is not widely known. In Black Feminist Thought, Patricia Hill Collins explores the words and ideas of Black feminist intellectuals as well as those African-American women outside academe. She provides an interpretive framework for the work of such prominent Black feminist thinkers as Angela Davis, bell hooks, Alice Walker, and Audre Lorde. The result is a superbly crafted book that provides the first synthetic overview of Black feminist thought.","['Consciousness', 'Empowerment', 'Politics', 'Sociology', 'Critical consciousness', 'Gender studies', 'Political science', 'Epistemology', 'Philosophy', 'Law', 'Pedagogy']","gender discrimination, black feminist thought, black feminist intellectuals, black feminist thinkers, black feminist thought, [PAD] [PAD]"
Paper_00443,Fuzzy identification of systems and its applications to modeling and control,"['Tomohiro Takagi', 'Michio Sugeno']",1985,IEEE Transactions on Systems Man and Cybernetics,Journal,,116-132,SMC-15,1,10.1109/tsmc.1985.6313399,A mathematical tool to build a fuzzy model of a system where fuzzy implications and reasoning are used is presented in this paper. The premise of an implication is the description of fuzzy subspace of inputs and its consequence is a linear input-output relation. The method of identification of a system using its input-output data is then shown. Two applications of the method to industrial processes are also discussed: a water cleaning process and a converter in a steel-making process.,"['Identification (biology)', 'Fuzzy control system', 'Relation (database)', 'Fuzzy logic', 'Subspace topology', 'Computer science', 'Process (computing)', 'Neuro-fuzzy', 'Premise', 'Fuzzy set operations', 'Control engineering', 'Control (management)', 'Artificial intelligence', 'Control theory (sociology)', 'Mathematics', 'Data mining', 'Engineering', 'Botany', 'Biology', 'Linguistics', 'Philosophy', 'Operating system']","mathematical, fuzzy model, fuzzy implications, reasoning, fuzzy subspace, industrial processes, water cleaning process, [PAD]"
Paper_00446,The need to belong: Desire for interpersonal attachments as a fundamental human motivation.,"['Roy F. Baumeister', 'Mark R. Leary']",1995,Psychological Bulletin,Journal,,497-529,117,3,10.1037/0033-2909.117.3.497,"A hypothesized need to form and maintain strong, stable interpersonal relationships is evaluated in light of the empirical literature. The need is for frequent, nonaversive interactions within an ongoing relational bond. Consistent with the belongingness hypothesis, people form social attachments readily under most conditions and resist the dissolution of existing bonds. Belongingness appears to have multiple and strong effects on emotional patterns and on cognitive processes. Lack of attachments is linked to a variety of ill effects on health, adjustment, and well-being. Other evidence, such as that concerning satiation, substitution, and behavioral consequences, is likewise consistent with the hypothesized motivation. Several seeming counterexamples turned out not to disconfirm the hypothesis. Existing evidence supports the hypothesis that the need to belong is a powerful, fundamental, and extremely pervasive motivation.","['Belongingness', 'Psychology', 'Interpersonal communication', 'Social psychology', 'Variety (cybernetics)', 'Interpersonal relationship', 'Cognition', 'Empirical research', 'Cognitive psychology', 'Epistemology', 'Philosophy', 'Neuroscience', 'Artificial intelligence', 'Computer science']","interpersonal relationships, ##aversive, relational bond, belongingness hypothesis, social attachments, belongingness, cognitive processes, satiation, substitution, behavioral consequences"
Paper_00448,The Competitive Advantage of Nations,"['Terry Clark', 'Michael Porter']",1991,Journal of Marketing,Journal,,118-118,55,4,10.2307/1251962,The Need for a New Paradigm - PART I: FOUNDATIONS - The Competitive Advantage of Firms in Global Industries - Determinants of National Competitive Advantage - The Dynamics of National Advantage - PART II: INDUSTRIES - Four Studies in National Competitive Advantage - National Competitive Advantage in Services - PART III: NATIONS - Patterns of National Competitive Advantage: The Early Postwar Winners - Emerging Nations in the 1970s and 1980s - Shifting National Advantage - The Competitive Development of National Economies - PART IV: IMPLICATIONS - Company Strategy - Government Policy - National Agendas - Epilogue - Appendices - References,"['Competitive advantage', 'Comparative advantage', 'Government (linguistics)', 'Business', 'Industrial organization', 'Revealed comparative advantage', 'International trade', 'Economics', 'Marketing', 'Linguistics', 'Philosophy']","competitive advantage, global industries, national competitive advantage, national advantage, national competitive advantage, national competitive advantage, services, national competitive advantage, national advantage, national economies, [PAD] [PAD], [PAD] [PAD], [PAD] [PAD]"
Paper_00449,Optical Constants of the Noble Metals,"['P. B. Johnson', 'R. W. Christy']",1972,"Physical review. B, Solid state",Journal,,4370-4379,6,12,10.1103/physrevb.6.4370,"The optical constants $n$ and $k$ were obtained for the noble metals (copper, silver, and gold) from reflection and transmission measurements on vacuum-evaporated thin films at room temperature, in the spectral range 0.5-6.5 eV. The film-thickness range was 185-500 \AA{}. Three optical measurements were inverted to obtain the film thickness $d$ as well as $n$ and $k$. The estimated error in $d$ was \ifmmode\pm\else\textpm\fi{} 2 \AA{}, and that in $n$, $k$ was less than 0.02 over most of the spectral range. The results in the film-thickness range 250-500 \AA{} were independent of thickness, and were unchanged after vacuum annealing or aging in air. The free-electron optical effective masses and relaxation times derived from the results in the near infrared agree satisfactorily with previous values. The interband contribution to the imaginary part of the dielectric constant was obtained by subtracting the free-electron contribution. Some recent theoretical calculations are compared with the results for copper and gold. In addition, some other recent experiments are critically compared with our results.","['Materials science', 'Copper', 'Dielectric', 'Annealing (glass)', 'Range (aeronautics)', 'Relaxation (psychology)', 'Reflection (computer programming)', 'Infrared', 'Free electron model', 'Condensed matter physics', 'Optics', 'Atomic physics', 'Analytical Chemistry (journal)', 'Physics', 'Chemistry', 'Optoelectronics', 'Metallurgy', 'Laser', 'Psychology', 'Social psychology', 'Chromatography', 'Computer science', 'Composite material', 'Programming language']","optical constant, noble metals, transmission, optical measurements, film, vacuum annealing, near infrared, interband contribution"
Paper_00450,A Theory of Social Comparison Processes,['Léon Festinger'],1954,Human Relations,Journal,,117-140,7,2,10.1177/001872675400700202,"Hypothesis I: There exists, in the human organism, a drive to evaluate his opinions and his abilities. While opinions and abilities may, at first glance, seem to be quite different things, there is a close functional tie between them. They act together in the manner in which they affect behavior. A person’s cognition (his opinions and beliefs) about the situation in which he exists and his appraisals of what he is capable of doing (his evaluation of his abilities) will together have bearing on his behavior. The holding of incorrect opinions and/or inaccurate appraisals of one’s abilities can be punishing or even fatal in many situations. It is necessary, before we proceed, to clarify the distinction between opinions and evaluations of abilities since at first glance it may seem that one’s evaluation of one’s own ability is an opinion about it. Abilities are of course manifested only through performance which is assumed to depend upon the particular ability. The clarity of the manifestation or performance can vary from instances where there is no clear ordering criterion of the ability to instances where the performance which reflects the ability can be clearly ordered. In the former case, the evaluation of the ability does function like other opinions which are not directly testable in “objective reality’. For example, a person’s evaluation of his ability to write poetry will depend to a large extent on the opinions which others have of his ability to write poetry. In cases where the criterion is unambiguous and can be clearly ordered, this furnishes an objective reality for the evaluation of one’s ability so that it depends less on the opinions of other persons and depends more on actual comparison of one’s performance with the performance of others. Thus, if a person evaluates his running ability, he will do so by comparing his time to run some distance with the times that other persons have taken. In the following pages, when we talk about evaluating an ability, we shall mean specifically the evaluation of that ability in situations where the performance is unambiguous and is known. Most situations in real life will, of course, present situations which are a mixture of opinion and ability evaluation. In a previous article (7) the author posited the existence of a drive to determine whether or not one’s opinions were “correct”. We are here stating that this same drive also produces behavior in people oriented toward obtaining an accurate appraisal of their abilities. The behavioral implication of the existence of such a drive is that we would expect to observe behaviour on the part of persons which enables them to ascertain whether or not their opinions are correct and also behavior which enables them accurately to evaluate their abilities. It is consequently","['Psychology', 'CLARITY', 'Function (biology)', 'Affect (linguistics)', 'Cognition', 'Social psychology', 'Cognitive psychology', 'Communication', 'Biochemistry', 'Chemistry', 'Evolutionary biology', 'Neuroscience', 'Biology']",objective reality
Paper_00453,Numerical recipes in C: the art of scientific computing,[],1993,Choice Reviews Online,Journal,,30-5638,30,10,10.5860/choice.30-5638,"From the Publisher:
This is the revised and greatly expanded Second Edition of the hugely popular Numerical Recipes: The Art of Scientific Computing. The product of a unique collaboration among four leading scientists in academic research and industry, Numerical Recipes is a complete text and reference book on scientific computing. In a self-contained manner it proceeds from mathematical and theoretical considerations to actual practical computer routines. With over 100 new routines (now well over 300 in all), plus upgraded versions of many of the original routines, this book is more than ever the most practical, comprehensive handbook of scientific computing available today. The book retains the informal, easy-to-read style that made the first edition so popular, with many new topics presented at the same accessible level. In addition, some sections of more advanced material have been introduced, set off in small type from the main body of the text. Numerical Recipes is an ideal textbook for scientists and engineers and an indispensable reference for anyone who works in scientific computing. Highlights of the new material include a new chapter on integral equations and inverse methods; multigrid methods for solving partial differential equations; improved random number routines; wavelet transforms; the statistical bootstrap method; a new chapter on less-numerical algorithms including compression coding and arbitrary precision arithmetic; band diagonal linear systems; linear algebra on sparse matrices; Cholesky and QR decomposition; calculation of numerical derivatives; Pade approximants, and rational Chebyshev approximation; new special functions; Monte Carlo integration in high-dimensional spaces; globally convergent methods for sets of nonlinear equations; an expanded chapter on fast Fourier methods; spectral analysis on unevenly sampled data; Savitzky-Golay smoothing filters; and two-dimensional Kolmogorov-Smirnoff tests. All this is in addition to material on such basic top",['Computer science'],"numerical recipes, scientific computing, numerical recipes, scientific computing, scientific computing, numerical recipes, scientific computing, integral equations, inverse methods, multigrid methods, partial differential equations, random number routines, wavelet transforms, statistical bootstrap method, compression coding, arbitrary precision arithmetic, band diagonal linear systems, linear algebra, sparse matrices, ##lesky, qr decomposition, numerical derivatives, pade approximants, rational chebyshev approximation, monte carlo integration, globally convergent methods, nonlinear equations, fast fourier methods, spectral analysis, unevenly sampled data, [PAD], [PAD] [PAD]"
Paper_00454,The Theory of Economic Development,['Joseph A. Schumpeter'],2017,Routledge eBooks,Unknown,,,,,10.4324/9781315135564,"Buku ini memberikan infmasi tentang aliran melingkar kehidupan ekonomi sebagaimana dikondisikan oleh keadaan tertentu, fenomena fundamental dari pembangunan ekonomi, kredit dan modal, laba wirausaha, bunga atas modal, dan siklus bisnis.","['Development (topology)', 'Economics', 'Mathematics', 'Mathematical analysis']","member, ##fm, ek, ##kondis, fenomena, [PAD]"
Paper_00455,Multivariate Data Analysis,"['Jürgen W. Einax', 'Heinz W. Zwanziger', 'Sabine Geiß']",1997,Unknown,Unknown,,139-203,,,10.1002/352760216x.ch5,This chapter contains sections titled: General Remarks Graphical Methods of Data Presentation Introduction Transformation Visualization of Similar Features – Correlations Similar Objects or Groups of Objects Nesting Techniques Star Plots Pictoral Representation Functional Representation Representation of Groups Box-Whisker Plots Multiple Box-Whisker Plots Limitations Cluster Analysis Objectives of Cluster Analysis Similarity Measures and Data Preprocessing Clustering Algorithms CA Calculations Demonstrated with a Simple Example Typical CA Results Illustrated with an Extended Example Principal Components Analysis and Factor Analysis Description of Principal Components Analysis PCA Calculations Demonstrated with a Simple Example Description of Factor Analysis Typical FA Results Illustrated with an Extended Example Canonical Correlation Analysis Description of Canonical Correlation Analysis Typical CCA Results Illustrated with an Extended Example Multivariate Analysis of Variance and Discriminant Analysis General Description DA Calculations Demonstrated with a Simple Example Typical DA Results Illustrated with an Extended Example Multivariate Modeling of Causal Dependencies Multiple Regression Partial Least Squares Method Simultaneous Equations and Path Analysis,"['Canonical correlation', 'Principal component analysis', 'Correspondence analysis', 'Cluster analysis', 'Multivariate statistics', 'Path analysis (statistics)', 'Representation (politics)', 'Linear discriminant analysis', 'Multiple correspondence analysis', 'Multivariate analysis of variance', 'Mathematics', 'Computer science', 'Preprocessor', 'Data mining', 'Statistics', 'Artificial intelligence', 'Politics', 'Political science', 'Law']","data presentation, transformation visualization, correlation, nesting techniques star plots pictoral representation, cluster analysis, cluster analysis similarity measures, data preprocessing, principal components analysis, factor analysis, principal components analysis, factor analysis, canonical correlation analysis, canonical correlation analysis, multivariate analysis, discriminant analysis, multivariate modeling, causal dependencies multiple regression partial least squares method simultaneous equations, path analysis"
Paper_00456,Applied Regression Analysis,"['Norman R. Draper', 'Harry Smith']",2005,Technometrics,Journal,,380-380,47,3,10.1198/tech.2005.s303,"Basic Prerequisite Knowledge. Fitting a Straight Line by Least Squares. Checking the Straight Line Fit. Fitting Straight Lines: Special Topics. Regression in Matrix Terms: Straight Line Case. The General Regression Situation. Extra Sums of Squares and Tests for Several Parameters Being Zero. Serial Correlation in the Residuals and the Durbin--Watson Test. More of Checking Fitted Models. Multiple Regression: Special Topics. Bias in Regression Estimates, and Expected Values of Mean Squares and Sums of Squares. On Worthwhile Regressions, Big F's, and R 2 . Models Containing Functions of the Predictors, Including Polynomial Models. Transformation of the Response Variable. Dummy Variables. Selecting the Best Regression Equation. Ill--Conditioning in Regression Data. Ridge Regression. Generalized Linear Models (GLIM). Mixture Ingredients as Predictor Variables. The Geometry of Least Squares. More Geometry of Least Squares. Orthogonal Polynomials and Summary Data. Multiple Regression Applied to Analysis of Variance Problems. An Introduction to Nonlinear Estimation. Robust Regression. Resampling Procedures (Bootstrapping). Bibliography. True/False Questions. Answers to Exercises. Tables. Indexes.","['Statistics', 'Regression analysis', 'Regression', 'Econometrics', 'Mathematics', 'Computer science']","matrix terms, general regression situation, serial correlation, multiple regression, regression estimates, expected values, worthwhile regressions, polynomial models, ridge regression, generalized linear models, glim, predictor, geometry, least squares, least squares, orthogonal polynomials, summary data, multiple regression, variance problems, nonlinear estimation, robust regression, resampling, bootstrapping, index"
Paper_00457,NMNH Extant Specimen Records,['Thomas Orrell'],2017,Unknown,Unknown,,,,,10.15468/hnhrg3,"Public records of accessioned specimens and observations curated by the National Museum of Natural History, Smithsonian Institution. These data are from the Departments of Botany, Entomology, Invertebrate Zoology and Vertebrate Zoology (Amphibians & Reptiles, Birds, Fishes, and Mammals) and include more than 270,000 primary type specimen records.","['Extant taxon', 'Natural history', 'Zoology', 'Vertebrate', 'National Museum of Natural History', 'Geography', 'Biology', 'Archaeology', 'Ecology', 'Evolutionary biology', 'Biochemistry', 'Gene']","accessioned specimens, entom, invertebrate zoology, ##rtebrate zoology, [PAD], [PAD] [PAD], [PAD], [PAD], [PAD], [PAD], [PAD] [PAD], [PAD] [PAD], [PAD] [PAD] [PAD] [PAD], [PAD] [PAD], [PAD], [PAD] [PAD] [PAD]"
Paper_00459,<i>WinGX</i>suite for small-molecule single-crystal crystallography,['Louis J. Farrugia'],1999,Journal of Applied Crystallography,Journal,,837-838,32,4,10.1107/s0021889899006020,"The category Computer Program Abstracts provides a rapid means of communicating up-to-date information concerning both new programs or systems and signi®cant updates to existing ones. Following normal submission, a Computer Program Abstract will be reviewed by one or two members of the IUCr Commission on Crystallographic Computing. It should not exceed 500 words in length and should follow the standard format given on page 189 of the June 1985 issue of the Journal [J. Appl. Cryst. (1985). 18, 189± 190] and on the World Wide Web at http://www.iucr. org/journals/jac/software/. Lists of software presented and/or reviewed in the Journal of Applied Crystallography are available on the World Wide Web at the above address, together with information about the availability of the software where this is known.","['Suite', 'Computer science', 'Software', 'World Wide Web', 'Information retrieval', 'Crystallography', 'Library science', 'Programming language', 'Chemistry', 'Geography', 'Archaeology']","computer program abstracts, ##i, computer program, iucr, crystallographic computing, applied crystallography"
Paper_00460,Social Network Analysis: Methods and Applications,"['Stanley Wasserman', 'Katherine Faust']",1994,['Contemporary Sociology'],Unknown,,275,25,2,10.2307/2077235,"Part I. Introduction: Networks, Relations, and Structure: 1. Relations and networks in the social and behavioral sciences 2. Social network data: collection and application Part II. Mathematical Representations of Social Networks: 3. Notation 4. Graphs and matrixes Part III. Structural and Locational Properties: 5. Centrality, prestige, and related actor and group measures 6. Structural balance, clusterability, and transitivity 7. Cohesive subgroups 8. Affiliations, co-memberships, and overlapping subgroups Part IV. Roles and Positions: 9. Structural equivalence 10. Blockmodels 11. Relational algebras 12. Network positions and roles Part V. Dyadic and Triadic Methods: 13. Dyads 14. Triads Part VI. Statistical Dyadic Interaction Models: 15. Statistical analysis of single relational networks 16. Stochastic blockmodels and goodness-of-fit indices Part VII. Epilogue: 17. Future directions.","['Transitive relation', 'Centrality', 'Social network analysis', 'Prestige', 'Notation', 'Equivalence (formal languages)', 'Social network (sociolinguistics)', 'Social relation', 'Computer science', 'Psychology', 'Social psychology', 'Mathematics', 'Discrete mathematics', 'Combinatorics', 'Linguistics', 'World Wide Web', 'Philosophy', 'Arithmetic', 'Social media']","social network data, mathematical representations, social networks, notation, graphs, matrixes, locational properties, centrality, prestige, group measures, structural balance, clusterability, transitivity, cohesive subgroups, affiliations, overlapping subgroups, structural equivalence, blockmodel, relational algebras, network positions, triadic methods, dyads, triads, statistical dyadic interaction models, statistical analysis, single relational networks, stochastic blockmodels"
Paper_00461,The mathematics of diffusion,['John Crank'],1956,['Kinetic Processes'],Unknown,,75-96,,,10.1002/3527603891.ch7,"Though it incorporates much new material, this new edition preserves the general character of the book in providing a collection of solutions of the equations of diffusion and describing how these solutions may be obtained.","['Character (mathematics)', 'Diffusion', 'Calculus (dental)', 'Mathematics', 'Computer science', 'Physics', 'Thermodynamics', 'Geometry', 'Medicine', 'Dentistry']",diffusion
Paper_00462,Sensitivity and False Alarm Rate of a Fall Sensor in Long-Term Fall Detection in the Elderly,"['Maarit Kangas', 'Raija Korpelainen', 'Irene Vikman', 'Lars Nyberg', 'Timo Jämsä']",2014,Gerontology,Journal,,61-68,61,1,10.1159/000362720,"Elderly patients unable to get up after a fall or to activate an alarm mechanism are particularly at risk of complications and need to be monitored with extreme care. The different risk factors have fostered the development of stand-alone devices facilitating early detection of falls. We aimed at assessing performance of the Vigi'Fall(®) system, a cutting edge fall detector associating a ""passive release"" mechanism attached to the patient and including external sensors; in the event of a fall, the system automatically triggers an alarm, and it also incorporates embedded confirmation software. We have put it to the test under real-life conditions so as to evaluate not only its efficacy, but also and more particularly its acceptability and tolerability in elderly subjects.The study ran from March 2007 through December 2008 in a geriatric ward with 10 subjects over 75 years of age, all of whom presented with a risk of falling.For eight patients wearing an accelerometric sensor, eight ""falling"" events and 30 ""alarm release"" events were recorded. Sensitivity and specificity of the device came to 62.5 and 99.5% respectively. For the two patients wearing the complete device, no events were detected. Not a single adverse occurrence was noted. Local tolerance was excellent in all but one of the subjects.Our results clearly show that the device may be worn by patients without discomfort over prolonged periods of time, and also demonstrate that the verification component will help to increase sensitivity in real-life conditions to a level comparable to the level attained in our laboratory studies.","['ALARM', 'Falling (accident)', 'Medicine', 'False alarm', 'Tolerability', 'Physical medicine and rehabilitation', 'Adverse effect', 'Poison control', 'Medical emergency', 'Computer science', 'Internal medicine', 'Artificial intelligence', 'Engineering', 'Environmental health', 'Aerospace engineering']","cutting edge fall detector, passive release, embedded confirmation software, geriatric ward, accelerometric sensor, alarm, local tolerance, verification"
Paper_00463,HTSeq—a Python framework to work with high-throughput sequencing data,"['Simon Anders', 'Paul Theodor Pyl', 'Wolfgang Huber']",2014,Bioinformatics,Journal,,166-169,31,2,10.1093/bioinformatics/btu638,"Abstract Motivation: A large choice of tools exists for many standard tasks in the analysis of high-throughput sequencing (HTS) data. However, once a project deviates from standard workflows, custom scripts are needed. Results: We present HTSeq, a Python library to facilitate the rapid development of such scripts. HTSeq offers parsers for many common data formats in HTS projects, as well as classes to represent data, such as genomic coordinates, sequences, sequencing reads, alignments, gene model information and variant calls, and provides data structures that allow for querying via genomic coordinates. We also present htseq-count, a tool developed with HTSeq that preprocesses RNA-Seq data for differential expression analysis by counting the overlap of reads with genes. Availability and implementation: HTSeq is released as an open-source software under the GNU General Public Licence and available from http://www-huber.embl.de/HTSeq or from the Python Package Index at https://pypi.python.org/pypi/HTSeq . Contact: sanders@fs.tum.de","['Python (programming language)', 'Computer science', 'Scripting language', 'Workflow', 'Programming language', 'Software', 'Parsing', 'Operating system', 'Data mining', 'Database']","htseq, python library, htseq, genomic coordinates, sequences, sequencing reads, alignments, gene model information, variant calls, genomic coordinates, ##tseq, differential expression analysis, htseq, python package, [PAD] [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD], [PAD], [PAD] [PAD] [PAD], [PAD], [PAD], [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD], [PAD], [PAD] [PAD], [PAD], [PAD] [PAD] [PAD] [PAD], [PAD]"
Paper_00464,"Cancer statistics, 2020","['Rebecca L. Siegel', 'Kimberly D. Miller', 'Ahmedin Jemal']",2020,CA A Cancer Journal for Clinicians,Journal,,7-30,70,1,10.3322/caac.21590,"Abstract Each year, the American Cancer Society estimates the numbers of new cancer cases and deaths that will occur in the United States and compiles the most recent data on population‐based cancer occurrence. Incidence data (through 2016) were collected by the Surveillance, Epidemiology, and End Results Program; the National Program of Cancer Registries; and the North American Association of Central Cancer Registries. Mortality data (through 2017) were collected by the National Center for Health Statistics. In 2020, 1,806,590 new cancer cases and 606,520 cancer deaths are projected to occur in the United States. The cancer death rate rose until 1991, then fell continuously through 2017, resulting in an overall decline of 29% that translates into an estimated 2.9 million fewer cancer deaths than would have occurred if peak rates had persisted. This progress is driven by long‐term declines in death rates for the 4 leading cancers (lung, colorectal, breast, prostate); however, over the past decade (2008‐2017), reductions slowed for female breast and colorectal cancers, and halted for prostate cancer. In contrast, declines accelerated for lung cancer, from 3% annually during 2008 through 2013 to 5% during 2013 through 2017 in men and from 2% to almost 4% in women, spurring the largest ever single‐year drop in overall cancer mortality of 2.2% from 2016 to 2017. Yet lung cancer still caused more deaths in 2017 than breast, prostate, colorectal, and brain cancers combined. Recent mortality declines were also dramatic for melanoma of the skin in the wake of US Food and Drug Administration approval of new therapies for metastatic disease, escalating to 7% annually during 2013 through 2017 from 1% during 2006 through 2010 in men and women aged 50 to 64 years and from 2% to 3% in those aged 20 to 49 years; annual declines of 5% to 6% in individuals aged 65 years and older are particularly striking because rates in this age group were increasing prior to 2013. It is also notable that long‐term rapid increases in liver cancer mortality have attenuated in women and stabilized in men. In summary, slowing momentum for some cancers amenable to early detection is juxtaposed with notable gains for other common cancers.","['Medicine', 'Colorectal cancer', 'Cancer', 'Prostate cancer', 'Breast cancer', 'Demography', 'Lung cancer', 'Population', 'Mortality rate', 'Epidemiology', 'Epidemiology of cancer', 'Incidence (geometry)', 'Health statistics', 'Gerontology', 'Oncology', 'Internal medicine', 'Environmental health', 'Physics', 'Sociology', 'Optics']","american cancer society, central cancer registries, lung cancer, metastatic, liver cancer mortality"
Paper_00465,RSEM: accurate transcript quantification from RNA-Seq data with or without a reference genome,"['Bo Li', 'Colin N. Dewey']",2011,BMC Bioinformatics,Journal,,,12,1,10.1186/1471-2105-12-323,"RNA-Seq is revolutionizing the way transcript abundances are measured. A key challenge in transcript quantification from RNA-Seq data is the handling of reads that map to multiple genes or isoforms. This issue is particularly important for quantification with de novo transcriptome assemblies in the absence of sequenced genomes, as it is difficult to determine which transcripts are isoforms of the same gene. A second significant issue is the design of RNA-Seq experiments, in terms of the number of reads, read length, and whether reads come from one or both ends of cDNA fragments. We present RSEM, an user-friendly software package for quantifying gene and isoform abundances from single-end or paired-end RNA-Seq data. RSEM outputs abundance estimates, 95% credibility intervals, and visualization files and can also simulate RNA-Seq data. In contrast to other existing tools, the software does not require a reference genome. Thus, in combination with a de novo transcriptome assembler, RSEM enables accurate transcript quantification for species without sequenced genomes. On simulated and real data sets, RSEM has superior or comparable performance to quantification methods that rely on a reference genome. Taking advantage of RSEM's ability to effectively use ambiguously-mapping reads, we show that accurate gene-level abundance estimates are best obtained with large numbers of short single-end reads. On the other hand, estimates of the relative frequencies of isoforms within single genes may be improved through the use of paired-end reads, depending on the number of possible splice forms for each gene. RSEM is an accurate and user-friendly software tool for quantifying transcript abundances from RNA-Seq data. As it does not rely on the existence of a reference genome, it is particularly useful for quantification with de novo transcriptome assemblies. In addition, RSEM has enabled valuable guidance for cost-efficient design of quantification experiments with RNA-Seq, which is currently relatively expensive.","['Computational biology', 'RNA-Seq', 'Genome', 'Biology', 'Reference genome', 'Gene', 'DNA microarray', 'Transcriptome', 'Genetics', 'Gene expression']","transcript abundances, de novo transcriptome assemblies, rsem, ##em, abundance estimates, credibility intervals, visualization, ##em, ##em, ##lice, ##em, ##em"
Paper_00466,"DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs","['Liang-Chieh Chen', 'George Papandreou', 'Iasonas Kokkinos', 'Kevin Murphy', 'Alan Yuille']",2017,IEEE Transactions on Pattern Analysis and Machine Intelligence,Journal,,834-848,40,4,10.1109/tpami.2017.2699184,"In this work we address the task of semantic image segmentation with Deep Learning and make three main contributions that are experimentally shown to have substantial practical merit. First, we highlight convolution with upsampled filters, or 'atrous convolution', as a powerful tool in dense prediction tasks. Atrous convolution allows us to explicitly control the resolution at which feature responses are computed within Deep Convolutional Neural Networks. It also allows us to effectively enlarge the field of view of filters to incorporate larger context without increasing the number of parameters or the amount of computation. Second, we propose atrous spatial pyramid pooling (ASPP) to robustly segment objects at multiple scales. ASPP probes an incoming convolutional feature layer with filters at multiple sampling rates and effective fields-of-views, thus capturing objects as well as image context at multiple scales. Third, we improve the localization of object boundaries by combining methods from DCNNs and probabilistic graphical models. The commonly deployed combination of max-pooling and downsampling in DCNNs achieves invariance but has a toll on localization accuracy. We overcome this by combining the responses at the final DCNN layer with a fully connected Conditional Random Field (CRF), which is shown both qualitatively and quantitatively to improve localization performance. Our proposed ""DeepLab"" system sets the new state-of-art at the PASCAL VOC-2012 semantic image segmentation task, reaching 79.7 percent mIOU in the test set, and advances the results on three other datasets: PASCAL-Context, PASCAL-Person-Part, and Cityscapes. All of our code is made publicly available online.","['Conditional random field', 'Artificial intelligence', 'Computer science', 'Pattern recognition (psychology)', 'Upsampling', 'Convolutional neural network', 'Pascal (unit)', 'Markov random field', 'Segmentation', 'Convolution (computer science)', 'CRFS', 'Image segmentation', 'Contextual image classification', 'Pooling', 'Object detection', 'Feature (linguistics)', 'Feature extraction', 'Image (mathematics)', 'Artificial neural network', 'Linguistics', 'Philosophy', 'Programming language']","semantic image segmentation, deep learning, convo, ##tion, upsampled filters, atrous convolution, dense prediction tasks, atrous convolution, deep convolutional neural networks, atrous spatial pyramid pooling, aspp, convolutional feature layer, object, dcnns, probabilistic graphical models, localization accuracy, fully connected conditional random field, localization performance, deep, semantic image segmentation task, cityscapes, [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"
Paper_00469,Absorption and Scattering of Light by Small Particles,"['Craig F. Bohren', 'Donald R. Huffman']",1998,Unknown,Unknown,,,,,10.1002/9783527618156,BASIC THEORY. Electromagnetic Theory. Absorption and Scattering by an Arbitrary Particle. Absorption and Scattering by a Sphere. Particles Small Compared with the Wavelength. Rayleigh--Gans Theory. Geometrical Optics. A Potpourri of Particles. OPTICAL PROPERTIES OF BULK MATTER. Classical Theories of Optical Constants. Measured Optical Properties. OPTICAL PROPERTIES OF PARTICLES. Extinction. Surface Modes in Small Particles. Angular Dependence of Scattering. A Miscellany of Applications. Appendices. References. Index.,"['Light scattering', 'Absorption (acoustics)', 'Scattering', 'Optics', 'Materials science', 'Physics']","electromagnetic theory, scattering, geometrical optics, potpourri, optical properties, bulk matter, classical theories, optical constants, measured optical properties, optical properties, extinction, surface modes, angular dependence, scattering, [PAD] [PAD], [PAD] [PAD] [PAD], [PAD], [PAD], [PAD] [PAD], [PAD] [PAD] [PAD], [PAD] [PAD], [PAD], [PAD] [PAD], [PAD]"
Paper_00470,van der Waals Volumes and Radii,['A. Bondì'],1964,The Journal of Physical Chemistry,Journal,,441-451,68,3,10.1021/j100785a001,"ADVERTISEMENT RETURN TO ISSUEArticleNEXTvan der Waals Volumes and RadiiA. BondiCite this: J. Phys. Chem. 1964, 68, 3, 441–451Publication Date (Print):March 1, 1964Publication History Published online1 May 2002Published inissue 1 March 1964https://pubs.acs.org/doi/10.1021/j100785a001https://doi.org/10.1021/j100785a001research-articleACS PublicationsRequest reuse permissionsArticle Views49041Altmetric-Citations16569LEARN ABOUT THESE METRICSArticle Views are the COUNTER-compliant sum of full text article downloads since November 2008 (both PDF and HTML) across all institutions and individuals. These metrics are regularly updated to reflect usage leading up to the last few days.Citations are the number of other articles citing this article, calculated by Crossref and updated daily. Find more information about Crossref citation counts.The Altmetric Attention Score is a quantitative measure of the attention that a research article has received online. Clicking on the donut icon will load a page at altmetric.com with additional details about the score and the social media presence for the given article. Find more information on the Altmetric Attention Score and how the score is calculated. Share Add toView InAdd Full Text with ReferenceAdd Description ExportRISCitationCitation and abstractCitation and referencesMore Options Share onFacebookTwitterWechatLinked InRedditEmail Other access options Get e-Alerts","['Citation', 'Icon', 'Social media', 'van der Waals force', 'Altmetrics', 'Computer science', 'Information retrieval', 'Physics', 'Data science', 'Library science', 'World Wide Web', 'Quantum mechanics', 'Molecule', 'Programming language']","##diia, permissionsarticle views, ##le, cross, ##f, cross, ##f, altmetric attention score, donut, social, altmetric attention score, reference, ##d, ##citation, abstract, ##ation, references, ##tter"
Paper_00472,MapReduce,"['Jay B. Dean', 'Sanjay Ghemawat']",2008,Communications of the ACM,Journal,,107-113,51,1,10.1145/1327452.1327492,"MapReduce is a programming model and an associated implementation for processing and generating large datasets that is amenable to a broad variety of real-world tasks. Users specify the computation in terms of a map and a reduce function, and the underlying runtime system automatically parallelizes the computation across large-scale clusters of machines, handles machine failures, and schedules inter-machine communication to make efficient use of the network and disks. Programmers find the system easy to use: more than ten thousand distinct MapReduce programs have been implemented internally at Google over the past four years, and an average of one hundred thousand MapReduce jobs are executed on Google's clusters every day, processing a total of more than twenty petabytes of data per day.","['Petabyte', 'Computer science', 'Computation', 'Variety (cybernetics)', 'Programming paradigm', 'Function (biology)', 'Parallel computing', 'Operating system', 'Distributed computing', 'Big data', 'Artificial intelligence', 'Programming language', 'Evolutionary biology', 'Biology']","mapreduce, reduce function, mapreduce, ##reduce"
Paper_00473,Neural networks and physical systems with emergent collective computational abilities.,['J. J. Hopfield'],1982,Proceedings of the National Academy of Sciences,Journal,,2554-2558,79,8,10.1073/pnas.79.8.2554,"Computational properties of use of biological organisms or to the construction of computers can emerge as collective properties of systems having a large number of simple equivalent components (or neurons). The physical meaning of content-addressable memory is described by an appropriate phase space flow of the state of a system. A model of such a system is given, based on aspects of neurobiology but readily adapted to integrated circuits. The collective properties of this model produce a content-addressable memory which correctly yields an entire memory from any subpart of sufficient size. The algorithm for the time evolution of the state of the system is based on asynchronous parallel processing. Additional emergent collective properties include some capacity for generalization, familiarity recognition, categorization, error correction, and time sequence retention. The collective properties are only weakly sensitive to details of the modeling or the failure of individual devices.","['Computer science', 'Asynchronous communication', 'Collective behavior', 'Generalization', 'Simple (philosophy)', 'Categorization', 'Content-addressable memory', 'Neural system', 'Artificial neural network', 'Physical system', 'State space', 'Meaning (existential)', 'Theoretical computer science', 'Artificial intelligence', 'Cognitive science', 'Neuroscience', 'Psychology', 'Sociology', 'Anthropology', 'Psychotherapist', 'Physics', 'Quantum mechanics', 'Mathematical analysis', 'Computer network', 'Philosophy', 'Statistics', 'Mathematics', 'Epistemology']","computational properties, biological organisms, computers, collective properties, phase space flow, neurobiology, integrated circuits, time evolution, asynchronous parallel processing, ##ization, familiarity recognition, categorization, error correction, time sequence retention"
Paper_00474,Deterministic Nonperiodic Flow,['Edward N. Lorenz'],1963,Journal of the Atmospheric Sciences,Journal,,130-141,20,2,10.1175/1520-0469(1963)020<0130:dnf>2.0.co;2,"Finite systems of deterministic ordinary nonlinear differential equations may be designed to represent forced dissipative hydrodynamic flow. Solutions of these equations can be identified with trajectories in phase space. For those systems with bounded solutions, it is found that nonperiodic solutions are ordinarily unstable with respect to small modifications, so that slightly differing initial states can evolve into considerably different states. Systems with bounded solutions are shown to possess bounded numerical solutions. A simple system representing cellular convection is solved numerically. All of the solutions are found to be unstable, and almost all of them are nonperiodic. The feasibility of very-long-range weather prediction is examined in the light of these results.","['Bounded function', 'Dissipative system', 'Ordinary differential equation', 'Nonlinear system', 'Flow (mathematics)', 'Simple (philosophy)', 'Mathematics', 'Mathematical analysis', 'Range (aeronautics)', 'Applied mathematics', 'Physics', 'Differential equation', 'Mechanics', 'Thermodynamics', 'Philosophy', 'Materials science', 'Epistemology', 'Quantum mechanics', 'Composite material']","finite systems, deterministic ordinary nonlinear differential equations, forced dissipative hydrodynamic flow, tr, ##ectories, phase space, bounded solutions, nonperiodic solutions, bounded solutions, bounded numerical solutions, cellular convection"
Paper_00475,Qualitative inquiry and research design: choosing among five traditions.,['John W. Creswell'],1998,['Health Promotion Practice'],Unknown,,473-475,16,4,10.1177/1524839915580941,"This book explores the philosophical underpinnings, history and key elements of five qualitative inquiry traditions: biography, phenomenology, grounded theory, ethnography and case study. John W Creswell relates research designs to each of the traditions of inquiry and compares each of the research strategies for theoretical frameworks, writing introduction to studies, collecting data, analyzing data, writing the narrative, and employing standards of quality and verifying results. Five journal articles in the appendix offer fascinating reading as well as examples of the five different qualitative designs.","['Qualitative research', 'Ethnography', 'Narrative', 'Phenomenology (philosophy)', 'Reading (process)', 'Biography', 'Epistemology', 'Grounded theory', 'Sociology', 'Pedagogy', 'Mathematics education', 'Social science', 'Psychology', 'Literature', 'Linguistics', 'Philosophy', 'Art', 'Anthropology']","philosophical, qualitative inquiry traditions, biography, phenomenology, grounded theory, ethnography, case study, ##alitative"
Paper_00479,Antibiotic Susceptibility Testing by a Standardized Single Disk Method,"['Alfred W. Bauer', 'William Kirby', 'J. C. Sherris', 'Marvin Turck']",1966,American Journal of Clinical Pathology,Journal,,493-496,45,4_ts,10.1093/ajcp/45.4_ts.493,"Journal Article Antibiotic Susceptibility Testing by a Standardized Single Disk Method Get access A. W. Bauer, M.D., A. W. Bauer, M.D. Departments of Microbiology and Medicine, University of Washington, School of Medicine, Seattle, Washington 98105 Search for other works by this author on: Oxford Academic Google Scholar W. M. M. Kirby, M.D., W. M. M. Kirby, M.D. Departments of Microbiology and Medicine, University of Washington, School of Medicine, Seattle, Washington 98105 Search for other works by this author on: Oxford Academic Google Scholar J. C. Sherris, M.D., J. C. Sherris, M.D. Departments of Microbiology and Medicine, University of Washington, School of Medicine, Seattle, Washington 98105 Search for other works by this author on: Oxford Academic Google Scholar M. Turck, M.D. M. Turck, M.D. Departments of Microbiology and Medicine, University of Washington, School of Medicine, Seattle, Washington 98105 Search for other works by this author on: Oxford Academic Google Scholar American Journal of Clinical Pathology, Volume 45, Issue 4_ts, April 1966, Pages 493–496, https://doi.org/10.1093/ajcp/45.4_ts.493 Published: 01 April 1966 Article history Received: 17 August 1965 Published: 01 April 1966","['Clinical microbiology', 'Library science', 'Medicine', 'Family medicine', 'Microbiology', 'Computer science', 'Biology']","standardized, clinical pathology"
Paper_00480,PAST: PALEONTOLOGICAL STATISTICAL SOFTWARE PACKAGE FOR EDUCATION AND DATA ANALYSIS,"['Øyvind Hammer', 'David A. T. Harper', 'Paul D. Ryan']",2001,['Social Science Micro Review'],Journal,,170-171,2,3,10.1177/089443938600200309,"A comprehensive, but simple-to-use software package for executing a range of standard numerical analysis and operations used in quantitative paleontology has been developed. The program, called PAST (PAleontological STatistics), runs on standard Windows computers and is available free of charge. PAST integrates spreadsheet-type data entry with univariate and multivariate statistics, curve fitting, timeseries analysis, data plotting, and simple phylogenetic analysis. Many of the functions are specific to paleontology and ecology, and these functions are not found in standard, more extensive, statistical packages. PAST also includes fourteen case studies (data files and exercises) illustrating use of the program for paleontological problems, making it a complete educational package for courses in quantitative methods.","['Univariate', 'Software', 'Software package', 'Computer science', 'R package', 'Computational statistics', 'Range (aeronautics)', 'Simple (philosophy)', 'Multivariate statistics', 'Statistical analysis', 'Data type', 'Data file', 'Paleontology', 'Data mining', 'Statistics', 'Biology', 'Mathematics', 'Computational science', 'Programming language', 'Machine learning', 'Engineering', 'Philosophy', 'Epistemology', 'Aerospace engineering']","numerical analysis, quantitative paleontology, paleontological statistics, curve fitting, timeseries analysis, data plotting, simple phylogenetic analysis, [PAD] [PAD] [PAD], [PAD], [PAD] [PAD], [PAD], [PAD], [PAD], [PAD] [PAD] [PAD] [PAD], [PAD], [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD], [PAD], [PAD], [PAD] [PAD] [PAD] [PAD], [PAD]"
Paper_00481,The Effect of Riding as an Alternative Treatment for Children with Cerebral Palsy: A Systematic Review and Meta-Analysis,"['Guoqin Wang', 'Ruiqin Ma', 'Guangwei Qiao', 'Koji Wada', 'Yoshiharu Aizawa', 'Toshihiko Satoh']",2015,Integrative Medicine International,Journal,,211-222,1,4,10.1159/000368408,"&lt;b&gt;&lt;i&gt;Background and Objectives:&lt;/i&gt;&lt;/b&gt; There is a substantial body of evidence assessing the effects of equine-assisted therapy on physiological and psychological aspects of individuals with disabilities. This study aimed to evaluate the physiological benefits of this alternative therapy for children with cerebral palsy (CP) by means of a systematic review and meta-analysis. &lt;b&gt;&lt;i&gt;Methods:&lt;/i&gt;&lt;/b&gt; This systematic review included all randomized and nonrandomized clinical trials of hippotherapy (HT), therapeutic horse riding (THR), and artificial saddle (AS) for the treatment of children with CP by a systematic search in Medline, Embase, Cochrane Library, and other databases up to November 2012. Articles were assessed for inclusion eligibility and quality by two independent reviewers. Any discordant case was re-reviewed and consensus was obtained after sufficient discussion. A random effects model of meta-analysis was applied to provide summary statistics for each outcome. &lt;b&gt;&lt;i&gt;Results:&lt;/i&gt;&lt;/b&gt; Seven randomized controlled trials (RCTs), 4 non-RCTs, and 7 self-controlled studies were included for quality assessment. Ten studies assessed the effect of HT, 5 evaluated THR, and 3 evaluated AS. The sample size differed from 3 to 72, and the quality ranged from low to moderate. Six studies were included in the meta-analysis, and there was a significant improvement in the 66-item Gross Motor Function Measure (GMFM-66), the GMFM-66/88 total score, and the dimension E of the GMFM. Although the asymmetry score tended to be reduced, it failed to reach statistical significance. &lt;b&gt;&lt;i&gt;Conclusions:&lt;/i&gt;&lt;/b&gt; HT, THR, and AS seem to improve the total score of the gross motor function via improvement of the walking, running, and jumping dimension. However, they are not likely to be of benefit to the symmetry of postural muscle activity. Studies included in this review lack high-quality RCTs with a sufficient number of subjects, which thus warrants further evaluations of these modalities using large-scale well-designed RCTs.","['Meta-analysis', 'Randomized controlled trial', 'Medicine', 'Cerebral palsy', 'Cochrane Library', 'Physical therapy', 'MEDLINE', 'Systematic review', 'Pediatrics', 'Internal medicine', 'Political science', 'Law']","cerebral palsy, hippotherapy, therapeutic horse riding, artificial saddle, medline, embase, cochrane library, inclusion, random effects model, random, gross motor function measure, as, postural muscle activity"
Paper_00482,The qualitative content analysis process,"['Satu Elo', 'Helvi Kyngäs']",2008,Journal of Advanced Nursing,Journal,,107-115,62,1,10.1111/j.1365-2648.2007.04569.x,"This paper is a description of inductive and deductive content analysis.Content analysis is a method that may be used with either qualitative or quantitative data and in an inductive or deductive way. Qualitative content analysis is commonly used in nursing studies but little has been published on the analysis process and many research books generally only provide a short description of this method.When using content analysis, the aim was to build a model to describe the phenomenon in a conceptual form. Both inductive and deductive analysis processes are represented as three main phases: preparation, organizing and reporting. The preparation phase is similar in both approaches. The concepts are derived from the data in inductive content analysis. Deductive content analysis is used when the structure of analysis is operationalized on the basis of previous knowledge.Inductive content analysis is used in cases where there are no previous studies dealing with the phenomenon or when it is fragmented. A deductive approach is useful if the general aim was to test a previous theory in a different situation or to compare categories at different time periods.","['Operationalization', 'Content analysis', 'Phenomenon', 'Computer science', 'Content (measure theory)', 'Inductive reasoning', 'Qualitative analysis', 'Process (computing)', 'Deductive reasoning', 'Inductive method', 'Qualitative research', 'Epistemology', 'Artificial intelligence', 'Psychology', 'Mathematics', 'Mathematics education', 'Mathematical analysis', 'Social science', 'Philosophy', 'Sociology', 'Teaching method', 'Operating system']","deductive content analysis, content analysis, qualitative content analysis, nursing studies, content analysis, de, inductive content analysis, deductive content analysis, inductive content analysis, de, [PAD], [PAD] [PAD], [PAD] [PAD], [PAD], [PAD]"
Paper_00483,International Physical Activity Questionnaire: 12-Country Reliability and Validity,"['Cora L. Craig', 'Alison L. Marshall', 'M Sj str m', 'Adrian Bauman', 'Michael Booth', 'Barbara E. Ainsworth', 'Michael Pratt', 'Ulf Ekelund', 'Agneta Yngve', 'James F. Sallis', 'Pekka Oja']",2003,Medicine & Science in Sports & Exercise,Journal,,1381-1395,35,8,10.1249/01.mss.0000078924.61453.fb,"Physical inactivity is a global concern, but diverse physical activity measures in use prevent international comparisons. The International Physical Activity Questionnaire (IPAQ) was developed as an instrument for cross-national monitoring of physical activity and inactivity.Between 1997 and 1998, an International Consensus Group developed four long and four short forms of the IPAQ instruments (administered by telephone interview or self-administration, with two alternate reference periods, either the ""last 7 d"" or a ""usual week"" of recalled physical activity). During 2000, 14 centers from 12 countries collected reliability and/or validity data on at least two of the eight IPAQ instruments. Test-retest repeatability was assessed within the same week. Concurrent (inter-method) validity was assessed at the same administration, and criterion IPAQ validity was assessed against the CSA (now MTI) accelerometer. Spearman's correlation coefficients are reported, based on the total reported physical activity.Overall, the IPAQ questionnaires produced repeatable data (Spearman's rho clustered around 0.8), with comparable data from short and long forms. Criterion validity had a median rho of about 0.30, which was comparable to most other self-report validation studies. The ""usual week"" and ""last 7 d"" reference periods performed similarly, and the reliability of telephone administration was similar to the self-administered mode.The IPAQ instruments have acceptable measurement properties, at least as good as other established self-reports. Considering the diverse samples in this study, IPAQ has reasonable measurement properties for monitoring population levels of physical activity among 18- to 65-yr-old adults in diverse settings. The short IPAQ form ""last 7 d recall"" is recommended for national monitoring and the long form for research requiring more detailed assessment.","['Concurrent validity', 'Criterion validity', 'Physical activity', 'Reliability (semiconductor)', 'Validity', 'Physical therapy', 'Telephone interview', 'Population', 'Psychology', 'Medicine', 'External validity', 'Repeatability', 'Statistics', 'Construct validity', 'Clinical psychology', 'Psychometrics', 'Environmental health', 'Mathematics', 'Social psychology', 'Internal consistency', 'Social science', 'Power (physics)', 'Physics', 'Quantum mechanics', 'Sociology']","physical inactivity, physical activity measures, international physical activity questionnaire, ipa, inactivity, international, ipa, telephone interview, correlation, criterion, telephone administration, ipa, ipa"
Paper_00484,System Identification: Theory for the User,['Lennart Ljung'],1987,['Automatica'],Unknown,,475-476,25,3,10.1016/0005-1098(89)90019-8,"Das Buch behandelt die Systemidentifizierung in dem theoretischen Bereich, der direkte Auswirkungen auf Verstaendnis und praktische Anwendung der verschiedenen Verfahren zur Identifizierung hat. Da ...","['Identification (biology)', 'Computer science', 'Biology', 'Botany']","systemidentifi, identifiz, [PAD], [PAD], [PAD], [PAD]"
Paper_00486,Reduction in the Incidence of Type 2 Diabetes with Lifestyle Intervention or Metformin,"['William C. Knowler', 'Elizabeth Barrett‐Connor', 'Sarah Fowler', 'Richard F. Hamman', 'John M. Lachin', 'Elizabeth A. Walker', 'David M. Nathan']",2002,New England Journal of Medicine,Journal,,393-403,346,6,10.1056/nejmoa012512,"Type 2 diabetes affects approximately 8 percent of adults in the United States. Some risk factors — elevated plasma glucose concentrations in the fasting state and after an oral glucose load, overweight, and a sedentary lifestyle — are potentially reversible. We hypothesized that modifying these factors with a lifestyle-intervention program or the administration of metformin would prevent or delay the development of diabetes.","['Metformin', 'Medicine', 'Overweight', 'Type 2 diabetes', 'Confidence interval', 'Diabetes mellitus', 'Placebo', 'Body mass index', 'Incidence (geometry)', 'Weight loss', 'Obesity', 'Internal medicine', 'Endocrinology', 'Physics', 'Alternative medicine', 'Optics', 'Pathology']","plasma glucose concentrations, fast, oral glucose load, ##weight, sedentary lifestyle, metform"
Paper_00487,Qualitative research and case study applications in education,['Sharan B. Merriam'],1998,['Music Education Research'],Unknown,,157-182,,,10.1093/oso/9780197639757.003.0009,"THE DESIGN OF QUALITATIVE RESEARCH. 1. What is Qualitative Research? 2. Case Studies as Qualtitative Research. 3. Designing the Study and Selecting a Sample. COLLECTING QUALITATIVE DATA. 4. Conducting Effective Interviews. 5. Being a Careful Observer. 6. Mining Data from Documents. 7. Collecting Data in Case Studies. ANALYZING AND REPORTING QUALITATIVE DATA. 8. Analytic Techniques and Data Management. 9. Levels of Analysis. 10. Dealing with Validity, Reliability and Ethics. 11. Writing Reports and Case Studies.","['Qualitative research', 'Qualitative property', 'Case study research', 'Reliability (semiconductor)', 'Computer science', 'Sample (material)', 'Data science', 'Research design', 'Management science', 'Knowledge management', 'Engineering', 'Sociology', 'Social science', 'Power (physics)', 'Physics', 'Chemistry', 'Chromatography', 'Quantum mechanics', 'Machine learning']","qualitative research, qualitative research, case studies, qualtitative research, analytic techniques, data management, validity, reliability, ethics, writing, case studies"
Paper_00488,Cultures and Organizations: Software of the Mind.,"['Harry C. Triandis', 'Geert Hofstede']",1993,Administrative Science Quarterly,Journal,,132-132,38,1,10.2307/2393257,"Despite calls for better co-operation between countries and different cultures, there is still confrontation between people, groups and nations. But at the same time they are exposed to common problems which demand cooperation for the solution of these problems. This book helps to understand the differences in the way strategists and their followers think, offering practical solutions for those in business to help solve conflict between different groups.","['Public relations', 'Sociology', 'Business', 'Political science', 'Knowledge management', 'Computer science']",
Paper_00491,RoB 2: a revised tool for assessing risk of bias in randomised trials,"['Jonathan A C Sterne', 'Jelena Savović', 'Matthew J. Page', 'Roy G. Elbers', 'Natalie Blencowe', 'Isabelle Boutron', 'Christopher J Cates', 'Hung‐Yuan Cheng', 'Mark Corbett', 'Sandra Eldridge', 'Jonathan Emberson', 'Miguel A. Hernán', 'Sally Hopewell', 'Asbjørn Hróbjartsson', 'Daniela R. Junqueira', 'Peter Jüni', 'Jamie J Kirkham', 'Toby J Lasserson', 'Tianjing Li', 'Alexandra McAleenan', 'Barnaby C Reeves', 'Sasha Shepperd', 'Ian Shrier', 'Lesley Stewart', 'Kate Tilling', 'Ian R. White', 'Penny Whiting', 'Julian P. T. Higgins']",2019,BMJ,Journal,,l4898-l4898,,,10.1136/bmj.l4898,"Assessment of risk of bias is regarded as an essential component of a systematic review on the effects of an intervention. The most commonly used tool for randomised trials is the Cochrane risk-of-bias tool. We updated the tool to respond to developments in understanding how bias arises in randomised trials, and to address user feedback on and limitations of the original tool.","['Systematic review', 'Randomized controlled trial', 'Medicine', 'Intervention (counseling)', 'Publication bias', 'Meta-analysis', 'MEDLINE', 'Psychology', 'Medical physics', 'Internal medicine', 'Psychiatry', 'Political science', 'Law']","randomised trials, randomised trials"
Paper_00494,Regularization and Variable Selection Via the Elastic Net,"['Hui Zou', 'Trevor Hastie']",2005,Journal of the Royal Statistical Society Series B (Statistical Methodology),Journal,,301-320,67,2,10.1111/j.1467-9868.2005.00503.x,"We propose the elastic net, a new regularization and variable selection method. Real world data and a simulation study show that the elastic net often outperforms the lasso, while enjoying a similar sparsity of representation. In addition, the elastic net encourages a grouping effect, where strongly correlated predictors tend to be in or out of the model together. The elastic net is particularly useful when the number of predictors (p) is much bigger than the number of observations (n). By contrast, the lasso is not a very satisfactory variable selection method in the p≫n case. An algorithm called LARS-EN is proposed for computing elastic net regularization paths efficiently, much like algorithm LARS does for the lasso.","['Elastic net regularization', 'Regularization (linguistics)', 'Feature selection', 'Variable (mathematics)', 'Computer science', 'Mathematics', 'Applied mathematics', 'Mathematical optimization', 'Algorithm', 'Artificial intelligence', 'Mathematical analysis']","elastic net, regularization, variable selection method, real, simulation, elastic net, lasso, elastic net, grouping effect, strongly correlated predictors, elastic net, lasso, variable selection, elastic net regularization, [PAD] [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD] [PAD], [PAD], [PAD], [PAD] [PAD], [PAD], [PAD] [PAD], [PAD], [PAD]"
Paper_00496,Naïve Bayesian Classifier for Rapid Assignment of rRNA Sequences into the New Bacterial Taxonomy,"['Qiong Wang', 'George M Garrity', 'James M. Tiedje', 'James R. Cole']",2007,Applied and Environmental Microbiology,Journal,,5261-5267,73,16,10.1128/aem.00062-07,"ABSTRACT The Ribosomal Database Project (RDP) Classifier, a naïve Bayesian classifier, can rapidly and accurately classify bacterial 16S rRNA sequences into the new higher-order taxonomy proposed in Bergey's Taxonomic Outline of the Prokaryotes (2nd ed., release 5.0, Springer-Verlag, New York, NY, 2004). It provides taxonomic assignments from domain to genus, with confidence estimates for each assignment. The majority of classifications (98%) were of high estimated confidence (≥95%) and high accuracy (98%). In addition to being tested with the corpus of 5,014 type strain sequences from Bergey's outline, the RDP Classifier was tested with a corpus of 23,095 rRNA sequences as assigned by the NCBI into their alternative higher-order taxonomy. The results from leave-one-out testing on both corpora show that the overall accuracies at all levels of confidence for near-full-length and 400-base segments were 89% or above down to the genus level, and the majority of the classification errors appear to be due to anomalies in the current taxonomies. For shorter rRNA segments, such as those that might be generated by pyrosequencing, the error rate varied greatly over the length of the 16S rRNA gene, with segments around the V2 and V4 variable regions giving the lowest error rates. The RDP Classifier is suitable both for the analysis of single rRNA sequences and for the analysis of libraries of thousands of sequences. Another related tool, RDP Library Compare, was developed to facilitate microbial-community comparison based on 16S rRNA gene sequence libraries. It combines the RDP Classifier with a statistical test to flag taxa differentially represented between samples. The RDP Classifier and RDP Library Compare are available online at http://rdp.cme.msu.edu/ .","['16S ribosomal RNA', 'Classifier (UML)', 'Ribosomal RNA', 'Biology', 'Taxonomic rank', 'Taxonomy (biology)', 'Artificial intelligence', 'Genetics', 'Computational biology', 'Computer science', 'Gene', 'Ecology', 'Taxon']","ribosomal database project, naive bayesian classifier, confidence estimates, ##p, ##bi, rdp, single, rdp library compare, rdp, statistical test, ##p, ##p library compare"
Paper_00497,The Structure and Function of Complex Networks,['Michael Newman'],2003,SIAM Review,Journal,,167-256,45,2,10.1137/s003614450342480,"Inspired by empirical studies of networked systems such as the Internet, social networks, and biological networks, researchers have in recent years developed a variety of techniques and models to help us understand or predict the behavior of these systems. Here we review developments in this field, including such concepts as the small-world effect, degree distributions, clustering, network correlations, random graph models, models of network growth and preferential attachment, and dynamical processes taking place on networks.","['Random graph', 'Complex network', 'Computer science', 'Cluster analysis', 'Degree distribution', 'Preferential attachment', 'Clustering coefficient', 'Biological network', 'Variety (cybernetics)', 'Evolving networks', 'The Internet', 'Field (mathematics)', 'Theoretical computer science', 'Network science', 'Small-world network', 'Network formation', 'Data science', 'Graph', 'Artificial intelligence', 'Mathematics', 'World Wide Web', 'Combinatorics', 'Pure mathematics']","networked systems, internet, social networks, biological networks, degree distributions, clustering, network correlations, random graph models, network growth, preferential attachment, dynamical processes"
Paper_00498,Structural Equations with Latent Variables.,"['Clifford C. Clogg', 'Kenneth A. Bollen']",1991,Contemporary Sociology A Journal of Reviews,Journal,,156-156,20,1,10.2307/2072165,"Model Notation, Covariances, and Path Analysis. Causality and Causal Models. Structural Equation Models with Observed Variables. The Consequences of Measurement Error. Measurement Models: The Relation Between Latent and Observed Variables. Confirmatory Factor Analysis. The General Model, Part I: Latent Variable and Measurement Models Combined. The General Model, Part II: Extensions. Appendices. Distribution Theory. References. Index.","['Latent variable', 'Structural equation modeling', 'Econometrics', 'Latent class model', 'Latent variable model', 'Mathematics', 'Applied mathematics', 'Statistics']","model notation, covariances, path analysis, causality, causal models, structural equation models, observed variables, measurement error, measurement models, confirmatory factor analysis, late, measurement models, distribution theory, [PAD] [PAD] [PAD] [PAD] [PAD]"
Paper_00499,Statistical Analysis With Missing Data,"['Maureen Lahiff', 'Roderick J. A. Little', 'Donald B. Rubin']",1989,Journal of the American Statistical Association,Journal,,332-332,84,405,10.2307/2289883,"Preface.PART I: OVERVIEW AND BASIC APPROACHES.Introduction.Missing Data in Experiments.Complete-Case and Available-Case Analysis, Including Weighting Methods.Single Imputation Methods.Estimation of Imputation Uncertainty.PART II: LIKELIHOOD-BASED APPROACHES TO THE ANALYSIS OF MISSING DATA.Theory of Inference Based on the Likelihood Function.Methods Based on Factoring the Likelihood, Ignoring the Missing-Data Mechanism.Maximum Likelihood for General Patterns of Missing Data: Introduction and Theory with Ignorable Nonresponse.Large-Sample Inference Based on Maximum Likelihood Estimates.Bayes and Multiple Imputation.PART III: LIKELIHOOD-BASED APPROACHES TO THE ANALYSIS OF MISSING DATA: APPLICATIONS TO SOME COMMON MODELS.Multivariate Normal Examples, Ignoring the Missing-Data Mechanism.Models for Robust Estimation.Models for Partially Classified Contingency Tables, Ignoring the Missing-Data Mechanism.Mixed Normal and Nonnormal Data with Missing Values, Ignoring the Missing-Data Mechanism.Nonignorable Missing-Data Models.References.Author Index.Subject Index.","['Missing data', 'Statistics', 'Computer science', 'Statistical analysis', 'Mathematics', 'Data mining']","missing data, weighting methods, single imputation methods, imputation uncertainty, missing data, likelihood function, maximum likelihood, maximum likelihood estimates, bayes, multiple imputation, multivariate normal examples, robust estimation, nonnormal data"
Paper_00500,"Agency Costs of Free Cash Flow, Corporate Finance, and Takeovers",['Michael C. Jensen'],1986,['Corporate Bankruptcy'],Journal,,11-16,76,2,10.1017/cbo9780511609435.005,"The interests and incentives of managers and shareholders conflict over such issues as the optimal size of the firm and the payment of cash to shareholders. These conflicts are especially severe in firms with large free cash flows—more cash than profitable investment opportunities. The theory developed here explains 1) the benefits of debt in reducing agency costs of free cash flows, 2) how debt can substitute for dividends, 3) why “diversification” programs are more likely to generate losses than takeovers or expansion in the same line of business or liquidationmotivated takeovers, 4) why the factors generating takeover activity in such diverse activities as broadcasting and tobacco are similar to those in oil, and 5) why bidders and some targets tend to perform abnormally well prior to takeover.","['Free cash flow', 'Agency cost', 'Shareholder', 'Cash flow statement', 'Business', 'Incentive', 'Debt', 'Cash management', 'Monetary economics', 'Cash flow forecasting', 'Cash flow', 'Operating cash flow', 'Finance', 'Economics', 'Dividend', 'Cash', 'Corporate governance', 'Microeconomics']","free cash flows, debt, agency costs, free cash flows, divide, liquidation, ##ivated takeovers, takeover, broadcasting, tobacco"
Paper_00503,"Global Cancer Statistics, 2002","['Donald Maxwell Parkin', 'Freddie Bray', 'Jacques Ferlay', 'Paola Pisani']",2005,CA A Cancer Journal for Clinicians,Journal,,74-108,55,2,10.3322/canjclin.55.2.74,"Estimates of the worldwide incidence, mortality and prevalence of 26 cancers in the year 2002 are now available in the GLOBOCAN series of the International Agency for Research on Cancer. The results are presented here in summary form, including the geographic variation between 20 large ""areas"" of the world. Overall, there were 10.9 million new cases, 6.7 million deaths, and 24.6 million persons alive with cancer (within three years of diagnosis). The most commonly diagnosed cancers are lung (1.35 million), breast (1.15 million), and colorectal (1 million); the most common causes of cancer death are lung cancer (1.18 million deaths), stomach cancer (700,000 deaths), and liver cancer (598,000 deaths). The most prevalent cancer in the world is breast cancer (4.4 million survivors up to 5 years following diagnosis). There are striking variations in the risk of different cancers by geographic area. Most of the international variation is due to exposure to known or suspected risk factors related to lifestyle or environment, and provides a clear challenge to prevention.","['Cancer', 'Medicine', 'Breast cancer', 'Lung cancer', 'International agency', 'Demography', 'Colorectal cancer', 'Incidence (geometry)', 'Stomach cancer', 'Cancer registry', 'Epidemiology of cancer', 'Cause of death', 'Causes of cancer', 'Mortality rate', 'Disease', 'Oncology', 'Internal medicine', 'Optics', 'Physics', 'Sociology']","globocan, breast, colorectal, lung cancer, stomach cancer, liver cancer, breast cancer"
Paper_00505,Density-functional approximation for the correlation energy of the inhomogeneous electron gas,['John P. Perdew'],1986,"Physical review. B, Condensed matter",Journal,,8822-8824,33,12,10.1103/physrevb.33.8822,"Langreth and Mehl (LM) and co-workers have developed a useful spin-density functional for the correlation energy of an electronic system. Here the LM functional is improved in two ways: (1) The natural separation between exchange and correlation is made, so that the density-gradient expansion of each is recovered in the slowly varying limit. (2) Uniform-gas and inhomogeneity effects beyond the randomphase approximation are built in. Numerical results for atoms, positive ions, and surfaces are close to the exact correlation energies, with major improvements over the original LM approximation for the ions and surfaces.","['Ion', 'Limit (mathematics)', 'Physics', 'Fermi gas', 'Correlation', 'Local-density approximation', 'Energy (signal processing)', 'Atomic physics', 'Electron', 'Density functional theory', 'Energy functional', 'Electronic correlation', 'Quantum mechanics', 'Mathematical analysis', 'Mathematics', 'Geometry']","correlation energy, electronic system, correlation, inhomogeneity effects, randomphase approximation, positive ions, correlation energies, [PAD], [PAD] [PAD], [PAD], [PAD]"
Paper_00506,Statistical Methods for Rates and Proportions,"['Joseph L. Fleiss', 'Bruce Levin', 'Myunghee Cho Paik']",2003,Wiley series in probability and statistics,Unknown,,,,,10.1002/0471445428,"Preface.Preface to the Second Edition.Preface to the First Edition.1. An Introduction to Applied Probability.2. Statistical Inference for a Single Proportion.3. Assessing Significance in a Fourfold Table.4. Determining Sample Sizes Needed to Detect a Difference Between Two Proportions.5. How to Randomize.6. Comparative Studies: Cross-Sectional, Naturalistic, or Multinomial Sampling.7. Comparative Studies: Prospective and Retrospective Sampling.8. Randomized Controlled Trials.9. The Comparison of Proportions from Several Independent Samples.10. Combining Evidence from Fourfold Tables.11. Logistic Regression.12. Poisson Regression.13. Analysis of Data from Matched Samples.14. Regression Models for Matched Samples.15. Analysis of Correlated Binary Data.16. Missing Data.17. Misclassification Errors: Effects, Control, and Adjustment.18. The Measurement of Interrater Agreement.19. The Standardization of Rates.Appendix A. Numerical Tables.Appendix B. The Basic Theory of Maximum Likelihood Estimation.Appendix C. Answers to Selected Problems.Author Index.Subject Index.","['Statistics', 'Mathematics']","applied probability, statistical inference, ##fold table, comparative studies, ##mial, retrospective sampling, randomized controlled trials, logistic regression, poisson regression, matched samples, regression models, matched samples, correlated binary data, missing data, misclassification errors, adjustment, interrater agreement, numerical tables, maximum likelihood estimation, [PAD], [PAD], [PAD]"
Paper_00508,Geneious Basic: An integrated and extendable desktop software platform for the organization and analysis of sequence data,"['Matthew D. Kearse', 'Richard Moir', 'Amy Wilson', 'Steven Stones-Havas', 'Matthew Cheung', 'Shane Sturrock', 'Simon Buxton', 'Alex Cooper', 'Sidney Markowitz', 'Chris Duran', 'Tobias Thierer', 'Bruce Ashton', 'Peter Meintjes', 'Alexei J. Drummond']",2012,Bioinformatics,Journal,,1647-1649,28,12,10.1093/bioinformatics/bts199,"Abstract Summary: The two main functions of bioinformatics are the organization and analysis of biological data using computational resources. Geneious Basic has been designed to be an easy-to-use and flexible desktop software application framework for the organization and analysis of biological data, with a focus on molecular sequences and related data types. It integrates numerous industry-standard discovery analysis tools, with interactive visualizations to generate publication-ready images. One key contribution to researchers in the life sciences is the Geneious public application programming interface (API) that affords the ability to leverage the existing framework of the Geneious Basic software platform for virtually unlimited extension and customization. The result is an increase in the speed and quality of development of computation tools for the life sciences, due to the functionality and graphical user interface available to the developer through the public API. Geneious Basic represents an ideal platform for the bioinformatics community to leverage existing components and to integrate their own specific requirements for the discovery, analysis and visualization of biological data. Availability and implementation: Binaries and public API freely available for download at http://www.geneious.com/basic, implemented in Java and supported on Linux, Apple OSX and MS Windows. The software is also available from the Bio-Linux package repository at http://nebc.nerc.ac.uk/news/geneiousonbl. Contact: peter@biomatters.com","['Computer science', 'Software', 'Personalization', 'Leverage (statistics)', 'Visualization', 'Cross-platform', 'Software engineering', 'Java', 'Graphical user interface', 'Interface (matter)', 'Application programming interface', 'Data visualization', 'Operating system', 'World Wide Web', 'Data mining', 'Bubble', 'Machine learning', 'Maximum bubble pressure method']","bioinformatics, biological data, computational resources, geneious basic, geneious public application programming interface, geneious, geneious"
Paper_00509,Environmental Applications of Semiconductor Photocatalysis,"['Michael R. Hoffmann', 'Scot T. Martin', 'Wonyong Choi', 'Detlef W. Bahnemann']",1995,Chemical Reviews,Journal,,69-96,95,1,10.1021/cr00033a004,"ADVERTISEMENT RETURN TO ISSUEPREVArticleNEXTEnvironmental Applications of Semiconductor PhotocatalysisMichael R. Hoffmann, Scot T. Martin, Wonyong Choi, and Detlef W. BahnemannCite this: Chem. Rev. 1995, 95, 1, 69–96Publication Date (Print):January 1, 1995Publication History Published online1 May 2002Published inissue 1 January 1995https://pubs.acs.org/doi/10.1021/cr00033a004https://doi.org/10.1021/cr00033a004research-articleACS PublicationsRequest reuse permissionsArticle Views50969Altmetric-Citations16166LEARN ABOUT THESE METRICSArticle Views are the COUNTER-compliant sum of full text article downloads since November 2008 (both PDF and HTML) across all institutions and individuals. These metrics are regularly updated to reflect usage leading up to the last few days.Citations are the number of other articles citing this article, calculated by Crossref and updated daily. Find more information about Crossref citation counts.The Altmetric Attention Score is a quantitative measure of the attention that a research article has received online. Clicking on the donut icon will load a page at altmetric.com with additional details about the score and the social media presence for the given article. Find more information on the Altmetric Attention Score and how the score is calculated. Share Add toView InAdd Full Text with ReferenceAdd Description ExportRISCitationCitation and abstractCitation and referencesMore Options Share onFacebookTwitterWechatLinked InRedditEmail Other access optionsGet e-Alertsclose Get e-Alerts","['Altmetrics', 'Citation', 'Social media', 'Icon', 'Computer science', 'Reuse', 'World Wide Web', 'Library science', 'Engineering', 'Programming language', 'Waste management']","##var, ##mental applications, semiconductor photocatalysis, ##le, altmetric attention score, social, altmetric attention score, ##riscitation, abstract, ##ation, referencesmore"
Paper_00511,Two-equation eddy-viscosity turbulence models for engineering applications,['Florian R. Menter'],1994,AIAA Journal,Journal,,1598-1605,32,8,10.2514/3.12149,"Two new two-equation eddy-viscosity turbulence models will be presented.They combine different elements of existing models that are considered superior to their alternatives.The first model, referred to as the baseline (BSL) model, utilizes the original k-u model of Wilcox in the inner region of the boundary layer and switches to the standard A>e model in the outer region and in free shear flows.It has a performance similar to the Wilcox model, but avoids that model's strong freestream sensitivity.The second model results from a modification to the definition of the eddy-viscosity in the BSL model, which accounts for the effect of the transport of the principal turbulent shear stress.The new model is called the shear-stress transport-model and leads to major improvements in the prediction of adverse pressure gradient flows.","['Turbulence modeling', 'Turbulence', 'K-epsilon turbulence model', 'Mechanics', 'K-omega turbulence model', 'Viscosity', 'Physics', 'Large eddy simulation', 'Aerospace engineering', 'Statistical physics', 'Classical mechanics', 'Meteorology', 'Engineering', 'Thermodynamics']","free shear flows, freestream sensitivity, principal turbulent shear stress, adverse pressure gradient flows, [PAD], [PAD] [PAD] [PAD], [PAD]"
Paper_00512,Compressed sensing,['David L. Donoho'],2004,['Computer Vision'],Unknown,,132-132,,,10.1007/978-0-387-31439-6_100224,"Suppose x is an unknown vector in Ropfm (a digital image or signal); we plan to measure n general linear functionals of x and then reconstruct. If x is known to be compressible by transform coding with a known transform, and we reconstruct via the nonlinear procedure defined here, the number of measurements n can be dramatically smaller than the size m. Thus, certain natural classes of images with m pixels need only n=O(m1/4log5/2(m)) nonadaptive nonpixel samples for faithful recovery, as opposed to the usual m pixel samples. More specifically, suppose x has a sparse representation in some orthonormal basis (e.g., wavelet, Fourier) or tight frame (e.g., curvelet, Gabor)-so the coefficients belong to an lscrp ball for 0<ples1. The N important coefficients in that expansion allow reconstruction with lscr2 error O(N1/2-1p/). It is possible to design n=O(Nlog(m)) nonadaptive measurements allowing reconstruction with accuracy comparable to that attainable with direct knowledge of the N important coefficients. Moreover, a good approximation to those N important coefficients is extracted from the n measurements by solving a linear program-Basis Pursuit in signal processing. The nonadaptive measurements have the character of random linear combinations of basis/frame elements. Our results use the notions of optimal recovery, of n-widths, and information-based complexity. We estimate the Gel'fand n-widths of lscrp balls in high-dimensional Euclidean space in the case 0<ples1, and give a criterion identifying near- optimal subspaces for Gel'fand n-widths. We show that most subspaces are near-optimal, and show that convex optimization (Basis Pursuit) is a near-optimal way to extract information derived from these near-optimal subspaces","['Orthonormal basis', 'Mathematics', 'Basis (linear algebra)', 'Basis pursuit', 'Compressed sensing', 'Linear subspace', 'Basis function', 'Euclidean space', 'Algorithm', 'Pixel', 'Combinatorics', 'Matching pursuit', 'Mathematical analysis', 'Artificial intelligence', 'Pure mathematics', 'Computer science', 'Geometry', 'Physics', 'Quantum mechanics']","unknown vector, digital image, linear functionals, transform coding, nonlinear procedure, nonadaptive, ##el samples, faithful recovery, sparse representation, ##ono, ##l basis, nonadaptive measurements, ##ptive measurements, optimal recovery, convex optimization, basis pursuit"
Paper_00513,<i>Colloquium</i>: Topological insulators,"['M. Zahid Hasan', 'C. L. Kane']",2010,Reviews of Modern Physics,Journal,,3045-3067,82,4,10.1103/revmodphys.82.3045,"Topological insulators are electronic materials that have a bulk band gap like an ordinary insulator, but have protected conducting states on their edge or surface. The 2D topological insulator is a quantum spin Hall insulator, which is a close cousin of the integer quantum Hall state. A 3D topological insulator supports novel spin polarized 2D Dirac fermions on its surface. In this Colloquium article we will review the theoretical foundation for these electronic states and describe recent experiments in which their signatures have been observed. We will describe transport experiments on HgCdTe quantum wells that demonstrate the existence of the edge states predicted for the quantum spin Hall insulator. We will then discuss experiments on Bi_{1-x}Sb_x, Bi_2 Se_3, Bi_2 Te_3 and Sb_2 Te_3 that establish these materials as 3D topological insulators and directly probe the topology of their surface states. We will then describe exotic states that can occur at the surface of a 3D topological insulator due to an induced energy gap. A magnetic gap leads to a novel quantum Hall state that gives rise to a topological magnetoelectric effect. A superconducting energy gap leads to a state that supports Majorana fermions, and may provide a new venue for realizing proposals for topological quantum computation. We will close by discussing prospects for observing these exotic states, a well as other potential device applications of topological insulators.","['Topological insulator', 'Physics', 'Quantum anomalous Hall effect', 'Majorana fermion', 'Topology (electrical circuits)', 'Topological degeneracy', 'Condensed matter physics', 'Fermion', 'Topological order', 'Quantum Hall effect', 'Topological quantum computer', 'Surface states', 'Dirac fermion', 'MAJORANA', 'Superconductivity', 'Symmetry protected topological order', 'Quantum mechanics', 'Quantum', 'Surface (topology)', 'Magnetic field', 'Mathematics', 'Combinatorics', 'Geometry']","topological insulators, electronic materials, bulk band gap, conducting states, 2d topological insulator, quantum spin hall insulator, integer quantum hall state, 3d topological insulator, spin polarized 2d dirac fermions, hgcdte quantum wells, quantum spin hall insulator, 3d topological insulators, induced energy gap, magnetic gap, quantum hall state, topological magnetoelectric effect, superconducting energy gap, majorana fermions, topological quantum computation, topological insulators, [PAD] [PAD], [PAD] [PAD] [PAD] [PAD]"
Paper_00514,"Stochastic Relaxation, Gibbs Distributions, and the Bayesian Restoration of Images","['Stuart Geman', 'Donald Geman']",1984,IEEE Transactions on Pattern Analysis and Machine Intelligence,Journal,,721-741,PAMI-6,6,10.1109/tpami.1984.4767596,"We make an analogy between images and statistical mechanics systems. Pixel gray levels and the presence and orientation of edges are viewed as states of atoms or molecules in a lattice-like physical system. The assignment of an energy function in the physical system determines its Gibbs distribution. Because of the Gibbs distribution, Markov random field (MRF) equivalence, this assignment also determines an MRF image model. The energy function is a more convenient and natural mechanism for embodying picture attributes than are the local characteristics of the MRF. For a range of degradation mechanisms, including blurring, nonlinear deformations, and multiplicative or additive noise, the posterior distribution is an MRF with a structure akin to the image model. By the analogy, the posterior distribution defines another (imaginary) physical system. Gradual temperature reduction in the physical system isolates low energy states (``annealing''), or what is the same thing, the most probable states under the Gibbs distribution. The analogous operation under the posterior distribution yields the maximum a posteriori (MAP) estimate of the image given the degraded observations. The result is a highly parallel ``relaxation'' algorithm for MAP estimation. We establish convergence properties of the algorithm and we experiment with some simple pictures, for which good restorations are obtained at low signal-to-noise ratios.","['Maximum a posteriori estimation', 'Posterior probability', 'Markov random field', 'Markov chain', 'Mathematics', 'Algorithm', 'Boltzmann distribution', 'Random field', 'Statistical physics', 'Gibbs sampling', 'Artificial intelligence', 'Computer science', 'Bayesian probability', 'Image segmentation', 'Statistics', 'Physics', 'Image (mathematics)', 'Maximum likelihood']","images, statistical mechanics systems, pixel gray levels, energy function, gibbs distribution, gibbs distribution, markov random field, energy function, ##ring, nonlinear deformations, additive noise, posterior distribution, posterior distribution, low energy states, annealing, convergence properties, [PAD] [PAD], [PAD] [PAD] [PAD] [PAD], [PAD], [PAD], [PAD], [PAD] [PAD] [PAD] [PAD]"
Paper_00515,Wireless Communications: Principles and Practice,['Theodore S. Rappaport'],1996,['Wireless Networks'],Unknown,,25-94,,,10.1002/047085801x.ch2,"From the Publisher:
The indispensable guide to wireless communicationsnow fully revised and updated!

Wireless Communications: Principles and Practice, Second Edition is the definitive modern text for wireless communications technology and system design. Building on his classic first edition, Theodore S. Rappaport covers the fundamental issues impacting all wireless networks and reviews virtually every important new wireless standard and technological development, offering especially comprehensive coverage of the 3G systems and wireless local area networks (WLANs) that will transform communications in the coming years. Rappaport illustrates each key concept with practical examples, thoroughly explained and solved step by step.
Coverage includes:

An overview of key wireless technologies: voice, data, cordless, paging, fixed and mobile broadband wireless systems, and beyond
Wireless system design fundamentals: channel assignment, handoffs, trunking efficiency, interference, frequency reuse, capacity planning, large-scale fading, and more
Path loss, small-scale fading, multipath, reflection, diffraction, scattering, shadowing, spatial-temporal channel modeling, and microcell/indoor propagation
Modulation, equalization, diversity, channel coding, and speech coding
New wireless LAN technologies: IEEE 802.11a/b, HIPERLAN, BRAN, and other alternatives
New 3G air interface standards, including W-CDMA, cdma2000, GPRS, UMTS, and EDGE
Bluetooth wearable computers, fixed wireless and Local Multipoint Distribution Service (LMDS), and other advanced technologies
Updated glossary of abbreviations and acronyms, and a thorolist of references
Dozens of new examples and end-of-chapter problems


Whether you're a communications/network professional, manager, researcher, or student, Wireless Communications: Principles and Practice, Second Edition gives you an in-depth understanding of the state of the art in wireless technologytoday's and tomorrow's.","['Fixed wireless', 'Wireless', 'Computer science', 'Wireless broadband', 'Wireless network', 'Computer network', 'Wi-Fi array', 'Telecommunications', 'Local Multipoint Distribution Service', 'Wireless WAN', 'Cordless', 'Engineering']","wireless communications, wireless, system design, 3, wireless local area networks, w, paging, mobile broadband, channel assignment, handoffs, trunking efficiency, interference, frequency reuse, capacity planning, multipath, reflection, diffraction, scattering, equalization, diversity, channel coding, speech coding, ##g, ##rs, ##ts, edge bluetooth wearable computers, fixed wireless, local multipoint distribution service"
Paper_00516,Gaussian Processes for Machine Learning,"['Carl Edward Rasmussen', 'Christopher K. I. Williams']",2005,Unknown,Unknown,,,,,10.7551/mitpress/3206.001.0001,"A comprehensive and self-contained introduction to Gaussian processes, which provide a principled, practical, probabilistic approach to learning in kernel machines. Gaussian processes (GPs) provide a principled, practical, probabilistic approach to learning in kernel machines. GPs have received increased attention in the machine-learning community over the past decade, and this book provides a long-needed systematic and unified treatment of theoretical and practical aspects of GPs in machine learning. The treatment is comprehensive and self-contained, targeted at researchers and students in machine learning and applied statistics. The book deals with the supervised-learning problem for both regression and classification, and includes detailed algorithms. A wide variety of covariance (kernel) functions are presented and their properties discussed. Model selection is discussed both from a Bayesian and a classical perspective. Many connections to other well-known techniques from machine learning and statistics are discussed, including support-vector machines, neural networks, splines, regularization networks, relevance vector machines and others. Theoretical issues including learning curves and the PAC-Bayesian framework are treated, and several approximation methods for learning with large datasets are discussed. The book contains illustrative examples and exercises, and code and datasets are available on the Web. Appendixes provide mathematical background and a discussion of Gaussian Markov processes.","['Artificial intelligence', 'Computer science', 'Machine learning', 'Gaussian process', 'Gaussian', 'Chemistry', 'Computational chemistry']","gaussian processes, kernel machines, gaussian processes, gps, kernel machines, machine learning, machine learning, applied statistics, covariance, model selection, machine learning, statistics, neural networks, splines, regularization networks, relevance vector machines, learning curves, approximation methods, gaussian markov processes"
Paper_00519,The WEKA data mining software,"['Mark Hall', 'Eibe Frank', 'Geoffrey Holmes', 'Bernhard Pfahringer', 'Peter Reutemann', 'Ian H. Witten']",2009,ACM SIGKDD Explorations Newsletter,Journal,,10-18,11,1,10.1145/1656274.1656278,"More than twelve years have elapsed since the first public release of WEKA. In that time, the software has been rewritten entirely from scratch, evolved substantially and now accompanies a text on data mining [35]. These days, WEKA enjoys widespread acceptance in both academia and business, has an active community, and has been downloaded more than 1.4 million times since being placed on Source-Forge in April 2000. This paper provides an introduction to the WEKA workbench, reviews the history of the project, and, in light of the recent 3.6 stable release, briefly discusses what has been added since the last stable version (Weka 3.4) released in 2003.","['Computer science', 'Workbench', 'Data science', 'Software', 'Data mining', 'Open source software', 'World Wide Web', 'Software engineering', 'Operating system', 'Visualization']","weka, data mining, weka, weka, weka, [PAD]"
Paper_00520,"Structural equation modeling with AMOS: basic concepts, applications, and programming",['Barbara M. Byrne'],2000,['International Statistical Review'],Unknown,,141-142,82,1,10.1111/insr.12051_1,Contents: Part I: Introduction. Structural Equation Models: The Basics. Using the EQS Program. Part II: Single-Group Analyses. Application 1: Testing for the Factorial Validity of a Theoretical Construct (First-Order CFA Model). Application 2: Testing for the Factorial Validity of Scores From a Measuring Instrument (First-Order CFA Model). Application 3: Testing for the Factorial Validity of Scores from a Measuring Instrument (Second-Order CFA Model). Application 4: Testing for the Validity of a Causal Structure. Part III: Multiple-Group Analyses. Application 5: Testing for the Factorial Invariance of a Measuring Instrument. Application 6: Testing for the Invariance of a Causal Structure. Application 7: Testing for Latent Mean Differences (First-Order CFA Model). Application 8: Testing for Latent Mean Differences (Second-Order CFA Model). Part IV: Other Important Topics. Application 9: Testing for Construct Validity: The Multitrait-Multimethod Model. Application 10: Testing for Change Over Time: The Latent Growth Curve Model. Application 11: Testing for Within- and Between-Level Variance: The Multilevel Model.,"['Structural equation modeling', 'Factorial', 'Construct validity', 'Confirmatory factor analysis', 'Construct (python library)', 'Latent variable', 'Measurement invariance', 'Factorial experiment', 'Variance (accounting)', 'Causal model', 'Mathematics', 'Statistics', 'Econometrics', 'Psychology', 'Computer science', 'Psychometrics', 'Programming language', 'Mathematical analysis', 'Accounting', 'Business']","structural equation models, eqs, factorial validity, theoretical construct, factorial validity, factorial validity, causal structure, factorial invariance, invar, causal structure, latent mean differences, latent mean differences, latent growth curve model, multilevel"
Paper_00522,Statistical Procedures for Agricultural Research.,"['D. F. Cox', 'K. A. Gomez', 'Arthur A. Gomez']",1985,Journal of the American Statistical Association,Journal,,486-486,80,390,10.2307/2287932,Elements of Experimentation. Single-Factor Experiments. Two-Factor Experiments. Three-or More-Factor Experiments. Comparison Between Treatment Means. Analysis of Multiobservation Data. Problem Data. Analysis of Data from a Series of Experiments. Regression and Correlation Analysis. Covariance Analysis. Chi-Square Test. Soil Heterogeneity. Competition Effects. Mechanical Errors. Sampling in Experimental Plots. Experiments in Farmers' Fields. Presentation of Experimental Results. Appendices. Index.,"['Agriculture', 'Computer science', 'Statistics', 'Econometrics', 'Mathematics', 'Geography', 'Archaeology']","multiobservation data, problem data, regression, correlation analysis, covariance analysis, soil heterogeneity, competition effects, mechanical errors, experimental plots, farmers, [PAD], [PAD] [PAD], [PAD], [PAD] [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD], [PAD] [PAD], [PAD] [PAD], [PAD] [PAD], [PAD]"
Paper_00524,A climbing image nudged elastic band method for finding saddle points and minimum energy paths,"['Graeme Henkelman', 'Blas P. Uberuaga', 'Hannes Jónsson']",2000,The Journal of Chemical Physics,Journal,,9901-9904,113,22,10.1063/1.1329672,"A modification of the nudged elastic band method for finding minimum energy paths is presented. One of the images is made to climb up along the elastic band to converge rigorously on the highest saddle point. Also, variable spring constants are used to increase the density of images near the top of the energy barrier to get an improved estimate of the reaction coordinate near the saddle point. Applications to CH4 dissociative adsorption on Ir(111) and H2 on Si(100) using plane wave based density functional theory are presented.","['Saddle point', 'Saddle', 'Climbing', 'Density functional theory', 'Point (geometry)', 'Elastic energy', 'Physics', 'Materials science', 'Atomic physics', 'Geometry', 'Mathematics', 'Quantum mechanics', 'Structural engineering', 'Mathematical optimization', 'Engineering']","nudged elastic band method, minimum energy paths, variable spring constants, reaction coordinate, ##ssociative adsorption, plane wave based density functional theory, [PAD], [PAD] [PAD] [PAD], [PAD] [PAD], [PAD] [PAD], [PAD]"
Paper_00526,Theory of games and economic behavior,"['Stephan Ramon Garcia', 'Steven J. Miller']",2019,American Mathematical Society eBooks,Unknown,,163-167,,,10.1090/mbk/121/32,"This is the classic work upon which modern-day game theory is based. What began more than sixty years ago as a modest proposal that a mathematician and an economist write a short paper together blossomed, in 1944, when Princeton University Press published Theory of Games and Economic Behavior. In it, John von Neumann and Oskar Morgenstern conceived a groundbreaking mathematical theory of economic and social organization, based on a theory of games of strategy. Not only would this revolutionize economics, but the entirely new field of scientific inquiry it yielded--game theory--has since been widely used to analyze a host of real-world phenomena from arms races to optimal policy choices of presidential candidates, from vaccination policy to major league baseball salary negotiations. And it is today established throughout both the social sciences and a wide range of other sciences.","['Economics', 'Psychology', 'Mathematical economics']","game theory, economic behavior, social organization, game theory, arms races, optimal policy choices, vaccination policy, major league baseball salary negotiations"
Paper_00527,Foundations of social theory,[],1990,Choice Reviews Online,Journal,,27-6637,27,11,10.5860/choice.27-6637,Suggests a new approach to describing both stability and change in social systems by linking the behavior of individuals to organizational behavior.,"['History', 'Sociology', 'Epistemology', 'Philosophy']","stability, change, social systems, individuals, organizational behavior, [PAD], [PAD], [PAD], [PAD], [PAD] [PAD], [PAD], [PAD], [PAD], [PAD] [PAD], [PAD], [PAD]"
Paper_00528,BLAST+: architecture and applications,"['Christiam Camacho', 'George Coulouris', 'Vahram Avagyan', 'Ning Ma', 'Jason S. Papadopoulos', 'Kevin Bealer', 'Thomas Madden']",2009,BMC Bioinformatics,Journal,,,10,1,10.1186/1471-2105-10-421,"Sequence similarity searching is a very important bioinformatics task. While Basic Local Alignment Search Tool (BLAST) outperforms exact methods through its use of heuristics, the speed of the current BLAST software is suboptimal for very long queries or database sequences. There are also some shortcomings in the user-interface of the current command-line applications.We describe features and improvements of rewritten BLAST software and introduce new command-line applications. Long query sequences are broken into chunks for processing, in some cases leading to dramatically shorter run times. For long database sequences, it is possible to retrieve only the relevant parts of the sequence, reducing CPU time and memory usage for searches of short queries against databases of contigs or chromosomes. The program can now retrieve masking information for database sequences from the BLAST databases. A new modular software library can now access subject sequence data from arbitrary data sources. We introduce several new features, including strategy files that allow a user to save and reuse their favorite set of options. The strategy files can be uploaded to and downloaded from the NCBI BLAST web site.The new BLAST command-line applications, compared to the current BLAST tools, demonstrate substantial speed improvements for long queries as well as chromosome length database sequences. We have also improved the user interface of the command-line applications.","['Computer science', 'Interface (matter)', 'Heuristics', 'Software', 'Database', 'Set (abstract data type)', 'Task (project management)', 'Sequence (biology)', 'Modular design', 'Information retrieval', 'Data mining', 'Programming language', 'Parallel computing', 'Operating system', 'Bubble', 'Maximum bubble pressure method', 'Biology', 'Economics', 'Genetics', 'Management']","sequence similarity searching, bio, ##form, local alignment search tool, blast, heuristics, database, cpu, memory usage, blast, modular software library, strategy files, strategy, chromosome length database"
Paper_00529,PLS-SEM: Indeed a Silver Bullet,"['Joe F. Hair', 'Christian M. Ringle', 'Marko Sarstedt']",2011,The Journal of Marketing Theory and Practice,Journal,,139-152,19,2,10.2753/mtp1069-6679190202,"Abstract Structural equation modeling (SEM) has become a quasi-standard in marketing and management research when it comes to analyzing the cause-effect relations between latent constructs. For most researchers, SEM is equivalent to carrying out covariance-based SEM (CB-SEM). While marketing researchers have a basic understanding of CB-SEM, most of them are only barely familiar with the other useful approach to SEM-partial least squares SEM (PLS-SEM). The current paper reviews PLS-SEM and its algorithm, and provides an overview of when it can be most appropriately applied, indicating its potential and limitations for future research. The authors conclude that PLS-SEM path modeling, if appropriately applied, is indeed a ""silver bullet"" for estimating causal models in many theoretical models and empirical data situations. This article is part of the following collections: Celebrating the Impactful Articles from Journal of Marketing Theory and Practice","['Structural equation modeling', 'Partial least squares regression', 'Silver bullet', 'Latent variable', 'Computer science', 'Scanning electron microscope', 'Mathematics', 'Management science', 'Artificial intelligence', 'Materials science', 'Engineering', 'Machine learning', 'Composite material', 'Metallurgy']","abstract structural equation modeling, management research, latent constructs, partial least squares sem, causal models, empirical data, marketing"
Paper_00531,Law and Finance,"['Rafael La Porta', 'Florencio López‐de‐Silanes', 'Andrei Shleifer', 'Robert W. Vishny']",1998,Journal of Political Economy,Journal,,1113-1155,106,6,10.1086/250042,"This paper examines legal rules covering protection of corporate shareholders and creditors, the origin of these rules, and the quality of their enforcement in 49 countries. The results show that common‐law countries generally have the strongest, and frenchcivillaw countries the weakest, legal protections of investors, with German‐and scandinavin‐civil‐law countries located in the middle. We also find that concentration of ownership of shares in the largest public companies is negativelyrelated to investor protections, consistent with the hypothesis that small, diversified share‐holders are unlikely to be important in countries that fail to protect their rights.","['Shareholder', 'Creditor', 'Enforcement', 'Business', 'Investor protection', 'Quality (philosophy)', 'German', 'Common law', 'Corporate governance', 'Finance', 'Accounting', 'Economics', 'Law', 'Debt', 'Political science', 'Philosophy', 'Archaeology', 'Epistemology', 'History']","legal rules, corporate shareholders, creditors, common, frenchcivillaw countries, legal protections, investors, ##dinavin, civil ‐ law, investor protections, [PAD], [PAD]"
Paper_00533,<b>lmerTest</b> Package: Tests in Linear Mixed Effects Models,"['Alexandra Kuznetsova', 'Per B. Brockhoff', 'Rune Haubo Bojesen Christensen']",2017,Journal of Statistical Software,Journal,,,82,13,10.18637/jss.v082.i13,"One of the frequent questions by users of the mixed model function lmer of the lme4 package has been: How can I get p values for the F and t tests for objects returned by lmer? The lmerTest package extends the 'lmerMod' class of the lme4 package, by overloading the anova and summary functions by providing p values for tests for fixed effects. We have implemented the Satterthwaite's method for approximating degrees of freedom for the t and F tests. We have also implemented the construction of Type I - III ANOVA tables. Furthermore, one may also obtain the summary as well as the anova table using the Kenward-Roger approximation for denominator degrees of freedom (based on the KRmodcomp function from the pbkrtest package). Some other convenient mixed model analysis tools such as a step method, that performs backward elimination of nonsignificant effects - both random and fixed, calculation of population means and multiple comparison tests together with plot facilities are provided by the package as well.","['R package', 'Mixed model', 'Degrees of freedom (physics and chemistry)', 'Mathematics', 'Analysis of variance', 'Statistics', 'Computer science', 'Random effects model', 'Generalized linear mixed model', 'Function (biology)', 'Score', 'Medicine', 'Meta-analysis', 'Physics', 'Quantum mechanics', 'Internal medicine', 'Evolutionary biology', 'Biology']","mixed model function, ##test, ##d, summary functions, degrees of freedom, anova tables, anova, denominator degrees of freedom, krmodcomp function, mixed model analysis, step method, backward elimination, nonsignificant effects, population means, multiple comparison tests, plot facilities"
Paper_00534,Climate change 2007 : the physical science basis : contribution of Working Group I to the Fourth Assessment Report of the Intergovernmental Panel on Climate Change,['Susan L. Solomon'],2007,['Choice Reviews Online'],Unknown,,45-5006-45-5006,45,09,10.5860/choice.45-5006,"Summary for policymakers -- Technical summary -- Historical overview of climate change science -- Changes in atmospheric constituents and radiative forcing -- Observations: atmospheric surface and climate change -- Observations: changes in snow, ice, and frozen ground -- Observations: ocean climate change and sea level -- Paleoclimate -- Coupling between changes in the climate system and biogeochemistry -- Climate models and their evaluation -- Understanding and attributing climate change -- Global climate projections -- Regional climate projections -- Annex I: Glossary -- Annex II: Contributors to the IPCC WGI Fourth Assessment Report -- Annex III: Reviewers of the IPCC WGI Fourth Assessment Report -- Annex IV: Acronyms.","['Climate change', 'Climatology', 'Radiative forcing', 'Environmental science', 'Climate model', 'Paleoclimatology', 'Snow', 'Forcing (mathematics)', 'Geography', 'Meteorology', 'Oceanography', 'Geology']","climate change, atmospheric constituents, radiative forcing, climate change, frozen, sea level, global climate projections, regional climate projections"
Paper_00535,Classification and Regression by randomForest,"['Andy Liaw', 'Matthew C. Wiener']",2007,['CRAN: Contributed Packages'],Unknown,,,,,10.32614/cran.package.randomforest,"Recently there has been a lot of interest in “ensemble learning” — methods that generate many classifiers and aggregate their results. Two well-known methods are boosting (see, e.g., Shapire et al., 1998) and bagging Breiman (1996) of classification trees. In boosting, successive trees give extra weight to points incorrectly predicted by earlier predictors. In the end, a weighted vote is taken for prediction. In bagging, successive trees do not depend on earlier trees — each is independently constructed using a bootstrap sample of the data set. In the end, a simple majority vote is taken for prediction. Breiman (2001) proposed random forests, which add an additional layer of randomness to bagging. In addition to constructing each tree using a different bootstrap sample of the data, random forests change how the classification or regression trees are constructed. In standard trees, each node is split using the best split among all variables. In a random forest, each node is split using the best among a subset of predictors randomly chosen at that node. This somewhat counterintuitive strategy turns out to perform very well compared to many other classifiers, including discriminant analysis, support vector machines and neural networks, and is robust against overfitting (Breiman, 2001). In addition, it is very user-friendly in the sense that it has only two parameters (the number of variables in the random subset at each node and the number of trees in the forest), and is usually not very sensitive to their values. The randomForest package provides an R interface to the Fortran programs by Breiman and Cutler (available at http://www.stat.berkeley.edu/ users/breiman/). This article provides a brief introduction to the usage and features of the R functions.","['Random forest', 'Boosting (machine learning)', 'Overfitting', 'Artificial intelligence', 'Computer science', 'Mathematics', 'Machine learning', 'Statistics', 'Pattern recognition (psychology)', 'Data mining', 'Artificial neural network']","ensemble learning, boosting, classification trees, boosting, weighted vote, bootstrap sample, majority vote, random forests, random forests, regression trees, random forest, discriminant analysis, support vector machines, neural networks, randomforest, ##ran"
Paper_00536,"Clinical Characteristics of 138 Hospitalized Patients With 2019 Novel Coronavirus–Infected Pneumonia in Wuhan, China","['Dawei Wang', 'Bo Hu', 'Chang Hu', 'Fangfang Zhu', 'Xing Liu', 'Jing Zhang', 'Binbin Wang', 'Hui Xiang', 'Zhenshun Cheng', 'Yong Xiong', 'Yan Zhao', 'Yirong Li', 'Xinghuan Wang', 'Zhiyong Peng']",2020,JAMA,Journal,,1061-1061,323,11,10.1001/jama.2020.1585,"<h3>Importance</h3> In December 2019, novel coronavirus (2019-nCoV)–infected pneumonia (NCIP) occurred in Wuhan, China. The number of cases has increased rapidly but information on the clinical characteristics of affected patients is limited. <h3>Objective</h3> To describe the epidemiological and clinical characteristics of NCIP. <h3>Design, Setting, and Participants</h3> Retrospective, single-center case series of the 138 consecutive hospitalized patients with confirmed NCIP at Zhongnan Hospital of Wuhan University in Wuhan, China, from January 1 to January 28, 2020; final date of follow-up was February 3, 2020. <h3>Exposures</h3> Documented NCIP. <h3>Main Outcomes and Measures</h3> Epidemiological, demographic, clinical, laboratory, radiological, and treatment data were collected and analyzed. Outcomes of critically ill patients and noncritically ill patients were compared. Presumed hospital-related transmission was suspected if a cluster of health professionals or hospitalized patients in the same wards became infected and a possible source of infection could be tracked. <h3>Results</h3> Of 138 hospitalized patients with NCIP, the median age was 56 years (interquartile range, 42-68; range, 22-92 years) and 75 (54.3%) were men. Hospital-associated transmission was suspected as the presumed mechanism of infection for affected health professionals (40 [29%]) and hospitalized patients (17 [12.3%]). Common symptoms included fever (136 [98.6%]), fatigue (96 [69.6%]), and dry cough (82 [59.4%]). Lymphopenia (lymphocyte count, 0.8 × 10<sup>9</sup>/L [interquartile range {IQR}, 0.6-1.1]) occurred in 97 patients (70.3%), prolonged prothrombin time (13.0 seconds [IQR, 12.3-13.7]) in 80 patients (58%), and elevated lactate dehydrogenase (261 U/L [IQR, 182-403]) in 55 patients (39.9%). Chest computed tomographic scans showed bilateral patchy shadows or ground glass opacity in the lungs of all patients. Most patients received antiviral therapy (oseltamivir, 124 [89.9%]), and many received antibacterial therapy (moxifloxacin, 89 [64.4%]; ceftriaxone, 34 [24.6%]; azithromycin, 25 [18.1%]) and glucocorticoid therapy (62 [44.9%]). Thirty-six patients (26.1%) were transferred to the intensive care unit (ICU) because of complications, including acute respiratory distress syndrome (22 [61.1%]), arrhythmia (16 [44.4%]), and shock (11 [30.6%]). The median time from first symptom to dyspnea was 5.0 days, to hospital admission was 7.0 days, and to ARDS was 8.0 days. Patients treated in the ICU (n = 36), compared with patients not treated in the ICU (n = 102), were older (median age, 66 years vs 51 years), were more likely to have underlying comorbidities (26 [72.2%] vs 38 [37.3%]), and were more likely to have dyspnea (23 [63.9%] vs 20 [19.6%]), and anorexia (24 [66.7%] vs 31 [30.4%]). Of the 36 cases in the ICU, 4 (11.1%) received high-flow oxygen therapy, 15 (41.7%) received noninvasive ventilation, and 17 (47.2%) received invasive ventilation (4 were switched to extracorporeal membrane oxygenation). As of February 3, 47 patients (34.1%) were discharged and 6 died (overall mortality, 4.3%), but the remaining patients are still hospitalized. Among those discharged alive (n = 47), the median hospital stay was 10 days (IQR, 7.0-14.0). <h3>Conclusions and Relevance</h3> In this single-center case series of 138 hospitalized patients with confirmed NCIP in Wuhan, China, presumed hospital-related transmission of 2019-nCoV was suspected in 41% of patients, 26% of patients received ICU care, and mortality was 4.3%.","['Medicine', 'Interquartile range', 'Epidemiology', 'Pneumonia', 'Retrospective cohort study', 'Internal medicine', 'Pediatrics', 'Emergency medicine']","infected pneumonia, critically, noncritically, fever, dry cough, l, ##open, ##ph, elevated, chest computed tomographic scans, ground glass"
Paper_00539,Very Deep Convolutional Networks for Large-Scale Image Recognition,"['Karen Simonyan', 'Andrew Zisserman']",2014,arXiv (Cornell University),Unknown,,,,,10.48550/arxiv.1409.1556,"In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.","['Computer science', 'Convolutional neural network', 'Artificial intelligence', 'Scale (ratio)', 'Pattern recognition (psychology)', 'Deep learning', 'Image (mathematics)', 'Cartography', 'Geography']","convolutional network depth, convolution filters, imagenet challenge, classification tracks, deep visual representations, computer vision, [PAD], [PAD] [PAD] [PAD] [PAD], [PAD], [PAD] [PAD], [PAD] [PAD], [PAD] [PAD]"
Paper_00540,The genetical theory of natural selection,['Ronald Aylmer Fisher'],1930,Unknown,Unknown,,,,,10.5962/bhl.title.27468,"We need scarcely add that the contemplation in natural science of a wider domain than the actual leads to a far better understanding of the actual.' (p. 267,The, Nature of the Physical World.)x PREFACE evolutionary theory was thus chiefly retrogressive, the mighty body of Mendelian researches throughout the world has evidently out- grown the fallacies with which it was at first fostered.As a pioneer of genetics he has done more than enough to expiate the rash polemics of his early writings.To treat Natural Selection as an agency based independently on its own foundations is not to mimimize its importance in the theory of evolution.On the contrary, as soon as we require to form opinions by other means than by comparison and analogy, such an indepen- dent deductive basis becomes a necessity.This necessity is particu- larly to be noted for mankind ; since we have some knowledge of the structure of society, of human motives, and of the vital statistics of this species, the use of the deductive method can supply a more intimate knowledge of the evolutionary processes than is elsewhere possible.In addition it will be of importance for our subject to call ) attention to several consequences of the principle of Natural Selection!which, since they do not consist in the adaptive modification of specific I forms, have necessarily escaped attention.The genetic phenomena of I dominance and linkage seem to offer examples of this class, the future ' investigation of which may add greatly to the scope of our subject.No efforts of mine could avail to make the book easy reading.I have endeavoured to assist the reader by giving short summaries at the ends of all chapters, except Chapter IV, which is summarized conjointly with Chapter V.Those who prefer to do so may regardChapter IV as a mathematical appendix to the corresponding part of the summary.The deductions respecting Man are strictly in- separable from the more general chapters, but have been placed together in a group commencing with Chapter VIII.I believe no one will be surprised that a large number of the points considered demand a far fuller, more rigorous, and more comprehensive treat- ment.It seems impossible that full justice should be done to the subject in this way, until there is built up a tradition of mathematical work devoted to biological problems, comparable to the researches upon which a mathematical physicist can draw in the resolution of special difficulties.","['Natural selection', 'Selection (genetic algorithm)', 'Natural (archaeology)', 'Evolutionary biology', 'Biology', 'Computer science', 'Artificial intelligence', 'Paleontology']","natural science, evolutionary theory, ##ian, natural selection, evolution, human motives, de, evolutionary, natural selection, genetic phenomena, linkage, mathematical physicist"
Paper_00541,Thought and language,['L. S. Vygotsky'],1962,['Вестник Башкирского университета'],Unknown,,947,,,10.33184/bulletin-bsu-2019.4.30,"Since it was introduced to the English-speaking world in 1962, Lev Vygotsky's highly original exploration of human mental development has become recognized as a classic foundational work of cognitive science. Vygotsky analyzes the relationship between words and consciousness, arguing that speech is social in its origins and that only as children develop does it become internalized verbal thought.Now Alex Kozulin has created a new edition of the original MIT Press translation by Eugenia Hanfmann and Gertrude Vakar that restores the work's complete text and adds materials that will help readers better understand Vygotsky's meaning and intentions. Kozulin has also contributed an introductory essay that offers new insight into the author's life, intellectual milieu, and research methods.Lev S. Vygotsky (1896-1934) studied at Moscow University and acquired in his brief lifespan a nearly encyclopedic knowledge of the social sciences, psychology, philosophy, linguistics, literature, and the arts. He began his systematic work in psychology at the age of 28, and within a few years formulated his theory of the development of specifically human higher mental functions. He died of tuberculosis ten years later, and Thought and Language was published posthumously in 1934.Alex Kozulin studied at the Moscow Institute of Medicine and the Moscow Institute of Psychology, where he began his investigation of Vygotsky and the history of Soviet psychology. He emigrated in 1979 and is now Associate Professor of Psychiatry (Psychology) at Boston University. He is the author of Psychology in Utopia: Toward a Social History of Soviet Psychology (MIT Press 1984).","['Psychology', 'Meaning (existential)', 'Psychoanalysis', 'Consciousness', 'The arts', 'Human science', 'History of psychology', 'Sociology', 'Social science', 'Art', 'Neuroscience', 'Visual arts', 'Psychotherapist']","human mental development, cognitive science, consciousness, soviet psychology, psychology, utopia, social history, soviet psychology"
Paper_00542,Specification Tests in Econometrics,['Jerry A. Hausman'],1978,Econometrica,Journal,,1251-1251,46,6,10.2307/1913827,"Using the result that under the null hypothesis of no misspecification an asymptotically efficient estimator must have zero asymptotic covariance with its difference from a consistent but asymptotically inefficient estimator, specification tests are devised for a number of model specifications in econometrics. Local power is calculated for small departures from the null hypothesis. An instrumental variable test as well as tests for a time series cross section model and the simultaneous equation model are presented. An empirical model provides evidence that unobserved individual factors are present which are not orthogonal to the included right-hand-side variable in a common econometric specification of an individual wage equation.","['Econometrics', 'Economics', 'Specification']","null, asymptotically, asymptotic covariance, specification tests, model specifications, econometrics, local power, instrumental variable test, time series cross section model, simultaneous equation model, empirical, unobserved individual factors, common econometric specification, individual wage equation, [PAD], [PAD], [PAD], [PAD] [PAD], [PAD] [PAD], [PAD], [PAD] [PAD] [PAD] [PAD] [PAD], [PAD], [PAD] [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD], [PAD]"
Paper_00543,The Standard Edition of the Complete Psychological Works of Sigmund Freud,['Sigmund Freud'],1953,['Psychoanalytic Psychotherapy'],Unknown,,255-260,38,3,10.1080/02668734.2024.2392576,Indexes and Bibliographies. This collection of twenty-four volumes is the first full paperback publication of the standard edition of The Complete Psychological Works of Sigmund Freud in English,"['Psychoanalysis', 'Psychology', 'Philosophy']",psychological works
Paper_00544,Glutathione S-Transferases,"['William H. Habig', 'M. Pabst', 'William B. Jakoby']",1974,Journal of Biological Chemistry,Journal,,7130-7139,249,22,10.1016/s0021-9258(19)42083-8,"The purification of homogeneous glutathione S-transferases B and C from rat liver is described. Kinetic and physical properties of these enzymes are compared with those of homogeneous transferases A and E. The letter designations for the transferases are based on the reverse order of elution from carboxymethylcellulose, the purification step in which the transferases are separated from each other. Transferase B was purified on the basis of its ability to conjugate iodomethane with glutathione, whereas transferase C was purified on the basis of conjugation with 1,2-dichloro-4-nitrobenzene. Although each of the four enzymes can be identified by its reactivity with specific substrates, all of the enzymes are active to differing degrees in the conjugation of glutathione with p-nitrobenzyl chloride. Assay conditions for a variety of substrates are included. All four glutathione transferases have a molecular weight of 45,000 and are dissociable into subunits of approximately 25,000 daltons. Despite the similar physical properties and overlapping substrate specificities of these enzymes, only transferases A and C are immunologically related.","['Glutathione', 'Enzyme', 'Chemistry', 'Biochemistry', 'Transferase', 'Substrate (aquarium)', 'Conjugate', 'Homogeneous', 'Substrate specificity', 'Glutathione transferase', 'Glutathione S-transferase', 'Biology', 'Ecology', 'Mathematical analysis', 'Physics', 'Mathematics', 'Thermodynamics']","homogeneous transferases, ##yme, g, ##tat, ##one transferase"
Paper_00545,Hierarchical Grouping to Optimize an Objective Function,['Joe H. Ward'],1963,Journal of the American Statistical Association,Journal,,236-244,58,301,10.1080/01621459.1963.10500845,"Abstract A procedure for forming hierarchical groups of mutually exclusive subsets, each of which has members that are maximally similar with respect to specified characteristics, is suggested for use in large-scale (n > 100) studies when a precise optimal solution for a specified number of groups is not practical. Given n sets, this procedure permits their reduction to n − 1 mutually exclusive sets by considering the union of all possible n(n − 1)/2 pairs and selecting a union having a maximal value for the functional relation, or objective function, that reflects the criterion chosen by the investigator. By repeating this process until only one group remains, the complete hierarchical structure and a quantitative estimate of the loss associated with each stage in the grouping can be obtained. A general flowchart helpful in computer programming and a numerical example are included.","['Flowchart', 'Mathematics', 'Function (biology)', 'Relation (database)', 'Mathematical optimization', 'Reduction (mathematics)', 'Group (periodic table)', 'Process (computing)', 'Scale (ratio)', 'Algorithm', 'Computer science', 'Statistics', 'Combinatorics', 'Data mining', 'Chemistry', 'Physics', 'Geometry', 'Organic chemistry', 'Quantum mechanics', 'Programming language', 'Operating system', 'Evolutionary biology', 'Biology']","hierarchical groups, mutually exclusive subsets, mutually exclusive sets, functional relation, objective function, general flowchart, computer programming, [PAD] [PAD] [PAD]"
Paper_00548,Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference,['Judea Pearl'],1988,['The Journal of Philosophy'],Unknown,,434,88,8,10.2307/2026705,"From the Publisher:
Probabilistic Reasoning in Intelligent Systems is a complete andaccessible account of the theoretical foundations and computational methods that underlie plausible reasoning under uncertainty. The author provides a coherent explication of probability as a language for reasoning with partial belief and offers a unifying perspective on other AI approaches to uncertainty, such as the Dempster-Shafer formalism, truth maintenance systems, and nonmonotonic logic. The author distinguishes syntactic and semantic approaches to uncertaintyand offers techniques, based on belief networks, that provide a mechanism for making semantics-based systems operational. Specifically, network-propagation techniques serve as a mechanism for combining the theoretical coherence of probability theory with modern demands of reasoning-systems technology: modular declarative inputs, conceptually meaningful inferences, and parallel distributed computation. Application areas include diagnosis, forecasting, image interpretation, multi-sensor fusion, decision support systems, plan recognition, planning, speech recognitionin short, almost every task requiring that conclusions be drawn from uncertain clues and incomplete information.
Probabilistic Reasoning in Intelligent Systems will be of special interest to scholars and researchers in AI, decision theory, statistics, logic, philosophy, cognitive psychology, and the management sciences. Professionals in the areas of knowledge-based systems, operations research, engineering, and statistics will find theoretical and computational tools of immediate practical use. The book can also be used as an excellent text for graduate-level courses in AI, operations research, or applied probability.","['Computer science', 'Probabilistic logic', 'Artificial intelligence', 'Reasoning system', 'Inference', 'Intelligent decision support system', 'Automated reasoning', 'Semantic reasoner', 'Semantics (computer science)', 'Expert system', 'Non-monotonic logic', 'Machine learning', 'Theoretical computer science', 'Programming language']","probabilistic reasoning, intelligent systems, computational methods, plausible reasoning, uncertainty, probability, partial belief, truth maintenance systems, nonmonotonic logic, belief networks, probability theory, modular declarative inputs, parallel distributed computation, diagnosis, forecasting, image interpretation, decision support systems, plan recognition, planning, speech recognition, incomplete information, probabilistic reasoning, intelligent systems, decision theory, statistics, logic, philosophy, cognitive psychology, management, applied probability"
Paper_00549,The three worlds of welfare capitalism,[],1990,Choice Reviews Online,Journal,,28-1046,28,02,10.5860/choice.28-1046,"Few discussions in modern social science have occupied as much attention as the changing nature of welfare states in Western societies. Gosta Esping-Andersen, one of the foremost contributors to current debates on this issue, here provides a new analysis of the character and role of welfare states in the functioning of contemporary advanced Western societies. Esping-Andersen distinguishes three major types of welfare state, connecting these with variations in the historical development of different Western countries. He argues that current economic processes, such as those moving toward a postindustrial order, are shaped not by autonomous market forces but by the nature of states and state differences. Fully informed by comparative materials, this book will have great appeal to all those working on issues of economic development and postindustrialism. Its audience will include students of sociology, economics, and politics.","['Capitalism', 'Welfare', 'Economics', 'Market economy', 'Political science', 'Law', 'Politics']","social science, welfare states, western societies, welfare states, advanced western societies, welfare state, postindustrial, autonomous market forces, state differences, postindustrialism, sociology, economics, politics, [PAD], [PAD]"
Paper_00553,Establishing a standard definition for child overweight and obesity worldwide: international survey,['Tim Cole'],2000,BMJ,Journal,,1240-1240,320,7244,10.1136/bmj.320.7244.1240,"<h3>Abstract</h3> <b>Objective:</b> To develop an internationally acceptable definition of child overweight and obesity, specifying the measurement, the reference population, and the age and sex specific cut off points. <b>Design:</b> International survey of six large nationally representative cross sectional growth studies. <b>Setting:</b> Brazil, Great Britain, Hong Kong, the Netherlands, Singapore, and the United States <b>Subjects:</b> 97 876 males and 94 851 females from birth to 25 years of age <b>Main outcome measure:</b> Body mass index (weight/height2). <b>Results:</b> For each of the surveys, centile curves were drawn that at age 18 years passed through the widely used cut off points of 25 and 30 kg/m2 for adult overweight and obesity. The resulting curves were averaged to provide age and sex specific cut off points from 2-18 years. <b>Conclusions:</b> The proposed cut off points, which are less arbitrary and more internationally based than current alternatives, should help to provide internationally comparable prevalence rates of overweight and obesity in children.","['Overweight', 'Obesity', 'Body mass index', 'Demography', 'Population', 'Cross-sectional study', 'Medicine', 'Geography', 'Gerontology', 'Sociology', 'Pathology', 'Internal medicine']","child overweight, obesity, reference population, body mass index, centile curves, adult overweight, obesity"
Paper_00554,Birds of a Feather: Homophily in Social Networks,"['Miller McPherson', 'Lynn Smith‐Lovin', 'James M. Cook']",2001,Annual Review of Sociology,Journal,,415-444,27,1,10.1146/annurev.soc.27.1.415,"Similarity breeds connection. This principle—the homophily principle—structures network ties of every type, including marriage, friendship, work, advice, support, information transfer, exchange, comembership, and other types of relationship. The result is that people's personal networks are homogeneous with regard to many sociodemographic, behavioral, and intrapersonal characteristics. Homophily limits people's social worlds in a way that has powerful implications for the information they receive, the attitudes they form, and the interactions they experience. Homophily in race and ethnicity creates the strongest divides in our personal environments, with age, religion, education, occupation, and gender following in roughly that order. Geographic propinquity, families, organizations, and isomorphic positions in social systems all create contexts in which homophilous relations form. Ties between nonsimilar individuals also dissolve at a higher rate, which sets the stage for the formation of niches (localized positions) within social space. We argue for more research on: (a) the basic ecological processes that link organizations, associations, cultural communities, social movements, and many other social forms; (b) the impact of multiplex ties on the patterns of homophily; and (c) the dynamics of network change over time through which networks and other social entities co-evolve.","['Homophily', 'Friendship', 'Interpersonal ties', 'Intrapersonal communication', 'Social psychology', 'Social network (sociolinguistics)', 'Sociology', 'Psychology', 'Interpersonal communication', 'Social media', 'Political science', 'Law']","similarity, connection, homophily principle, network ties, marriage, friendship, advice, support, information transfer, exchange, comembership, personal networks, homophily, homophily, ethnicity, gender, geographic prop, families, organizations, isomorphic positions, social systems, homophilous relations, nonsi, ##lar individuals, localized positions, ecological processes, cultural communities, social movements, multiplex ties, homophily"
Paper_00555,A density-based algorithm for discovering clusters in large spatial Databases with Noise,"['Martin Ester', 'Hans‐Peter Kriegel', 'Jörg Sander', 'Xiaowei Xu']",1996,['International Journal of Computer Applications'],Conference,,1-4,3,6,10.5120/739-1038,"Clustering algorithms are attractive for the task of class identification in spatial databases. However, the application to large spatial databases rises the following requirements for clustering algorithms: minimal requirements of domain knowledge to determine the input parameters, discovery of clusters with arbitrary shape and good efficiency on large databases. The well-known clustering algorithms offer no solution to the combination of these requirements. In this paper, we present the new clustering algorithm DBSCAN relying on a density-based notion of clusters which is designed to discover clusters of arbitrary shape. DBSCAN requires only one input parameter and supports the user in determining an appropriate value for it. We performed an experimental evaluation of the effectiveness and efficiency of DBSCAN using synthetic data and real data of the SEQUOIA 2000 benchmark. The results of our experiments demonstrate that (1) DBSCAN is significantly more effective in discovering clusters of arbitrary shape than the well-known algorithm CLARANS, and that (2) DBSCAN outperforms CLARANS by a factor of more than 100 in terms of efficiency.","['DBSCAN', 'Cluster analysis', 'Computer science', 'Data mining', 'Noise (video)', 'Benchmark (surveying)', 'Algorithm', 'Spatial database', 'Spatial analysis', 'Database', 'CURE data clustering algorithm', 'Pattern recognition (psychology)', 'Correlation clustering', 'Artificial intelligence', 'Mathematics', 'Image (mathematics)', 'Statistics', 'Geodesy', 'Geography']","clustering algorithms, class identification, spatial databases, large spatial databases, clustering algorithms, domain knowledge, cluster, clustering algorithm dbscan, dbscan, dbscan, se, ##oia, dbscan, dbscan, [PAD], [PAD]"
Paper_00556,Polymorphic transitions in single crystals: A new molecular dynamics method,"['Michele Parrinello', 'A. Rahman']",1981,Journal of Applied Physics,Journal,,7182-7190,52,12,10.1063/1.328693,"Views Icon Views Article contents Figures & tables Video Audio Supplementary Data Peer Review Share Icon Share Twitter Facebook Reddit LinkedIn Tools Icon Tools Reprints and Permissions Cite Icon Cite Search Site Citation M. Parrinello, A. Rahman; Polymorphic transitions in single crystals: A new molecular dynamics method. Journal of Applied Physics 1 December 1981; 52 (12): 7182–7190. https://doi.org/10.1063/1.328693 Download citation file: Ris (Zotero) Reference Manager EasyBib Bookends Mendeley Papers EndNote RefWorks BibTex toolbar search Search Dropdown Menu toolbar search search input Search input auto suggest filter your search All ContentAIP Publishing PortfolioJournal of Applied Physics Search Advanced Search |Citation Search","['Bifurcation', 'Molecular dynamics', 'Stress (linguistics)', 'Materials science', 'Shock (circulatory)', 'Work (physics)', 'Stress space', 'Ultimate tensile strength', 'Mechanics', 'Lagrangian', 'Statistical physics', 'Space (punctuation)', 'Classical mechanics', 'Finite element method', 'Physics', 'Constitutive equation', 'Thermodynamics', 'Mathematics', 'Mathematical analysis', 'Nonlinear system', 'Chemistry', 'Computational chemistry', 'Composite material', 'Computer science', 'Medicine', 'Linguistics', 'Philosophy', 'Quantum mechanics', 'Internal medicine', 'Operating system']","polymorphic transitions, single crystals, molecular dynamics, ##s, zotero, mendeley, bibt, citation"
Paper_00557,Bounds testing approaches to the analysis of level relationships,"['M. Hashem Pesaran', 'Yongcheol Shin', 'Richard J. Smith']",2001,Journal of Applied Econometrics,Journal,,289-326,16,3,10.1002/jae.616,"This paper develops a new approach to the problem of testing the existence of a level relationship between a dependent variable and a set of regressors, when it is not known with certainty whether the underlying regressors are trend- or first-difference stationary. The proposed tests are based on standard F- and t-statistics used to test the significance of the lagged levels of the variables in a univariate equilibrium correction mechanism. The asymptotic distributions of these statistics are non-standard under the null hypothesis that there exists no level relationship, irrespective of whether the regressors are I(0) or I(1). Two sets of asymptotic critical values are provided: one when all regressors are purely I(1) and the other if they are all purely I(0). These two sets of critical values provide a band covering all possible classifications of the regressors into purely I(0), purely I(1) or mutually cointegrated. Accordingly, various bounds testing procedures are proposed. It is shown that the proposed tests are consistent, and their asymptotic distribution under the null and suitably defined local alternatives are derived. The empirical relevance of the bounds procedures is demonstrated by a re-examination of the earnings equation included in the UK Treasury macroeconometric model. Copyright © 2001 John Wiley & Sons, Ltd.","['Mathematics', 'Null hypothesis', 'Econometrics', 'Univariate', 'Statistical hypothesis testing', 'Null (SQL)', 'Variable (mathematics)', 'Asymptotic analysis', 'Set (abstract data type)', 'Statistics', 'Applied mathematics', 'Mathematical economics', 'Multivariate statistics', 'Computer science', 'Mathematical analysis', 'Database', 'Programming language']","level relationship, dependent variable, regress, lagged levels, univariate equilibrium correction mechanism, asymptotic distributions, asymptotic critical values, bounds testing procedures, earnings equation, uk treasury macroeconometric model"
Paper_00559,Longitudinal data analysis using generalized linear models,"['Kung‐Yee Liang', 'Scott L. Zeger']",1986,Biometrika,Journal,,13-22,73,1,10.1093/biomet/73.1.13,"This paper proposes an extension of generalized linear models to the analysis of longitudinal data. We introduce a class of estimating equations that give consistent estimates of the regression parameters and of their variance under mild assumptions about the time dependence. The estimating equations are derived without specifying the joint distribution of a subject's observations yet they reduce to the score equations for niultivariate Gaussian outcomes. Asymptotic theory is presented for the general class of estimators. Specific cases in which we assume independence, m-dependence and exchangeable correlation structures from each subject are discussed. Efficiency of the pioposecl estimators in two simple situations is considered. The approach is closely related to quasi-likelihood.","['Mathematics', 'Estimator', 'Estimating equations', 'Generalized estimating equation', 'Extension (predicate logic)', 'Applied mathematics', 'Generalized linear model', 'Gaussian', 'Independence (probability theory)', 'Class (philosophy)', 'Asymptotic distribution', 'Simple (philosophy)', 'Linear model', 'Variance (accounting)', 'Statistics', 'Longitudinal data', 'Linear regression', 'Quasi-likelihood', 'Count data', 'Computer science', 'Philosophy', 'Physics', 'Accounting', 'Epistemology', 'Quantum mechanics', 'Artificial intelligence', 'Data mining', 'Programming language', 'Business', 'Poisson distribution']","generalized linear models, longitudinal data, estimating equations, regression parameters, time dependence, estimating equations, joint distribution, score equations, niultivariate gaussian outcomes, asymptotic theory, exchangeable correlation structures, pioposecl estimators, [PAD], [PAD], [PAD] [PAD] [PAD], [PAD], [PAD], [PAD], [PAD]"
Paper_00560,Rapid object detection using a boosted cascade of simple features,"['Paul Viola', 'Michael Jones']",2005,Unknown,Unknown,,I-518,1,,10.1109/cvpr.2001.990517,"This paper describes a machine learning approach for visual object detection which is capable of processing images extremely rapidly and achieving high detection rates. This work is distinguished by three key contributions. The first is the introduction of a new image representation called the ""integral image"" which allows the features used by our detector to be computed very quickly. The second is a learning algorithm, based on AdaBoost, which selects a small number of critical visual features from a larger set and yields extremely efficient classifiers. The third contribution is a method for combining increasingly more complex classifiers in a ""cascade"" which allows background regions of the image to be quickly discarded while spending more computation on promising object-like regions. The cascade can be viewed as an object specific focus-of-attention mechanism which unlike previous approaches provides statistical guarantees that discarded regions are unlikely to contain the object of interest. In the domain of face detection the system yields detection rates comparable to the best previous systems. Used in real-time applications, the detector runs at 15 frames per second without resorting to image differencing or skin color detection.","['Computer science', 'Object detection', 'Artificial intelligence', 'Viola–Jones object detection framework', 'AdaBoost', 'Cascade', 'Computer vision', 'Pattern recognition (psychology)', 'Face detection', 'Object-class detection', 'Detector', 'Object (grammar)', 'Contextual image classification', 'Set (abstract data type)', 'Focus (optics)', 'Representation (politics)', 'Cognitive neuroscience of visual object recognition', 'Image (mathematics)', 'Facial recognition system', 'Support vector machine', 'Chemistry', 'Physics', 'Optics', 'Chromatography', 'Politics', 'Law', 'Political science', 'Programming language', 'Telecommunications']","machine learning, visual object detection, image representation, integral image, learning algorithm, adaboost, face detection, image differencing, skin color detection"
Paper_00561,The CCP4 suite: programs for protein crystallography,['Number Collaborative Computational Project'],1994,Acta Crystallographica Section D Biological Crystallography,Journal,,760-763,50,5,10.1107/s0907444994003112,"The CCP4 (Collaborative Computational Project, number 4) program suite is a collection of programs and associated data and subroutine libraries which can be used for macromolecular structure determination by X-ray crystallography. The suite is designed to be flexible, allowing users a number of methods of achieving their aims and so there may be more than one program to cover each function. The programs are written mainly in standard Fortran77. They are from a wide variety of sources but are connected by standard data file formats. The package has been ported to all the major platforms under both Unix and VMS. The suite is distributed by anonymous ftp from Daresbury Laboratory and is widely used throughout the world.","['Suite', 'Unix', 'Subroutine', 'Computer science', 'Porting', 'Operating system', 'Variety (cybernetics)', 'Programming language', 'Software', 'Geography', 'Archaeology', 'Artificial intelligence']","ccp, collaborative computational project, subroutine libraries, macromolecular structure determination, data file formats, unix, vms, anonymous ftp, dare, [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD], [PAD], [PAD], [PAD] [PAD]"
Paper_00563,"Early Transmission Dynamics in Wuhan, China, of Novel Coronavirus–Infected Pneumonia","['Qun Li', 'Xuhua Guan', 'Peng Wu', 'Xiaoye Wang', 'Lei Zhou', 'Yeqing Tong', 'Ruiqi Ren', 'Kathy Leung', 'Eric H. Y. Lau', 'Jessica Y. Wong', 'Xuesen Xing', 'Nijuan Xiang', 'Yang Wu', 'Chao Li', 'Qi Chen', 'Dan Li', 'Tian Liu', 'Jing Zhao', 'Man Liu', 'Wenxiao Tu', 'Chuding Chen', 'Lianmei Jin', 'Rui Yang', 'Qi Wang', 'Suhua Zhou', 'Rui Wang', 'Hui Liu', 'Yinbo Luo', 'Yuan Liu', 'Ge Shao', 'Huan Li', 'Zhongfa Tao', 'Yang Yang', 'Zhiqiang Deng', 'Boxi Liu', 'Zhitao Ma', 'Yanping Zhang', 'Guoqing Shi', 'Tommy Tsan‐Yuk Lam', 'Joseph T. Wu', 'George F. Gao', 'Benjamin J. Cowling', 'Bo Yang', 'GM Leung', 'Zijian Feng']",2020,New England Journal of Medicine,Journal,,1199-1207,382,13,10.1056/nejmoa2001316,"The initial cases of novel coronavirus (2019-nCoV)-infected pneumonia (NCIP) occurred in Wuhan, Hubei Province, China, in December 2019 and January 2020. We analyzed data on the first 425 confirmed cases in Wuhan to determine the epidemiologic characteristics of NCIP.We collected information on demographic characteristics, exposure history, and illness timelines of laboratory-confirmed cases of NCIP that had been reported by January 22, 2020. We described characteristics of the cases and estimated the key epidemiologic time-delay distributions. In the early period of exponential growth, we estimated the epidemic doubling time and the basic reproductive number.Among the first 425 patients with confirmed NCIP, the median age was 59 years and 56% were male. The majority of cases (55%) with onset before January 1, 2020, were linked to the Huanan Seafood Wholesale Market, as compared with 8.6% of the subsequent cases. The mean incubation period was 5.2 days (95% confidence interval [CI], 4.1 to 7.0), with the 95th percentile of the distribution at 12.5 days. In its early stages, the epidemic doubled in size every 7.4 days. With a mean serial interval of 7.5 days (95% CI, 5.3 to 19), the basic reproductive number was estimated to be 2.2 (95% CI, 1.4 to 3.9).On the basis of this information, there is evidence that human-to-human transmission has occurred among close contacts since the middle of December 2019. Considerable efforts to reduce transmission will be required to control outbreaks if similar dynamics apply elsewhere. Measures to prevent or reduce transmission should be implemented in populations at risk. (Funded by the Ministry of Science and Technology of China and others.).","['Coronavirus', 'Transmission (telecommunications)', 'Pneumonia', 'Coronavirus disease 2019 (COVID-19)', 'Virology', 'China', 'Severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2)', '2019-20 coronavirus outbreak', 'Dynamics (music)', 'Medicine', 'Geography', 'Outbreak', 'Computer science', 'Telecommunications', 'Physics', 'Disease', 'Infectious disease (medical specialty)', 'Internal medicine', 'Acoustics', 'Archaeology']","##idemi, ##gic characteristics, demographic characteristics, exposure history, illness timelines, epidemic doubling time, seafood wholesale market"
Paper_00564,A Dynamic Theory of Organizational Knowledge Creation,['Ikujiro Nonaka'],1994,Organization Science,Journal,,14-37,5,1,10.1287/orsc.5.1.14,"This paper proposes a paradigm for managing the dynamic aspects of organizational knowledge creating processes. Its central theme is that organizational knowledge is created through a continuous dialogue between tacit and explicit knowledge. The nature of this dialogue is examined and four patterns of interaction involving tacit and explicit knowledge are identified. It is argued that while new knowledge is developed by individuals, organizations play a critical role in articulating and amplifying that knowledge. A theoretical framework is developed which provides an analytical perspective on the constituent dimensions of knowledge creation. This framework is then applied in two operational models for facilitating the dynamic creation of appropriate organizational knowledge.","['Knowledge management', 'Tacit knowledge', 'Organizational learning', 'Perspective (graphical)', 'Knowledge value chain', 'Knowledge creation', 'Explicit knowledge', 'Dynamic capabilities', 'Computer science', 'Personal knowledge management', 'Body of knowledge', 'Theme (computing)', 'Business', 'Artificial intelligence', 'Marketing', 'Downstream (manufacturing)', 'Operating system']","organizational knowledge creating, organizational knowledge, explicit knowledge, explicit knowledge, knowledge creation, operational models, organizational knowledge"
Paper_00565,A primer on partial least squares structural equation modeling (PLS-SEM),['Adrián Leguina'],2015,International Journal of Research & Method in Education,Journal,,220-221,38,2,10.1080/1743727x.2015.1005806,"Although structural equation modelling (SEM) is a popular statistical technique for multivariate data analysis in social and behavioural sciences, its use in education has massified more recently. ...","['Partial least squares regression', 'Structural equation modeling', 'Statistics', 'Mathematics', 'Econometrics']","structural equation modelling, multivariate data analysis, behaviour, [PAD], [PAD] [PAD] [PAD] [PAD] [PAD], [PAD] [PAD]"
Paper_00566,Testing for a unit root in time series regression,"['Peter C.B. Phillips', 'Pierre Perrón']",1988,Biometrika,Journal,,335-346,75,2,10.1093/biomet/75.2.335,This paper proposes new tests for detecting the presence of a unit root in quite general time series models. Our approach is nonparametric with respect to nuisance parameters and thereby allows for a very wide class of weakly dependent and possibly heterogeneously distributed data. The tests accommodate models with a fitted drift and a time trend so that they may be used to discriminate between unit root nonstationarity and stationarity about a deterministic trend. The limiting distributions of the statistics are obtained under both the unit root null and a sequence of local alternatives. The latter noncentral distribution theory yields local asymptotic power functions for the tests and facilitates comparisons with alternative procedures due to Dickey & Fuller. Simulations are reported on the performance of the new tests in finite samples.,"['Unit root', 'Mathematics', 'Series (stratigraphy)', 'Nonparametric statistics', 'Nuisance parameter', 'Statistics', 'Statistical hypothesis testing', 'Null hypothesis', 'Asymptotic distribution', 'Limiting', 'Unit root test', 'Null (SQL)', 'Augmented Dickey–Fuller test', 'Econometrics', 'Regression', 'Applied mathematics', 'Time series', 'Cointegration', 'Computer science', 'Data mining', 'Paleontology', 'Biology', 'Mechanical engineering', 'Estimator', 'Engineering']","unit root, time series models, nuisance parameters, ##geneously, fitted drift, time trend, unit root nonstationarity, stationarity, deterministic trend, limiting distributions, unit root null, local alternatives, noncentral distribution theory, local asymptotic power functions, [PAD] [PAD] [PAD] [PAD], [PAD], [PAD] [PAD], [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD], [PAD], [PAD], [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD], [PAD], [PAD] [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD], [PAD] [PAD], [PAD]"
Paper_00568,An integrated encyclopedia of DNA elements in the human genome,['Sylvain Foissac'],2012,Nature,Journal,,57-74,489,7414,10.1038/nature11247,"The human genome encodes the blueprint of life, but the function of the vast majority of its nearly three billion bases is unknown. The Encyclopedia of DNA Elements (ENCODE) project has systematically mapped regions of transcription, transcription factor association, chromatin structure and histone modification. These data enabled us to assign biochemical functions for 80% of the genome, in particular outside of the well-studied protein-coding regions. Many discovered candidate regulatory elements are physically associated with one another and with expressed genes, providing new insights into the mechanisms of gene regulation. The newly identified elements also show a statistical correspondence to sequence variants linked to human disease, and can thereby guide interpretation of this variation. Overall, the project provides new insights into the organization and regulation of our genes and genome, and is an expansive resource of functional annotations for biomedical research. This overview of the ENCODE project outlines the data accumulated so far, revealing that 80% of the human genome now has at least one biochemical function assigned to it; the newly identified functional elements should aid the interpretation of results of genome-wide association studies, as many correspond to sites of association with human disease. The Encyclopedia of DNA Elements (ENCODE) project has systematically mapped regions of transcription, transcription-factor association, chromatin structure and histone modification. In this overview, the Consortium guides the readers through the project itself, the data and their integrated analyses. Eighty per cent of the human genome now has at least one biochemical function assigned to it. In addition to expanding our understanding of how gene expression is regulated on a genome-wide scale, the newly identified functional elements should help researchers to interpret the results of genome-wide associated studies because many correspond to sites associated with human disease.","['ENCODE', 'Human genome', 'Genome', 'Biology', 'Genetics', 'Computational biology', 'Gene', 'Chromatin', 'Genome project', 'Encyclopedia', 'Expansive', 'Computer science', 'Compressive strength', 'Materials science', 'Library science', 'Composite material']","human, encyclopedia, encode, transcription, transcription factor association, chromatin structure, ##tone modification, expressed genes, gene regulation, functional annotations, biomedical, encode, histone modification, gene"
Paper_00569,Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification,"['Kaiming He', 'Xiangyu Zhang', 'Shaoqing Ren', 'Jian Sun']",2015,Unknown,Unknown,,,,,10.1109/iccv.2015.123,"Rectified activation units (rectifiers) are essential for state-of-the-art neural networks. In this work, we study rectifier neural networks for image classification from two aspects. First, we propose a Parametric Rectified Linear Unit (PReLU) that generalizes the traditional rectified unit. PReLU improves model fitting with nearly zero extra computational cost and little overfitting risk. Second, we derive a robust initialization method that particularly considers the rectifier nonlinearities. This method enables us to train extremely deep rectified models directly from scratch and to investigate deeper or wider network architectures. Based on the learnable activation and advanced initialization, we achieve 4.94% top-5 test error on the ImageNet 2012 classification dataset. This is a 26% relative improvement over the ILSVRC 2014 winner (GoogLeNet, 6.66% [33]). To our knowledge, our result is the first to surpass the reported human-level performance (5.1%, [26]) on this dataset.","['Overfitting', 'Initialization', 'Computer science', 'Scratch', 'Artificial intelligence', 'Rectifier (neural networks)', 'Artificial neural network', 'Contextual image classification', 'Parametric statistics', 'Deep neural networks', 'Machine learning', 'Convolutional neural network', 'Deep learning', 'Pattern recognition (psychology)', 'Image (mathematics)', 'Recurrent neural network', 'Mathematics', 'Types of artificial neural networks', 'Statistics', 'Programming language', 'Operating system']","rectified activation units, rectifiers, neural networks, rectifier neural networks, image classification, parametric rectified linear unit, ##lu, ##tified, computational cost, ##fitting, robust initialization method, rectifier nonlinearities, ##able activation, advanced, imagenet, ilsvr, google"
Paper_00571,"Erratum: Atoms, molecules, solids, and surfaces: Applications of the generalized gradient approximation for exchange and correlation","['John P. Perdew', 'J. A. Chevary', 'S. H. Vosko', 'Koblar Alan Jackson', 'Mark R. Pederson', 'Diksha Singh', 'Carlos Fiolhais']",1993,"Physical review. B, Condensed matter",Journal,,4978-4978,48,7,10.1103/physrevb.48.4978.2,PACS number(s),"['Molecule', 'Correlation', 'Materials science', 'Atomic physics', 'Molecular physics', 'Physics', 'Statistical physics', 'Quantum mechanics', 'Mathematics', 'Geometry']",
Paper_00572,Primer-Directed Enzymatic Amplification of DNA with a Thermostable DNA Polymerase,"['Randall K. Saiki', 'David H. Gelfand', 'Susanne Stoffel', 'Stephen J. Scharf', 'Russell Higuchi', 'Glenn T. Horn', 'Kary B. Mullis', 'M Kellis']",1988,Science,Journal,,487-491,239,4839,10.1126/science.2448875,"A thermostable DNA polymerase was used in an in vitro DNA amplification procedure, the polymerase chain reaction. The enzyme, isolated from Thermus aquaticus, greatly simplifies the procedure and, by enabling the amplification reaction to be performed at higher temperatures, significantly improves the specificity, yield, sensitivity, and length of products that can be amplified. Single-copy genomic sequences were amplified by a factor of more than 10 million with very high specificity, and DNA segments up to 2000 base pairs were readily amplified. In addition, the method was used to amplify and detect a target DNA molecule present only once in a sample of 10(5) cells.","['Thermus aquaticus', 'Multiple displacement amplification', 'Hot start PCR', 'DNA polymerase', 'Primer dimer', 'Polymerase chain reaction', 'Primer (cosmetics)', 'Molecular biology', 'Taq polymerase', 'DNA', 'Biology', 'Polymerase chain reaction optimization', 'genomic DNA', 'Polymerase', 'Recombinase Polymerase Amplification', 'Base pair', 'Applications of PCR', 'Chemistry', 'Genetics', 'Digital polymerase chain reaction', 'Multiplex polymerase chain reaction', 'DNA extraction', 'Gene', 'Organic chemistry']","thermostable dna polymerase, polymerase chain reaction, the, [PAD] [PAD] [PAD], [PAD] [PAD], [PAD]"
Paper_00574,Observational Evidence from Supernovae for an Accelerating Universe and a Cosmological Constant,"['Adam G. Riess', 'A. V. Filippenko', 'P. Challis', 'A. Clocchiatti', 'Alan H. Diercks', 'P. Garnavich', 'Ron Gilliland', 'Craig J. Hogan', 'Saurabh W. Jha', 'R. Kirshner', 'B. Leibundgut', 'M. M. Phillips', 'David J. Reiss', 'B. Schmidt', 'R. A. Schommer', 'R. Chris Smith', 'J. Spyromilio', 'C. W. Stubbs', 'N. B. Suntzeff', 'J. Tonry']",1998,The Astronomical Journal,Journal,,1009-1038,116,3,10.1086/300499,"We present spectral and photometric observations of 10 Type Ia supernovae (SNe Ia) in the redshift range 0.16 ≤ z ≤ 0.62. The luminosity distances of these objects are determined by methods that employ relations between SN Ia luminosity and light curve shape. Combined with previous data from our High-z Supernova Search Team and recent results by Riess et al., this expanded set of 16 high-redshift supernovae and a set of 34 nearby supernovae are used to place constraints on the following cosmological parameters: the Hubble constant (H0), the mass density (ΩM), the cosmological constant (i.e., the vacuum energy density, ΩΛ), the deceleration parameter (q0), and the dynamical age of the universe (t0). The distances of the high-redshift SNe Ia are, on average, 10%–15% farther than expected in a low mass density (ΩM = 0.2) universe without a cosmological constant. Different light curve fitting methods, SN Ia subsamples, and prior constraints unanimously favor eternally expanding models with positive cosmological constant (i.e., ΩΛ > 0) and a current acceleration of the expansion (i.e., q0 < 0). With no prior constraint on mass density other than ΩM ≥ 0, the spectroscopically confirmed SNe Ia are statistically consistent with q0 < 0 at the 2.8 σ and 3.9 σ confidence levels, and with ΩΛ > 0 at the 3.0 σ and 4.0 σ confidence levels, for two different fitting methods, respectively. Fixing a ""minimal"" mass density, ΩM = 0.2, results in the weakest detection, ΩΛ > 0 at the 3.0 σ confidence level from one of the two methods. For a flat universe prior (ΩM + ΩΛ = 1), the spectroscopically confirmed SNe Ia require ΩΛ > 0 at 7 σ and 9 σ formal statistical significance for the two different fitting methods. A universe closed by ordinary matter (i.e., ΩM = 1) is formally ruled out at the 7 σ to 8 σ confidence level for the two different fitting methods. We estimate the dynamical age of the universe to be 14.2 ± 1.7 Gyr including systematic uncertainties in the current Cepheid distance scale. We estimate the likely effect of several sources of systematic error, including progenitor and metallicity evolution, extinction, sample selection bias, local perturbations in the expansion rate, gravitational lensing, and sample contamination. Presently, none of these effects appear to reconcile the data with ΩΛ = 0 and q0 ≥ 0.","['Physics', 'Astrophysics', 'Cosmological constant', 'Supernova', 'Redshift', 'Dark energy', ""Hubble's law"", 'Luminosity', 'Luminosity distance', 'Universe', 'Shape of the universe', 'Deceleration parameter', 'Metric expansion of space', 'Cosmology', 'Galaxy', 'Mathematical physics']","##metric, ##ft, luminosity distances, light curve shape, hubble constant, mass density, cosmological constant, vacuum energy density, deceleration parameter, dynamical age of, light curve fitting, flat universe prior"
Paper_00576,Swin Transformer: Hierarchical Vision Transformer using Shifted Windows,"['Ze Liu', 'Yutong Lin', 'Yue Cao', 'Han Hu', 'Yixuan Wei', 'Zheng Zhang', 'Stephen Lin', 'Baining Guo']",2021,2021 IEEE/CVF International Conference on Computer Vision (ICCV),Conference,"2021 IEEE/CVF International Conference on Computer Vision (ICCV), Montreal, QC, Canada",9992-10002,,,10.1109/iccv48922.2021.00986,"This paper presents a new vision Transformer, called Swin Transformer, that capably serves as a general-purpose backbone for computer vision. Challenges in adapting Transformer from language to vision arise from differences between the two domains, such as large variations in the scale of visual entities and the high resolution of pixels in images compared to words in text. To address these differences, we propose a hierarchical Transformer whose representation is computed with Shifted windows. The shifted windowing scheme brings greater efficiency by limiting self-attention computation to non-overlapping local windows while also allowing for cross-window connection. This hierarchical architecture has the flexibility to model at various scales and has linear computational complexity with respect to image size. These qualities of Swin Transformer make it compatible with a broad range of vision tasks, including image classification (87.3 top-1 accuracy on ImageNet-1K) and dense prediction tasks such as object detection (58.7 box AP and 51.1 mask AP on COCO test-dev) and semantic segmentation (53.5 mIoU on ADE20K val). Its performance surpasses the previous state-of-the-art by a large margin of +2.7 box AP and +2.6 mask AP on COCO, and +3.2 mIoU on ADE20K, demonstrating the potential of Transformer-based models as vision backbones. The hierarchical design and the shifted window approach also prove beneficial for all-MLP architectures. The code and models are publicly available at https://github.com/microsoft/Swin-Transformer.","['Transformer', 'Computer science', 'Segmentation', 'Artificial intelligence', 'Computation', 'Pixel', 'Architecture', 'Image segmentation', 'Computer vision', 'Algorithm', 'Engineering', 'Voltage', 'Electrical engineering', 'Art', 'Visual arts']","vision transformer, swin transformer, computer vision, hierarchical transformer, shifted windows, shifted windowing scheme, hierarchical architecture, swin transform, image classification, dense prediction tasks, object detection, semantic segmentation, hierarchical design, shifted window approach"
Paper_00577,Metaphors We Live By,"['George Lakoff', 'Mark L. Johnson']",1980,['South African Journal of African Languages'],Unknown,,71-80,8,sup1,10.1080/02572117.1988.10586767,"People use every time they speak. Some of those are literary - devices for making thoughts more vivid or entertaining. But most are much more basic than that - they're metaphors we live by, we use without even realizing we're using them. In this book, George Lakoff and Mark Johnson suggest that these basic not only affect the way we communicate ideas, but actually structure our perceptions and understandings from the beginning. Bringing together the perspectives of linguistics and philosophy, Lakoff and Johnson offer an intriguing and surprising guide to some of the most common and what they can tell us about the human mind. And for this new edition, they supply an afterword both extending their arguments and offering a fascinating overview of the current state of thinking on the subject of the metaphor.","['Metaphor', 'Subject (documents)', 'Perception', 'George (robot)', 'Affect (linguistics)', 'State (computer science)', 'Epistemology', 'Cognitive science', 'Aesthetics', 'Linguistics', 'Philosophy', 'Psychology', 'Art', 'Computer science', 'Art history', 'Algorithm', 'Library science']","metaphor, linguistics, philosophy, human mind"
Paper_00579,The Interpretation of Cultures,"['Richard K. Fenn', 'Clifford Geertz']",2017,Macat Library eBooks,Unknown,,,,,10.4324/9781912128310,"Clifford Geertz has been called 'the most original anthropologist of his generation' – and this reputation rests largely on the huge contributions to the methodology and approaches of anthropological interpretation that he outlined in The Interpretation of Cultures. The centrality of interpretative skills to anthropology is uncontested: in a subject that is all about understanding mankind, and which seeks to outline the differences and the common ground that exists between cultures, interpretation is the crucial skillset. For Geertz, however, standard interpretative approaches did not go deep enough, and his life's work concentrated on deepening and perfecting his subject's interpretative skills. Geertz is best known for his definition of 'culture,' and his theory of 'thick description,' an influential technique that depends on fresh interpretative approaches. For Geertz, 'cultures' are 'webs of meaning' in which everyone is suspended. Understanding culture, therefore, is not so much a matter of going in search of law, but of setting out an interpretative framework for meaning that focuses directly on attempts to define the real meaning of things within a given culture. The best way to do this, for Geertz, is via 'thick description:' a way of recording things that explores context and surroundings, and articulates meaning within the web of culture. Ambitious and bold, Geertz's greatest creation is a method all critical thinkers can learn from.","['Interpretation (philosophy)', 'Linguistics', 'Philosophy']","anthropological interpretation, interpretative skills, thick description, thick description"
Paper_00580,A method for registration of 3-D shapes,"['Paul J. Besl', 'Neil David McKay']",1992,IEEE Transactions on Pattern Analysis and Machine Intelligence,Journal,,239-256,14,2,10.1109/34.121791,"The authors describe a general-purpose, representation-independent method for the accurate and computationally efficient registration of 3-D shapes including free-form curves and surfaces. The method handles the full six degrees of freedom and is based on the iterative closest point (ICP) algorithm, which requires only a procedure to find the closest point on a geometric entity to a given point. The ICP algorithm always converges monotonically to the nearest local minimum of a mean-square distance metric, and the rate of convergence is rapid during the first few iterations. Therefore, given an adequate set of initial rotations and translations for a particular class of objects with a certain level of 'shape complexity', one can globally minimize the mean-square distance metric over all six degrees of freedom by testing each initial registration. One important application of this method is to register sensed data from unfixtured rigid objects with an ideal geometric model, prior to shape inspection. Experimental results show the capabilities of the registration algorithm on point sets, curves, and surfaces.< <ETX xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">&gt;</ETX>","['Iterative closest point', 'Metric (unit)', 'Point (geometry)', 'Representation (politics)', 'Algorithm', 'Degrees of freedom (physics and chemistry)', 'Convergence (economics)', 'Mathematics', 'Computer science', 'Set (abstract data type)', 'Image registration', 'Square (algebra)', 'Artificial intelligence', 'Point cloud', 'Image (mathematics)', 'Geometry', 'Operations management', 'Physics', 'Quantum mechanics', 'Politics', 'Law', 'Political science', 'Economics', 'Programming language', 'Economic growth']","iterative closest point, shape complexity, ##ured rigid objects, shape inspection, registration algorithm"
Paper_00581,fastp: an ultra-fast all-in-one FASTQ preprocessor,"['Shifu Chen', 'Yanqing Zhou', 'Yaru Chen', 'Jia Gu']",2018,Bioinformatics,Journal,,i884-i890,34,17,10.1093/bioinformatics/bty560,"Quality control and preprocessing of FASTQ files are essential to providing clean data for downstream analysis. Traditionally, a different tool is used for each operation, such as quality control, adapter trimming and quality filtering. These tools are often insufficiently fast as most are developed using high-level programming languages (e.g. Python and Java) and provide limited multi-threading support. Reading and loading data multiple times also renders preprocessing slow and I/O inefficient.We developed fastp as an ultra-fast FASTQ preprocessor with useful quality control and data-filtering features. It can perform quality control, adapter trimming, quality filtering, per-read quality pruning and many other operations with a single scan of the FASTQ data. This tool is developed in C++ and has multi-threading support. Based on our evaluation, fastp is 2-5 times faster than other FASTQ preprocessing tools such as Trimmomatic or Cutadapt despite performing far more operations than similar tools.The open-source code and corresponding instructions are available at https://github.com/OpenGene/fastp.","['Computer science', 'Preprocessor', 'Trimming', 'Python (programming language)', 'Adapter (computing)', 'Java', 'Data mining', 'Data pre-processing', 'Programming language', 'Source code', 'Operating system']","quality control, preprocessing, fastq files, downstream analysis, quality control, adapter trimming, quality filtering, fastp, quality control, adapter trimming, quality filtering, fastp, fastq prepro, trimmomatic, cutadapt"
Paper_00582,Assessment of Older People: Self-Maintaining and Instrumental Activities of Daily Living,"['M. P. Lawton', 'Elaine Brody']",1969,The Gerontologist,Journal,,179-186,9,3 Part 1,10.1093/geront/9.3_part_1.179,"Journal Article Assessment of Older People: Self-Maintaining and Instrumental Activities of Daily Living Get access M. Powell Lawton, PhD, M. Powell Lawton, PhD 2Research Psychologist Philadelphia Geriatric Center 5301 Old York RoadPhiladelphia 19141 Search for other works by this author on: Oxford Academic PubMed Google Scholar Elaine M. Brody, ACSW Elaine M. Brody, ACSW Director 3Department of Social WorkPhiladelphia Geriatric Center Search for other works by this author on: Oxford Academic PubMed Google Scholar The Gerontologist, Volume 9, Issue 3_Part_1, Autumn 1969, Pages 179–186, https://doi.org/10.1093/geront/9.3_Part_1.179 Published: 01 October 1969","['Older people', 'Gerontology', 'Activities of daily living', 'Center (category theory)', 'Psychology', 'Medicine', 'Psychiatry', 'Chemistry', 'Crystallography']","older people, instrumental activities, daily living, philadelphia geriatric center, 3dep, gerontologist"
Paper_00583,Characteristics of and Important Lessons From the Coronavirus Disease 2019 (COVID-19) Outbreak in China,"['Zunyou Wu', 'Jennifer M. McGoogan']",2020,JAMA,Journal,,1239-1239,323,13,10.1001/jama.2020.2648,"This Viewpoint summarizes key epidemiologic and clinical findings from all cases of coronavirus disease 2019 (COVID-19) reported through February 11, 2020, in mainland China, and case trends in response to government attempts to control and contain the infection.","['Medicine', 'Coronavirus disease 2019 (COVID-19)', 'Outbreak', 'Mainland China', '2019-20 coronavirus outbreak', 'Severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2)', 'Coronavirus', 'China', 'Betacoronavirus', 'Virology', 'Government (linguistics)', 'Disease', 'Coronavirus Infections', 'Contact tracing', 'Pandemic', 'Environmental health', 'Infectious disease (medical specialty)', 'Pathology', 'Geography', 'Archaeology', 'Linguistics', 'Philosophy']",coronavirus disease
Paper_00585,GRADE: an emerging consensus on rating quality of evidence and strength of recommendations,"['Gordon Guyatt', 'Andrew D Oxman', 'Gunn Elisabeth Vist', 'Regina Kunz', 'Yngve Falck–Ytter', 'Pablo Alonso‐Coello', 'Holger J. Schünemann']",2008,BMJ,Journal,,924-926,336,7650,10.1136/bmj.39489.470347.ad,"Guidelines are inconsistent in how they rate the quality of evidence and the strength of recommendations. This article explores the advantages of the GRADE system, which is increasingly being adopted by organisations worldwide","['Quality of evidence', 'Quality (philosophy)', 'Consensus conference', 'Computer science', 'Evidence-based medicine', 'Rating system', 'Medicine', 'Data science', 'Alternative medicine', 'Meta-analysis', 'Pathology', 'Environmental economics', 'Economics', 'Library science', 'Philosophy', 'Epistemology']",
Paper_00587,Competitive Strategy: Techniques for Analyzing Industries and Competitors,['Michael E. Porter'],1980,['Industrial Marketing Management'],Unknown,,318-319,11,4,10.1016/0019-8501(82)90025-6,"Michael Porter presents a comprehensive structural framework and analytical techniques to help a firm to analyze its industry and evolution, understand its competitors and its own position, and translate this understanding into a competitive strategy to allow the firm to compete more effectively to strengthen its market position. The introduction reviews a classic approach to strategy formulation, one that comprises a combination of ends and means (policies), factors that limit what a company can accomplish, tests of consistency, and an approach for developing competitive strategy. A competitive strategy articulates a firm's goals, how it will compete, and its policies for achieving those goals. Competitive advantage is defined in terms of cost and differentiation while linking it to profitability. Part I, General Analytical Techniques, provides a general framework for analyzing the structure of an industry and understanding the underlying forces of competition (and hence profitability). Five competitive forces act on an industry: (1) threat of new entrants, (2) intensity of rivalry among existing firms, (3) threat of substitute products or services, (4) bargaining power of buyers, and (5) bargaining power of suppliers. Looking at industry structure provides a way to consider how value is created and divided among existing and potential industry participants. One competitive force always captures essential issues in the division of value.There are three generic competitive strategies for coping with the five competitive forces: (1) overall cost leadership, (2) differentiation, and (3) focus. There are risks with each strategy. A firm without a strategy is stuck in the middle. This framework for examining competition transcends particular industry, technology, or management theories. Building on this framework, techniques are presented for industry forecasting, analysis of competitors, predicting their behavior, and building a response profile. Essential for a competitive strategy are techniques for recognizing and accurately reading market signals. Implications of structural analysis for buyer selection and purchasing strategy are presented. Game theory provides concepts for responding to competitive moves. Using the concept of strategic groups, structural analysis can also explain differences in firm performance (profitability), provide a guide for competitive strategy, and predict industry evolution. Part II, Generic Industry Environments, shows how firms can use the analytical framework to develop a competitive strategy in industry environments, which reflect differences in industry concentration, state of industry maturity, and exposure to international competition. These environments determine a business's competitive strategic context, available alternatives, and common strategic errors. Five generic industry environments are examined: fragmented industries (where level of industrial concentration is low), emerging industries, transition to industry maturity, declining industries, and global industries. In each, the crucial aspects of industry structure, key strategic issues, characteristic strategic alternatives (including divestment), and strategic pitfalls are identified. Part III, Strategic Decisions, draws on the analytical framework to examine important types of strategic decisions confronting firms that compete in a single industry: vertical integration, major capacity expansion, and new business entry. Additional use of economic theory and administrative consideration of management and motivation helps a company to make key decisions, and gives insight into how competitors, customers, suppliers, and potential entrants might make them. Appendix A discusses use of techniques for portfolio analysis applied to competitor analysis. Appendix B provides approaches to conducting an industry study, including sources of field and published dat","['Competitor analysis', 'Profitability index', 'Rivalry', 'Industrial organization', 'Competitive advantage', 'Business', 'Bargaining power', 'Position (finance)', 'Competition (biology)', 'Cost leadership', 'Marketing', 'Consistency (knowledge bases)', 'Economics', 'Microeconomics', 'Computer science', 'Ecology', 'Finance', 'Artificial intelligence', 'Biology']","structural framework, analytical techniques, competitive strategy, strategy formulation, competitive strategy, competitive strategy, competitive advantage, cost, differentiation, profitability, profitability, bargaining power, bargaining power, cost leadership, industry forecasting, structural analysis, buyer selection, purchasing strategy, game theory, strategic groups, structural analysis, firm performance, profitability, competitive strategy, generic industry environments, industry environments, industry concentration, international, strategic, generic, fragmented industries"
Paper_00588,ESTIMATING<i>F</i>-STATISTICS FOR THE ANALYSIS OF POPULATION STRUCTURE,"['B. S. Weir', 'C. Clark Cockerham']",1984,Evolution,Journal,,1358-1370,38,6,10.1111/j.1558-5646.1984.tb05657.x,Corresponding Editor: J. Felsenstein,"['Biology', 'Statistics', 'Population', 'Population structure', 'Demography', 'Mathematics', 'Sociology']",
Paper_00590,The Commitment-Trust Theory of Relationship Marketing,"['Robert M. Morgan', 'Shelby D. Hunt']",1994,Journal of Marketing,Journal,,20-20,58,3,10.2307/1252308,"Relationship marketing—establishing, developing, and maintaining successful relational exchanges—constitutes a major shift in marketing theory and practice. After conceptualizing relationship marketing and discussing its ten forms, the authors (1) theorize that successful relationship marketing requires relationship commitment and trust, (2) model relationship commitment and trust as key mediating variables, (3) test this key mediating variable model using data from automobile tire retailers, and (4) compare their model with a rival that does not allow relationship commitment and trust to function as mediating variables. Given the favorable test results for the key mediating variable model, suggestions for further explicating and testing it are offered.","['Relationship marketing', 'Key (lock)', 'Marketing', 'Business', 'Test (biology)', 'Structural equation modeling', 'Variable (mathematics)', 'Function (biology)', 'Variables', 'Marketing management', 'Computer science', 'Mathematics', 'Paleontology', 'Mathematical analysis', 'Computer security', 'Machine learning', 'Evolutionary biology', 'Biology']","relationship marketing, relational exchanges, marketing, relationship marketing, relationship marketing, relationship commitment, trust, relationship commitment, trust, automobile tire retailers, relationship commitment"
Paper_00592,Elements of X-ray diffraction,['B. D. Cullity'],1956,['American Journal of Physics'],Unknown,,394-395,25,6,10.1119/1.1934486,1. Properties of X-rays. 2. Geometry of Crystals. 3. Diffraction I: Directions of Diffracted Beams. 4. Diffraction II: Intensities of Diffracted Beams. 5. Diffraction III: Non-Ideal Samples. 6. Laure Photographs. 7. Powder Photographs. 8. Diffractometer and Spectrometer. 9. Orientation and Quality of Single Crystals. 10. Structure of Polycrystalline Aggregates. 11. Determination of Crystal Structure. 12. Precise Parameter Measurements. 13. Phase-Diagram Determination. 14. Order-Disorder Transformation. 15. Chemical Analysis of X-ray Diffraction. 16. Chemical Analysis by X-ray Spectrometry. 17. Measurements of Residual Stress. 18. Polymers. 19. Small Angle Scatters. 20. Transmission Electron Microscope.,"['Diffractometer', 'Diffraction', 'Materials science', 'X-ray crystallography', 'Powder diffraction', 'Optics', 'Crystallite', 'Crystallography', 'Selected area diffraction', 'Chemistry', 'Crystal structure', 'Physics']","diffraction, diffracted beams, diffraction, ##ensities, diffracted beams, diffraction, ideal, laure photographs, powder photographs, diffrac, single crystals, polycrystalline aggregates, crystal, precise parameter measurements, chemical analysis, chemical analysis, residual stress, polymers, small angle scatters, transmission electron microscope"
Paper_00593,Significance tests and goodness of fit in the analysis of covariance structures.,"['Peter M. Bentler', 'Douglas G. Bonett']",1980,Psychological Bulletin,Journal,,588-606,88,3,10.1037/0033-2909.88.3.588,"Factor analysis, path analysis, structural equation modeling, and related multivariate statistical methods are based on maximum likelihood or generalized least squares estimation developed for covariance structure models. Large-sample theory provides a chi-square goodness-of-fit test for comparing a model against a general alternative model based on correlated variables. This model comparison is insufficient for model evaluation: In large samples virtually any model tends to be rejected as inadequate, and in small samples various competing models, if evaluated, might be equally acceptable. A general null model based on modified independence among variables is proposed to provide an additional reference point for the statistical and scientific evaluation of covariance structure models. Use of the null model in the context of a procedure that sequentially evaluates the statistical necessity of various sets of parameters places statistical methods in covariance structure analysis into a more complete framework. The concepts of ideal models and pseudo chi-square tests are introduced, and their roles in hypothesis testing are developed. The importance of supplementing statistical evaluation with incremental fit indices associated with the comparison of hierarchical models is also emphasized. Normed and nonnormed fit indices are developed and illustrated.","['Goodness of fit', 'Covariance', 'Analysis of covariance', 'Statistics', 'Psychology', 'Statistical analysis', 'Statistical hypothesis testing', 'Mathematics', 'Econometrics']","factor analysis, path analysis, structural equation modeling, multivariate statistical methods, maximum likelihood, generalized least squares estimation, covariance structure models, correlated variables, general, modified, covariance structure models, covariance structure analysis, ideal models, hypothesis testing, statistical evaluation, incremental fit indices, hierarchical models, nonnormed fit indices"
Paper_00595,Boundary layer theory,['Hermann Schlichting'],1955,['European Journal of Mechanics - B/Fluids'],Unknown,,155-157,20,1,10.1016/s0997-7546(00)01101-8,"The flow laws of the actual flows at high Reynolds numbers differ considerably from those of the laminar flows treated in the preceding part. These actual flows show a special characteristic, denoted as turbulence. The character of a turbulent flow is most easily understood the case of the pipe flow. Consider the flow through a straight pipe of circular cross section and with a smooth wall. For laminar flow each fluid particle moves with uniform velocity along a rectilinear path. Because of viscosity, the velocity of the particles near the wall is smaller than that of the particles at the center. i% order to maintain the motion, a pressure decrease is required which, for laminar flow, is proportional to the first power of the mean flow velocity. Actually, however, one ob~erves that, for larger Reynolds numbers, the pressure drop increases almost with the square of the velocity and is very much larger then that given by the Hagen Poiseuille law. One may conclude that the actual flow is very different from that of the Poiseuille flow.","['Laminar flow', 'Hagen–Poiseuille equation', 'Mechanics', 'Turbulence', 'Laminar sublayer', 'Reynolds number', 'Boundary layer', 'Open-channel flow', 'Laminar flow reactor', 'Pressure drop', 'Hele-Shaw flow', 'Chézy formula', 'Pipe flow', 'Flow (mathematics)', 'Physics', 'Flow separation', 'Law of the wall', 'Potential flow around a circular cylinder', 'Classical mechanics']","flow laws, laminar flows, turbulence, turbulent flow, pipe flow, circular, ##ina, rectilinear, viscosity, pressure decrease, pressure drop, hagen poise, poise"
Paper_00596,Development as Freedom,['Amartya Sen'],1999,['Development in Practice'],Unknown,,193-200,16,2,10.1080/09614520600562439,"In Development as Freedom Amartya Sen quotes the eighteenth century poet William Cowper on freedom: Freedom has a thousand charms to show, That slaves howe'er contented, never know. Sen explains how in a world of unprecedented increase in overall opulence, millions of people living in rich and poor countries are still unfree. Even if they are not technically slaves, they are denied elementary freedom and remain imprisoned in one way or another by economic poverty, social deprivation, political tyranny or cultural authoritarianism. The main purpose of development is to spread freedom and its 'thousand charms' to the unfree citizens. Freedom, Sen persuasively argues, is at once the ultimate goal of social and economic arrangements and the most efficient means of realizing general welfare. Social institutions like markets, political parties, legislatures, the judiciary, and the media contribute to development by enhancing individual freedom and are in turn sustained by social values. Values, institutions, development, and freedom are all closely interrelated, and Sen links them together in an elegant analytical framework. By asking What is the relation between our collective economic wealth and our individual ability to live as we would like? and by incorporating individual freedom as a social commitment into his analysis, Sen allows economics once again, as it did in the time of Adam Smith, to address the social basis of individual well-being and freedom.","['Political freedom', 'Politics', 'Authoritarianism', 'Economic freedom', 'Poverty', 'Political science', 'Legislature', 'Law and economics', 'Political economy', 'Sociology', 'Law', 'Democracy']","economic poverty, social deprivation, political tyranny, cultural authoritarianism, social institutions, markets, political parties, legislatures, judiciary, media, individual freedom, values, institutions, development, freedom, collective economic wealth, individual freedom"
Paper_00599,Development and testing of a general amber force field,"['Junmei Wang', 'Romain M. Wolf', 'James W. Caldwell', 'Peter A. Kollman', 'David A. Case']",2004,Journal of Computational Chemistry,Journal,,1157-1174,25,9,10.1002/jcc.20035,"We describe here a general Amber force field (GAFF) for organic molecules. GAFF is designed to be compatible with existing Amber force fields for proteins and nucleic acids, and has parameters for most organic and pharmaceutical molecules that are composed of H, C, N, O, S, P, and halogens. It uses a simple functional form and a limited number of atom types, but incorporates both empirical and heuristic models to estimate force constants and partial atomic charges. The performance of GAFF in test cases is encouraging. In test I, 74 crystallographic structures were compared to GAFF minimized structures, with a root-mean-square displacement of 0.26 A, which is comparable to that of the Tripos 5.2 force field (0.25 A) and better than those of MMFF 94 and CHARMm (0.47 and 0.44 A, respectively). In test II, gas phase minimizations were performed on 22 nucleic acid base pairs, and the minimized structures and intermolecular energies were compared to MP2/6-31G* results. The RMS of displacements and relative energies were 0.25 A and 1.2 kcal/mol, respectively. These data are comparable to results from Parm99/RESP (0.16 A and 1.18 kcal/mol, respectively), which were parameterized to these base pairs. Test III looked at the relative energies of 71 conformational pairs that were used in development of the Parm99 force field. The RMS error in relative energies (compared to experiment) is about 0.5 kcal/mol. GAFF can be applied to wide range of molecules in an automatic fashion, making it suitable for rational drug design and database searching.","['Force field (fiction)', 'Chemistry', 'Computational chemistry', 'Molecule', 'Intermolecular force', 'Atom (system on chip)', 'Base (topology)', 'Thermodynamics', 'Crystallography', 'Mathematics', 'Physics', 'Organic chemistry', 'Computer science', 'Mathematical analysis', 'Embedded system', 'Quantum mechanics']","general amber force field, gaff, organic molecules, gaff, amber force fields, nucleic, pharmaceutical, ##uri, force constants, partial atomic charges, ##ff, tripos, charmm, gas phase minimizations, nucleic, inter, relative, conformational pairs, rms, ##ff, database searching"
Paper_00600,The Social Construction of Reality: A Treatise in the Sociology of Knowledge.,"['George L. Simpson', 'Peter L. Berger', 'Thomas Luckmann']",1967,American Sociological Review,Journal,,137-137,32,1,10.2307/2091739,"A general and systematic account of the role of knowledge in society aimed to stimulate both critical discussion and empirical investigations. This book is concerned with the sociology of 'everything that passes for knowledge in society'. It focuses particularly on that 'common-sense knowledge' which constitutes the reality of everyday life for the ordinary member of society. The authors are concerned to present an analysis of knowledge in everyday life in the context of a theory of society as a dialectical process between objective and subjective reality. Their development of a theory of institutions, legitimations and socializations has implications beyond the discipline of sociology, and their 'humanistic' approach has considerable relevance for other social scientists, historians, philosophers and anthropologists.","['Sociology', 'Social reality', 'Sociology of knowledge', 'Epistemology', 'Social constructionism', 'Social science', 'Philosophy']","knowledge, everyday life, society, social, [PAD]"
Paper_00602,phyloseq: An R Package for Reproducible Interactive Analysis and Graphics of Microbiome Census Data,"['Paul J. McMurdie', 'Susan Holmes']",2013,PLoS ONE,Journal,,e61217-e61217,8,4,10.1371/journal.pone.0061217,"Background The analysis of microbial communities through DNA sequencing brings many challenges: the integration of different types of data with methods from ecology, genetics, phylogenetics, multivariate statistics, visualization and testing. With the increased breadth of experimental designs now being pursued, project-specific statistical analyses are often needed, and these analyses are often difficult (or impossible) for peer researchers to independently reproduce. The vast majority of the requisite tools for performing these analyses reproducibly are already implemented in R and its extensions (packages), but with limited support for high throughput microbiome census data. Results Here we describe a software project, phyloseq, dedicated to the object-oriented representation and analysis of microbiome census data in R. It supports importing data from a variety of common formats, as well as many analysis techniques. These include calibration, filtering, subsetting, agglomeration, multi-table comparisons, diversity analysis, parallelized Fast UniFrac, ordination methods, and production of publication-quality graphics; all in a manner that is easy to document, share, and modify. We show how to apply functions from other R packages to phyloseq-represented data, illustrating the availability of a large number of open source analysis techniques. We discuss the use of phyloseq with tools for reproducible research, a practice common in other fields but still rare in the analysis of highly parallel microbiome census data. We have made available all of the materials necessary to completely reproduce the analysis and figures included in this article, an example of best practices for reproducible research. Conclusions The phyloseq project for R is a new open-source software package, freely available on the web from both GitHub and Bioconductor.","['UniFrac', 'Computer science', 'Data science', 'Data mining', 'Visualization', 'Data visualization', 'Graphics', 'Microbiome', 'R package', 'Software', 'Information retrieval', 'Bioinformatics', 'Biology', 'Genetics', 'Computer graphics (images)', '16S ribosomal RNA', 'Computational science', 'Bacteria', 'Programming language']","microbial communities, dna sequencing, ecology, genetics, phylogenetics, multivariate statistics, visualization, phyloseq, microbiome census data, calibration, filtering, subsetting, agglomeration, diversity analysis, parallelized fast unifrac, ordination methods, phyloseq, ##roducible research, ##roducible, phyloseq, gi, ##ub, biocon, ##ctor"
Paper_00604,"The magical number seven, plus or minus two: Some limits on our capacity for processing information.",['George Miller'],1994,Psychological Review,Journal,,343-352,101,2,10.1037/0033-295x.101.2.343,"First, the span of absolute judgment and the span of immediate memory impose severe limitations on the amount of information that we are able to receive, process, and remember. By organizing the stimulus input simultaneously into several dimensions and successively into a sequence or chunks, we manage to break (or at least stretch) this informational bottleneck. Second, the process of recoding is a very important one in human psychology and deserves much more explicit attention than it has received. In particular, the kind of linguistic recoding that people do seems to me to be the very lifeblood of the thought processes. Recoding procedures are a constant concern to clinicians, social psychologists, linguists, and anthropologists and yet, probably because recoding is less accessible to experimental manipulation than nonsense syllables or T mazes, the traditional experimental psychologist has contributed little or nothing to their analysis. Nevertheless, experimental techniques can be used, methods of recoding can be specified, behavioral indicants can be found. And I anticipate that we will find a very orderly set of relations describing what now seems an uncharted wilderness of individual differences. Third, the concepts and measures provided by the theory of information provide a quantitative way of getting at some of these questions. The theory provides us with a yardstick for calibrating our stimulus materials and for measuring the performance of our subjects. In the interests of communication I have suppressed the technical details of information measurement and have tried to express the ideas in more familiar terms; I hope this paraphrase will not lead you to think they are not useful in research. Informational concepts have already proved valuable in the study of discrimination and of language; they promise a great deal in the study of learning and memory; and it has even been proposed that they can be useful in the study of concept formation. A lot of questions that seemed fruitless twenty or thirty years ago may now be worth another look. In fact, I feel that my story here must stop just as it begins to get really interesting. And finally, what about the magical number seven? What about the seven wonders of the world, the seven seas, the seven deadly sins, the seven daughters of Atlas in the Pleiades, the seven ages of man, the seven levels of hell, the seven primary colors, the seven notes of the musical scale, and the seven days of the week? What about the seven-point rating scale, the seven categories for absolute judgment, the seven objects in the span of attention, and the seven digits in the span of immediate memory? For the present I propose to withhold judgment. Perhaps there is something deep and profound behind all these sevens, something just calling out for us to discover it. But I suspect that it is only a pernicious, Pythagorean coincidence.","['Information processing', 'Psychology', 'Computer science', 'Cognitive psychology']","absolute judgment, immediate memory, human psychology, linguistic recoding, clinic, social psychologists, linguist, anthropologist, nonsense syllables, t mazes, experimental psychologist, behavioral indicants, information measurement, discrimination, concept formation, magical number seven, seven, seven seas, seven, seven, pleiades, seven ages, seven levels of, seven, musical scale, absolute judgment"
Paper_00605,Bootstrap Methods: Another Look at the Jackknife,['B. Efron'],1979,The Annals of Statistics,Journal,,,7,1,10.1214/aos/1176344552,"We discuss the following problem: given a random sample $\mathbf{X} = (X_1, X_2, \cdots, X_n)$ from an unknown probability distribution $F$, estimate the sampling distribution of some prespecified random variable $R(\mathbf{X}, F)$, on the basis of the observed data $\mathbf{x}$. (Standard jackknife theory gives an approximate mean and variance in the case $R(\mathbf{X}, F) = \theta(\hat{F}) - \theta(F), \theta$ some parameter of interest.) A general method, called the ""bootstrap,"" is introduced, and shown to work satisfactorily on a variety of estimation problems. The jackknife is shown to be a linear approximation method for the bootstrap. The exposition proceeds by a series of examples: variance of the sample median, error rates in a linear discriminant analysis, ratio estimation, estimating regression parameters, etc.","['Jackknife resampling', 'Mathematics', 'Statistics', 'Random variable', 'Distribution (mathematics)', 'Linear discriminant analysis', 'Combinatorics', 'Applied mathematics', 'Mathematical analysis', 'Estimator']","random sample, unknown probability distribution, sampling distribution, ##ecified random variable, jackknife, approximate mean, bootstrap, jack, ##fe, linear approximation method, bootstrap, variance, sample median, error rates, linear discriminant analysis, ratio estimation, regression parameters, [PAD] [PAD] [PAD] [PAD], [PAD] [PAD], [PAD], [PAD] [PAD] [PAD]"
Paper_00606,The diagnosis of dementia due to Alzheimer's disease: Recommendations from the National Institute on Aging‐Alzheimer's Association workgroups on diagnostic guidelines for Alzheimer's disease,"['Guy M. McKhann', 'David S. Knopman', 'Howard Chertkow', 'Bradley T. Hyman', 'Clifford R. Jack', 'Claudia H. Kawas', 'William E. Klunk', 'Walter J. Koroshetz', 'Jennifer J. Manly', 'Richard Mayeux', 'Richard C. Mohs', 'John C. Morris', 'Martin N. Rossor', 'Philip Scheltens', 'María C. Carrillo', 'Bill Thies', 'Sandra Weıntraub', 'Creighton H. Phelps']",2011,Alzheimer s & Dementia,Journal,,263-269,7,3,10.1016/j.jalz.2011.03.005,"The National Institute on Aging and the Alzheimer's Association charged a workgroup with the task of revising the 1984 criteria for Alzheimer's disease (AD) dementia. The workgroup sought to ensure that the revised criteria would be flexible enough to be used by both general healthcare providers without access to neuropsychological testing, advanced imaging, and cerebrospinal fluid measures, and specialized investigators involved in research or in clinical trial studies who would have these tools available. We present criteria for all‐cause dementia and for AD dementia. We retained the general framework of probable AD dementia from the 1984 criteria. On the basis of the past 27 years of experience, we made several changes in the clinical criteria for the diagnosis. We also retained the term possible AD dementia, but redefined it in a manner more focused than before. Biomarker evidence was also integrated into the diagnostic formulations for probable and possible AD dementia for use in research settings. The core clinical criteria for AD dementia will continue to be the cornerstone of the diagnosis in clinical practice, but biomarker evidence is expected to enhance the pathophysiological specificity of the diagnosis of AD dementia. Much work lies ahead for validating the biomarker diagnosis of AD dementia.","['Dementia', 'Disease', ""Alzheimer's disease"", 'Association (psychology)', 'Medicine', 'Gerontology', 'Psychiatry', 'Psychology', 'Pathology', 'Psychotherapist']","alzheimer, general healthcare providers, neuro, ##logical testing, advanced imaging, cerebrospinal fluid measures, clinical, ad dementia, probable ad dementia, possible ad dementia, biomarker evidence, biomarker evidence, biomarker diagnosis, ad dementia, [PAD] [PAD] [PAD], [PAD]"
Paper_00607,"YOLO9000: Better, Faster, Stronger","['Joseph Redmon', 'Ali Farhadi']",2017,Unknown,Unknown,,6517-6525,,,10.1109/cvpr.2017.690,"We introduce YOLO9000, a state-of-the-art, real-time object detection system that can detect over 9000 object categories. First we propose various improvements to the YOLO detection method, both novel and drawn from prior work. The improved model, YOLOv2, is state-of-the-art on standard detection tasks like PASCAL VOC and COCO. Using a novel, multi-scale training method the same YOLOv2 model can run at varying sizes, offering an easy tradeoff between speed and accuracy. At 67 FPS, YOLOv2 gets 76.8 mAP on VOC 2007. At 40 FPS, YOLOv2 gets 78.6 mAP, outperforming state-of-the-art methods like Faster RCNN with ResNet and SSD while still running significantly faster. Finally we propose a method to jointly train on object detection and classification. Using this method we train YOLO9000 simultaneously on the COCO detection dataset and the ImageNet classification dataset. Our joint training allows YOLO9000 to predict detections for object classes that dont have labelled detection data. We validate our approach on the ImageNet detection task. YOLO9000 gets 19.7 mAP on the ImageNet detection validation set despite only having detection data for 44 of the 200 classes. On the 156 classes not in COCO, YOLO9000 gets 16.0 mAP. YOLO9000 predicts detections for more than 9000 different object categories, all in real-time.","['Object detection', 'Pascal (unit)', 'Computer science', 'Artificial intelligence', 'Pattern recognition (psychology)', 'Object (grammar)', 'Training set', 'Computer vision', 'Programming language']","yolo9000, yolo detection method, yolov2, pascal voc, coco, ##lov, ##lov, voc, ##lov, ##nn, resnet, ssd, object detection, classification, ##lo9000, coco detection dataset, imagenet classification dataset, ##lo9000, imagenet detection, ##lo9000, imagenet detection validation set, coco, ##lo9000"
Paper_00610,Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift,"['Sergey Ioffe', 'Christian Szegedy']",2015,['IEEE Transactions on Neural Networks and Learning Systems'],Unknown,,5082-5092,32,11,10.1109/tnnls.2020.3026784,"Training Deep Neural Networks is complicated by the fact that the distribution of each layer's inputs changes during training, as the parameters of the previous layers change. This slows down the training by requiring lower learning rates and careful parameter initialization, and makes it notoriously hard to train models with saturating nonlinearities. We refer to this phenomenon as internal covariate shift, and address the problem by normalizing layer inputs. Our method draws its strength from making normalization a part of the model architecture and performing the normalization for each training mini-batch. Batch Normalization allows us to use much higher learning rates and be less careful about initialization. It also acts as a regularizer, in some cases eliminating the need for Dropout. Applied to a state-of-the-art image classification model, Batch Normalization achieves the same accuracy with 14 times fewer training steps, and beats the original model by a significant margin. Using an ensemble of batch-normalized networks, we improve upon the best published result on ImageNet classification: reaching 4.9% top-5 validation error (and 4.8% test error), exceeding the accuracy of human raters.","['Normalization (sociology)', 'Initialization', 'Computer science', 'Artificial intelligence', 'Margin (machine learning)', 'Artificial neural network', 'Covariate', 'Training (meteorology)', 'Deep neural networks', 'Word error rate', 'Deep learning', 'Training set', 'Machine learning', 'Pattern recognition (psychology)', 'Physics', 'Sociology', 'Meteorology', 'Anthropology', 'Programming language']","learning rates, parameter initialization, internal covariate shift, normalization, batch normalization, image classification, batch normalization, imagenet classification, human rate, [PAD], [PAD], [PAD] [PAD]"
Paper_00542,"A Simple, Fast, and Accurate Algorithm to Estimate Large Phylogenies by Maximum Likelihood","['Stéphane Guindon', 'Olivier Gascuel']",2003,Systematic Biology,Journal,,696-704,52,5,10.1080/10635150390235520,"The increase in the number of large data sets and the complexity of current probabilistic sequence evolution models necessitates fast and reliable phylogeny reconstruction methods. We describe a new approach, based on the maximum-likelihood principle, which clearly satisfies these requirements. The core of this method is a simple hill-climbing algorithm that adjusts tree topology and branch lengths simultaneously. This algorithm starts from an initial tree built by a fast distance-based method and modifies this tree to improve its likelihood at each iteration. Due to this simultaneous adjustment of the topology and branch lengths, only a few iterations are sufficient to reach an optimum. We used extensive and realistic computer simulations to show that the topological accuracy of this new method is at least as high as that of the existing maximum-likelihood programs and much higher than the performance of distance-based and parsimony approaches. The reduction of computing time is dramatic in comparison with other maximum-likelihood packages, while the likelihood maximization ability tends to be higher. For example, only 12 min were required on a standard personal computer to analyze a data set consisting of 500 rbc L sequences with 1,428 base pairs from plant plastids, thus reaching a speed of the same order as some popular distance-based and parsimony algorithms. This new method is implemented in the PHYML program, which is freely available on our web page: http://www.lirmm.fr/w3ifa/MAAS/.","['Algorithm', 'Tree (set theory)', 'Simple (philosophy)', 'Expectation–maximization algorithm', 'Set (abstract data type)', 'Computer science', 'Maximization', 'Maximum likelihood', 'Maximum parsimony', 'Probabilistic logic', 'Sequence (biology)', 'Mathematics', 'Phylogenetic tree', 'Mathematical optimization', 'Statistics', 'Artificial intelligence', 'Combinatorics', 'Biology', 'Clade', 'Philosophy', 'Biochemistry', 'Genetics', 'Epistemology', 'Gene', 'Programming language']","##bilistic sequence evolution models, phylogeny reconstruction methods, branch lengths, computer simulations, topological accuracy, parsimony, likelihood maximization, plant plastids, ph, ##l"
Paper_00543,New Algorithms and Methods to Estimate Maximum-Likelihood Phylogenies: Assessing the Performance of PhyML 3.0,"['Stéphane Guindon', 'Jean-François Dufayard', 'Vincent Lefort', 'Maria Anisimova', 'Wim Hordijk', 'Olivier Gascuel']",2010,Systematic Biology,Journal,,307-321,59,3,10.1093/sysbio/syq010,"PhyML is a phylogeny software based on the maximum-likelihood principle. Early PhyML versions used a fast algorithm performing nearest neighbor interchanges to improve a reasonable starting tree topology. Since the original publication (Guindon S., Gascuel O. 2003. A simple, fast and accurate algorithm to estimate large phylogenies by maximum likelihood. Syst. Biol. 52:696–704), PhyML has been widely used (>2500 citations in ISI Web of Science) because of its simplicity and a fair compromise between accuracy and speed. In the meantime, research around PhyML has continued, and this article describes the new algorithms and methods implemented in the program. First, we introduce a new algorithm to search the tree space with user-defined intensity using subtree pruning and regrafting topological moves. The parsimony criterion is used here to filter out the least promising topology modifications with respect to the likelihood function. The analysis of a large collection of real nucleotide and amino acid data sets of various sizes demonstrates the good performance of this method. Second, we describe a new test to assess the support of the data for internal branches of a phylogeny. This approach extends the recently proposed approximate likelihood-ratio test and relies on a nonparametric, Shimodaira–Hasegawa–like procedure. A detailed analysis of real alignments sheds light on the links between this new approach and the more classical nonparametric bootstrap method. Overall, our tests show that the last version (3.0) of PhyML is fast, accurate, stable, and ready to use. A Web server and binary files are available from http://www.atgc-montpellier.fr/phyml/.","['Algorithm', 'Pruning', 'Computer science', 'Tree (set theory)', 'Nonparametric statistics', 'Simple (philosophy)', 'Software', 'Data mining', 'Mathematics', 'Statistics', 'Biology', 'Philosophy', 'Epistemology', 'Agronomy', 'Mathematical analysis', 'Programming language']","phyml, phylogeny software, ph, ##l, nearest neighbor interchanges, starting tree topology, phyml, phyml, subtree pruning, topological moves, parsimony criterion, likelihood function, amino, real, nonparametric bootstrap, ph, ##l, web, binary files"
Paper_00544,"Probability, Random Variables, and Stochastic Processes.","['Julia Abrahams', 'A. Papoulis']",1984,Journal of the American Statistical Association,Journal,,957-957,79,388,10.2307/2288754,Part 1 Probability and Random Variables 1 The Meaning of Probability 2 The Axioms of Probability 3 Repeated Trials 4 The Concept of a Random Variable 5 Functions of One Random Variable 6 Two Random Variables 7 Sequences of Random Variables 8 Statistics Part 2 Stochastic Processes 9 General Concepts 10 Random Walk and Other Applications 11 Spectral Representation 12 Spectral Estimation 13 Mean Square Estimation 14 Entropy 15 Markov Chains 16 Markov Processes and Queueing Theory,"['Mathematics', 'Random variable', 'Econometrics', 'Statistics']","probability, random variables, meaning, probability, ax, probability, repeated trials, random variable, random variables, stochastic processes, random walk, spectral representation, spectral estimation, mean square estimation, entropy, markov chains, markov processes, queueing theory, [PAD] [PAD], [PAD], [PAD], [PAD], [PAD] [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD] [PAD], [PAD], [PAD], [PAD] [PAD], [PAD] [PAD], [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD], [PAD], [PAD], [PAD] [PAD] [PAD], [PAD], [PAD] [PAD], [PAD] [PAD], [PAD] [PAD]"
Paper_00546,Scalable molecular dynamics with NAMD,"['J. C. Phillips', 'Rosemary Braun', 'Wei Wang', 'James C. Gumbart', 'Emad Tajkhorshid', 'Elizabeth Villa', 'Christophe Chipot', 'Robert D. Skeel', 'Laxmikant V. Kalé', 'Klaus Schulten']",2005,Journal of Computational Chemistry,Journal,,1781-1802,26,16,10.1002/jcc.20289,"Abstract NAMD is a parallel molecular dynamics code designed for high‐performance simulation of large biomolecular systems. NAMD scales to hundreds of processors on high‐end parallel platforms, as well as tens of processors on low‐cost commodity clusters, and also runs on individual desktop and laptop computers. NAMD works with AMBER and CHARMM potential functions, parameters, and file formats. This article, directed to novices as well as experts, first introduces concepts and methods used in the NAMD program, describing the classical molecular dynamics force field, equations of motion, and integration methods along with the efficient electrostatics evaluation algorithms employed and temperature and pressure controls used. Features for steering the simulation across barriers and for calculating both alchemical and conformational free energy differences are presented. The motivations for and a roadmap to the internal design of NAMD, implemented in C++ and based on Charm++ parallel objects, are outlined. The factors affecting the serial and parallel performance of a simulation are discussed. Finally, typical NAMD use is illustrated with representative applications to a small, a medium, and a large biomolecular system, highlighting particular features of NAMD, for example, the Tcl scripting language. The article also provides a list of the key features of NAMD and discusses the benefits of combining NAMD with the molecular graphics/sequence analysis software VMD and the grid computing/collaboratory software BioCoRE. NAMD is distributed free of charge with source code at www.ks.uiuc.edu . © 2005 Wiley Periodicals, Inc. J Comput Chem 26: 1781–1802, 2005","['Computer science', 'Scalability', 'Software', 'Molecular dynamics', 'Field (mathematics)', 'Scripting language', 'Computational science', 'Graphics', 'Code (set theory)', 'Parallel computing', 'Programming language', 'Computer graphics (images)', 'Operating system', 'Chemistry', 'Computational chemistry', 'Mathematics', 'Set (abstract data type)', 'Pure mathematics']","abstract, ##d, parallel molecular dynamics, high ‐ performance simulation, large biomolecular systems, charm, classical molecular dynamics force field, equations of motion, integration methods, electrostatics evaluation, parallel performance, tcl scripting, wiley"
Paper_00549,The Art of Case Study Research,"['Karen E. Johnson', 'Robert E. Stake']",1996,Modern Language Journal,Journal,,556-556,80,4,10.2307/329758,Introduction An Intensive Study of Case Study Research Methods The Unique Case Research Questions The Nature of Qualitative Research Data Gathering Analysis and Interpretation Case Researcher Roles Triangulation Writing the Report Reflections Harper School,"['Interpretation (philosophy)', 'Triangulation', 'Qualitative research', 'Case study research', 'Sociology', 'Psychology', 'Mathematics education', 'Epistemology', 'Linguistics', 'Management science', 'Social science', 'Philosophy', 'Geography', 'Engineering', 'Cartography']","case study, qualitative research data gathering analysis, interpretation, triangulation writing, report reflections harper, [PAD], [PAD] [PAD], [PAD] [PAD] [PAD], [PAD], [PAD], [PAD] [PAD] [PAD], [PAD] [PAD], [PAD], [PAD], [PAD] [PAD] [PAD], [PAD], [PAD], [PAD], [PAD], [PAD] [PAD] [PAD], [PAD] [PAD], [PAD] [PAD], [PAD], [PAD] [PAD], [PAD], [PAD], [PAD] [PAD]"
Paper_00550,A unified formulation of the constant temperature molecular dynamics methods,['Shūichi Nosé'],1984,The Journal of Chemical Physics,Journal,,511-519,81,1,10.1063/1.447334,"Three recently proposed constant temperature molecular dynamics methods by: (i) Nosé (Mol. Phys., to be published); (ii) Hoover et al. [Phys. Rev. Lett. 48, 1818 (1982)], and Evans and Morriss [Chem. Phys. 77, 63 (1983)]; and (iii) Haile and Gupta [J. Chem. Phys. 79, 3067 (1983)] are examined analytically via calculating the equilibrium distribution functions and comparing them with that of the canonical ensemble. Except for effects due to momentum and angular momentum conservation, method (1) yields the rigorous canonical distribution in both momentum and coordinate space. Method (2) can be made rigorous in coordinate space, and can be derived from method (1) by imposing a specific constraint. Method (3) is not rigorous and gives a deviation of order N−1/2 from the canonical distribution (N the number of particles). The results for the constant temperature–constant pressure ensemble are similar to the canonical ensemble case.","['Canonical ensemble', 'Constant (computer programming)', 'Molecular dynamics', 'Momentum (technical analysis)', 'Distribution (mathematics)', 'Grand canonical ensemble', 'Angular momentum', 'Space (punctuation)', 'Statistical physics', 'Physics', 'Microcanonical ensemble', 'Mathematics', 'Mathematical physics', 'Classical mechanics', 'Mathematical analysis', 'Quantum mechanics', 'Monte Carlo method', 'Linguistics', 'Statistics', 'Philosophy', 'Finance', 'Computer science', 'Economics', 'Programming language']","constant temperature molecular dynamics methods, equilibrium distribution functions, canonical ensemble, angular momentum conservation, canonical distribution, coordinate space, constant temperature, constant pressure ensemble, canonical ensemble"
Paper_00551,Array programming with NumPy,"['C. R. Harris', 'K. Jarrod Millman', 'Stéfan van der Walt', 'Ralf Gommers', 'Pauli Virtanen', 'David Cournapeau', 'Eric Wieser', 'Julian Taylor', 'Sebastian Berg', 'Nathaniel J. Smith', 'Robert Kern', 'Matti Picus', 'Stephan Hoyer', 'M. H. van Kerkwijk', 'Matthew Brett', 'Allan Haldane', 'Jaime Fernández del Río', 'Mark Wiebe', 'Pearu Peterson', 'P Gerard-Marchant', 'Kevin Sheppard', 'Tyler Reddy', 'Warren Weckesser', 'Hameer Abbasi', 'Christoph Gohlke', 'Travis E. Oliphant']",2020,Nature,Journal,,357-362,585,7825,10.1038/s41586-020-2649-2,"Abstract Array programming provides a powerful, compact and expressive syntax for accessing, manipulating and operating on data in vectors, matrices and higher-dimensional arrays. NumPy is the primary array programming library for the Python language. It has an essential role in research analysis pipelines in fields as diverse as physics, chemistry, astronomy, geoscience, biology, psychology, materials science, engineering, finance and economics. For example, in astronomy, NumPy was an important part of the software stack used in the discovery of gravitational waves 1 and in the first imaging of a black hole 2 . Here we review how a few fundamental array concepts lead to a simple and powerful programming paradigm for organizing, exploring and analysing scientific data. NumPy is the foundation upon which the scientific Python ecosystem is constructed. It is so pervasive that several projects, targeting audiences with specialized needs, have developed their own NumPy-like interfaces and array objects. Owing to its central position in the ecosystem, NumPy increasingly acts as an interoperability layer between such array computation libraries and, together with its application programming interface (API), provides a flexible framework to support the next decade of scientific and industrial analysis.",['Computer science'],"abstract array programming, numpy, array programming library, python language, research analysis, astronomy, numpy, gravitational waves, black hole, numpy, scientific python ecosystem, numpy, application programming interface"
Paper_00553,An analysis of variance test for normality (complete samples),"['Samuel S. Shapiro', 'M. B. Wilk']",1965,Biometrika,Journal,,591-611,52,3-4,10.1093/biomet/52.3-4.591,"Journal Article An analysis of variance test for normality (complete samples) Get access S. S. SHAPIRO, S. S. SHAPIRO General Electric Co. and Bell Telephone Laboratories, Inc. Search for other works by this author on: Oxford Academic Google Scholar M. B. WILK M. B. WILK General Electric Co. and Bell Telephone Laboratories, Inc. Search for other works by this author on: Oxford Academic Google Scholar Biometrika, Volume 52, Issue 3-4, December 1965, Pages 591–611, https://doi.org/10.1093/biomet/52.3-4.591 Published: 01 December 1965","['Normality', 'Mathematics', 'Test (biology)', 'Statistics', 'Normality test', 'Variance (accounting)', 'Statistical hypothesis testing', 'Biology', 'Paleontology', 'Accounting', 'Business']","analysis of variance test, normality, complete samples, bell, bell, biomet, [PAD], [PAD], [PAD] [PAD], [PAD] [PAD]"
Paper_00554,Principles of Polymer Chemistry.,['Maurice L. Huggins'],1954,Journal of the American Chemical Society,Journal,,2854-2854,76,10,10.1021/ja01639a090,"ADVERTISEMENT RETURN TO ISSUEPREVArticleNEXTPrinciples of Polymer Chemistry.Maurice L. HugginsCite this: J. Am. Chem. Soc. 1954, 76, 10, 2854Publication Date (Print):May 1, 1954Publication History Published online1 May 2002Published inissue 1 May 1954https://pubs.acs.org/doi/10.1021/ja01639a090https://doi.org/10.1021/ja01639a090research-articleACS PublicationsRequest reuse permissionsArticle Views917Altmetric-Citations20LEARN ABOUT THESE METRICSArticle Views are the COUNTER-compliant sum of full text article downloads since November 2008 (both PDF and HTML) across all institutions and individuals. These metrics are regularly updated to reflect usage leading up to the last few days.Citations are the number of other articles citing this article, calculated by Crossref and updated daily. Find more information about Crossref citation counts.The Altmetric Attention Score is a quantitative measure of the attention that a research article has received online. Clicking on the donut icon will load a page at altmetric.com with additional details about the score and the social media presence for the given article. Find more information on the Altmetric Attention Score and how the score is calculated. Share Add toView InAdd Full Text with ReferenceAdd Description ExportRISCitationCitation and abstractCitation and referencesMore Options Share onFacebookTwitterWechatLinked InRedditEmail Other access optionsGet e-Alertsclose Get e-Alerts","['Chemistry', 'Polymer science']","##varticlenext, polymer chemistry, permissionsarticle views, ##le, cross, ##f, altmetric attention score, social, altmetric attention score, ##ation, abstract, ##ation"
Paper_00556,The Framing of Decisions and the Psychology of Choice,"['Amos Tversky', 'Daniel Kahneman']",1981,Science,Journal,,453-458,211,4481,10.1126/science.7455683,"The psychological principles that govern the perception of decision problems and the evaluation of probabilities and outcomes produce predictable shifts of preference when the same problem is framed in different ways. Reversals of preference are demonstrated in choices regarding monetary outcomes, both hypothetical and real, and in questions pertaining to the loss of human lives. The effects of frames on preferences are compared to the effects of perspectives on perceptual appearance. The dependence of preferences on the formulation of decision problems is a significant concern for the theory of rational choice.","['Framing effect', 'Framing (construction)', 'Perception', 'Preference', 'Psychology', 'Social psychology', 'Prospect theory', 'Expected utility hypothesis', 'Decision theory', 'Cognitive psychology', 'Economics', 'Microeconomics', 'Mathematical economics', 'Persuasion', 'Structural engineering', 'Neuroscience', 'Engineering']","psychological principles, decision problems, monetary outcomes, perceptual appearance, rational choice, [PAD] [PAD], [PAD]"
Paper_00557,Cluster analysis and display of genome-wide expression patterns,"['Michael B. Eisen', 'Paul T. Spellman', 'Patrick O. Brown', 'David Botstein']",1998,Proceedings of the National Academy of Sciences,Journal,,14863-14868,95,25,10.1073/pnas.95.25.14863,"A system of cluster analysis for genome-wide expression data from DNA microarray hybridization is described that uses standard statistical algorithms to arrange genes according to similarity in pattern of gene expression. The output is displayed graphically, conveying the clustering and the underlying expression data simultaneously in a form intuitive for biologists. We have found in the budding yeast Saccharomyces cerevisiae that clustering gene expression data groups together efficiently genes of known similar function, and we find a similar tendency in human data. Thus patterns seen in genome-wide expression experiments can be interpreted as indications of the status of cellular processes. Also, coexpression of genes of known function with poorly characterized or novel genes may provide a simple means of gaining leads to the functions of many genes for which information is not available currently.","['Genome', 'Gene', 'Biology', 'Computational biology', 'Saccharomyces cerevisiae', 'Cluster analysis', 'Genetics', 'DNA microarray', 'Function (biology)', 'Gene expression', 'Similarity (geometry)', 'Gene cluster', 'Expression (computer science)', 'Microarray databases', 'Human genome', 'Computer science', 'Artificial intelligence', 'Image (mathematics)', 'Programming language']","cluster analysis, dna microarray hybridization, statistical algorithms, budding yeast saccharomyces cerevisiae"
Paper_00558,Toward reliable density functional methods without adjustable parameters: The PBE0 model,"['Carlo Adamo', 'Vincenzo Barone']",1999,The Journal of Chemical Physics,Journal,,6158-6170,110,13,10.1063/1.478522,"We present an analysis of the performances of a parameter free density functional model (PBE0) obtained combining the so called PBE generalized gradient functional with a predefined amount of exact exchange. The results obtained for structural, thermodynamic, kinetic and spectroscopic (magnetic, infrared and electronic) properties are satisfactory and not far from those delivered by the most reliable functionals including heavy parameterization. The way in which the functional is derived and the lack of empirical parameters fitted to specific properties make the PBE0 model a widely applicable method for both quantum chemistry and condensed matter physics.","['Density functional theory', 'Statistical physics', 'Orbital-free density functional theory', 'Hybrid functional', 'Quantum', 'Kinetic energy', 'Physics', 'Biological system', 'Quantum mechanics', 'Biology']","parameter free density functional model, p, ##be generalized gradient functional, heavy parameterization, pbe, quantum chemistry, condensed matter physics, [PAD] [PAD], [PAD] [PAD], [PAD] [PAD], [PAD], [PAD] [PAD] [PAD], [PAD] [PAD], [PAD], [PAD] [PAD] [PAD] [PAD]"
Paper_00559,"Intermolecular interactions from a natural bond orbital, donor-acceptor viewpoint","['Alan E. Reed', 'Larry A. Curtiss', 'Frank Weinhold']",1988,Chemical Reviews,Journal,,899-926,88,6,10.1021/cr00088a005,"ADVERTISEMENT RETURN TO ISSUEPREVArticleNEXTIntermolecular interactions from a natural bond orbital, donor-acceptor viewpointAlan E. Reed, Larry A. Curtiss, and Frank WeinholdCite this: Chem. Rev. 1988, 88, 6, 899–926Publication Date (Print):September 1, 1988Publication History Published online1 May 2002Published inissue 1 September 1988https://pubs.acs.org/doi/10.1021/cr00088a005https://doi.org/10.1021/cr00088a005research-articleACS PublicationsRequest reuse permissionsArticle Views19552Altmetric-Citations15820LEARN ABOUT THESE METRICSArticle Views are the COUNTER-compliant sum of full text article downloads since November 2008 (both PDF and HTML) across all institutions and individuals. These metrics are regularly updated to reflect usage leading up to the last few days.Citations are the number of other articles citing this article, calculated by Crossref and updated daily. Find more information about Crossref citation counts.The Altmetric Attention Score is a quantitative measure of the attention that a research article has received online. Clicking on the donut icon will load a page at altmetric.com with additional details about the score and the social media presence for the given article. Find more information on the Altmetric Attention Score and how the score is calculated. Share Add toView InAdd Full Text with ReferenceAdd Description ExportRISCitationCitation and abstractCitation and referencesMore Options Share onFacebookTwitterWechatLinked InRedditEmail Other access optionsGet e-Alertsclose Get e-Alerts","['Icon', 'Citation', 'Altmetrics', 'Computer science', 'Social media', 'Acceptor', 'World Wide Web', 'Information retrieval', 'Physics', 'Condensed matter physics', 'Programming language']","##varticlene, ##lecular interactions, natural bond orbital, ##sar, ##le views, ##le, ##f, ##f, altmetric attention score, social, altmetric attention score, ##riscitation, abstract, ##ation, referencesmore options"
Paper_00560,Hybrid functionals based on a screened Coulomb potential,"['Jochen Heyd', 'Gustavo E. Scuseria', 'Matthias Ernzerhof']",2003,The Journal of Chemical Physics,Journal,,8207-8215,118,18,10.1063/1.1564060,"Views Icon Views Article contents Figures & tables Video Audio Supplementary Data Peer Review Share Icon Share Twitter Facebook Reddit LinkedIn Tools Icon Tools Reprints and Permissions Cite Icon Cite Search Site Citation Jochen Heyd, Gustavo E. Scuseria, Matthias Ernzerhof; Hybrid functionals based on a screened Coulomb potential. J. Chem. Phys. 8 May 2003; 118 (18): 8207–8215. https://doi.org/10.1063/1.1564060 Download citation file: Ris (Zotero) Reference Manager EasyBib Bookends Mendeley Papers EndNote RefWorks BibTex toolbar search Search Dropdown Menu toolbar search search input Search input auto suggest filter your search All ContentAIP Publishing PortfolioThe Journal of Chemical Physics Search Advanced Search |Citation Search","['Coulomb', 'Hybrid functional', 'Periodic boundary conditions', 'Density functional theory', 'Hybrid system', 'Hartree', 'Bottleneck', 'Molecule', 'Hartree–Fock method', 'Range (aeronautics)', 'Work (physics)', 'Statistical physics', 'Physics', 'Materials science', 'Boundary value problem', 'Quantum mechanics', 'Computer science', 'Electron', 'Composite material', 'Machine learning', 'Embedded system']","##dit linked, hybrid functionals, screened coulomb potential, ##s, zotero, mendeley, ##bt, chemical physics, citation"
Paper_00562,Auto-Encoding Variational Bayes,"['Diederik P. Kingma', 'Max Welling']",2014,['Cambridge Explorations in Arts and Sciences'],Unknown,,,2,1,10.61603/ceas.v2i1.33,"Abstract: How can we perform efficient inference and learning in directed probabilistic models, in the presence of continuous latent variables with intractable posterior distributions, and large datasets? We introduce a stochastic variational inference and learning algorithm that scales to large datasets and, under some mild differentiability conditions, even works in the intractable case. Our contributions is two-fold. First, we show that a reparameterization of the variational lower bound yields a lower bound estimator that can be straightforwardly optimized using standard stochastic gradient methods. Second, we show that for i.i.d. datasets with continuous latent variables per datapoint, posterior inference can be made especially efficient by fitting an approximate inference model (also called a recognition model) to the intractable posterior using the proposed lower bound estimator. Theoretical advantages are reflected in experimental results.","['Inference', 'Estimator', 'Upper and lower bounds', 'Latent variable', 'Differentiable function', ""Bayes' theorem"", 'Computer science', 'Posterior probability', 'Bayesian inference', 'Algorithm', 'Probabilistic logic', 'Approximate inference', 'Artificial intelligence', 'Mathematics', 'Applied mathematics', 'Bayesian probability', 'Statistics', 'Mathematical analysis']","inference, learning, directed probabilistic models, continuous latent variables, intractable posterior distributions, stochastic variational inference, learning algorithm, ##bility, ##ara, lower bound estimator, stochastic gradient methods, continuous latent variables, posterior inference, approximate inference model, recognition model, lower bound estimator"
Paper_00565,A Conceptual Model of Service Quality and Its Implications for Future Research,"['A. Parasuraman', 'Valarie A. Zeithaml', 'Leonard L. Berry']",1985,Journal of Marketing,Journal,,41-41,49,4,10.2307/1251430,"The attainment of quality in products and services has become a pivotal concern of the 1980s. While quality in tangible goods has been described and measured by marketers, quality in services is largely undefined and unresearched. The authors attempt to rectify this situation by reporting the insights obtained in an extensive exploratory investigation of quality in four service businesses and by developing a model of service quality. Propositions and recommendations to stimulate future research about service quality are offered.","['Quality (philosophy)', 'Business', 'Service quality', 'Service (business)', 'Marketing', 'Conceptual model', 'Exploratory research', 'Process management', 'Sociology', 'Computer science', 'Philosophy', 'Epistemology', 'Database', 'Anthropology']","quality, services, quality, tangible goods, quality, services, quality, service businesses, service quality, service quality, [PAD] [PAD] [PAD], [PAD] [PAD]"
Paper_00566,"The magical number seven, plus or minus two: Some limits on our capacity for processing information.",['George Miller'],1956,Psychological Review,Journal,,81-97,63,2,10.1037/h0043158,"First, the span of absolute judgment and the span of immediate memory impose severe limitations on the amount of information that we are able to receive, process, and remember. By organizing the stimulus input simultaneously into several dimensions and successively into a sequence or chunks, we manage to break (or at least stretch) this informational bottleneck. Second, the process of recoding is a very important one in human psychology and deserves much more explicit attention than it has received. In particular, the kind of linguistic recoding that people do seems to me to be the very lifeblood of the thought processes. Recoding procedures are a constant concern to clinicians, social psychologists, linguists, and anthropologists and yet, probably because recoding is less accessible to experimental manipulation than nonsense syllables or T mazes, the traditional experimental psychologist has contributed little or nothing to their analysis. Nevertheless, experimental techniques can be used, methods of recoding can be specified, behavioral indicants can be found. And I anticipate that we will find a very orderly set of relations describing what now seems an uncharted wilderness of individual differences. Third, the concepts and measures provided by the theory of information provide a quantitative way of getting at some of these questions. The theory provides us with a yardstick for calibrating our stimulus materials and for measuring the performance of our subjects. In the interests of communication I have suppressed the technical details of information measurement and have tried to express the ideas in more familiar terms; I hope this paraphrase will not lead you to think they are not useful in research. Informational concepts have already proved valuable in the study of discrimination and of language; they promise a great deal in the study of learning and memory; and it has even been proposed that they can be useful in the study of concept formation. A lot of questions that seemed fruitless twenty or thirty years ago may now be worth another look. In fact, I feel that my story here must stop just as it begins to get really interesting. And finally, what about the magical number seven? What about the seven wonders of the world, the seven seas, the seven deadly sins, the seven daughters of Atlas in the Pleiades, the seven ages of man, the seven levels of hell, the seven primary colors, the seven notes of the musical scale, and the seven days of the week? What about the seven-point rating scale, the seven categories for absolute judgment, the seven objects in the span of attention, and the seven digits in the span of immediate memory? For the present I propose to withhold judgment. Perhaps there is something deep and profound behind all these sevens, something just calling out for us to discover it. But I suspect that it is only a pernicious, Pythagorean coincidence.","['Information processing', 'Psychology', 'Cognitive psychology']","absolute judgment, immediate memory, human psychology, linguistic recoding, clinic, social psychologists, linguist, anthropologist, nonsense syllables, t mazes, experimental psychologist, behavioral indicants, information measurement, discrimination, concept formation, magical number seven, seven, seven seas, seven, seven, pleiades, seven ages, seven levels of, seven, musical scale, absolute judgment"
Paper_00567,A global reference for human genetic variation,"['Adam Auton', 'Gonçalo R. Abecasis', 'David Altshuler', 'Richard Durbin', 'Gonçalo R. Abecasis', 'David Bentley', 'Aravinda Chakravarti', 'Andrew G. Clark', 'Peter Donnelly', 'Evan E. Eichler', 'Paul Flicek', 'Stacey Gabriel', 'Richard A. Gibbs', 'Eric D. Green', 'Matthew E. Hurles', 'Bartha Maria Knoppers', 'Jan O. Korbel', 'Eric S. Lander', 'Charles Lee', 'Hans Lehrach', 'Elaine R. Mardis', 'Gábor Marth', 'Gil McVean', 'Deborah A. Nickerson', 'Jeanette P. Schmidt', 'Stephen T. Sherry', 'Jun Wang', 'Richard K. Wilson', 'Richard A. Gibbs', 'Eric Boerwinkle', 'HarshaVardhan Doddapaneni', 'Yi Han', 'Viktoriya Korchina', 'Christie Kovar', 'Charles Lee', 'Donna M. Muzny', 'Jeffrey G. Reid', 'Yiming Zhu', 'Jun Wang', 'Yuqi Chang', 'Qiang Feng', 'Xiaodong Fang', 'Xiaosen Guo', 'Min Jian', 'Hui Jiang', 'Xin Jin', 'Tianming Lan', 'Guoqing Li', 'Jingxiang Li', 'Yingrui Li', 'Shengmao Liu', 'Xiao Liu', 'Yao Lu', 'Xuedi Ma', 'Meifang Tang', 'Bo Wang', 'Guangbiao Wang', 'Honglong Wu', 'Renhua Wu', 'Xun Xu', 'Ye Yin', 'Dandan Zhang', 'Wenwei Zhang', 'Jiao Zhao', 'Meiru Zhao', 'Xiaole Zheng', 'Eric S. Lander', 'David Altshuler', 'Stacey Gabriel', 'Namrata Gupta', 'Neda Gharani', 'Lorraine H. Toji', 'Norman P. Gerry', 'Alissa Resch', 'Paul Flicek', 'Juliet N. Barker', 'Laura Clarke', 'Laurent Gil', 'Sarah Hunt', 'Gavin Kelman', 'Eugene Kulesha', 'Rasko Leinonen', 'William McLaren', 'Rajesh Radhakrishnan', 'Asier Roa', 'Dmitriy Smirnov', 'Richard E. Smith', 'Ian Streeter', 'Anja Thormann', 'Iliana Toneva', 'Brendan Vaughan', 'Xiangqun Zheng-Bradley', 'David Bentley', 'Russell Grocock', 'Sean Humphray', 'Terena James', 'Zoya Kingsbury', 'Hans Lehrach', 'Ralf Sudbrak', 'Marcus W. Albrecht']",2015,Nature,Journal,,68-74,526,7571,10.1038/nature15393,"The 1000 Genomes Project set out to provide a comprehensive description of common human genetic variation by applying whole-genome sequencing to a diverse set of individuals from multiple populations. Here we report completion of the project, having reconstructed the genomes of 2,504 individuals from 26 populations using a combination of low-coverage whole-genome sequencing, deep exome sequencing, and dense microarray genotyping. We characterized a broad spectrum of genetic variation, in total over 88 million variants (84.7 million single nucleotide polymorphisms (SNPs), 3.6 million short insertions/deletions (indels), and 60,000 structural variants), all phased onto high-quality haplotypes. This resource includes >99% of SNP variants with a frequency of >1% for a variety of ancestries. We describe the distribution of genetic variation across the global sample, and discuss the implications for common disease studies.","['Variation (astronomy)', 'Human genetic variation', 'Genetic variation', 'Evolutionary biology', 'Biology', 'Computational biology', 'Human genome', 'Genetics', 'Genome', 'Gene', 'Physics', 'Astrophysics']","1000 genomes, human genetic variation, deep exome sequencing, dense microarray genotyping, structural variants, snp, ##ces, common"
Paper_00571,Learning Internal Representations by Error Propagation,"['David E. Rumelhart', 'Geoffrey E. Hinton', 'Ronald J. Williams']",1985,Unknown,Unknown,,,,,10.21236/ada164453,"This chapter contains sections titled: The Problem, The Generalized Delta Rule, Simulation Results, Some Further Generalizations, Conclusion","['Computer science', 'Artificial intelligence']","generalized delta rule, simulation results, [PAD], [PAD] [PAD], [PAD]"
Paper_00572,"Capitalism, Socialism and Democracy","['Francis Fukuyama', 'Joseph A. Schumpeter']",1997,Foreign Affairs,Journal,,214-214,76,5,10.2307/20048211,"Introduction. Part I: The Marxian Doctrine. Prologue. I. Marx the Prophet. II. Marx the Sociologist. III. Marx the Economist. IV Marx the Teacher. Part II: Can Capitalism Survive? Prologue. V. The Rate of Increase of Total Output. VI. Plausible Capitalism. VII. The Process of Creative Destruction. VIII. Monopolistics Practices. IX. Closed Season. X. The Vanishing of Investment Opportunity. XI. The Civilization of Capitalism. XII. Crumbling Walls. XIII. Growing Hostility. XIV. Decomposition. Part III: Can Socialism Work? XV. Clearing Decks. XVI. The Socialist Blueprint. XVII. Comparison of Blueprints. XVIII. The Human Element. XIX. Transition. Part IV: Socialism and Democracy. XX. The Setting of the Problem. XXI. The Classical Doctrine of Democracy. XXII. Another Theory of Democracy. XXIII. The Inference. Part V: A Historical Sketch of Socialist Parties. Prologue. XXIV. The Nonage. XXV. The Situation that Marx Faced. XXVI. From 1875 to 1914. XXVII. From the First to the Second World War. XXVIII. The Consequences of the Second World War. Preface to the First Edition, 1942. Preface to the Second Edition, 1946. Preface to the Third Edition, 1949. The March Into Socialism. Index.","['Capitalism', 'Socialism', 'Democracy', 'Political science', 'State socialism', 'Economic system', 'Political economy', 'Neoclassical economics', 'Economics', 'Communism', 'Law', 'Politics']","marxian doctrine, marx, marx, plausible capitalism, creative destruction, monopolistics practices, closed season, investment opportunity, civilization, capitalism, crumbling walls, clearing decks, socialist blueprint, human element, socialism, democracy, classical doctrine, socialist parties, non, socialism"
Paper_00575,"Cancer statistics in China, 2015","['Wanqing Chen', 'Rongshou Zheng', 'Peter D. Baade', 'Siwei Zhang', 'Hongmei Zeng', 'Freddie Bray', 'Ahmedin Jemal', 'Xue Qin Yu', 'Jie He']",2016,CA A Cancer Journal for Clinicians,Journal,,115-132,66,2,10.3322/caac.21338,"With increasing incidence and mortality, cancer is the leading cause of death in China and is a major public health problem. Because of China's massive population (1.37 billion), previous national incidence and mortality estimates have been limited to small samples of the population using data from the 1990s or based on a specific year. With high‐quality data from an additional number of population‐based registries now available through the National Central Cancer Registry of China, the authors analyzed data from 72 local, population‐based cancer registries (2009‐2011), representing 6.5% of the population, to estimate the number of new cases and cancer deaths for 2015. Data from 22 registries were used for trend analyses (2000‐2011). The results indicated that an estimated 4292,000 new cancer cases and 2814,000 cancer deaths would occur in China in 2015, with lung cancer being the most common incident cancer and the leading cause of cancer death. Stomach, esophageal, and liver cancers were also commonly diagnosed and were identified as leading causes of cancer death. Residents of rural areas had significantly higher age‐standardized (Segi population) incidence and mortality rates for all cancers combined than urban residents (213.6 per 100,000 vs 191.5 per 100,000 for incidence; 149.0 per 100,000 vs 109.5 per 100,000 for mortality, respectively). For all cancers combined, the incidence rates were stable during 2000 through 2011 for males (+0.2% per year; P = .1), whereas they increased significantly (+2.2% per year; P &lt; .05) among females. In contrast, the mortality rates since 2006 have decreased significantly for both males (−1.4% per year; P &lt; .05) and females (−1.1% per year; P &lt; .05). Many of the estimated cancer cases and deaths can be prevented through reducing the prevalence of risk factors, while increasing the effectiveness of clinical care delivery, particularly for those living in rural areas and in disadvantaged populations. CA Cancer J Clin 2016;66:115–132. © 2016 American Cancer Society.","['Medicine', 'Cancer', 'Population', 'Incidence (geometry)', 'Demography', 'Stomach cancer', 'Cancer registry', 'Lung cancer', 'Mortality rate', 'Esophageal cancer', 'Standardized mortality ratio', 'Environmental health', 'Internal medicine', 'Physics', 'Sociology', 'Optics']","public, lung cancer, stomach, ##ha, liver cancers, clinical care delivery, american cancer society"
Paper_00576,On Persistence in Mutual Fund Performance,['Mark M. Carhart'],1997,The Journal of Finance,Journal,,57-82,52,1,10.1111/j.1540-6261.1997.tb03808.x,"ABSTRACT Using a sample free of survivor bias, I demonstrate that common factors in stock returns and investment expenses almost completely explain persistence in equity mutual funds' mean and risk‐adjusted returns. Hendricks, Patel and Zeckhauser's (1993) “hot hands” result is mostly driven by the one‐year momentum effect of Jegadeesh and Titman (1993) , but individual funds do not earn higher returns from following the momentum strategy in stocks. The only significant persistence not explained is concentrated in strong underperformance by the worst‐return mutual funds. The results do not support the existence of skilled or informed mutual fund portfolio managers.","['Mutual fund', 'Closed-end fund', 'Open-end fund', 'Portfolio', 'Equity (law)', 'Persistence (discontinuity)', 'Fund of funds', 'Economics', 'Stock (firearms)', 'Financial economics', 'Momentum (technical analysis)', 'Business', 'Econometrics', 'Monetary economics', 'Finance', 'Institutional investor', 'Corporate governance', 'Political science', 'Geography', 'Geotechnical engineering', 'Archaeology', 'Market liquidity', 'Law', 'Engineering']","survivor bias, stock returns, investment expenses, equity mutual funds, momentum effect, momentum strategy, worst, mutual fund portfolio managers, [PAD]"
Paper_00579,Governing the Commons,['Элинор Остром'],1990,Unknown,Unknown,,,,,10.1017/cbo9780511807763,"The governance of natural resources used by many individuals in common is an issue of increasing concern to policy analysts. Both state control and privatisation of resources have been advocated, but neither the state nor the market have been uniformly successful in solving common pool resource problems. Offering a critique of the foundations of policy analysis as applied to natural resources, Elinor Ostrom here provides a unique body of empirical data to explore conditions under which common pool resource problems have been satisfactorily or unsatisfactorily solved. Dr Ostrom first describes three models most frequently used as the foundation for recommending state or market solutions. She then outlines theoretical and empirical alternatives to these models in order to illustrate the diversity of possible solutions. In the following chapters she uses institutional analysis to examine different ways - both successful and unsuccessful - of governing the commons. In contrast to the proposition of the tragedy of the commons argument, common pool problems sometimes are solved by voluntary organisations rather than by a coercive state. Among the cases considered are communal tenure in meadows and forests, irrigation communities and other water rights, and fisheries.","['Commons', 'Tragedy of the commons', 'Common-pool resource', 'Natural resource', 'Corporate governance', 'Argument (complex analysis)', 'Institutional analysis', 'Environmental governance', 'State (computer science)', 'Resource (disambiguation)', 'Law and economics', 'Order (exchange)', 'Diversity (politics)', 'Political science', 'Economics', 'Public economics', 'Sociology', 'Microeconomics', 'Law', 'Social science', 'Computer science', 'Management', 'Computer network', 'Biochemistry', 'Chemistry', 'Finance', 'Algorithm']","natural resources, policy analysts, state control, privatisation, common, policy analysis, natural resources, common, institutional analysis, tragedy, common, voluntary organisations, coe, ##ive, communal tenure, meadows, forests, irrigation communities, water rights, fisheries"
Paper_00580,<scp>genalex</scp> 6: genetic analysis in Excel. Population genetic software for teaching and research,"['Rod Peakall', 'Peter E. Smouse']",2005,Molecular Ecology Notes,Journal,,288-295,6,1,10.1111/j.1471-8286.2005.01155.x,"Abstract genalex is a user‐friendly cross‐platform package that runs within Microsoft Excel, enabling population genetic analyses of codominant, haploid and binary data. Allele frequency‐based analyses include heterozygosity, F statistics, Nei's genetic distance, population assignment, probabilities of identity and pairwise relatedness. Distance‐based calculations include amova , principal coordinates analysis (PCA), Mantel tests, multivariate and 2D spatial autocorrelation and twogener . More than 20 different graphs summarize data and aid exploration. Sequence and genotype data can be imported from automated sequencers, and exported to other software. Initially designed as tool for teaching, genalex 6 now offers features for researchers as well. Documentation and the program are available at http://www.anu.edu.au/BoZo/GenAlEx/","['Pairwise comparison', 'Software', 'Population', 'Computer science', 'Genetic distance', 'Allele frequency', 'Statistics', 'Biology', 'Genotype', 'Data mining', 'Genetics', 'Artificial intelligence', 'Programming language', 'Mathematics', 'Genetic variation', 'Demography', 'Sociology', 'Gene']","abstract gen, ##x, microsoft, population genetic analyses, ##ominant, haploid, binary data, allele frequency, heterozygosity, f statistics, genetic distance, population assignment, probabilities of identity, pairwise relatedness, distance ‐, amova, principal coordinates analysis, mantel tests, 2d spatial autocorrelation, twogener, automated sequencers, genalex, ##ale"
Paper_00581,Model-based Analysis of ChIP-Seq (MACS),"['Yong Zhang', 'Tao Liu', 'Clifford A. Meyer', 'Jérôme Eeckhoute', 'David S. Johnson', 'B Bernstein', 'Chad Nusbaum', 'R Myers', 'Myles Brown', 'Wei Li', 'X. Shirley Liu']",2008,Genome biology,Journal,,,9,9,10.1186/gb-2008-9-9-r137,"We present Model-based Analysis of ChIP-Seq data, MACS, which analyzes data generated by short read sequencers such as Solexa's Genome Analyzer. MACS empirically models the shift size of ChIP-Seq tags, and uses it to improve the spatial resolution of predicted binding sites. MACS also uses a dynamic Poisson distribution to effectively capture local biases in the genome, allowing for more robust predictions. MACS compares favorably to existing ChIP-Seq peak-finding algorithms, and is freely available.","['Biology', 'Computational biology', 'Human genetics', 'Genome Biology', 'Computational genomics', 'Evolutionary biology', 'Genomics', 'Genetics', 'Genome', 'Gene']","macs, short read sequencers, solexa, genome analyzer, macs, shift size, spatial resolution, macs, dynamic poisson distribution, local biases, macs, [PAD], [PAD]"
Paper_00582,Binary Alloy Phase Diagrams,"['T. B. Massalski', 'J. L. Murray', 'L. H. Bennett', 'H. H. Baker']",2016,ASM International eBooks,Unknown,,89-89,,,10.31399/asm.hb.v03.a0006247,"Abstract This article provides a discussion on binary alloy phase diagrams published in this handbook. All diagrams presented are for stable equilibrium conditions, except where metastable conditions are indicated.","['Phase diagram', 'Alloy', 'Materials science', 'Phase (matter)', 'Binary alloy', 'Metallurgy', 'Physics', 'Quantum mechanics']","binary alloy phase diagrams, stable equilibrium conditions, metastable conditions, [PAD], [PAD] [PAD] [PAD] [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD] [PAD] [PAD], [PAD] [PAD] [PAD], [PAD], [PAD], [PAD] [PAD], [PAD], [PAD], [PAD], [PAD] [PAD], [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD], [PAD] [PAD], [PAD] [PAD] [PAD], [PAD] [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD] [PAD], [PAD], [PAD] [PAD], [PAD], [PAD], [PAD], [PAD] [PAD], [PAD] [PAD], [PAD], [PAD] [PAD], [PAD], [PAD] [PAD]"
Paper_00583,SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation,"['Vijay Badrinarayanan', 'A. C. Kendall', 'Roberto Cipolla']",2017,IEEE Transactions on Pattern Analysis and Machine Intelligence,Journal,,2481-2495,39,12,10.1109/tpami.2016.2644615,"We present a novel and practical deep fully convolutional neural network architecture for semantic pixel-wise segmentation termed SegNet. This core trainable segmentation engine consists of an encoder network, a corresponding decoder network followed by a pixel-wise classification layer. The architecture of the encoder network is topologically identical to the 13 convolutional layers in the VGG16 network [1] . The role of the decoder network is to map the low resolution encoder feature maps to full input resolution feature maps for pixel-wise classification. The novelty of SegNet lies is in the manner in which the decoder upsamples its lower resolution input feature map(s). Specifically, the decoder uses pooling indices computed in the max-pooling step of the corresponding encoder to perform non-linear upsampling. This eliminates the need for learning to upsample. The upsampled maps are sparse and are then convolved with trainable filters to produce dense feature maps. We compare our proposed architecture with the widely adopted FCN [2] and also with the well known DeepLab-LargeFOV [3] , DeconvNet [4] architectures. This comparison reveals the memory versus accuracy trade-off involved in achieving good segmentation performance. SegNet was primarily motivated by scene understanding applications. Hence, it is designed to be efficient both in terms of memory and computational time during inference. It is also significantly smaller in the number of trainable parameters than other competing architectures and can be trained end-to-end using stochastic gradient descent. We also performed a controlled benchmark of SegNet and other architectures on both road scenes and SUN RGB-D indoor scene segmentation tasks. These quantitative assessments show that SegNet provides good performance with competitive inference time and most efficient inference memory-wise as compared to other architectures. We also provide a Caffe implementation of SegNet and a web demo at http://mi.eng.cam.ac.uk/projects/segnet/.","['Computer science', 'Artificial intelligence', 'Upsampling', 'Feature (linguistics)', 'Encoder', 'Pattern recognition (psychology)', 'Convolutional neural network', 'Segmentation', 'Pixel', 'Pooling', 'Deep learning', 'Benchmark (surveying)', 'Network architecture', 'Image segmentation', 'Computer vision', 'Image (mathematics)', 'Philosophy', 'Linguistics', 'Computer security', 'Geodesy', 'Geography', 'Operating system']","segnet, ##able segmentation engine, encoder network, decoder network, con, ##tion, ##der, ##gnet, pooling indices, ##able, dense feature maps, ##n, largefo, ##n, ##t, ##astic gradient descent, segnet, road, segnet, competitive inference, caffe, segnet"
Paper_00584,DETERMINATION OF SERUM PROTEINS BY MEANS OF THE BIURET REACTION,"['Allan G. Gornall', 'Charles J. Bardawill', 'Maxima M. David']",1949,Journal of Biological Chemistry,Journal,,751-766,177,2,10.1016/s0021-9258(18)57021-6,"In the course of an investigation of the biochemical changes following experimental liver injury we felt the need of a simple, rapid, and accurate method for determining the protein fractions in small amounts of serum. Among the simpler procedures known, the biuret reaction seemed to offer the most encouraging possibilities. Variations and improvements in the application of the biuret reaction to clinical chemistry can be traced in the works of Autenrieth (l), Hiller (2), Fine (3), Kingsley (4), and Robinson and Hogden (5). Kingsley (6) simplified the technique by adding serum directly to a “one piece” reagent. Efforts have been made to increase the stability of such biuret reagents with ethylene glycol (7), tartrate (8), and citrate (9)) We began our investigation with Kingsley’s (6) method and report briefly on the two main difficulties encountered in its use. The first is that the total protein (TP) reagent and, to a lesser extent, the albumin (ALB) reagent are not sufficiently stable. The length of time they remain so depends upon the technique of their preparation. One consequence of this variable stability is a difficulty in duplicating calibration curves with different lots of reagent. Errors may arise when results with a new reagent are read from an old calibration curve. Serious errors occur if a reagent is used after the separation of any black deposit gives evidence of deterioration. A second difficulty has been that total protein estimations made with the TP reagent and read, as prescribed, from calibration curves prepared with the ALB reagent have tended to be too low. Recorded in Table I are the results of a number of analyses in which Kingsley’s biuret procedure has been compared with the Kjeldahl method2 on both normal and ab-","['Biuret test', 'Chemistry', 'Blood proteins', 'Biochemistry', 'Urea']","liver injury, protein fractions, biuret reaction, biuret reaction, clinical chemistry, ##ure, et, tartrate, citrate, total, albumin, ##ration, total, ##ration, biuret"
Paper_00585,A profile refinement method for nuclear and magnetic structures,['H. M. Rietveld'],1969,Journal of Applied Crystallography,Journal,,65-71,2,2,10.1107/s0021889869006558,"A structure refinement method is described which does not use integrated neutron powder intensities, single or overlapping, but employs directly the profile intensities obtained from step-scanning measurements of the powder diagram. Nuclear as well as magnetic structures can be refined, the latter only when their magnetic unit cell is equal to, or a multiple of, the nuclear cell. The least-squares refinement procedure allows, with a simple code, the introduction of linear or quadratic constraints between the parameters.","['Simple (philosophy)', 'Code (set theory)', 'Neutron', 'Quadratic equation', 'Computational physics', 'Diagram', 'Materials science', 'Computer science', 'Algorithm', 'Physics', 'Mathematics', 'Nuclear physics', 'Geometry', 'Philosophy', 'Set (abstract data type)', 'Epistemology', 'Database', 'Programming language']","structure refinement method, integrated neutron powder intensities, profile intensities, powder diagram, quadratic constraints, [PAD], [PAD] [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD], [PAD], [PAD], [PAD] [PAD] [PAD] [PAD], [PAD], [PAD]"
Paper_00588,Internal combustion engine fundamentals,[],1988,Choice Reviews Online,Journal,,26-0943,26,02,10.5860/choice.26-0943,1 Engine Types and Their Operations 2 Engine Design and Operating Parameters 3 Thermochemistry of Fuel-Air Mixtures 4 Properties of Working Fluids 5 Ideal Models of Engine Cycles 6 Gas Exchange Processes 7 SI Engine Fuel Metering and Manifold Phenomena 8 Charge Motion within the Cylinder 9 Combustion in Ignition Engines 10 Combustion in Compression Ignition Engines 11 Pollutant Formation and Control 12 Engine Heat Transfer 13 Engine Friction and Lubrication 14 Modeling Real Engine Flow and Combustion Processes 15 Engine Operating Characteristics Appendixes,"['Internal combustion engine', 'Combustion', 'Environmental science', 'Automotive engineering', 'Engineering', 'Chemistry', 'Organic chemistry']","the, ##oche, working fluids, gas exchange processes, manifold phenomena, charge motion, pollutant formation, engine heat transfer, engine friction, lubrication, engine operating characteristics"
Paper_00589,Efficient Estimation of Word Representations in Vector Space,"['Tomáš Mikolov', 'Kai Chen', 'Greg S. Corrado', 'Jay B. Dean']",2013,arXiv (Cornell University),Unknown,,,,,10.48550/arxiv.1301.3781,"We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities.","['Word (group theory)', 'Computer science', 'Similarity (geometry)', 'Set (abstract data type)', 'Vector space', 'Artificial intelligence', 'Task (project management)', 'Natural language processing', 'Vector space model', 'Test set', 'Semantic similarity', 'Space (punctuation)', 'Artificial neural network', 'Mathematics', 'Geometry', 'Operating system', 'Management', 'Economics', 'Image (mathematics)', 'Programming language']","continuous vector representations, word similarity task, neural networks, semantic word similarities"
Paper_00591,"Global Strategy for the Diagnosis, Management, and Prevention of Chronic Obstructive Pulmonary Disease","['Jørgen Vestbo', 'Suzanne S. Hurd', 'Àlvar Agustí', 'Paul Jones', 'Claus Vogelmeier', 'Antonio Anzueto', 'Peter J. Barnes', 'Leonardo M. Fabbri', 'Fernando J. Martínez', 'Masaharu Nishimura', 'Robert A. Stockley', 'Don D. Sin', 'Roberto Rodríguez-Roisin']",2012,American Journal of Respiratory and Critical Care Medicine,Journal,,347-365,187,4,10.1164/rccm.201204-0596pp,Section:ChooseTop of pageAbstract <<ContentsIntroduction1. Definition and Overvie...2. Diagnosis and Assessme...3. Therapeutic Options4. Management Of Stable C...5. Management of Exacerba...6. COPD and ComorbiditiesReferencesCITING ARTICLES,"['Medicine', 'Pulmonary disease', 'Intensive care medicine', 'Disease management', 'Disease', 'Chronic disease', 'Internal medicine', ""Parkinson's disease""]","page, overvie, assess, therapeutic options, exace, copd, comorbidities"
Paper_00596,Phase annealing in SHELX-90: direct methods for larger structures,['George M. Sheldrick'],1990,Acta Crystallographica Section A Foundations of Crystallography,Journal,,467-473,46,6,10.1107/s0108767390000277,"A number of extensions to the multisolution approach to the crystallographic phase problem are discussed in which the negative quartet relations play an important role. A phase annealing method, related to the simulated annealing approach in other optimization problems, is proposed and it is shown that it can result in an improvement of up to an order of magnitude in the chances of solving large structures at atomic resolution. The ideas presented here are incorporated in the program system SHELX-90; the philosophical and mathematical background to the direct-methods part (SHELXS) of this system is described.","['Simulated annealing', 'Annealing (glass)', 'Computer science', 'Quantum annealing', 'Algorithm', 'Mathematical optimization', 'Mathematics', 'Physics', 'Quantum mechanics', 'Thermodynamics', 'Quantum computer', 'Quantum']","multisolution approach, crystallographic phase problem, negative quartet relations, phase annealing method, simulated annealing approach, optimization"
Paper_00597,"GROMACS: Fast, flexible, and free","['David van der Spoel', 'Erik Lindahl', 'Berk Hess', 'Gerrit Groenhof', 'Alan E. Mark', 'Herman J. C. Berendsen']",2005,Journal of Computational Chemistry,Journal,,1701-1718,26,16,10.1002/jcc.20291,"Abstract This article describes the software suite GROMACS (Groningen MAchine for Chemical Simulation) that was developed at the University of Groningen, The Netherlands, in the early 1990s. The software, written in ANSI C, originates from a parallel hardware project, and is well suited for parallelization on processor clusters. By careful optimization of neighbor searching and of inner loop performance, GROMACS is a very fast program for molecular dynamics simulation. It does not have a force field of its own, but is compatible with GROMOS, OPLS, AMBER, and ENCAD force fields. In addition, it can handle polarizable shell models and flexible constraints. The program is versatile, as force routines can be added by the user, tabulated functions can be specified, and analyses can be easily customized. Nonequilibrium dynamics and free energy determinations are incorporated. Interfaces with popular quantum‐chemical packages (MOPAC, GAMES‐UK, GAUSSIAN) are provided to perform mixed MM/QM simulations. The package includes about 100 utility and analysis programs. GROMACS is in the public domain and distributed (with source code and documentation) under the GNU General Public License. It is maintained by a group of developers from the Universities of Groningen, Uppsala, and Stockholm, and the Max Planck Institute for Polymer Research in Mainz. Its Web site is http://www.gromacs.org . © 2005 Wiley Periodicals, Inc. J Comput Chem 26: 1701–1718, 2005","['Computer science', 'Software', 'Computational science', 'Force field (fiction)', 'Suite', 'Molecular dynamics', 'Software suite', 'Field (mathematics)', 'Documentation', 'Parallel computing', 'Operating system', 'Chemistry', 'Computational chemistry', 'Artificial intelligence', 'Mathematics', 'Archaeology', 'Pure mathematics', 'History']","gromacs, groningen machine, chemical simulation, parallel hardware, processor clusters, neighbor searching, inner loop performance, gromacs, molecular dynamics simulation, gromos, opls, amber, encad force fields, polarizable shell models, flexible constraints, force routines, ##ulated, nonequilibrium dynamics, free energy determinations, quantum ‐ chemical packages, mopac, games, gaussian, gromacs, polymer research, ##omacs, wiley, [PAD] [PAD], [PAD], [PAD], [PAD], [PAD], [PAD] [PAD], [PAD] [PAD] [PAD] [PAD], [PAD]"
Paper_00600,Repertoires of Autophagy in the Pathogenesis of Ocular Diseases,"['Yujie Li', 'Qin Jiang', 'Guo-Fan Cao', 'Jin Yao', 'Biao Yan']",2015,Cellular Physiology and Biochemistry,Journal,,1663-1676,35,5,10.1159/000373980,"Age-related macular degeneration (AMD) is the most common reason of visual impairment in the elderly in the Western countries. The degeneration of retinal pigment epithelial cells (RPE) causes secondarily adverse effects on neural retina leading to visual loss. The aging characteristics of the RPE involve lysosomal accumulation of lipofuscin and extracellular protein aggregates called ""drusen"". Molecular mechanisms behind protein aggregations are weakly understood. There is intriguing evidence suggesting that protein SQSTM1/p62, together with autophagy, has a role in the pathology of different degenerative diseases. It appears that SQSTM1/p62 is a connecting link between autophagy and proteasome mediated proteolysis, and expressed strongly under the exposure to various oxidative stimuli and proteasomal inhibition. ELAVL1/HuR protein is a post-transcriptional factor, which acts mainly as a positive regulator of gene expression by binding to specific mRNAs whose corresponding proteins are fundamental for key cellular functions. We here show that, under proteasomal inhibitor MG-132, ELAVL1/HuR is up-regulated at both mRNA and protein levels, and that this protein binds and post-transcriptionally regulates SQSTM1/p62 mRNA in ARPE-19 cell line. Furthermore, we observed that proteasomal inhibition caused accumulation of SQSTM1/p62 bound irreversibly to perinuclear protein aggregates. The addition of the AMPK activator AICAR was pro-survival and promoted cleansing by autophagy of the former complex, but not of the ELAVL1/HuR accumulation, indeed suggesting that SQSTM1/p62 is decreased through autophagy-mediated degradation, while ELAVL1/HuR through the proteasomal pathway. Interestingly, when compared to human controls, AMD donor samples show strong SQSTM1/p62 rather than ELAVL1/HuR accumulation in the drusen rich macular area suggesting impaired autophagy in the pathology of AMD.","['Autophagy', 'Cell biology', 'Lipofuscin', 'Biology', 'Proteasome', 'Sequestosome 1', 'Activator (genetics)', 'LAMP1', 'Apoptosis', 'Gene', 'Biochemistry']",##al
Paper_00601,Constructing grounded theory : a practical guide through qualitative analysis,['Kathy Charmaz'],2006,['International Journal of Qualitative Studies on Health and Well-being'],Unknown,,,1,3,10.3402/qhw.v1i3.4932,"An Invitation to Grounded Theory Gathering Rich Data Coding in Grounded Theory Practice Memo-Writing Theoretical Sampling, Saturation and Sorting Reconstructing Theory in Grounded Theory Studies Writing the Draft Reflecting on the Research Process","['Grounded theory', 'Theoretical sampling', 'Qualitative research', 'Coding (social sciences)', 'Computer science', 'Epistemology', 'Sociology', 'Social science', 'Philosophy']","grounded theory, rich data coding, grounded theory, saturation, sorting, grounded theory, [PAD], [PAD], [PAD]"
Paper_00603,Self-consistent molecular orbital methods. XX. A basis set for correlated wave functions,"['R. Krishnan', 'J. Stephen Binkley', 'Rolf Seeger', 'John A. Pople']",1980,The Journal of Chemical Physics,Journal,,650-654,72,1,10.1063/1.438955,"Views Icon Views Article contents Figures & tables Video Audio Supplementary Data Peer Review Share Icon Share Twitter Facebook Reddit LinkedIn Tools Icon Tools Reprints and Permissions Cite Icon Cite Search Site Citation R. Krishnan, J. S. Binkley, R. Seeger, J. A. Pople; Self‐consistent molecular orbital methods. XX. A basis set for correlated wave functions. J. Chem. Phys. 1 January 1980; 72 (1): 650–654. https://doi.org/10.1063/1.438955 Download citation file: Ris (Zotero) Reference Manager EasyBib Bookends Mendeley Papers EndNote RefWorks BibTex toolbar search Search Dropdown Menu toolbar search search input Search input auto suggest filter your search All ContentAIP Publishing PortfolioThe Journal of Chemical Physics Search Advanced Search |Citation Search","['Basis set', 'Wave function', 'Gaussian', 'Valence (chemistry)', 'Basis (linear algebra)', 'STO-nG basis sets', 'Atomic physics', 'Basis function', 'Physics', 'Polarization (electrochemistry)', 'Atom (system on chip)', 'Computational chemistry', 'Molecule', 'Mathematics', 'Molecular physics', 'Chemistry', 'Quantum mechanics', 'Geometry', 'Linear combination of atomic orbitals', 'Computer science', 'Physical chemistry', 'Embedded system']","##dit linked, molecular orbital methods, basis set, correlated wave functions, ##s, zotero, men, ##bt, chemical physics, citation"
Paper_00605,Sensemaking in Organizations,"['Dennis A. Gioia', 'Ajay Mehra', 'Karl E. Weick']",1996,Academy of Management Review,Journal,,1226-1226,21,4,10.2307/259169,The Nature of Sensemaking Seven Properties of Sensemaking Sensemaking in Organizations Occasions for Sensemaking The Substance of Sensemaking Belief-Driven Processes of Sensemaking Action-Driven Processes of Sensemaking The Future of Sensemaking,"['Sensemaking', 'Sociology', 'Organizational behavior', 'Process management', 'Management', 'Business', 'Public relations', 'Knowledge management', 'Engineering ethics', 'Political science', 'Engineering', 'Computer science', 'Economics']","sense, sense, sense, organizations, sense, sense, sense, [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD]"
Paper_00606,Motivation and Personality,['Abraham H. Maslow'],1997,SAGE Publications Ltd eBooks,Unknown,,110-133,,,10.4135/9781446221815.n7,Perspectives on Sexuality Sex Research - an Overview Part 1. Biological Perspectives: Sexual Anatomy 1. Sexual Physiology 2. Human Reproduction 3. Birth Control 4. Abortion Part 2. Developmental Perspectives: Childhood Sexuality 5. Adolescent Sexuality 6. Adult Sexuality 7. Gender Roles Part 3. Psychological Perspectives: Loving and Being Loved 8. Intimacy and Communication Skills 9. Enhancing your Sexual Relationships 10. Sexual Orientation 11. Sexual Behaviour 12. Sexual Variations 13. Coercive Sex - the Varieties of Sexual Assault Part 4. Sexual Health Perspectives: Sexually Transmitted Diseases and Sexual Infections 14. HIV Infection and AIDS 15. Sexual Dysfunctions and Sex Therapy 16. Sexual Disorders and Sexual Health Part 5 Cultural Perspectives: Sex and the Law 17. Religious and Ethical Perspectives and Sexuality,"['Human sexuality', 'Psychology', 'Sexual orientation', 'Personality', 'Reproductive health', 'Developmental psychology', 'Human immunodeficiency virus (HIV)', 'Sexual attraction', 'Sexual behavior', 'Clinical psychology', 'Social psychology', 'Gender studies', 'Medicine', 'Population', 'Sociology', 'Environmental health', 'Family medicine']","sexuality sex research, sexual anatomy, sexual physiology, human reproduction, birth control, abortion, childhood sexuality, adolescent sexuality, adult sexuality, gender roles, psychological perspectives, intimacy, communication skills, sexual relationships, sexual orientation, sexual behaviour, sexual variations, coercive sex, sexual assault, sexual health perspectives, sexually transmitted diseases, sexual infections, hiv infection, sexual dysfunctions, sex therapy, sexual disorders, sexual health"
Paper_00607,Ten lectures on wavelets,['Ingrid Daubechies'],1992,['Mathematics of Computation'],Unknown,,941,61,204,10.2307/2153268,"Introduction Preliminaries and notation The what, why, and how of wavelets The continuous wavelet transform Discrete wavelet transforms: Frames Time-frequency density and orthonormal bases Orthonormal bases of wavelets and multiresolutional analysis Orthonormal bases of compactly supported wavelets More about the regularity of compactly supported wavelets Symmetry for compactly supported wavelet bases Characterization of functional spaces by means of wavelets Generalizations and tricks for orthonormal wavelet bases References Indexes.","['Wavelet', 'Legendre wavelet', 'Orthonormal basis', 'Mathematics', 'Discrete wavelet transform', 'Gabor wavelet', 'Fast wavelet transform', 'Pure mathematics', 'Wavelet transform', 'Continuous wavelet transform', 'Multiresolution analysis', 'Computer science', 'Artificial intelligence', 'Physics', 'Quantum mechanics']","continuous wavelet transform discrete wavelet transforms, orthonormal bases orthono, ##l bases, wavelets, multiresolutional analysis, ##th, ##l bases, compactly supported wavelets, compact, compactly supported wavelet bases, functional spaces, ##thonormal, [PAD]"
Paper_00608,A New Method for Measuring Daytime Sleepiness: The Epworth Sleepiness Scale,['Murray W. Johns'],1991,SLEEP,Journal,,540-545,14,6,10.1093/sleep/14.6.540,"The development and use of a new scale, the Epworth sleepiness scale (ESS), is described. This is a simple, self-administered questionnaire which is shown to provide a measurement of the subject's general level of daytime sleepiness. One hundred and eighty adults answered the ESS, including 30 normal men and women as controls and 150 patients with a range of sleep disorders. They rated the chances that they would doze off or fall asleep when in eight different situations commonly encountered in daily life. Total ESS scores significantly distinguished normal subjects from patients in various diagnostic groups including obstructive sleep apnea syndrome, narcolepsy and idiopathic hypersomnia. ESS scores were significantly correlated with sleep latency measured during the multiple sleep latency test and during overnight polysomnography. In patients with obstructive sleep apnea syndrome ESS scores were significantly correlated with the respiratory disturbance index and the minimum SaO2 recorded overnight. ESS scores of patients who simply snored did not differ from controls.","['Epworth Sleepiness Scale', 'Polysomnography', 'Narcolepsy', 'Excessive daytime sleepiness', 'Obstructive sleep apnea', 'Multiple Sleep Latency Test', 'Respiratory disturbance index', 'Physical therapy', 'Medicine', 'Sleep disorder', 'Sleep apnea', 'Apnea', 'Sleep Stages', 'Psychology', 'Internal medicine', 'Neurology', 'Insomnia', 'Psychiatry']","epworth sleepiness scale, daytime sleepiness, sleep disorders, obstructive sleep apnea syndrome, narcolepsy, idiopathic hypersomnia, sleep latency, multiple sleep latency test, overnight polysomnography, obstructive sleep apnea syndrome, respiratory disturbance index"
Paper_00610,Some Models for Estimating Technical and Scale Inefficiencies in Data Envelopment Analysis,"['Rajiv D. Banker', 'A. Charnes', 'W. W. Cooper']",1984,Management Science,Journal,,1078-1092,30,9,10.1287/mnsc.30.9.1078,"In management contexts, mathematical programming is usually used to evaluate a collection of possible alternative courses of action en route to selecting one which is best. In this capacity, mathematical programming serves as a planning aid to management. Data Envelopment Analysis reverses this role and employs mathematical programming to obtain ex post facto evaluations of the relative efficiency of management accomplishments, however they may have been planned or executed. Mathematical programming is thereby extended for use as a tool for control and evaluation of past accomplishments as well as a tool to aid in planning future activities. The CCR ratio form introduced by Charnes, Cooper and Rhodes, as part of their Data Envelopment Analysis approach, comprehends both technical and scale inefficiencies via the optimal value of the ratio form, as obtained directly from the data without requiring a priori specification of weights and/or explicit delineation of assumed functional forms of relations between inputs and outputs. A separation into technical and scale efficiencies is accomplished by the methods developed in this paper without altering the latter conditions for use of DEA directly on observational data. Technical inefficiencies are identified with failures to achieve best possible output levels and/or usage of excessive amounts of inputs. Methods for identifying and correcting the magnitudes of these inefficiencies, as supplied in prior work, are illustrated. In the present paper, a new separate variable is introduced which makes it possible to determine whether operations were conducted in regions of increasing, constant or decreasing returns to scale (in multiple input and multiple output situations). The results are discussed and related not only to classical (single output) economics but also to more modern versions of economics which are identified with “contestable market theories.”","['Data envelopment analysis', 'Computer science', 'Operations research', 'Scale (ratio)', 'Variable (mathematics)', 'Constant (computer programming)', 'Mathematical optimization', 'Linear programming', 'Returns to scale', 'Production (economics)', 'Mathematics', 'Economics', 'Algorithm', 'Mathematical analysis', 'Physics', 'Quantum mechanics', 'Programming language', 'Macroeconomics']","management, mathematical programming, mathematical programming, data envelopment analysis, mathematical programming, mathematical programming, ccr ratio form, data envelopment analysis, scale in, scale efficiencies, technical in, multiple output"
Paper_00615,A Survey of Corporate Governance,"['Andrei Shleifer', 'Robert W. Vishny']",1997,The Journal of Finance,Journal,,737-783,52,2,10.1111/j.1540-6261.1997.tb04820.x,"ABSTRACT This article surveys research on corporate governance, with special attention to the importance of legal protection of investors and of ownership concentration in corporate governance systems around the world.","['Corporate governance', 'Business', 'Accounting', 'Survey research', 'Finance', 'Business administration']","corporate governance, legal protection, investors, ownership concentration, corporate governance systems, [PAD] [PAD], [PAD], [PAD], [PAD] [PAD], [PAD] [PAD], [PAD], [PAD] [PAD], [PAD] [PAD], [PAD] [PAD], [PAD] [PAD], [PAD]"
Paper_00616,Numerical recipes in C,"['William H. Press', 'Saul A. Teukolsky', 'William T. Vetterling', 'Brian P. Flannery']",1994,['Computers &amp; Chemistry'],Unknown,,297-298,13,3,10.1016/0097-8485(89)85017-x,"Note: Includes bibliographical references, 3 appendixes and 2 indexes.- Diskette v 2.06, 3.5''[1.44M] for IBM PC, PS/2 and compatibles [DOS] Reference Record created on 2004-09-07, modified on 2016-08-08",['Computer science'],bibliographical references
Paper_00617,Crystallography &amp; NMR System: A New Software Suite for Macromolecular Structure Determination,"['Axel T. Brünger', 'Paul D. Adams', 'G. Marius Clore', 'Warren L. DeLano', 'Piet Gros', 'Ralf W. Grosse‐Kunstleve', 'Jiansheng Jiang', 'John Kuszewski', 'Michaël Nilges', 'Neesh Pannu', 'Randy J. Read', 'Luke M. Rice', 'Thomas Simonson', 'Gregory L. Warren']",1998,Acta Crystallographica Section D Biological Crystallography,Journal,,905-921,54,5,10.1107/s0907444998003254,"A new software suite, called Crystallography & NMR System (CNS), has been developed for macromolecular structure determination by X-ray crystallography or solution nuclear magnetic resonance (NMR) spectroscopy. In contrast to existing structure-determination programs the architecture of CNS is highly flexible, allowing for extension to other structure-determination methods, such as electron microscopy and solid-state NMR spectroscopy. CNS has a hierarchical structure: a high-level hypertext markup language (HTML) user interface, task-oriented user input files, module files, a symbolic structure-determination language (CNS language), and low-level source code. Each layer is accessible to the user. The novice user may just use the HTML interface, while the more advanced user may use any of the other layers. The source code will be distributed, thus source-code modification is possible. The CNS language is sufficiently powerful and flexible that many new algorithms can be easily implemented in the CNS language without changes to the source code. The CNS language allows the user to perform operations on data structures, such as structure factors, electron-density maps, and atomic properties. The power of the CNS language has been demonstrated by the implementation of a comprehensive set of crystallographic procedures for phasing, density modification and refinement. User-friendly task-oriented input files are available for nearly all aspects of macromolecular structure determination by X-ray crystallography and solution NMR.","['Computer science', 'Software', 'Interface (matter)', 'Source code', 'User interface', 'Suite', 'Crystallography', 'Programming language', 'Computational science', 'Chemistry', 'Archaeology', 'Bubble', 'Maximum bubble pressure method', 'Parallel computing', 'History']","macro, ##lecular structure determination, module, html, ##s, ##s, structure factors, atomic, density modification, ##cular structure, solution"
Paper_00618,Case study research,['Jean Hartley'],2004,['Practice-Based Scholarly Inquiry and the DNP Project'],Unknown,,,,,10.1891/9780826134943.0006,"Essential Guide to Qualitative Methods in Organizational Research is an excellent resource for students and researchers in the areas of organization studies, management research and organizational psychology, bringing together in one volume the range of methods available for undertaking qualitative data collection and analysis. 

The volume includes 30 chapters, each focusing on a specific technique. The chapters cover traditional research methods, analysis techniques, and interventions as well as the latest developments in the field. Each chapter reviews how the method has been used in organizational research, discusses the advantages and disadvantages of using the method, and presents a case study example of the method in use. A list of further reading is supplied for those requiring additional information about a given method. 

The comprehensive and accessible nature of this collection will make it an essential and lasting handbook for researchers and students studying organizations.","['Resource (disambiguation)', 'Management science', 'Field (mathematics)', 'Data collection', 'Reading (process)', 'Qualitative research', 'Computer science', 'Knowledge management', 'Data science', 'Engineering', 'Sociology', 'Political science', 'Social science', 'Computer network', 'Mathematics', 'Law', 'Pure mathematics']","qualitative methods, organizational research, organization studies, management research, organizational psychology, qualitative data collection, analysis, organizational research, case study"
Paper_00619,Research Methods for Business Students,"['Mark N. K. Saunders', 'Philip Lewis', 'Adrian Thornhill']",1996,['Qualitative Market Research: An International Journal'],Unknown,,215-218,3,4,10.1108/qmr.2000.3.4.215.2,"How to use this book Guided tour Preface Contributors 1 The nature of business and management research and structure of this book 2 Formulating and clarifying the research topic 3 Critically reviewing the literature 4 Understanding research philosophies and approaches 5 Formulating the research design 6 Negotiating access and research ethics 7 Selecting samples 8 Using secondary data 9 Collecting primary data through observation 10 Collecting primary data using semi-structured, in-depth and group interviews 11 Collecting primary data using questionnaires 12 Analysing quantitative data 13 Analysing qualitative data 14 Writing and presenting your project report Appendices Glossary Index","['Glossary', 'Negotiation', 'Index (typography)', 'Qualitative research', 'Qualitative property', 'Research data', 'Knowledge management', 'Computer science', 'Data science', 'Management science', 'Sociology', 'Engineering', 'World Wide Web', 'Data curation', 'Social science', 'Linguistics', 'Philosophy', 'Machine learning']","business, management, research ethics, secondary data, questionnaire, qualitative data"
Paper_00620,The American Economic Review,[],2013,American Economic Review,Journal,,i-viii,103,5,10.1257/aer.103.5.i,The front matter of the August 2013 issue contains the Table of Contents,"['Economics', 'Neoclassical economics']",
Paper_00621,GENEPOP (Version 1.2): Population Genetics Software for Exact Tests and Ecumenicism,"['Michel Raymond', 'François Rousset']",1995,Journal of Heredity,Journal,,248-249,86,3,10.1093/oxfordjournals.jhered.a111573,"Journal Article GENEPOP (Version 1.2): Population Genetics Software for Exact Tests and Ecumenicism Get access M. Raymond, M. Raymond Institut des Sciences de l'Evolution, URA CNRS 327, Laboratoire de Genetique et Environnement, Universite de Montpellier II (CC 065)Place E. Bataillon, 34095 Montpellier cedex 05, France Search for other works by this author on: Oxford Academic PubMed Google Scholar F. Rousset F. Rousset Institut des Sciences de l'Evolution, URA CNRS 327, Laboratoire de Genetique et Environnement, Universite de Montpellier II (CC 065)Place E. Bataillon, 34095 Montpellier cedex 05, France Search for other works by this author on: Oxford Academic PubMed Google Scholar Journal of Heredity, Volume 86, Issue 3, May 1995, Pages 248–249, https://doi.org/10.1093/oxfordjournals.jhered.a111573 Published: 01 May 1995 Article history Received: 28 March 1994 Accepted: 04 October 1994 Published: 01 May 1995","['Biology', 'Population', 'Library science', 'Genealogy', 'Demography', 'Computer science', 'History', 'Sociology']","##pop, population genetics software, exact tests, ecumenicism, heredity"
Paper_00622,CAPITAL ASSET PRICES: A THEORY OF MARKET EQUILIBRIUM UNDER CONDITIONS OF RISK*,['William F. Sharpe'],1964,The Journal of Finance,Journal,,425-442,19,3,10.1111/j.1540-6261.1964.tb02865.x,"One of the problems which has plagued those attempting to predict the behavior of capital markets is the absence of a body of positive microeconomic theory dealing with conditions of risk. Although many useful insights can be obtained from the traditional models of investment under conditions of certainty, the pervasive influence of risk in financial transactions has forced those working in this area to adopt models of price behavior which are little more than assertions. A typical classroom explanation of the determination of capital asset prices, for example, usually begins with a careful and relatively rigorous description of the process through which individual preferences and physical relationships interact to determine an equilibrium pure interest rate. This is generally followed by the assertion that somehow a market risk-premium is also determined, with the prices of assets adjusting accordingly to account for differences in their risk. A useful representation of the view of the capital market implied in such discussions is illustrated in Figure 1. In equilibrium, capital asset prices have adjusted so that the investor, if he follows rational procedures (primarily diversification), is able to attain any desired point along a capital market line.11 Although some discussions are also consistent with a non-linear (but monotonic) curve. He may obtain a higher expected rate of return on his holdings only by incurring additional risk. In effect, the market presents him with two prices: the price of time, or the pure interest rate (shown by the intersection of the line with the horizontal axis) and the price of risk, the additional expected return per unit of risk borne (the reciprocal of the slope of the line). At present there is no theory describing the manner in which the price of risk results from the basic influences of investor preferences, the physical attributes of capital assets, etc. Moreover, lacking such a theory, it is difficult to give any real meaning to the relationship between the price of a single asset and its risk. Through diversification, some of the risk inherent in an asset can be avoided so that its total risk is obviously not the relevant influence on its price; unfortunately little has been said concerning the particular risk component which is relevant. In the last ten years a number of economists have developed normative models dealing with asset choice under conditions of risk. Markowltz,22 Harry M. Markowitz, Portfolio Selection, Efficient Diversification of Investments (New York: John Wiley and Sons, Inc., 1959). The major elements of the theory first appeared in his article “Portfolio Selection,” The Journal of Finance, XII (March 1952), 77–91. following Von Neumann and Morgenstern, developed an analysis based on the expected utility maxim and proposed a general solution for the portfolio selection problem. Tobin33 James Tobin, “Liquidity Preference as Behavior Towards Risk,” The Review of Economic Studies, XXV (February, 1958), 65–86. showed that under certain conditions Markowitz's model implies that the process of investment choice can be broken down into two phases: first, the choice of a unique optimum combination of risky assets; and second, a separate choice concerning the allocation of funds between such a combination and a single riskless asset. Recently, Hicks44 John R. Hicks, “Liquidity,” The Economic Journal, LXXII (December, 1962), 787–802. has used a model similar to that proposed by Tobin to derive corresponding conclusions about individual investor behavior, dealing somewhat more explicitly with the nature of the conditions under which the process of investment choice can be dichotomized. An even more detailed discussion of this process, including a rigorous proof in the context of a choice among lotteries has been presented by Gordon and Gangolli.55 M. J. Gordon and Ramesh Gangolli, “Choice Among and Scale of Play on Lottery Type Alternatives,” College of Business Administration, University of Rochester, 1962. For another discussion of this relationship see W. F. Sharpe, “A Simplified Model for Portfolio Analysis,” Management Science, Vol. 9, No. 2 (January 1963), 277–293. A related discussion can be found in F. Modigliani and M. H. Miller, “The Cost of Capital, Corporation Finance, and the Theory of Investment,” The American Economic Review, XLVIII (June 1958), 261–297. Although all the authors cited use virtually the same model of investor behavior,66 Recently Hirshleifer has suggested that the mean-variance approach used in the articles cited is best regarded as a special case of a more general formulation due to Arrow. See Hirshleifer's “Investment Decision Under Uncertainty,” Papers and Proceedings of the Seventy-Sixth Annual Meeting of the American Economic Association, Dec. 1963, or Arrow's “Le Role des Valeurs Boursieres pour la Repartition la Meilleure des Risques,” International Colloquium on Econometrics, 1952. none has yet attempted to extend it to construct a market equilibrium theory of asset prices under conditions of risk.77 After preparing this paper the author learned that Mr. Jack L. Treynor, of Arthur D. Little, Inc., had independently developed a model similar in many respects to the one described here. Unfortunately Mr. Treynor's excellent work on this subject is, at present, unpublished. We will show that such an extension provides a theory with implications consistent with the assertions of traditional financial theory described above. Moreover, it sheds considerable light on the relationship between the price of an asset and the various components of its overall risk. For these reasons it warrants consideration as a model of the determination of capital asset prices. Part II provides the model of individual investor behavior under conditions of risk. In Part III the equilibrium conditions for the capital market are considered and the capital market line derived. The implications for the relationship between the prices of individual capital assets and the various components of risk are described in Part IV. Investors are assumed to prefer a higher expected future wealth to a lower value, ceteris paribus ( dU/dE w > 0 ) . Moreover, they exhibit risk-aversion, choosing an investment offering a lower value of σw to one with a greater level, given the level of E w ( dU / d σ w < 0 ) . These assumptions imply that indifference curves relating Ew and σw will be upward-sloping.99 While only these characteristics are required for the analysis, it is generally assumed that the curves have the property of diminishing marginal rates of substitution between Ew and σw, as do those in our diagrams. Figure 2 summarizes the model of investor preferences in a family of indifference curves; successive curves indicate higher levels of utility as one moves down and/or to the right.1010 Such indifference curves can also be derived by assuming that the investor wishes to maximize expected utility and that his total utility can be represented by a quadratic function of R with decreasing marginal utility. Both Markowitz and Tobin present such a derivation. A similar approach is used by Donald E. Farrar in The Investment Decision Under Uncertainty (Prentice-Hall, 1962). Unfortunately Farrar makes an error in his derivation; he appeals to the Von-Neumann-Morgenstern cardinal utility axioms to transform a function of the form: E ( U ) = a + bE R − cE R 2 − c σ R 2 into one of the form: E ( U ) = k 1 E R − k 2 σ R 2 . That such a transformation is not consistent with the axioms can readily be seen in this form, since the first equation implies non-linear indifference curves in the ER, σ R 2 plane while the second implies a linear relationship. Obviously no three (different) points can lie on both a line and a non-linear curve (with a monotonic derivative). Thus the two functions must imply different orderings among alternative choices in at least some instance. The model of investor behavior considers the investor as choosing from a set of investment opportunities that one which maximizes his utility. Every investment plan available to him may be represented by a point in the ER, σR plane. If all such plans involve some risk, the area composed of such points will have an appearance similar to that shown in Figure 2. The investor will choose from among all possible plans the one placing him on the indifference curve representing the highest level of utility (point F). The decision can be made in two stages: first, find the set of efficient investment plans and, second choose one from among this set. A plan is said to be efficient if (and only if) there is no alternative with either (1) the same ER and a lower σR, (2) the same σR and a higher ER or (3) a higher ER and a lower σR. Thus investment Z is inefficient since investments B, C, and D (among others) dominate it. The only plans which would be chosen must lie along the lower right-hand boundary (AFBDCX)—the investment opportunity curve. Note that this relationship includes rab, the correlation coefficient between the predicted rates of return of the two investment plans. A value of +1 would indicate an investor's belief that there is a precise positive relationship between the outcomes of the two investments. A zero value would indicate a belief that the outcomes of the two investments are completely independent and —1 that the investor feels that there is a precise inverse relationship between them. In the usual case rab will have a value between 0 and +1. Figure 3 shows the possible values of ERc and σRc obtainable with different combinations of A and B under two different assumptions about the value of rab. If the two investments are perfectly correlated, the combinations will lie along a straight line between the two points, since in this case both ERc and σRc will be linearly related to the proportions invested in the two plans.1111 E Rc = α E Ra + ( 1 − α ) E R b = E Rb + ( E R a − E R b ) α σ R c = α 2 σ R a 2 + ( 1 − α ) 2 σ Rb 2 + 2 r ab α ( 1 − α ) σ Ra σ Rb but r ab = 1 , therefore the expression under the square root sign can be factored: σ Rc = [ α σ Ra + ( 1 − α ) σ R b ] 2 = α σ Ra + ( 1 − α ) σ Rb = σ Rb + ( σ Ra − σ Rb ) α If they are less than perfectly positively correlated, the standard deviation of any combination must be less than that obtained with perfect correlation (since rab will be less); thus the combinations must lie along a curve below the line AB.1212 This curvature is, in essence, the rationale for diversification. AZB shows such a curve for the case of complete independence ( r ab = 0 ) ; with negative correlation the locus is even more U-shaped.1313 When r ab = 0 , the slope of the curve at point A is − σ Ra E Rb − E Ra , at point B it is σ Rb E Rb − E Ra . When r ab = − 1 , the curve degenerates to two straight lines to a point on the horizontal axis. The manner in which the investment opportunity curve is formed is relatively simple conceptually, although exact solutions are usually quite difficult.1414 Markowitz has shown that this is a problem in parametric quadratic programming. An efficient solution technique is described in his article, “The Optimization of a Quadratic Function Subject to Linear Constraints,” Naval Research Logistics Quarterly, Vol. 3 (March and June, 1956), 111–133. A solution method for a special case is given in the author's “A Simplified Model for Portfolio Analysis,” op. cit. One first traces curves indicating ER, σR values available with simple combinations of individual assets, then considers combinations of combinations of assets. The lower right-hand boundary must be either linear or increasing at an increasing rate ( d 2 σ R / dE 2 R > 0 ). As suggested earlier, the complexity of the relationship between the characteristics of individual assets and the location of the investment opportunity curve makes it difficult to provide a simple rule for assessing the desirability of individual assets, since the effect of an asset on an investor's over-all investment opportunity curve depends not only on its expected rate of return (ERi) and risk σRi), but also on its correlations with the other available opportunities (ri1, ri2, …., rin). However, such a rule is implied by the equilibrium conditions for the model, as we will show in part IV. This implies that all combinations involving any risky asset or combination of assets plus the riskless asset must have values of ERc and σRc which lie along a straight line between the points representing the two components. Thus in Figure 4 all combinations of ER and σR lying along the line PA are attainable if some money is loaned at the pure rate and some placed in A. Similarly, by lending at the pure rate and investing in B, combinations along PB can be attained. Of all such possibilities, however, one will dominate: that investment plan lying at the point of the original investment opportunity curve where a ray from point P is tangent to the curve. In Figure 4 all investments lying along the original curve from X to ϕ are dominated by some combination of investment in ϕ and lending at the pure interest rate. Consider next the possibility of borrowing. If the investor can borrow at the pure rate of interest, this is equivalent to disinvesting in P. The effect of borrowing to purchase more of any given investment than is possible with the given amount of wealth can be found simply by letting a take on negative values in the equations derived for the case of lending. This will obviously give points lying along the extension of line PA if borrowing is used to purchase more of A; points lying along the extension of PB if the funds are used to purchase B, etc. As in the case of lending, however, one investment plan will dominate all others when borrowing is possible. When the rate at which funds can be borrowed equals the lending rate, this plan will be the same one which is dominant if lending is to take place. Under these conditions, the investment opportunity curve becomes a line (PϕZ in Figure 4). Moreover, if the original investment opportunity curve is not linear at point ϕ, the process of investment choice can be dichotomized as follows: first select the (unique) optimum combination of risky assets (point ϕ), and second borrow or lend to obtain the particular point on PZ at which an indifference curve is tangent to the line.1515 This proof was first presented by Tobin for the case in which the pure rate of interest is zero (cash). Hicks considers the lending situation under comparable conditions but does not allow borrowing. Both authors present their analysis using maximization subject to constraints expressed as equalities. Hicks' analysis assumes independence and thus insures that the solution will include no negative holdings of risky assets; Tobin's covers the general case, thus his solution would generally include negative holdings of some assets. The discussion in this paper is based on Markowitz' formulation, which includes non-negativity constraints on the holdings of all assets. Before proceeding with the analysis, it may be useful to consider alternative assumptions under which only a combination of assets lying at the point of tangency between the original investment opportunity curve and a ray from P can be efficient. Even if borrowing is impossible, the investor will choose ϕ (and lending) if his risk-aversion leads him to a point below ϕ on the line Pϕ Since a large number of investors choose to place some of their funds in relatively risk-free investments, this is not an unlikely possibility. Alternatively, if borrowing is possible but only up to some limit, the choice of ϕ would be made by all but those investors willing to undertake considerable risk. These alternative paths lead to the main conclusion, thus making the assumption of borrowing or lending at the pure interest rate less onerous than it might initially appear to be. In order to derive conditions for equilibrium in the capital market we invoke two assumptions. First, we assume a common pure rate of interest, with all investors able to borrow or lend funds on equal terms. Second, we assume homogeneity of investor expectations:1616 A term suggested by one of the referees. investors are assumed to agree on the prospects of various investments—the expected values, standard deviations and correlation coefficients described in Part II. Needless to say, these are highly restrictive and undoubtedly unrealistic assumptions. However, since the proper test of a theory is not the realism of its assumptions but the acceptability of its implications, and since these assumptions imply equilibrium conditions which form a major part of classical financial doctrine, it is far from clear that this formulation should be rejected—especially in view of the dearth of alternative models leading to similar results. Under these assumptions, given some set of capital asset prices, each investor will view his alternatives in the same manner. For one set of prices the alternatives might appear as shown in Figure 5. In this situation, an investor with the preferences indicated by indifference curves A1 through A4 would seek to lend some of his funds at the pure interest rate and to invest the remainder in the combination of assets shown by point ϕ, since this would give him the preferred over-all position A*. An investor with the preferences indicated by curves B1 through B4 would seek to invest all his funds in combination ϕ, while an investor with indifference curves C1 through C4 would invest all his funds plus additional (borrowed) funds in combination ϕ in order to reach his preferred position (C*). In any event, all would attempt to purchase only those risky assets which enter combination ϕ. The attempts by investors to purchase the assets in combination ϕ and their lack of interest in holding assets not in combination ϕ would, of course, lead to a revision of prices. The prices of assets in ϕ will rise and, since an asset's expected return relates future income to present price, their expected returns will fall. This will reduce the attractiveness of combinations which include such assets; thus point ϕ (among others) will move to the left of its initial position.1717 If investors consider the variability of future dollar returns unrelated to present price, both ER and σR will fall; under these conditions the point representing an asset would move along a ray through the origin as its price changes. On the other hand, the prices of assets not in ϕ will fall, causing an increase in their expected returns and a rightward movement of points representing combinations which include them. Such price changes will lead to a revision of investors' actions; some new combination or combinations will become attractive, leading to different demands and thus to further revisions in prices. As the process continues, the investment opportunity curve will tend to become more linear, with points such as ϕ moving to the left and formerly inefficient points (such as F and G) moving to the right. Capital asset prices must, of course, continue to change until a set of prices is attained for which every asset enters at least one combination lying on the capital market line. Figure 6 illustrates such an equilibrium condition.1818 The area in Figure 6 representing ER, σR values attained with only risky assets has been drawn at some distance from the horizontal axis for emphasis. It is likely that a more accurate representation would place it very close to the axis. All possibilities in the shaded area can be attained with combinations of risky assets, while points lying along the line PZ can be attained by borrowing or lending at the pure rate plus an investment in some combination of risky assets. Certain possibilities (those lying along PZ from point A to point B) can be obtained in either manner. For example, the ER, σR values shown by point A can be obtained solely by some combination of risky assets; alternatively, the point can be reached by a combination of lending and investing in combination C of risky assets. It is important to recognize that in the situation shown in Figure 6 many alternative combinations of risky assets are efficient (i.e., lie along line PZ), and thus the theory does not imply that all investors will hold the same combination.1919 This statement contradicts Tobin's conclusion that there will be a unique optimal combination of risky assets. Tobin's proof of a unique optimum can be shown to be incorrect for the case of perfect correlation of efficient risky investment plans if the line connecting their ER, σR points would pass through point P. In the graph on page 83 of this article (op. cit.) the constant-risk locus would, in this case, degenerate from a family of ellipses into one of straight lines parallel to the constant-return loci, thus giving multiple optima. On the other hand, all such combinations must be perfectly (positively) correlated, since they lie along a linear border of the ER, σR region.2020 ER, σR values given by combinations of any two combinations must lie within the region and cannot plot above a straight line joining the points. In this case they cannot plot below such a straight line. But since only in the case of perfect correlation will they plot along a straight line, the two combinations must be perfectly correlated. As shown in Part IV, this does not necessarily imply that the individual securities they contain are perfectly correlated. This provides a key to the relationship between the prices of capital assets and different types of risk. We have argued that in equilibrium there will be a simple linear relationship between the expected return and standard deviation of return for efficient combinations of risky assets. Thus far nothing has been said about such a relationship for individual assets. Typically the ER, σR values associated with single assets will lie above the capital market line, reflecting the inefficiency of undiversified holdings. Moreover, such points may be scattered throughout the feasible region, with no consistent relationship between their expected return and total risk (σR). However, there will be a consistent relationship between their expected returns and what might best be called systematic risk, as we will now show. Figure 7 illustrates the typical relationship between a single capital asset (point i) and an efficient combination of assets (point g) of which it is a part. The curve igg′ indicates all ER, σR values which can be obtained with feasible combinations of asset i and combination g. As before, we denote such a combination in terms of a proportion α of asset i and ( 1 — α ) of combination g. A value of α = 1 would indicate pure investment in asset i while α = 0 would imply investment in combination g. Note, however, that α = .5 implies a total investment of more than half the funds in asset i, since half would be invested in i itself and the other half used to purchase combination g, which also includes some of asset i. This means that a combination in which asset i does not appear at all must be represented by some negative value of α. Point g′ indicates such a combination. In Figure 7 the curve igg' has been drawn tangent to the capital market line (PZ) at point g. This is no accident. All such curves must be tangent to the capital market line in equilibrium, since (1) they must touch it at the point representing the efficient combination and (2) they are continuous at that point.2121 Only if r ig = − 1 will the curve be discontinuous over the range in question. Under these conditions a lack of tangency would imply that the curve intersects PZ. But then some feasible combination of assets would lie to the right of the capital market line, an obvious impossibility since the capital market line represents the efficient boundary of feasible values of ER and σR. The requirement that curves such as igg' be tangent to the capital market line can be shown to lead to a relatively simple formula which relates the expected rate of return to various elements of risk for all assets which are included in combination g.2222 The standard deviation of a combination of g and i will be: σ = α 2 σ Ri 2 + ( 1 − α ) 2 σ Rg 2 + 2 r ig α ( 1 − α ) σ Ri σ Rg at α = 0 : d σ d α = − 1 σ [ σ Rg 2 − r ig σ Ri σ Rg ] but σ = σ Rg at α = 0 . Thus: d σ d α = − [ σ Rg − r ig σ Ri ] The expected return of a combination will be: E = α E Ri + ( 1 − α ) E Rg Thus, at all values of α: dE d α = − [ E Rg − E Ri ] and, at α = 0 : d σ dE = σ Rg − r ig σ Ri E Rg − E Ri . Let the equation of the capital market line be: σ R = s ( E R − P ) where P is the pure interest rate. Since igg′ is tangent to the line when α = 0 , and since (ERg, σRg lies on the line: σ Rg − r ig σ Ri E Rg − E Ri = σ Rg E Rg − P or: r ig σ Ri σ Rg = − [ P E Rg − P ] + [ 1 E Rg − P ] E Ri . Its economic meaning can best be seen if the relationship between the return of asset i and that of combination g is viewed in a manner similar to that used in regression analysis.2323 This model has been called the diagonal model since its portfolio analysis solution can be facilitated by re-arranging the data so that the variance-covariance matrix becomes diagonal. The method is described in the author's article, cited earlier. Imagine that we were given a number of (ex post) observations of the return of the two investments. The points might plot as shown in Fig. 8. The scatter of the Ri observations around their mean (which will approximate ERi) is, of course, evidence of the total risk of the asset—σRi. But part of the scatter is due to an underlying relationship with the return on combination g, shown by Big, the slope of the regression line. The response of Ri to changes in Rg(and variations in Rg itself) account for much of the variation in Ri, It is this component of the asset's total risk which we term the systematic risk. The remainder,2424 ex post, the standard error. being uncorrelated with Rg, is the unsystematic component. This formulation of the relationship between Ri and Rg can be employed ex ante as a predictive model. Big becomes the predicted response of Ri to changes in Rg. Then, given σRg (the predicted risk of Rg), the systematic portion of the predicted risk of each asset can be determined. This interpretation allows us to state the relationship derived from the tangency of curves such as igg' with the capital market line in the form shown in Figure 9. All assets entering efficient combination g must have (predicted) Big and ERi values lying on the line PQ.2525 r ig = B ig 2 σ Rg 2 σ Ri 2 = B ig σ Rg σ Ri and: B ig = r ig σ Ri σ Rg . The expression on the right is the expression on the left-hand side of the last equation in footnote 22. Thus: B ig = − [ P E Rg − P ] + [ 1 E Rg − P ] E Ri . Prices will adjust so that assets which are more responsive to changes in Rg will have higher expected returns than those which are less responsive. This accords with common sense. Obviously the part of an asset's risk which is due to its correlation with the return on a combination cannot be diversified away when the asset is added to the combination. Since Big indicates the magnitude of this type of risk it should be directly related to expected return. The relationship illustrated in Figure 9 provides a partial answer to the question posed earlier concerning the relationship between an asset's risk and its expected return. But thus far we have argued only that the relationship holds for the assets which enter some particular efficient combination (g). Had another combination been selected, a different linear relationship would have been derived. Fortunately this limitation is easily overcome. As shown in the footnote,2626 Consider the two assets i and i*, the former included in efficient combination g and the latter in combination g*. As shown above: B ig = − [ P E Rg − P ] + [ 1 E Rg − P ] E Ri and: B i * g * = − [ P E Rg * − P ] + [ 1 E Rg * − P ] E Ri * . Since Rg and Rg* are perfectly correlated: r i * g * = r i * g * Thus: B i * g * σ Rg * σ Ri * = B i * g σ Rg σ Ri * and: B i * g * = B i * g [ σ Rg σ Rg * ] . Since both g and g* lie on a line which intercepts the E-axis at P: σ Rg σ Rg * = E Rg − P E Rg * − P and: B i * g * = B i * g [ E Rg − P E Rg * − P ] Thus: − [ P E Rg * − P ] + [ 1 E Rg * − P ] E Ri * = B i * g [ E Rg − P E Rg * − P ] from which we have the desired relationship between Ri* and g: B i * g = − [ P E Rg − P ] + [ 1 E Rg − P ] E Ri * Bi*g must therefore plot on the same line as does Big. we may arbitrarily select any one of the efficient combinations, then measure the predicted responsiveness of every asset's rate of return to that of the combination selected; and these coefficients will be related to the expected rates of return of the assets in exactly the manner pictured in Figure 9. The fact that rates of return from all efficient combinations will be perfectly correlated provides the justification for arbitrarily selecting any one of them. Alternatively we may choose instead any variable perfectly correlated with the rate of return of such combinations. The vertical axis in Figure 9 would then indicate alternative levels of a coefficient measuring the sensitivity of the rate of return of a capital asset to changes in the variable chosen. This possibility suggests both a plausible explanation for the implication that all efficient combinations will be perfectly correlated and a useful interpretation of the relationship between an individual asset's expected return and its risk. Although the theory itself implies only that rates of return from efficient combinations will be perfectly correlated, we might expect that this would be due to their common dependence on the over-all level of economic activity. If so, diversification enables the investor to escape all but the risk resulting from swings in economic activity—this type of risk remains even in efficient combinations. And, since all other types can be avoided by diversification, only the responsiveness of an asset's rate of return to the level of economic activity is relevant in assessing its risk. Prices will adjust until there is a linear relationship between the magnitude of such responsiveness and expected return. Assets which are unaffected by changes in economic activity will return the pure interest rate; those which move with economic activity will promise appropriately higher expected rates of return. This discussion provides an answer to the second of the two questions posed in this paper. In Part III it was shown that with respect to equilibrium conditions in the capital market as a whole, the theory leads to results consistent with classical doctrine (i.e., the capital market line). We have now shown that with regard to capital assets considered individually, it also yields implications consistent with traditional concepts: it is common practice for investment counselors to accept a lower expected return from defensive securities (those which respond little to changes in the economy) than they require from aggressive securities (which exhibit significant response). As suggested earlier, the familiarity of the implications need not be considered a drawback. The provision of a logical framework for producing some of the major elements of traditional financial theory should be a useful contribution in its own right.","['Economics', 'Diversification (marketing strategy)', 'Interest rate', 'Security market line', 'Capital asset pricing model', 'Asset (computer security)', 'Financial economics', 'Capital market', 'Risk premium', 'Microeconomics', 'Econometrics', 'Monetary economics', 'Finance', 'Business', 'Stock market', 'Context (archaeology)', 'Paleontology', 'Computer security', 'Computer science', 'Biology', 'Marketing']","capital markets, financial transactions, price behavior, capital asset prices, capital market, capital asset prices, ##ification, capital, investor preferences, capital assets, asset choice, portfolio selection, efficient diversification, portfolio selection, finance"
Paper_00623,Measurements of Ω and Λ from 42 High‐Redshift Supernovae,"['S. Perlmutter', 'G. Aldering', 'G. Goldhaber', 'R. A. Knop', 'P. Nugent', 'P. G. Castro', 'Susana E. Deustua', 'S. Fabbro', 'A. Goobar', 'D. E. Groom', 'I. Hook', 'Alex Kim', 'M. Y. Kim', 'J. C. Lee', 'N. J. Nunes', 'R. Pain', 'C. Pennypacker', 'R. Quimby', 'C. Lidman', 'Richard S. Ellis', 'M. J. Irwin', 'R. G. McMahon', 'P. Ruiz‐Lapuente', 'N. A. Walton', 'Bradley E. Schaefer', 'B. J. Boyle', 'A. V. Filippenko', 'T. Matheson', 'A. S. Fruchter', 'N. Panagia', 'Heidi Jo Newberg', 'W. J. Couch', 'The Supernova Cosmology Project']",1999,The Astrophysical Journal,Journal,,565-586,517,2,10.1086/307221,"We report measurements of the mass density, ΩM, and cosmological-constant energy density, ΩΛ, of the universe based on the analysis of 42 type Ia supernovae discovered by the Supernova Cosmology Project. The magnitude-redshift data for these supernovae, at redshifts between 0.18 and 0.83, are fitted jointly with a set of supernovae from the Calán/Tololo Supernova Survey, at redshifts below 0.1, to yield values for the cosmological parameters. All supernova peak magnitudes are standardized using a SN Ia light-curve width-luminosity relation. The measurement yields a joint probability distribution of the cosmological parameters that is approximated by the relation 0.8ΩM-0.6ΩΛ≈-0.2±0.1 in the region of interest (ΩM≲1.5). For a flat (ΩM+ΩΛ=1) cosmology we find ΩMflat=0.28+0.09-0.08 (1 σ statistical) +0.05-0.04 (identified systematics). The data are strongly inconsistent with a Λ=0 flat cosmology, the simplest inflationary universe model. An open, Λ=0 cosmology also does not fit the data well: the data indicate that the cosmological constant is nonzero and positive, with a confidence of P(Λ>0)=99%, including the identified systematic uncertainties. The best-fit age of the universe relative to the Hubble time is t0flat=14.9+1.4-1.1(0.63/h) Gyr for a flat cosmology. The size of our sample allows us to perform a variety of statistical tests to check for possible systematic errors and biases. We find no significant differences in either the host reddening distribution or Malmquist bias between the low-redshift Calán/Tololo sample and our high-redshift sample. Excluding those few supernovae that are outliers in color excess or fit residual does not significantly change the results. The conclusions are also robust whether or not a width-luminosity relation is used to standardize the supernova peak magnitudes. We discuss and constrain, where possible, hypothetical alternatives to a cosmological constant.","['Supernova', 'Redshift', 'Astrophysics', 'Physics', 'Astronomy', 'Galaxy']","mass density, supernova cosmology, ##nova peak magnitudes, joint probability distribution, systematic, ##ble time, statistical, systematic errors, host reddening distribution, malmquist bias"
Paper_00625,Social Network Analysis,"['Stanley Wasserman', 'Katherine Faust']",1994,Unknown,Unknown,,,,,10.1017/cbo9780511815478,"Social network analysis is used widely in the social and behavioral sciences, as well as in economics, marketing, and industrial engineering. The social network perspective focuses on relationships among social entities and is an important addition to standard social and behavioral research, which is primarily concerned with attributes of the social units. Social Network Analysis: Methods and Applications reviews and discusses methods for the analysis of social networks with a focus on applications of these methods to many substantive examples. It is a reference book that can be used by those who want a comprehensive review of network methods, or by researchers who have gathered network data and want to find the most appropriate method by which to analyze it. It is also intended for use as a textbook as it is the first book to provide comprehensive coverage of the methodology and applications of the field.","['Social network analysis', 'Social network (sociolinguistics)', 'Organizational network analysis', 'Field (mathematics)', 'Data science', 'Perspective (graphical)', 'Computer science', 'Management science', 'Focus (optics)', 'Knowledge management', 'World Wide Web', 'Artificial intelligence', 'Engineering', 'Social media', 'Organizational learning', 'Physics', 'Mathematics', 'Optics', 'Pure mathematics']","social network analysis, economics, marketing, industrial engineering, social, social entities, social network analysis, social networks, network methods"
Paper_00628,The Economic Institutions of Capitalism,['William M. Dugger'],1987,Journal of Economic Issues,Journal,,528-530,21,1,10.1080/00213624.1987.11504638,"(1987). The Economic Institutions of Capitalism. Journal of Economic Issues: Vol. 21, No. 1, pp. 528-530.","['Capitalism', 'Institutional economics', 'Economics', 'Economic system', 'Neoclassical economics', 'Political science', 'Politics', 'Law']","economic institutions, capitalism, economic issues, [PAD] [PAD], [PAD] [PAD]"
Paper_00630,Object recognition from local scale-invariant features,['David Lowe'],1999,Unknown,Unknown,,1150-1157 vol.2,,,10.1109/iccv.1999.790410,"An object recognition system has been developed that uses a new class of local image features. The features are invariant to image scaling, translation, and rotation, and partially invariant to illumination changes and affine or 3D projection. These features share similar properties with neurons in inferior temporal cortex that are used for object recognition in primate vision. Features are efficiently detected through a staged filtering approach that identifies stable points in scale space. Image keys are created that allow for local geometric deformations by representing blurred image gradients in multiple orientation planes and at multiple scales. The keys are used as input to a nearest neighbor indexing method that identifies candidate object matches. Final verification of each match is achieved by finding a low residual least squares solution for the unknown model parameters. Experimental results show that robust object recognition can be achieved in cluttered partially occluded images with a computation time of under 2 seconds.","['Artificial intelligence', 'Computer vision', 'Cognitive neuroscience of visual object recognition', 'Pattern recognition (psychology)', 'Invariant (physics)', '3D single-object recognition', 'Computer science', 'Affine transformation', 'Computation', 'Search engine indexing', 'Feature extraction', 'Mathematics', 'Algorithm', 'Pure mathematics', 'Mathematical physics']","object recognition system, local image features, image scaling, translation, rotation, illumination changes, 3d projection, inferior temporal cortex, object recognition, primate vision, staged filtering, image keys, local geometric deformations, blurred image gradients, nearest neighbor indexing method, low residual least squares solution, robust object recognition"
Paper_00633,Infrared and <scp>R</scp> aman Spectra of Inorganic and Coordination Compounds,['Kazuo Nakamoto'],2001,Handbook of Vibrational Spectroscopy,Journal,,,,,10.1002/0470027320.s4104,"Abstract Inorganic molecules (ions) and ligands are classified into diatomic, triatomic, four‐atomic, five‐atomic, six‐atomic, and seven‐atomic types, and their normal modes of vibration are illustrated and the corresponding vibrational frequencies are listed for each type. Molecules of other types are grouped into compounds of boron, carbon, silicon, nitrogen, phosphorus, and sulfur, and the structures and infrared (IR)/Raman spectra of select examples are shown for each group. Group frequency charts including band assignments are shown for phosphorus and sulfur compounds. Other group frequency charts include hydrogen stretching frequencies, halogen stretching frequencies, oxygen stretching and bending frequencies, inorganic ions, and metal complexes containing simple coordinating ligands.","['Chemistry', 'Molecule', 'Halogen', 'Raman spectroscopy', 'Sulfur', 'Infrared', 'Boron', 'Infrared spectroscopy', 'Ion', 'Diatomic molecule', 'Group (periodic table)', 'Triatomic molecule', 'Carbon fibers', 'Crystallography', 'Silicon', 'Spectral line', 'Inorganic chemistry', 'Materials science', 'Organic chemistry', 'Alkyl', 'Physics', 'Optics', 'Astronomy', 'Composite number', 'Composite material']","abstract inorganic molecules, ligands, vibrational frequencies, group frequency charts, band assignments, group frequency, hydrogen stretching frequencies, halogen stretching frequencies, oxygen stretching, bending frequencies, inorganic ions, metal complexes, coordinating ligands, [PAD]"
Paper_00634,A 12-Item Short-Form Health Survey,"['John E. Ware', 'Mark Kosinski', 'Susan Keller']",1996,Medical Care,Journal,,220-233,34,3,10.1097/00005650-199603000-00003,"Regression methods were used to select and score 12 items from the Medical Outcomes Study 36-Item Short-Form Health Survey (SF-36) to reproduce the Physical Component Summary and Mental Component Summary scales in the general US population (n = 2,333). The resulting 12-item short-form (SF-12) achieved multiple R squares of 0.911 and 0.918 in predictions of the SF-36 Physical Component Summary and SF-36 Mental Component Summary scores, respectively. Scoring algorithms from the general population used to score 12-item versions of the two components (Physical Component Summary and Mental Component Summary) achieved R squares of 0.905 with the SF-36 Physical Component Summary and 0.938 with the SF-36 Mental Component Summary when cross-validated in the Medical Outcomes Study. Test-retest (2-week) correlations of 0.89 and 0.76 were observed for the 12-item Physical Component Summary and the 12-item Mental Component Summary, respectively, in the general US population (n = 232). Twenty cross-sectional and longitudinal tests of empirical validity previously published for the 36-item short-form scales and summary measures were replicated for the 12-item Physical Component Summary and the 12-item Mental Component Summary, including comparisons between patient groups known to differ or to change in terms of the presence and seriousness of physical and mental conditions, acute symptoms, age and aging, self-reported 1-year changes in health, and recovery from depression. In 14 validity tests involving physical criteria, relative validity estimates for the 12-item Physical Component Summary ranged from 0.43 to 0.93 (median = 0.67) in comparison with the best 36-item short-form scale. Relative validity estimates for the 12-item Mental Component Summary in 6 tests involving mental criteria ranged from 0.60 to 1.07 (median = 0.97) in relation to the best 36-item short-form scale. Average scores for the 2 summary measures, and those for most scales in the 8-scale profile based on the 12-item short-form, closely mirrored those for the 36-item short-form, although standard errors were nearly always larger for the 12-item short-form.","['Mental health', 'Component (thermodynamics)', 'Population', 'SF-36', 'Seriousness', 'Physical health', 'Psychology', 'Clinical psychology', 'Depression (economics)', 'Medicine', 'Psychiatry', 'Disease', 'Health related quality of life', 'Environmental health', 'Physics', 'Macroeconomics', 'Pathology', 'Political science', 'Law', 'Economics', 'Thermodynamics']","regression, medical outcomes, mental component summary, medical outcomes, empirical, acute symptoms, relative validity estimates"
Paper_00637,Knowledge and Teaching:Foundations of the New Reform,['Lee S. Shulman'],1987,Harvard Educational Review,Journal,,1-23,57,1,10.17763/haer.57.1.j463w79r56455411,"Lee S. Shulman builds his foundation for teaching reform on an idea of teaching that emphasizes comprehension and reasoning, transformation and reflection. ""This emphasis is justified,"" he writes, ""by the resoluteness with which research and policy have so blatantly ignored those aspects of teaching in the past."" To articulate and justify this conception, Shulman responds to four questions: What are the sources of the knowledge base for teaching?In what terms can these sources be conceptualized? What are the processes of pedagogical reasoning and action? and What are the implications for teaching policy and educational reform? The answers — informed by philosophy, psychology, and a growing body of casework based on young and experienced practitioners — go far beyond current reform assumptions and initiatives. The outcome for educational practitioners, scholars, and policymakers is a major redirection in how teaching is to be understood and teachers are to be trained and evaluated. This article was selected for the November 1986 special issue on ""Teachers, Teaching,and Teacher Education,"" but appears here because of the exigencies of publishing.","['Comprehension', 'Publishing', 'Pedagogy', 'Teaching method', 'Action (physics)', 'Sociology', 'Educational psychology', 'Foundation (evidence)', 'Mathematics education', 'Reflection (computer programming)', 'Psychology', 'Epistemology', 'Political science', 'Law', 'Philosophy', 'Linguistics', 'Physics', 'Quantum mechanics', 'Computer science', 'Programming language']","teaching reform, reasoning, reflection, pedagogical reasoning, educational reform, teachers, teacher education, [PAD], [PAD], [PAD] [PAD] [PAD]"
Paper_00638,Self-Reports in Organizational Research: Problems and Prospects,"['Philip M. Podsakoff', 'Dennis W. Organ']",1986,Journal of Management,Journal,,531-544,12,4,10.1177/014920638601200408,"Self-reports figure prominently in organizational and management research, but there are several problems associated with their use. This article identifies six categories of self-reports and discusses such problems as common method variance, the consistency motif, and social desirability. Statistical and post hoc remedies and some procedural methods for dealing with artifactual bias are presented and evaluated. Recommendations for future research are also offered.","['Psychology', 'Post hoc', 'Consistency (knowledge bases)', 'Variance (accounting)', 'Social psychology', 'Management science', 'Computer science', 'Business', 'Artificial intelligence', 'Engineering', 'Medicine', 'Accounting', 'Dentistry']","organizational, management research, common method variance, consistency motif, social desirability, post, procedural methods, artifactual bias, [PAD], [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD], [PAD], [PAD], [PAD] [PAD], [PAD], [PAD], [PAD] [PAD] [PAD] [PAD], [PAD], [PAD], [PAD] [PAD]"
Paper_00640,Those Who Understand: Knowledge Growth in Teaching,['Lee S. Shulman'],1986,Educational Researcher,Journal,,4-14,15,2,10.3102/0013189x015002004,"Este articulo fue un discurso presidencial en la reunion de America Educational Research Association de Chicago el ano 1985. -- Curioso sobre el por que el publico a menudo tiene una baja opinion sobre el conocimiento de los profesores, Shulman observa la historia de evaluaciones docentes. En la segunda mitad del 1800, las evaluaciones para quienes deseaban ensenar se basaban casi por completo en contenido. Para el ano en que el autor escribe el articulo, en 1985, la evaluacion era completamente distinta. En lugar de enfocarse en contenido, se enfocaba en topicos como planificacion de clases, sensibilizacion cultural, y otros aspectos de la conducta docente. Mientras los topicos usualmente tenian raices en la investigacion, claramente no representan el amplio espectro de habilidades y conocimientos que un docente necesita para ser efectivo. Mas especificamente, para los anos 80', la evaluacion docente parecia preocuparse tanto por los conocimientos, como el siglo anterior se preocupaba por la pedagogia.","['Mathematics education', 'Psychology', 'Teaching method', 'Pedagogy']",educational research association
Paper_00641,"Cancer statistics, 2016","['Rebecca L. Siegel', 'Kimberly D. Miller', 'Ahmedin Jemal']",2016,CA A Cancer Journal for Clinicians,Journal,,7-30,66,1,10.3322/caac.21332,"Each year, the American Cancer Society estimates the numbers of new cancer cases and deaths that will occur in the United States in the current year and compiles the most recent data on cancer incidence, mortality, and survival. Incidence data were collected by the National Cancer Institute (Surveillance, Epidemiology, and End Results [SEER] Program), the Centers for Disease Control and Prevention (National Program of Cancer Registries), and the North American Association of Central Cancer Registries. Mortality data were collected by the National Center for Health Statistics. In 2016, 1,685,210 new cancer cases and 595,690 cancer deaths are projected to occur in the United States. Overall cancer incidence trends (13 oldest SEER registries) are stable in women, but declining by 3.1% per year in men (from 2009‐2012), much of which is because of recent rapid declines in prostate cancer diagnoses. The cancer death rate has dropped by 23% since 1991, translating to more than 1.7 million deaths averted through 2012. Despite this progress, death rates are increasing for cancers of the liver, pancreas, and uterine corpus, and cancer is now the leading cause of death in 21 states, primarily due to exceptionally large reductions in death from heart disease. Among children and adolescents (aged birth‐19 years), brain cancer has surpassed leukemia as the leading cause of cancer death because of the dramatic therapeutic advances against leukemia. Accelerating progress against cancer requires both increased national investment in cancer research and the application of existing cancer control knowledge across all segments of the population. CA Cancer J Clin 2016;7–30. © 2015 American Cancer Society.","['Cancer', 'Medicine', 'Cause of death', 'Prostate cancer', 'Incidence (geometry)', 'Epidemiology', 'Disease', 'Mortality rate', 'Cancer prevention', 'Demography', 'Epidemiology of cancer', 'Causes of cancer', 'Gerontology', 'Internal medicine', 'Breast cancer', 'Physics', 'Sociology', 'Optics']","american cancer society, central cancer registries, women, prostate cancer, pancre, uterine corpus, brain cancer, cancer, american cancer society"
Paper_00642,Resilience and Stability of Ecological Systems,['C. S. Holling'],1973,Annual Review of Ecology and Systematics,Journal,,1-23,4,1,10.1146/annurev.es.04.110173.000245,"Individuals die, populations disappear, and species become extinct. That is one view of the world. But another view of the world concentrates not so much on presence or absence as upon the numbers of organisms and the degree of constancy of their numbers. These are two very different ways of viewing the behavior of systems and the usefulness of the view depends very much on the properties of the system concerned. If we are examining a particular device designed by the engineer to perform specific tasks under a rather narrow range of predictable external conditions, we are likely to be more concerned with consistent nonvariable performance in which slight departures from the performance goal are immediately counteracted. A quantitative view of the behavior of the system is, therefore, essential. With attention focused upon achieving constancy, the critical events seem to be the amplitude and frequency of oscillations. But if we are dealing with a system profoundly affected by changes external to it, and continually confronted by the unexpected, the constancy of its behavior becomes less important than the persistence of the relationships. Attention shifts, therefore, to the qualitative and to questions of existence or not. Our traditions of analysis in theoretical and empirical ecology have been largely inherited from developments in classical physics and its applied variants. Inevitably, there has been a tendency to emphasize the quantitative rather than the qualitative, for it is important in this tradition to know not just that a quantity is larger than another quantity, but precisely how much larger. It is similarly important, if a quantity fluctuates, to know its amplitude and period of fluctuation. But this orientation may simply reflect an analytic approach developed in one area because it was useful and then transferred to another where it may not be. Our traditional view of natural systems, therefore, might well be less a meaningful reality than a perceptual convenience. There can in some years be more owls and fewer mice and in others, the reverse. Fish populations wax and wane as a natural condition, and insect populations can range over extremes that only logarithmic","['Resilience (materials science)', 'Ecology', 'Ecological systems theory', 'Geography', 'Environmental resource management', 'Environmental science', 'Biology', 'Physics', 'Thermodynamics']","nonvariable performance, osci, empirical ecology, classical physics, natural systems, owls, mice, fish populations, insect populations, logarithmic"
Paper_00644,"Cancer statistics, 2018","['Rebecca L. Siegel', 'Kimberly D. Miller', 'Ahmedin Jemal']",2018,CA A Cancer Journal for Clinicians,Journal,,7-30,68,1,10.3322/caac.21442,"Abstract Each year, the American Cancer Society estimates the numbers of new cancer cases and deaths that will occur in the United States and compiles the most recent data on cancer incidence, mortality, and survival. Incidence data, available through 2014, were collected by the Surveillance, Epidemiology, and End Results Program; the National Program of Cancer Registries; and the North American Association of Central Cancer Registries. Mortality data, available through 2015, were collected by the National Center for Health Statistics. In 2018, 1,735,350 new cancer cases and 609,640 cancer deaths are projected to occur in the United States. Over the past decade of data, the cancer incidence rate (2005‐2014) was stable in women and declined by approximately 2% annually in men, while the cancer death rate (2006‐2015) declined by about 1.5% annually in both men and women. The combined cancer death rate dropped continuously from 1991 to 2015 by a total of 26%, translating to approximately 2,378,600 fewer cancer deaths than would have been expected if death rates had remained at their peak. Of the 10 leading causes of death, only cancer declined from 2014 to 2015. In 2015, the cancer death rate was 14% higher in non‐Hispanic blacks (NHBs) than non‐Hispanic whites (NHWs) overall (death rate ratio [DRR], 1.14; 95% confidence interval [95% CI], 1.13‐1.15), but the racial disparity was much larger for individuals aged &lt;65 years (DRR, 1.31; 95% CI, 1.29‐1.32) compared with those aged ≥65 years (DRR, 1.07; 95% CI, 1.06‐1.09) and varied substantially by state. For example, the cancer death rate was lower in NHBs than NHWs in Massachusetts for all ages and in New York for individuals aged ≥65 years, whereas for those aged &lt;65 years, it was 3 times higher in NHBs in the District of Columbia (DRR, 2.89; 95% CI, 2.16‐3.91) and about 50% higher in Wisconsin (DRR, 1.78; 95% CI, 1.56‐2.02), Kansas (DRR, 1.51; 95% CI, 1.25‐1.81), Louisiana (DRR, 1.49; 95% CI, 1.38‐1.60), Illinois (DRR, 1.48; 95% CI, 1.39‐1.57), and California (DRR, 1.45; 95% CI, 1.38‐1.54). Larger racial inequalities in young and middle‐aged adults probably partly reflect less access to high‐quality health care. CA Cancer J Clin 2018;68:7‐30 . © 2018 American Cancer Society .","['Cancer', 'Medicine', 'Demography', 'Mortality rate', 'Epidemiology', 'Incidence (geometry)', 'Cause of death', 'Confidence interval', 'Gerontology', 'Disease', 'Internal medicine', 'Physics', 'Sociology', 'Optics']","american cancer society, central cancer registries, women, cancer, hispanic, racial disparity, louisiana"
Paper_00645,New Guidelines to Evaluate the Response to Treatment in Solid Tumors,"['Patrick Therasse', 'Susan G. Arbuck', 'Elizabeth A. Eisenhauer', 'J. Wanders', 'Richard Kaplan', 'Larry Rubinstein', 'Jaap Verweij', 'M. van Glabbeke', 'Allan T. van Oosterom', 'Michaele C. Christian', 'Steve G. Gwyther']",2000,JNCI Journal of the National Cancer Institute,Journal,,205-216,92,3,10.1093/jnci/92.3.205,"Anticancer cytotoxic agents go through a process by which their antitumor activity-on the basis of the amount of tumor shrinkage they could generate-has been investigated. In the late 1970s, the International Union Against Cancer and the World Health Organization introduced specific criteria for the codification of tumor response evaluation. In 1994, several organizations involved in clinical research combined forces to tackle the review of these criteria on the basis of the experience and knowledge acquired since then. After several years of intensive discussions, a new set of guidelines is ready that will supersede the former criteria. In parallel to this initiative, one of the participating groups developed a model by which response rates could be derived from unidimensional measurement of tumor lesions instead of the usual bidimensional approach. This new concept has been largely validated by the Response Evaluation Criteria in Solid Tumors Group and integrated into the present guidelines. This special article also provides some philosophic background to clarify the various purposes of response evaluation. It proposes a model by which a combined assessment of all existing lesions, characterized by target lesions (to be measured) and nontarget lesions, is used to extrapolate an overall response to treatment. Methods of assessing tumor lesions are better codified, briefly within the guidelines and in more detail in Appendix I. All other aspects of response evaluation have been discussed, reviewed, and amended whenever appropriate.","['Response Evaluation Criteria in Solid Tumors', 'Medicine', 'Set (abstract data type)', 'Medical physics', 'Process (computing)', 'Cancer', 'Solid tumor', 'Computer science', 'Management science', 'Operations research', 'Intensive care medicine', 'Pathology', 'Clinical trial', 'Internal medicine', 'Mathematics', 'Engineering', 'Phases of clinical research', 'Programming language', 'Operating system']","anticancer cytotoxic agents, antitumor, tumor shrinkage, world health organization, tumor response evaluation, clinical research, response rates, unidimensional measurement, tumor lesions, bidimens, response evaluation criteria, solid tumors, response evaluation, nontarget, tumor lesions, response evaluation"
Paper_00646,Embryonic Stem Cell Lines Derived from Human Blastocysts,"['James A. Thomson', 'Joseph Itskovitz‐Eldor', 'Sander S. Shapiro', 'Michelle Waknitz', 'Jennifer J. Swiergiel', 'Vivienne S. Marshall', 'Jeffrey M. Jones']",1998,Science,Journal,,1145-1147,282,5391,10.1126/science.282.5391.1145,"Human blastocyst-derived, pluripotent cell lines are described that have normal karyotypes, express high levels of telomerase activity, and express cell surface markers that characterize primate embryonic stem cells but do not characterize other early lineages. After undifferentiated proliferation in vitro for 4 to 5 months, these cells still maintained the developmental potential to form trophoblast and derivatives of all three embryonic germ layers, including gut epithelium (endoderm); cartilage, bone, smooth muscle, and striated muscle (mesoderm); and neural epithelium, embryonic ganglia, and stratified squamous epithelium (ectoderm). These cell lines should be useful in human developmental biology, drug discovery, and transplantation medicine.","['Biology', 'Embryonic stem cell', 'Endoderm', 'Germ layer', 'Cell biology', 'Ectoderm', 'Stem cell', 'Amniotic epithelial cells', 'Blastocyst', 'Inner cell mass', 'Mesoderm', 'Epithelium', 'Embryoid body', 'Adult stem cell', 'Induced pluripotent stem cell', 'Anatomy', 'Embryogenesis', 'Embryo', 'Genetics', 'Gene']","tel, ##rase, cell surface markers, primate embryonic stem cells, gut epithelium, endoder, smooth muscle, striated muscle, ##soder, neural epithelium, embryonic, stratified squamous epithelium, ectoderm, human developmental biology, drug discovery, transplantation medicine"
Paper_00648,"Social Network Sites: Definition, History, and Scholarship","['danah boyd', 'Nicole B. Ellison']",2007,Journal of Computer-Mediated Communication,Journal,,210-230,13,1,10.1111/j.1083-6101.2007.00393.x,"Social network sites (SNSs) are increasingly attracting the attention of academic and industry researchers intrigued by their affordances and reach. This special theme section of the Journal of Computer-Mediated Communication brings together scholarship on these emergent phenomena. In this introductory article, we describe features of SNSs and propose a comprehensive definition. We then present one perspective on the history of such sites, discussing key changes and developments. After briefly summarizing existing scholarship concerning SNSs, we discuss the articles in this special section and conclude with considerations for future research.","['Scholarship', 'Affordance', 'Theme (computing)', 'Perspective (graphical)', 'Section (typography)', 'Key (lock)', 'Sociology', 'Computer science', 'World Wide Web', 'Political science', 'Human–computer interaction', 'Computer security', 'Law', 'Artificial intelligence', 'Operating system']","social network sites, snss, industry, snss, snss"
Paper_00651,"The Cost of Capital, Corporation Finance and the Theory of Investment",['Merton H. Miller'],1958,['Revista de Administração e Contabilidade da Unisinos'],Journal,,154-155,5,2,10.4013/base.20082.07,"The potential advantages of the market-value approach have long been appreciated; yet analytical results have been meager. What appears to be keeping this line of development from achieving its promise is largely the lack of an adequate theory of the effect of financial structure on market valuations, and of how these effects can be inferred from objective market data. It is with the development of such a theory and of its implications for the cost-of-capital problem that we shall be concerned in this paper. Our procedure will be to develop in Section I the basic theory itself and to give some brief account of its empirical relevance. In Section II we show how the theory can be used to answer the cost-of-capital questions and how it permits us to develop a theory of investment of the firm under conditions of uncertainty. Throughout these sections the approach is essentially a partial-equilibrium one focusing on the firm and industry. Accordingly, the of certain income streams will be treated as constant and given from outside the model, just as in the standard Marshallian analysis of the firm and industry the prices of all inputs and of all other products are taken as given. We have chosen to focus at this level rather than on the economy as a whole because it is at firm and the industry that the interests of the various specialists concerned with the cost-of-capital problem come most closely together. Although the emphasis has thus been placed on partial-equilibrium analysis, the results obtained also provide the essential building block for a general equilibrium model which shows how those prices which are here taken as given, are themselves determined. For reasons of space, however, and because the material is of interest in its own right, the presentation of the general equilibrium model which rounds out the analysis must be deferred to a subsequent paper.","['Economics', 'Investment (military)', 'Capital (architecture)', 'Corporation', 'Cost of capital', 'Microeconomics', 'Value (mathematics)', 'Neoclassical economics', 'Finance', 'Incentive', 'Archaeology', 'Machine learning', 'Politics', 'Political science', 'Computer science', 'Law', 'History']","financial structure, market valuations, marshallian analysis, general, general"
Paper_00652,Can Quantum-Mechanical Description of Physical Reality Be Considered Complete?,"['Albert Einstein', 'Boris Podolsky', 'N. Rosen']",1935,Physical Review,Journal,,777-780,47,10,10.1103/physrev.47.777,"In a complete theory there is an element corresponding to each element of reality. A sufficient condition for the reality of a physical quantity is the possibility of predicting it with certainty, without disturbing the system. In quantum mechanics in the case of two physical quantities described by non-commuting operators, the knowledge of one precludes the knowledge of the other. Then either (1) the description of reality given by the wave function in quantum mechanics is not complete or (2) these two quantities cannot have simultaneous reality. Consideration of the problem of making predictions concerning a system on the basis of measurements made on another system that had previously interacted with it leads to the result that if (1) is false then (2) is also false. One is thus led to conclude that the description of reality as given by a wave function is not complete.","['Certainty', 'Element (criminal law)', 'Function (biology)', 'Basis (linear algebra)', 'Physical system', 'Wave function', 'Quantum', 'Computer science', 'Physics', 'Theoretical physics', 'Quantum mechanics', 'Classical mechanics', 'Mathematics', 'Geometry', 'Evolutionary biology', 'Political science', 'Law', 'Biology']","complete theory, quantum mechanics, physical quantities, non - commuting operators, wave function, quantum mechanics, wave function, [PAD], [PAD] [PAD]"
Paper_00654,The Knowledge-Creating Company,"['Ikujiro Nonaka', 'Hirotaka Takeuchi']",1995,Unknown,Unknown,,,,,10.1093/oso/9780195092691.001.0001,"Abstract How has Japan become a major economic power, a world leader in the automotive and electronics industries? What is the secret of their success? The consensus has been that, though the Japanese are not particularly innovative, they are exceptionally skilful at imitation, at improving products that already exist. But now two leading Japanese business experts, Ikujiro Nonaka and Hiro Takeuchi, turn this conventional wisdom on its head: Japanese firms are successful, they contend, precisely because they are innovative, because they create new knowledge and use it to produce successful products and technologies. Examining case studies drawn from such firms as Honda, Canon, Matsushita, NEC, 3M, GE, and the U.S. Marines, this book reveals how Japanese companies translate tacit to explicit knowledge and use it to produce new processes, products, and services.","['Tacit knowledge', 'Imitation', 'Automotive industry', 'Business', 'Explicit knowledge', 'Competitive advantage', 'Knowledge management', 'Marketing', 'Engineering', 'Computer science', 'Psychology', 'Social psychology', 'Aerospace engineering']","electronics, japanese, honda, canon, nec, ge"
Paper_00655,A Fast Learning Algorithm for Deep Belief Nets,"['Geoffrey E. Hinton', 'Simon Osindero', 'Yee‐Whye Teh']",2006,Neural Computation,Journal,,1527-1554,18,7,10.1162/neco.2006.18.7.1527,"We show how to use “complementary priors” to eliminate the explaining-away effects that make inference difficult in densely connected belief nets that have many hidden layers. Using complementary priors, we derive a fast, greedy algorithm that can learn deep, directed belief networks one layer at a time, provided the top two layers form an undirected associative memory. The fast, greedy algorithm is used to initialize a slower learning procedure that fine-tunes the weights using a contrastive version of the wake-sleep algorithm. After fine-tuning, a network with three hidden layers forms a very good generative model of the joint distribution of handwritten digit images and their labels. This generative model gives better digit classification than the best discriminative learning algorithms. The low-dimensional manifolds on which the digits lie are modeled by long ravines in the free-energy landscape of the top-level associative memory, and it is easy to explore these ravines by using the directed connections to display what the associative memory has in mind.","['Computer science', 'Associative property', 'Prior probability', 'Discriminative model', 'Generative model', 'Content-addressable memory', 'Artificial intelligence', 'Inference', 'Algorithm', 'Generative grammar', 'Pattern recognition (psychology)', 'Deep belief network', 'Artificial neural network', 'Mathematics', 'Bayesian probability', 'Pure mathematics']","complementary priors, densely connected belief nets, hidden layers, directed belief networks, undirected, generative model, joint distribution, handwritten digit images, ##riminative learning algorithms"
Paper_00656,A rapid alkaline extraction procedure for screening recombinant plasmid DNA,"['H.C. Birnboim', 'Janine Doly']",1979,Nucleic Acids Research,Journal,,1513-1523,7,6,10.1093/nar/7.6.1513,"A procedure for extracting plasmid DNA from bacterial cells is described. The method is simple enough to permit the analysis by gel electrophoresis of 100 or more clones per day yet yields plasmid DNA which is pure enough to be digestible by restriction enzymes. The principle of the method is selective alkaline denaturation of high molecular weight chromosomal DNA while covalently closed circular DNA remains double-stranded. Adequate pH control is accomplished without using a pH meter. Upon neutralization, chromosomal DNA renatures to form an insoluble clot, leaving plasmid DNA in the supernatant. Large and small plasmid DNAs have been extracted by this method.","['Plasmid', 'Biology', 'DNA', 'Recombinant DNA', 'Plasmid preparation', 'Restriction enzyme', 'Molecular biology', 'Denaturation (fissile materials)', 'Alkaline lysis', 'Gel electrophoresis', 'DNA extraction', 'Restriction map', 'Electrophoresis', 'Biochemistry', 'Polymerase chain reaction', 'Gene', 'Chemistry', 'DNA vaccination', 'PBR322', 'Nuclear chemistry']","plasmid dna, bacterial cells, gel electrophoresis, plasmi, restriction enzymes, selective alkaline denaturation, ##valently, ph control, ph meter, ##romosomal dna, ##asmi"
Paper_00657,RoBERTa: A Robustly Optimized BERT Pretraining Approach,"['Yinhan Liu', 'Myle Ott', 'Naman Goyal', 'Jingfei Du', 'Mandar Joshi', 'Danqi Chen', 'Omer Levy', 'Mike Lewis', 'Luke Zettlemoyer', 'Veselin Stoyanov']",2019,arXiv (Cornell University),Unknown,,,,,10.48550/arxiv.1907.11692,"Language model pretraining has led to significant performance gains but careful comparison between different approaches is challenging. Training is computationally expensive, often done on private datasets of different sizes, and, as we will show, hyperparameter choices have significant impact on the final results. We present a replication study of BERT pretraining (Devlin et al., 2019) that carefully measures the impact of many key hyperparameters and training data size. We find that BERT was significantly undertrained, and can match or exceed the performance of every model published after it. Our best model achieves state-of-the-art results on GLUE, RACE and SQuAD. These results highlight the importance of previously overlooked design choices, and raise questions about the source of recently reported improvements. We release our models and code.","['Hyperparameter', 'Computer science', 'Replication (statistics)', 'Code (set theory)', 'Key (lock)', 'Language model', 'Artificial intelligence', 'Machine learning', 'Training set', 'Natural language processing', 'Programming language', 'Statistics', 'Mathematics', 'Set (abstract data type)', 'Computer security']","language model pretraining, performance, hyperparameter choices, bert pretraining, glue, race, squad"
Paper_00658,ANFIS: adaptive-network-based fuzzy inference system,['Jyh‐Shing Roger Jang'],1993,IEEE Transactions on Systems Man and Cybernetics,Journal,,665-685,23,3,10.1109/21.256541,"The architecture and learning procedure underlying ANFIS (adaptive-network-based fuzzy inference system) is presented, which is a fuzzy inference system implemented in the framework of adaptive networks. By using a hybrid learning procedure, the proposed ANFIS can construct an input-output mapping based on both human knowledge (in the form of fuzzy if-then rules) and stipulated input-output data pairs. In the simulation, the ANFIS architecture is employed to model nonlinear functions, identify nonlinear components on-line in a control system, and predict a chaotic time series, all yielding remarkable results. Comparisons with artificial neural networks and earlier work on fuzzy modeling are listed and discussed. Other extensions of the proposed ANFIS and promising applications to automatic control and signal processing are also suggested.< <ETX xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">&gt;</ETX>","['Adaptive neuro fuzzy inference system', 'Computer science', 'Artificial intelligence', 'Neuro-fuzzy', 'Artificial neural network', 'Inference system', 'Fuzzy logic', 'Nonlinear system', 'Machine learning', 'Fuzzy control system', 'Fuzzy inference system', 'Data mining', 'Control engineering', 'Engineering', 'Physics', 'Quantum mechanics']","learning procedure, anfis, fuzzy inference, fuzzy inference system, adaptive networks, hybrid learning procedure, anfis, nonlinear functions, chaotic time series, artificial neural networks, fuzzy modeling, automatic control, signal processing"
Paper_00659,Density Estimation for Statistics and Data Analysis,['B.W. Silverman'],2018,Routledge eBooks,Unknown,,,,,10.1201/9781315140919,Introduction. Survey of Existing Methods. The Kernel Method for Univariate Data. The Kernel Method for Multivariate Data. Three Important Methods. Density Estimation in Action.,"['Statistics', 'Estimation', 'Computer science', 'Econometrics', 'Mathematics', 'Engineering', 'Systems engineering']","kernel method, univariate data, kernel method, multivariate data, density estimation, [PAD] [PAD] [PAD] [PAD] [PAD] [PAD], [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD], [PAD], [PAD], [PAD], [PAD] [PAD] [PAD] [PAD], [PAD], [PAD] [PAD] [PAD] [PAD], [PAD] [PAD], [PAD], [PAD] [PAD] [PAD], [PAD] [PAD] [PAD], [PAD], [PAD] [PAD] [PAD], [PAD] [PAD], [PAD], [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD], [PAD] [PAD], [PAD] [PAD] [PAD] [PAD] [PAD], [PAD], [PAD], [PAD] [PAD], [PAD], [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD] [PAD], [PAD], [PAD]"
Paper_00660,Efficient pseudopotentials for plane-wave calculations,"['N. Troullier', 'José Luı́s Martins']",1991,"Physical review. B, Condensed matter",Journal,,1993-2006,43,3,10.1103/physrevb.43.1993,"We present a simple procedure to generate first-principles norm-conserving pseudopotentials, which are designed to be smooth and therefore save computational resources when used with a plane-wave basis. We found that these pseudopotentials are extremely efficient for the cases where the plane-wave expansion has a slow convergence, in particular, for systems containing first-row elements, transition metals, and rare-earth elements. The wide applicability of the pseudopotentials are exemplified with plane-wave calculations for copper, zinc blende, diamond, \ensuremath{\alpha}-quartz, rutile, and cerium.","['Plane wave', 'Pseudopotential', 'Cerium', 'Physics', 'Plane (geometry)', 'Diamond', 'Condensed matter physics', 'Materials science', 'Quantum mechanics', 'Mathematics', 'Geometry', 'Metallurgy', 'Composite material']","##pot, pseudopot, transition metals, pseudopot, copper, zinc blende, diamond, quartz, rutile, cerium, [PAD]"
Paper_00661,Global Prevalence of Diabetes,"['Sarah H. Wild', 'Gojka Roglić', 'Anders Green', 'Richard Sicree', 'Hilary King']",2004,Diabetes Care,Journal,,1047-1053,27,5,10.2337/diacare.27.5.1047,"OBJECTIVE—The goal of this study was to estimate the prevalence of diabetes and the number of people of all ages with diabetes for years 2000 and 2030. RESEARCH DESIGN AND METHODS—Data on diabetes prevalence by age and sex from a limited number of countries were extrapolated to all 191 World Health Organization member states and applied to United Nations’ population estimates for 2000 and 2030. Urban and rural populations were considered separately for developing countries. RESULTS—The prevalence of diabetes for all age-groups worldwide was estimated to be 2.8% in 2000 and 4.4% in 2030. The total number of people with diabetes is projected to rise from 171 million in 2000 to 366 million in 2030. The prevalence of diabetes is higher in men than women, but there are more women with diabetes than men. The urban population in developing countries is projected to double between 2000 and 2030. The most important demographic change to diabetes prevalence across the world appears to be the increase in the proportion of people &amp;gt;65 years of age. CONCLUSIONS—These findings indicate that the “diabetes epidemic” will continue even if levels of obesity remain constant. Given the increasing prevalence of obesity, it is likely that these figures provide an underestimate of future diabetes prevalence.","['Diabetes mellitus', 'Medicine', 'Obesity', 'Population', 'Developing country', 'Demography', 'Environmental health', 'Public health', 'Prevalence', 'Gerontology', 'Developed country', 'Internal medicine', 'Endocrinology', 'Economic growth', 'Nursing', 'Sociology', 'Economics']","rural populations, urban population"
Paper_00663,Robust uncertainty principles: exact signal reconstruction from highly incomplete frequency information,"['Emmanuel J. Candès', 'Justin Romberg', 'Terence Tao']",2006,IEEE Transactions on Information Theory,Journal,,489-509,52,2,10.1109/tit.2005.862083,"This paper considers the model problem of reconstructing an object from incomplete frequency samples. Consider a discrete-time signal f/spl isin/C/sup N/ and a randomly chosen set of frequencies /spl Omega/. Is it possible to reconstruct f from the partial knowledge of its Fourier coefficients on the set /spl Omega/? A typical result of this paper is as follows. Suppose that f is a superposition of |T| spikes f(t)=/spl sigma//sub /spl tau//spl isin/T/f(/spl tau/)/spl delta/(t-/spl tau/) obeying |T|/spl les/C/sub M//spl middot/(log N)/sup -1/ /spl middot/ |/spl Omega/| for some constant C/sub M/>0. We do not know the locations of the spikes nor their amplitudes. Then with probability at least 1-O(N/sup -M/), f can be reconstructed exactly as the solution to the /spl lscr//sub 1/ minimization problem. In short, exact recovery may be obtained by solving a convex optimization problem. We give numerical values for C/sub M/ which depend on the desired probability of success. Our result may be interpreted as a novel kind of nonlinear sampling theorem. In effect, it says that any signal made out of |T| spikes may be recovered by convex programming from almost every set of frequencies of size O(|T|/spl middot/logN). Moreover, this is nearly optimal in the sense that any method succeeding with probability 1-O(N/sup -M/) would in general require a number of frequency samples at least proportional to |T|/spl middot/logN. The methodology extends to a variety of other situations and higher dimensions. For example, we show how one can reconstruct a piecewise constant (one- or two-dimensional) object from incomplete frequency samples - provided that the number of jumps (discontinuities) obeys the condition above - by minimizing other convex functionals such as the total variation of f.","['Omega', 'Combinatorics', 'Mathematics', 'Signal reconstruction', 'Superposition principle', 'Convex optimization', 'Discrete mathematics', 'Regular polygon', 'Algorithm', 'Signal processing', 'Mathematical analysis', 'Physics', 'Computer science', 'Quantum mechanics', 'Geometry', 'Telecommunications', 'Radar']","incomplete frequency samples, fourier coefficients, convex optimization problem, nonlinear sampling theorem, convex programming, frequency samples, piecewise constant, incomplete frequency samples, convex functionals"
Paper_00664,Rayyan—a web and mobile app for systematic reviews,"['Mourad Ouzzani', 'Hossam M. Hammady', 'Zbys Fedorowicz', 'Ahmed K. Elmagarmid']",2016,Systematic Reviews,Journal,,,5,1,10.1186/s13643-016-0384-4,"Synthesis of multiple randomized controlled trials (RCTs) in a systematic review can summarize the effects of individual outcomes and provide numerical answers about the effectiveness of interventions. Filtering of searches is time consuming, and no single method fulfills the principal requirements of speed with accuracy. Automation of systematic reviews is driven by a necessity to expedite the availability of current best evidence for policy and clinical decision-making. We developed Rayyan ( http://rayyan.qcri.org ), a free web and mobile app, that helps expedite the initial screening of abstracts and titles using a process of semi-automation while incorporating a high level of usability. For the beta testing phase, we used two published Cochrane reviews in which included studies had been selected manually. Their searches, with 1030 records and 273 records, were uploaded to Rayyan. Different features of Rayyan were tested using these two reviews. We also conducted a survey of Rayyan's users and collected feedback through a built-in feature. Pilot testing of Rayyan focused on usability, accuracy against manual methods, and the added value of the prediction feature. The ""taster"" review (273 records) allowed a quick overview of Rayyan for early comments on usability. The second review (1030 records) required several iterations to identify the previously identified 11 trials. The ""suggestions"" and ""hints,"" based on the ""prediction model,"" appeared as testing progressed beyond five included studies. Post rollout user experiences and a reflexive response by the developers enabled real-time modifications and improvements. The survey respondents reported 40% average time savings when using Rayyan compared to others tools, with 34% of the respondents reporting more than 50% time savings. In addition, around 75% of the respondents mentioned that screening and labeling studies as well as collaborating on reviews to be the two most important features of Rayyan. As of November 2016, Rayyan users exceed 2000 from over 60 countries conducting hundreds of reviews totaling more than 1.6M citations. Feedback from users, obtained mostly through the app web site and a recent survey, has highlighted the ease in exploration of searches, the time saved, and simplicity in sharing and comparing include-exclude decisions. The strongest features of the app, identified and reported in user feedback, were its ability to help in screening and collaboration as well as the time savings it affords to users. Rayyan is responsive and intuitive in use with significant potential to lighten the load of reviewers.","['Usability', 'Medicine', 'Systematic review', 'Automation', 'Computer science', 'Upload', 'MEDLINE', 'World Wide Web', 'Human–computer interaction', 'Mechanical engineering', 'Political science', 'Law', 'Engineering']","multiple randomized controlled trials, systematic review, systematic reviews, rayyan, cochrane reviews, ##yan, rayyan, ##yan, ##yan, prediction, ##yan, prediction, ##ive, ##yan, ##yan, rayyan"
Paper_00665,RAxML-VI-HPC: maximum likelihood-based phylogenetic analyses with thousands of taxa and mixed models,['Alexandros Stamatakis'],2006,Bioinformatics,Journal,,2688-2690,22,21,10.1093/bioinformatics/btl446,"Abstract Summary: RAxML-VI-HPC (randomized axelerated maximum likelihood for high performance computing) is a sequential and parallel program for inference of large phylogenies with maximum likelihood (ML). Low-level technical optimizations, a modification of the search algorithm, and the use of the GTR+CAT approximation as replacement for GTR+Γ yield a program that is between 2.7 and 52 times faster than the previous version of RAxML. A large-scale performance comparison with GARLI, PHYML, IQPNNI and MrBayes on real data containing 1000 up to 6722 taxa shows that RAxML requires at least 5.6 times less main memory and yields better trees in similar times than the best competing program (GARLI) on datasets up to 2500 taxa. On datasets ≥4000 taxa it also runs 2–3 times faster than GARLI. RAxML has been parallelized with MPI to conduct parallel multiple bootstraps and inferences on distinct starting trees. The program has been used to compute ML trees on two of the largest alignments to date containing 25 057 (1463 bp) and 2182 (51 089 bp) taxa, respectively. Availability: Contact: Alexandros.Stamatakis@epfl.ch Supplementary information: Supplementary data are available at Bioinformatics online.","['Taxon', 'Inference', 'Computer science', 'Phylogenetic tree', 'Parallel computing', 'Maximum likelihood', 'Biology', 'Mathematics', 'Statistics', 'Artificial intelligence', 'Ecology', 'Biochemistry', 'Gene']","randomized axelerated maximum likelihood, high performance computing, maximum likelihood, search algorithm, ##ml, ##i, phyml, iq, ##es, ##xml, raxml, ##i, parallel multiple bootstraps, bioinformatics"
Paper_00666,A new mixing of Hartree–Fock and local density-functional theories,['Axel D. Becke'],1993,The Journal of Chemical Physics,Journal,,1372-1377,98,2,10.1063/1.464304,Views Icon Views Article contents Figures & tables Video Audio Supplementary Data Peer Review Share Icon Share Twitter Facebook Reddit LinkedIn Tools Icon Tools Reprints and Permissions Cite Icon Cite Search Site Citation Axel D. Becke; A new mixing of Hartree–Fock and local density‐functional theories. J. Chem. Phys. 15 January 1993; 98 (2): 1372–1377. https://doi.org/10.1063/1.464304 Download citation file: Ris (Zotero) Reference Manager EasyBib Bookends Mendeley Papers EndNote RefWorks BibTex toolbar search Search Dropdown Menu toolbar search search input Search input auto suggest filter your search All ContentAIP Publishing PortfolioThe Journal of Chemical Physics Search Advanced Search |Citation Search,"['Simplicity', 'Density functional theory', 'Hartree–Fock method', 'Mixing (physics)', 'Coupling (piping)', 'Ionization', 'Proton', 'Computational chemistry', 'Statistical physics', 'Chemistry', 'Physics', 'Quantum mechanics', 'Materials science', 'Ion', 'Metallurgy']","reddit linked, hartree, ##ock, local density, functional theories, ##s, zotero, reference manager easybib, mendeley papers, bibtex, chemical physics, citation search"
Paper_00668,"PyTorch: An Imperative Style, High-Performance Deep Learning Library","['Adam Paszke', 'Sam Gross', 'Francisco Massa', 'Adam Lerer', 'James T. Bradbury', 'Gregory Chanan', 'Trevor Killeen', 'Zeming Lin', 'Natalia Gimelshein', 'Luca Antiga', 'Alban Desmaison', 'Andreas Köpf', 'Edward Yang', 'Zach DeVito', 'Martin Raison', 'Alykhan Tejani', 'Sasank Chilamkurthy', 'Benoit Steiner', 'Lu Fang', 'Junjie Bai', 'Soumith Chintala']",2019,arXiv (Cornell University),Unknown,,,,,10.48550/arxiv.1912.01703,"Deep learning frameworks have often focused on either usability or speed, but not both. PyTorch is a machine learning library that shows that these two goals are in fact compatible: it provides an imperative and Pythonic programming style that supports code as a model, makes debugging easy and is consistent with other popular scientific computing libraries, while remaining efficient and supporting hardware accelerators such as GPUs. In this paper, we detail the principles that drove the implementation of PyTorch and how they are reflected in its architecture. We emphasize that every aspect of PyTorch is a regular Python program under the full control of its user. We also explain how the careful and pragmatic implementation of the key components of its runtime enables them to work together to achieve compelling performance. We demonstrate the efficiency of individual subsystems, as well as the overall speed of PyTorch on several common benchmarks.","['Computer science', 'Debugging', 'Python (programming language)', 'Programming style', 'Deep learning', 'Usability', 'Key (lock)', 'Architecture', 'Artificial intelligence', 'Programming language', 'Computer architecture', 'Human–computer interaction', 'Operating system', 'Art', 'Visual arts']","deep learning frameworks, pytorch, machine learning library, python, code, debugging, scientific computing libraries, hardware, gpus, pytorch, pytorch, python, p, ##orch"
Paper_00670,"A Simple, Positive Semi-Definite, Heteroskedasticity and Autocorrelation Consistent Covariance Matrix","['Whitney K. Newey', 'Kenneth D. West']",1987,Econometrica,Journal,,703-703,55,3,10.2307/1913610,This paper describes a simple method of calculating a heteroskedasticity and autocorrelation consistent covariance matrix that is positive semi-definite by construction. It also establishes consistency of the estimated covariance matrix under fairly general conditions.,"['Heteroscedasticity', 'Mathematics', 'Positive-definite matrix', 'Simple (philosophy)', 'Covariance matrix', 'Autocorrelation', 'Applied mathematics', 'Matrix (chemical analysis)', 'Econometrics', 'Covariance', 'Statistics', 'Physics', 'Eigenvalues and eigenvectors', 'Chemistry', 'Philosophy', 'Epistemology', 'Chromatography', 'Quantum mechanics']","heteroskedasticity, autocorrelation consistent covariance matrix, estimated covariance matrix, [PAD] [PAD], [PAD], [PAD] [PAD] [PAD] [PAD] [PAD], [PAD], [PAD] [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"
Paper_00671,Principles and Procedures of Statistics: A Biometrical Approach,"['R. G. D. Steel', 'J. H. Torrie']",1980,['Journal of the American Statistical Association'],Unknown,,753,76,375,10.2307/2287561,Observations probability sampling from a normal distribution comparisons involving two sample means principles of experimental design analysis of variance I - the one-way classification mutiple comparisons analysis of variance II - multiway classification linear regression linear correlation matrix notation linear regression in matrix notation multiple and partial regression and correlation analysis of variance III - factorial experiments analysis of variance analysis of covariance IV analysis of covariance analysis of variance V - unequal subclass numbers some uses of chi-square enumeration data I - one-way classifications enumeration data II - contingency tables categorical models some discrete distributions nonparametric statistics sampling finite populations.,"['Statistics', 'Mathematics', 'Categorical variable', 'Contingency table', 'Nonparametric statistics', 'Covariance matrix', 'Analysis of covariance', 'Regression analysis', 'Sampling (signal processing)', 'Notation', 'Linear regression', 'Enumeration', 'Computer science', 'Combinatorics', 'Arithmetic', 'Filter (signal processing)', 'Computer vision']","observations probability sampling, normal distribution, experimental design analysis, variance, mutiple comparisons, variance, multiway classification linear regression linear correlation matrix notation linear regression, matrix notation, correlation analysis, variance, factorial experiments, variance, covariance, covariance analysis, variance, une, enumeration data, contingency tables categorical models, discrete distributions non, finite populations, [PAD] [PAD] [PAD], [PAD], [PAD], [PAD], [PAD], [PAD] [PAD], [PAD], [PAD] [PAD] [PAD], [PAD] [PAD] [PAD], [PAD] [PAD], [PAD] [PAD], [PAD]"
Paper_00673,The PRISMA statement for reporting systematic reviews and meta-analyses of studies that evaluate healthcare interventions: explanation and elaboration,"['A. Liberati', 'Doug Altman', 'Jennifer Tetzlaff', 'Cynthia D. Mulrow', 'Peter C Gøtzsche', 'John P. A. Ioannidis', 'Mike Clarke', 'P.J. Devereaux', 'Jos Kleijnen', 'David Moher']",2009,BMJ,Journal,,b2700-b2700,339,jul21 1,10.1136/bmj.b2700,"Systematic reviews and meta-analyses are essential to summarise evidence relating to efficacy and safety of healthcare interventions accurately and reliably. The clarity and transparency of these reports, however, are not optimal. Poor reporting of systematic reviews diminishes their value to clinicians, policy makers, and other users. Since the development of the QUOROM (quality of reporting of meta-analysis) statement—a reporting guideline published in 1999—there have been several conceptual, methodological, and practical advances regarding the conduct and reporting of systematic reviews and meta-analyses. Also, reviews of published systematic reviews have found that key information about these studies is often poorly reported. Realising these issues, an international group that included experienced authors and methodologists developed PRISMA (preferred reporting items for systematic reviews and meta-analyses) as an evolution of the original QUOROM guideline for systematic reviews and meta-analyses of evaluations of health care interventions. The PRISMA statement consists of a 27-item checklist and a four-phase flow diagram. The checklist includes items deemed essential for transparent reporting of a systematic review. In this explanation and elaboration document, we explain the meaning and rationale for each checklist item. For each item, we include an example of good reporting and, where possible, references to relevant empirical studies and methodological literature. The PRISMA statement, this document, and the associated website (www.prisma-statement.org/) should be helpful resources to improve reporting of systematic reviews and meta-analyses.","['Systematic review', 'Checklist', 'Psychological intervention', 'Guideline', 'Health care', 'MEDLINE', 'CLARITY', 'Psychology', 'Medicine', 'Management science', 'Nursing', 'Political science', 'Pathology', 'Law', 'Economics', 'Biochemistry', 'Chemistry', 'Cognitive psychology']","systematic reviews, healthcare interventions, systematic reviews, quorom, prisma, quo, health care interventions, prism, prism"
Paper_00675,Operating Characteristics of a Rank Correlation Test for Publication Bias,"['Colin B. Begg', 'Madhuchhanda Mazumdar']",1994,Biometrics,Journal,,1088-1088,50,4,10.2307/2533446,"An adjusted rank correlation test is proposed as a technique for identifying publication bias in a meta-analysis, and its operating characteristics are evaluated via simulations. The test statistic is a direct statistical analogue of the popular ""funnel-graph."" The number of component studies in the meta-analysis, the nature of the selection mechanism, the range of variances of the effect size estimates, and the true underlying effect size are all observed to be influential in determining the power of the test. The test is fairly powerful for large meta-analyses with 75 component studies, but has only moderate power for meta-analyses with 25 component studies. However, in many of the configurations in which there is low power, there is also relatively little bias in the summary effect size estimate. Nonetheless, the test must be interpreted with caution in small meta-analyses. In particular, bias cannot be ruled out if the test is not significant. The proposed technique has potential utility as an exploratory tool for meta-analysts, as a formal procedure to complement the funnel-graph.","['Publication bias', 'Funnel plot', 'Statistics', 'Sample size determination', 'Meta-analysis', 'Statistic', 'Complement (music)', 'Statistical power', 'Type I and type II errors', 'Test statistic', 'Econometrics', 'Computer science', 'Statistical hypothesis testing', 'Rank (graph theory)', 'Mathematics', 'Confidence interval', 'Medicine', 'Biochemistry', 'Chemistry', 'Combinatorics', 'Complementation', 'Internal medicine', 'Gene', 'Phenotype']","adjusted rank correlation test, publication bias, test stat, effect, underlying, summary effect size estimate"
Paper_00676,Normalized cuts and image segmentation,"['Jianbo Shi', 'Jitendra Malik']",2000,IEEE Transactions on Pattern Analysis and Machine Intelligence,Journal,,888-905,22,8,10.1109/34.868688,"We propose a novel approach for solving the perceptual grouping problem in vision. Rather than focusing on local features and their consistencies in the image data, our approach aims at extracting the global impression of an image. We treat image segmentation as a graph partitioning problem and propose a novel global criterion, the normalized cut, for segmenting the graph. The normalized cut criterion measures both the total dissimilarity between the different groups as well as the total similarity within the groups. We show that an efficient computational technique based on a generalized eigenvalue problem can be used to optimize this criterion. We applied this approach to segmenting static images, as well as motion sequences, and found the results to be very encouraging.","['Artificial intelligence', 'Image segmentation', 'Segmentation', 'Pattern recognition (psychology)', 'Segmentation-based object categorization', 'Market segmentation', 'Scale-space segmentation', 'Computer vision', 'Range segmentation', 'Graph', 'Computer science', 'Image (mathematics)', 'Similarity (geometry)', 'Mathematics', 'Image texture', 'Theoretical computer science', 'Marketing', 'Business']","perceptual grouping problem, vision, local features, image segmentation, graph partitioning problem, normalized cut, normalized cut criterion, ##milarity, computational technique, generalized eigenvalue problem, static images, motion sequences, [PAD] [PAD], [PAD]"
Paper_00677,Neural Machine Translation by Jointly Learning to Align and Translate,"['Dzmitry Bahdanau', 'Kyunghyun Cho', 'Yoshua Bengio']",2015,['Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing'],Unknown,,,,,10.18653/v1/2021.emnlp-main.1,"Abstract: Neural machine translation is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neural machine translation often belong to a family of encoder-decoders and consists of an encoder that encodes a source sentence into a fixed-length vector from which a decoder generates a translation. In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based system on the task of English-to-French translation. Furthermore, qualitative analysis reveals that the (soft-)alignments found by the model agree well with our intuition.","['Machine translation', 'Computer science', 'Transfer-based machine translation', 'Example-based machine translation', 'Artificial intelligence', 'Sentence', 'Bottleneck', 'Artificial neural network', 'Translation (biology)', 'Natural language processing', 'Encoder', 'Phrase', 'Word (group theory)', 'Rule-based machine translation', 'Speech recognition', 'Machine learning', 'Biochemistry', 'Chemistry', 'Linguistics', 'Philosophy', 'Messenger RNA', 'Gene', 'Embedded system', 'Operating system']","machine translation, statistical machine translation, neural machine translation, neural network, neural machine translation, translation, qualitative"
Paper_00678,Psychophysical bases of perceived exertion,['Gunnar Borg'],1982,Medicine & Science in Sports & Exercise,Journal,,377???381-377???381,14,5,10.1249/00005768-198205000-00012,"There is a great demand for perceptual effort ratings in order to better understand man at work. Such ratings are important complements to behavioral and physiological measurements of physical performance and work capacity. This is true for both theoretical analysis and application in medicine, human factors, and sports. Perceptual estimates, obtained by psychophysical ratio-scaling methods, are valid when describing general perceptual variation, but category methods are more useful in several applied situations when differences between individuals are described. A presentation is made of ratio-scaling methods, category methods, especially the Borg Scale for ratings of perceived exertion, and a new method that combines the category method with ratio properties. Some of the advantages and disadvantages of the different methods are discussed in both theoretical-psychophysical and psychophysiological frames of reference.","['Perceived exertion', 'Perception', 'Exertion', 'Psychology', 'Cognitive psychology', 'Work (physics)', 'Scale (ratio)', 'Presentation (obstetrics)', 'Multidimensional scaling', 'Scaling', 'Variation (astronomy)', 'Computer science', 'Statistics', 'Mathematics', 'Physical therapy', 'Medicine', 'Engineering', 'Mechanical engineering', 'Heart rate', 'Physics', 'Geometry', 'Quantum mechanics', 'Neuroscience', 'Astrophysics', 'Blood pressure', 'Radiology']","perceptual effort ratings, physical performance, work capacity, medicine, human factors, sports, perceptual estimates, general perceptual variation, category methods, category methods, borg scale, perceived, category method, ratio properties, psycho, ##logical, [PAD], [PAD], [PAD], [PAD] [PAD]"
Paper_00680,Discipline and Punish: The Birth of the Prison.,"['Sharon Zukin', 'Michel Foucault', 'Alan Sheridan']",1996,Contemporary Sociology A Journal of Reviews,Journal,,463-463,25,4,10.2307/2077073,"In the Middle Ages there were gaols and dungeons, but punishment was for the most part a spectacle. The economic changes and growing popular dissent of the 18th century made necessary a more systematic control over the individual members of society, and this in effect meant a change from punishment, which chastised the body, to reform, which touched the soul. Foucault shows the development of the Western system of prisons, police organizations, administrative and legal hierarchies for social control - and the growth of disciplinary society as a whole. He also reveals that between school, factories, barracks and hospitals all share a common organization, in which it is possible to control the use of an individual's time and space hour by hour.","['Spectacle', 'Dissent', 'Prison', 'Punishment (psychology)', 'Discipline', 'Soul', 'Criminology', 'Social control', 'Control (management)', 'Sociology', 'Law', 'Political science', 'Crime control', 'Psychology', 'Criminal justice', 'Social psychology', 'Management', 'Economics', 'Philosophy', 'Theology', 'Politics']","gaols, dungeons, police organizations, legal hierarchies, social control, disciplinary society, hospitals"
Paper_00684,A discrete numerical model for granular assemblies,"['Peter Cundall', 'Otto D. L. Strack']",1979,Géotechnique,Journal,,47-65,29,1,10.1680/geot.1979.29.1.47,The distinct element method is a numerical model capable of describing the mechanical behaviour of assemblies of discs and spheres. The method is based on the use of an explicit numerical scheme in which the interaction of the particles is monitored contact by contact and the motion of the particles modelled particle by particle. The main features of the distinct element method are described. The method is validated by comparing force vector plots obtained from the computer program BALL with the corresponding plots obtained from a photoelastic analysis. The photoelastic analysis used for the comparison is the one applied to an assembly of discs by De Josselin de Jong and Verruijt (1969). The force vector diagrams obtained numerically closely resemble those obtained photoelastically. It is concluded from this comparison that the distinct element method and the program BALL are valid tools for research into the behaviour of granular assemblies. La méthode des éléments distincts est un modèle numérique capable de décrire le comportement mécanique de l'assemblage de disques et de sphères. La méthode est basée sur l'utilisation d'un système numérique explicite dans lequel l'interaction des particules est contrôlée contact par contact et le mouvement des particules simulé particule par particule. Les caracteristiques principales de la méthode des eléments distints sont décrites. La méthode est validée en comparant les tracés de vecteur de force obtenus par le programme sur ordicateur BALL avec les tracés correspondants obtanus a l'aide d'une analyse photo-élastique. L'analyse photo-élastique utilisée pour la comparaison est celle appliquée sur un assemblage de disques par De Josselin de Jong et Verruijt (1969). Les diagrammes de vecteur de force obtenus numériquement sont très voisins de ceux obtenus photo-élastiquement. Cette comparaison permet de conclure que la methode des éléments distincts et le programme BALL sont des instruments valables pour la recherche du comportement des assemblages granulaires.,"['Discrete element method', 'Ball (mathematics)', 'Physics', 'Granular material', 'Contact force', 'Geometry', 'Mechanics', 'Classical mechanics', 'Mathematics', 'Quantum mechanics']","distinct element method, numerical model, mechanical behaviour, explicit numerical scheme, distinct, force vector plots, photoelastic analysis, photoelastic analysis, force vector diagrams, distinct, granular assemblies"
Paper_00686,Risks and Benefits of Estrogen Plus Progestin in Healthy Postmenopausal Women: Principal Results From the Women's Health Initiative Randomized Controlled Trial,"['Jacques E. Rossouw', 'Garnet L. Anderson', 'Ross L. Prentice', 'Andrea Z. LaCroix', 'Charles Kooperberg', 'Marcia L. Stefanick', 'Rebecca D. Jackson', 'Shirley A.A. Beresford', 'Barbara V. Howard', 'Karen Johnson', 'Jane Morley Kotchen', 'Judith K. Ockene']",2002,JAMA,Journal,,321-333,288,3,10.1001/jama.288.3.321,"ContextDespite decades of accumulated observational evidence, the balance of risks and benefits for hormone use in healthy postmenopausal women remains uncertain.ObjectiveTo assess the major health benefits and risks of the most commonly used combined hormone preparation in the United States.DesignEstrogen plus progestin component of the Women's Health Initiative, a randomized controlled primary prevention trial (planned duration, 8.5 years) in which 16608 postmenopausal women aged 50-79 years with an intact uterus at baseline were recruited by 40 US clinical centers in 1993-1998.InterventionsParticipants received conjugated equine estrogens, 0.625 mg/d, plus medroxyprogesterone acetate, 2.5 mg/d, in 1 tablet (n = 8506) or placebo (n = 8102).Main Outcomes MeasuresThe primary outcome was coronary heart disease (CHD) (nonfatal myocardial infarction and CHD death), with invasive breast cancer as the primary adverse outcome. A global index summarizing the balance of risks and benefits included the 2 primary outcomes plus stroke, pulmonary embolism (PE), endometrial cancer, colorectal cancer, hip fracture, and death due to other causes.ResultsOn May 31, 2002, after a mean of 5.2 years of follow-up, the data and safety monitoring board recommended stopping the trial of estrogen plus progestin vs placebo because the test statistic for invasive breast cancer exceeded the stopping boundary for this adverse effect and the global index statistic supported risks exceeding benefits. This report includes data on the major clinical outcomes through April 30, 2002. Estimated hazard ratios (HRs) (nominal 95% confidence intervals [CIs]) were as follows: CHD, 1.29 (1.02-1.63) with 286 cases; breast cancer, 1.26 (1.00-1.59) with 290 cases; stroke, 1.41 (1.07-1.85) with 212 cases; PE, 2.13 (1.39-3.25) with 101 cases; colorectal cancer, 0.63 (0.43-0.92) with 112 cases; endometrial cancer, 0.83 (0.47-1.47) with 47 cases; hip fracture, 0.66 (0.45-0.98) with 106 cases; and death due to other causes, 0.92 (0.74-1.14) with 331 cases. Corresponding HRs (nominal 95% CIs) for composite outcomes were 1.22 (1.09-1.36) for total cardiovascular disease (arterial and venous disease), 1.03 (0.90-1.17) for total cancer, 0.76 (0.69-0.85) for combined fractures, 0.98 (0.82-1.18) for total mortality, and 1.15 (1.03-1.28) for the global index. Absolute excess risks per 10 000 person-years attributable to estrogen plus progestin were 7 more CHD events, 8 more strokes, 8 more PEs, and 8 more invasive breast cancers, while absolute risk reductions per 10 000 person-years were 6 fewer colorectal cancers and 5 fewer hip fractures. The absolute excess risk of events included in the global index was 19 per 10 000 person-years.ConclusionsOverall health risks exceeded benefits from use of combined estrogen plus progestin for an average 5.2-year follow-up among healthy postmenopausal US women. All-cause mortality was not affected during the trial. The risk-benefit profile found in this trial is not consistent with the requirements for a viable intervention for primary prevention of chronic diseases, and the results indicate that this regimen should not be initiated or continued for primary prevention of CHD.","['Medicine', ""Women's Health Initiative"", 'Medroxyprogesterone acetate', 'Hazard ratio', 'Randomized controlled trial', 'Placebo', 'Hormone therapy', 'Gynecology', 'Endometrial cancer', 'Adverse effect', 'Stroke (engine)', 'Hormone replacement therapy (female-to-male)', 'Internal medicine', 'Breast cancer', 'Estrogen', 'Observational study', 'Confidence interval', 'Cancer', 'Mechanical engineering', 'Alternative medicine', 'Pathology', 'Engineering', 'Testosterone (patch)']","##men, combined hormone preparation, coronary heart disease, nonfatal myocardial infarction, chd death, invasive breast cancer, global index, pulmonary embolism, end, ##trial cancer, colorectal cancer, hip fracture, invasive breast cancer, breast cancer, colorectal cancer, endometrial cancer, hip fracture"
Paper_00687,Arlequin suite ver 3.5: a new series of programs to perform population genetics analyses under Linux and Windows,"['Laurent Excoffier', 'Heidi E. L. Lischer']",2010,Molecular Ecology Resources,Journal,,564-567,10,3,10.1111/j.1755-0998.2010.02847.x,"We present here a new version of the Arlequin program available under three different forms: a Windows graphical version (Winarl35), a console version of Arlequin (arlecore), and a specific console version to compute summary statistics (arlsumstat). The command-line versions run under both Linux and Windows. The main innovations of the new version include enhanced outputs in XML format, the possibility to embed graphics displaying computation results directly into output files, and the implementation of a new method to detect loci under selection from genome scans. Command-line versions are designed to handle large series of files, and arlsumstat can be used to generate summary statistics from simulated data sets within an Approximate Bayesian Computation framework.","['Suite', 'Computer science', 'XML', 'Graphics', 'Series (stratigraphy)', 'Line (geometry)', 'Population', 'Computation', 'Biology', 'Operating system', 'Programming language', 'Mathematics', 'Demography', 'Archaeology', 'Sociology', 'History', 'Paleontology', 'Geometry']","arlequin, windows, winarl, console, arlequin, arlecore, compute summary statistics, arlsumstat, xml, loci, genome scans, arlsumstat, summary statistics, approximate bayesian computation framework, [PAD], [PAD], [PAD], [PAD], [PAD], [PAD] [PAD], [PAD], [PAD] [PAD], [PAD] [PAD], [PAD], [PAD], [PAD] [PAD]"
Paper_00689,"Genetic algorithms in search, optimization, and machine learning",['David E. Goldberg'],1988,['Choice Reviews Online'],Unknown,,27-0936-27-0936,27,02,10.5860/choice.27-0936,"From the Publisher:
This book brings together - in an informal and tutorial fashion - the computer techniques, mathematical tools, and research results that will enable both students and practitioners to apply genetic algorithms to problems in many fields. 

Major concepts are illustrated with running examples, and major algorithms are illustrated by Pascal computer programs. No prior knowledge of GAs or genetics is assumed, and only a minimum of computer programming and mathematics background is required.","['Pascal (unit)', 'Computer science', 'Genetic programming', 'Genetic algorithm', 'Machine learning', 'Artificial intelligence', 'Quality control and genetic algorithms', 'Theoretical computer science', 'Algorithm', 'Programming language', 'Meta-optimization']","computer techniques, mathematical tools, genetic algorithms, pascal computer programs"
Paper_00690,Primer3 on the WWW for General Users and for Biologist Programmers,"['Steve Rozen', 'Helen Skaletsky']",2003,Humana Press eBooks,Unknown,,365-386,,,10.1385/1-59259-192-2:365,"Designing PCR and sequencing primers are essential activities for molecular biologists around the world. This chapter assumes acquaintance with the principles and practice of PCR, as outlined in, for example, refs. 1–4.","['Biologist', 'Computer science', 'World Wide Web', 'Computational biology', 'Software engineering', 'Data science', 'Biology', 'Genetics']","##r, sequencing primers, molecular biologist, ##r"
Paper_00691,Bergey's Manual of Systematic Bacteriology,['in chief George M. Garrity'],1990,Annals of Internal Medicine,Journal,,391-391,112,5,10.7326/0003-4819-112-5-391_3,"BCL3 and Sheehy cite Bergey's manual of determinative bacteriology of which systematic bacteriology, first edition, is an expansion. With v.4 the set is complete. The volumes cover, roughly, v.1, the Gram-negatives except those in v.3 ($87.95); v.2, the Gram-positives less actinomycetes ($71.95); v.","['Bacteriology', 'Medicine', 'Cover (algebra)', 'Biology', 'Bacteria', 'Genetics', 'Mechanical engineering', 'Engineering']","determinative bacteriology, systematic bacteriology, ##my, [PAD]"
Paper_00692,DnaSP v5: a software for comprehensive analysis of DNA polymorphism data,"['Pablo Librado', 'Julio Rozas']",2009,Bioinformatics,Journal,,1451-1452,25,11,10.1093/bioinformatics/btp187,"DnaSP is a software package for a comprehensive analysis of DNA polymorphism data. Version 5 implements a number of new features and analytical methods allowing extensive DNA polymorphism analyses on large datasets. Among other features, the newly implemented methods allow for: (i) analyses on multiple data files; (ii) haplotype phasing; (iii) analyses on insertion/deletion polymorphism data; (iv) visualizing sliding window results integrated with available genome annotations in the UCSC browser.Freely available to academic users from: (http://www.ub.edu/dnasp).","['Software', 'Computer science', 'R package', 'Haplotype', 'Computational biology', 'Polymorphism (computer science)', 'Sliding window protocol', 'Genome browser', 'Genome', 'Data mining', 'Biology', 'Genetics', 'Genomics', 'Window (computing)', 'World Wide Web', 'Operating system', 'Genotype', 'Gene', 'Programming language']","dnasp, dna polymorphism data, analytical, dna polymorphism, haplotype phasing, sliding window results, ucsc, dna"
Paper_00693,"Physisorption of gases, with special reference to the evaluation of surface area and pore size distribution (IUPAC Technical Report)","['Matthias Thommes', 'Katsumi Kaneko', 'Alexander V. Neimark', 'James P. Olivier', 'F. Rodrı́guez-Reinoso', 'J. Rouquérol', 'K. S. W. Sing']",2015,Pure and Applied Chemistry,Journal,,1051-1069,87,9-10,10.1515/pac-2014-1117,"Abstract Gas adsorption is an important tool for the characterisation of porous solids and fine powders. Major advances in recent years have made it necessary to update the 1985 IUPAC manual on Reporting Physisorption Data for Gas/Solid Systems. The aims of the present document are to clarify and standardise the presentation, nomenclature and methodology associated with the application of physisorption for surface area assessment and pore size analysis and to draw attention to remaining problems in the interpretation of physisorption data.","['Physisorption', 'Chemical nomenclature', 'Chemistry', 'Adsorption', 'Surface (topology)', 'Process engineering', 'Nanotechnology', 'Physical chemistry', 'Organic chemistry', 'Materials science', 'Geometry', 'Mathematics', 'Engineering']","abstract gas adsorption, porous solids, fine powders, physisor, physis, ##ption, surface area assessment, pore size analysis, ph, [PAD], [PAD], [PAD], [PAD] [PAD] [PAD], [PAD], [PAD], [PAD], [PAD], [PAD] [PAD], [PAD], [PAD], [PAD], [PAD] [PAD] [PAD] [PAD], [PAD] [PAD], [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"
Paper_00697,Qualitative Research for Education: An Introduction to Theory and Methods,"['Robert Bogdan', 'Sari Knopp Biklen']",1997,['Journal of Medical Education and Development'],Unknown,,,,,10.18502/jmed.v16i4.8580,1. Foundations of Qualitative Research in Education: An Introduction. Characteristics of Qualitative Research. Traditions of Qualitative Research. Theoretical Underpinnings. Ten Common Questions About Qualitative Research. Ethics. What Is to Come. 2. Research Design. Choosing a Study. Case Studies. Multi-Site Studies. Additional Issues Related to Design. Concluding Remarks. 3. Fieldwork. Gaining Access. First Days in the Field. The Participant/Observer Continuum. Doing Fieldwork in Another Culture. Researcher Characteristics and Special Problems with Rapport. Be Discreet. Research in Politically Charged and Conflict-Ridden Settings. Feelings. How Long Should an Observation Session Be? Interviewing. Visual Recording and Fieldwork. Triangulation. Leaving the Field. 4. Qualitative Data. Some Friendly Advice. Fieldnotes. The Process of Writing Fieldnotes. Transcripts from Taped Interviews. Documents. Photography. Official Statistics and Other Quantitative Data. Concluding Remarks. 5. Data Analysis. Analysis in the Field. Analysis After Data Collection. The Mechanics of Working with Data. Concluding Remarks. 6. Writing It Up. Writing Choices. More Writing Tips. Criteria for Evaluating Writing. Texts. A Final Point About Getting Started. 7. Applied Qualitative Research for Education. Evaluation and Policy Research. Action Research. Practitioner Uses of Qualitative Research. Appendix A. Examples of Observational Questions for Educational Settings. Appendix B. Examples of Fieldnotes. Glossary. References. Index.,"['Fieldnotes', 'Qualitative research', 'Glossary', 'Reflexivity', 'Interview', 'Participant observation', 'Exploratory research', 'Field research', 'Sociology', 'Educational research', 'Qualitative property', 'Psychology', 'Social science', 'Computer science', 'Ethnography', 'Linguistics', 'Philosophy', 'Machine learning', 'Anthropology']","qualitative research, education, qualitative research, qualitative research, qualitative research, research design, visual recording, field, triang, quali, taped interviews, data analysis, education, policy research, action research"
Paper_00698,Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization,"['Ramprasaath R. Selvaraju', 'Michael Cogswell', 'Abhishek Das', 'Ramakrishna Vedantam', 'Devi Parikh', 'Dhruv Batra']",2017,Unknown,Unknown,,618-626,,,10.1109/iccv.2017.74,"We propose a technique for producing `visual explanations' for decisions from a large class of Convolutional Neural Network (CNN)-based models, making them more transparent. Our approach - Gradient-weighted Class Activation Mapping (Grad-CAM), uses the gradients of any target concept (say logits for `dog' or even a caption), flowing into the final convolutional layer to produce a coarse localization map highlighting the important regions in the image for predicting the concept. Unlike previous approaches, Grad- CAM is applicable to a wide variety of CNN model-families: (1) CNNs with fully-connected layers (e.g. VGG), (2) CNNs used for structured outputs (e.g. captioning), (3) CNNs used in tasks with multi-modal inputs (e.g. visual question answering) or reinforcement learning, without architectural changes or re-training. We combine Grad-CAM with existing fine-grained visualizations to create a high-resolution class-discriminative visualization, Guided Grad-CAM, and apply it to image classification, image captioning, and visual question answering (VQA) models, including ResNet-based architectures. In the context of image classification models, our visualizations (a) lend insights into failure modes of these models (showing that seemingly unreasonable predictions have reasonable explanations), (b) outperform previous methods on the ILSVRC-15 weakly-supervised localization task, (c) are more faithful to the underlying model, and (d) help achieve model generalization by identifying dataset bias. For image captioning and VQA, our visualizations show even non-attention based models can localize inputs. Finally, we design and conduct human studies to measure if Grad-CAM explanations help users establish appropriate trust in predictions from deep networks and show that Grad-CAM helps untrained users successfully discern a `stronger' deep network from a `weaker' one even when both make identical predictions. Our code is available at https: //github.com/ramprs/grad-cam/ along with a demo on CloudCV [2] and video at youtu.be/COjUB9Izk6E.","['Closed captioning', 'Computer science', 'Discriminative model', 'Convolutional neural network', 'Artificial intelligence', 'Visualization', 'Generalization', 'Question answering', 'Class (philosophy)', 'Context (archaeology)', 'Contextual image classification', 'Pattern recognition (psychology)', 'Task (project management)', 'Image (mathematics)', 'Machine learning', 'Mathematical analysis', 'Paleontology', 'Mathematics', 'Management', 'Economics', 'Biology']","visual explanations, convolutional neural network, coarse localization map, cnn, ##ion, cnn, visual question answering, reinforcement learning, image classification, image captioning, visual question answering, image classification models, dataset bias, cloud, you"
Paper_00699,Multi-Objective Optimization Using Evolutionary Algorithms,"['Kalyanmoy Deb', 'Deb Kalyanmoy']",2001,['Engineering Optimization'],Unknown,,541-557,43,5,10.1080/0305215x.2010.502935,"From the Publisher:
Evolutionary algorithms are relatively new, but very powerful techniques used to find solutions to many real-world search and optimization problems. Many of these problems have multiple objectives, which leads to the need to obtain a set of optimal solutions, known as effective solutions. It has been found that using evolutionary algorithms is a highly effective way of finding multiple effective solutions in a single simulation run. · Comprehensive coverage of this growing area of research · Carefully introduces each algorithm with examples and in-depth discussion · Includes many applications to real-world problems, including engineering design and scheduling · Includes discussion of advanced topics and future research · Features exercises and solutions, enabling use as a course text or for self-study · Accessible to those with limited knowledge of classical multi-objective optimization and evolutionary algorithms The integrated presentation of theory, algorithms and examples will benefit those working and researching in the areas of optimization, optimal design and evolutionary computing. This text provides an excellent introduction to the use of evolutionary algorithms in multi-objective optimization, allowing use as a graduate course text or for self-study.","['Evolutionary algorithm', 'Computer science', 'Set (abstract data type)', 'Optimization problem', 'Evolutionary computation', 'Evolutionary programming', 'Scheduling (production processes)', 'Mathematical optimization', 'Presentation (obstetrics)', 'Optimization algorithm', 'Artificial intelligence', 'Management science', 'Algorithm', 'Mathematics', 'Engineering', 'Medicine', 'Radiology', 'Programming language']","evolutionary algorithms, optimization, effective, evolutionary algorithms, engineering design, scheduling, evolutionary algorithms, optimization, optimal design, evolutionary computing, evolutionary algorithms, [PAD], [PAD], [PAD]"
Paper_00700,Prediction of Creatinine Clearance from Serum Creatinine,"['Donald W. Cockcroft', 'Henry Gault']",1976,Nephron,Journal,,31-41,16,1,10.1159/000180580,"A formula has been developed to predict creatinine clearance (Ccr) from serum creatinine (Scr) in adult males: Ccr = (140 – age) (wt kg)/72 × Scr(mg/100ml) (15% less in females). Derivation included the relationship found between age and 24-hour creatinine excretion/kg in 249 patients aged 18–92. Values for Ccr were predicted by this formula and four other methods and the results compared with the means of two 24-hour Ccr's measured in 236 patients. The above formula gave a correlation coefficient between predicted and mean measured Ccr·s of 0.83; on average, the difference between predicted and mean measured values was no greater than that between paired clearances. Factors for age and body weight must be included for reasonable prediction.","['Creatinine', 'Medicine', 'Renal function', 'Urology', 'Internal medicine', 'Body weight', 'Endocrinology']","creatinine clearance, serum creatinine, adult, correlation coefficient, paired clearances, age, body weight"
Paper_00701,A Method of Computing the Effectiveness of an Insecticide,['W. S. Abbott'],1925,Journal of Economic Entomology,Journal,,265-267,18,2,10.1093/jee/18.2.265a,"Journal Article A Method of Computing the Effectiveness of an Insecticide Get access W. S. Abbott W. S. Abbott Bureau of Entomology, United States Department of Agriculture Search for other works by this author on: Oxford Academic PubMed Google Scholar Journal of Economic Entomology, Volume 18, Issue 2, 1 April 1925, Pages 265–267, https://doi.org/10.1093/jee/18.2.265a Published: 01 April 1925","['Entomology', 'Library science', 'Biology', 'Agriculture', 'Ecology', 'Computer science']","insect, economic entomology, [PAD]"
Paper_00702,Xception: Deep Learning with Depthwise Separable Convolutions,['François Chollet'],2017,Unknown,Unknown,,1800-1807,,,10.1109/cvpr.2017.195,"We present an interpretation of Inception modules in convolutional neural networks as being an intermediate step in-between regular convolution and the depthwise separable convolution operation (a depthwise convolution followed by a pointwise convolution). In this light, a depthwise separable convolution can be understood as an Inception module with a maximally large number of towers. This observation leads us to propose a novel deep convolutional neural network architecture inspired by Inception, where Inception modules have been replaced with depthwise separable convolutions. We show that this architecture, dubbed Xception, slightly outperforms Inception V3 on the ImageNet dataset (which Inception V3 was designed for), and significantly outperforms Inception V3 on a larger image classification dataset comprising 350 million images and 17,000 classes. Since the Xception architecture has the same number of parameters as Inception V3, the performance gains are not due to increased capacity but rather to a more efficient use of model parameters.","['Convolution (computer science)', 'Pointwise', 'Separable space', 'Convolutional neural network', 'Computer science', 'Artificial intelligence', 'Deep learning', 'Interpretation (philosophy)', 'Pattern recognition (psychology)', 'Image (mathematics)', 'Algorithm', 'Artificial neural network', 'Mathematics', 'Mathematical analysis', 'Programming language']","inception modules, convolutional neural networks, regular convolution, depthwise separable convolution operation, depthwise convolution, pointwise convolution, depthwise separable convolution, inception module, deep convolutional neural network architecture, inception, inception modules, depthwise separable convolutions, xception, imagenet dataset, image classification, xception architecture, [PAD] [PAD] [PAD] [PAD], [PAD]"
Paper_00703,The Practice of Social Research,"['Alan Neustadtl', 'Earl R. Babbie']",1989,Teaching Sociology,Journal,,499-499,17,4,10.2307/1318433,"Part I: AN INTRODUCTION TO INQUIRY. 1. Human Inquiry and Science. 2. Paradigms, Theory, and Social Research. 3. The Ethics and Politics of Social Research. Part II: THE STRUCTURING OF INQUIRY: QUANTITATIVE AND QUALITATIVE. 4. Research Design. 5. Conceptualization, Operationalization, and Measurement. 6. Indexes, Scales, and Typologies. 7. The Logic of Sampling. Part III: MODES OF OPERATION: QUANTITATIVE AND QUALITATIVE. 8. Experiments. 9. Survey Research. 10. Qualitative Field Research. 11. Unobtrusive Research. 12. Evaluation Research. Part IV: ANALYSIS OF DATA: QUANTITATIVE AND QUALITATIVE. 13. Qualitative Data Analysis. 14. Quantitative Data Analysis. 15. The Logic of Multivariate Analysis. 16. Statistical Analyses. 17. Reading and Writing Social Research. APPENDICES. A. Using the Library. B. GSS Household Enumeration Questionnaire. C. Random Numbers. D. Distribution of Chi Square. E. Normal Curve Areas. F. Estimated Sampling Error. Preface. Acknowledgments.","['Sociology', 'Pedagogy', 'Higher education', 'Social science', 'Political science', 'Law']","human inquiry, social research, social research, research design, conceptual, operational, typologies, survey research, qualitative field research, unobtrusive research, evaluation research, qualitative data analysis, quantitative data analysis, logic, multivariate analysis, statistical analyses, household enumeration questionnaire, random numbers, normal curve areas, estimated sampling error"
Paper_00704,Qualitative research & evaluation methods,['Michael Quinn Patton'],2002,['International Journal of Information Management'],Unknown,,323,10,4,10.1016/0268-4012(90)90041-p,"This book explains clearly conceptual issues and themes on qualitative research and evaluaton methods including: qualitative data, triangulated inquiry, qualitative inquiry, constructivism, constructionism, Complexity (chaos) theory, qualitative designs and data collection, fieldwork strategies, interviewing, tape-recording, ethical issues, analysis, interpretation and reporting, observations vs. perceived impacts and utilisation-focused evaluation reporting.","['Qualitative research', 'Interview', 'Strict constructionism', 'Constructivism (international relations)', 'Interpretation (philosophy)', 'Qualitative property', 'Constructionism', 'Qualitative analysis', 'Management science', 'Epistemology', 'Psychology', 'Engineering ethics', 'Sociology', 'Computer science', 'Social science', 'Engineering', 'Political science', 'Philosophy', 'International relations', 'Machine learning', 'Politics', 'Anthropology', 'Law', 'Programming language']","qualitative research, evaluaton methods, qualitative data, triangulated inquiry, qualitative inquiry, constructivism, constructionism, complexity, chaos, qualitative designs, data collection, fieldwork strategies, ethical issues, analysis"
Paper_00705,The finite element method,['Ogierd Cecil Zienkiewicz'],1989,['Introduction to Computational Mathematics'],Unknown,,157-170,,1,10.1142/9789814635790_0012,"Keywords: methodes : numeriques ; fonction de forme Reference Record created on 2005-11-18, modified on 2016-08-08","['Finite element method', 'Computer science', 'Structural engineering', 'Engineering']","numer, [PAD]"
Paper_00706,Numerical Heat Transfer and Fluid Flow,['Chia‐Jung Hsu'],1981,Nuclear Science and Engineering,Journal,,196-197,78,2,10.13182/nse81-a20112,"""Numerical Heat Transfer and Fluid Flow."" Nuclear Science and Engineering, 78(2), pp. 196–197 Additional informationNotes on contributorsChia-Jung HsuAbout the Reviewer: C. J. Hsu has been at Brookhaven National Laboratory for over 18 years as a chemical engineer and a member of the scientific staff of the Department of Nuclear Energy. He also served as adjunct professor of mechanical engineering at the Cooper Union for the Advancement of Science and Art in New York City. Although his theoretical research interests were in the fields of fluid dynamics and liquid-metal heat transfer, during the past several years he has been involved mainly in the development and applications of thermal and hydraulic computer codes related to nuclear reactor safety analyses. Dr. Hsu holds graduate degrees from Columbia University and the University of Houston.","['Heat transfer', 'Fluid dynamics', 'National laboratory', 'Thermal hydraulics', 'Nuclear science', 'Energy transfer', 'Nuclear engineering', 'Nuclear physics', 'Physics', 'Engineering physics', 'Mechanics', 'Engineering']","numerical heat transfer, fluid flow, fluid dynamics, hydraulic computer codes, nuclear reactor safety analyses"
Paper_00707,Experimental and Quasi-Experimental Designs for Research,"['Donald T. Campbell', 'Julian C. Stanley', 'Nathaniel L. Gage']",1963,['The SAGE Encyclopedia of Abnormal and Clinical Psychology'],Unknown,,,,,10.4135/9781483365817.n1111,"A survey drawn from social-science research which deals with correlational, ex post facto, true experimental, and quasi-experimental designs and makes methodological recommendations. Bibliogs.",['Computer science'],correlation
Paper_00708,"Definition, diagnosis and classification of diabetes mellitus and its complications. Part 1: diagnosis and classification of diabetes mellitus. Provisional report of a WHO Consultation","['K. G. M. M. Alberti', 'Paul Zimmet']",1998,Diabetic Medicine,Journal,,539-553,15,7,10.1002/(sici)1096-9136(199807)15:7<539::aid-dia668>3.0.co;2-s,"The classification of diabetes mellitus and the tests used for its diagnosis were brought into order by the National Diabetes Data Group of the USA and the second World Health Organization Expert Committee on Diabetes Mellitus in 1979 and 1980. Apart from minor modifications by WHO in 1985, little has been changed since that time. There is however considerable new knowledge regarding the aetiology of different forms of diabetes as well as more information on the predictive value of different blood glucose values for the complications of diabetes. A WHO Consultation has therefore taken place in parallel with a report by an American Diabetes Association Expert Committee to re-examine diagnostic criteria and classification. The present document includes the conclusions of the former and is intended for wide distribution and discussion before final proposals are submitted to WHO for approval. The main changes proposed are as follows. The diagnostic fasting plasma (blood) glucose value has been lowered to ≥7.0 mmol l−1 (6.1 mmol l−1). Impaired Glucose Tolerance (IGT) is changed to allow for the new fasting level. A new category of Impaired Fasting Glycaemia (IFG) is proposed to encompass values which are above normal but below the diagnostic cut-off for diabetes (plasma ≥6.1 to <7.0 mmol l−1; whole blood ≥5.6 to <6.1 mmol l−1). Gestational Diabetes Mellitus (GDM) now includes gestational impaired glucose tolerance as well as the previous GDM. The classification defines both process and stage of the disease. The processes include Type 1, autoimmune and non-autoimmune, with beta-cell destruction; Type 2 with varying degrees of insulin resistance and insulin hyposecretion; Gestational Diabetes Mellitus; and Other Types where the cause is known (e.g. MODY, endocrinopathies). It is anticipated that this group will expand as causes of Type 2 become known. Stages range from normoglycaemia to insulin required for survival. It is hoped that the new classification will allow better classification of individuals and lead to fewer therapeutic misjudgements. © 1998 WHO","['Medicine', 'Diabetes mellitus', 'Gestational diabetes', 'Impaired glucose tolerance', 'Etiology', 'Internal medicine', 'Type 2 Diabetes Mellitus', 'Endocrinology', 'Type 2 diabetes', 'Pregnancy', 'Gestation', 'Biology', 'Genetics']","diabetes mellitus, national diabetes data group, world health organization, diabetes mellitus, who, ##ive value, who, american diabetes association, diagnostic fasting plasma, impaired glucose tolerance, impaired fasting glycaemia, gestational diabetes, gestational diabetes, endocrinopathies, normog, ##ca"
Paper_00709,The Cross‐Section of Expected Stock Returns,"['Eugene F. Fama', 'Kenneth R. French']",1992,The Journal of Finance,Journal,,427-465,47,2,10.1111/j.1540-6261.1992.tb04398.x,"ABSTRACT Two easily measured variables, size and book‐to‐market equity, combine to capture the cross‐sectional variation in average stock returns associated with market β , size, leverage, book‐to‐market equity, and earnings‐price ratios. Moreover, when the tests allow for variation in β that is unrelated to size, the relation between market β and average return is flat, even when β is the only explanatory variable.","['Equity (law)', 'Econometrics', 'Economics', 'Financial economics', 'Earnings', 'Leverage (statistics)', 'Stock market', 'Stock (firearms)', 'Market size', 'Statistics', 'Mathematics', 'Accounting', 'Geography', 'Context (archaeology)', 'Archaeology', 'Political science', 'Law', 'Commerce']","size, book, market equity, average stock returns, size, leverage, market equity, earnings, average return"
Paper_00710,Investigation of the freely available easy-to-use software ‘EZR’ for medical statistics,['Yoshinobu Kanda'],2012,Bone Marrow Transplantation,Journal,,452-458,48,3,10.1038/bmt.2012.244,"Although there are many commercially available statistical software packages, only a few implement a competing risk analysis or a proportional hazards regression model with time-dependent covariates, which are necessary in studies on hematopoietic SCT. In addition, most packages are not clinician friendly, as they require that commands be written based on statistical languages. This report describes the statistical software 'EZR' (Easy R), which is based on R and R commander. EZR enables the application of statistical functions that are frequently used in clinical studies, such as survival analyses, including competing risk analyses and the use of time-dependent covariates, receiver operating characteristics analyses, meta-analyses, sample size calculation and so on, by point-and-click access. EZR is freely available on our website ( http://www.jichi.ac.jp/saitama-sct/SaitamaHP.files/statmed.html ) and runs on both Windows (Microsoft Corporation, USA) and Mac OS X (Apple, USA). This report provides instructions for the installation and operation of EZR.","['Software', 'Statistical software', 'Medicine', 'Statistical analysis', 'Covariate', 'Computer science', 'Software engineering', 'Operating system', 'Statistics', 'Mathematics', 'Machine learning']","statistical software, competing risk analysis, proportional hazards regression model, hematopoietic sct, statistical, ezr, ##zr, clinical studies, survival analyses, competing, receiver operating characteristics analyses, sample size calculation, ##zr, ##r, [PAD] [PAD] [PAD], [PAD] [PAD], [PAD] [PAD], [PAD], [PAD], [PAD], [PAD] [PAD] [PAD], [PAD] [PAD], [PAD] [PAD] [PAD], [PAD]"
Paper_00711,Quantum Mechanical Continuum Solvation Models,"['Jacopo Tomasi', 'Benedetta Mennucci', 'Roberto Cammi']",2005,Chemical Reviews,Journal,,2999-3094,105,8,10.1021/cr9904009,"ADVERTISEMENT RETURN TO ISSUEPREVArticleNEXTQuantum Mechanical Continuum Solvation ModelsJacopo Tomasi, Benedetta Mennucci, and Roberto CammiView Author Information Dipartimento di Chimica e Chimica Industriale, Università di Pisa, Via Risorgimento 35, 56126 Pisa, Italy, and Dipartimento di Chimica, Università di Parma, Viale delle Scienze 17/A, 43100 Parma, Italy Cite this: Chem. Rev. 2005, 105, 8, 2999–3094Publication Date (Web):July 26, 2005Publication History Received6 January 2005Published online26 July 2005Published inissue 1 August 2005https://pubs.acs.org/doi/10.1021/cr9904009https://doi.org/10.1021/cr9904009research-articleACS PublicationsCopyright © 2005 American Chemical SocietyRequest reuse permissionsArticle Views40539Altmetric-Citations13824LEARN ABOUT THESE METRICSArticle Views are the COUNTER-compliant sum of full text article downloads since November 2008 (both PDF and HTML) across all institutions and individuals. These metrics are regularly updated to reflect usage leading up to the last few days.Citations are the number of other articles citing this article, calculated by Crossref and updated daily. Find more information about Crossref citation counts.The Altmetric Attention Score is a quantitative measure of the attention that a research article has received online. Clicking on the donut icon will load a page at altmetric.com with additional details about the score and the social media presence for the given article. Find more information on the Altmetric Attention Score and how the score is calculated. Share Add toView InAdd Full Text with ReferenceAdd Description ExportRISCitationCitation and abstractCitation and referencesMore Options Share onFacebookTwitterWechatLinked InRedditEmail Other access optionsGet e-Alertsclose SUBJECTS:Cavities,Molecules,Solution chemistry,Solvation,Solvents Get e-Alerts","['Solvation', 'Citation', 'Altmetrics', 'Computer science', 'Physics', 'Library science', 'Quantum mechanics', 'Molecule']","american chemical society, ##f, cross, ##f, altmetric attention score, social, altmetric attention score, ##ation, abstract, ##tter, cavities, molecules, solution chemistry, solvation, solvents"
Paper_00712,"STRING v11: protein–protein association networks with increased coverage, supporting functional discovery in genome-wide experimental datasets","['Damian Szklarczyk', 'Annika L Gable', 'David Lyon', 'Alexander Junge', 'Stefan Wyder', 'Jaime Huerta‐Cepas', 'Milan Simonovic', 'Nadezhda T. Doncheva', 'John H. Morris', 'Peer Bork', 'Lars Juhl Jensen', 'Christian von Mering']",2018,Nucleic Acids Research,Journal,,D607-D613,47,D1,10.1093/nar/gky1131,"Proteins and their functional interactions form the backbone of the cellular machinery. Their connectivity network needs to be considered for the full understanding of biological phenomena, but the available information on protein-protein associations is incomplete and exhibits varying levels of annotation granularity and reliability. The STRING database aims to collect, score and integrate all publicly available sources of protein-protein interaction information, and to complement these with computational predictions. Its goal is to achieve a comprehensive and objective global network, including direct (physical) as well as indirect (functional) interactions. The latest version of STRING (11.0) more than doubles the number of organisms it covers, to 5090. The most important new feature is an option to upload entire, genome-wide datasets as input, allowing users to visualize subsets as interaction networks and to perform gene-set enrichment analysis on the entire input. For the enrichment analysis, STRING implements well-known classification systems such as Gene Ontology and KEGG, but also offers additional, new classification systems based on high-throughput text-mining as well as on a hierarchical clustering of the association network itself. The STRING resource is available online at https://string-db.org/.","['String (physics)', 'KEGG', 'Biology', 'Computational biology', 'Computer science', 'Cluster analysis', 'Genome', 'Data mining', 'Interaction network', 'Gene ontology', 'Set (abstract data type)', 'Gene', 'Machine learning', 'Genetics', 'Gene expression', 'Physics', 'Quantum mechanics', 'Programming language']","functional interactions, cellular machinery, connectivity network, ann, ##tion granularity, reliability, string database, interaction networks, classification systems, gene ontology, kegg, hierarchical clustering, string"
Paper_00713,Confirmatory factor analysis for applied research,['Timothy A. Brown'],2007,Choice Reviews Online,Journal,,44-2769,44,05,10.5860/choice.44-2769,"With its emphasis on practical and conceptual aspects, rather than mathematics or formulas, this accessible book has established itself as the go-to resource on confirmatory factor analysis (CFA). Detailed, worked-through examples drawn from psychology, management, and sociology studies illustrate the procedures, pitfalls, and extensions of CFA methodology. The text shows how to formulate, program, and interpret CFA models using popular latent variable software packages (LISREL, Mplus, EQS, SAS/CALIS); understand the similarities and differences between CFA and exploratory factor analysis (EFA); and report results from a CFA study. It is filled with useful advice and tables that outline the procedures. The companion website offers data and program syntax files for most of the research examples, as well as links to CFA-related resources. New to This Edition *Updated throughout to incorporate important developments in latent variable modeling. *Chapter on Bayesian CFA and multilevel measurement models. *Addresses new topics (with examples): exploratory structural equation modeling, bifactor analysis, measurement invariance evaluation with categorical indicators, and a new method for scaling latent variables. *Utilizes the latest versions of major latent variable software packages--","['Confirmatory factor analysis', 'Factor (programming language)', 'Computer science', 'Mathematics', 'Statistics', 'Structural equation modeling', 'Programming language']","confirmatory factor analysis, cfa, management, sociology, cfa, latent variable software packages, lisrel, mplus, eqs, ##is, exploratory factor analysis, ##fa, program syntax, latent variable modeling, bayesian cfa, multilevel measurement models, exploratory structural equation modeling, bifactor analysis, measurement invariance evaluation, categorical indicators, latent variables, latent variable software"
Paper_00714,The cBio Cancer Genomics Portal: An Open Platform for Exploring Multidimensional Cancer Genomics Data,"['Ethan Cerami', 'Jianjiong Gao', 'Uḡur Doḡrusöz', 'Benjamin Groß', 'S. Onur Sumer', 'Bülent Arman Aksoy', 'Anders J. Skanderup', 'Caitlin J. Byrne', 'Michael Heuer', 'Erik Larsson', 'Yevgeniy Antipin', 'Boris Reva', 'Arthur P. Goldberg', 'Chris Sander', 'Nikolaus Schultz']",2012,Cancer Discovery,Journal,,401-404,2,5,10.1158/2159-8290.cd-12-0095,"Abstract The cBio Cancer Genomics Portal (http://cbioportal.org) is an open-access resource for interactive exploration of multidimensional cancer genomics data sets, currently providing access to data from more than 5,000 tumor samples from 20 cancer studies. The cBio Cancer Genomics Portal significantly lowers the barriers between complex genomic data and cancer researchers who want rapid, intuitive, and high-quality access to molecular profiles and clinical attributes from large-scale cancer genomics projects and empowers researchers to translate these rich data sets into biologic insights and clinical applications. Cancer Discov; 2(5); 401–4. ©2012 AACR.","['Genomics', 'Cancer', 'Computational biology', 'Biology', 'Bioinformatics', 'Genome', 'Genetics', 'Gene']","cbio, cbio, ##al, multidimensional cancer genomics, cbio, clinical attributes, cancer discov, [PAD], [PAD], [PAD]"
Paper_00715,Scale Development : Theory and Applications,['Robert F. DeVellis'],1991,['Contemporary Sociology'],Unknown,,876,21,6,10.2307/2075704,Chapter 1: Overview General Perspectives on Measurement Historical Origins of Measurement in Social Science Later Developments in Measurement The Role of Measurement in the Social Sciences Summary and Preview Chapter 2: Understanding the Constructs Versus Measures Latent Variable as the Presumed Cause of Item Values Path Diagrams Further Elaboration of the Measurement Model Parallel Tests Alternative Models Exercises Chapter 3: Reliability Continuous Versus Dichotomous Items Internal Consistency Relability Based on Correlations Between Scale Scores Generalizability Theory Summary and Exercises Chapter 4: Validity Content Validity Criterion-related Validity Construct Validity What About Face Validity? Exercises Chapter 5: Guidelines in Scale Development Step 1: Determine Clearly What it Is You Want to Measure Step 2: Generate an Item Pool Step 3: Determine the Format for Measurement Step 4: Have Initial Item Pool Reviewed by Experts Step 5: Consider Inclusion of Validation Items Step 6: Administer Items to a Development Sample Step 7: Evaluate the Items Step 8: Optimize Scale Length Exercises Chapter 6: Factor Analysis Overview of Factor Analysis Conceptual Description of Factor Analysis Interpreting Factors Principal Components vs Common Factors Confirmatory Factor Analysis Using Factor Analysis in Scale Development Sample Size Conclusion Chapter 7: An Overview of Item Response Theory Item Difficulty Item Discrimination False Positives Item Characteristic Curves Complexities of IRT When to Use IRT Conclusions Chapter 8: Measurement in the Broader Research Context Before the Scale Development After the Scale Administration Final Thoughts References Index About the Author,"['Confirmatory factor analysis', 'Scale (ratio)', 'Item response theory', 'Generalizability theory', 'Construct validity', 'Face validity', 'Psychology', 'Reliability (semiconductor)', 'Item analysis', 'Sample (material)', 'Psychometrics', 'Statistics', 'Structural equation modeling', 'Mathematics', 'Clinical psychology', 'Developmental psychology', 'Power (physics)', 'Physics', 'Chemistry', 'Chromatography', 'Quantum mechanics']","measurement, measurement, social science, measurement, measurement, social, validity content, scale development, factor analysis, factor analysis, factor, factor analysis"
Paper_00717,<i>XDS</i>,['Wolfgang Kabsch'],2010,Acta Crystallographica Section D Biological Crystallography,Journal,,125-132,66,2,10.1107/s0907444909047337,"The usage and control of recent modifications of the program package XDS for the processing of rotation images are described in the context of previous versions. New features include automatic determination of spot size and reflecting range and recognition and assignment of crystal symmetry. Moreover, the limitations of earlier package versions on the number of correction/scaling factors and the representation of pixel contents have been removed. Large program parts have been restructured for parallel processing so that the quality and completeness of collected data can be assessed soon after measurement.","['Computer science', 'Completeness (order theory)', 'Context (archaeology)', 'Pixel', 'Rotation (mathematics)', 'Artificial intelligence', 'Scaling', 'Data processing', 'Representation (politics)', 'Computer vision', 'Mathematics', 'Database', 'Geography', 'Geometry', 'Mathematical analysis', 'Archaeology', 'Politics', 'Political science', 'Law']","xds, rotation images, spot size, reflecting range, crystal symmetry, pixel, parallel processing, [PAD] [PAD], [PAD] [PAD], [PAD], [PAD]"
Paper_00719,Inference from Iterative Simulation Using Multiple Sequences,"['Andrew Gelman', 'Donald B. Rubin']",1992,Statistical Science,Journal,,,7,4,10.1214/ss/1177011136,"The Gibbs sampler, the algorithm of Metropolis and similar iterative simulation methods are potentially very helpful for summarizing multivariate distributions. Used naively, however, iterative simulation can give misleading answers. Our methods are simple and generally applicable to the output of any iterative simulation; they are designed for researchers primarily interested in the science underlying the data and models they are analyzing, rather than for researchers interested in the probability theory underlying the iterative simulations themselves. Our recommended strategy is to use several independent sequences, with starting points sampled from an overdispersed distribution. At each step of the iterative simulation, we obtain, for each univariate estimand of interest, a distributional estimate and an estimate of how much sharper the distributional estimate might become if the simulations were continued indefinitely. Because our focus is on applied inference for Bayesian posterior distributions in real problems, which often tend toward normality after transformations and marginalization, we derive our results as normal-theory approximations to exact Bayesian inference, conditional on the observed simulations. The methods are illustrated on a random-effects mixture model applied to experimental measurements of reaction times of normal and schizophrenic patients.","['Inference', 'Computer science', 'Univariate', 'Iterative method', 'Bayesian probability', 'Gibbs sampling', 'Bayesian inference', 'Multivariate normal distribution', 'Simple (philosophy)', 'Algorithm', 'Normality', 'Applied mathematics', 'Multivariate statistics', 'Econometrics', 'Mathematics', 'Statistics', 'Machine learning', 'Artificial intelligence', 'Philosophy', 'Epistemology']","gibbs sampler, metropolis, iterative simulation methods, multivariate distributions, iterative simulation, overdispersed distribution, it, univariate est, distributional estimate, bayesian posterior distributions, ##hi, ##renic patients"
Paper_00720,When to use and how to report the results of PLS-SEM,"['Joseph F. Hair', 'Jeffrey J. Risher', 'Marko Sarstedt', 'Christian M. Ringle']",2018,European Business Review,Journal,,2-24,31,1,10.1108/ebr-11-2018-0203,"Purpose The purpose of this paper is to provide a comprehensive, yet concise, overview of the considerations and metrics required for partial least squares structural equation modeling (PLS-SEM) analysis and result reporting. Preliminary considerations are summarized first, including reasons for choosing PLS-SEM, recommended sample size in selected contexts, distributional assumptions, use of secondary data, statistical power and the need for goodness-of-fit testing. Next, the metrics as well as the rules of thumb that should be applied to assess the PLS-SEM results are covered. Besides presenting established PLS-SEM evaluation criteria, the overview includes the following new guidelines: PLSpredict (i.e., a novel approach for assessing a model’s out-of-sample prediction), metrics for model comparisons, and several complementary methods for checking the results’ robustness. Design/methodology/approach This paper provides an overview of previously and recently proposed metrics as well as rules of thumb for evaluating the research results based on the application of PLS-SEM. Findings Most of the previously applied metrics for evaluating PLS-SEM results are still relevant. Nevertheless, scholars need to be knowledgeable about recently proposed metrics (e.g. model comparison criteria) and methods (e.g. endogeneity assessment, latent class analysis and PLSpredict), and when and how to apply them to extend their analyses. Research limitations/implications Methodological developments associated with PLS-SEM are rapidly emerging. The metrics reported in this paper are useful for current applications, but must always be up to date with the latest developments in the PLS-SEM method. Originality/value In light of more recent research and methodological developments in the PLS-SEM domain, guidelines for the method’s use need to be continuously extended and updated. This paper is the most current and comprehensive summary of the PLS-SEM method and the metrics applied to assess its solutions.","['Structural equation modeling', 'Computer science', 'Rule of thumb', 'Robustness (evolution)', 'Partial least squares regression', 'Sample (material)', 'Sample size determination', 'Originality', 'Data mining', 'Artificial intelligence', 'Machine learning', 'Mathematics', 'Statistics', 'Algorithm', 'Psychology', 'Social psychology', 'Biochemistry', 'Chemistry', 'Chromatography', 'Creativity', 'Gene']","partial least squares structural equation modeling, result reporting, distributional assumptions, secondary data, statistical power, plspredict, metrics, model comparisons, model comparison criteria, endogeneity assessment, latent class analysis, plspredict"
Paper_00721,"Stress, social support, and the buffering hypothesis.","['Sheldon Cohen', 'Thomas A. Wills']",1985,Psychological Bulletin,Journal,,310-357,98,2,10.1037/0033-2909.98.2.310,"Examines whether the positive association between social support and well-being is attributable more to an overall beneficial effect of support (main- or direct-effect model) or to a process of support protecting persons from potentially adverse effects of stressful events (buffering model). The review of studies is organized according to (1) whether a measure assesses support structure (the existence of relationships) or function (the extent to which one's interpersonal relationships provide particular resources) and (2) the degree of specificity (vs globality) of the scale. Special attention is given to methodological characteristics that are requisite for a fair comparison of the models. It is concluded that there is evidence consistent with both models. Evidence for the buffering model is found when the social support measure assesses the perceived availability of interpersonal resources that are responsive to the needs elicited by stressful events. Evidence for a main effect model is found when the support measure assesses a person's degree of integration in a large social network. Both conceptualizations of social support are correct in some respects, but each represents a different process through which social support may affect well-being. Implications for theories of social support processes and for the design of preventive interventions are discussed.","['Psychology', 'Stress (linguistics)', 'Social psychology', 'Social support', 'Cognitive psychology', 'Philosophy', 'Linguistics']","social support, buffering, methodological characteristics, buffering, social, interpersonal resources, social, social, social support, preventive interventions, [PAD], [PAD], [PAD]"
Paper_00722,A Programmable Dual-RNA–Guided DNA Endonuclease in Adaptive Bacterial Immunity,"['Martin Jínek', 'Krzysztof Chylinski', 'Ines Fonfara', 'M. Hauer', 'Jennifer A. Doudna', 'Emmanuelle Charpentier']",2012,Science,Journal,,816-821,337,6096,10.1126/science.1225829,"Clustered regularly interspaced short palindromic repeats (CRISPR)/CRISPR-associated (Cas) systems provide bacteria and archaea with adaptive immunity against viruses and plasmids by using CRISPR RNAs (crRNAs) to guide the silencing of invading nucleic acids. We show here that in a subset of these systems, the mature crRNA that is base-paired to trans-activating crRNA (tracrRNA) forms a two-RNA structure that directs the CRISPR-associated protein Cas9 to introduce double-stranded (ds) breaks in target DNA. At sites complementary to the crRNA-guide sequence, the Cas9 HNH nuclease domain cleaves the complementary strand, whereas the Cas9 RuvC-like domain cleaves the noncomplementary strand. The dual-tracrRNA:crRNA, when engineered as a single RNA chimera, also directs sequence-specific Cas9 dsDNA cleavage. Our study reveals a family of endonucleases that use dual-RNAs for site-specific DNA cleavage and highlights the potential to exploit the system for RNA-programmable genome editing.","['Trans-activating crRNA', 'CRISPR', 'Cas9', 'Endonuclease', 'DNA', 'Biology', 'RNA', 'Nucleic acid', 'Cleave', 'Computational biology', 'Genetics', 'Gene']","pali, adaptive immunity, ##as, crispr rnas, ##on"
Paper_00724,"GROMACS 4: Algorithms for Highly Efficient, Load-Balanced, and Scalable Molecular Simulation","['Berk Hess', 'Carsten Kutzner', 'David van der Spoel', 'Erik Lindahl']",2008,Journal of Chemical Theory and Computation,Journal,,435-447,4,3,10.1021/ct700301q,"Molecular simulation is an extremely useful, but computationally very expensive tool for studies of chemical and biomolecular systems. Here, we present a new implementation of our molecular simulation toolkit GROMACS which now both achieves extremely high performance on single processors from algorithmic optimizations and hand-coded routines and simultaneously scales very well on parallel machines. The code encompasses a minimal-communication domain decomposition algorithm, full dynamic load balancing, a state-of-the-art parallel constraint solver, and efficient virtual site algorithms that allow removal of hydrogen atom degrees of freedom to enable integration time steps up to 5 fs for atomistic simulations also in parallel. To improve the scaling properties of the common particle mesh Ewald electrostatics algorithms, we have in addition used a Multiple-Program, Multiple-Data approach, with separate node domains responsible for direct and reciprocal space interactions. Not only does this combination of algorithms enable extremely long simulations of large systems but also it provides that simulation performance on quite modest numbers of standard cluster nodes.","['Computer science', 'Scalability', 'Algorithm', 'Computational science', 'Node (physics)', 'Molecular dynamics', 'Parallel computing', 'Supercomputer', 'Domain decomposition methods', 'Solver', 'Chemistry', 'Physics', 'Computational chemistry', 'Structural engineering', 'Database', 'Finite element method', 'Engineering', 'Thermodynamics', 'Programming language']","molecular simulation, molecular simulation, gromacs, single processors, parallel machines, full dynamic load balancing, parallel constraint solver, virtual site algorithms, hydrogen atom degrees of freedom, particle mesh, reciprocal space interactions, [PAD]"
Paper_00725,Evidence based medicine: what it is and what it isn't,"['David L. Sackett', 'William Rosenberg', 'J. A. Muir Gray', 'R. Brian Haynes', 'W. Scott Richardson']",1996,BMJ,Journal,,71-72,312,7023,10.1136/bmj.312.7023.71,"It's about integrating individual clinical expertise and the best external evidence

Evidence based medicine, whose philosophical origins extend back to mid-19th century Paris and earlier, remains a hot topic for clinicians, public health practitioners, purchasers, planners, and the public. There are now frequent workshops in how to practice and teach it (one sponsored by the BMJ will be held in London on 24 April); undergraduate1 and postgraduate2 training programmes are incorporating it3 (or pondering how to do so); British centres for evidence based practice have been established or planned in adult medicine, child health, surgery, pathology, pharmacotherapy, nursing, general practice, and dentistry; the Cochrane Collaboration and Britain's Centre for Review and Dissemination in York are providing systematic reviews of the effects of health care; new evidence based practice journals are being launched; and it has become a common topic in the lay media. But enthusiasm has been mixed with some negative reaction.4 5 6 Criticism has ranged from evidence based medicine being old hat to it being a dangerous innovation, perpetrated by the arrogant to serve cost cutters and suppress clinical freedom. As evidence based medicine continues to evolve and adapt, now is a useful time to refine the discussion of what it is and what it is not.

Evidence based medicine is the conscientious, explicit, and judicious use of current best evidence in making decisions about the care of individual patients. The …","['Medicine', 'Psychology', 'Computer science']","evidence based medicine, public health practitioners, evidence based practice, adult medicine, child health, pathology, pharmacotherapy, nursing, general practice, dentistry, cochrane collaboration, evidence based practice, evidence based medicine, evidence based medicine, evidence based medicine"
Paper_00726,Adverse Renal Effects of Immune Checkpoint Inhibitors: A Narrative Review,"['Rimda Wanchoo', 'Sabine Karam', 'Nupur N. Uppal', 'Valerie S. Barta', 'Gilbert Deray', 'Craig Devoe', 'Vincent Launay‐Vacher', 'Kenar D. Jhaveri']",2017,American Journal of Nephrology,Journal,,160-169,45,2,10.1159/000455014,"Ipilimumab is a fully human monoclonal antibody targeting cytotoxic T-lymphocyte antigen-4 and has become the first immune checkpoint inhibitor to enter clinical practice, being recently approved for the treatment of metastatic melanoma. Immune toxicity due to ipilimumab causing colitis, hepatitis, dermatitis and hypophysitis is well-described. We report on a case of acute renal failure resolving rapidly with high-dose corticosteroid treatment highlighting the importance of vigilance for rarer immune-related toxicities as clinical experience with ipilimumab grows.","['Medicine', 'Ipilimumab', 'Nivolumab', 'Pembrolizumab', 'Adverse effect', 'Internal medicine', 'Kidney cancer', 'Atezolizumab', 'Cancer', 'Oncology', 'Gastroenterology', 'Immunology', 'Immunotherapy']","ipilimumab, immune checkpoint inhibitor, metastatic melanoma, immune toxicity, ipilimum, hypophysit, acute renal failure, ipilimumab, [PAD], [PAD], [PAD] [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD] [PAD], [PAD] [PAD], [PAD]"
Paper_00727,The Fractal Geometry of Nature.,"['Colin Sparrow', 'B. B. Mandelbrot']",1984,Journal of the Royal Statistical Society Series A (General),Journal,,616-616,147,4,10.2307/2981858,"...a blend of erudition (fascinating and sometimes obscure historical minutiae abound), popularization (mathematical rigor is relegated to appendices) and exposition (the reader need have little knowledge of the fields involved) ...and the illustrations include many superb examples of computer graphics that are works of art in their own right. Nature","['Fractal', 'Geometry', 'Mathematics', 'Mathematical analysis']","mathematical rig, computer graphics"
Paper_00729,Manual of Clinical Microbiology.,[],1980,Annals of Internal Medicine,Journal,,939-939,93,6,10.7326/0003-4819-93-6-939_2,"The 11th edition of the Manual of Clinical Microbiology continues to set the standard for state-of-the-science laboratory practices as the most authoritative reference in the field of clinical microbiology. This new edition presents the numerous microbial taxonomic changes and newer more powerful diagnostic approaches that have been developed since publication of the 10th edition. A collaborative team of editors and authors from around the world, all experienced practitioners, researchers, or public health experts, revised the Manual to include the latest applications of genomics and proteomics, producing an authoritative work of two volumes filled with current findings regarding infectious agents, leading-edge diagnostic methods, laboratory practices, and safety guidelines.","['Medicine', 'Clinical microbiology', 'Microbiology', 'Medical physics', 'Intensive care medicine', 'Biology']","clinical microbiology, laboratory practices, clinical microbiology, microbial taxonomic changes, public health, gen, proteomics, infectious agents, laboratory practices, safety guidelines"
Paper_00730,Dictionary of protein secondary structure: Pattern recognition of hydrogen‐bonded and geometrical features,"['Wolfgang Kabsch', 'Christian Sander']",1983,Biopolymers,Journal,,2577-2637,22,12,10.1002/bip.360221211,"For a successful analysis of the relation between amino acid sequence and protein structure, an unambiguous and physically meaningful definition of secondary structure is essential. We have developed a set of simple and physically motivated criteria for secondary structure, programmed as a pattern-recognition process of hydrogen-bonded and geometrical features extracted from x-ray coordinates. Cooperative secondary structure is recognized as repeats of the elementary hydrogen-bonding patterns ""turn"" and ""bridge."" Repeating turns are ""helices,"" repeating bridges are ""ladders,"" connected ladders are ""sheets."" Geometric structure is defined in terms of the concepts torsion and curvature of differential geometry. Local chain ""chirality"" is the torsional handedness of four consecutive Cα positions and is positive for right-handed helices and negative for ideal twisted β-sheets. Curved pieces are defined as ""bends."" Solvent ""exposure"" is given as the number of water molecules in possible contact with a residue. The end result is a compilation of the primary structure, including SS bonds, secondary structure, and solvent exposure of 62 different globular proteins. The presentation is in linear form: strip graphs for an overall view and strip tables for the details of each of 10.925 residues. The dictionary is also available in computer-readable form for protein structure prediction work.","['Protein secondary structure', 'Chemistry', 'Hydrogen bond', 'Torsion (gastropod)', 'Curvature', 'Crystallography', 'Globular protein', 'Loop modeling', 'Molecule', 'Protein structure', 'Geometry', 'Mathematics', 'Protein structure prediction', 'Medicine', 'Biochemistry', 'Surgery', 'Organic chemistry']","amino, protein structure, secondary structure, secondary structure, ##lices, geometric structure, torsion, curvature, differential geometry, chirality, torsional, ss bonds, secondary structure, solvent exposure, ##lobular proteins, strip graphs, strip tables, protein structure prediction"
Paper_00731,A Contribution to the Empirics of Economic Growth,"['N. Gregory Mankiw', 'Daniel Römer', 'David Weil']",1992,The Quarterly Journal of Economics,Journal,,407-437,107,2,10.2307/2118477,"This paper examines whether the Solow growth model is consistent with the international variation in the standard of living. It shows that an augmented Solow model that includes accumulation of human as well as physical capital provides an excellent description of the cross-country data. The paper also examines the implications of the Solow model for convergence in standards of living, that is, for whether poor countries tend to grow faster than rich countries. The evidence indicates that, holding population growth and capital accumulation constant, countries converge at about the rate the augmented Solow model predicts.","['Economics', 'Convergence (economics)', 'Human capital', 'Growth model', 'Solow residual', 'Standard of living', 'Constant (computer programming)', 'Econometrics', 'Capital (architecture)', 'Population growth', 'Growth accounting', 'Population', 'Macroeconomics', 'Economic growth', 'Productivity', 'Total factor productivity', 'Market economy', 'History', 'Demography', 'Archaeology', 'Sociology', 'Computer science', 'Programming language']","solow growth model, international variation, standard of living, augmented solow model, physical capital, solo, standards of living, population growth, capital accumulation, augmented solow model, [PAD] [PAD], [PAD], [PAD]"
Paper_00732,"METODE PENELITIAN Kuantitatif, Kualitatif dan R&D",['Sugiyono Sugiyono'],2014,Unknown,Unknown,,,,,10.31227/osf.io/4nq5e,"Buku ini memukakan tiga metode yaitu kuantitatif, kualitatif, penelitian dan pengembangan (research and development/ R&D). Metode kuantitatif cocok digunakan untuk penelitian pada populasi yang luas, permasalahan sudah jelas, teramati, terukur, dan peneliti bermaksud menguji hipotesis. Metode penelitian kualitatif cocok digunakan terutama bila permasalahan masih remang-remang bahkan gelap, peneliti bermaksud ingin memahami secara mendalam suatu situasi sosial yang kompleks, penuh mengkontruksi fenomena sosial yang rumit, menemukan hipotesis dan teori. Metode penelitian dan pengembangan (R&D) digunakan apabila peneliti bermaksud menghasilkan produk tertentu, dan sekaligus menguji keefektifan produk tersebut. Dengan metode R&D diharapkan dapat ditemukan dan diuji masyarakat. Borg and Gall (1989) mengungkapkan beberapa nama penelitian kuantitatif dan kualitatif. Penelitian kuantitatif disebut sebagai metode tradisional, positivistik, scientific, confirmatory, kuantitatif. Sedangkan metode kualitatif sering disebut sebagai metode baru, postpositivistic, discovery, interpretive, dan kualitatif. Nama kedua metode tersebut yang paling banyak digunakan adalah metode kuantitatif dan kualitatif. Perbedaan kedua metode tersebut, tidak semata-mata yang satu pakai angka dan yang lain tidak. perbedaan kedua metode tersebut meliputi aksioma dasar, proses penelitian dan karakteristik penelitian itu sendiri. Dari segi proses, penelitian kuantitatif bersifat deduktif dan penelitin kualitatif bersifat induktif.Keberadaan metode tersebut tidak perlu dipertentangkan, karena justru satu sama lain saling melengkapi","['Humanities', 'Art']","##tatif, positivist, ##sit"
Paper_00734,Semi-Supervised Classification with Graph Convolutional Networks,"['Thomas Kipf', 'Max Welling']",2016,arXiv (Cornell University),Unknown,,,,,10.48550/arxiv.1609.02907,We present a scalable approach for semi-supervised learning on graph-structured data that is based on an efficient variant of convolutional neural networks which operate directly on graphs. We motivate the choice of our convolutional architecture via a localized first-order approximation of spectral graph convolutions. Our model scales linearly in the number of graph edges and learns hidden layer representations that encode both local graph structure and features of nodes. In a number of experiments on citation networks and on a knowledge graph dataset we demonstrate that our approach outperforms related methods by a significant margin.,"['Computer science', 'Graph', 'Convolutional neural network', 'Scalability', 'Artificial intelligence', 'ENCODE', 'Margin (machine learning)', 'Theoretical computer science', 'Pattern recognition (psychology)', 'Machine learning', 'Biochemistry', 'Chemistry', 'Database', 'Gene']","scalable approach, convolutional neural networks, convolutional architecture, spectral graph convolutions, hidden layer representations, local graph structure, citation networks, knowledge graph dataset, [PAD] [PAD], [PAD] [PAD], [PAD] [PAD], [PAD], [PAD], [PAD] [PAD] [PAD] [PAD], [PAD] [PAD], [PAD] [PAD] [PAD] [PAD] [PAD], [PAD], [PAD] [PAD], [PAD] [PAD], [PAD] [PAD], [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD], [PAD] [PAD], [PAD] [PAD], [PAD] [PAD] [PAD], [PAD], [PAD], [PAD], [PAD] [PAD] [PAD], [PAD] [PAD], [PAD] [PAD] [PAD], [PAD], [PAD], [PAD]"
Paper_00735,Community structure in social and biological networks,"['Michelle Girvan', 'M. E. J. Newman']",2002,Proceedings of the National Academy of Sciences,Journal,,7821-7826,99,12,10.1073/pnas.122653799,"A number of recent studies have focused on the statistical properties of networked systems such as social networks and the World-Wide Web. Researchers have concentrated particularly on a few properties which seem to be common to many networks: the small-world property, power-law degree distributions, and network transitivity. In this paper, we highlight another property which is found in many networks, the property of community structure, in which network nodes are joined together in tightly-knit groups between which there are only looser connections. We propose a new method for detecting such communities, built around the idea of using centrality indices to find community boundaries. We test our method on computer generated and real-world graphs whose community structure is already known, and find that it detects this known structure with high sensitivity and reliability. We also apply the method to two networks whose community structure is not well-known - a collaboration network and a food web - and find that it detects significant and informative community divisions in both cases.","['Community structure', 'Computer science', 'Centrality', 'Transitive relation', 'Clique percolation method', 'Reliability (semiconductor)', 'Property (philosophy)', 'Complex network', 'Data science', 'Evolving networks', 'Biological network', 'Degree distribution', 'Network science', 'Theoretical computer science', 'Data mining', 'Social network (sociolinguistics)', 'The Internet', 'Network analysis', 'World Wide Web', 'Power (physics)', 'Mathematics', 'Statistics', 'Engineering', 'Physics', 'Philosophy', 'Epistemology', 'Combinatorics', 'Quantum mechanics', 'Social media', 'Electrical engineering']","statistical properties, networked systems, social networks, network transitivity, community structure, centrality indices, community boundaries, community structure, community structure, collaboration network, food web, community divisions, [PAD] [PAD], [PAD] [PAD]"
Paper_00736,Statistical Aspects of the Analysis of Data From Retrospective Studies of Disease,"['Nathan Mantel', 'William Haenszel']",1959,JNCI Journal of the National Cancer Institute,Journal,,,,,10.1093/jnci/22.4.719,"The role and limitations of retrospective investigations of factors possibly associated with the occurrence of a disease are discussed and their relationship to forward-type studies emphasized. Examples of situations in which misleading associations could arise through the use of inappropriate control groups are presented. The possibility of misleading associations may be minimized by controlling or matching on factors which could produce such associations; the statistical analysis will then be modified. Statistical methodology is presented for analyzing retrospective study data, including chi-square measures of statistical significance of the observed association between the disease and the factor under study, and measures for interpreting the association in terms of an increased relative risk of disease. An extension of the chi-square test to the situation where data are subclassified by factors controlled in the analysis is given. A summary relative risk formula, R, is presented and discussed in connection with the problem of weighting the individual subcategory relative risks according to their importance or their precision. Alternative relative-risk formulas, R1, R2, R3, and R4, which require the calculation of subcategory-adjusted proportions of the study factor among diseased persons and controls for the computation of relative risks, are discussed. While these latter formulas may be useful in many instances, they may be biased or inconsistent and are not, in fact, averages of the relative risks observed in the separate subcategories. Only the relative-risk formula, R, of those presented, can be viewed as such an average. The relationship of the matched-sample method to the sub-classification approach is indicated. The statistical methodology presented is illustrated with examples from a study of women with epidermoid and undifferentiated pulmonary carcinoma.","['Relative risk', 'Weighting', 'Statistics', 'Disease', 'Risk factor', 'Statistical hypothesis testing', 'Subcategory', 'Retrospective cohort study', 'Mathematics', 'Medicine', 'Econometrics', 'Demography', 'Confidence interval', 'Surgery', 'Pathology', 'Sociology', 'Pure mathematics', 'Radiology']","retrospective, misleading associations, inappropriate, misleading, statistical, statistical, summary relative risk formula, relative, epider, undifferentiated pulmonary carcinoma"
Paper_00738,Principal Component Analysis,['Ian T. Jolliffe'],2005,Encyclopedia of Statistics in Behavioral Science,Journal,,,,,10.1002/0470013192.bsa501,"Abstract When large multivariate datasets are analyzed, it is often desirable to reduce their dimensionality. Principal component analysis is one technique for doing this. It replaces the p original variables by a smaller number, q , of derived variables, the principal components, which are linear combinations of the original variables. Often, it is possible to retain most of the variability in the original variables with q very much smaller than p . Despite its apparent simplicity, principal component analysis has a number of subtleties, and it has many uses and extensions. A number of choices associated with the technique are briefly discussed, namely, covariance or correlation, how many components, and different normalization constraints, as well as confusion with factor analysis. Various uses and extensions are outlined.","['Principal component analysis', 'Normalization (sociology)', 'Covariance matrix', 'Covariance', 'Curse of dimensionality', 'Multivariate statistics', 'Mathematics', 'Dimensionality reduction', 'Confusion', 'Simplicity', 'Statistics', 'Computer science', 'Artificial intelligence', 'Psychology', 'Philosophy', 'Epistemology', 'Sociology', 'Anthropology', 'Psychoanalysis']","principal component analysis, principal components, principal component analysis, covariance, correlation, normalization constraints, factor analysis"
Paper_00739,Canonical sampling through velocity rescaling,"['Giovanni Bussi', 'Davide Donadio', 'Michele Parrinello']",2007,The Journal of Chemical Physics,Journal,,,126,1,10.1063/1.2408420,"The authors present a new molecular dynamics algorithm for sampling the canonical distribution. In this approach the velocities of all the particles are rescaled by a properly chosen random factor. The algorithm is formally justified and it is shown that, in spite of its stochastic nature, a quantity can still be defined that remains constant during the evolution. In numerical applications this quantity can be used to measure the accuracy of the sampling. The authors illustrate the properties of this new method on Lennard-Jones and TIP4P water models in the solid and liquid phases. Its performance is excellent and largely independent of the thermostat parameter also with regard to the dynamic properties.","['Thermostat', 'Sampling (signal processing)', 'Statistical physics', 'Measure (data warehouse)', 'Constant (computer programming)', 'Canonical ensemble', 'Mathematics', 'Applied mathematics', 'Molecular dynamics', 'Computer science', 'Statistics', 'Physics', 'Thermodynamics', 'Monte Carlo method', 'Data mining', 'Filter (signal processing)', 'Computer vision', 'Programming language', 'Quantum mechanics']","molecular dynamics algorithm, canonical distribution, velocit, random factor, tip, liquid, therm, dynamic properties"
Paper_00741,A comprehensive set of sequence analysis programs for the VAX,"['John Devereux', 'Paul Haeberli', 'Oliver Smithies']",1984,Nucleic Acids Research,Journal,,387-395,12,1Part1,10.1093/nar/12.1part1.387,"The University of Wisconsin Genetics Computer Group (UWGCG) has been organized to develop computational tools for the analysis and publication of biological sequence data.A group of programs that will interact with each other has been developed for the Digital Equipment Corporation VAX computer using the VMS operating system.The programs available and the conditions for transfer are described. DESIGN PRINCIPLESUWGCG program design is based on the ""software tools"" approach of Kernighan and Plauger(l).Each program performs a simple function and is easy to use.The programs can be used independently in different combinations so","['Biology', 'Sequence (biology)', 'Set (abstract data type)', 'Sequence analysis', 'Digital computer', 'Sequence alignment', 'Group (periodic table)', 'Computational biology', 'Genetics', 'Computer science', 'Programming language', 'Peptide sequence', 'Gene', 'Computer engineering', 'Chemistry', 'Organic chemistry']","university, u, biological sequence data, digital equipment corporation vax computer, vms, software tools"
Paper_00676,"Research Design: Qualitative, Quantitative, and Mixed Methods Approaches",['Atlanta Sloane-Seale'],2009,Canadian Journal of University Continuing Education,Journal,,,35,2,10.21225/d54s3d,"Given the increased use of qualitative and mixed methods, and the continued use of quantitative methods, Creswell's third edition of Research Design: Qualitative, Quantitative, and Mixed Methods Approaches is most timely.He not only compares and contrasts these approaches but also promotes a framework, a process, and strategies for the design and conduct of research in the human and social sciences.The book has two parts.The four chapters that make up Part 1, ""Preliminary Considerations,"" describe the basic elements of a research undertaking, such as philosophical assumptions, the literature review, the use of theory, and the writing style and ethics.The six chapters in Part 2, ""Designing Research,"" elaborate on the design components of research, such as the introduction, the research purpose, research questions and problems, and methods and procedures for data collection and analysis.","['Management science', 'Multimethodology', 'Research design', 'Qualitative research', 'Psychology', 'Sociology', 'Engineering ethics', 'Mathematics education', 'Social science', 'Engineering']","mixed methods, quantitative methods, research design, mixed methods, philosophical assumptions, literature review, writing, ethics, data collection"
Paper_00678,Ror2 signaling regulates Golgi structure and transport through IFT20 for tumor invasiveness,"['Michiru Nishita', 'Seung‐Yeol Park', 'Tadashi Nishio', 'Koki Kamizaki', 'Zhichao Wang', 'Kota Tamada', 'Toru Takumi', 'Ryuju Hashimoto', 'Hiroki Otani', 'Gregory J. Pazour', 'Victor W. Hsu', 'Yasuhiro Minami']",2017,Scientific Reports,Journal,,,7,1,10.1038/s41598-016-0028-x,"Signaling through the Ror2 receptor tyrosine kinase promotes invadopodia formation for tumor invasion. Here, we identify intraflagellar transport 20 (IFT20) as a new target of this signaling in tumors that lack primary cilia, and find that IFT20 mediates the ability of Ror2 signaling to induce the invasiveness of these tumors. We also find that IFT20 regulates the nucleation of Golgi-derived microtubules by affecting the GM130-AKAP450 complex, which promotes Golgi ribbon formation in achieving polarized secretion for cell migration and invasion. Furthermore, IFT20 promotes the efficiency of transport through the Golgi complex. These findings shed new insights into how Ror2 signaling promotes tumor invasiveness, and also advance the understanding of how Golgi structure and transport can be regulated.","['Golgi apparatus', 'Cell biology', 'Cilium', 'Biology', 'Endoplasmic reticulum']","ror, invadopodia formation, tumor invasion, intraflagellar transport 20, ift20, primary cilia, ift, ro, ift, go, ##gi ribbon formation, polarized secretion, cell migration, ift, ror, tumor invasiveness, ##gi, [PAD]"
Paper_00679,<i>Ab initio</i> effective core potentials for molecular calculations. Potentials for K to Au including the outermost core orbitals,"['P. Jeffrey Hay', 'Willard R. Wadt']",1985,The Journal of Chemical Physics,Journal,,299-310,82,1,10.1063/1.448975,"Ab initio effective core potentials (ECP’s) have been generated to replace the innermost core electron for third-row (K–Au), fourth-row (Rb–Ag), and fifth-row (Cs–Au) atoms. The outermost core orbitals—corresponding to the ns2np6 configuration for the three rows here—are not replaced by the ECP but are treated on an equal footing with the nd, (n+1)s and (n+1)p valence orbitals. These ECP’s have been derived for use in molecular calculations where these outer core orbitals need to be treated explicitly rather than to be replaced by an ECP. The ECP’s for the forth and fifth rows also incorporate the mass–velocity and Darwin relativistic effects into the potentials. Analytic fits to the potentials are presented for use in multicenter integral evaluation. Gaussian orbital valence basis sets are developed for the (3s, 3p, 3d, 4s, 4p), (4s, 4p, 4d, 5s, 5p), and (5s, 5p, 5d, 6s, 6p) ortibals of the three respective rows.","['Atomic orbital', 'Molecular orbital', 'Valence (chemistry)', 'Atomic physics', 'Core electron', 'Physics', 'Core (optical fiber)', 'Row', 'Molecular orbital theory', 'Ab initio', 'Chemistry', 'Electron', 'Molecular physics', 'Molecule', 'Quantum mechanics', 'Database', 'Computer science', 'Optics']","effective core potentials, innermost core electron, outermost core orbitals, molecular calculations, mass – velocity, darwin relativistic effects, multicenter integral evaluation, gaussian orbital valence basis sets"
Paper_00680,MAFFT: a novel method for rapid multiple sequence alignment based on fast Fourier transform,['Kazutaka Katoh'],2002,Nucleic Acids Research,Journal,,3059-3066,30,14,10.1093/nar/gkf436,"A multiple sequence alignment program, MAFFT, has been developed. The CPU time is drastically reduced as compared with existing methods. MAFFT includes two novel techniques. (i) Homo logous regions are rapidly identified by the fast Fourier transform (FFT), in which an amino acid sequence is converted to a sequence composed of volume and polarity values of each amino acid residue. (ii) We propose a simplified scoring system that performs well for reducing CPU time and increasing the accuracy of alignments even for sequences having large insertions or extensions as well as distantly related sequences of similar length. Two different heuristics, the progressive method (FFT‐NS‐2) and the iterative refinement method (FFT‐NS‐i), are implemented in MAFFT. The performances of FFT‐NS‐2 and FFT‐NS‐i were compared with other methods by computer simulations and benchmark tests; the CPU time of FFT‐NS‐2 is drastically reduced as compared with CLUSTALW with comparable accuracy. FFT‐NS‐i is over 100 times faster than T‐COFFEE, when the number of input sequences exceeds 60, without sacrificing the accuracy.","['Fast Fourier transform', 'Computer science', 'Multiple sequence alignment', 'Split-radix FFT algorithm', 'Sequence (biology)', 'Parallel computing', 'Benchmark (surveying)', 'Algorithm', 'Heuristics', 'Sequence alignment', 'Fourier transform', 'Computational science', 'Biology', 'Mathematics', 'Peptide sequence', 'Fourier analysis', 'Short-time Fourier transform', 'Mathematical analysis', 'Biochemistry', 'Genetics', 'Geodesy', 'Gene', 'Geography', 'Operating system']","multiple sequence alignment program, mafft, cpu time, mafft, homo logous regions, fast fourier transform, polarity, progressive method, ff, iterative refinement method, ff, ##ff, computer simulations, benchmark tests, ##ustal, [PAD] [PAD], [PAD] [PAD] [PAD], [PAD]"
Paper_00683,A More Accurate Method To Estimate Glomerular Filtration Rate from Serum Creatinine: A New Prediction Equation,"['Andrew S. Levey', 'Juan Bosch', 'Julia B. Lewis', 'Tom Greene', 'Nancy Rogers', 'David A. Roth']",1999,Annals of Internal Medicine,Journal,,461-461,130,6,10.7326/0003-4819-130-6-199903160-00002,"Background: Serum creatinine concentration is widely used as an index of renal function, but this concentration is affected by factors other than glomerular filtration rate (GFR). Objective: To develop an equation to predict GFR from serum creatinine concentration and other factors. Design: Cross-sectional study of GFR, creatinine clearance, serum creatinine concentration, and demographic and clinical characteristics in patients with chronic renal disease. Patients: 1628 patients enrolled in the baseline period of the Modification of Diet in Renal Disease (MDRD) Study, of whom 1070 were randomly selected as the training sample; the remaining 558 patients constituted the validation sample. Methods: The prediction equation was developed by stepwise regression applied to the training sample. The equation was then tested and compared with other prediction equations in the validation sample. Results: To simplify prediction of GFR, the equation included only demographic and serum variables. Independent factors associated with a lower GFR included a higher serum creatinine concentration, older age, female sex, nonblack ethnicity, higher serum urea nitrogen levels, and lower serum albumin levels (P < 0.001 for all factors). The multiple regression model explained 90.3% of the variance in the logarithm of GFR in the validation sample. Measured creatinine clearance overestimated GFR by 19%, and creatinine clearance predicted by the Cockcroft-Gault formula overestimated GFR by 16%. After adjustment for this overestimation, the percentage of variance of the logarithm of GFR predicted by measured creatinine clearance or the Cockcroft-Gault formula was 86.6% and 84.2%, respectively. Conclusion: The equation developed from the MDRD Study provided a more accurate estimate of GFR in our study group than measured creatinine clearance or other commonly used equations. *For members of the Modification of Diet in Renal Disease Study Group, see N Engl J Med. 1994; 330:877-84.","['Creatinine', 'Renal function', 'Medicine', 'Urology', 'Stepwise regression', 'Kidney disease', 'Linear regression', 'Internal medicine', 'Endocrinology', 'Statistics', 'Mathematics']","serum creatinine concentration, renal function, glomerular filtration rate, serum cr, creatinine, serum cr, chronic renal disease, prediction, stepwise regression, female sex, ##bla, multiple regression model, renal"
Paper_00684,Mining association rules between sets of items in large databases,"['Rakesh Agrawal', 'Tomasz Imieliński', 'Arun Swami']",1993,Unknown,Unknown,,,,,10.1145/170035.170072,"We are given a large database of customer transactions. Each transaction consists of items purchased by a customer in a visit. We present an efficient algorithm that generates all significant association rules between items in the database. The algorithm incorporates buffer management and novel estimation and pruning techniques. We also present results of applying this algorithm to sales data obtained from a large retailing company, which shows the effectiveness of the algorithm.","['Association rule learning', 'Database transaction', 'Computer science', 'Pruning', 'Database', 'Data mining', 'Apriori algorithm', 'Transaction data', 'Data warehouse', 'Association (psychology)', 'Affinity analysis', 'Transaction processing', 'Information retrieval', 'Philosophy', 'Epistemology', 'Agronomy', 'Biology']","customer transactions, association rules, buffer management, pruning techniques, sales data, retail, [PAD], [PAD]"
Paper_00685,Refinement of Macromolecular Structures by the Maximum-Likelihood Method,"['Garib N. Murshudov', 'A. A. Vagin', 'E. J. Dodson']",1997,Acta Crystallographica Section D Biological Crystallography,Journal,,240-255,53,3,10.1107/s0907444996012255,"This paper reviews the mathematical basis of maximum likelihood. The likelihood function for macromolecular structures is extended to include prior phase information and experimental standard uncertainties. The assumption that different parts of a structure might have different errors is considered. A method for estimating σA using `free' reflections is described and its effects analysed. The derived equations have been implemented in the program REFMAC. This has been tested on several proteins at different stages of refinement (bacterial α-amylase, cytochrome c′, cross-linked insulin and oligopeptide binding protein). The results derived using the maximum-likelihood residual are consistently better than those obtained from least-squares refinement.","['Maximum likelihood', 'Likelihood function', 'Function (biology)', 'Mathematics', 'Basis (linear algebra)', 'Least-squares function approximation', 'Residual', 'Applied mathematics', 'Macromolecule', 'Statistics', 'Computer science', 'Algorithm', 'Chemistry', 'Biology', 'Geometry', 'Biochemistry', 'Evolutionary biology', 'Estimator']","mathematical basis, maximum likelihood, likelihood function, macromolecular structures, prior phase information, σ, refmac, ##to, oligopeptide binding protein"
Paper_00688,Prokka: rapid prokaryotic genome annotation,['Torsten Seemann'],2014,Bioinformatics,Journal,,2068-2069,30,14,10.1093/bioinformatics/btu153,"The multiplex capability and high yield of current day DNA-sequencing instruments has made bacterial whole genome sequencing a routine affair. The subsequent de novo assembly of reads into contigs has been well addressed. The final step of annotating all relevant genomic features on those contigs can be achieved slowly using existing web- and email-based systems, but these are not applicable for sensitive data or integrating into computational pipelines. Here we introduce Prokka, a command line software tool to fully annotate a draft bacterial genome in about 10 min on a typical desktop computer. It produces standards-compliant output files for further analysis or viewing in genome browsers.Prokka is implemented in Perl and is freely available under an open source GPLv2 license from http://vicbioinformatics.com/.","['Perl', 'Computer science', 'Genome', 'Contig', 'Annotation', 'MIT License', 'Software', 'Sequence assembly', 'Genome project', 'Bacterial genome size', 'Computational biology', 'Open source', 'World Wide Web', 'Biology', 'Genetics', 'Programming language', 'Artificial intelligence', 'Gene', 'Gene expression', 'Transcriptome']","multiplex, bacterial whole genome sequencing, con, ##gs, gen, prokka, command, prokka, vicbioinform"
Paper_00689,Numerical optimization,"['W. John Braun', 'Duncan J. Murdoch']",2021,Cambridge University Press eBooks,Unknown,,222-247,,,10.1017/9781108993456.011,"This third edition of Braun and Murdoch's bestselling textbook now includes discussion of the use and design principles of the tidyverse packages in R, including expanded coverage of ggplot2, and R Markdown. The expanded simulation chapter introduces the Box–Muller and Metropolis–Hastings algorithms. New examples and exercises have been added throughout. This is the only introduction you'll need to start programming in R, the computing standard for analyzing data. This book comes with real R code that teaches the standards of the language. Unlike other introductory books on the R system, this book emphasizes portable programming skills that apply to most computing languages and techniques used to develop more complex projects. Solutions, datasets, and any errata are available from www.statprogr.science. Worked examples - from real applications - hundreds of exercises, and downloadable code, datasets, and solutions make a complete package for anyone working in or learning practical data science.","['Computer science', 'Code (set theory)', 'Programming language', 'Software engineering', 'Set (abstract data type)']","tidyverse packages, ggplot, r, hastings algorithms, real r code, portable programming skills, data"
Paper_00690,Toward a knowledge‐based theory of the firm,['Robert M. Grant'],1996,Strategic Management Journal,Journal,,109-122,17,S2,10.1002/smj.4250171110,"Abstract Given assumptions about the characteristics of knowledge and the knowledge requirements of production, the firm is conceptualized as an institution for integrating knowledge. The primary contribution of the paper is in exploring the coordination mechanisms through which firms integrate the specialist knowledge of their members. In contrast to earlier literature, knowledge is viewed as residing within the individual, and the primary role of the organization is knowledge application rather than knowledge creation. The resulting theory has implications for the basis of organizational capability, the principles of organization design (in particular, the analysis of hierarchy and the distribution of decision‐making authority), and the determinants of the horizontal and vertical boundaries of the firm. More generally, the knowledge‐based approach sheds new light upon current organizational innovations and trends and has far‐reaching implications for management practice.","['Hierarchy', 'Knowledge management', 'Organizational learning', 'Knowledge value chain', 'Business', 'Institution', 'Body of knowledge', 'Contrast (vision)', 'Computer science', 'Sociology', 'Economics', 'Social science', 'Artificial intelligence', 'Market economy']","knowledge, knowledge requirements, coordination mechanisms, specialist knowledge, knowledge application, knowledge creation, organizational capability, organization design, hierarchy, organizational, management practice"
Paper_00691,Parallel Distributed Processing,"['David E. Rumelhart', 'James L. McClelland']",1986,Unknown,Unknown,,,,,10.7551/mitpress/5236.001.0001,"What makes people smarter than computers? These volumes by a pioneering neurocomputing group suggest that the answer lies in the massively parallel architecture of the human mind. They describe a new theory of cognition called connectionism that is challenging the idea of symbolic computation that has traditionally been at the center of debate in theoretical discussions about the mind. The authors' theory assumes the mind is composed of a great number of elementary units connected in a neural network. Mental processes are interactions between these units which excite and inhibit each other in parallel rather than sequential operations. In this context, knowledge can no longer be thought of as stored in localized structures; instead, it consists of the connections between pairs of units that are distributed throughout the network. Volume 1 lays the foundations of this exciting theory of parallel distributed processing, while Volume 2 applies it to a number of specific issues in cognitive science and neuroscience, with chapters describing models of aspects of perception, memory, language, and thought.","['Connectionism', 'Cognitive science', 'Computer science', 'Context (archaeology)', 'Cognition', 'Perception', 'Cognitive architecture', 'Massively parallel', 'Artificial intelligence', 'Artificial neural network', 'Psychology', 'Neuroscience', 'Parallel computing', 'Paleontology', 'Biology']","neurocomputing, massively parallel architecture, human mind, cognition, connectionism, symbolic computation, neural network, mental, parallel distributed processing, cognitive science, neuroscience, perception, memory, language, thought"
Paper_00692,LINCS: A linear constraint solver for molecular simulations,"['Berk Hess', 'Henk Bekker', 'Herman J. C. Berendsen', 'J. G. E. M. Fraaije']",1997,Journal of Computational Chemistry,Journal,,1463-1472,18,12,10.1002/(sici)1096-987x(199709)18:12<1463::aid-jcc4>3.0.co;2-h,"In this article, we present a new LINear Constraint Solver (LINCS) for molecular simulations with bond constraints. The algorithm is inherently stable, as the constraints themselves are reset instead of derivatives of the constraints, thereby eliminating drift. Although the derivation of the algorithm is presented in terms of matrices, no matrix matrix multiplications are needed and only the nonzero matrix elements have to be stored, making the method useful for very large molecules. At the same accuracy, the LINCS algorithm is three to four times faster than the SHAKE algorithm. Parallelization of the algorithm is straightforward. © 1997 John Wiley & Sons, Inc. J Comput Chem 18: 1463–1472, 1997","['Solver', 'Matrix (chemical analysis)', 'Reset (finance)', 'Constraint (computer-aided design)', 'Algorithm', 'Computer science', 'Matrix multiplication', 'Shake', 'Mathematical optimization', 'Parallel computing', 'Mathematics', 'Chemistry', 'Physics', 'Chromatography', 'Quantum mechanics', 'Astronomy', 'Financial economics', 'Economics', 'Quantum', 'Geometry']","linear constraint solver, lincs, molecular simulations, bond constraints, matrices, matrix matrix multiplications, nonzero matrix elements, lincs, shake algorithm"
Paper_00693,DNA primers for amplification of mitochondrial cytochrome c oxidase subunit I from diverse metazoan invertebrates.,"['OLE FOLMER', 'Michael B. Black', 'Walter R. Hoeh', 'Richard A. Lutz', 'Robert C. Vrijenhoek']",1994,['Database'],Unknown,,294-9,2022,5,10.1093/database/baab084,"We describe ""universal"" DNA primers for polymerase chain reaction (PCR) amplification of a 710-bp fragment of the mitochondrial cytochrome c oxidase subunit I gene (COI) from 11 invertebrate phyla: Echinodermata, Mollusca, Annelida, Pogonophora, Arthropoda, Nemertinea, Echiura, Sipuncula, Platyhelminthes, Tardigrada, and Coelenterata, as well as the putative phylum Vestimentifera. Preliminary comparisons revealed that these COI primers generate informative sequences for phylogenetic analyses at the species and higher taxonomic levels.","['Biology', 'Phylum', 'Mitochondrial DNA', 'Cytochrome c oxidase subunit I', 'Cytochrome c oxidase', 'Phylogenetic tree', 'Invertebrate', 'DNA barcoding', 'Zoology', 'Marine invertebrates', 'Cytochrome b', 'Phylogenetics', 'Gene', 'Evolutionary biology', 'Genetics', 'Mitochondrion', 'Ecology']","universal, dna primers, polymerase chain reaction, mitochondrial, inverteb, echinodermata, mollusca, annelid, pogonophora, arthropoda, nemertine, echiura, sipuncula, platyhelminthes, tardigrad, coelenterata, put"
Paper_00694,Nonlinear Dimensionality Reduction by Locally Linear Embedding,"['Sam T. Roweis', 'Lawrence K. Saul']",2000,Science,Journal,,2323-2326,290,5500,10.1126/science.290.5500.2323,"Many areas of science depend on exploratory data analysis and visualization. The need to analyze large amounts of multivariate data raises the fundamental problem of dimensionality reduction: how to discover compact representations of high-dimensional data. Here, we introduce locally linear embedding (LLE), an unsupervised learning algorithm that computes low-dimensional, neighborhood-preserving embeddings of high-dimensional inputs. Unlike clustering methods for local dimensionality reduction, LLE maps its inputs into a single global coordinate system of lower dimensionality, and its optimizations do not involve local minima. By exploiting the local symmetries of linear reconstructions, LLE is able to learn the global structure of nonlinear manifolds, such as those generated by images of faces or documents of text.","['Dimensionality reduction', 'Nonlinear dimensionality reduction', 'Maxima and minima', 'Embedding', 'Cluster analysis', 'Isomap', 'Curse of dimensionality', 'Computer science', 'Reduction (mathematics)', 'Diffusion map', 'Visualization', 'Artificial intelligence', 'Pattern recognition (psychology)', 'Nonlinear system', 'Algorithm', 'Mathematics', 'Physics', 'Mathematical analysis', 'Geometry', 'Quantum mechanics']","##oratory data analysis, visualization, multivariate data, dimensionality reduction, compact representations, locally linear embedding, ##pervised learning algorithm, clustering, local dimensionality reduction, global coordinate system, local minima, local symmetries, linear reconstructions, global structure, nonlinear manifolds, [PAD], [PAD] [PAD], [PAD] [PAD]"
Paper_00697,The Location of Culture,['Homi Κ. Bhabha'],1994,Unknown,Unknown,,,,,10.4324/9780203820551,"Acknowledgements, Introduction: Locations of culture, 1. The commitment to theory, 2. Interrogating identity: Frantz Fanon and the postcolonial prerogative, 3. The other question: Stereotype, discrimination and the discourse of colonialism, 4. Of mimicry and man: The ambivalence of colonial discourse, 5. Sly civility, 6. Signs taken for wonders: Questions of ambivalence and authority under a tree outside Delhi, May 1817, 7. Articulating the archaic: Cultural difference and colonial nonsense, 8. DissemiNation: Time, narrative and the margins of the modern nation, 9. The postcolonial and the postmodern: The question of agency, 10. By bread alone: Signs of violence in the mid-nineteenth century, 11. How newness enters the world: Postmodern space, postcolonial times and the trials of cultural translation, 12. Conclusion: 'Race', time and the revision of modernity, Notes, Index.","['Civility', 'Postmodernism', 'Ambivalence', 'Colonialism', 'Modernity', 'Aesthetics', 'Gender studies', 'Sociology', 'Narrative', 'Agency (philosophy)', 'Identity (music)', 'Anthropology', 'Literature', 'Art', 'Social science', 'Political science', 'Psychoanalysis', 'Politics', 'Law', 'Psychology']","##ro, identity, postcolonial pre, stereotype, discrimination, colonialism, mimicry, man, colonial discourse, sly civility, ##nce, cultural difference, colonial nonsense, dissemination, ##l, ##modern, agency, ##ness, ##modern space, postcolonial times, cultural translation, time"
Paper_00698,Multiresolution gray-scale and rotation invariant texture classification with local binary patterns,"['Timo Ojala', 'Matti Pietikäinen', 'Topi Mäenpää']",2002,IEEE Transactions on Pattern Analysis and Machine Intelligence,Journal,,971-987,24,7,10.1109/tpami.2002.1017623,"Presents a theoretically very simple, yet efficient, multiresolution approach to gray-scale and rotation invariant texture classification based on local binary patterns and nonparametric discrimination of sample and prototype distributions. The method is based on recognizing that certain local binary patterns, termed ""uniform,"" are fundamental properties of local image texture and their occurrence histogram is proven to be a very powerful texture feature. We derive a generalized gray-scale and rotation invariant operator presentation that allows for detecting the ""uniform"" patterns for any quantization of the angular space and for any spatial resolution and presents a method for combining multiple operators for multiresolution analysis. The proposed approach is very robust in terms of gray-scale variations since the operator is, by definition, invariant against any monotonic transformation of the gray scale. Another advantage is computational simplicity as the operator can be realized with a few operations in a small neighborhood and a lookup table. Experimental results demonstrate that good discrimination can be achieved with the occurrence statistics of simple rotation invariant local binary patterns.","['Pattern recognition (psychology)', 'Artificial intelligence', 'Mathematics', 'Local binary patterns', 'Histogram', 'Invariant (physics)', 'Binary number', 'Scale invariance', 'Algorithm', 'Computer science', 'Computer vision', 'Image (mathematics)', 'Statistics', 'Arithmetic', 'Mathematical physics']","##res, rotation invariant texture classification, local binary patterns, nonparametric discrimination, prototype distributions, local binary patterns, local image texture, occurrence his, rotation, spatial resolution, multiresolution analysis, monotonic transformation, ##up, occurrence statistics, rotation invariant local binary patterns"
Paper_00699,THE GENETICS OF <i>CAENORHABDITIS ELEGANS</i>,['Sydney Brenner'],1974,Genetics,Journal,,71-94,77,1,10.1093/genetics/77.1.71,"ABSTRACT Methods are described for the isolation, complementation and mapping of mutants of Caenorhabditis elegans, a small free-living nematode worm. About 300 EMS-induced mutants affecting behavior and morphology have been characterized and about one hundred genes have been defined. Mutations in 77 of these alter the movement of the animal. Estimates of the induced mutation frequency of both the visible mutants and X chromosome lethals suggests that, just as in Drosophila, the genetic units in C.elegans are large.","['Biology', 'Caenorhabditis elegans', 'Complementation', 'Genetics', 'Mutant', 'Caenorhabditis', 'Mutation', 'Gene', 'Drosophila (subgenus)', 'Chromosome']","ca, ##rh, ##ditis, induced mutation frequency, x chromosome lethals, [PAD]"
Paper_00701,"Risk, Return, and Equilibrium: Empirical Tests","['Eugene F. Fama', 'James D. MacBeth']",1973,Journal of Political Economy,Journal,,607-636,81,3,10.1086/260061,"This paper tests the relationship between average return and risk for New York Stock Exchange common stocks. The theoretical basis of the tests is the ""two-parameter"" portfolio model and models of market equilibrium derived from the two-parameter portfolio model. We cannot reject the hypothesis of these models that the pricing of common stocks reflects the attempts of risk-averse investors to hold portfolios that are ""efficient"" in terms of expected value and dispersion of return. Moreover, the observed ""fair game"" properties of the coefficients and residuals of the risk-return regressions are consistent with an ""efficient capital market""--that is, a market where prices of securities","['Economics', 'Econometrics', 'Portfolio', 'Expected return', 'Capital asset pricing model', 'Risk–return spectrum', 'Market portfolio', 'Stock exchange', 'Financial economics', 'Market risk', 'Rate of return on a portfolio', 'Modern portfolio theory', 'Finance']","average return, new york stock exchange common stocks, market equilibrium, common stocks, expected value, dispersion of, fair game"
Paper_00702,"<scp>CHARMM</scp>: A program for macromolecular energy, minimization, and dynamics calculations","['Bernard R. Brooks', 'Robert E. Bruccoleri', 'Barry D. Olafson', 'David J. States', 'S. Swaminathan', 'Martin Karplus']",1983,Journal of Computational Chemistry,Journal,,187-217,4,2,10.1002/jcc.540040211,"Abstract CHARMM ( C hemistry at HAR vard M acromolecular M echanics) is a highly flexible computer program which uses empirical energy functions to model macromolecular systems. The program can read or model build structures, energy minimize them by first‐ or second‐derivative techniques, perform a normal mode or molecular dynamics simulation, and analyze the structural, equilibrium, and dynamic properties determined in these calculations. The operations that CHARMM can perform are described, and some implementation details are given. A set of parameters for the empirical energy function and a sample run are included.","['Computer science', 'Molecular dynamics', 'Statistical physics', 'Computational chemistry', 'Chemistry', 'Physics']","abstract charmm, ##ist, echanics, empirical energy functions, macromolecular systems, normal mode, molecular dynamics simulation, dynamic properties, charm, empirical energy function"
Paper_00703,Social Research Methods,"['Kevin M. G. Taylor', 'Sarah Nettleton', 'Geoffrey Harding']",2010,Taylor & Francis eBooks,Unknown,,157-184,,,10.4324/9780203381175_chapter_9,"Sociology for Pharmacists: An Introduction is written specifically for professionals and students in pharmacy who are newcomers to the study of sociology. It introduces the key concepts of sociology and demonstrates their importance and application to pharmacy practice in the 21st century. It is unique in its role as the only text to introduce sociology specifically to pharmacists. Rather than an exhaustive treatment, the book provides a concise introduction to major perspectives in sociology-drawing on research evidence pertaining to health, illness, and professional practice-which will inform and enhance pharmacy practice. It offers an overview of sociology for rather than sociology of pharmacy, and will both inform practitioners and stimulate informed research into the social aspects of pharmacy practice.Key issues covered include:Key sociological concepts and perspectives Contemporary developments in pharmacy practice and pharmacy's professional statusA review of research into the way people react to illness and look after their healthHow and why illness and disease are influenced by gender, ethnicity, and social class Health education and pharmacists' role in promoting health and ensuring appropriate medicine usageSocial research methodsPharmacists are frequently encouraged to broaden their day-to-day practice. This timely book does just that by encouraging pharmacists to become more involved with advising clients, managing medicines, and supporting the promotion of health. In addition to providing an overview of these topics, the book also reviews the relevant research, and directs readers to further information.","['Sociology', 'Computer science']","sociology, pharmacists, pharmacy, sociology, sociology, pharmacy practice, ph, ##ac, professional practice, pharmacy practice, pharmacy, pharmacy, pharmacy, gender, social class, ph, ##acists"
Paper_00704,Structure validation in chemical crystallography,['Anthony L. Spek'],2009,Acta Crystallographica Section D Biological Crystallography,Journal,,148-155,65,2,10.1107/s090744490804362x,"Automated structure validation was introduced in chemical crystallography about 12 years ago as a tool to assist practitioners with the exponential growth in crystal structure analyses. Validation has since evolved into an easy-to-use checkCIF/PLATON web-based IUCr service. The result of a crystal structure determination has to be supplied as a CIF-formatted computer-readable file. The checking software tests the data in the CIF for completeness, quality and consistency. In addition, the reported structure is checked for incomplete analysis, errors in the analysis and relevant issues to be verified. A validation report is generated in the form of a list of ALERTS on the issues to be corrected, checked or commented on. Structure validation has largely eliminated obvious problems with structure reports published in IUCr journals, such as refinement in a space group of too low symmetry. This paper reports on the current status of structure validation and possible future extensions.","['Computer science', 'Consistency (knowledge bases)', 'Data structure', 'Completeness (order theory)', 'Data mining', 'Software', 'Information retrieval', 'Algorithm', 'Programming language', 'Artificial intelligence', 'Mathematics', 'Mathematical analysis']","automated structure validation, chemical crystallography, crystal structure analyses, crystal structure determination, validation report, structure validation, iucr, space group, structure validation, [PAD]"
Paper_00706,The Postmodern Condition: A Report on Knowledge,"['Jean-François Lyotard', 'Geoff Bennington', 'Brian Massumi']",1984,Poetics Today,Journal,,886-886,5,4,10.2307/1772278,"Many definitions of postmodernism focus on its nature as the aftermath of the modern industrial age when technology developed. This book extends that analysis to postmodernism by looking at the status of science, technology, and the arts, the significance of technocracy, and the way the flow of information is controlled in the Western world.","['Postmodernism', 'Aesthetics', 'Art', 'History', 'Literature']","postmodernism, postmodernism, arts, technocracy, [PAD], [PAD]"
Paper_00707,Theory Building From Cases: Opportunities And Challenges,"['Kathleen M. Eisenhardt', 'Melissa E. Graebner']",2007,Academy of Management Journal,Journal,,25-32,50,1,10.5465/amj.2007.24160888,"This article discusses the research strategy of theory building from cases, particularly multiple cases. Such a strategy involves using one or more cases to create theoretical constructs, propositions, and/or midrange theory from case-based, empirical evidence. Replication logic means that each case serves as a distinct experiment that stands on its own merits as an analytic unit. The frequent use of case studies as a research strategy has given rise to some challenges that can be mitigated by the use of very precise wording and thoughtful research design.","['Management science', 'Replication (statistics)', 'Organizational theory', 'Computer science', 'Empirical research', 'Positive economics', 'Knowledge management', 'Sociology', 'Economics', 'Epistemology', 'Management', 'Philosophy', 'Statistics', 'Mathematics']","theory building, ##s, replication logic, case studies, thoughtful research design"
Paper_00708,Distributed Representations of Words and Phrases and their Compositionality,"['Tomáš Mikolov', 'Ilya Sutskever', 'Kai Chen', 'Greg S. Corrado', 'Jeff Dean']",2013,['Proceedings of the 1st Workshop on Vector Space Modeling for Natural Language Processing'],Conference,"Proceedings of the 1st Workshop on Vector Space Modeling for Natural Language Processing, Denver, Colorado",8-16,26,,10.3115/v1/w15-1502,"The recently introduced continuous Skip-gram model is an efficient method for learning high-quality distributed vector representations that capture a large number of precise syntactic and semantic word relationships. In this paper we present several extensions that improve both the quality of the vectors and the training speed. By subsampling of the frequent words we obtain significant speedup and also learn more regular word representations. We also describe a simple alternative to the hierarchical softmax called negative sampling.

An inherent limitation of word representations is their indifference to word order and their inability to represent idiomatic phrases. For example, the meanings of Canada and cannot be easily combined to obtain Air Canada. Motivated by this example, we present a simple method for finding phrases in text, and show that learning good vector representations for millions of phrases is possible.","['Computer science', 'Principle of compositionality', 'Softmax function', 'Word (group theory)', 'Natural language processing', 'Artificial intelligence', 'Simple (philosophy)', 'Semantics (computer science)', 'Quality (philosophy)', 'Speedup', 'Linguistics', 'Artificial neural network', 'Philosophy', 'Epistemology', 'Programming language', 'Operating system']","semantic word relationships, frequent words, regular word representations, hierarchical softmax, negative sampling, word representations, word order, idiomatic phrases, air canada, vector representations"
Paper_00709,The 1982 revised criteria for the classification of systemic lupus erythematosus,"['Eng M. Tan', 'Alan S. Cohen', 'James F. Fries', 'Alfonse T. Masi', 'Dennis J. McShane', 'Naomi F. Rothfield', 'Jane G. Schaller', 'Norman Talal', 'Robert Winchester']",1982,Arthritis & Rheumatism,Journal,,1271-1277,25,11,10.1002/art.1780251101,"The 1971 preliminary criteria for the classification of systemic lupus erythematosus (SLE) were revised and updated to incorporate new immunologic knowledge and improve disease classification. The 1982 revised criteria include fluorescence antinuclear antibody and antibody to native DNA and Sm antigen. Some criteria involving the same organ systems were aggregated into single criteria. Raynaud's phenomenon and alopecia were not included in the 1982 revised criteria because of low sensitivity and specificity. The new criteria were 96% sensitive and 96% specific when tested with SLE and control patient data gathered from 18 participating clinics. When compared with the 1971 criteria, the 1982 revised criteria showed gains in sensitivity and specificity.","['Medicine', 'Anti-nuclear antibody', 'Lupus erythematosus', 'Immunology', 'Dermatology', 'Systemic lupus erythematosus', 'Antibody', 'Disease', 'Internal medicine', 'Autoantibody']","systemic lupus erythematosus, sl, disease classification, fluorescence antinuclear antibody, native dna, sm, alopecia, ##ity, specificity"
Paper_00710,Self—Consistent Molecular Orbital Methods. XII. Further Extensions of Gaussian—Type Basis Sets for Use in Molecular Orbital Studies of Organic Molecules,"['Warren J. Hehre', 'R. Ditchfield', 'John A. Pople']",1972,The Journal of Chemical Physics,Journal,,2257-2261,56,5,10.1063/1.1677527,"Two extended basis sets (termed 5–31G and 6–31G) consisting of atomic orbitals expressed as fixed linear combinations of Gaussian functions are presented for the first row atoms carbon to fluorine. These basis functions are similar to the 4–31G set [J. Chem. Phys. 54, 724 (1971)] in that each valence shell is split into inner and outer parts described by three and one Gaussian function, respectively. Inner shells are represented by a single basis function taken as a sum of five (5–31G) or six (6–31G) Gaussians. Studies with a number of polyatomic molecules indicate a substantial lowering of calculated total energies over the 4–31G set. Calculated relative energies and equilibrium geometries do not appear to be altered significantly.","['STO-nG basis sets', 'Basis set', 'Gaussian', 'Molecular orbital', 'Valence (chemistry)', 'Atomic orbital', 'Basis (linear algebra)', 'Fragment molecular orbital', 'Polyatomic ion', 'Chemistry', 'Computational chemistry', 'Slater-type orbital', 'Molecule', 'Atomic physics', 'Gaussian orbital', 'Basis function', 'Function (biology)', 'Non-bonding orbital', 'Molecular physics', 'Molecular orbital theory', 'Physics', 'Quantum mechanics', 'Mathematics', 'Geometry', 'Density functional theory', 'Electron', 'Evolutionary biology', 'Biology']","extended basis sets, atomic orbitals, gaussian functions, valence shell, ##ussian function, polyatomic molecules, equilibrium geometries"
Paper_00711,Stigma: Notes on the Management of Spoiled Identity,['Erving Goffman'],1969,Postgraduate Medical Journal,Journal,,642-642,45,527,10.1136/pgmj.45.527.642,CONTENTS 1. Stigma and Social Identity Preliminary Conceptions The Own and the Wise Moral Career 2. Information Control and Personal Identity The Discredited and the Discreditable Social Information Visibility Personal Identity Biography Biographical Others Passing Techniques of Information Control Covering 3. Group Alignment and Ego Identity Ambivalence Professional Presentations In-Group Alignments Out-Group Alignments The Politics of Identity 4. The Self and Its Other Deviations and Norms The Normal Deviant Stigma and Reality 5. Deviations and Deviance,"['Medicine', 'Identity (music)', 'Identity management', 'Bioinformatics', 'Computer security', 'Aesthetics', 'Computer science', 'Philosophy', 'Access control', 'Biology']","stigma, social identity, information control, personal identity, information control, group alignment, ego identity, identity, self, deviant stigma, deviations, deviance, [PAD]"
Paper_00712,How Many Interviews Are Enough?,"['Greg Guest', 'Arwen Bunce', 'Laura Johnson']",2005,Field Methods,Journal,,59-82,18,1,10.1177/1525822x05279903,"Guidelines for determining nonprobabilistic sample sizes are virtually nonexistent. Purposive samples are the most commonly used form of nonprobabilistic sampling, and their size typically relies on the concept of “saturation,” or the point at which no new information or themes are observed in the data. Although the idea of saturation is helpful at the conceptual level, it provides little practical guidance for estimating sample sizes, prior to data collection, necessary for conducting quality research. Using data from a study involving sixty in-depth interviews with women in two West African countries, the authors systematically document the degree of data saturation and variability over the course of thematic analysis. They operationalize saturation and make evidence-based recommendations regarding nonprobabilistic sample sizes for interviews. Based on the data set, they found that saturation occurred within the first twelve interviews, although basic elements for metathemes were present as early as six interviews. Variability within the data followed similar patterns.","['Operationalization', 'Data collection', 'Nonprobability sampling', 'Sample (material)', 'Saturation (graph theory)', 'Data quality', 'Sample size determination', 'Psychology', 'Statistics', 'Data science', 'Computer science', 'Medicine', 'Mathematics', 'Engineering', 'Population', 'Environmental health', 'Philosophy', 'Chemistry', 'Metric (unit)', 'Operations management', 'Epistemology', 'Chromatography', 'Combinatorics']","nonprobabilistic sample sizes, purposive samples, nonprobabilistic sampling, saturation, data, quality, women, data saturation, thematic analysis, sat, nonprobabilistic sample sizes, sat, metathemes, [PAD]"
Paper_00713,Electron affinities of the first-row atoms revisited. Systematic basis sets and wave functions,"['Rick A. Kendall', 'Thom H. Dunning', 'Robert J. Harrison']",1992,The Journal of Chemical Physics,Journal,,6796-6806,96,9,10.1063/1.462569,"The calculation of accurate electron affinities (EAs) of atomic or molecular species is one of the most challenging tasks in quantum chemistry. We describe a reliable procedure for calculating the electron affinity of an atom and present results for hydrogen, boron, carbon, oxygen, and fluorine (hydrogen is included for completeness). This procedure involves the use of the recently proposed correlation-consistent basis sets augmented with functions to describe the more diffuse character of the atomic anion coupled with a straightforward, uniform expansion of the reference space for multireference singles and doubles configuration-interaction (MRSD-CI) calculations. Comparison with previous results and with corresponding full CI calculations are given. The most accurate EAs obtained from the MRSD-CI calculations are (with experimental values in parentheses) hydrogen 0.740 eV (0.754), boron 0.258 (0.277), carbon 1.245 (1.263), oxygen 1.384 (1.461), and fluorine 3.337 (3.401). The EAs obtained from the MR-SDCI calculations differ by less than 0.03 eV from those predicted by the full CI calculations.","['Affinities', 'Chemistry', 'Wave function', 'Fluorine', 'Electron affinity (data page)', 'Hydrogen', 'Atomic physics', 'Ion', 'Boron', 'Hydrogen atom', 'Electronic correlation', 'Basis set', 'Computational chemistry', 'Quantum chemistry', 'Oxygen atom', 'Electron', 'Physical chemistry', 'Physics', 'Molecule', 'Quantum mechanics', 'Stereochemistry', 'Density functional theory', 'Group (periodic table)', 'Organic chemistry', 'Electrode', 'Electrochemistry']","accurate electron affinities, quantum chemistry, electron affinity, flu, atomic an, ##ference, bo, fluorin"
Paper_00714,Discovering Statistics Using Ibm Spss Statistics,['Andy P. Field'],2017,['Journal of Political Science Education'],Unknown,,145-147,14,1,10.1080/15512169.2017.1366328,"Unrivalled in the way it makes the teaching of statistics compelling and accessible to even the most anxious of students, the only statistics textbook you and your students will ever need just got better! Andy Field's comprehensive and bestselling Discovering Statistics Using SPSS 4th Edition takes students from introductory statistical concepts through very advanced concepts, incorporating SPSS throughout. The Fourth Edition focuses on providing essential content updates, better accessibility to key features, more instructor resources, and more content specific to select disciplines. It also incorporates powerful new digital developments on the textbook's companion website(visit sagepub.com for more information). WebAssign The Fourth Edition will be available on WebAssign, allowing instructors to produce and manage assignments with their studnets online using a grade book that allows them to track and monitor students' progress. Students receive unlimited practice using a combination of approximately 2000 multiple choice and algorithmic questions. WebAssign provided students with instant feedback and links directly to the accompanying eBook section where the concept was covered, allowing students to find the correct solution. SAGE MobileStudy SAGE MobileStudy allows students equipped with smartphones and tablets to access select material, such as Cramming Sam's Study Tips, anywhere they receive mobile service. With QR codes included throughout the text, it's easy for students to get right to the section they need to study, allowing them to continue their study from virtually anywhere, even when they are away from thier printed copy of the text. Click here to preview the MobileStudy site (available late spring 2013). Education and Sport Sciences instructor support materials with enhanced ones for Psychology, Business and Management and the Health sciences make the book even more relevant to a wider range of subjects across the social sciences and where statistics is taught to a cross-disciplinary audience. Major Updates to the 4th Edition Fully compatible with recent SPSS releases up to and including version 20.0 Exciting new characters, including statistical cult leader Oditi, who provides students access to interesting and helpful video clips to illustrate statistical and SPSS concepts, and Confusious, who helps students clarify confusing quantitative terminology New discipline specific support matierlas have been added for Education, Sports Sciences, Psychology, Business & Management, and Health Sciences, making the book even more relevant to a wider range of subjects across the Social, Behavioral, and Health Sciences is taught to an interdisciplinary audience. An enhanced Companion Website (available late spring 2013) offers a wealth of material that can be used in conjunction with the textbook, including: PowerPoints Testbanks Answers to the Smart Alex tasks at the end of each chapter Datafiles for testing problems in SPSS Flashcards of key concepts Self-assessment multiple-choice questions Online videos of key statistical and SPSS procedures","['IBM', 'Computer science', 'Field (mathematics)', 'Section (typography)', 'Descriptive statistics', 'Statistics', 'World Wide Web', 'Mathematics education', 'Multimedia', 'Psychology', 'Mathematics', 'Materials science', 'Pure mathematics', 'Nanotechnology', 'Operating system']","statistics, statistics, statistics, ##ss, sage, webassign, webassign, webassign, sage mobilest, qr codes, mobile, sport sciences, health, statistical cult leader, confusious, education, sports sciences, psychology, business, health sciences, powerpoints"
Paper_00717,"Cancer Statistics, 2021","['Rebecca L. Siegel', 'Kimberly D. Miller', 'Hannah E. Fuchs', 'Ahmedin Jemal']",2021,CA A Cancer Journal for Clinicians,Journal,,7-33,71,1,10.3322/caac.21654,"Each year, the American Cancer Society estimates the numbers of new cancer cases and deaths in the United States and compiles the most recent data on population-based cancer occurrence. Incidence data (through 2017) were collected by the Surveillance, Epidemiology, and End Results Program; the National Program of Cancer Registries; and the North American Association of Central Cancer Registries. Mortality data (through 2018) were collected by the National Center for Health Statistics. In 2021, 1,898,160 new cancer cases and 608,570 cancer deaths are projected to occur in the United States. After increasing for most of the 20th century, the cancer death rate has fallen continuously from its peak in 1991 through 2018, for a total decline of 31%, because of reductions in smoking and improvements in early detection and treatment. This translates to 3.2 million fewer cancer deaths than would have occurred if peak rates had persisted. Long-term declines in mortality for the 4 leading cancers have halted for prostate cancer and slowed for breast and colorectal cancers, but accelerated for lung cancer, which accounted for almost one-half of the total mortality decline from 2014 to 2018. The pace of the annual decline in lung cancer mortality doubled from 3.1% during 2009 through 2013 to 5.5% during 2014 through 2018 in men, from 1.8% to 4.4% in women, and from 2.4% to 5% overall. This trend coincides with steady declines in incidence (2.2%-2.3%) but rapid gains in survival specifically for nonsmall cell lung cancer (NSCLC). For example, NSCLC 2-year relative survival increased from 34% for persons diagnosed during 2009 through 2010 to 42% during 2015 through 2016, including absolute increases of 5% to 6% for every stage of diagnosis; survival for small cell lung cancer remained at 14% to 15%. Improved treatment accelerated progress against lung cancer and drove a record drop in overall cancer mortality, despite slowing momentum for other common cancers.","['Cancer', 'Statistics', 'Medicine', 'Mathematics', 'Internal medicine']","american cancer society, end results, central cancer registries, cancer death, prostate cancer, color, ##al, lung cancer, lung cancer mortality, nonsmall cell lung cancer, small cell lung cancer, lung"
Paper_00718,The Principles of Nuclear Magnetism,"['A. Abragam', 'L. C. Hebel']",1961,American Journal of Physics,Journal,,860-861,29,12,10.1119/1.1937646,First Page,"['Physics', 'Magnetism', 'Theoretical physics', 'Nuclear physics', 'Quantum mechanics']",
Paper_00722,Differential expression analysis for sequence count data,"['Simon Anders', 'Wolfgang Huber']",2010,Genome biology,Journal,,,11,10,10.1186/gb-2010-11-10-r106,"High-throughput sequencing assays such as RNA-Seq, ChIP-Seq or barcode counting provide quantitative readouts in the form of count data. To infer differential signal in such data correctly and with good statistical power, estimation of data variability throughout the dynamic range and a suitable error model are required. We propose a method based on the negative binomial distribution, with variance and mean linked by local regression and present an implementation, DESeq, as an R/Bioconductor package.","['Bioconductor', 'Count data', 'Negative binomial distribution', 'Barcode', 'Biology', 'Statistics', 'Binomial distribution', 'Computational biology', 'Computer science', 'Mathematics', 'Genetics', 'Gene', 'Poisson distribution', 'Operating system']","barcode counting, quantitative, count data, differential signal, statistical power, data variability, dynamic range, error model, negative binomial distribution, local regression"
Paper_00723,How to do things with words,['John Austin'],1962,"['Terminology and Lexicography Research and Practice', 'New Insights into the Semantics of Legal Concepts and the Legal Dictionary']",Unknown,,61-78,,,10.1075/tlrp.17.c3,* Lecture I * Lecture II * Lecture III * Lecture IV * Lecture V * Lecture VI * Lecture VII * Lecture VIII * Lecture IX * Lecture X * Lecture XI * Lecture XII,"['Lecture hall', 'History', 'Archaeology']",
Paper_00724,Self-efficacy mechanism in human agency.,['Albert Bandura'],1982,American Psychologist,Journal,,122-147,37,2,10.1037/0003-066x.37.2.122,"This article addresses the centrality of the self-efficacy mechanism in human agency. Self-per- cepts of efficacy influence thought patterns, actions, and emotional arousal. In causal tests the higher the level of induced self-efficacy, the higher the perfor- mance accomplishments and the lower the emotional arousal. Different lines of research are reviewed, show- ing that the self-efficacy mechanism may have wide explanatory power. Perceived self-efficacy helps to ac- count for such diverse phenomena as changes in coping behavior produced by different modes of influence, level of physiological stress reactions, self-regulation of refractory behavior, resignation and despondency to failure experiences, self-debilitating effects of proxy control and illusory inefficaciousness, achievement strivings, growth of intrinsic interest, and career pur- suits. The influential role of perceived collective effi- cacy in social change is analyzed, as are the social con- ditions conducive to development of collective inefficacy. Psychological theorizing and research tend to cen- ter on issues concerning either acquisition of knowledge or execution of response patterns. As a result the processes governing the interrelation- ship between knowledge and action have been largely neglected (Newell, 1978). Some of the re- cent efforts to bridge this gap have been directed at the biomechanics problem—how efferent com- mands of action plans guide the production of ap- propriate response patterns (Stelmach, 1976,1978). Others have approached the matter in terms of algorithmic knowledge, which furnishes guides for executing action sequences (Greeno, 1973; Newell, 1973). ,","['Mechanism (biology)', 'Agency (philosophy)', 'Psychology', 'Social psychology', 'Sociology', 'Epistemology', 'Social science', 'Philosophy']","human agency, thought patterns, emotional arousal, emotional arousal, coping behavior, physiological stress reactions, ##tory, ##dency, proxy control, ##ry in, achievement strivings, social, collective in, psychological, bio, ##ics, ##ic"
Paper_00725,The psychological impact of quarantine and how to reduce it: rapid review of the evidence,"['Samantha K. Brooks', 'Rebecca Webster', 'Louise Smith', 'Lisa Woodland', 'Simon Wessely', 'Neil Greenberg', 'Gideon James Rubin']",2020,The Lancet,Journal,,912-920,395,10227,10.1016/s0140-6736(20)30460-8,"The December, 2019 coronavirus disease outbreak has seen many countries ask people who have potentially come into contact with the infection to isolate themselves at home or in a dedicated quarantine facility. Decisions on how to apply quarantine should be based on the best available evidence. We did a Review of the psychological impact of quarantine using three electronic databases. Of 3166 papers found, 24 are included in this Review. Most reviewed studies reported negative psychological effects including post-traumatic stress symptoms, confusion, and anger. Stressors included longer quarantine duration, infection fears, frustration, boredom, inadequate supplies, inadequate information, financial loss, and stigma. Some researchers have suggested long-lasting effects. In situations where quarantine is deemed necessary, officials should quarantine individuals for no longer than required, provide clear rationale for quarantine and information about protocols, and ensure sufficient supplies are provided. Appeals to altruism by reminding the public about the benefits of quarantine to wider society can be favourable.","['Quarantine', 'Anger', 'Pandemic', 'Medicine', 'Stressor', 'Boredom', 'Coronavirus disease 2019 (COVID-19)', 'Internet privacy', 'Psychology', 'Business', 'Public relations', 'Social psychology', 'Disease', 'Psychiatry', 'Infectious disease (medical specialty)', 'Political science', 'Computer science', 'Pathology']","coronavirus disease, quaran, quaran, quaran, electronic databases, infection fears"
Paper_00727,Adaptation in Natural and Artificial Systems,['John H. Holland'],1992,Unknown,Unknown,,,,,10.7551/mitpress/1090.001.0001,"Genetic algorithms are playing an increasingly important role in studies of complex adaptive systems, ranging from adaptive agents in economic theory to the use of machine learning techniques in the design of complex devices such as aircraft turbines and integrated circuits. Adaptation in Natural and Artificial Systems is the book that initiated this field of study, presenting the theoretical foundations and exploring applications. In its most familiar form, adaptation is a biological process, whereby organisms evolve by rearranging genetic material to survive in environments confronting them. In this now classic work, Holland presents a mathematical model that allows for the nonlinearity of such complex interactions. He demonstrates the model's universality by applying it to economics, physiological psychology, game theory, and artificial intelligence and then outlines the way in which this approach modifies the traditional views of mathematical genetics. Initially applying his concepts to simply defined artificial systems with limited numbers of parameters, Holland goes on to explore their use in the study of a wide range of complex, naturally occuring processes, concentrating on systems having multiple factors that interact in nonlinear ways. Along the way he accounts for major effects of coadaptation and coevolution: the emergence of building blocks, or schemata, that are recombined and passed on to succeeding generations to provide, innovations and improvements. Bradford Books imprint","['Adaptation (eye)', 'Natural (archaeology)', 'Computer science', 'Artificial intelligence', 'Psychology', 'Geography', 'Neuroscience', 'Archaeology']","genetic algorithms, complex adaptive systems, adaptive agents, economic theory, machine learning techniques, complex devices, aircraft turbines, integrated circuits, adaptation, mathematical model, economics, physiological psychology, game theory, artificial intelligence, mathematical genetics, coadaptation, coevolution, building blocks, schemata"
Paper_00729,Use of avidin-biotin-peroxidase complex (ABC) in immunoperoxidase techniques: a comparison between ABC and unlabeled antibody (PAP) procedures.,"['S M Hsu', 'Laurence Raine', 'Herbert Fanger']",1981,Journal of Histochemistry & Cytochemistry,Journal,,577-580,29,4,10.1177/29.4.6166661,"The use of avidin-biotin interaction in immunoenzymatic techniques provides a simple and sensitive method to localize antigens in formalin-fixed tissues. Among the several staining procedures available, the ABC method, which involves an application of biotin-labeled secondary antibody followed by the addition of avidin-biotin-peroxidase complex, gives a superior result when compared to the unlabeled antibody method. The availability of biotin-binding sites in the complex is created by the incubation of a relative excess of avidin with biotin-labeled peroxidase. During formation of the complex, avidin acts as a bridge between biotin-labeled peroxidase molecules; and biotin-labeled peroxidase molecules, which contains several biotin moieties, serve as a link between the avidin molecules. Consequently, a ""lattice"" complex containing several peroxidase molecules is likely formed. Binding of this complex to the biotin moieties associated with secondary antibody results in a high staining intensity.","['Avidin', 'Biotin', 'Peroxidase', 'Chemistry', 'Biochemistry', 'Biotinylation', 'Immunoperoxidase', 'Antibody', 'Primary and secondary antibodies', 'Enzyme', 'Monoclonal antibody', 'Biology', 'Immunology']","immunoenzymatic techniques, staining, avid, biotin"
Paper_00730,Advanced inorganic chemistry,['F.A. Cotton'],1999,Choice Reviews Online,Journal,,37-0940,37,02,10.5860/choice.37-0940,"For more than a quarter century, Cotton and Wilkinson's Advanced Inorganic Chemistry has been the source that students and professional chemists have turned to for the background needed to understand current research literature in inorganic chemistry and aspects of organometallic chemistry. Like its predecessors, this updated Sixth Edition is organized around the periodic table of elements and provides a systematic treatment of the chemistry of all chemical elements and their compounds. It incorporates important recent developments with an emphasis on advances in the interpretation of structure, bonding, and reactivity.From the reviews of the Fifth Edition:* The first place to go when seeking general information about the chemistry of a particular element, especially when up-to-date, authoritative information is desired. -Journal of the American Chemical Society.* Every student with a serious interest in inorganic chemistry should have [this book]. -Journal of Chemical Education.* A mine of information . . . an invaluable guide. -Nature.* The standard by which all other inorganic chemistry books are judged.-Nouveau Journal de Chimie.* A masterly overview of the chemistry of the elements.-The Times of London Higher Education Supplement.* A bonanza of information on important results and developments which could otherwise easily be overlooked in the general deluge of publications. -Angewandte Chemie.","['Chemistry', 'Chemistry education', 'Chemist', 'Library science', 'Computer science', 'Organic chemistry', 'Epistemology', 'Philosophy', 'Quality (philosophy)']","inorganic chemistry, professional chemist, inorganic chemistry, organometallic chemistry, periodic table, reactivity, american, inorganic chemistry, chemical education, inorganic chemistry, ##te"
Paper_00731,Handbook of Theory and Research for the Sociology of Education.,"[""David O'Shea"", 'John G. Richardson']",1987,Contemporary Sociology A Journal of Reviews,Journal,,571-571,16,4,10.2307/2069964,"The first of its kind, this handbook synthesizes major advances in the sociology of education over the past several decades. It incorporates both a systematic review of significant theoretical and empirical work and challenging original contributions by distinguished American, English, and French sociologists. In his introduction, John G. Richardson traces the development of the sociology of education and reviews the important classical European works in which this discipline is grounded. Each chapter, devoted to a major topic in the field, provides both a review of the literature and an exposition of an original thesis. The inclusion of subjects outside traditional sociological concern--such as the historical foundations of education and the sociology of special education--gives an interdisciplinary scope that enhances the volume's usefulness.","['Sociology', 'Social science', 'Regional science']","sociology, education, sociology, education, historical foundations of, sociology, special education"
Paper_00732,To Err Is Human,['Institute of Medicine'],2000,National Academies Press eBooks,Unknown,,,,,10.17226/9728,"Boken presenterer en helhetlig strategi for hvordan myndigheter, helsepersonell, industri og forbrukere kan redusere medisinske feil.",['Computer science'],##erson
Paper_00735,Universal Solvation Model Based on Solute Electron Density and on a Continuum Model of the Solvent Defined by the Bulk Dielectric Constant and Atomic Surface Tensions,"['Aleksandr V. Marenich', 'Christopher J. Cramer', 'Donald G. Truhlar']",2009,The Journal of Physical Chemistry B,Journal,,6378-6396,113,18,10.1021/jp810292n,"We present a new continuum solvation model based on the quantum mechanical charge density of a solute molecule interacting with a continuum description of the solvent. The model is called SMD, where the ""D"" stands for ""density"" to denote that the full solute electron density is used without defining partial atomic charges. ""Continuum"" denotes that the solvent is not represented explicitly but rather as a dielectric medium with surface tension at the solute-solvent boundary. SMD is a universal solvation model, where ""universal"" denotes its applicability to any charged or uncharged solute in any solvent or liquid medium for which a few key descriptors are known (in particular, dielectric constant, refractive index, bulk surface tension, and acidity and basicity parameters). The model separates the observable solvation free energy into two main components. The first component is the bulk electrostatic contribution arising from a self-consistent reaction field treatment that involves the solution of the nonhomogeneous Poisson equation for electrostatics in terms of the integral-equation-formalism polarizable continuum model (IEF-PCM). The cavities for the bulk electrostatic calculation are defined by superpositions of nuclear-centered spheres. The second component is called the cavity-dispersion-solvent-structure term and is the contribution arising from short-range interactions between the solute and solvent molecules in the first solvation shell. This contribution is a sum of terms that are proportional (with geometry-dependent proportionality constants called atomic surface tensions) to the solvent-accessible surface areas of the individual atoms of the solute. The SMD model has been parametrized with a training set of 2821 solvation data including 112 aqueous ionic solvation free energies, 220 solvation free energies for 166 ions in acetonitrile, methanol, and dimethyl sulfoxide, 2346 solvation free energies for 318 neutral solutes in 91 solvents (90 nonaqueous organic solvents and water), and 143 transfer free energies for 93 neutral solutes between water and 15 organic solvents. The elements present in the solutes are H, C, N, O, F, Si, P, S, Cl, and Br. The SMD model employs a single set of parameters (intrinsic atomic Coulomb radii and atomic surface tension coefficients) optimized over six electronic structure methods: M05-2X/MIDI!6D, M05-2X/6-31G, M05-2X/6-31+G, M05-2X/cc-pVTZ, B3LYP/6-31G, and HF/6-31G. Although the SMD model has been parametrized using the IEF-PCM protocol for bulk electrostatics, it may also be employed with other algorithms for solving the nonhomogeneous Poisson equation for continuum solvation calculations in which the solute is represented by its electron density in real space. This includes, for example, the conductor-like screening algorithm. With the 6-31G basis set, the SMD model achieves mean unsigned errors of 0.6-1.0 kcal/mol in the solvation free energies of tested neutrals and mean unsigned errors of 4 kcal/mol on average for ions with either Gaussian03 or GAMESS.","['Solvation', 'Chemistry', 'Dielectric', 'Surface tension', 'Solvent models', 'Polarizable continuum model', 'Implicit solvation', 'Electrostatics', 'London dispersion force', 'Charge density', 'Water model', 'Solvation shell', 'Thermodynamics', 'Solvent', 'Chemical physics', 'Molecule', 'Computational chemistry', 'Quantum mechanics', 'Molecular dynamics', 'Physical chemistry', 'Physics', 'van der Waals force', 'Organic chemistry']","continuum solvation model, quantum mechanical charge density, solute molecule, continuum description, smd, full solute electron density, partial atomic charges, universal solvation model, diele, refractive index, bulk surface tension, ##ity parameters, bulk electrostatic contribution, non, atomic surface tensions, aqueous ionic solvation free energies, ##vation free energies, dime, nonaqueous organic solvents, transfer free energies, organic, atomic surface tension"
Paper_00737,An R Companion to Applied Regression,"['Sanford Weisberg', 'John Fox']",2010,['CRAN: Contributed Packages'],Unknown,,,,,10.32614/cran.package.car,Preface 1. Getting Started With R 2. Reading and Manipulating Data 3. Exploring and Transforming Data 4. Fitting Linear Models 5. Fitting Generalized Linear Models 6. Diagnosing Problems in Linear and Generalized Linear Models 7. Drawing Graphs 8. Writing Programs References Author Index Subject Index Command Index Data Set Index Package Index About the Authors,"['Index (typography)', 'Linear regression', 'Set (abstract data type)', 'Subject (documents)', 'Linear model', 'Data set', 'Generalized linear model', 'Computer science', 'Reading (process)', 'Applied mathematics', 'Mathematics', 'Statistics', 'Artificial intelligence', 'Linguistics', 'Library science', 'Programming language', 'Philosophy']","linear models, generalized linear models, generalized linear models, drawing graphs, [PAD], [PAD], [PAD] [PAD], [PAD], [PAD], [PAD]"
Paper_00738,2015 American Thyroid Association Management Guidelines for Adult Patients with Thyroid Nodules and Differentiated Thyroid Cancer: The American Thyroid Association Guidelines Task Force on Thyroid Nodules and Differentiated Thyroid Cancer,"['Bryan R. Haugen', 'Erik K. Alexander', 'Keith C. Bible', 'Gerard M. Doherty', 'Susan J. Mandel', 'Yuri E. Nikiforov', 'Furio Pacini', 'Gregory W. Randolph', 'Anna M. Sawka', 'Martin Schlumberger', 'Kathryn G. Schuff', 'Steven I. Sherman', 'Julie Ann Sosa', 'David L. Steward', 'R. Michael Tuttle', 'Leonard Wartofsky']",2015,Thyroid,Journal,,1-133,26,1,10.1089/thy.2015.0020,"Background: Thyroid nodules are a common clinical problem, and differentiated thyroid cancer is becoming increasingly prevalent. Since the American Thyroid Association's (ATA's) guidelines for the management of these disorders were revised in 2009, significant scientific advances have occurred in the field. The aim of these guidelines is to inform clinicians, patients, researchers, and health policy makers on published evidence relating to the diagnosis and management of thyroid nodules and differentiated thyroid cancer. Methods: The specific clinical questions addressed in these guidelines were based on prior versions of the guidelines, stakeholder input, and input of task force members. Task force panel members were educated on knowledge synthesis methods, including electronic database searching, review and selection of relevant citations, and critical appraisal of selected studies. Published English language articles on adults were eligible for inclusion. The American College of Physicians Guideline Grading System was used for critical appraisal of evidence and grading strength of recommendations for therapeutic interventions. We developed a similarly formatted system to appraise the quality of such studies and resultant recommendations. The guideline panel had complete editorial independence from the ATA. Competing interests of guideline task force members were regularly updated, managed, and communicated to the ATA and task force members. Results: The revised guidelines for the management of thyroid nodules include recommendations regarding initial evaluation, clinical and ultrasound criteria for fine-needle aspiration biopsy, interpretation of fine-needle aspiration biopsy results, use of molecular markers, and management of benign thyroid nodules. Recommendations regarding the initial management of thyroid cancer include those relating to screening for thyroid cancer, staging and risk assessment, surgical management, radioiodine remnant ablation and therapy, and thyrotropin suppression therapy using levothyroxine. Recommendations related to long-term management of differentiated thyroid cancer include those related to surveillance for recurrent disease using imaging and serum thyroglobulin, thyroid hormone therapy, management of recurrent and metastatic disease, consideration for clinical trials and targeted therapy, as well as directions for future research. Conclusions: We have developed evidence-based recommendations to inform clinical decision-making in the management of thyroid nodules and differentiated thyroid cancer. They represent, in our opinion, contemporary optimal care for patients with these disorders.","['Thyroid nodules', 'Thyroid cancer', 'Medicine', 'Guideline', 'Thyroid', 'Grading (engineering)', 'Task force', 'Fine-needle aspiration', 'Pathology', 'Biopsy', 'Internal medicine', 'Civil engineering', 'Public administration', 'Political science', 'Engineering']","thyroid nodules, differentiated thyroid cancer, american thyroid association, differentiated thyroid cancer, knowledge synthesis, electronic database searching, american college of physicians guideline grading system, therapeutic, risk assessment, surgical management, radio, thyrot, ##in suppression therapy, ##yr, differentiated thyroid cancer, thyroid hormone therapy, targeted, thyroid, differentiated thyroid cancer"
Paper_00739,Calcium's Role in Mechanotransduction during Muscle Development,"['Tatiana Benavides Damm', 'Marcel Egli']",2014,Cellular Physiology and Biochemistry,Journal,,249-272,33,2,10.1159/000356667,"Slow- and fast-twitch myofibers of adult skeletal muscles express unique sets of muscle-specific genes, and these distinctive programs of gene expression are controlled by variations in motor neuron activity. It is well established that, as a consequence of more frequent neural stimulation, slow fibers maintain higher levels of intracellular free calcium than fast fibers, but the mechanisms by which calcium may function as a messenger linking nerve activity to changes in gene expression in skeletal muscle have been unknown. Here, fiber-type-specific gene expression in skeletal muscles is shown to be controlled by a signaling pathway that involves calcineurin, a cyclosporin-sensitive, calcium-regulated serine/threonine phosphatase. Activation of calcineurin in skeletal myocytes selectively up-regulates slow-fiber-specific gene promoters. Conversely, inhibition of calcineurin activity by administration of cyclosporin A to intact animals promotes slow-to-fast fiber transformation. Transcriptional activation of slow-fiber-specific transcription appears to be mediated by a combinatorial mechanism involving proteins of the NFAT and MEF2 families. These results identify a molecular mechanism by which different patterns of motor nerve activity promote selective changes in gene expression to establish the specialized characteristics of slow and fast myofibers.","['NFAT', 'Calcineurin', 'Cell biology', 'Skeletal muscle', 'Biology', 'CAMK', 'Mef2', 'Gene expression', 'Myocyte', 'Mechanotransduction', 'Regulation of gene expression', 'Calcium signaling', 'Transcription factor', 'Chemistry', 'Signal transduction', 'Gene', 'Endocrinology', 'Internal medicine', 'Biochemistry', 'Phosphorylation', 'Enhancer', 'Protein kinase A', 'Medicine', 'Autophosphorylation', 'Transplantation']","adult skeletal muscles, motor neuron activity, skeletal muscle, skeletal muscles, calcine, ##n, skeletal myocytes, cal, [PAD], [PAD]"
Paper_00740,Convergence of Probability Measures,['Patrick Billingsley'],1999,Wiley series in probability and statistics,Unknown,,,,,10.1002/9780470316962,Weak Convergence in Metric Spaces. The Space C. The Space D. Dependent Variables. Other Modes of Convergence. Appendix. Some Notes on the Problems. Bibliographical Notes. Bibliography. Index.,"['Convergence (economics)', 'Computer science', 'Econometrics', 'Mathematics', 'Economics', 'Economic growth']","weak convergence, metric spaces, dependent variables, ##graphic"
Paper_00741,Constructing grounded theory,['Kathy Charmaz'],2014,['Neighborhood as Refuge'],Unknown,,231-238,,1,10.7551/mitpress/9837.003.0013,"An Invitation to Grounded Theory Gathering Rich Data Crafting and Conducting Intensive Interviews Interviewing in Grounded Theory Studies The Logic of Grounded Theory Coding Practices and Initial Coding Focused Coding and beyond Memo-Writing Theoretical Sampling, Saturation and Sorting Reconstructing Theory in Grounded Theory Studies Symbolic Interactionism and Grounded Theory Writing the Draft Reflecting on the Research Process","['Grounded theory', 'Interview', 'Symbolic interactionism', 'Theoretical sampling', 'Constructivist grounded theory', 'Coding (social sciences)', 'Coding theory', 'Qualitative research', 'Epistemology', 'Sociology', 'Computer science', 'Psychology', 'Social psychology', 'Theoretical computer science', 'Social science', 'Philosophy', 'Anthropology']","grounded theory, grounded theory, grounded theory coding practices, initial coding, saturation, grounded theory, symbolic interactionism, grounded theory"
Paper_00743,<i>The Properties of Gases and Liquids</i>,"['Robert C. Reid', 'T. K. Sherwood', 'Robert E. Street']",1959,Physics Today,Journal,,38-40,12,4,10.1063/1.3060771,"Share Icon Share Twitter Facebook Reddit LinkedIn Reprints and Permissions Cite Icon Cite Search Site Citation Robert C. Reid, Thomas K. Sherwood, Robert E. Street; The Properties of Gases and Liquids. Physics Today 1 April 1959; 12 (4): 38–40. https://doi.org/10.1063/1.3060771 Download citation file: Ris (Zotero) Reference Manager EasyBib Bookends Mendeley Papers EndNote RefWorks BibTex toolbar search Search Dropdown Menu toolbar search search input Search input auto suggest filter your search All ContentPhysics Today Search Advanced Search","['Thermodynamics', 'Vaporization', 'Viscosity', 'Surface tension', 'Volume (thermodynamics)', 'Thermal conductivity', 'Materials science', 'Vapor pressure', 'Diffusion', 'Ideal gas', 'Chemistry', 'Physics']","##s, zotero, mendeley, bibtex"
Paper_00744,"<i>ATHENA</i>,<i>ARTEMIS</i>,<i>HEPHAESTUS</i>: data analysis for X-ray absorption spectroscopy using<i>IFEFFIT</i>","['Bruce Ravel', 'M. Newville']",2005,Journal of Synchrotron Radiation,Journal,,537-541,12,4,10.1107/s0909049505012719,"A software package for the analysis of X-ray absorption spectroscopy (XAS) data is presented. This package is based on the IFEFFIT library of numerical and XAS algorithms and is written in the Perl programming language using the Perl/Tk graphics toolkit. The programs described here are: (i) ATHENA, a program for XAS data processing, (ii) ARTEMIS, a program for EXAFS data analysis using theoretical standards from FEFF and (iii) HEPHAESTUS, a collection of beamline utilities based on tables of atomic absorption data. These programs enable high-quality data analysis that is accessible to novices while still powerful enough to meet the demands of an expert practitioner. The programs run on all major computer platforms and are freely available under the terms of a free software license.","['X-ray absorption spectroscopy', 'Perl', 'Beamline', 'Computer science', 'Software', 'Graphics', 'Spectroscopy', 'Absorption (acoustics)', 'Extended X-ray absorption fine structure', 'Absorption spectroscopy', 'Computational science', 'Computer graphics (images)', 'Optics', 'Physics', 'Operating system', 'Beam (structure)', 'Quantum mechanics']","ifeffit, xas, ##l, athena, xas, artemis, exafs data analysis, feff, hephaestus, beamline utilities, atomic absorption data"
Paper_00747,The Pfam protein families database.,"['Alex Bateman', 'Ewan Birney', 'Lorenzo Cerruti', 'Richard Durbin', 'Laurence Etwiller', 'Sean R. Eddy', 'Sam Griffiths‐Jones', 'Kevin Howe', 'Mhairi Marshall', 'Erik L L Sonnhammer']",2002,Nucleic Acids Research,Journal,,276-80,30,1,10.1093/nar/30.1.276,"Pfam is a large collection of protein multiple sequence alignments and profile hidden Markov models. Pfam is available on the World Wide Web in the UK at http://www.sanger.ac.uk/Software/Pfam/, in Sweden at http://www.cgb.ki.se/Pfam/, in France at http://pfam.jouy.inra.fr/ and in the US at http://pfam.wustl.edu/. The latest version (6.6) of Pfam contains 3071 families, which match 69% of proteins in SWISS-PROT 39 and TrEMBL 14. Structural data, where available, have been utilised to ensure that Pfam families correspond with structural domains, and to improve domain-based annotation. Predictions of non-domain regions are now also included. In addition to secondary structure, Pfam multiple sequence alignments now contain active site residue mark-up. New search tools, including taxonomy search and domain query, greatly add to the functionality and usability of the Pfam resource.","['Biology', 'UniProt', 'Computational biology', 'Annotation', 'Sequence alignment', 'Protein domain', 'Protein family', 'Bioinformatics', 'Genetics', 'Peptide sequence', 'Gene']","pfam, protein multiple sequence alignments, profile hidden markov models, pfam, pfam, pfa, structural, pfam multiple sequence alignments, active site residue, search, taxonomy search, domain query, [PAD]"
Paper_00748,"Cancer statistics, 2017","['Rebecca L. Siegel', 'Kimberly D. Miller', 'Ahmedin Jemal']",2017,CA A Cancer Journal for Clinicians,Journal,,7-30,67,1,10.3322/caac.21387,"Each year, the American Cancer Society estimates the numbers of new cancer cases and deaths that will occur in the United States in the current year and compiles the most recent data on cancer incidence, mortality, and survival. Incidence data were collected by the Surveillance, Epidemiology, and End Results Program; the National Program of Cancer Registries; and the North American Association of Central Cancer Registries. Mortality data were collected by the National Center for Health Statistics. In 2017, 1,688,780 new cancer cases and 600,920 cancer deaths are projected to occur in the United States. For all sites combined, the cancer incidence rate is 20% higher in men than in women, while the cancer death rate is 40% higher. However, sex disparities vary by cancer type. For example, thyroid cancer incidence rates are 3-fold higher in women than in men (21 vs 7 per 100,000 population), despite equivalent death rates (0.5 per 100,000 population), largely reflecting sex differences in the ""epidemic of diagnosis."" Over the past decade of available data, the overall cancer incidence rate (2004-2013) was stable in women and declined by approximately 2% annually in men, while the cancer death rate (2005-2014) declined by about 1.5% annually in both men and women. From 1991 to 2014, the overall cancer death rate dropped 25%, translating to approximately 2,143,200 fewer cancer deaths than would have been expected if death rates had remained at their peak. Although the cancer death rate was 15% higher in blacks than in whites in 2014, increasing access to care as a result of the Patient Protection and Affordable Care Act may expedite the narrowing racial gap; from 2010 to 2015, the proportion of blacks who were uninsured halved, from 21% to 11%, as it did for Hispanics (31% to 16%). Gains in coverage for traditionally underserved Americans will facilitate the broader application of existing cancer control knowledge across every segment of the population. CA Cancer J Clin 2017;67:7-30. © 2017 American Cancer Society.","['Cancer', 'Medicine', 'Demography', 'Mortality rate', 'Population', 'Incidence (geometry)', 'Epidemiology', 'Thyroid cancer', 'Cause of death', 'Epidemiology of cancer', 'Cancer prevention', 'Gerontology', 'Breast cancer', 'Disease', 'Internal medicine', 'Environmental health', 'Physics', 'Sociology', 'Optics']","american cancer society, central cancer registries, sex disparities, thyroid cancer incidence, women, patient protection, racial, blacks, cancer control, american cancer society"
Paper_00749,The European Organization for Research and Treatment of Cancer QLQ-C30: A Quality-of-Life Instrument for Use in International Clinical Trials in Oncology,"['N.K. Aaronson', 'Sam H. Ahmedzai', 'Bengt Bergman', 'Monika Bullinger', 'A. Cull', 'N. Duez', 'A. Filiberti', 'Hans‐Henning Flechtner', 'Stewart B. Fleishman', 'J.C.J.M. de Haes', 'S. Kaasa', 'M. Klee', 'David Osoba', 'Darius Razavi', 'Peter B. C. Rofe', 'S Schraub', 'K.C.A. Sneeuw', 'Marianne Sullivan', 'Fumikazu Takeda']",1993,JNCI Journal of the National Cancer Institute,Journal,,365-376,85,5,10.1093/jnci/85.5.365,"Background : In 1986, the European Organization for Research and Treatment of Cancer (EORTC) initiated a research program to develop an integrated, modular approach for evaluating the quality of life of patients participating in international clinical trials. Purpose : We report here the results of an international field study of the practicality, reliability, and validity of the EORTC QLQ-C30, the current core questionnaire. The QLQ-C30 incorporates nine multi-item scales: five functional scales (physical, role, cognitive, emotional, and social); three symptom scales (fatigue, pain, and nausea and vomiting); and a global health and quality-of-life scale. Several single-item symptom measures are also included. Methods : The questionnaire was administered before treatment and once during treatment to 305 patients with nonresectable lung cancer from centers in 13 countries. Clinical variables assessed included disease stage, weight loss, performance status, and treatment toxicity. Results : The average time required to complete the questionnaire was approximately 11 minutes, and most patients required no assistance. The data supported the hypothesized scale structure of the questionnaire with the exception of role functioning (work and household activities), which was also the only multi-item scale that failed to meet the minimal standards for reliability (Cronbach's alpha coefficient >.70) either before or during treatment. Validity was shown by three findings. First, while all interscale correlations were statistically significant, the correlation was moderate, indicating that the scales were assessing distinct components of the quality-of-life construct. Second, most of the functional and symptom measures discriminated clearly between patients differing in clinical status as defined by the Eastern Cooperative Oncology Group performance status scale, weight loss, and treatment toxicity. Third, there were statistically significant changes, in the expected direction, in physical and role functioning, global quality of life, fatigue, and nausea and vomiting, for patients whose performance status had improved or worsened during treatment. The reliability and validity of the questionnaire were highly consistent across the three language-cultural groups studied: patients from English-speaking countries, Northern Europe, and Southern Europe. Conclusions : These results support the EORTC QLQ-C30 as a reliable and valid measure of the quality of life of cancer patients in multicultural clinical research settings. Work is ongoing to examine the performance of the questionnaire among more heterogenous patient samples and in phase II and phase III clinical trials. [J Natl Cancer Inst 85: 365-376, 1993]","['Quality of life (healthcare)', ""Cronbach's alpha"", 'Clinical trial', 'Construct validity', 'Medicine', 'Nausea', 'Physical therapy', 'Reliability (semiconductor)', 'Psychology', 'Psychometrics', 'Clinical psychology', 'Internal medicine', 'Nursing', 'Power (physics)', 'Physics', 'Quantum mechanics']","##ortc, international clinical trials, functional scales, nonresectable lung cancer, weight loss, performance status, treatment toxicity, role functioning, household activities, eastern cooperative oncology group performance status scale, weight loss, treatment toxicity, southern"
Paper_00753,A Behavioral Model of Rational Choice,['Herbert A. Simon'],1955,The Quarterly Journal of Economics,Journal,,99-99,69,1,10.2307/1884852,"Introduction, 99. — I. Some general features of rational choice, 100.— II. The essential simplifications, 103. — III. Existence and uniqueness of solutions, 111. — IV. Further comments on dynamics, 113. — V. Conclusion, 114. — Appendix, 115.","['Uniqueness', 'Mathematical economics', 'Mathematics', 'Computer science', 'Mathematical analysis']","rational choice, essential, unique, dynamics, [PAD]"
Paper_00754,Multiplex Genome Engineering Using CRISPR/Cas Systems,"['Le Cong', 'F. Ann Ran', 'David Cox', 'Shuailiang Lin', 'Robert P. J. Barretto', 'Naomi Habib', 'Patrick D. Hsu', 'Xuebing Wu', 'Wenyan Jiang', 'Luciano A. Marraffini', 'Feng Zhang']",2013,Science,Journal,,819-823,339,6121,10.1126/science.1231143,"Functional elucidation of causal genetic variants and elements requires precise genome editing technologies. The type II prokaryotic CRISPR (clustered regularly interspaced short palindromic repeats)/Cas adaptive immune system has been shown to facilitate RNA-guided site-specific DNA cleavage. We engineered two different type II CRISPR/Cas systems and demonstrate that Cas9 nucleases can be directed by short RNAs to induce precise cleavage at endogenous genomic loci in human and mouse cells. Cas9 can also be converted into a nicking enzyme to facilitate homology-directed repair with minimal mutagenic activity. Lastly, multiple guide sequences can be encoded into a single CRISPR array to enable simultaneous editing of several sites within the mammalian genome, demonstrating easy programmability and wide applicability of the RNA-guided nuclease technology.","['CRISPR', 'Cas9', 'Genome editing', 'Guide RNA', 'Biology', 'Genome engineering', 'Computational biology', 'Nuclease', 'Multiplex', 'Genome', 'DNA', 'Palindrome', 'Genetics', 'RNA', 'Gene']","causal genetic variants, genome editing, cas, cas, nicking enzyme"
Paper_00757,New directions in cryptography,"['Whitfield Diffie', 'Martin E. Hellman']",1976,IEEE Transactions on Information Theory,Journal,,644-654,22,6,10.1109/tit.1976.1055638,"Two kinds of contemporary developments in cryptography are examined. Widening applications of teleprocessing have given rise to a need for new types of cryptographic systems, which minimize the need for secure key distribution channels and supply the equivalent of a written signature. This paper suggests ways to solve these currently open problems. It also discusses how the theories of communication and computation are beginning to provide the tools to solve cryptographic problems of long standing.","['Cryptography', 'Computer science', 'Key (lock)', 'Signature (topology)', 'Digital signature', 'Theoretical computer science', 'Computer security', 'Financial cryptography', 'Cryptographic primitive', 'ID-based cryptography', 'Cryptographic protocol', 'PKCS #1', 'Neural cryptography', 'Computation', 'Public-key cryptography', 'Key distribution', 'Encryption', 'Mathematics', 'Algorithm', 'Hash function', 'Cryptosystem', 'Geometry']","cryptography, teleprocessing, cryptographic systems, secure key distribution channels, written signature, communication, computation, crypt, [PAD], [PAD] [PAD] [PAD] [PAD], [PAD], [PAD] [PAD], [PAD] [PAD] [PAD] [PAD] [PAD]"
Paper_00758,Bayesian Data Analysis,"['Andrew Gelman', 'John B. Carlin', 'Hal S. Stern', 'David B. Dunson', 'Aki Vehtari', 'Donald B. Rubin']",1995,['Computing in Science &amp; Engineering'],Unknown,,86-91,3,4,10.1109/5992.931908,"FUNDAMENTALS OF BAYESIAN INFERENCE Probability and Inference Single-Parameter Models Introduction to Multiparameter Models Asymptotics and Connections to Non-Bayesian Approaches Hierarchical Models FUNDAMENTALS OF BAYESIAN DATA ANALYSIS Model Checking Evaluating, Comparing, and Expanding Models Modeling Accounting for Data Collection Decision Analysis ADVANCED COMPUTATION Introduction to Bayesian Computation Basics of Markov Chain Simulation Computationally Efficient Markov Chain Simulation Modal and Distributional Approximations REGRESSION MODELS Introduction to Regression Models Hierarchical Linear Models Generalized Linear Models Models for Robust Inference Models for Missing Data NONLINEAR AND NONPARAMETRIC MODELS Parametric Nonlinear Models Basic Function Models Gaussian Process Models Finite Mixture Models Dirichlet Process Models APPENDICES A: Standard Probability Distributions B: Outline of Proofs of Asymptotic Theorems C: Computation in R and Stan Bibliographic Notes and Exercises appear at the end of each chapter.","['Variable-order Bayesian network', 'Approximate Bayesian computation', 'Computer science', 'Markov chain Monte Carlo', 'Bayesian inference', 'Bayesian probability', 'Inference', 'Dirichlet process', 'Frequentist inference', 'Bayesian statistics', 'Mathematics', 'Algorithm', 'Artificial intelligence']","bayesian inference, multiparameter models asymptotics, hierarchical models, bayesian data analysis, data collection decision analysis, bayesian computation, markov chain simulation, ##al approximation, hierarchical linear models generalized linear models, robust inference, parametric nonlinear, gaussian process models finite mixture models dirichlet process, standard probability distributions, asymptotic"
Paper_00760,The American Economic Review,[],2012,American Economic Review,Journal,,i-viii,102,2,10.1257/aer.102.2.i,The front matter of the April 2012 issue contains the Table of Contents,"['Economics', 'Neoclassical economics']",
Paper_00761,The MIQE Guidelines: Minimum Information for Publication of Quantitative Real-Time PCR Experiments,"['Stephen A. Bustin', 'Vladimı́r Beneš', 'Jeremy A. Garson', 'Jan Hellemans', 'Jim F. Huggett', 'Mikael Kubista', 'Reinhold Mueller', 'Tania Nolan', 'Michael W. Pfaffl', 'Gregory L. Shipley', 'Jo Vandesompele', 'Carl T. Wittwer']",2009,Clinical Chemistry,Journal,,611-622,55,4,10.1373/clinchem.2008.112797,"Background: Currently, a lack of consensus exists on how best to perform and interpret quantitative real-time PCR (qPCR) experiments. The problem is exacerbated by a lack of sufficient experimental detail in many publications, which impedes a reader's ability to evaluate critically the quality of the results presented or to repeat the experiments. Content: The Minimum Information for Publication of Quantitative Real-Time PCR Experiments (MIQE) guidelines target the reliability of results to help ensure the integrity of the scientific literature, promote consistency between laboratories, and increase experimental transparency. MIQE is a set of guidelines that describe the minimum information necessary for evaluating qPCR experiments. Included is a checklist to accompany the initial submission of a manuscript to the publisher. By providing all relevant experimental conditions and assay characteristics, reviewers can assess the validity of the protocols used. Full disclosure of all reagents, sequences, and analysis methods is necessary to enable other investigators to reproduce results. MIQE details should be published either in abbreviated form or as an online supplement. Summary: Following these guidelines will encourage better experimental practice, allowing more reliable and unequivocal interpretation of qPCR results.","['Real-time polymerase chain reaction', 'Computer science', 'Computational biology', 'Information retrieval', 'Statistics', 'Biology', 'Mathematics', 'Genetics', 'Gene']","q, mi, miqe, qpcr, assay characteristics, miqe"
Paper_00762,The Newcastle-Ottawa Scale (NOS) for Assessing the Quality of Nonrandomised Studies in Meta-Analyses,['George A. Wells'],2014,['World Journal of Meta-Analysis'],Unknown,,80,5,4,10.13105/wjma.v5.i4.80,"Nonrandomised studies, including case-control and cohort studies, can be challenging to implement and conduct. Assessment of the quality of such studies is essential for a proper understanding of nonrandomised studies. The Newcastle-Ottawa Scale (NOS) is an ongoing collaboration between the Universities of Newcastle, Australia and Ottawa, Canada. It was developed to assess the quality of nonrandomised studies with its design, content and ease of use directed to the task of incorporating the quality assessments in the interpretation of meta-analytic results. A 'star system' has been developed in which a study is judged on three broad perspectives: the selection of the study groups; the comparability of the groups; and the ascertainment of either the exposure or outcome of interest for case-control or cohort studies respectively. The goal of this project is to develop an instrument providing an easy and convenient tool for quality assessment of nonrandomised studies to be used in a systematic review.","['Quality (philosophy)', 'Comparability', 'Scale (ratio)', 'Task (project management)', 'Psychology', 'Economics', 'Geography', 'Philosophy', 'Mathematics', 'Cartography', 'Management', 'Epistemology', 'Combinatorics']","nonrandomised studies, cohort studies, nonrandomised studies, nonrandomised studies, quality assessments, star system, cohort, quality assessment, nonrandomised, [PAD], [PAD], [PAD]"
Paper_00763,One-step inactivation of chromosomal genes in <i>Escherichia coli</i> K-12 using PCR products,"['Kirill A. Datsenko', 'Barry L. Wanner']",2000,Proceedings of the National Academy of Sciences,Journal,,6640-6645,97,12,10.1073/pnas.120163297,"We have developed a simple and highly efficient method to disrupt chromosomal genes in Escherichia coli in which PCR primers provide the homology to the targeted gene(s). In this procedure, recombination requires the phage λ Red recombinase, which is synthesized under the control of an inducible promoter on an easily curable, low copy number plasmid. To demonstrate the utility of this approach, we generated PCR products by using primers with 36- to 50-nt extensions that are homologous to regions adjacent to the gene to be inactivated and template plasmids carrying antibiotic resistance genes that are flanked by FRT (FLP recognition target) sites. By using the respective PCR products, we made 13 different disruptions of chromosomal genes. Mutants of the arcB , cyaA , lacZYA , ompR - envZ , phnR , pstB , pstCA , pstS , pstSCAB - phoU , recA , and torSTRCAD genes or operons were isolated as antibiotic-resistant colonies after the introduction into bacteria carrying a Red expression plasmid of synthetic (PCR-generated) DNA. The resistance genes were then eliminated by using a helper plasmid encoding the FLP recombinase which is also easily curable. This procedure should be widely useful, especially in genome analysis of E. coli and other bacteria because the procedure can be done in wild-type cells.","['Plasmid', 'Recombinase', 'Biology', 'Escherichia coli', 'Gene', 'Homologous recombination', 'Genetics', 'Operon', 'Genome', 'Homology (biology)', 'Mutant', 'DNA', 'Recombination']","chromosomal genes, escherichia, ##r primers, ##bina, phage λ red recombinase, ##ucible, antibiotic resistance genes, ##p, ##osomal genes, ##tc, red"
Paper_00764,MOLSCRIPT: a program to produce both detailed and schematic plots of protein structures,['P. Kraulis'],1991,Journal of Applied Crystallography,Journal,,946-950,24,5,10.1107/s0021889891004399,"The MOLSCRIPT program produces plots of protein structures using several different kinds of representations.Schematic drawings, simple wire models, ball-and-stick models, CPK models and text labels can be mixed freely.The schematic drawings are shaded to improve the illusion of three dimensionality.A number of parameters affecting various aspects of the objects drawn can be changed by the user.The output from the program is in PostScript format.","['Schematic', 'Computer science', 'Engineering drawing', 'Computer graphics (images)', 'Simple (philosophy)', 'Illusion', 'Curse of dimensionality', 'Ball (mathematics)', 'Artificial intelligence', 'Geometry', 'Mathematics', 'Engineering', 'Psychology', 'Electrical engineering', 'Philosophy', 'Epistemology', 'Neuroscience']","molscript, protein structures, schematic drawings, simple wire models, cpk models, text labels, schematic drawings, postscript, [PAD], [PAD], [PAD] [PAD] [PAD] [PAD], [PAD], [PAD] [PAD], [PAD], [PAD], [PAD] [PAD], [PAD] [PAD], [PAD], [PAD], [PAD], [PAD], [PAD]"
Paper_00765,Bitcoin: A Peer-to-Peer Electronic Cash System,['Dr Craig S Wright'],2008,SSRN Electronic Journal,Unknown,,,,,10.2139/ssrn.3440802,"A purely peer-to-peer version of electronic cash would allow online payments to be sent directly from one party to another without the burdens of going through a financial institution. Digital signatures provide part of the solution, but the main benefits are lost if a trusted third party is still required to prevent double-spending. We propose a solution to the double-spending problem using a peer-to-peer network. The network timestamps transactions by hashing them into an ongoing chain of hash-based proof-of-work, forming a record that cannot be changed without redoing the proof-of-work. The longest chain not only serves as proof of the sequence of events witnessed, but proof that it came from the largest pool of CPU power. As long as honest nodes control the most CPU power on the network, they can generate the longest chain and outpace any attackers. The network itself requires minimal structure. Messages are broadcast on a best effort basis, and nodes can leave and rejoin the network at will, accepting the longest proof-of-work chain as proof of what happened while they were gone.","['Peer-to-peer', 'Business', 'Cash', 'Monetary economics', 'Computer science', 'Economics', 'World Wide Web', 'Finance']","electronic cash, online payments, digital signatures"
Paper_00767,A study of the conditions and mechanism of the diphenylamine reaction for the colorimetric estimation of deoxyribonucleic acid,['K. Burton'],1956,Biochemical Journal,Journal,,315-323,62,2,10.1042/bj0620315,"Research Article| February 01 1956 A study of the conditions and mechanism of the diphenylamine reaction for the colorimetric estimation of deoxyribonucleic acid K. Burton K. Burton 1Medical Research Council, Cell Metabolism Research Unit, Department of Biochemistry, University of Oxford Search for other works by this author on: This Site PubMed Google Scholar Author and article information Publisher: Portland Press Ltd © 1956 CAMBRIDGE UNIVERSITY PRESS1956 Biochem J (1956) 62 (2): 315–323. https://doi.org/10.1042/bj0620315 Views Icon Views Article contents Figures & tables Video Audio Supplementary Data Peer Review Share Icon Share Facebook Twitter LinkedIn Email Cite Icon Cite Get Permissions Citation K. Burton; A study of the conditions and mechanism of the diphenylamine reaction for the colorimetric estimation of deoxyribonucleic acid. Biochem J 1 February 1956; 62 (2): 315–323. doi: https://doi.org/10.1042/bj0620315 Download citation file: Ris (Zotero) Reference Manager EasyBib Bookends Mendeley Papers EndNote RefWorks BibTex toolbar search Search Dropdown Menu toolbar search search input Search input auto suggest filter your search All ContentAll JournalsBiochemical Journal Search Advanced Search This content is only available as a PDF. © 1956 CAMBRIDGE UNIVERSITY PRESS1956 Article PDF first page preview Close Modal You do not currently have access to this content.","['Diphenylamine', 'Citation', 'Icon', 'Information retrieval', 'Upload', 'Computer science', 'World Wide Web', 'Download', 'Library science', 'Chemistry', 'Organic chemistry', 'Programming language']","diphenylamine reaction, colorimetric estimation, ##ib, ##c, cell metabolism, portland, ##hen, ##mine, colorimetric estimation, ##ro"
Paper_00768,Neural Machine Translation by Jointly Learning to Align and Translate,"['Dzmitry Bahdanau', 'Kyunghyun Cho', 'Yoshua Bengio']",2014,['Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing'],Unknown,,,,,10.18653/v1/2021.emnlp-main.1,"Neural machine translation is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neural machine translation often belong to a family of encoder-decoders and consists of an encoder that encodes a source sentence into a fixed-length vector from which a decoder generates a translation. In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based system on the task of English-to-French translation. Furthermore, qualitative analysis reveals that the (soft-)alignments found by the model agree well with our intuition.","['Machine translation', 'Computer science', 'Transfer-based machine translation', 'Example-based machine translation', 'Sentence', 'Bottleneck', 'Artificial intelligence', 'Translation (biology)', 'Artificial neural network', 'Natural language processing', 'Encoder', 'Phrase', 'Word (group theory)', 'Speech recognition', 'Biochemistry', 'Chemistry', 'Linguistics', 'Philosophy', 'Messenger RNA', 'Gene', 'Embedded system', 'Operating system']","neural machine translation, machine translation, statistical machine translation, neural machine translation, neural network, neural machine translation, translation, qualitative"
Paper_00769,Endogenous Technological Change,['Paul Romer'],1989,Unknown,Unknown,,,,,10.3386/w3210,"Growth in this model is driven by technological change that arises from intentional investment decisions made by profit maximizing agents.The distinguishing feature of the technology as an input is that it is neither a conventional good nor a public good; it is a nonrival, partially excludable good.Because of the nonconvexity introduced by a nonrival good, price-taking competition cannot be supported, and instead, the equilibrium is one with monopolistic competition.The main conclusions are that the stock of human capital determines the rate of growth, that too little human capital is devoted to research in equilibrium, that integration into world markets will increase growth rates, and that having a large population is not sufficient to generate growth.",['Economics'],"technological change, intentional investment decisions, profit maximizing agents, conventional good, public good, ##conve, ##val, monopolistic competition, human capital, human, world markets"
Paper_00770,Numerical solution of initial boundary value problems involving maxwell's equations in isotropic media,['K.S. Yee'],1966,IEEE Transactions on Antennas and Propagation,Journal,,302-307,14,3,10.1109/tap.1966.1138693,"Maxwell's equations are replaced by a set of finite difference equations. It is shown that if one chooses the field points appropriately, the set of finite difference equations is applicable for a boundary condition involving perfectly conducting surfaces. An example is given of the scattering of an electromagnetic pulse by a perfectly conducting cylinder.","[""Maxwell's equations"", 'Boundary value problem', 'T-matrix method', 'Inhomogeneous electromagnetic wave equation', 'Mathematical analysis', 'Electromagnetic field solver', 'Mathematics', 'Finite difference method', 'Scattering-matrix method', 'Electromagnetic field', 'Cylinder', 'Isotropy', 'Scattering', 'Simultaneous equations', 'Independent equation', 'Physics', 'Differential equation', 'Geometry', 'Optics', 'Optical field', 'Quantum mechanics']","finite difference equations, finite difference equations, boundary condition, perfectly conducting surfaces, electromagnetic pulse, perfectly"
Paper_00774,Improved Survival with Ipilimumab in Patients with Metastatic Melanoma,"['F. Stephen Hodi', 'Steven O’Day', 'David F. McDermott', 'Robert Weber', 'Jeffrey A. Sosman', 'John B.A.G. Haanen', 'René González', 'Caroline Robert', 'Dirk Schadendorf', 'Jessica C. Hassel', 'Wallace Akerley', 'Alfons J.M. van den Eertwegh', 'Jose Lutzky', 'Paul Lorigan', 'Julia Vaübel', 'Gerald P. Linette', 'David Hogg', 'Christian H. Ottensmeier', 'Célèste Lebbé', 'Christian Peschel', 'Ian Quirt', 'Joseph I. Clark', 'Jedd D. Wolchok', 'Jeffrey S. Weber', 'Jason Tian', 'Michael Yellin', 'Geoffrey Nichol', 'Axel Hoos', 'Walter J. Urba']",2010,New England Journal of Medicine,Journal,,711-723,363,8,10.1056/nejmoa1003466,"An improvement in overall survival among patients with metastatic melanoma has been an elusive goal. In this phase 3 study, ipilimumab — which blocks cytotoxic T-lymphocyte–associated antigen 4 to potentiate an antitumor T-cell response — administered with or without a glycoprotein 100 (gp100) peptide vaccine was compared with gp100 alone in patients with previously treated metastatic melanoma.","['Ipilimumab', 'Metastatic melanoma', 'Medicine', 'Melanoma', 'Cytotoxic T cell', 'Antigen', 'Oncology', 'Cancer research', 'Overall survival', 'Peptide', 'Internal medicine', 'Immunotherapy', 'Immunology', 'Cancer', 'Biology', 'In vitro', 'Biochemistry']","metastatic melanoma, ipilimumab, ##tum, ##ly, metastatic melanoma"
Paper_00775,Standard methods for the examination of water and wastewater,[],2012,Choice Reviews Online,Journal,,49-6910,49,12,10.5860/choice.49-6910,"Standard methods for the examination of water and wastewater , Standard methods for the examination of water and wastewater , مرکز فناوری اطلاعات و اطلاع رسانی کشاورزی","['Wastewater', 'Environmental science', 'Environmental engineering']",
Paper_00777,Monte Carlo sampling methods using Markov chains and their applications,['W. Keith Hastings'],1970,Biometrika,Journal,,97-109,57,1,10.1093/biomet/57.1.97,"A generalization of the sampling method introduced by Metropolis et al. (1953) is presented along with an exposition of the relevant theory, techniques of application and methods and difficulties of assessing the error in Monte Carlo estimates. Examples of the methods, including the generation of random orthogonal matrices and potential applications of the methods to numerical problems arising in statistics, are discussed.","['Rejection sampling', 'Mathematics', 'Markov chain Monte Carlo', 'Monte Carlo method', 'Hybrid Monte Carlo', 'Generalization', 'Slice sampling', 'Sampling (signal processing)', 'Applied mathematics', 'Exposition (narrative)', 'Markov chain', 'Monte Carlo integration', 'Quasi-Monte Carlo method', 'Algorithm', 'Statistical physics', 'Statistics', 'Computer science', 'Mathematical analysis', 'Physics', 'Filter (signal processing)', 'Computer vision', 'Art', 'Literature']","sampling method, monte carlo estimates, random orthogonal matrices"
Paper_00778,Bowling alone,['Robert D. Putnam'],2000,Unknown,Unknown,,357-357,,,10.1145/358916.361990,No abstract available.,['Computer science'],
Paper_00779,Haploview: analysis and visualization of LD and haplotype maps,"['Jeffrey C. Barrett', 'Ben Fry', 'Julian Maller', 'Mark Daly']",2004,Bioinformatics,Journal,,263-265,21,2,10.1093/bioinformatics/bth457,"Research over the last few years has revealed significant haplotype structure in the human genome. The characterization of these patterns, particularly in the context of medical genetic association studies, is becoming a routine research activity. Haploview is a software package that provides computation of linkage disequilibrium statistics and population haplotype patterns from primary genotype data in a visually appealing and interactive interface.http://www.broad.mit.edu/mpg/haploview/jcbarret@broad.mit.edu","['Haplotype', 'Linkage disequilibrium', 'Visualization', 'Context (archaeology)', 'Genetic association', 'Disequilibrium', 'International HapMap Project', 'Genetics', 'Computer science', 'Data mining', 'Computational biology', 'Biology', 'Genotype', 'Single-nucleotide polymorphism', 'Medicine', 'Gene', 'Paleontology', 'Ophthalmology']","haplotype structure, human genome, medical genetic association studies, haploview, ##age disequilibrium statistics, population haplotype patterns, primary genotype data"
Paper_00781,Journal of Physics: Conference Series,"['Woro Retnaningsih', 'Wildan Mahir Muttaqin', 'Nuning Kurniasih', 'Langgeng Budianto', 'Imam Ghozali', 'Masrokan Mutohar', 'Djoko Susanto', 'Aris Slamet Widodo', 'Adi Loka']",2013,Journal of Physics Conference Series,Journal,,,,,10.1088/issn.1742-6596,"Following the rapid growth of the social media communication technology worldwide, WhatsApp (WA) becomes one of the most practical means to corelate students and lecturers.In fact, students are able to contact their lecturers anytime they need to confirm any other task and assigment.However, to contact the lecturers, students have frequently need the appropriate speech act strategy to convey thir intention.While several studies have addressed this issue by focusing on the use of hedgs to express politeness in WA to express politeness, and violations are found in approbation maxim.In an attempt to fill this gap, of the use of WA to express students confirming speech act strategy to the lecturers.The method of providing data was carried out by tapping method with recording technique.This tehcnique is screen shoot the written document of speech act used by students when communicating with lecturers by using WA.The investigation reveals that, the most widely strategy used by students in WA to lecturers was to seek an agreement and the lowest use was to imply or express reciprocity, give understanding, and cooperation with the lecturers.This study argues that students send WA to the lecturers with the various purposes.","['Series (stratigraphy)', 'Library science', 'Physics', 'Computer science', 'Geology', 'Paleontology']","social media communication technology, what, ##pp, speech act strategy, hedgs, ##ness, ##ness, wa, tapping, recording technique, screen"
Paper_00783,Rating neurologic impairment in multiple sclerosis,['John F. Kurtzke'],1983,Neurology,Journal,,1444-1444,33,11,10.1212/wnl.33.11.1444,"One method of evaluating the degree of neurologic impairment in MS has been the combination of grades (0 = normal to 5 or 6 = maximal impairment) within 8 Functional Systems (FS) and an overall Disability Status Scale (DSS) that had steps from 0 (normal) to 10 (death due to MS). A new Expanded Disability Status Scale (EDSS) is presented, with each of the former steps (1,2,3 … 9) now divided into two (1.0, 1.5, 2.0 … 9.5). The lower portion is obligatorily defined by Functional System grades. The FS are Pyramidal, Cerebellar, Brain Stem, Sensory, Bowel &amp; Bladder, Visual, Cerebral, and Other; the Sensory and Bowel &amp; Bladder Systems have been revised. Patterns of FS and relations of FS by type and grade to the DSS are demonstrated.","['Expanded Disability Status Scale', 'Multiple sclerosis', 'Medicine', 'Visual impairment', 'Sensory system', 'Physical medicine and rehabilitation', 'Audiology', 'Psychology', 'Neuroscience', 'Psychiatry']","neurologic impairment, maximal impairment, functional systems, overall disability status scale, expanded disability status scale, functional system, pyramid, ##bella"
Paper_00785,The Chemistry and Applications of Metal-Organic Frameworks,"['Hiroyasu Furukawa', 'Kyle E. Cordova', 'M. O’Keeffe', 'Omar M. Yaghi']",2013,Science,Journal,,,341,6149,10.1126/science.1230444,"Crystalline metal-organic frameworks (MOFs) are formed by reticular synthesis, which creates strong bonds between inorganic and organic units. Careful selection of MOF constituents can yield crystals of ultrahigh porosity and high thermal and chemical stability. These characteristics allow the interior of MOFs to be chemically altered for use in gas separation, gas storage, and catalysis, among other applications. The precision commonly exercised in their chemical modification and the ability to expand their metrics without changing the underlying topology have not been achieved with other solids. MOFs whose chemical composition and shape of building units can be multiply varied within a particular structure already exist and may lead to materials that offer a synergistic combination of properties.","['Porosity', 'Metal-organic framework', 'Molecule', 'Chemistry', 'Chemical engineering', 'Nanotechnology', 'Materials science', 'Organic chemistry', 'Adsorption', 'Engineering']","reticular synthesis, mof, ultrahigh porosity, chemical stability, mo, gas separation, gas storage, catalysis, mo, [PAD], [PAD], [PAD] [PAD], [PAD], [PAD], [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD], [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD]"
Paper_00787,"Cancer statistics, 2022","['Rebecca L. Siegel', 'Kimberly D. Miller', 'Hannah E. Fuchs', 'Ahmedin Jemal']",2022,CA A Cancer Journal for Clinicians,Journal,,7-33,72,1,10.3322/caac.21708,"Each year, the American Cancer Society estimates the numbers of new cancer cases and deaths in the United States and compiles the most recent data on population-based cancer occurrence and outcomes. Incidence data (through 2018) were collected by the Surveillance, Epidemiology, and End Results program; the National Program of Cancer Registries; and the North American Association of Central Cancer Registries. Mortality data (through 2019) were collected by the National Center for Health Statistics. In 2022, 1,918,030 new cancer cases and 609,360 cancer deaths are projected to occur in the United States, including approximately 350 deaths per day from lung cancer, the leading cause of cancer death. Incidence during 2014 through 2018 continued a slow increase for female breast cancer (by 0.5% annually) and remained stable for prostate cancer, despite a 4% to 6% annual increase for advanced disease since 2011. Consequently, the proportion of prostate cancer diagnosed at a distant stage increased from 3.9% to 8.2% over the past decade. In contrast, lung cancer incidence continued to decline steeply for advanced disease while rates for localized-stage increased suddenly by 4.5% annually, contributing to gains both in the proportion of localized-stage diagnoses (from 17% in 2004 to 28% in 2018) and 3-year relative survival (from 21% to 31%). Mortality patterns reflect incidence trends, with declines accelerating for lung cancer, slowing for breast cancer, and stabilizing for prostate cancer. In summary, progress has stagnated for breast and prostate cancers but strengthened for lung cancer, coinciding with changes in medical practice related to cancer screening and/or treatment. More targeted cancer control interventions and investment in improved early detection and treatment would facilitate reductions in cancer mortality.","['Medicine', 'Prostate cancer', 'Cancer', 'Lung cancer', 'Breast cancer', 'Incidence (geometry)', 'Cancer registry', 'Relative survival', 'Population', 'Epidemiology of cancer', 'Epidemiology', 'Disease', 'Demography', 'Mortality rate', 'Oncology', 'Internal medicine', 'Environmental health', 'Physics', 'Sociology', 'Optics']","american cancer society, central cancer registries, lung, female breast cancer, prostate, advanced disease, lung cancer, advanced, lung, breast, prostate cancer, lung cancer, medical, targeted cancer control"
Paper_00788,Welcome to the Tidyverse,"['Hadley Wickham', 'Mara Averick', 'Jennifer Bryan', 'Winston Chang', 'Lucy D’Agostino McGowan', 'Romain François', 'Garrett Grolemund', 'Alex Hayes', 'L. Banziiaf Henry', 'Jim Hester', 'Max Kühn', 'Thomas Lin Pedersen', 'Evan Miller', 'Stephan Bache', 'Kirill Müller', 'Jeroen Ooms', 'David M. Robinson', 'Dana P. Seidel', 'Vitalie Spinu', 'Kohske Takahashi', 'Davis Vaughan', 'Claus O. Wilke', 'Kara Woo', 'Hiroaki Yutani']",2019,The Journal of Open Source Software,Journal,,1686-1686,4,43,10.21105/joss.01686,"RESUMENEvaluación del efecto de un curso nivelatorio de matemáticas en educación superior: el caso de Matemáticas Básicas La investigación evalúa los efectos de tomar un curso de nivelación obligatorio, que se ofrece una única vez (i.e.no puede repetirse) para estudiantes de pregrado, sobre la probabilidad de matricularse, el desempeño en las asignaturas universitarias de matemáticas, avance en la carrera y probabilidad de graduarse.La investigación emplea un diseño de regresión discontinua que aprovecha el hecho de que los estudiantes admitidos a la universidad que tengan en la prueba de ingreso un puntaje en matemáticas inferior a un umbral están obligados a tomar el curso de nivelación de matemáticas básicas.Se encuentra que el curso de nivelación no tiene un efecto en la probabilidad de matricularse, de desvincularse del programa ni de graduarse seis años después de haber sido admitido.Hay un efecto",['History'],
Paper_00789,Raman Spectrum of Graphene and Graphene Layers,"['Andrea C. Ferrari', 'Jannik C. Meyer', 'Vittorio Scardaci', 'Cinzia Casiraghi', 'Michele Lazzeri', 'Francesco Mauri', 'S. Piscanec', 'Da Jiang', 'Kostya S. Novoselov', 'S. Roth', 'A. K. Geǐm']",2006,Physical Review Letters,Journal,,,97,18,10.1103/physrevlett.97.187401,"Graphene is the two-dimensional building block for carbon allotropes of every other dimensionality. We show that its electronic structure is captured in its Raman spectrum that clearly evolves with the number of layers. The $D$ peak second order changes in shape, width, and position for an increasing number of layers, reflecting the change in the electron bands via a double resonant Raman process. The $G$ peak slightly down-shifts. This allows unambiguous, high-throughput, nondestructive identification of graphene layers, which is critically lacking in this emerging research area.","['Graphene', 'Raman spectroscopy', 'Materials science', 'Carbon nanotube', 'Curse of dimensionality', 'Block (permutation group theory)', 'Nanotechnology', 'Optics', 'Physics', 'Computer science', 'Geometry', 'Mathematics', 'Machine learning']","graphene, carbon allotropes, raman spectrum, electron bands, double resonant raman process, ##destruct, graph, [PAD], [PAD], [PAD]"
Paper_00790,Least squares quantization in PCM,['Sheelagh Lloyd'],1982,IEEE Transactions on Information Theory,Journal,,129-137,28,2,10.1109/tit.1982.1056489,"It has long been realized that in pulse-code modulation (PCM), with a given ensemble of signals to handle, the quantum values should be spaced more closely in the voltage regions where the signal amplitude is more likely to fall. It has been shown by Panter and Dite that, in the limit as the number of quanta becomes infinite, the asymptotic fractional density of quanta per unit voltage should vary as the one-third power of the probability density per unit voltage of signal amplitudes. In this paper the corresponding result for any finite number of quanta is derived; that is, necessary conditions are found that the quanta and associated quantization intervals of an optimum finite quantization scheme must satisfy. The optimization criterion used is that the average quantization noise power be a minimum. It is shown that the result obtained here goes over into the Panter and Dite result as the number of quanta become large. The optimum quautization schemes for <tex xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">2^{b}</tex> quanta, <tex xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">b=1,2, \cdots, 7</tex> , are given numerically for Gaussian and for Laplacian distribution of signal amplitudes.","['Quantization (signal processing)', 'Amplitude', 'Gaussian', 'Mathematics', 'Physics', 'Quantum mechanics', 'Algorithm', 'Topology (electrical circuits)', 'Applied mathematics', 'Combinatorics']","quantum values, signal amplitude, asymptotic fractional density, probability density, signal amplitudes, quantization intervals, optimization, quantization noise power, optimum quautization schemes, gauss, laplacian distribution, signal amplitudes"
Paper_00791,Understanding the Warburg Effect: The Metabolic Requirements of Cell Proliferation,"['Matthew G. Vander Heiden', 'Lewis C. Cantley', 'Craig B. Thompson']",2009,Science,Journal,,1029-1033,324,5930,10.1126/science.1160809,"In contrast to normal differentiated cells, which rely primarily on mitochondrial oxidative phosphorylation to generate the energy needed for cellular processes, most cancer cells instead rely on aerobic glycolysis, a phenomenon termed ""the Warburg effect."" Aerobic glycolysis is an inefficient way to generate adenosine 5'-triphosphate (ATP), however, and the advantage it confers to cancer cells has been unclear. Here we propose that the metabolism of cancer cells, and indeed all proliferating cells, is adapted to facilitate the uptake and incorporation of nutrients into the biomass (e.g., nucleotides, amino acids, and lipids) needed to produce a new cell. Supporting this idea are recent studies showing that (i) several signaling pathways implicated in cell proliferation also regulate metabolic pathways that incorporate nutrients into biomass; and that (ii) certain cancer-associated mutations enable cancer cells to acquire and metabolize nutrients in a manner conducive to proliferation rather than efficient ATP production. A better understanding of the mechanistic links between cellular metabolism and growth control may ultimately lead to better treatments for human cancer.","['Warburg effect', 'Anaerobic glycolysis', 'Cancer cell', 'Oxidative phosphorylation', 'Glycolysis', 'Cell growth', 'Biology', 'Adenosine triphosphate', 'Cell biology', 'Metabolic pathway', 'Biochemistry', 'Metabolism', 'Cell', 'Cancer', 'Genetics']","mitochondrial oxidative phosphorylation, cancer cells, aerobic glycolysis, aerobic g, cancer, nu, lip, signaling pathways, cell proliferation, cellular metabolism, growth control"
Paper_00792,Atomic Force Microscope,"['G. Binnig', 'C. F. Quate', 'Ch. Gerber']",1986,Physical Review Letters,Journal,,930-933,56,9,10.1103/physrevlett.56.930,"The scanning tunneling microscope is proposed as a method to measure forces as small as ${10}^{\ensuremath{-}18}$ N. As one application for this concept, we introduce a new type of microscope capable of investigating surfaces of insulators on an atomic scale. The atomic force microscope is a combination of the principles of the scanning tunneling microscope and the stylus profilometer. It incorporates a probe that does not damage the surface. Our preliminary results in air demonstrate a lateral resolution of 30 \AA{}A and a vertical resolution less than 1 \AA{}.","['Stylus', 'Microscope', 'Profilometer', 'Scanning tunneling microscope', 'Scanning probe microscopy', 'Scanning Hall probe microscope', 'Materials science', 'Magnetic force microscope', 'Atomic force microscopy', 'Resolution (logic)', 'Optics', 'Conductive atomic force microscopy', 'Non-contact atomic force microscopy', 'Nanotechnology', 'Physics', 'Conventional transmission electron microscope', 'Scanning electron microscope', 'Surface finish', 'Computer science', 'Acoustics', 'Composite material', 'Scanning transmission electron microscopy', 'Artificial intelligence', 'Magnetization', 'Quantum mechanics', 'Magnetic field']","scanning tunneling microscope, ins, atomic force microscope, scanning tunneling microscope, stylus profilometer, lateral resolution, vertical resolution"
Paper_00795,THE USE OF MULTIPLE MEASUREMENTS IN TAXONOMIC PROBLEMS,['Ronald Aylmer Fisher'],1936,Annals of Eugenics,Journal,,179-188,7,2,10.1111/j.1469-1809.1936.tb02137.x,"The articles published by the Annals of Eugenics (1925–1954) have been made available online as an historical archive intended for scholarly use. The work of eugenicists was often pervaded by prejudice against racial, ethnic and disabled groups. The online publication of this material for scholarly research purposes is not an endorsement of those views nor a promotion of eugenics in any way.","['Eugenics', 'Prejudice (legal term)', 'Annals', 'Ethnic group', 'Promotion (chess)', 'Race (biology)', 'Sociology', 'Genealogy', 'Gender studies', 'Anthropology', 'History', 'Political science', 'Law', 'Classics', 'Politics']","eugenics, eugenicists, disabled, eugenics, [PAD], [PAD]"
Paper_00796,Introduction to Solid State Physics,"['C. Kittel', 'D. L. Dexter']",1953,American Journal of Physics,Journal,,650-650,21,8,10.1119/1.1933590,First Page,"['Physics', 'Theoretical physics', 'Statistical physics', 'Engineering physics']",
Paper_00798,The theory of the growth of the firm,['Edith Penrose'],1959,['The Journal of Business'],Unknown,,29,38,1,10.1086/294742,Introduction Preface 1. Introduction 2. The Firm in Theory 3. The Productive Opportunity of the Firm and the 'Entrepreneur' 4. Expansion Without Merger: The Receding Managerial Limit 5. 'Inherited' Resources and the Direction of Expansion 6. The Economies of Size and the Economies of Growth 7. The Economics of Diversification 8. Expansion Through Acquisition and Merger 9. The Rate of Growth of Firms Through Time 10. The Position of Large and Small Firms in a Growing Economy 11. Growing Firms in a Growing Economy: The Process of Industrial Concentration and the Pattern of Dominance,"['Diversification (marketing strategy)', 'Dominance (genetics)', 'Economics', 'Growth theory', 'Position (finance)', 'Market economy', 'Industrial organization', 'Economic system', 'Economic geography', 'Monetary economics', 'Business', 'Neoclassical economics', 'Finance', 'Biochemistry', 'Chemistry', 'Marketing', 'Gene']","firm, productive opportunity, ##eding managerial limit, economies, diversification, industrial concentration"
Paper_00799,A Ladder Of Citizen Participation,['Sherry R. Arnstein'],1969,Journal of the American Institute of Planners,Journal,,216-224,35,4,10.1080/01944366908977225,"Abstract Abstract The heated controversy over “citizen participation,” “citizen control”, and “maximum feasible involvement of the poor,” has been waged largely in terms of exacerbated rhetoric and misleading euphemisms. To encourage a more enlightened dialogue, a typology of citizen participation is offered using examples from three federal social programs: urban renewal, anti-poverty, and Model Cities. The typology, which is designed to be provocative, is arranged in a ladder pattern with each rung corresponding to the extent of citizens' power in determining the plan and/or program.","['Typology', 'Rhetoric', 'Plan (archaeology)', 'Poverty', 'Power (physics)', 'Control (management)', 'Public administration', 'Political science', 'Sociology', 'Public relations', 'Law', 'Management', 'Economics', 'Geography', 'Linguistics', 'Archaeology', 'Philosophy', 'Quantum mechanics', 'Anthropology', 'Physics']","citizen participation, citizen control, poor, citizen participation, urban renewal, model cities, [PAD], [PAD] [PAD]"
Paper_00800,An Overview of CMIP5 and the Experiment Design,"['Karl E. Taylor', 'Ronald J. Stouffer', 'Gerald A. Meehl']",2011,Bulletin of the American Meteorological Society,Journal,,485-498,93,4,10.1175/bams-d-11-00094.1,"The fifth phase of the Coupled Model Intercomparison Project (CMIP5) will produce a state-of-the- art multimodel dataset designed to advance our knowledge of climate variability and climate change. Researchers worldwide are analyzing the model output and will produce results likely to underlie the forthcoming Fifth Assessment Report by the Intergovernmental Panel on Climate Change. Unprecedented in scale and attracting interest from all major climate modeling groups, CMIP5 includes “long term” simulations of twentieth-century climate and projections for the twenty-first century and beyond. Conventional atmosphere–ocean global climate models and Earth system models of intermediate complexity are for the first time being joined by more recently developed Earth system models under an experiment design that allows both types of models to be compared to observations on an equal footing. Besides the longterm experiments, CMIP5 calls for an entirely new suite of “near term” simulations focusing on recent decades and the future to year 2035. These “decadal predictions” are initialized based on observations and will be used to explore the predictability of climate and to assess the forecast system's predictive skill. The CMIP5 experiment design also allows for participation of stand-alone atmospheric models and includes a variety of idealized experiments that will improve understanding of the range of model responses found in the more complex and realistic simulations. An exceptionally comprehensive set of model output is being collected and made freely available to researchers through an integrated but distributed data archive. For researchers unfamiliar with climate models, the limitations of the models and experiment design are described.","['Predictability', 'Coupled model intercomparison project', 'Climate model', 'Climate change', 'Computer science', 'Variety (cybernetics)', 'Earth system science', 'Scale (ratio)', 'Set (abstract data type)', 'Suite', 'Climatology', 'Range (aeronautics)', 'Downscaling', 'Environmental science', 'Meteorology', 'Geography', 'Geology', 'Artificial intelligence', 'Aerospace engineering', 'Physics', 'Oceanography', 'Cartography', 'Archaeology', 'Quantum mechanics', 'Engineering', 'Programming language']","coupled model intercomparison project, cmip, ##del, climate variability, climate change, climate change, ##ip, earth system models, long, cmip5, near term ” simulations, decadal predictions, predict, cmip"
Paper_00803,ANALYZING TABLES OF STATISTICAL TESTS,['William R. Rice'],1989,Evolution,Journal,,223-225,43,1,10.1111/j.1558-5646.1989.tb04220.x,Technique non parametrique pour la signification statistique de tables de tests utilisees dans les etudes sur l'evolution notamment,"['Biology', 'Statistical hypothesis testing', 'Statistics', 'Mathematics']","paramet, sign, [PAD], [PAD], [PAD]"
Paper_00804,"Software survey: VOSviewer, a computer program for bibliometric mapping","['Nees Jan van Eck', 'Ludo Waltman']",2009,Scientometrics,Journal,,523-538,84,2,10.1007/s11192-009-0146-3,"We present VOSviewer, a freely available computer program that we have developed for constructing and viewing bibliometric maps. Unlike most computer programs that are used for bibliometric mapping, VOSviewer pays special attention to the graphical representation of bibliometric maps. The functionality of VOSviewer is especially useful for displaying large bibliometric maps in an easy-to-interpret way. The paper consists of three parts. In the first part, an overview of VOSviewer's functionality for displaying bibliometric maps is provided. In the second part, the technical implementation of specific parts of the program is discussed. Finally, in the third part, VOSviewer's ability to handle large maps is demonstrated by using the program to construct and display a co-citation map of 5,000 major scientific journals.","['Computer science', 'Construct (python library)', 'Bibliometrics', 'Citation', 'Software', 'Representation (politics)', 'Data science', 'World Wide Web', 'Political science', 'Programming language', 'Law', 'Politics']","vosviewer, computer program, bibliometric maps, bibliometric mapping, vosviewer, graphical representation, bibliometric maps, vosviewer, ##sviewer, ##etric, ##sviewer"
Paper_00805,Introductory Econometrics: A Modern Approach,['Jeffrey M. Wooldridge'],1999,['Economica'],Unknown,,229,40,158,10.2307/2551793,1. The Nature of Econometrics and Economic Data. Part I: REGRESSION ANALYSIS WITH CROSS-SECTIONAL DATA. 2. The Simple Regression Model. 3. Multiple Regression Analysis: Estimation. 4. Multiple Regression Analysis: Inference. 5. Multiple Regression Analysis: OLS Asymptotics. 6. Multiple Regression Analysis: Further Issues. 7. Multiple Regression Analysis with Qualitative Information: Binary (or Dummy) Variables. 8. Heteroskedasticity. 9. More on Specification and Data Problems. Part II: REGRESSION ANALYSIS WITH TIME SERIES DATA. 10. Basic Regression Analysis with Time Series Data. 11. Further Issues in Using OLS with Time Series Data. 12. Serial Correlation and Heteroskedasticity in Time Series Regressions. Part III: ADVANCED TOPICS. 13. Pooling Cross Sections across Time: Simple Panel Data Methods. 14. Advanced Panel Data Methods. 15. Instrumental Variables Estimation and Two Stage Least Squares. 16. Simultaneous Equations Models. 17. Limited Dependent Variable Models and Sample Selection Corrections. 18. Advanced Time Series Topics. 19. Carrying out an Empirical Project. APPENDICES. Appendix A: Basic Mathematical Tools. Appendix B: Fundamentals of Probability. Appendix C: Fundamentals of Mathematical Statistics. Appendix D: Summary of Matrix Algebra. Appendix E: The Linear Regression Model in Matrix Form. Appendix F: Answers to Chapter Questions. Appendix G: Statistical Tables. References. Glossary. Index.,"['Regression diagnostic', 'Regression analysis', 'Simple linear regression', 'Statistics', 'Linear regression', 'Time series', 'Heteroscedasticity', 'Econometrics', 'Mathematics', 'Statistical inference', 'Ordinary least squares', 'Pooling', 'Instrumental variable', 'Series (stratigraphy)', 'Computer science', 'Polynomial regression', 'Artificial intelligence', 'Paleontology', 'Biology']","econometrics, economic data, regression, simple regression model, multiple regression analysis, multiple regression analysis, multiple regression analysis, ols asymptotics, multiple regression analysis, multiple regression analysis, qualitative, heteroskedasticity, time, basic, time series data, ##s, serial correlation, heteroskedasticity, time series regressions, advanced panel data methods, instrumental variables estimation, two stage least squares, simultaneous equations models, limited dependent variable models, sample selection corrections, probability, mathematical statistics, matrix algebra, linear regression model, statistical tables"
Paper_00806,Conducting Meta-Analyses in<i>R</i>with the<b>metafor</b>Package,['Wolfgang Viechtbauer'],2010,Journal of Statistical Software,Journal,,,36,3,10.18637/jss.v036.i03,"The <b>metafor</b> package provides functions for conducting meta-analyses in <b>R</b>. The package includes functions for fitting the meta-analytic fixed- and random-effects models and allows for the inclusion of moderators variables (study-level covariates) in these models. Meta-regression analyses with continuous and categorical moderators can be conducted in this way. Functions for the Mantel-Haenszel and Peto's one-step method for meta-analyses of 2 x 2 table data are also available. Finally, the package provides various plot functions (for example, for forest, funnel, and radial plots) and functions for assessing the model fit, for obtaining case diagnostics, and for tests of publication bias.","['Covariate', 'R package', 'Categorical variable', 'Statistics', 'Funnel plot', 'Mathematics', 'Random effects model', 'Plot (graphics)', 'Meta-analysis', 'Computer science', 'Econometrics', 'Publication bias', 'Confidence interval', 'Medicine', 'Internal medicine']","moderators, ##egorical, plot functions, funnel, radial plots, case diagnostics, publication bias, [PAD] [PAD]"
Paper_00809,The Principles of Psychology,['William James'],1890,['The Journal of Philosophy'],Unknown,,248,23,9,10.2307/2014781,"Arguably the greatest single work in the history of psychology. James's analyses of habit, the nature of emotion, the phenomenology of attention, the stream of thought, the perception of space, and the multiplicity of the consciousness of self are still widely cited and incorporated into contemporary theoretical accounts of these phenomena.","['Phenomenology (philosophy)', 'Perception', 'Epistemology', 'Consciousness', 'Psychology', 'Cognitive science', 'Philosophy']","psychology, habit, emotion, phenomen, attention, stream, multi"
Paper_00810,Frames of Mind: The Theory of Multiple Intelligences,"['Robert Klitgaard', 'Howard Gardner']",1984,Journal of Policy Analysis and Management,Journal,,627-627,3,4,10.2307/3324560,* Introduction to the Tenth Anniversary Edition Background * The Idea of Multiple Intelligences * Intelligence: Earlier Views * Biological Foundations of Intelligence * What Is an Intelligence? The Theory * Linguistic Intelligence * Musical Intelligence * Logical-Mathematical Intelligence * Spatial Intelligence * Bodily-Kinesthetic Intelligence * The Personal Intelligences * A Critique of the Theory of Multiple Intelligences * The Socialization of Human Intelligences through Symbols Implications And Applications * The Education of Intelligences * The Application of Intelligences,"['Theory of multiple intelligences', 'Psychology', 'Mathematics education']","multiple intelligences, intelligence, biological foundations, intelligence, intelligence, linguistic intelligence, musical intelligence, spatial intelligence, personal intelligences, multiple intelligences, human intelligence, intelligence"
Paper_00811,A new optimizer using particle swarm theory,"['R.C. Eberhart', 'James Kennedy']",2002,Unknown,Unknown,,39-43,,,10.1109/mhs.1995.494215,"The optimization of nonlinear functions using particle swarm methodology is described. Implementations of two paradigms are discussed and compared, including a recently developed locally oriented paradigm. Benchmark testing of both paradigms is described, and applications, including neural network training and robot task learning, are proposed. Relationships between particle swarm optimization and both artificial life and evolutionary computation are reviewed.","['Particle swarm optimization', 'Benchmark (surveying)', 'Computer science', 'Multi-swarm optimization', 'Evolutionary computation', 'Implementation', 'Artificial neural network', 'Task (project management)', 'Metaheuristic', 'Artificial intelligence', 'Computation', 'Swarm robotics', 'Swarm behaviour', 'Swarm intelligence', 'Evolutionary algorithm', 'Robot', 'Mathematical optimization', 'Machine learning', 'Algorithm', 'Mathematics', 'Engineering', 'Geodesy', 'Systems engineering', 'Programming language', 'Geography']","nonlinear functions, particle swarm methodology, locally oriented paradigm, ##mark testing, neural network training, robot task learning, particle swarm optimization, artificial life, evolutionary computation, [PAD], [PAD] [PAD] [PAD] [PAD], [PAD], [PAD] [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"
Paper_00812,Note on an Approximation Treatment for Many-Electron Systems,"['CHR. KN. MØLLER', 'M. S. Plesset']",1934,Physical Review,Journal,,618-622,46,7,10.1103/physrev.46.618,A perturbation theory is developed for treating a system of $n$ electrons in which the Hartree-Fock solution appears as the zero-order approximation. It is shown by this development that the first order correction for the energy and the charge density of the system is zero. The expression for the second-order correction for the energy greatly simplifies because of the special property of the zero-order solution. It is pointed out that the development of the higher approximation involves only calculations based on a definite one-body problem.,"['Electron', 'Zero order', 'Zero (linguistics)', 'Perturbation theory (quantum mechanics)', 'Physics', 'Hartree–Fock method', 'Order (exchange)', 'Quantum electrodynamics', 'Perturbation (astronomy)', 'Total energy', 'Quantum mechanics', 'First order', 'Mathematics', 'Applied mathematics', 'Psychology', 'Linguistics', 'Philosophy', 'Displacement (psychology)', 'Finance', 'Economics', 'Psychotherapist']","perturbation theory, charge density"
Paper_00813,An Integrative Model Of Organizational Trust,"['Roger C. Mayer', 'James H. Davis', 'F. David Schoorman']",1995,Academy of Management Review,Journal,,709-734,20,3,10.5465/amr.1995.9508080335,"Scholars in various disciplines have considered the causes, nature, and effects of trust. Prior approaches to studying trust are considered, including characteristics of the trustor, the trustee, and the role of risk. A definition of trust and a model of its antecedents and outcomes are presented, which integrate research from multiple disciplines and differentiate trust from similar constructs. Several research propositions based on the model are presented.","['Organizational behavior', 'Psychology', 'Organizational culture', 'Sociology', 'Management', 'Knowledge management', 'Social psychology', 'Public relations', 'Political science', 'Computer science', 'Economics']","trust, trust, trust, trustee, risk, trust, trust, [PAD], [PAD]"
Paper_00814,Diagnosis and Classification of Diabetes Mellitus,[],2010,Diabetes Care,Journal,,S62-S69,34,Supplement_1,10.2337/dc11-s062,"OF DIABETES MELLITUS -Diabetes is a group of metabolic diseases characterized by hyperglycemia resulting from defects in insulin secretion, insulin action, or both.The chronic hyperglycemia of diabetes is associated with long-term damage, dysfunction, and failure of differentorgans, especially the eyes, kidneys, nerves, heart, and blood vessels.Several pathogenic processes are involved in the development of diabetes.These range from autoimmune destruction of the ␤-cells of the pancreas with consequent insulin deficiency to abnormalities that result in resistance to insulin action.The basis of the abnormalities in carbohydrate, fat, and protein metabolism in diabetes is deficient action of insulin on target tissues.Deficient insulin action results from inadequate insulin secretion and/or diminished tissue responses to insulin at one or more points in the complex pathways of hormone action.Impairment of insulin secretion and defects in insulin action frequently coexist in the same patient, and it is often unclear which abnormality, if either alone, is the primary cause of the hyperglycemia.Symptoms of marked hyperglycemia include polyuria, polydipsia, weight loss, sometimes with polyphagia, and blurred vision.Impairment of growth and susceptibility to certain infections may also accompany chronic hyperglycemia.Acute, life-threatening consequences of uncontrolled diabetes are hyperglycemia with ketoacidosis or the nonketotic hyperosmolar syndrome.Long-term complications of diabetes include retinopathy with potential loss of vision; nephropathy leading to renal failure; peripheral neuropathy with risk of foot ulcers, amputations, and Charcot joints; and autonomic neuropathy causing gastrointestinal, genitourinary, and Section on gestational diabetes diagnosis","['Medicine', 'Diabetes mellitus', 'Internal medicine', 'MEDLINE', 'Endocrinology', 'Political science', 'Law']","insulin secretion, insulin, chronic hyperglycemia, protein, insulin secretion, poly, polydipsia, weight loss, poly, blurred vision, nonketotic hyper, retino, renal, peripheral neuropathy, foot ulcers, amp, charcot joints, auto, ##mic neuropathy, gestational diabetes"
Paper_00818,Markets and Hierarchies: Analysis and Antitrust Implications.,"['D. O’Brien', 'Oliver E. Williamson']",1976,The Economic Journal,Journal,,619-619,86,343,10.2307/2230812,"Journal Article Markets and Hierarchies: Analysis and Antitrust Implications Get access Markets and Hierarchies: Analysis and Antitrust Implications. By O. E. WILLIAMSON. (London: Collier-Macmillan, 1975. Pp. xvii + 286. £995.) D. P. O'Brien D. P. O'Brien University of Durham Search for other works by this author on: Oxford Academic Google Scholar The Economic Journal, Volume 86, Issue 343, 1 September 1976, Pages 619–621, https://doi.org/10.2307/2230812 Published: 01 September 1976","['Economic analysis', 'Economics', 'Political science', 'Law and economics', 'Classical economics']","hierarchies, antitrust, hierarchies, antitrust, economic, [PAD] [PAD] [PAD], [PAD] [PAD]"
Paper_00822,The Forms of Capital,['Pierre Bourdieu'],2002,Unknown,Unknown,,280-291,,,10.1002/9780470755679.ch15,"Capital is accumulated labor that, when appropriated on a private, that is, exclusive, basis by agents or groups of agents, enables them to appropriate social energy in the form of reified or living labor. Most of the properties of cultural capital can be deduced from the fact that, in its fundamental state, it is linked to the body and presupposes embodiment. Cultural capital, in the objectified state, has a number of properties that are defined only in the relationship with cultural capital in its embodied form. By conferring institutional recognition on the cultural capital possessed by any given agent, the academic qualification also makes it possible to compare qualification holders and even to exchange them. Furthermore, it makes it possible to establish conversion rates between cultural capital and economic capital by guaranteeing the monetary value of a given academic capital.","['Capital (architecture)', 'Business', 'Geography', 'Archaeology']","accumulated labor, social energy, living labor, cultural capital, cultural capital, institutional recognition, academic qualification, qualification holders, cultural capital, economic capital, monetary value, academic capital"
Paper_00823,All-Atom Empirical Potential for Molecular Modeling and Dynamics Studies of Proteins,"['Alexander D. MacKerell', 'Donald Bashford', 'M. Bellott', 'Roland L. Dunbrack', 'Jeffrey D. Evanseck', 'Martin J. Field', 'Stefan Fischer', 'Jun Gao', 'Hong Guo', 'Sookhee Ha', 'Diane Joseph‐McCarthy', 'L. Kuchnir', 'Krzysztof Kuczera', 'Frankie Tat Kwong Lau', 'Carla Mattos', 'Stephen W. Michnick', 'Thuy T. M. Ngo', 'Dzung T. Nguyen', ""Blaise Prod'hom"", 'W. E. Reiher', 'Benoı̂t Roux', 'Michael Schlenkrich', 'Jeremy C. Smith', 'Roland H. Stote', 'John E. Straub', 'Masakatsu Watanabe', 'Joanna Wiórkiewicz-Kuczera', 'Tyler Yin', 'Martin Karplus']",1998,The Journal of Physical Chemistry B,Journal,,3586-3616,102,18,10.1021/jp973084f,"New protein parameters are reported for the all-atom empirical energy function in the CHARMM program. The parameter evaluation was based on a self-consistent approach designed to achieve a balance between the internal (bonding) and interaction (nonbonding) terms of the force field and among the solvent-solvent, solvent-solute, and solute-solute interactions. Optimization of the internal parameters used experimental gas-phase geometries, vibrational spectra, and torsional energy surfaces supplemented with ab initio results. The peptide backbone bonding parameters were optimized with respect to data for N-methylacetamide and the alanine dipeptide. The interaction parameters, particularly the atomic charges, were determined by fitting ab initio interaction energies and geometries of complexes between water and model compounds that represented the backbone and the various side chains. In addition, dipole moments, experimental heats and free energies of vaporization, solvation and sublimation, molecular volumes, and crystal pressures and structures were used in the optimization. The resulting protein parameters were tested by applying them to noncyclic tripeptide crystals, cyclic peptide crystals, and the proteins crambin, bovine pancreatic trypsin inhibitor, and carbonmonoxy myoglobin in vacuo and in crystals. A detailed analysis of the relationship between the alanine dipeptide potential energy surface and calculated protein φ, χ angles was made and used in optimizing the peptide group torsional parameters. The results demonstrate that use of ab initio structural and energetic data by themselves are not sufficient to obtain an adequate backbone representation for peptides and proteins in solution and in crystals. Extensive comparisons between molecular dynamics simulations and experimental data for polypeptides and proteins were performed for both structural and dynamic properties. Energy minimization and dynamics simulations for crystals demonstrate that the latter are needed to obtain meaningful comparisons with experimental crystal structures. The presented parameters, in combination with the previously published CHARMM all-atom parameters for nucleic acids and lipids, provide a consistent set for condensed-phase simulations of a wide variety of molecules of biological interest.","['Chemistry', 'Solvation', 'Ab initio', 'Molecular dynamics', 'Dipeptide', 'Computational chemistry', 'Potential energy', 'Protein crystallization', 'Crystallography', 'Thermodynamics', 'Chemical physics', 'Solvent', 'Peptide', 'Organic chemistry', 'Atomic physics', 'Crystallization', 'Biochemistry', 'Physics']","charmm, vibrational spectra, torsional energy surfaces, peptide backbone bonding parameters, alan, atomic, dipole moments, free energies, ##ation, crystal, non, ##ic tripeptide crystals, cyclic peptide crystals, cram, bovine pancreatic try, χ, molecular, energy mini, dynamics, lipids"
Paper_00824,A survey on sensor networks,"['Ian F. Akyildiz', 'Weilian Su', 'Yogesh Sankarasubramaniam', 'Erdal Çayırcı']",2002,IEEE Communications Magazine,Journal,,102-114,40,8,10.1109/mcom.2002.1024422,"The advancement in wireless communications and electronics has enabled the development of low-cost sensor networks. The sensor networks can be used for various application areas (e.g., health, military, home). For different application areas, there are different technical issues that researchers are currently resolving. The current state of the art of sensor networks is captured in this article, where solutions are discussed under their related protocol stack layer sections. This article also points out the open research issues and intends to spark new interests and developments in this field.","['Wireless sensor network', 'Computer science', 'Protocol stack', 'SPARK (programming language)', 'Open research', 'Field (mathematics)', 'Electronics', 'Telecommunications', 'Key distribution in wireless sensor networks', 'Computer network', 'State (computer science)', 'Protocol (science)', 'Stack (abstract data type)', 'Wireless', 'Wireless network', 'Electrical engineering', 'Engineering', 'World Wide Web', 'Medicine', 'Alternative medicine', 'Mathematics', 'Algorithm', 'Pathology', 'Pure mathematics', 'Programming language']","wireless communications, electronics, sensor networks, protocol stack layer"
Paper_00825,Spectrometric identification of organic compounds,"['Robert M. Silverstein', 'G. Clayton Bassler']",1962,Journal of Chemical Education,Journal,,546-546,39,11,10.1021/ed039p546,"ADVERTISEMENT RETURN TO ISSUEPREVArticleNEXTSpectrometric identification of organic compoundsRobert M. Silverstein and G. Clayton Bassler Cite this: J. Chem. Educ. 1962, 39, 11, 546Publication Date (Print):November 1, 1962Publication History Received3 August 2009Published online1 November 1962Published inissue 1 November 1962https://doi.org/10.1021/ed039p546RIGHTS & PERMISSIONSArticle Views8834Altmetric-Citations341LEARN ABOUT THESE METRICSArticle Views are the COUNTER-compliant sum of full text article downloads since November 2008 (both PDF and HTML) across all institutions and individuals. These metrics are regularly updated to reflect usage leading up to the last few days.Citations are the number of other articles citing this article, calculated by Crossref and updated daily. Find more information about Crossref citation counts.The Altmetric Attention Score is a quantitative measure of the attention that a research article has received online. Clicking on the donut icon will load a page at altmetric.com with additional details about the score and the social media presence for the given article. Find more information on the Altmetric Attention Score and how the score is calculated. Share Add toView InAdd Full Text with ReferenceAdd Description ExportRISCitationCitation and abstractCitation and referencesMore Options Share onFacebookTwitterWechatLinked InReddit PDF (4 MB) Get e-Alerts Get e-Alerts","['Altmetrics', 'Citation', 'Icon', 'Identification (biology)', 'Social media', 'Computer science', 'Information retrieval', 'Library science', 'World Wide Web', 'Botany', 'Biology', 'Programming language']","##varticlenextspectrometric identification, organic compounds, permissionsar, ##le views, cross, ##f, cross, ##f, altmetric attention score, alt, social media presence, altmetric attention score, ##d, ##ation, abstract, ##ation"
Paper_00827,Theory of elasticity,"['S. Timoshenko', 'James Norman Goodier']",1934,"['World Scientific Series on Nonlinear Science Series A', 'Continuum Mechanics Via Problems and Exercises']",Unknown,,179-213,,,10.1142/9789812796370_0006,Chapter 1: Stresses and Strains Chapter 2: Foundations of Plasticity Chapter 3: Elasto-Plastic Bending and Torsion Chapter 4: Plastic Analysis of Beams and Frames Chapter 5: Further Solutions of Elasto-Plastic Problems Chapter 6: Theory of the Slipline Field Chapter 7: Steady Problems in Plane Strain Chapter 8: Non-Steady Problems in Plane Strain,"['Torsion (gastropod)', 'Plasticity', 'Plane stress', 'Elasticity (physics)', 'Structural engineering', 'Plastic bending', 'Plasticity theory', 'Bending', 'Mathematics', 'Classical mechanics', 'Materials science', 'Mechanics', 'Engineering', 'Physics', 'Composite material', 'Finite element method', 'Bending stiffness', 'Medicine', 'Surgery']","stresses, strains, plasticity, torsion, plastic analysis, beams, slipline field, steady problems, plane strain, non, steady problems, plane strain, [PAD], [PAD], [PAD] [PAD], [PAD], [PAD], [PAD], [PAD] [PAD], [PAD], [PAD] [PAD], [PAD], [PAD], [PAD]"
Paper_00828,Analysis of molecular variance inferred from metric distances among DNA haplotypes: application to human mitochondrial DNA restriction data.,"['Laurent Excoffier', 'Peter E. Smouse', 'Joseph M. Quattro']",1992,Genetics,Journal,,479-491,131,2,10.1093/genetics/131.2.479,"Abstract We present here a framework for the study of molecular variation within a single species. Information on DNA haplotype divergence is incorporated into an analysis of variance format, derived from a matrix of squared-distances among all pairs of haplotypes. This analysis of molecular variance (AMOVA) produces estimates of variance components and F-statistic analogs, designated here as phi-statistics, reflecting the correlation of haplotypic diversity at different levels of hierarchical subdivision. The method is flexible enough to accommodate several alternative input matrices, corresponding to different types of molecular data, as well as different types of evolutionary assumptions, without modifying the basic structure of the analysis. The significance of the variance components and phi-statistics is tested using a permutational approach, eliminating the normality assumption that is conventional for analysis of variance but inappropriate for molecular data. Application of AMOVA to human mitochondrial DNA haplotype data shows that population subdivisions are better resolved when some measure of molecular differences among haplotypes is introduced into the analysis. At the intraspecific level, however, the additional information provided by knowing the exact phylogenetic relations among haplotypes or by a nonlinear translation of restriction-site change into nucleotide diversity does not significantly modify the inferred population genetic structure. Monte Carlo studies show that site sampling does not fundamentally affect the significance of the molecular variance components. The AMOVA treatment is easily extended in several different directions and it constitutes a coherent and flexible framework for the statistical analysis of molecular data.","['Biology', 'Analysis of molecular variance', 'Haplotype', 'Population', 'Genetics', 'Nucleotide diversity', 'Evolutionary biology', 'Population variance', 'Statistics', 'Mathematics', 'Estimator', 'Gene', 'Genotype', 'Demography', 'Sociology']","molecular variation, dna haplotype divergence, molecular variance, amova, variance, haplotypic diversity, hierarchical subdivision, permutational, normality assumption, amova, human mitochondrial dna haplotype data, phylogenetic, site sampling, am"
Paper_00829,Eigenfaces for Recognition,"['Matthew Turk', 'Alex Pentland']",1991,Journal of Cognitive Neuroscience,Journal,,71-86,3,1,10.1162/jocn.1991.3.1.71,"We have developed a near-real-time computer system that can locate and track a subject's head, and then recognize the person by comparing characteristics of the face to those of known individuals. The computational approach taken in this system is motivated by both physiology and information theory, as well as by the practical requirements of near-real-time performance and accuracy. Our approach treats the face recognition problem as an intrinsically two-dimensional (2-D) recognition problem rather than requiring recovery of three-dimensional geometry, taking advantage of the fact that faces are normally upright and thus may be described by a small set of 2-D characteristic views. The system functions by projecting face images onto a feature space that spans the significant variations among known face images. The significant features are known as ""eigenfaces,"" because they are the eigenvectors (principal components) of the set of faces; they do not necessarily correspond to features such as eyes, ears, and noses. The projection operation characterizes an individual face by a weighted sum of the eigenface features, and so to recognize a particular face it is necessary only to compare these weights to those of known individuals. Some particular advantages of our approach are that it provides for the ability to learn and later recognize new faces in an unsupervised manner, and that it is easy to implement using a neural network architecture.","['Eigenface', 'Face (sociological concept)', 'Facial recognition system', 'Projection (relational algebra)', 'Artificial intelligence', 'Set (abstract data type)', 'Computer science', 'Pattern recognition (psychology)', 'Feature (linguistics)', 'Artificial neural network', 'Principal (computer security)', 'Computer vision', 'Machine learning', 'Algorithm', 'Social science', 'Linguistics', 'Philosophy', 'Sociology', 'Programming language', 'Operating system']","information theory, face recognition, eigenfaces, e, ##ve, eyes, ears, noses, neural network architecture"
Paper_00830,An Analysis of Transformations,"['George E. P. Box', 'David R. Cox']",1964,Journal of the Royal Statistical Society Series B (Statistical Methodology),Journal,,211-243,26,2,10.1111/j.2517-6161.1964.tb00553.x,"Summary In the analysis of data it is often assumed that observations y 1, y 2, …, yn are independently normally distributed with constant variance and with expectations specified by a model linear in a set of parameters θ. In this paper we make the less restrictive assumption that such a normal, homoscedastic, linear model is appropriate after some suitable transformation has been applied to the y's. Inferences about the transformation and about the parameters of the linear model are made by computing the likelihood function and the relevant posterior distribution. The contributions of normality, homoscedasticity and additivity to the transformation are separated. The relation of the present methods to earlier procedures for finding transformations is discussed. The methods are illustrated with examples.","['Homoscedasticity', 'Transformation (genetics)', 'Normality', 'Applied mathematics', 'Additive function', 'Mathematics', 'Constant (computer programming)', 'Data transformation', 'Set (abstract data type)', 'Linear map', 'Linear model', 'Variance (accounting)', 'Heteroscedasticity', 'Statistics', 'Computer science', 'Pure mathematics', 'Mathematical analysis', 'Data mining', 'Biochemistry', 'Chemistry', 'Accounting', 'Business', 'Data warehouse', 'Gene', 'Programming language']","constant variance, likelihood function, posterior distribution, normality, homoscedasticity, additivity"
Paper_00831,Data Reduction and Error Analysis for the Physical Sciences,"['P. R. Bevington', 'D. Keith Robinson']",1969,['Journal of Quality Technology'],Unknown,,119-120,4,2,10.1080/00224065.1972.11980528,Uncertainties in measurements probability distributions error analysis estimates of means and errors Monte Carlo techniques dependent and independent variables least-squares fit to a polynomial least-squares fit to an arbitrary function fitting composite peaks direct application of the maximum likelihood. Appendices: numerical methods matrices graphs and tables histograms and graphs computer routines in Pascal.,"['Monte Carlo method', 'Pascal (unit)', 'Histogram', 'Statistics', 'Applied mathematics', 'Least-squares function approximation', 'Mathematics', 'Reduction (mathematics)', 'Algorithm', 'Data reduction', 'Computer science', 'Artificial intelligence', 'Geometry', 'Estimator', 'Image (mathematics)', 'Programming language']","uncertainties, measurements probability distributions error analysis, composite peaks, maximum likelihood, numerical methods, computer routines"
Paper_00832,UCHIME improves sensitivity and speed of chimera detection,"['R. C. Edgar', 'Brian J. Haas', 'José C. Clemente', 'Christopher Quince', 'Rob Knight']",2011,Bioinformatics,Journal,,2194-2200,27,16,10.1093/bioinformatics/btr381,"Abstract Motivation: Chimeric DNA sequences often form during polymerase chain reaction amplification, especially when sequencing single regions (e.g. 16S rRNA or fungal Internal Transcribed Spacer) to assess diversity or compare populations. Undetected chimeras may be misinterpreted as novel species, causing inflated estimates of diversity and spurious inferences of differences between populations. Detection and removal of chimeras is therefore of critical importance in such experiments. Results: We describe UCHIME, a new program that detects chimeric sequences with two or more segments. UCHIME either uses a database of chimera-free sequences or detects chimeras de novo by exploiting abundance data. UCHIME has better sensitivity than ChimeraSlayer (previously the most sensitive database method), especially with short, noisy sequences. In testing on artificial bacterial communities with known composition, UCHIME de novo sensitivity is shown to be comparable to Perseus. UCHIME is &amp;gt;100× faster than Perseus and &amp;gt;1000× faster than ChimeraSlayer. Contact: robert@drive5.com Availability: Source, binaries and data: http://drive5.com/uchime. Supplementary information: Supplementary data are available at Bioinformatics online.","['Chimera (genetics)', 'Computational biology', 'Biology', 'Spurious relationship', 'Polymerase chain reaction', 'Genetics', 'Computer science', 'Gene', 'Machine learning']","chimeric dna sequences, polymerase chain reaction, fungal internal transcribed spacer, ##cted, ##as, uchime, ##hime, abundance data, ##e, chimeraslayer, perseus, ##us, chi, ##as, bioinformatics"
Paper_00833,"Atomically Thin<mml:math xmlns:mml=""http://www.w3.org/1998/Math/MathML"" display=""inline""><mml:msub><mml:mi>MoS</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:math>: A New Direct-Gap Semiconductor","['Kin Fai Mak', 'Changgu Lee', 'James Hone', 'Jie Shan', 'Tony F. Heinz']",2010,Physical Review Letters,Journal,,,105,13,10.1103/physrevlett.105.136805,"The electronic properties of ultrathin crystals of molybdenum disulfide consisting of $N=1,2,\dots{},6$ S-Mo-S monolayers have been investigated by optical spectroscopy. Through characterization by absorption, photoluminescence, and photoconductivity spectroscopy, we trace the effect of quantum confinement on the material's electronic structure. With decreasing thickness, the indirect band gap, which lies below the direct gap in the bulk material, shifts upwards in energy by more than 0.6 eV. This leads to a crossover to a direct-gap material in the limit of the single monolayer. Unlike the bulk material, the ${\mathrm{MoS}}_{2}$ monolayer emits light strongly. The freestanding monolayer exhibits an increase in luminescence quantum efficiency by more than a factor of ${10}^{4}$ compared with the bulk material.","['Algorithm', 'Physics', 'Computer science']","electronic properties, ultrathin crystals, mo, ##um disulfide, optical spectroscopy, photoluminescence, photoconductivity spectroscopy, quantum confinement, indirect band gap, direct gap, single mono, freestanding monolayer, luminescence quantum efficiency, [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD], [PAD] [PAD]"
Paper_00834,Ground State of the Electron Gas by a Stochastic Method,"['David M. Ceperley', 'B. J. Alder']",1980,Physical Review Letters,Journal,,566-569,45,7,10.1103/physrevlett.45.566,"An exact stochastic simulation of the Schroedinger equation for charged bosons and fermions has been used to calculate the correlation energies, to locate the transitions to their respective crystal phases at zero temperature within 10%, and to establish the stability at intermediate densities of a ferromagnetic fluid of electrons.","['Fermion', 'Physics', 'Electron', 'Boson', 'Ground state', 'Fermi gas', 'Stability (learning theory)', 'Ferromagnetism', 'Equation of state', 'Schrödinger equation', 'Quantum mechanics', 'Condensed matter physics', 'Quantum electrodynamics', 'Atomic physics', 'Computer science', 'Machine learning']","stochastic simulation, schroedinger equation, charged bosons, fermions, correlation energies, crystal, intermediate densities, ferromagnetic fluid, [PAD], [PAD], [PAD], [PAD] [PAD] [PAD], [PAD] [PAD], [PAD], [PAD] [PAD] [PAD] [PAD], [PAD] [PAD], [PAD] [PAD] [PAD] [PAD] [PAD], [PAD] [PAD], [PAD] [PAD], [PAD] [PAD]"
Paper_00835,Energy-efficient communication protocol for wireless microsensor networks,"['Wendi Heinzelman', 'Anantha P. Chandrakasan', 'Hari Balakrishnan']",2005,Unknown,Unknown,,10-10,vol.1,,10.1109/hicss.2000.926982,"Wireless distributed microsensor systems will enable the reliable monitoring of a variety of environments for both civil and military applications. In this paper, we look at communication protocols, which can have significant impact on the overall energy dissipation of these networks. Based on our findings that the conventional protocols of direct transmission, minimum-transmission-energy, multi-hop routing, and static clustering may not be optimal for sensor networks, we propose LEACH (Low-Energy Adaptive Clustering Hierarchy), a clustering-based protocol that utilizes randomized rotation of local cluster based station (cluster-heads) to evenly distribute the energy load among the sensors in the network. LEACH uses localized coordination to enable scalability and robustness for dynamic networks, and incorporates data fusion into the routing protocol to reduce the amount of information that must be transmitted to the base station. Simulations show the LEACH can achieve as much as a factor of 8 reduction in energy dissipation compared with conventional outing protocols. In addition, LEACH is able to distribute energy dissipation evenly throughout the sensors, doubling the useful system lifetime for the networks we simulated.","['Computer science', 'Routing protocol', 'Wireless sensor network', 'Cluster analysis', 'Computer network', 'Scalability', 'Base station', 'Energy consumption', 'Distributed computing', 'Robustness (evolution)', 'Efficient energy use', 'Wireless Routing Protocol', 'Dissipation', 'Routing (electronic design automation)', 'Engineering', 'Electrical engineering', 'Biochemistry', 'Chemistry', 'Database', 'Machine learning', 'Gene', 'Physics', 'Thermodynamics']","wireless distributed microsensor systems, communication protocols, energy dissipation, static clustering, leach, randomized rotation, leach, localized coordination, ##bility, robustness, data fusion, routing protocol, energy dissi"
Paper_00836,Bioinformatics enrichment tools: paths toward the comprehensive functional analysis of large gene lists,"['Da Wei Huang', 'Brad T. Sherman', 'Richard A. Lempicki']",2008,Nucleic Acids Research,Journal,,1-13,37,1,10.1093/nar/gkn923,"Functional analysis of large gene lists, derived in most cases from emerging high-throughput genomic, proteomic and bioinformatics scanning approaches, is still a challenging and daunting task. The gene-annotation enrichment analysis is a promising high-throughput strategy that increases the likelihood for investigators to identify biological processes most pertinent to their study. Approximately 68 bioinformatics enrichment tools that are currently available in the community are collected in this survey. Tools are uniquely categorized into three major classes, according to their underlying enrichment algorithms. The comprehensive collections, unique tool classifications and associated questions/issues will provide a more comprehensive and up-to-date view regarding the advantages, pitfalls and recent trends in a simpler tool-class level rather than by a tool-by-tool approach. Thus, the survey will help tool designers/developers and experienced end users understand the underlying algorithms and pertinent details of particular tool categories/tools, enabling them to make the best choices for their particular research interests.","['Biology', 'Data science', 'Annotation', 'Task (project management)', 'Computational biology', 'Computer science', 'Bioinformatics', 'Engineering', 'Systems engineering']","functional analysis, gene lists, prote, bioinformatics scanning, bioinformatics enrichment tools"
Paper_00837,Endogenous Technological Change,['Paul Romer'],1990,Journal of Political Economy,Journal,,S71-S102,98,"5, Part 2",10.1086/261725,"Growth in this model is driven by technological change that arises from intentional investment decisions made by profit-maximizing agents. The distinguishing feature of the technology as an input is that it is neither a conventional good nor a public good; it is a nonrival, partially excludable good. Because of the nonconvexity introduced by a nonrival good, price-taking competition cannot be supported. Instead, the equilibrium is one with monopolistic competition. The main conclusions are that the stock of human capital determines the rate of growth, that too little human capital is devoted to research in equilibrium, that integration into world markets will increase growth rates, and that having a large population is not sufficient to generate growth.","['Monopolistic competition', 'Economics', 'Excludability', 'Endogenous growth theory', 'Technological change', 'Microeconomics', 'Stock (firearms)', 'Profit (economics)', 'Investment (military)', 'Population growth', 'Human capital', 'Population', 'Industrial organization', 'Public good', 'Monopoly', 'Market economy', 'Macroeconomics', 'Mechanical engineering', 'Demography', 'Sociology', 'Politics', 'Political science', 'Law', 'Engineering']","technological change, intentional investment decisions, public good, ##conve, ##val, monopolistic competition, human capital, human capital, world markets"
Paper_00840,Principles of Biomedical Ethics,"['Tom L. Beauchamp', 'James F. Childress']",2012,The MIT Press eBooks,Unknown,,,,,10.7551/mitpress/9079.003.0009,"Morality and ethical theory types of ethical theory the principle of respect for autonomy the principle of nonmaleficence the principle of beneficence the principle of justice professional-patient relationships ideals, virtues and conscientiousness.","['Medicine', 'Engineering ethics', 'Intensive care medicine', 'Family medicine', 'Engineering']","morality, ethical theory, ethical theory, respect, autonomy, nonmaleficence, beneficence, justice, virtues, conscientiousness, [PAD] [PAD] [PAD], [PAD], [PAD] [PAD] [PAD], [PAD], [PAD] [PAD], [PAD], [PAD], [PAD] [PAD], [PAD], [PAD] [PAD] [PAD] [PAD]"
Paper_00842,An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale,"['Alexey Dosovitskiy', 'Lucas Beyer', 'Alexander Kolesnikov', 'Dirk Weissenborn', 'Xiaohua Zhai', 'Thomas Unterthiner', 'Mostafa Dehghani', 'Matthias Minderer', 'Georg Heigold', 'Sylvain Gelly', 'Jakob Uszkoreit', 'Neil Houlsby']",2020,arXiv (Cornell University),Unknown,,,,,10.48550/arxiv.2010.11929,"While the Transformer architecture has become the de-facto standard for natural language processing tasks, its applications to computer vision remain limited. In vision, attention is either applied in conjunction with convolutional networks, or used to replace certain components of convolutional networks while keeping their overall structure in place. We show that this reliance on CNNs is not necessary and a pure transformer applied directly to sequences of image patches can perform very well on image classification tasks. When pre-trained on large amounts of data and transferred to multiple mid-sized or small image recognition benchmarks (ImageNet, CIFAR-100, VTAB, etc.), Vision Transformer (ViT) attains excellent results compared to state-of-the-art convolutional networks while requiring substantially fewer computational resources to train.","['Image (mathematics)', 'Artificial intelligence', 'Transformer', 'Computer science', 'Computer vision', 'Scale (ratio)', 'Engineering', 'Cartography', 'Electrical engineering', 'Geography', 'Voltage']","transformer architecture, natural language processing tasks, computer vision, vision, convolutional networks, convolutional networks, cnns, image patches, image classification tasks, image recognition, imagenet, vt, vision transformer, con, ##lutional networks"
Paper_00844,WordNet,['George A. Miller'],1995,Communications of the ACM,Journal,,39-41,38,11,10.1145/219717.219748,"Because meaningful sentences are composed of meaningful words, any system that hopes to process natural languages as people do must have information about words and their meanings. This information is traditionally provided through dictionaries, and machine-readable dictionaries are now widely available. But dictionary entries evolved for the convenience of human readers, not for machines. WordNet 1 provides a more effective combination of traditional lexicographic information and modern computing. WordNet is an online lexical database designed for use under program control. English nouns, verbs, adjectives, and adverbs are organized into sets of synonyms, each representing a lexicalized concept. Semantic relations link the synonym sets [4].","['WordNet', 'Computer science', 'Lexicographical order', 'Natural language processing', 'Artificial intelligence', 'Noun', 'Synonym (taxonomy)', 'Lexical database', 'Lemmatisation', 'Process (computing)', 'Linguistics', 'Programming language', 'Mathematics', 'Philosophy', 'Botany', 'Combinatorics', 'Biology', 'Genus']","meaningful sentences, meaningful words, natural languages, dictionaries, dictionary entries, wordnet, lexico, wordnet, online lexical database, program control, english nouns, verbs, adjectives, adverbs, synonym, lexical, semantic relations, synonym sets, [PAD] [PAD], [PAD] [PAD], [PAD] [PAD], [PAD] [PAD], [PAD] [PAD], [PAD], [PAD], [PAD]"
Paper_00845,Interpretation of Raman spectra of disordered and amorphous carbon,"['Andrea C. Ferrari', 'John Robertson']",2000,"Physical review. B, Condensed matter",Journal,,14095-14107,61,20,10.1103/physrevb.61.14095,"The model and theoretical understanding of the Raman spectra in disordered and amorphous carbon are given. The nature of the G and D vibration modes in graphite is analyzed in terms of the resonant excitation of \ensuremath{\pi} states and the long-range polarizability of \ensuremath{\pi} bonding. Visible Raman data on disordered, amorphous, and diamondlike carbon are classified in a three-stage model to show the factors that control the position, intensity, and widths of the G and D peaks. It is shown that the visible Raman spectra depend formally on the configuration of the ${\mathrm{sp}}^{2}$ sites in ${\mathrm{sp}}^{2}$-bonded clusters. In cases where the ${\mathrm{sp}}^{2}$ clustering is controlled by the ${\mathrm{sp}}^{3}$ fraction, such as in as-deposited tetrahedral amorphous carbon (ta-C) or hydrogenated amorphous carbon (a-C:H) films, the visible Raman parameters can be used to derive the ${\mathrm{sp}}^{3}$ fraction.","['Raman spectroscopy', 'Amorphous carbon', 'Amorphous solid', 'Materials science', 'Polarizability', 'Carbon fibers', 'Spectral line', 'Excitation', 'Crystallography', 'Analytical Chemistry (journal)', 'Molecular physics', 'Nuclear magnetic resonance', 'Atomic physics', 'Physics', 'Chemistry', 'Optics', 'Molecule', 'Quantum mechanics', 'Chromatography', 'Composite number', 'Composite material']","raman spectra, amorphous carbon, graphite, resonant excitation, visible raman data, diamond, visible raman spectra, hydrogenated, visible raman parameters"
Paper_00846,Development and Testing of the OPLS All-Atom Force Field on Conformational Energetics and Properties of Organic Liquids,"['William L. Jorgensen', 'David S. Maxwell', 'Julian Tirado‐Rives']",1996,Journal of the American Chemical Society,Journal,,11225-11236,118,45,10.1021/ja9621760,"The parametrization and testing of the OPLS all-atom force field for organic molecules and peptides are described. Parameters for both torsional and nonbonded energetics have been derived, while the bond stretching and angle bending parameters have been adopted mostly from the AMBER all-atom force field. The torsional parameters were determined by fitting to rotational energy profiles obtained from ab initio molecular orbital calculations at the RHF/6-31G*//RHF/6-31G* level for more than 50 organic molecules and ions. The quality of the fits was high with average errors for conformational energies of less than 0.2 kcal/mol. The force-field results for molecular structures are also demonstrated to closely match the ab initio predictions. The nonbonded parameters were developed in conjunction with Monte Carlo statistical mechanics simulations by computing thermodynamic and structural properties for 34 pure organic liquids including alkanes, alkenes, alcohols, ethers, acetals, thiols, sulfides, disulfides, aldehydes, ketones, and amides. Average errors in comparison with experimental data are 2% for heats of vaporization and densities. The Monte Carlo simulations included sampling all internal and intermolecular degrees of freedom. It is found that such non-polar and monofunctional systems do not show significant condensed-phase effects on internal energies in going from the gas phase to the pure liquids.","['Chemistry', 'Force field (fiction)', 'OPLS', 'Ab initio', 'Molecule', 'Monte Carlo method', 'Computational chemistry', 'Intermolecular force', 'Enthalpy of vaporization', 'Thermodynamics', 'Molecular dynamics', 'Physical chemistry', 'Enthalpy', 'Organic chemistry', 'Physics', 'Water model', 'Artificial intelligence', 'Computer science', 'Statistics', 'Mathematics']","##rization, organic molecules, peptide, nonbonded, bond stretching, angle bending parameters, torsion, rotational energy profiles, nonbonded parameters, monte, statistical mechanics simulations, structural, al, alken, ether, th, sul"
Paper_00848,A Practical Guide to Wavelet Analysis,"['Christopher Torrence', 'Gilbert P. Compo']",1998,Bulletin of the American Meteorological Society,Journal,,61-78,79,1,10.1175/1520-0477(1998)079<0061:apgtwa>2.0.co;2,"A practical step-by-step guide to wavelet analysis is given, with examples taken from time series of the El Niño–Southern Oscillation (ENSO). The guide includes a comparison to the windowed Fourier transform, the choice of an appropriate wavelet basis function, edge effects due to finite-length time series, and the relationship between wavelet scale and Fourier frequency. New statistical significance tests for wavelet power spectra are developed by deriving theoretical wavelet spectra for white and red noise processes and using these to establish significance levels and confidence intervals. It is shown that smoothing in time or scale can be used to increase the confidence of the wavelet spectrum. Empirical formulas are given for the effect of smoothing on significance levels and confidence intervals. Extensions to wavelet analysis such as filtering, the power Hovmöller, cross-wavelet spectra, and coherence are described. The statistical significance tests are used to give a quantitative measure of changes in ENSO variance on interdecadal timescales. Using new datasets that extend back to 1871, the Niño3 sea surface temperature and the Southern Oscillation index show significantly higher power during 1880–1920 and 1960–90, and lower power during 1920–60, as well as a possible 15-yr modulation of variance. The power Hovmöller of sea level pressure shows significant variations in 2–8-yr wavelet power in both longitude and time.","['Wavelet', 'Wavelet transform', 'Smoothing', 'Mathematics', 'Statistics', 'White noise', 'Spectral density', 'Computer science', 'Artificial intelligence']","wavelet analysis, time series, el nino – southern oscillation, en, windowed fourier transform, wavelet basis function, edge effects, ##let scale, fourier frequency, statistical significance tests, wavelet power spectra, significance levels, confidence intervals, significance levels, confidence intervals, wavelet analysis, filtering, power hovmoller, coherence, statistical significance tests, enso, inter, ##dal times, sea surface temperature, southern oscillation index, power hov, sea level pressure"
Paper_00849,Sequence to Sequence Learning with Neural Networks,"['Ilya Sutskever', 'Oriol Vinyals', 'Quoc V. Le']",2014,arXiv (Cornell University),Unknown,,,,,10.48550/arxiv.1409.3215,"Deep Neural Networks (DNNs) are powerful models that have achieved excellent performance on difficult learning tasks. Although DNNs work well whenever large labeled training sets are available, they cannot be used to map sequences to sequences. In this paper, we present a general end-to-end approach to sequence learning that makes minimal assumptions on the sequence structure. Our method uses a multilayered Long Short-Term Memory (LSTM) to map the input sequence to a vector of a fixed dimensionality, and then another deep LSTM to decode the target sequence from the vector. Our main result is that on an English to French translation task from the WMT'14 dataset, the translations produced by the LSTM achieve a BLEU score of 34.8 on the entire test set, where the LSTM's BLEU score was penalized on out-of-vocabulary words. Additionally, the LSTM did not have difficulty on long sentences. For comparison, a phrase-based SMT system achieves a BLEU score of 33.3 on the same dataset. When we used the LSTM to rerank the 1000 hypotheses produced by the aforementioned SMT system, its BLEU score increases to 36.5, which is close to the previous best result on this task. The LSTM also learned sensible phrase and sentence representations that are sensitive to word order and are relatively invariant to the active and the passive voice. Finally, we found that reversing the order of the words in all source sentences (but not target sentences) improved the LSTM's performance markedly, because doing so introduced many short term dependencies between the source and the target sentence which made the optimization problem easier.","['Computer science', 'Artificial intelligence', 'Sentence', 'Phrase', 'Sequence (biology)', 'Natural language processing', 'Word (group theory)', 'Task (project management)', 'Speech recognition', 'Recurrent neural network', 'Artificial neural network', 'Machine translation', 'Vocabulary', 'Deep learning', 'Mathematics', 'Genetics', 'Biology', 'Linguistics', 'Philosophy', 'Geometry', 'Management', 'Economics']","deep neural networks, dnns, ##nns, sequence learning"
Paper_00850,2013 ESH/ESC Guidelines for the management of arterial hypertension,"['Giuseppe Mancia', 'Robert Fagard', 'Krzysztof Narkiewicz', 'Josep Redón', 'Alberto Zanchetti', 'Michael Böhm', 'Thierry Christiaens', 'Renata Cífková', 'Guy De Backer', 'Anna F. Dominiczak', 'Maurizio Galderisi', 'Diederick E. Grobbee', 'Tiny Jaarsma', 'Paulus Kirchhof', 'Sverre E. Kjeldsen', 'Stéphane Laurent', 'Athanasios J Manolis', 'Peter M. Nilsson', 'Luís M. Ruilope', 'Roland E Schmieder', 'Per Anton Sirnes', 'Peter Sleight', 'Margus Viigimaa', 'Bernard Waeber', 'Faı̈ez Zannad', 'Michel Burnier', 'Ettore Ambrosioni', 'Mark Caufield', 'António Coca', 'Michael Hecht Olsen', 'Costas Tsioufis', 'Philippe van de Borne', 'Jose Luis Zamorano', 'Stephan Achenbach', 'Helmut Baumgartner', 'Jeroen J. Bax', 'Héctor Bueno', 'Veronica Dean', 'Christi Deaton', 'Çetin Erol', 'Roberto Ferrari', 'David Hasdai', 'Arno W Hoes', 'Juhani Knuuti', 'Philippe Kolh', 'Patrizio Lancellotti', 'Aleš Linhart', 'Petros Nihoyannopoulos', 'Massimo Piepoli', 'Piotr Ponikowski', 'Juan Tamargo', 'Michał Tendera', 'Adam Torbicki', 'William Wijns', 'Stephan Windecker', 'Denis Clément', 'Thierry Gillebert', 'Enrico Agabiti Rosei', 'Stefan D Anker', 'Johann Bauersachs', 'Jana Brguljan Hitij', 'Mark J. Caulfield', 'Marc De Buyzere', 'Sabina De Geest', 'Geneviève Dérumeaux', 'Serap Erdine', 'Csaba Farsang', 'Christian Funck‐Brentano', 'Vjekoslav Gerc', 'Giuseppe Germanò', 'Stephan Gielen', 'Herman Haller', 'Jens Jordan', 'Thomas Kahan', 'Michel Komajda', 'Dragan Lović', 'Heiko Mahrholdt', 'Jan Ostergren', 'Gianfranco Parati', 'Joep Perk', 'Jorge Polónia', 'Bogdan A Popescu', 'Zeljko Reiner', 'Lars Rydén', 'Yu.M. Sіrenko', 'Alice Stanton', 'Harry Struijker-Boudier', 'Charalambos Vlachopoulos', 'Massimo Volpe', 'David Wood']",2013,European Heart Journal,Journal,,2159-2219,34,28,10.1093/eurheartj/eht151,"The ESH/ESC Guidelines represent the views of the ESH and ESC and were arrived at after careful consideration of the available evidence at the time they were written.Health professionals are encouraged to take them fully into account when exercising their clinical judgement.The guidelines do not, however, override the individual responsibility of health professionals to make appropriate decisions in the circumstances of the individual patients, in consultation with that patient, and where appropriate and necessary the patient's guardian or carer.It is also the health professional's responsibility to verify the rules and regulations applicable to drugs and devices at the time of prescription.","['Medicine', 'Internal medicine', 'Cardiology', 'Candesartan', 'Blood pressure', 'Kidney disease', 'Diabetes mellitus', 'Stroke (engine)', 'Coronary artery disease', 'Angiotensin II', 'Endocrinology', 'Mechanical engineering', 'Engineering']","health, health, health"
Paper_00851,An Introduction to Support Vector Machines and Other Kernel-based Learning Methods,"['Nello Cristianini', 'John Shawe‐Taylor']",2000,Unknown,Unknown,,,,,10.1017/cbo9780511801389,"This is the first comprehensive introduction to Support Vector Machines (SVMs), a generation learning system based on recent advances in statistical learning theory. SVMs deliver state-of-the-art performance in real-world applications such as text categorisation, hand-written character recognition, image classification, biosequences analysis, etc., and are now established as one of the standard tools for machine learning and data mining. Students will find the book both stimulating and accessible, while practitioners will be guided smoothly through the material required for a good grasp of the theory and its applications. The concepts are introduced gradually in accessible and self-contained stages, while the presentation is rigorous and thorough. Pointers to relevant literature and web sites containing software ensure that it forms an ideal starting point for further study. Equally, the book and its associated web site will guide practitioners to updated literature, new applications, and on-line software.","['Computer science', 'GRASP', 'Support vector machine', 'Point (geometry)', 'Artificial intelligence', 'Statistical learning theory', 'Presentation (obstetrics)', 'Machine learning', 'Software', 'Kernel (algebra)', 'Data science', 'Software engineering', 'Programming language', 'Medicine', 'Geometry', 'Combinatorics', 'Radiology', 'Mathematics']","support vector machines, svms, generation learning system, statistical learning theory, svms, text categorisation, image classification, biosequences analysis, machine learning, data mining"
Paper_00852,A Brief History of Neoliberalism,['David J. Harvey'],2005,Oxford University Press eBooks,Unknown,,,,,10.1093/oso/9780199283262.001.0001,"Neoliberalism--the doctrine that market exchange is an ethic in itself, capable of acting as a guide for all human action--has become dominant in both thought and practice throughout much of the world since 1970 or so. Writing for a wide audience, David Harvey, author of The New Imperialism and The Condition of Postmodernity, here tells the political-economic story of where neoliberalization came from and how it proliferated on the world stage. Through critical engagement with this history, he constructs a framework, not only for analyzing the political and economic dangers that now surround us, but also for assessing the prospects for the more socially just alternatives being advocated by many oppositional movements.","['Neoliberalism (international relations)', 'Postmodernity', 'Doctrine', 'Politics', 'Action (physics)', 'Political economy', 'Sociology', 'Political science', 'Environmental ethics', 'Aesthetics', 'Law', 'Philosophy', 'Modernity', 'Physics', 'Quantum mechanics']","neoliberalism, market exchange, ##modern, neoliberal"
Paper_00853,Organic electroluminescent diodes,"['Chak Wah Tang', 'S. A. VanSlyke']",1987,Applied Physics Letters,Journal,,913-915,51,12,10.1063/1.98799,"A novel electroluminescent device is constructed using organic materials as the emitting elements. The diode has a double-layer structure of organic thin films, prepared by vapor deposition. Efficient injection of holes and electrons is provided from an indium-tin-oxide anode and an alloyed Mg:Ag cathode. Electron-hole recombination and green electroluminescent emission are confined near the organic interface region. High external quantum efficiency (1% photon/electron), luminous efficiency (1.5 lm/W), and brightness (&amp;gt;1000 cd/m2) are achievable at a driving voltage below 10 V.","['Electroluminescence', 'Materials science', 'OLED', 'Indium tin oxide', 'Anode', 'Optoelectronics', 'Quantum efficiency', 'Cathode', 'Diode', 'Indium', 'Brightness', 'Luminous efficacy', 'Chemical vapor deposition', 'Organic semiconductor', 'Thin film', 'Layer (electronics)', 'Electrode', 'Optics', 'Chemistry', 'Nanotechnology', 'Physics', 'Physical chemistry']","electroluminescent device, organic materials, organic thin films, vapor deposition, green electroluminescent emission, organic interface region, external quantum efficiency, luminous efficiency, brightness"
Paper_00854,Hierarchical Linear Models: Applications and Data Analysis Methods,['Marie Davidian'],2003,Journal of the American Statistical Association,Journal,,767-768,98,463,10.1198/jasa.2003.s288,"(2003). Hierarchical Linear Models: Applications and Data Analysis Methods. Journal of the American Statistical Association: Vol. 98, No. 463, pp. 767-768.","['Computer science', 'Linear model', 'Mathematics', 'Statistics']","hierarchical linear models, data analysis methods, american statistical association, [PAD], [PAD] [PAD], [PAD]"
Paper_00855,Safety and Efficacy of the BNT162b2 mRNA Covid-19 Vaccine,"['Fernando P. Polack', 'Stephen J. Thomas', 'Nicholas Kitchin', 'Judith Absalon', 'Alejandra Gurtman', 'Stephen Lockhart', 'John L. Perez', 'Gonzalo Pérez Marc', 'Edson Duarte Moreira', 'Cristiano A. F. Zerbini', 'Ruth Bailey', 'Kena A. Swanson', 'Satrajit Roychoudhury', 'Kenneth Koury', 'Ping Li', 'Warren V. Kalina', 'David Cooper', 'Robert W. Frenck', 'Laura L Hammitt', 'Özlem Türeci', 'Haylene Nell', 'Axel Schaefer', 'Serhat Ünal', 'Dina B Tresnan', 'Susan Mather', 'Philip R. Dormitzer', 'Uğur Şahin', 'Kathrin U. Jansen', 'William C. Gruber']",2020,New England Journal of Medicine,Journal,,2603-2615,383,27,10.1056/nejmoa2034577,"BackgroundSevere acute respiratory syndrome coronavirus 2 (SARS-CoV-2) infection and the resulting coronavirus disease 2019 (Covid-19) have afflicted tens of millions of people in a worldwide pandemic. Safe and effective vaccines are needed urgently.MethodsIn an ongoing multinational, placebo-controlled, observer-blinded, pivotal efficacy trial, we randomly assigned persons 16 years of age or older in a 1:1 ratio to receive two doses, 21 days apart, of either placebo or the BNT162b2 vaccine candidate (30 μg per dose). BNT162b2 is a lipid nanoparticle–formulated, nucleoside-modified RNA vaccine that encodes a prefusion stabilized, membrane-anchored SARS-CoV-2 full-length spike protein. The primary end points were efficacy of the vaccine against laboratory-confirmed Covid-19 and safety.Download a PDF of the Research Summary.ResultsA total of 43,548 participants underwent randomization, of whom 43,448 received injections: 21,720 with BNT162b2 and 21,728 with placebo. There were 8 cases of Covid-19 with onset at least 7 days after the second dose among participants assigned to receive BNT162b2 and 162 cases among those assigned to placebo; BNT162b2 was 95% effective in preventing Covid-19 (95% credible interval, 90.3 to 97.6). Similar vaccine efficacy (generally 90 to 100%) was observed across subgroups defined by age, sex, race, ethnicity, baseline body-mass index, and the presence of coexisting conditions. Among 10 cases of severe Covid-19 with onset after the first dose, 9 occurred in placebo recipients and 1 in a BNT162b2 recipient. The safety profile of BNT162b2 was characterized by short-term, mild-to-moderate pain at the injection site, fatigue, and headache. The incidence of serious adverse events was low and was similar in the vaccine and placebo groups.ConclusionsA two-dose regimen of BNT162b2 conferred 95% protection against Covid-19 in persons 16 years of age or older. Safety over a median of 2 months was similar to that of other viral vaccines. (Funded by BioNTech and Pfizer; ClinicalTrials.gov number, NCT04368728.) Quick Take Safety and Efficacy of the BNT162b2 Covid-19 Vaccine 3m 0s","['Coronavirus disease 2019 (COVID-19)', 'Severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2)', '2019-20 coronavirus outbreak', 'Virology', 'Business', 'Medicine', 'Outbreak', 'Internal medicine', 'Infectious disease (medical specialty)', 'Disease']","lip, ##ch, ##zer"
Paper_00857,Dynamic capabilities: what are they?,"['Kathleen M. Eisenhardt', 'Jeffrey A. Martin']",2000,Strategic Management Journal,Journal,,1105-1121,21,10-11,10.1002/1097-0266(200010/11)21:10/11<1105::aid-smj133>3.0.co;2-e,"This paper focuses on dynamic capabilities and, more generally, the resource-based view of the firm. We argue that dynamic capabilities are a set of specific and identifiable processes such as product development, strategic decision making, and alliancing. They are neither vague nor tautological. Although dynamic capabilities are idiosyncratic in their details and path dependent in their emergence, they have significant commonalities across firms (popularly termed 'best practice'). This suggests that they are more homogeneous, fungible, equifinal, and substitutable than is usually assumed. In moderately dynamic markets, dynamic capabilities resemble the traditional conception of routines. They are detailed, analytic, stable processes with predictable outcomes. In contrast, in high-velocity markets, they are simple, highly experiential and fragile processes with unpredictable outcomes. Finally, well-known learning mechanisms guide the evolution of dynamic capabilities. In moderately dynamic markets, the evolutionary emphasis is on variation. In high-velocity markets, it is on selection. At the level of RBV, we conclude that traditional RBV misidentifies the locus of long-term competitive advantage in dynamic markets, overemphasizes the strategic logic of leverage, and reaches a boundary condition in high-velocity markets. Copyright © 2000 John Wiley & Sons, Ltd.","['Dynamic capabilities', 'Leverage (statistics)', 'Dynamic decision-making', 'Resource (disambiguation)', 'Industrial organization', 'Microeconomics', 'Set (abstract data type)', 'Homogeneous', 'Resource-based view', 'Path dependence', 'Computer science', 'Economics', 'Dynamic pricing', 'Competitive advantage', 'Business', 'Management', 'Mathematics', 'Artificial intelligence', 'Computer network', 'Combinatorics', 'Programming language']","dynamic capabilities, dynamic capabilities, product development, strategic decision making, alliancing, dynamic capabilities, best, moderately dynamic markets, dynamic capabilities, learning mechanisms, moderately, ##v, strategic logic, [PAD] [PAD]"
Paper_00858,Limited-dependent and qualitative variables in econometrics,['G. S. Maddala'],1983,Unknown,Unknown,,,,,10.1017/cbo9780511810176,"This book presents the econometric analysis of single-equation and simultaneous-equation models in which the jointly dependent variables can be continuous, categorical, or truncated. Despite the traditional emphasis on continuous variables in econometrics, many of the economic variables encountered in practice are categorical (those for which a suitable category can be found but where no actual measurement exists) or truncated (those that can be observed only in certain ranges). Such variables are involved, for example, in models of occupational choice, choice of tenure in housing, and choice of type of schooling. Models with regulated prices and rationing, and models for program evaluation, also represent areas of application for the techniques presented by the author.","['Categorical variable', 'Econometrics', 'Econometric model', 'Rationing', 'Variables', 'Continuous variable', 'Discrete choice', 'Simultaneous equations model', 'Economics', 'Instrumental variable', 'Variable (mathematics)', 'Mathematics', 'Statistics', 'Mathematical analysis', 'Health care', 'Economic growth']","econometric analysis, jointly, ##egorical, truncated, continuous variables, econometrics, economic variables, categorical, occupational choice, housing, regulated prices, rationing, program evaluation"
Paper_00859,Evolving to a New Dominant Logic for Marketing,"['Stephen L. Vargo', 'Robert F. Lusch']",2003,Journal of Marketing,Journal,,1-17,68,1,10.1509/jmkg.68.1.1.24036,"Marketing inherited a model of exchange from economics, which had a dominant logic based on the exchange of “goods,” which usually are manufactured output. The dominant logic focused on tangible resources, embedded value, and transactions. Over the past several decades, new perspectives have emerged that have a revised logic focused on intangible resources, the cocreation of value, and relationships. The authors believe that the new perspectives are converging to form a new dominant logic for marketing, one in which service provision rather than goods is fundamental to economic exchange. The authors explore this evolving logic and the corresponding shift in perspective for marketing scholars, marketing practitioners, and marketing educators.","['Service-dominant logic', 'Marketing', 'Perspective (graphical)', 'Marketing mix', 'Business', 'Value (mathematics)', 'Marketing management', 'Service (business)', 'Computer science', 'Artificial intelligence', 'Machine learning']","marketing, exchange, economics, manufactured output, tangible resources, embedded value, transactions, intangible resources, cocreation, relationships, marketing, economic exchange, marketing, marketing practitioners, marketing educators"
Paper_00860,Viscoelastic Properties of Polymers,"['John D. Ferry', 'H. S. Myers']",1961,Journal of The Electrochemical Society,Journal,,142C-142C,108,7,10.1149/1.2428174,"The Nature of Viscoelastic Behavior. Illustrations of Viscoelastic Behavior of Polymeric Systems. Exact Interrelations among the Viscoelastic Functions. Approximate Interrelations among the Linear Viscoelastic Functions. Experimental Methods for Viscoelastic Liquids. Experimental Methods for Soft Viscoelastic Solids and Liquids of High Viscosity. Experimental Methods for Hard Viscoelastic Solids. Experimental Methods for Bulk Measurements. Dilute Solutions: Molecular Theory and Comparisons with Experiments. Molecular Theory for Undiluted Amorphous Polymers and Concentrated Solutions Networks and Entanglements. Dependence of Viscoelastic Behavior on Temperature and Pressure. The Transition Zone from Rubberlike to Glasslike Behavior. The Plateau and Terminal Zones in Uncross-Linked Polymers. Cross-Linked Polymers and Composite Systems. The Glassy State. Crystalline Polymers. Concentrated Solutions, Plasticized Polymers, and Gels. Viscoelastic Behavior in Bulk (Volume) Deformation. Applications to Practical Problems. Appendices. Author & Subject Indexes.","['Viscoelasticity', 'Materials science', 'Polymer', 'Viscosity', 'Amorphous solid', 'Deformation (meteorology)', 'Thermodynamics', 'Composite material', 'Chemistry', 'Physics', 'Organic chemistry']","viscoelastic behavior, viscoelastic behavior, polymeric systems, viscoelastic functions, linear viscoelastic functions, viscoelastic liquids, soft viscoelastic solids, high, hard, bulk measurements, dilute solutions, molecular theory, undiluted, concentrated solutions networks, entanglements, ##lastic behavior, transition zone, glass, terminal zones, composite systems, glassy state, crystalline polymers, concentrated solutions, plasticized polymers, gels, viscoelastic behavior, [PAD]"
Paper_00864,Interrater reliability: the kappa statistic,['Marry L. McHugh'],2012,Biochemia Medica,Journal,,276-282,,,10.11613/bm.2012.031,"The kappa statistic is frequently used to test interrater reliability. The importance of rater reliability lies in the fact that it represents the extent to which the data collected in the study are correct representations of the variables measured. Measurement of the extent to which data collectors (raters) assign the same score to the same variable is called interrater reliability. While there have been a variety of methods to measure interrater reliability, traditionally it was measured as percent agreement, calculated as the number of agreement scores divided by the total number of scores. In 1960, Jacob Cohen critiqued use of percent agreement due to its inability to account for chance agreement. He introduced the Cohen's kappa, developed to account for the possibility that raters actually guess on at least some variables due to uncertainty. Like most correlation statistics, the kappa can range from -1 to +1. While the kappa is one of the most commonly used statistics to test interrater reliability, it has limitations. Judgments about what level of kappa should be acceptable for health research are questioned. Cohen's suggested interpretation may be too lenient for health related studies because it implies that a score as low as 0.41 might be acceptable. Kappa and percent agreement are compared, and levels for both kappa and percent agreement that should be demanded in healthcare studies are suggested.","['Inter-rater reliability', 'Kappa', ""Cohen's kappa"", 'Statistics', 'Statistic', 'Reliability (semiconductor)', 'Mathematics', 'Test (biology)', 'Psychology', 'Medicine', 'Rating scale', 'Paleontology', 'Biology', 'Power (physics)', 'Geometry', 'Physics', 'Quantum mechanics']","kappa statistic, interrater reliability, rater reliability, interrater reliability, inter, ##r reliability, percent agreement, agreement scores, percent agreement, chance agreement, correlation statistics, interrater reliability, health research, health, percent agreement, percent agreement, healthcare studies"
Paper_00865,Exchange and Power in Social Life,['Peter M. Blau'],2017,Routledge eBooks,Unknown,,,,,10.4324/9780203792643,"In his landmark study of exchange and power in social life, Peter M. Blau contributes to an understanding of social structure by analyzing the social processes that govern the relations between individuals and groups. The basic question that Blau considers is: How does social life become organized into increasingly complex structures of associations among humans. This analysis, first published in 1964, represents a pioneering contribution to the sociological literature. Blau uses concepts of exchange, reciprocity, imbalance, and power to examine social life and to derive the more complex processes in social structure from the simpler ones. The principles of reciprocity and imbalance are used to derive such processes as power, changes in group structure; and the two major forces that govern the dynamics of complex social structures: the legitimization of organizing authority of increasing scope and the emergence of oppositions along different lines producing conflict and change.","['Power (physics)', 'Social power', 'Social life', 'Sociology', 'Psychology', 'Political science', 'Social science', 'Physics', 'Politics', 'Quantum mechanics', 'Law']","exchange, power, social life, social structure, social life, sociological, exchange, reciprocity, imbalance, power, social life, rec, ##rocity, imbalance, power, group structure, organizing authority, [PAD], [PAD] [PAD]"
Paper_00866,The 2007 WHO Classification of Tumours of the Central Nervous System,"['David N. Louis', 'Hiroko Ohgaki', 'Otmar D. Wiestler', 'Webster K. Cavenee', 'Peter C. Burger', 'Anne Jouvet', 'Bernd W. Scheithauer', 'Paul Kleihues']",2007,Acta Neuropathologica,Journal,,97-109,114,2,10.1007/s00401-007-0243-4,"The fourth edition of the World Health Organization (WHO) classification of tumours of the central nervous system, published in 2007, lists several new entities, including angiocentric glioma, papillary glioneuronal tumour, rosette-forming glioneuronal tumour of the fourth ventricle, papillary tumour of the pineal region, pituicytoma and spindle cell oncocytoma of the adenohypophysis. Histological variants were added if there was evidence of a different age distribution, location, genetic profile or clinical behaviour; these included pilomyxoid astrocytoma, anaplastic medulloblastoma and medulloblastoma with extensive nodularity. The WHO grading scheme and the sections on genetic profiles were updated and the rhabdoid tumour predisposition syndrome was added to the list of familial tumour syndromes typically involving the nervous system. As in the previous, 2000 edition of the WHO 'Blue Book', the classification is accompanied by a concise commentary on clinico-pathological characteristics of each tumour type. The 2007 WHO classification is based on the consensus of an international Working Group of 25 pathologists and geneticists, as well as contributions from more than 70 international experts overall, and is presented as the standard for the definition of brain tumours to the clinical oncology and cancer research communities world-wide.","['Medulloblastoma', 'Pathology', 'Grading (engineering)', 'Central nervous system', 'Medicine', 'Biology', 'Internal medicine', 'Ecology']","world health organization, central nervous system, angiocentric glioma, papillary glioneuronal tumour, papillary tumour, pineal region, pituicy, spindle cell oncocytoma, ##to, clinical, pilomyx, anaplastic medulloblastoma, medulloblastoma, extensive, who, genetic profiles, rhabdoid tumour predisposition syndrome, who, brain tumours"
Paper_00867,Nearest neighbor pattern classification,"['Thomas M. Cover', 'Peter E. Hart']",1967,IEEE Transactions on Information Theory,Journal,,21-27,13,1,10.1109/tit.1967.1053964,"The nearest neighbor decision rule assigns to an unclassified sample point the classification of the nearest of a set of previously classified points. This rule is independent of the underlying joint distribution on the sample points and their classifications, and hence the probability of error <tex xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">R</tex> of such a rule must be at least as great as the Bayes probability of error <tex xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">R^{\ast}</tex> --the minimum probability of error over all decision rules taking underlying probability structure into account. However, in a large sample analysis, we will show in the <tex xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">M</tex> -category case that <tex xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">R^{\ast} \leq R \leq R^{\ast}(2 --MR^{\ast}/(M-1))</tex> , where these bounds are the tightest possible, for all suitably smooth underlying distributions. Thus for any number of categories, the probability of error of the nearest neighbor rule is bounded above by twice the Bayes probability of error. In this sense, it may be said that half the classification information in an infinite sample set is contained in the nearest neighbor.","[""Bayes' theorem"", 'k-nearest neighbors algorithm', 'Probability distribution', 'Artificial intelligence', 'Mathematics', 'Computer science', 'Combinatorics', 'Pattern recognition (psychology)', 'Algorithm', 'Statistics', 'Bayesian probability']","nearest neighbor decision rule, unclassified sample point, underlying joint distribution, bayes probability of error, nearest neighbor rule, bayes probability of"
Paper_00868,Competitive Advantage: Creating and Sustaining Superior Performance,['Michael E. Porter'],1985,['Revista de Administração de Empresas'],Unknown,,82-84,25,2,10.1590/s0034-75901985000200009,"COMPETITIVE ADVANTAGE introduces a whole new way of understanding what a firm does. Porter's groundbreaking concept of the value chain disaggregates a company into 'activities', or the discrete functions or processes that represent the elemental building blocks of competitive advantage. Now an essential part of international business thinking, COMPETITIVE ADVANTAGE takes strategy from broad vision to an internally consistent configuration of activities. Its powerful framework provides the tools to understand the drivers of cost and a company's relative cost position. Porter's value chain enables managers to isolate the underlying sources of buyer value that will command a premium price, and the reasons why one product or service substitutes for another. He shows how competitive advantage lies not only in activities themselves but in the way activities relate to each other, to supplier activities, and to customer activities. That the phrases 'competitive advantage' and 'sustainable competitive advantage' have become commonplace is testimony to the power of Porter's ideas. COMPETITIVE ADVANTAGE has guided countless companies, business school students, and scholars in understanding the roots of competition. Porter's work captures the extraordinary complexity of competition in a way that makes strategy both concrete and actionable.","['Competitive advantage', 'Competition (biology)', 'Industrial organization', 'Value (mathematics)', 'Business', 'Product (mathematics)', 'Value chain', 'Marketing', 'Supply chain', 'Computer science', 'Ecology', 'Geometry', 'Mathematics', 'Machine learning', 'Biology']","competitive advantage, value chain, competitive advantage, international business thinking, competitive advantage, value, buyer value, competitive advantage, supplier activities, competitive advantage, sustainable competitive advantage, competitive advantage, business school, [PAD] [PAD] [PAD]"
Paper_00869,"A Simple, Positive Semi-Definite, Heteroskedasticity and AutocorrelationConsistent Covariance Matrix","['Whitney K. Newey', 'Kenneth D. West']",1986,Unknown,Unknown,,,,,10.3386/t0055,This paper describes a simple method of calculating a heteroskedasticity and autocorrelation consistent covariance matrix that is positive semi-definite by construction. It also establishes consistency of the estimated covariance matrix under fairly general conditions.,"['Positive-definite matrix', 'Simple (philosophy)', 'Mathematics', 'Covariance matrix', 'Heteroscedasticity', 'Applied mathematics', 'Matrix (chemical analysis)', 'Covariance', 'Econometrics', 'Statistics', 'Physics', 'Chemistry', 'Philosophy', 'Eigenvalues and eigenvectors', 'Chromatography', 'Epistemology', 'Quantum mechanics']","heteroskedasticity, autocorrelation consistent covariance matrix, estimated covariance matrix, [PAD] [PAD], [PAD], [PAD] [PAD] [PAD] [PAD] [PAD], [PAD], [PAD] [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD], [PAD], [PAD] [PAD] [PAD] [PAD], [PAD], [PAD], [PAD] [PAD], [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD]"
Paper_00871,The Sequence of the Human Genome,"['J. Craig Venter', 'Mark D. Adams', 'Eugene W. Myers', 'Peter W. Li', 'Richard Mural', 'Granger G. Sutton', 'Hamilton O. Smith', 'Mark Yandell', 'Cheryl Evans', 'Robert A. Holt', 'Jeannine D. Gocayne', 'Peter G. Amanatides', 'Richard M. Ballew', 'Daniel H. Huson', 'Jennifer R. Wortman', 'Qing Zhang', 'Chinnappa D. Kodira', 'Xiangqun Zheng-Bradley', 'Lin Chen', 'Marian Skupski', 'G. Subramanian', 'Paul D. Thomas', 'Jinghui Zhang', 'George L. Gabor Miklos', 'Catherine R. Nelson', 'Samuel Broder', 'Andrew G. Clark', 'Joe Nadeau', 'Victor A. McKusick', 'Norton D. Zinder', 'Arnold J. Levine', 'Richard J. Roberts', 'Mel I. Simon', 'Carolyn W. Slayman', 'Michael W. Hunkapiller', 'Randall Bolanos', 'Arthur L. Delcher', 'Ian Dew', 'Daniel Fasulo', 'Michael J. Flanigan', 'Liliana Florea', 'Aaron L. Halpern', 'Sridhar Hannenhalli', 'Saul Kravitz', 'Samuel Lévy', 'Clark Mobarry', 'Knut Reinert', 'Karin Remington', 'Jane Abu-Threideh', 'Ellen M. Beasley', 'Kendra Biddick', 'Vivien Bonazzi', 'Rhonda Brandon', 'Michele Cargill', 'Ishwar Chandramouliswaran', 'Rosane Charlab', 'Kabir Chaturvedi', 'Zuoming Deng', 'Valentina Di Francesco', 'Patrick Dunn', 'Karen Eilbeck', 'Carlos Evangelista', 'Andrei Gabrielian', 'Weiniu Gan', 'Wangmao Ge', 'Fangcheng Gong', 'Zhiping Gu', 'Ping Guan', 'Thomas J. Heiman', 'Maureen E. Higgins', 'Rui‐Ru Ji', 'Zhaoxi Ke', 'Karen A. Ketchum', 'Zhongwu Lai', 'Yiding Lei', 'Zhenya Li', 'Jiayin Li', 'Yong Liang', 'Xiaoying Lin', 'Fu Lu', 'Gennady V. Merkulov', 'Natalia V. Milshina', 'Helen M. Moore', 'Ashwinikumar K. Naik', 'Vaibhav A. Narayan', 'Beena Neelam', 'Deborah Nusskern', 'Douglas B. Rusch', 'Steven L. Salzberg', 'Wei Shao', 'Bixiong Chris Shue', 'Jing‐Tao Sun', 'Zhen Yuan Wang', 'Aihui Wang', 'Xin Wang', 'Jian Wang', 'Minghui Wei', 'Ron Wides', 'Chunlin Xiao', 'Chunhua Yan']",2001,Science,Journal,,1304-1351,291,5507,10.1126/science.1058040,"A 2.91-billion base pair (bp) consensus sequence of the euchromatic portion of the human genome was generated by the whole-genome shotgun sequencing method. The 14.8-billion bp DNA sequence was generated over 9 months from 27,271,853 high-quality sequence reads (5.11-fold coverage of the genome) from both ends of plasmid clones made from the DNA of five individuals. Two assembly strategies—a whole-genome assembly and a regional chromosome assembly—were used, each combining sequence data from Celera and the publicly funded genome effort. The public data were shredded into 550-bp segments to create a 2.9-fold coverage of those genome regions that had been sequenced, without including biases inherent in the cloning and assembly procedure used by the publicly funded group. This brought the effective coverage in the assemblies to eightfold, reducing the number and size of gaps in the final assembly over what would be obtained with 5.11-fold coverage. The two assembly strategies yielded very similar results that largely agree with independent mapping data. The assemblies effectively cover the euchromatic regions of the human chromosomes. More than 90% of the genome is in scaffold assemblies of 100,000 bp or more, and 25% of the genome is in scaffolds of 10 million bp or larger. Analysis of the genome sequence revealed 26,588 protein-encoding transcripts for which there was strong corroborating evidence and an additional ∼12,000 computationally derived genes with mouse matches or other weak supporting evidence. Although gene-dense clusters are obvious, almost half the genes are dispersed in low G+C sequence separated by large tracts of apparently noncoding sequence. Only 1.1% of the genome is spanned by exons, whereas 24% is in introns, with 75% of the genome being intergenic DNA. Duplications of segmental blocks, ranging in size up to chromosomal lengths, are abundant throughout the genome and reveal a complex evolutionary history. Comparative genomic analysis indicates vertebrate expansions of genes associated with neuronal function, with tissue-specific developmental regulation, and with the hemostasis and immune systems. DNA sequence comparisons between the consensus sequence and publicly funded genome data provided locations of 2.1 million single-nucleotide polymorphisms (SNPs). A random pair of human haploid genomes differed at a rate of 1 bp per 1250 on average, but there was marked heterogeneity in the level of polymorphism across the genome. Less than 1% of all SNPs resulted in variation in proteins, but the task of determining which SNPs have functional consequences remains an open challenge.","['Genome', 'Sequence assembly', 'Biology', 'Genetics', 'Human genome', 'Reference genome', 'Hybrid genome assembly', 'Genome project', 'Shotgun sequencing', 'Computational biology', 'Whole genome sequencing', 'Contig', 'Gene', 'Gene expression', 'Transcriptome']","consensus, human, ##as, regional chromosome assembly, ##fold, segment, ne, ##al function, hemosta, immune systems"
Paper_00872,Dynamic Programming,['Richard Bellman'],1957,['Journal of the Operational Research Society'],Unknown,,505-506,20,4,10.1057/jors.1969.118,"From the Publisher:
An introduction to the mathematical theory of multistage decision processes, this text takes a functional equation approach to the discovery of optimum policies. Written by a leading developer of such policies, it presents a series of methods, uniqueness and existence theorems, and examples for solving the relevant equations. The text examines existence and uniqueness theorems, the optimal inventory equation, bottleneck problems in multistage production processes, a new formalism in the calculus of variation, strategies behind multistage games, and Markovian decision processes. Each chapter concludes with a problem set that Eric V. Denardo of Yale University, in his informative new introduction, calls a rich lode of applications and research topics. 1957 edition. 37 figures.","['Uniqueness', 'Bottleneck', 'Computer science', 'Formalism (music)', 'Mathematical economics', 'Dynamic programming', 'Mathematics', 'Calculus (dental)', 'Mathematical optimization', 'Algorithm', 'Medicine', 'Art', 'Mathematical analysis', 'Musical', 'Dentistry', 'Visual arts', 'Embedded system']","multistage decision processes, functional equation, optimum policies, uniqueness, existence theorems, uniqueness theorems, optimal inventory equation, bottleneck problems, multistage production processes, calculus of, multistage games, markovian decision processes, yale, [PAD]"
Paper_00873,Framing: Toward Clarification of a Fractured Paradigm,['Robert M. Entman'],1993,Journal of Communication,Journal,,51-58,43,4,10.1111/j.1460-2466.1993.tb01304.x,"Journal Article Framing: Toward Clarification of a Fractured Paradigm Get access Robert M. Entman Robert M. Entman 1Robert M. Entman is an associate professor of communication studies, journalism, and political science and chair of the program in Communications, Media, and Public Policy at the Center for Urban Affairs and Policy Research at Northwestern University, Evanston, IL. He gratefully acknowledges the comments of students in his ""Mass Communication and Democratic Theory"" seminar, especially Andrew Rojecki. Search for other works by this author on: Oxford Academic Google Scholar Journal of Communication, Volume 43, Issue 4, December 1993, Pages 51–58, https://doi.org/10.1111/j.1460-2466.1993.tb01304.x Published: 07 February 2006","['Framing (construction)', 'Journalism', 'Media studies', 'Scholarly communication', 'Political communication', 'Democracy', 'Political science', 'Politics', 'Sociology', 'Library science', 'Law', 'Publishing', 'Computer science', 'History', 'Archaeology']","communication studies, journalism, political science, public policy, urban affairs, policy research, mass communication, democratic theory"
Paper_00874,Methods of Theoretical Physics,"['Philip Μ. Morse', 'Herman Feshbach', 'E. L. Hill']",1954,American Journal of Physics,Journal,,410-413,22,6,10.1119/1.1933765,First Page,"['Physics', 'Theoretical physics', 'Classical mechanics', 'Statistical physics']",
Paper_00875,Depression and Quality of Life in Older Persons: A Review,"['Heidi Sivertsen', 'Guro Hanevold Bjørkløf', 'Knut Engedal', 'Geir Selbæk', 'Anne-Sofie Helvik']",2015,Dementia and Geriatric Cognitive Disorders,Journal,,311-339,40,5-6,10.1159/000437299,"A visual analogue scale has been constructed to allow relatives and professionals to rate the behaviour of elderly patients. The scale has been shown to have good inter-rater reliability, test-retest reliability and validity. It is suggested that the scale can provide a quick and convenient initial assessment of the patient either at home or in hospital, and possibly also a measure of change.","['Psychology', 'Reliability (semiconductor)', 'Quality of life (healthcare)', 'Scale (ratio)', 'Psychometrics', 'Test validity', 'Test (biology)', 'Clinical psychology', 'Dementia', 'Gerontology', 'Validation test', 'Psychiatry', 'Medicine', 'Psychotherapist', 'Disease', 'Cartography', 'Paleontology', 'Power (physics)', 'Physics', 'Pathology', 'Quantum mechanics', 'Biology', 'Geography']",visual analogue scale
Paper_00816,<i>MolProbity</i>: all-atom structure validation for macromolecular crystallography,"['Vincent B. Chen', 'W.B. Arendall', 'Jeffrey J. Headd', 'D.A. Keedy', 'Robert M. Immormino', 'Gary J. Kapral', 'Laura W. Murray', 'Jane S. Richardson', 'David Richardson']",2009,Acta Crystallographica Section D Biological Crystallography,Journal,,12-21,66,1,10.1107/s0907444909042073,"MolProbity is a structure-validation web service that provides broad-spectrum solidly based evaluation of model quality at both the global and local levels for both proteins and nucleic acids. It relies heavily on the power and sensitivity provided by optimized hydrogen placement and all-atom contact analysis, complemented by updated versions of covalent-geometry and torsion-angle criteria. Some of the local corrections can be performed automatically in MolProbity and all of the diagnostics are presented in chart and graphical forms that help guide manual rebuilding. X-ray crystallography provides a wealth of biologically important molecular data in the form of atomic three-dimensional structures of proteins, nucleic acids and increasingly large complexes in multiple forms and states. Advances in automation, in everything from crystallization to data collection to phasing to model building to refinement, have made solving a structure using crystallography easier than ever. However, despite these improvements, local errors that can affect biological interpretation are widespread at low resolution and even high-resolution structures nearly all contain at least a few local errors such as Ramachandran outliers, flipped branched protein side chains and incorrect sugar puckers. It is critical both for the crystallographer and for the end user that there are easy and reliable methods to diagnose and correct these sorts of errors in structures. MolProbity is the authors' contribution to helping solve this problem and this article reviews its general capabilities, reports on recent enhancements and usage, and presents evidence that the resulting improvements are now beneficially affecting the global database.","['Ramachandran plot', 'Computer science', 'Protein crystallization', 'Phaser', 'Algorithm', 'Crystallography', 'Protein structure', 'Chemistry', 'Crystallization', 'Physics', 'Biochemistry', 'Organic chemistry', 'Optics']","molpro, ##y, ##zed hydrogen placement, ##ro, nuclei, automation, data collection, ##raphy, ramachandran outliers, flipped branched protein side chains, incorrect sugar puckers, molprobity"
Paper_00817,Exchange and Power in Social Life.,"['Robert Bierstedt', 'Peter M. Blau']",1965,American Sociological Review,Journal,,789-789,30,5,10.2307/2091154,"In his landmark study of exchange and power in social life, Peter M. Blau contributes to an understanding of social structure by analyzing the social processes that govern the relations between individuals and groups. The basic question that Blau considers is: How does social life become organized into increasingly complex structures of associations among humans. This analysis, first published in 1964, represents a pioneering contribution to the sociological literature. Blau uses concepts of exchange, reciprocity, imbalance, and power to examine social life and to derive the more complex processes in social structure from the simpler ones. The principles of reciprocity and imbalance are used to derive such processes as power, changes in group structure; and the two major forces that govern the dynamics of complex social structures: the legitimization of organizing authority of increasing scope and the emergence of oppositions along different lines producing conflict and change.","['Power (physics)', 'Sociology', 'Social power', 'Social life', 'Psychology', 'Political science', 'Social science', 'Politics', 'Physics', 'Quantum mechanics', 'Law']","exchange, power, social life, social structure, social life, sociological, exchange, reciprocity, imbalance, power, social life, rec, ##rocity, imbalance, power, group structure, organizing authority, [PAD], [PAD] [PAD], [PAD] [PAD] [PAD], [PAD], [PAD]"
Paper_00819,Bowling Alone: America's Declining Social Capital,['Robert D. Putnam'],1995,Journal of democracy,Journal,,65-78,6,1,10.1353/jod.1995.0002,"Bowling Alone: America’s Declining Social Capital Robert D. Putnam (bio) Many students of the new democracies that have emerged over the past decade and a half have emphasized the importance of a strong and active civil society to the consolidation of democracy. Especially with regard to the postcommunist countries, scholars and democratic activists alike have lamented the absence or obliteration of traditions of independent civic engagement and a widespread tendency toward passive reliance on the state. To those concerned with the weakness of civil societies in the developing or postcommunist world, the advanced Western democracies and above all the United States have typically been taken as models to be emulated. There is striking evidence, however, that the vibrancy of American civil society has notably declined over the past several decades. Ever since the publication of Alexis de Tocqueville’s Democracy in America, the United States has played a central role in systematic studies of the links between democracy and civil society. Although this is in part because trends in American life are often regarded as harbingers of social modernization, it is also because America has traditionally been considered unusually “civic” (a reputation that, as we shall later see, has not been entirely unjustified). When Tocqueville visited the United States in the 1830s, it was the Americans’ propensity for civic association that most impressed him as the key to their unprecedented ability to make democracy work. “Americans of all ages, all stations in life, and all types of disposition,” [End Page 65] he observed, “are forever forming associations. There are not only commercial and industrial associations in which all take part, but others of a thousand different types—religious, moral, serious, futile, very general and very limited, immensely large and very minute. . . . Nothing, in my view, deserves more attention than the intellectual and moral associations in America.” 1 Recently, American social scientists of a neo-Tocquevillean bent have unearthed a wide range of empirical evidence that the quality of public life and the performance of social institutions (and not only in America) are indeed powerfully influenced by norms and networks of civic engagement. Researchers in such fields as education, urban poverty, unemployment, the control of crime and drug abuse, and even health have discovered that successful outcomes are more likely in civically engaged communities. Similarly, research on the varying economic attainments of different ethnic groups in the United States has demonstrated the importance of social bonds within each group. These results are consistent with research in a wide range of settings that demonstrates the vital importance of social networks for job placement and many other economic outcomes. Meanwhile, a seemingly unrelated body of research on the sociology of economic development has also focused attention on the role of social networks. Some of this work is situated in the developing countries, and some of it elucidates the peculiarly successful “network capitalism” of East Asia. 2 Even in less exotic Western economies, however, researchers have discovered highly efficient, highly flexible “industrial districts” based on networks of collaboration among workers and small entrepreneurs. Far from being paleoindustrial anachronisms, these dense interpersonal and interorganizational networks undergird ultramodern industries, from the high tech of Silicon Valley to the high fashion of Benetton. The norms and networks of civic engagement also powerfully affect the performance of representative government. That, at least, was the central conclusion of my own 20-year, quasi-experimental study of subnational governments in different regions of Italy. 3 Although all these regional governments seemed identical on paper, their levels of effectiveness varied dramatically. Systematic inquiry showed that the quality of governance was determined by longstanding traditions of civic engagement (or its absence). Voter turnout, newspaper readership, membership in choral societies and football clubs—these were the hallmarks of a successful region. In fact, historical analysis suggested that these networks of organized reciprocity and civic solidarity, far from being an epiphenomenon of socioeconomic modernization, were a precondition for it. No doubt the mechanisms through which civic engagement and social connectedness produce such results—better schools, faster economic [End Page 66] development, lower crime, and more effective government—are multiple and complex. While these briefly recounted findings require further confirmation and perhaps qualification, the...","['Democracy', 'Civil society', 'Modernization theory', 'Social capital', 'Political science', 'Civic engagement', 'State (computer science)', 'Reputation', 'Voluntary association', 'Political economy', 'Economic history', 'Sociology', 'Law', 'Politics', 'History', 'Algorithm', 'Computer science']","social capital, civil society, independent civic engagement, civil society, american life, social modernization, civic association, industrial associations, moral associations, public life, social institutions, civic engagement, education, urban poverty, unemployment, drug abuse, economic attainments, social bonds"
Paper_00821,CRC Handbook of Chemistry and Physics,[],2016,CRC Press eBooks,Unknown,,,,,10.1201/9781315380476,"Proudly serving the scientific community for over a century, this 97th edition of the CRC Handbook of Chemistry and Physics is an update of a classic reference, mirroring the growth and direction of science. This venerable work continues to be the most accessed and respected scientific reference in the world. An authoritative resource consisting of tables of data and current international recommendations on nomenclature, symbols, and units, its usefulness spans not only the physical sciences but also related areas of biology, geology, and environmental science. The 97th edition of the Handbook includes 20 new or updated tables along with other updates and expansions. It is now also available as an eBook. This reference puts physical property data and mathematical formulas used in labs and classrooms every day within easy reach. &nbsp","['Library science', 'Engineering physics', 'Physics', 'Computer science']","##c, chemistry, nomenclature, symbols, environmental science, physical property data, mathematical formulas"
Paper_00822,Inhibited Spontaneous Emission in Solid-State Physics and Electronics,['Eli Yablonovitch'],1987,Physical Review Letters,Journal,,2059-2062,58,20,10.1103/physrevlett.58.2059,"It has been recognized for some time that the spontaneous emission by atoms is not necessarily a fixed and immutable property of the coupling between matter and space, but that it can be controlled by modification of the properties of the radiation field. This is equally true in the solid state, where spontaneous emission plays a fundamental role in limiting the performance of semiconductor lasers, heterojunction bipolar transistors, and solar cells. If a three-dimensionally periodic dielectric structure has an electromagnetic band gap which overlaps the electronic band edge, then spontaneous emission can be rigorously forbidden.","['Spontaneous emission', 'Physics', 'Semiconductor', 'Heterojunction', 'Laser', 'Electronics', 'Coupling (piping)', 'Optoelectronics', 'Atomic physics', 'Materials science', 'Optics', 'Electrical engineering', 'Metallurgy', 'Engineering']","spontaneous emission, radiation field, solid state, spontaneous emission, semiconductor lasers, heterojunction bipolar transistors, solar cells, electromagnetic band gap, electronic band edge, spontaneous emission, [PAD] [PAD], [PAD]"
Paper_00823,How to Design and Evaluate Research in Education,"['Jack R. Fraenkel', 'Norman E. Wallen']",1990,['Contemporary Psychology: A Journal of Reviews'],Unknown,,1125-1125,38,10,10.1037/032719,Part One: Introduction to Research Chapter 1: The Nature of Educational Research Part Two: The Basics of Educational Research Chapter 2: The Research Problem Chapter 3: Ethics and Research Chapter 4: Variables and Hypotheses Chapter 5: Reviewing the Literature Chapter 6: Sampling Chapter 7: Instrumentation Chapter 8: Validity and Reliability Chapter 9: Internal Validity Part Three: Data Analysis Chapter 10: Descriptive Statistics Chapter 11: Inferential Statistics Chapter 12: Statistics in Perspective Part Four: Research Methodologies: I Chapter 13: Experimental Research Chapter 14: Single-Subject Research Chapter 15: Correlational Research Chapter 16: Causal-Comparative Research Chapter 17: Survey Research Part Five: Research Methodologies: II Chapter 18: Content Analysis Research Chapter 19: Qualitative Research: I Chapter 20: Qualitative Research: II Chapter 21: Historical Research Part Six: Preparing Research Proposals and Reports Chapter 22: Writing Research Proposals and Reports Part Seven: Research by Practitioners Chapter 23: Doing Research in Schools Appendix A: Table of Random Numbers Appendix B: Normal Curve Table Appendix C: Chi-Square Distribution Appendix D: Illustration of Statistical Procedures,"['Table of contents', 'Research design', 'Management science', 'Educational research', 'Descriptive statistics', 'Subject (documents)', 'Mathematics education', 'Computer science', 'Statistics', 'Mathematics', 'Library science', 'Engineering', 'World Wide Web']","educational research, educational research, research, ethics, variables, hypoth, sampling, instrumentation, validity, reliability, internal validity, data analysis, descriptive statistics, inferential statistics, experimental research, correlational research, survey research, research methodologies, content analysis, qualitative research, qualitative research, historical research, random numbers, normal curve table, statistical procedures"
Paper_00824,Initial conditions and moment restrictions in dynamic panel data models,"['Richard Blundell', 'Stephen Bond']",1995,Working paper series - Institute for Fiscal Studies/Working papers,Journal,,,,,10.1920/wp.ifs.1995.9517,"In this paper we consider estimation of the autoregressive error components model. When the autoregressive parameter is moderately large and the number of time series observations is moderately small, the usual Generalised Methods of Moments (GMM) estimator obtained after first differencing has been found to be poorly behaved. Here we consider alternative linear estimators that are designed to improve the properties of the standard first-differenced GMM estimator. We consider two approaches to estimation. The first approach extends the model by adding the observed initial values as an extra regressor. This allows consistent estimates to be obtained by error-components GLS. This estimator is shown to be equivalent to the optimal GMM estimator for the normal homoskedastic error components model. The second approach considers a mild restriction on the initial condition process under which lagged differences in the dependent variable can be used to construct linear moment conditions in the levels equations. The complete set of moment conditions can then be exploited by a linear GMM estimator in a system of first-differenced and levels equations, rendering the non-linear moment conditions redundant for estimation. This estimator is strictly more efficient than non-linear GMM when the additional restriction is valid. Monte Carlo simulations are reported which demonstrate the dramatic improvement in performance of the proposed estimators compared to the usual first-differenced GMM estimator, especially for high values of the autoregressive parameter.","['Estimator', 'Autoregressive model', 'Mathematics', 'Moment (physics)', 'Generalized method of moments', 'Applied mathematics', 'Monte Carlo method', 'Statistics', 'Physics', 'Classical mechanics']","autoregressive error components model, ##ssive parameter, time series observations, linear estimators, normal homoskedastic error components, ##gged, linear moment conditions, levels"
Paper_00825,DNA polymorphisms amplified by arbitrary primers are useful as genetic markers,"['John G. Williams', 'Anne R. Kubelik', 'Kenneth J. Livak', 'J. Antoni Rafalski', 'Scott Tingey']",1990,Nucleic Acids Research,Journal,,6531-6535,18,22,10.1093/nar/18.22.6531,"Molecular genetic maps are commonly constructed by analyzing the segregation of restriction fragment length polymorphisms (RFLPs) among the progeny of a sexual cross. Here we describe a new DNA polymorphism assay based on the amplification of random DNA segments with single primers of arbitrary nucleotide sequence. These polymorphisms, simply detected as DNA segments which amplify from one parent but not the other, are inherited in a Mendellan fashion and can be used to construct genetic maps in a variety of species. We suggest that these polymorphisms be called RAPD markers, after Random Amplified Polymorphic DNA.","['Biology', 'RAPD', 'Genetics', 'Restriction fragment length polymorphism', 'DNA', 'Genetic marker', 'Polymorphism (computer science)', 'Amplified fragment length polymorphism', 'Polymerase chain reaction', 'DNA sequencing', 'Molecular biology', 'Gene', 'Genotype', 'Genetic diversity', 'Population', 'Demography', 'Sociology']","molecular genetic maps, restriction fragment length polymorphisms, rflp, sexual cross, dna polymorphism assay, random dna segments, men, ##an, rapd markers, random amplified polymorphic dna, [PAD], [PAD], [PAD], [PAD] [PAD], [PAD] [PAD] [PAD], [PAD] [PAD] [PAD], [PAD]"
Paper_00827,The variant call format and VCFtools,"['Petr Danecek', 'Adam Auton', 'Gonçalo R. Abecasis', 'Cornelis A. Albers', 'Eric Banks', 'Mark A. DePristo', 'Robert E. Handsaker', 'Gerton Lunter', 'Gábor Marth', 'Stephen T. Sherry', 'Gil McVean', 'Richard Durbin']",2011,Bioinformatics,Journal,,2156-2158,27,15,10.1093/bioinformatics/btr330,"Abstract Summary: The variant call format (VCF) is a generic format for storing DNA polymorphism data such as SNPs, insertions, deletions and structural variants, together with rich annotations. VCF is usually stored in a compressed manner and can be indexed for fast data retrieval of variants from a range of positions on the reference genome. The format was developed for the 1000 Genomes Project, and has also been adopted by other projects such as UK10K, dbSNP and the NHLBI Exome Project. VCFtools is a software suite that implements various utilities for processing VCF files, including validation, merging, comparing and also provides a general Perl API. Availability: http://vcftools.sourceforge.net Contact: rd@sanger.ac.uk","['dbSNP', 'Perl', 'Computer science', 'Suite', 'Software', 'Exome', 'Annotation', 'Exome sequencing', 'World Wide Web', 'Single-nucleotide polymorphism', 'Programming language', 'Genetics', 'Biology', 'Artificial intelligence', 'Mutation', 'Gene', 'Genotype', 'History', 'Archaeology']","abstract summary, variant call format, vcf, dna polymorphism data, snps, insertions, deletions, structural variants, vcf, 1000 genomes, uk10k, dbsnp, nhlbi exome, vcftools, vcf, perl, ##ft, [PAD], [PAD], [PAD] [PAD], [PAD] [PAD], [PAD], [PAD] [PAD], [PAD], [PAD] [PAD] [PAD], [PAD] [PAD]"
Paper_00828,Observational Study of Behavior: Sampling Methods,['Jeanne Altmann'],1974,Behaviour,Journal,,227-266,49,3-4,10.1163/156853974x00534,"Abstract Seven major types of sampling for observational studies of social behavior have been found in the literature. These methods differ considerably in their suitability for providing unbiased data of various kinds. Below is a summary of the major recommended uses of each technique: In this paper, I have tried to point out the major strengths and weaknesses of each sampling method. Some methods are intrinsically biased with respect to many variables, others to fewer. In choosing a sampling method the main question is whether the procedure results in a biased sample of the variables under study. A method can produce a biased sample directly, as a result of intrinsic bias with respect to a study variable, or secondarily due to some degree of dependence (correlation) between the study variable and a directly-biased variable. In order to choose a sampling technique, the observer needs to consider carefully the characteristics of behavior and social interactions that are relevant to the study population and the research questions at hand. In most studies one will not have adequate empirical knowledge of the dependencies between relevant variables. Under the circumstances, the observer should avoid intrinsic biases to whatever extent possible, in particular those that direcly affect the variables under study. Finally, it will often be possible to use more than one sampling method in a study. Such samples can be taken successively or, under favorable conditions, even concurrently. For example, we have found it possible to take Instantaneous Samples of the identities and distances of nearest neighbors of a focal individual at five or ten minute intervals during Focal-Animal (behavior) Samples on that individual. Often during Focal-Animal Sampling one can also record All Occurrences of Some Behaviors, for the whole social group, for categories of conspicuous behavior, such as predation, intergroup contact, drinking, and so on. The extent to which concurrent multiple sampling is feasible will depend very much on the behavior categories and rate of occurrence, the observational conditions, etc. Where feasible, such multiple sampling can greatly aid in the efficient use of research time.","['Observational study', 'Sampling (signal processing)', 'Variable (mathematics)', 'Statistics', 'Sample size determination', 'Sample (material)', 'Observer (physics)', 'Population', 'Variables', 'Econometrics', 'Observational methods in psychology', 'Sampling bias', 'Computer science', 'Psychology', 'Mathematics', 'Mathematical analysis', 'Chemistry', 'Physics', 'Demography', 'Filter (signal processing)', 'Chromatography', 'Quantum mechanics', 'Sociology', 'Computer vision']","observational studies, social behavior, unbiased, social interactions, conspicuous behavior, predation, intergroup contact, drinking, concurrent multiple sampling"
Paper_00829,The Nature of Prejudice,['Gordon W. Āllport'],1954,['Journal of the History of the Behavioral Sciences'],Unknown,,489-498,36,4,10.1002/1520-6696(200023)36:4<489::aid-jhbs13>3.0.co;2-n,"Preferential Thinking * What Is the Problem? * The Normality of Prejudgment * Formation of In-Groups * Rejection of Out-Groups * Patterning and Extent of Prejudice Group Differences * The Scientific Study of Group Differences * Racial and Ethnic Differences * Visibility and Strangeness * Traits Due to Victimization Perceiving And Thinking About Group Differences * The Cognitive Process * Linguistic Factors * Stereotypes in Our Culture * Theories of Prejudice Sociocultural Factors * Social Structure And Cultural Pattern * Choice of Scapegoats * The Effect of Contact * Acquiring Prejudice * Conforming * The Young Child * Later Learning * Inner Conflict The Dynamics Of Prejudice * Frustration * Aggression and Hatred * Anxiety, Sex, and Guilt * Projection Character Structure * The Prejudiced Personality * Demagogy * The Tolerant Personality * Religion and Prejudice Reducing Group Tensions * Ought There to Be a Law? * Evaluation of Programs * Limitations and Horizons","['Prejudice (legal term)', 'Social psychology', 'Psychology', 'Group conflict', 'Hatred', 'Contact hypothesis', 'Social dominance orientation', 'Sociocultural evolution', 'Ethnic group', 'Personality', 'Aggression', 'Political science', 'Politics', 'Law', 'Authoritarianism', 'Democracy']","preferential thinking, normality, prejudgment, patterning, prejudice group differences, group differences, racial, ethnic differences, visibility, strangeness, cognitive process, linguistic factors, prejudice, social structure, cultural pattern, inner conflict, prejudice, frustration, aggression, hatred, anxiety, sex, guilt, projection, prejudiced personality, demagogy, tolerant personality, religion, prejudice"
Paper_00830,Genetic Programming: On the Programming of Computers by Means of Natural Selection,['John R. Koza'],1992,['Statistics and Computing'],Unknown,,,4,2,10.1007/bf00175355,"Background on genetic algorithms, LISP, and genetic programming hierarchical problem-solving introduction to automatically-defined functions - the two-boxes problem problems that straddle the breakeven point for computational effort Boolean parity functions determining the architecture of the program the lawnmower problem the bumblebee problem the increasing benefits of ADFs as problems are scaled up finding an impulse response function artificial ant on the San Mateo trail obstacle-avoiding robot the minesweeper problem automatic discovery of detectors for letter recognition flushes and four-of-a-kinds in a pinochle deck introduction to biochemistry and molecular biology prediction of transmembrane domains in proteins prediction of omega loops in proteins lookahead version of the transmembrane problem evolutionary selection of the architecture of the program evolution of primitives and sufficiency evolutionary selection of terminals evolution of closure simultaneous evolution of architecture, primitive functions, terminals, sufficiency, and closure the role of representation and the lens effect. Appendices: list of special symbols list of special functions list of type fonts default parameters computer implementation annotated bibliography of genetic programming electronic mailing list and public repository.","['Genetic programming', 'Computer science', 'Artificial intelligence', 'Evolutionary programming', 'Theoretical computer science', 'Evolutionary algorithm', 'Programming language']","genetic algorithms, lisp, genetic programming, breakeven, boolean parity functions, lawnmower problem, bumblebee problem, adfs, impulse response, minesweeper problem, letter recognition, pin, ##le deck, molecular biology, transmembrane domains, proteins, omega loops, ##membrane problem, su, ##ciency, terminals, primitive functions, terminals, su, ##ciency, closure, representation, lens effect, type fonts, genetic programming"
Paper_00831,Experience and Education,['John Dewey'],1986,The Educational Forum,Journal,,241-252,50,3,10.1080/00131728609335764,"Experience and Educationis the best concise statement on education ever published by John Dewey, the man acknowledged to be the pre-eminent educational theorist of the twentieth century. Written more than two decades after Democracy and Education(Dewey's most comprehensive statement of his position in educational philosophy), this book demonstrates how Dewey reformulated his ideas as a result of his intervening experience with the schools and in the light of the criticisms his theories had received. Analysing both traditional and progressive education, Dr. Dewey here insists that neither the old nor the new education is adequate and that each is miseducative because neither of them applies the principles of a carefully developed philosophy of experience. Many pages of this volume illustrate Dr. Dewey's ideas for a philosophy of experience and its relation to education. He particularly urges that all teachers and educators looking for a new movement in education should think in terms of the deeped and larger issues of education rather than in terms of some divisive ism about education, even such an ism as progressivism. His philosophy, here expressed in its most essential, most readable form, predicates an American educational system that respects all sources of experience, on that offers a true learning situation that is both historical and social, both orderly and dynamic.","['Mathematics education', 'Pedagogy', 'Psychology', 'Sociology']","experience, education, education, educational theorist, democracy, education, educational philosophy, progressive, experience, progressivism"
Paper_00832,The Coding Manual for Qualitative Researchers,['Johnny Saldaña'],2009,['American Journal of Qualitative Research'],Unknown,,232-237,6,1,10.29333/ajqr/12085,"An Introduction to Codes and Coding Chapter Summary Purposes of the Manual What Is a Code? Codifying and Categorizing What Gets Coded? The Mechanics of Coding The Numbers of Codes Manual and CAQDAS Coding Solo and Team Coding Necessary Personal Attributes for Coding On Method Writing Analytic Memos Chapter Summary The Purposes of Analytic Memo-Writing What Is an Analytic Memo? Examples of Analytic Memos Coding and Categorizing Analytic Memos Grounded Theory and Its Coding Canon Analytic Memos on Visual Data First-Cycle Coding Methods Chapter Summary The Coding Cycles Selecting the Appropriate Coding Method(s) Overview of First-Cycle Coding Methods The Coding Methods Profiles Grammatical Methods Elemental Methods Affective Methods Literary and Language Methods Exploratory Methods Forms for Additional First-Cycle Coding Methods Theming the Data Procedural Methods After First-Cycle Coding Chapter Summary Post-Coding Transitions Eclectic Coding Code Mapping and Landscaping Operational Model Diagramming Additional Transition Methods Transitioning to Second-Cycle Coding Methods Second-Cycle Coding Methods Chapter Summary The Goals of Second-Cycle Methods Overview of Second-Cycle Coding Methods Second-Cycle Coding Methods Forms for Additional Second-Cycle Coding Methods After Second-Cycle Coding Chapter Summary Post-Coding and Pre-Writing Transitions Focusing Strategies From Coding to Theorizing Formatting Matters Writing about Coding Ordering and Re-Ordering Assistance from Others Closure Appendix A: A Glossary of Coding Methods Appendix B: A Glossary of Analytic Recommendations Appendix C: Field Note, Interview Transcript and Document Samples for Coding Appendix D: Exercises and Activities for Coding and Qualitative Data Analytic Skill Development References Index","['Coding (social sciences)', 'Glossary', 'Tunstall coding', 'Shannon–Fano coding', 'Variable-length code', 'Computer science', 'Context-adaptive variable-length coding', 'Context-adaptive binary arithmetic coding', 'Mathematics', 'Linguistics', 'Statistics', 'Philosophy']","ca, ##das, team coding, coding, affect, language methods, landscaping"
Paper_00834,Distributed Representations of Words and Phrases and their Compositionality,"['Tomáš Mikolov', 'Ilya Sutskever', 'Kai Chen', 'Greg S. Corrado', 'Jeffrey Dean']",2013,arXiv (Cornell University),Unknown,,,,,10.48550/arxiv.1310.4546,"The recently introduced continuous Skip-gram model is an efficient method for learning high-quality distributed vector representations that capture a large number of precise syntactic and semantic word relationships. In this paper we present several extensions that improve both the quality of the vectors and the training speed. By subsampling of the frequent words we obtain significant speedup and also learn more regular word representations. We also describe a simple alternative to the hierarchical softmax called negative sampling. An inherent limitation of word representations is their indifference to word order and their inability to represent idiomatic phrases. For example, the meanings of ""Canada"" and ""Air"" cannot be easily combined to obtain ""Air Canada"". Motivated by this example, we present a simple method for finding phrases in text, and show that learning good vector representations for millions of phrases is possible.","['Principle of compositionality', 'Softmax function', 'Computer science', 'Word (group theory)', 'Natural language processing', 'Simple (philosophy)', 'Artificial intelligence', 'Quality (philosophy)', 'Speedup', 'Linguistics', 'Artificial neural network', 'Philosophy', 'Epistemology', 'Operating system']","semantic word relationships, frequent words, regular word representations, hierarchical softmax, negative sampling, word representations, word order, idiomatic phrases, air canada, vector representations"
Paper_00836,Finding and evaluating community structure in networks,"['Michelle G. Newman', 'Michelle Girvan']",2004,Physical Review E,Journal,,,69,2,10.1103/physreve.69.026113,"We propose and study a set of algorithms for discovering community structure in networks-natural divisions of network nodes into densely connected subgroups. Our algorithms all share two definitive features: first, they involve iterative removal of edges from the network to split it into communities, the edges removed being identified using any one of a number of possible ""betweenness"" measures, and second, these measures are, crucially, recalculated after each removal. We also propose a measure for the strength of the community structure found by our algorithms, which gives us an objective metric for choosing the number of communities into which a network should be divided. We demonstrate that our algorithms are highly effective at discovering community structure in both computer-generated and real-world network data, and show how they can be used to shed light on the sometimes dauntingly complex structure of networked systems.","['Betweenness centrality', 'Community structure', 'Computer science', 'Complex network', 'Metric (unit)', 'Set (abstract data type)', 'Measure (data warehouse)', 'Network structure', 'Data mining', 'Theoretical computer science', 'Natural (archaeology)', 'Evolving networks', 'Data science', 'Mathematics', 'Centrality', 'Geography', 'World Wide Web', 'Statistics', 'Engineering', 'Operations management', 'Programming language', 'Archaeology']","community structure, network nodes, densely connected subgroups, betweenness, community structure, community structure, networked systems"
Paper_00837,YOLOv3: An Incremental Improvement,"['Joseph Redmon', 'Ali Farhadi']",2018,arXiv (Cornell University),Unknown,,,,,10.48550/arxiv.1804.02767,"We present some updates to YOLO! We made a bunch of little design changes to make it better. We also trained this new network that's pretty swell. It's a little bigger than last time but more accurate. It's still fast though, don't worry. At 320x320 YOLOv3 runs in 22 ms at 28.2 mAP, as accurate as SSD but three times faster. When we look at the old .5 IOU mAP detection metric YOLOv3 is quite good. It achieves 57.9 mAP@50 in 51 ms on a Titan X, compared to 57.5 mAP@50 in 198 ms by RetinaNet, similar performance but 3.8x faster. As always, all the code is online at https://pjreddie.com/yolo/","['Computer science', 'Code (set theory)', 'Titan (rocket family)', 'Artificial intelligence', 'Metric (unit)', 'Swell', 'Computer vision', 'Physics', 'Engineering', 'Programming language', 'Operations management', 'Set (abstract data type)', 'Astronomy', 'Thermodynamics']","yolov, yolov, titan, retinanet"
Paper_00839,Regularization Paths for Generalized Linear Models via Coordinate Descent,"['Jerome H. Friedman', 'Trevor Hastie', 'Robert Tibshirani']",2010,Journal of Statistical Software,Journal,,,33,1,10.18637/jss.v033.i01,"We develop fast algorithms for estimation of generalized linear models with convex penalties. The models include linear regression, two-class logistic regression, and multi- nomial regression problems while the penalties include ℓ<sub>1</sub> (the lasso), ℓ<sub>2</sub> (ridge regression) and mixtures of the two (the elastic net). The algorithms use cyclical coordinate descent, computed along a regularization path. The methods can handle large problems and can also deal efficiently with sparse features. In comparative timings we find that the new algorithms are considerably faster than competing methods.","['Coordinate descent', 'Elastic net regularization', 'Lasso (programming language)', 'Regularization (linguistics)', 'Linear regression', 'Regression', 'Computer science', 'Generalized linear model', 'Linear model', 'Regular polygon', 'Logistic regression', 'Mathematics', 'Ridge', 'Algorithm', 'Mathematical optimization', 'Applied mathematics', 'Artificial intelligence', 'Statistics', 'Biology', 'Paleontology', 'Geometry', 'World Wide Web']","generalized linear models, convex penalties, linear regression, lasso, ridge regression, elastic net, cyclical coordinate descent, regularization path, sparse features, comparative timings, [PAD] [PAD], [PAD] [PAD]"
Paper_00840,A Global Geometric Framework for Nonlinear Dimensionality Reduction,"['Joshua B. Tenenbaum', 'Vin de Silva', 'John Langford']",2000,Science,Journal,,2319-2323,290,5500,10.1126/science.290.5500.2319,"Scientists working with large volumes of high-dimensional data, such as global climate patterns, stellar spectra, or human gene distributions, regularly confront the problem of dimensionality reduction: finding meaningful low-dimensional structures hidden in their high-dimensional observations. The human brain confronts the same problem in everyday perception, extracting from its high-dimensional sensory inputs—30,000 auditory nerve fibers or 106 optic nerve fibers—a manageably small number of perceptually relevant features. Here we describe an approach to solving dimensionality reduction problems that uses easily measured local metric information to learn the underlying global geometry of a data set. Unlike classical techniques such as principal component analysis (PCA) and multidimensional scaling (MDS), our approach is capable of discovering the nonlinear degrees of freedom that underlie complex natural observations, such as human handwriting or images of a face under different viewing conditions. In contrast to previous algorithms for nonlinear dimensionality reduction, ours efficiently computes a globally optimal solution, and, for an important class of data manifolds, is guaranteed to converge asymptotically to the true structure.","['Dimensionality reduction', 'Principal component analysis', 'Isomap', 'Nonlinear dimensionality reduction', 'Multidimensional scaling', 'Nonlinear system', 'Curse of dimensionality', 'Metric (unit)', 'Diffusion map', 'Computer science', 'Reduction (mathematics)', 'Artificial intelligence', 'Set (abstract data type)', 'Pattern recognition (psychology)', 'Degrees of freedom (physics and chemistry)', 'Handwriting', 'Mathematics', 'Machine learning', 'Physics', 'Operations management', 'Geometry', 'Quantum mechanics', 'Economics', 'Programming language']","global climate patterns, stellar spectra, human gene distributions, dimensionality reduction, human brain, everyday perception, auditory nerve fibers, optic nerve fibers, dimensionality reduction, global geometry, principal component analysis, multidimensional scaling, nonlinear degrees of freedom, human, nonlinear dimensionality reduction, globally optimal solution"
Paper_00841,Iterative Methods for Sparse Linear Systems,['Yousef Saad'],2003,Unknown,Unknown,,,,,10.1137/1.9780898718003,Preface 1. Background in linear algebra 2. Discretization of partial differential equations 3. Sparse matrices 4. Basic iterative methods 5. Projection methods 6. Krylov subspace methods Part I 7. Krylov subspace methods Part II 8. Methods related to the normal equations 9. Preconditioned iterations 10. Preconditioning techniques 11. Parallel implementations 12. Parallel preconditioners 13. Multigrid methods 14. Domain decomposition methods Bibliography Index.,"['Computer science', 'Mathematics']","linear algebra, discretization, partial differential equations, sparse matrices, basic iterative methods, projection methods, krylov subspace methods, krylov subspace methods, normal equations, preconditioned iterations, preconditioning techniques, parallel implementations, parallel preconditioners, multigrid methods, domain decomposition methods bibliography index, [PAD], [PAD] [PAD], [PAD] [PAD] [PAD] [PAD] [PAD], [PAD], [PAD], [PAD] [PAD], [PAD], [PAD], [PAD] [PAD], [PAD], [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD], [PAD], [PAD], [PAD], [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"
Paper_00842,"Identity, youth, and crisis",['Erik H. Erikson'],1968,['Archives of General Psychiatry'],Unknown,,635,21,5,10.1001/archpsyc.1969.01740230123023,"Identity, Erikson writes, is an unfathomable as it is all-pervasive. It deals with a process that is located both in the core of the individual and in the core of the communal culture. As the culture changes, new kinds of identity questions arise-Erikson comments, for example, on issues of social protest and changing gender roles that were particular to the 1960s. Representing two decades of groundbreaking work, the essays are not so much a systematic formulation of theory as an evolving report that is both clinical and theoretical. The subjects range from creative confusion in two famous lives-the dramatist George Bernard Shaw and the philosopher William James-to the connection between individual struggles and social order. Race and the Wider Identity and the controversial Womanhood and the Inner Space are included in the collection.","[""Erikson's stages of psychosocial development"", 'Identity (music)', 'Identity crisis', 'Confusion', 'Gender studies', 'Sociology', 'Identity formation', 'Race (biology)', 'Epistemology', 'Psychoanalysis', 'Aesthetics', 'Social science', 'Psychology', 'Self-concept', 'Art', 'Philosophy', 'Face (sociological concept)']","communal culture, social protest, gender roles, creative confusion, individual struggles, social order, woman, inner space"
Paper_00844,Statistical method for testing the neutral mutation hypothesis by DNA polymorphism.,['Fumio Tajima'],1989,Genetics,Journal,,585-595,123,3,10.1093/genetics/123.3.585,"The relationship between the two estimates of genetic variation at the DNA level, namely the number of segregating sites and the average number of nucleotide differences estimated from pairwise comparison, is investigated. It is found that the correlation between these two estimates is large when the sample size is small, and decreases slowly as the sample size increases. Using the relationship obtained, a statistical method for testing the neutral mutation hypothesis is developed. This method needs only the data of DNA polymorphism, namely the genetic variation within population at the DNA level. A simple method of computer simulation, that was used in order to obtain the distribution of a new statistic developed, is also presented. Applying this statistical method to the five regions of DNA sequences in Drosophila melanogaster, it is found that large insertion/deletion (greater than 100 bp) is deleterious. It is suggested that the natural selection against large insertion/deletion is so weak that a large amount of variation is maintained in a population.","['Biology', 'Genetics', 'Polymorphism (computer science)', 'Mutation', 'DNA', 'Computational biology', 'Genotype', 'Gene']","genetic variation, segregating, nucleotide differences, pairwise comparison, neutral mutation hypothesis, dna polymorphism, genetic, computer simulation, dna, drosophila melanogaster"
Paper_00845,Distilling the Knowledge in a Neural Network,"['Geoffrey E. Hinton', 'Oriol Vinyals', 'Jay B. Dean']",2015,arXiv (Cornell University),Unknown,,,,,10.48550/arxiv.1503.02531,"A very simple way to improve the performance of almost any machine learning algorithm is to train many different models on the same data and then to average their predictions. Unfortunately, making predictions using a whole ensemble of models is cumbersome and may be too computationally expensive to allow deployment to a large number of users, especially if the individual models are large neural nets. Caruana and his collaborators have shown that it is possible to compress the knowledge in an ensemble into a single model which is much easier to deploy and we develop this approach further using a different compression technique. We achieve some surprising results on MNIST and we show that we can significantly improve the acoustic model of a heavily used commercial system by distilling the knowledge in an ensemble of models into a single model. We also introduce a new type of ensemble composed of one or more full models and many specialist models which learn to distinguish fine-grained classes that the full models confuse. Unlike a mixture of experts, these specialist models can be trained rapidly and in parallel.","['Artificial neural network', 'Computer science', 'Artificial intelligence']","machine learning algorithm, neural nets, mnist, acoustic model"
Paper_00846,"Social Capital, Intellectual Capital, and the Organizational Advantage","['Janine Nahapiet', 'Sumantra Ghoshal']",1998,Academy of Management Review,Journal,,242-266,23,2,10.5465/amr.1998.533225,"Scholars of the theory of the firm have begun to emphasize the sources and conditions of what has been described as “the organizational advantage,” rather than focus on the causes and consequences of market failure. Typically, researchers see such organizational advantage as accruing from the particular capabilities organizations have for creating and sharing knowledge. In this article we seek to contribute to this body of work by developing the following arguments: (1) social capital facilitates the creation of new intellectual capital; (2) organizations, as institutional settings, are conducive to the development of high levels of social capital; and (3) it is because of their more dense social capital that firms, within certain limits, have an advantage over markets in creating and sharing intellectual capital. We present a model that incorporates this overall argument in the form of a series of hypothesized relationships between different dimensions of social capital and the main mechanisms and proces...","['Intellectual capital', 'Social capital', 'Business', 'Organizational capital', 'Individual capital', 'Social reproduction', 'Organizational culture', 'Financial capital', 'Economic capital', 'Management', 'Economics', 'Sociology', 'Human capital', 'Finance', 'Social science', 'Economic growth']","organizational advantage, market failure, organizational advantage, social capital, intellectual capital, institutional settings, social, social capital"
Paper_00848,Emerging adulthood: A theory of development from the late teens through the twenties.,['Jeffrey Jensen Arnett'],2000,American Psychologist,Journal,,469-480,55,5,10.1037/0003-066x.55.5.469,"Emerging adulthood is proposed as a new conception of development for the period from the late teens through the twenties, with a focus on ages 18-25. A theoretical background is presented. Then evidence is provided to support the idea that emerging adulthood is a distinct period demographically, subjectively, and in terms of identity explorations. How emerging adulthood differs from adolescence and young adulthood is explained. Finally, a cultural context for the idea of emerging adulthood is outlined, and it is specified that emerging adulthood exists only in cultures that allow young people a prolonged period of independent role exploration during the late teens and twenties.","['Young adult', 'Period (music)', 'Early adulthood', 'Psychology', 'Adult development', 'Developmental psychology', 'Context (archaeology)', 'Identity (music)', 'Life course approach', 'Adolescent development', 'History', 'Physics', 'Archaeology', 'Acoustics']","emerging adulthood, emerging adulthood, identity explorations, emerging adulthood, young adulthood, cultural context, emerging adulthood, emerging adulthood, [PAD] [PAD], [PAD], [PAD] [PAD] [PAD]"
Paper_00849,Faster R-CNN: towards real-time object detection with region proposal networks,"['Shaoqing Ren', 'Kaiming He', 'Ross Girshick', 'Jian Sun']",2015,['IEEE Transactions on Pattern Analysis and Machine Intelligence'],Conference,,1137-1149,39,6,10.1109/tpami.2016.2577031,"State-of-the-art object detection networks depend on region proposal algorithms to hypothesize object locations. Advances like SPPnet [7] and Fast R-CNN [5] have reduced the running time of these detection networks, exposing region proposal computation as a bottleneck. In this work, we introduce a Region Proposal Network (RPN) that shares full-image convolutional features with the detection network, thus enabling nearly cost-free region proposals. An RPN is a fully-convolutional network that simultaneously predicts object bounds and objectness scores at each position. RPNs are trained end-to-end to generate high-quality region proposals, which are used by Fast R-CNN for detection. With a simple alternating optimization, RPN and Fast R-CNN can be trained to share convolutional features. For the very deep VGG-16 model [19], our detection system has a frame rate of 5fps (including all steps) on a GPU, while achieving state-of-the-art object detection accuracy on PASCAL VOC 2007 (73.2% mAP) and 2012 (70.4% mAP) using 300 proposals per image. Code is available at https://github.com/ShaoqingRen/faster_rcnn.","['Computer science', 'Pascal (unit)', 'Object detection', 'Convolutional neural network', 'Bottleneck', 'Artificial intelligence', 'Frame rate', 'Computation', 'Frame (networking)', 'Pattern recognition (psychology)', 'Computer vision', 'Algorithm', 'Computer network', 'Programming language', 'Embedded system']","region proposal algorithms, sppnet, region proposal, region proposal network, objectness scores, alternating optimization, pascal vo"
Paper_00851,Maps of Dust Infrared Emission for Use in Estimation of Reddening and Cosmic Microwave Background Radiation Foregrounds,"['David J. Schlegel', 'Douglas P. Finkbeiner', 'Marc Davis']",1998,The Astrophysical Journal,Journal,,525-553,500,2,10.1086/305772,"We present a full-sky 100 μm map that is a reprocessed composite of the COBE/DIRBE and IRAS/ISSA maps, with the zodiacal foreground and confirmed point sources removed. Before using the ISSA maps, we remove the remaining artifacts from the IRAS scan pattern. Using the DIRBE 100 and 240 μm data, we have constructed a map of the dust temperature so that the 100 μm map may be converted to a map proportional to dust column density. The dust temperature varies from 17 to 21 K, which is modest but does modify the estimate of the dust column by a factor of 5. The result of these manipulations is a map with DIRBE quality calibration and IRAS resolution. A wealth of filamentary detail is apparent on many different scales at all Galactic latitudes. In high-latitude regions, the dust map correlates well with maps of H I emission, but deviations are coherent in the sky and are especially conspicuous in regions of saturation of H I emission toward denser clouds and of formation of H2 in molecular clouds. In contrast, high-velocity H I clouds are deficient in dust emission, as expected.","['Physics', 'Zodiacal light', 'Astrophysics', 'Cosmic infrared background', 'Cosmic dust', 'Astronomy', 'Sky', 'Cosmic microwave background', 'Latitude', 'Extinction (optical mineralogy)', 'Infrared', 'Anisotropy', 'Optics', 'Quantum mechanics']","##rocessed, zodiacal foreground, confirmed point sources, ##s, dust temperature, dust column density, dust temperature, dust, ##be quality calibration, iras, filamentary detail, molecular clouds, dust emission, [PAD] [PAD] [PAD] [PAD]"
Paper_00852,Non‐parametric multivariate analyses of changes in community structure,['K.R. Clarke'],1993,Australian Journal of Ecology,Journal,,117-143,18,1,10.1111/j.1442-9993.1993.tb00438.x,"Abstract In the early 1980s, a strategy for graphical representation of multivariate (multi‐species) abundance data was introduced into marine ecology by, among others, Field, et al. (1982). A decade on, it is instructive to: (i) identify which elements of this often‐quoted strategy have proved most useful in practical assessment of community change resulting from pollution impact; and (ii) ask to what extent evolution of techniques in the intervening years has added self‐consistency and comprehensiveness to the approach. The pivotal concept has proved to be that of a biologically‐relevant definition of similarity of two samples, and its utilization mainly in simple rank form, for example ‘sample A is more similar to sample B than it is to sample C’. Statistical assumptions about the data are thus minimized and the resulting non‐parametric techniques will be of very general applicability. From such a starting point, a unified framework needs to encompass: (i) the display of community patterns through clustering and ordination of samples; (ii) identification of species principally responsible for determining sample groupings; (iii) statistical tests for differences in space and time (multivariate analogues of analysis of variance, based on rank similarities); and (iv) the linking of community differences to patterns in the physical and chemical environment (the latter also dictated by rank similarities between samples). Techniques are described that bring such a framework into place, and areas in which problems remain are identified. Accumulated practical experience with these methods is discussed, in particular applications to marine benthos, and it is concluded that they have much to offer practitioners of environmental impact studies on communities.","['Ordination', 'Rank (graph theory)', 'Multivariate statistics', 'Sample (material)', 'Consistency (knowledge bases)', 'Similarity (geometry)', 'Community structure', 'Representation (politics)', 'Field (mathematics)', 'Ecology', 'Cluster analysis', 'Computer science', 'Mathematics', 'Biology', 'Artificial intelligence', 'Machine learning', 'Chemistry', 'Chromatography', 'Combinatorics', 'Politics', 'Political science', 'Pure mathematics', 'Law', 'Image (mathematics)']","graphical representation, marine ecology, community change, pollution impact, statistical, ‐ parametric, community patterns, clustering, sample, statistical tests, multivariate analogues, rank similarities, community differences, rank similarities, marine benthos, environmental impact studies"
Paper_00853,Integrative Analysis of Complex Cancer Genomics and Clinical Profiles Using the cBioPortal,"['Jianjiong Gao', 'Bülent Arman Aksoy', 'Uḡur Doḡrusöz', 'Gideon Dresdner', 'Benjamin Groß', 'S. Onur Sumer', 'Yichao Sun', 'Anders J. Skanderup', 'Rileen Sinha', 'Erik Larsson', 'Ethan Cerami', 'Chris Sander', 'Nikolaus Schultz']",2013,Science Signaling,Journal,,,6,269,10.1126/scisignal.2004088,"The cBioPortal for Cancer Genomics (http://cbioportal.org) provides a Web resource for exploring, visualizing, and analyzing multidimensional cancer genomics data. The portal reduces molecular profiling data from cancer tissues and cell lines into readily understandable genetic, epigenetic, gene expression, and proteomic events. The query interface combined with customized data storage enables researchers to interactively explore genetic alterations across samples, genes, and pathways and, when available in the underlying data, to link these to clinical outcomes. The portal provides graphical summaries of gene-level data from multiple platforms, network visualization and analysis, survival analysis, patient-centric queries, and software programmatic access. The intuitive Web interface of the portal makes complex cancer genomics profiles accessible to researchers and clinicians without requiring bioinformatics expertise, thus facilitating biological discoveries. Here, we provide a practical guide to the analysis and visualization features of the cBioPortal for Cancer Genomics.","['Genomics', 'Visualization', 'Interface (matter)', 'Computer science', 'Computational biology', 'Data visualization', 'Software', 'Data science', 'Bioinformatics', 'World Wide Web', 'Genome', 'Biology', 'Gene', 'Data mining', 'Genetics', 'Bubble', 'Maximum bubble pressure method', 'Parallel computing', 'Programming language']","cbioportal, cancer genomics, cbio, ##al, multidimensional cancer genomics, molecular profiling, cancer tissues, ##te, customized, clinical outcomes, network visualization, survival analysis, software programmatic access, clinic, cbio, ##al, cancer genomics"
Paper_00854,The FAIR Guiding Principles for scientific data management and stewardship,"['Mark D. Wilkinson', 'Michel Dumontier', 'IJsbrand Jan Aalbersberg', 'Gabrielle Appleton', 'Myles Axton', 'Arie Baak', 'Niklas Blomberg', 'Jan‐Willem Boiten', 'Luiz Olavo Bonino da Silva Santos', 'Philip E. Bourne', 'Jildau Bouwman', 'Anthony J. Brookes', 'Tim W. Clark', 'Mercè Crosas', 'Ingrid Dillo', 'Olivier Dumon', 'Scott Edmunds', 'Chris T. Evelo', 'Richard Finkers', 'Alejandra González-Beltrán', 'Alasdair J. G. Gray', 'Paul Groth', 'Carole Goble', 'Jeffrey S. Grethe', 'Jaap Heringa', 'Peter A.C. ’t Hoen', 'Rob Hooft', 'Tobias Kuhn', 'Ruben Kok', 'Joost N. Kok', 'Scott J. Lusher', 'Maryann E. Martone', 'Albert Mons', 'Abel L. Packer', 'Bengt Persson', 'Philippe Rocca‐Serra', 'Marco Roos', 'René van Schaik', 'Susanna‐Assunta Sansone', 'Erik Schultes', 'Thierry Sengstag', 'Ted Slater', 'George Strawn', 'Morris A. Swertz', 'Mark Thompson', 'Johan van der Lei', 'Erik M. van Mulligen', 'Jan Velterop', 'Andra Waagmeester', 'Peter Wittenburg', 'Katherine Wolstencroft', 'Jun Zhao', 'Barend Mons']",2016,Scientific Data,Journal,,,3,1,10.1038/sdata.2016.18,"There is an urgent need to improve the infrastructure supporting the reuse of scholarly data. A diverse set of stakeholders-representing academia, industry, funding agencies, and scholarly publishers-have come together to design and jointly endorse a concise and measureable set of principles that we refer to as the FAIR Data Principles. The intent is that these may act as a guideline for those wishing to enhance the reusability of their data holdings. Distinct from peer initiatives that focus on the human scholar, the FAIR Principles put specific emphasis on enhancing the ability of machines to automatically find and use the data, in addition to supporting its reuse by individuals. This Comment is the first formal publication of the FAIR Principles, and includes the rationale behind them, and some exemplar implementations in the community.","['Stewardship (theology)', 'Reuse', 'Reusability', 'Implementation', 'Computer science', 'Set (abstract data type)', 'Workflow', 'Data science', 'Knowledge management', 'Engineering ethics', 'Process management', 'Public relations', 'Business', 'Political science', 'Software engineering', 'Database', 'Engineering', 'Law', 'Software', 'Politics', 'Programming language', 'Waste management']","scholarly data, funding agencies, scholarly publishers, fair data principles, human scholar"
Paper_00855,Data Analysis Using Regression and Multilevel/Hierarchical Models,"['Andrew Gelman', 'Jennifer Hill']",2006,Unknown,Unknown,,,,,10.1017/cbo9780511790942,"Data Analysis Using Regression and Multilevel/Hierarchical Models, first published in 2007, is a comprehensive manual for the applied researcher who wants to perform data analysis using linear and nonlinear regression and multilevel models. The book introduces a wide variety of models, whilst at the same time instructing the reader in how to fit these models using available software packages. The book illustrates the concepts by working through scores of real data examples that have arisen from the authors' own applied research, with programming codes provided for each one. Topics covered include causal inference, including regression, poststratification, matching, regression discontinuity, and instrumental variables, as well as multilevel logistic regression and missing-data imputation. Practical tips regarding building, fitting, and understanding are provided throughout.","['Multilevel model', 'Computer science', 'Regression analysis', 'Marginal model', 'Logistic regression', 'Imputation (statistics)', 'Missing data', 'Regression', 'Causal inference', 'Regression diagnostic', 'Data mining', 'Hierarchical database model', 'Multivariate adaptive regression splines', 'Inference', 'Cross-sectional regression', 'Linear regression', 'Machine learning', 'Statistics', 'Artificial intelligence', 'Polynomial regression', 'Mathematics']","data analysis, nonlinear regression, multilevel models, software packages, programming codes, causal inference, regression, poststratification, matching, regression discontinuity, instrumental variables, multilevel logistic regression"
Paper_00857,Evaluating Goodness-of-Fit Indexes for Testing Measurement Invariance,"['Gordon W. Cheung', 'Roger B. Rensvold']",2002,Structural Equation Modeling A Multidisciplinary Journal,Journal,,233-255,9,2,10.1207/s15328007sem0902_5,"Abstract Measurement invariance is usually tested using Multigroup Confirmatory Factor Analysis, which examines the change in the goodness-of-fit index (GFI) when cross-group constraints are imposed on a measurement model. Although many studies have examined the properties of GFI as indicators of overall model fit for single-group data, there have been none to date that examine how GFIs change when between-group constraints are added to a measurement model. The lack of a consensus about what constitutes significant GFI differences places limits on measurement invariance testing. We examine 20 GFIs based on the minimum fit function. A simulation under the two-group situation was used to examine changes in the GFIs (ΔGFIs) when invariance constraints were added. Based on the results, we recommend using Δcomparative fit index, ΔGamma hat, and ΔMcDonald's Noncentrality Index to evaluate measurement invariance. These three ΔGFIs are independent of both model complexity and sample size, and are not correlated with the overall fit measures. We propose critical values of these ΔGFIs that indicate measurement invariance.","['Goodness of fit', 'Measurement invariance', 'Confirmatory factor analysis', 'Statistics', 'Structural equation modeling', 'Mathematics', 'Econometrics', 'Index (typography)', 'Factor analysis', 'Psychology', 'Computer science', 'World Wide Web']","abstract measurement invariance, multigroup confirmatory factor analysis, measurement, ##fi, overall model fit, measurement invariance testing, minimum fit function, invariance constraints, δcomparative fit index, δgamma hat, ##mcdon, noncentrality index, measurement invariance, model complexity, sample size, measurement invariance"
Paper_00858,Building Theories from Case Study Research,['Kathleen M. Eisenhardt'],1989,Academy of Management Review,Journal,,532-532,14,4,10.2307/258557,"Describes the process of building theories from case studies and examines the strengths and weaknesses of this process. The case study research strategy is one in which the goal is to understand the dynamics present within an individual environment. The steps identified for building theory include selecting cases, crafting instruments and protocols, entering the field, analyzing data, shaping hypotheses, enfolding literature, and reaching closure. This process is highly iterative and closely tied to the empirical data. Using case studies to build theory has several advantages. First, it is likely to generate novel theory. Additionally, the theories generated are more likely to be built on constructs that are measurable, and these theories are likely to be empirically valid. On the other hand, this approach has weaknesses which include theories that are overly complex or narrow and idiosyncratic. This approach is best used in situations where one does not want to rely on previous literature or prior empirical evidence. The theories generated from this approach must be grounded in convincing evidence and should present novel ideas which meet the requirements of good theory. (SRD)","['Organizational behavior', 'Sociology', 'Management', 'Economics']","case studies, case study research strategy, [PAD]"
Paper_00860,Distributed Optimization and Statistical Learning via the Alternating Direction Method of Multipliers,['Stephen Boyd'],2010,Unknown,Unknown,,,,,10.1561/9781601984616,"Many problems of recent interest in statistics and machine learning can be posed in the framework of convex optimization. Due to the explosion in size and complexity of modern datasets, it is increasingly important to be able to solve problems with a very large number of features or training examples. As a result, both the decentralized collection or storage of these datasets as well as accompanying distributed solution methods are either necessary or at least highly desirable. Distributed Optimization and Statistical Learning via the Alternating Direction Method of Multipliers argues that the alternating direction method of multipliers is well suited to distributed convex optimization, and in particular to large-scale problems arising in statistics, machine learning, and related areas. The method was developed in the 1970s, with roots in the 1950s, and is equivalent or closely related to many other algorithms, such as dual decomposition, the method of multipliers, Douglas-Rachford splitting, Spingarn's method of partial inverses, Dykstra's alternating projections, Bregman iterative algorithms for ?1 problems, proximal methods, and others. After briefly surveying the theory and history of the algorithm, it discusses applications to a wide variety of statistical and machine learning problems of recent interest, including the lasso, sparse logistic regression, basis pursuit, covariance selection, support vector machines, and many others. It also discusses general distributed optimization, extensions to the nonconvex setting, and efficient implementation, including some details on distributed MPI and Hadoop MapReduce implementations.","['Computer science', 'Optimization problem', 'Convex optimization', 'Mathematical optimization', 'Regular polygon', 'Algorithm', 'Mathematics', 'Geometry']","machine learning, convex optimization, distributed solution methods, distributed optimization, statistical learning, alternating, multi, alternating, distributed convex optimization, machine learning, dual decomposition, multipliers, partial inverses, alternating projections, ##man, proximal methods, lasso, sparse logistic regression, basis pursuit, covariance selection, support vector machines, general distributed optimization, nonconvex setting, distributed mpi, hadoop mapreduce implementations"
Paper_00861,The Strengths and Difficulties Questionnaire: A Research Note,['Robert Goodman'],1997,Journal of Child Psychology and Psychiatry,Journal,,581-586,38,5,10.1111/j.1469-7610.1997.tb01545.x,"A novel behavioural screening questionnaire, the Strengths and Difficulties Questionnaire (SDQ), was administered along with Rutter questionnaires to parents and teachers of 403 children drawn from dental and psychiatric clinics. Scores derived from the SDQ and Rutter questionnaires were highly correlated; parent-teacher correlations for the two sets of measures were comparable or favoured the SDQ. The two sets of measures did not differ in their ability to discriminate between psychiatric and dental clinic attenders. These preliminary findings suggest that the SDQ functions as well as the Rutter questionnaires while offering the following additional advantages: a focus on strengths as well as difficulties; better coverage of inattention, peer relationships, and prosocial behaviour; a shorter format; and a single form suitable for both parents and teachers, perhaps thereby increasing parent-teacher correlations.","['Rutter', 'Strengths and Difficulties Questionnaire', 'Psychology', 'Prosocial behavior', 'Clinical psychology', 'Developmental psychology', 'Psychometrics', 'Psychiatry', 'Mental health']","behavioural screening questionnaire, strengths, ##tter, psychiatric clinics, ##tter, dental clinic, inattention, peer relationships, prosocial behaviour"
Paper_00863,A flexible new technique for camera calibration,['Z. Zhang'],2000,IEEE Transactions on Pattern Analysis and Machine Intelligence,Journal,,1330-1334,22,11,10.1109/34.888718,"We propose a flexible technique to easily calibrate a camera. It only requires the camera to observe a planar pattern shown at a few (at least two) different orientations. Either the camera or the planar pattern can be freely moved. The motion need not be known. Radial lens distortion is modeled. The proposed procedure consists of a closed-form solution, followed by a nonlinear refinement based on the maximum likelihood criterion. Both computer simulation and real data have been used to test the proposed technique and very good results have been obtained. Compared with classical techniques which use expensive equipment such as two or three orthogonal planes, the proposed technique is easy to use and flexible. It advances 3D computer vision one more step from laboratory environments to real world use.","['Artificial intelligence', 'Computer science', 'Computer vision', 'Camera resectioning', 'Planar', 'Calibration', 'Camera auto-calibration', 'Distortion (music)', 'Single camera', 'Lens (geology)', 'Nonlinear system', 'Computer graphics (images)', 'Mathematics', 'Optics', 'Statistics', 'Amplifier', 'Computer network', 'Physics', 'Bandwidth (computing)', 'Quantum mechanics']","planar pattern, radial lens distortion, nonlinear refinement, maximum likelihood criterion, computer simulation, real data, orthogonal planes, 3d computer vision, laboratory environments, [PAD]"
Paper_00864,External Control of Organizations: Resource Dependence Perspective,"['Jeffrey Pfeffer', 'Gerald R. Salancik']",2011,Routledge eBooks,Unknown,,267-271,,,10.4324/9781315701967-54,"Among the most widely cited books in the social sciences, The External Control of Organizations has long been required reading for any student of organization studies. The book, reissued on its 25th anniversary as part of the Stanford Business Classics series, includes a new preface written by Jeffrey Pfeffer, which examines the legacy of this influential work in current research and its relationship to other theories.The External Control of Organizations explores how external constraints affect organizations and provides insights for designing and managing organizations to mitigate these constraints. All organizations are dependent on the environment for their survival. As the authors contend, it is the fact of the organization's dependence on the environment that makes the external constraint and control of organizational behavior both possible and almost inevitable. Organizations can either try to change their environments through political means or form interorganizational relationships to control or absorb uncertainty. This seminal book established the resource dependence approach that has informed so many other important organization theories.","['Perspective (graphical)', 'Control (management)', 'Resource dependence theory', 'Human resource management', 'Management control system', 'Business', 'Knowledge management', 'Management', 'Sociology', 'Operations management', 'Engineering', 'Computer science', 'Economics', 'Artificial intelligence']","social, external control, organizations, organization studies, stanford business classics, external control, organizations, external constraints, external constraint, organizational behavior, ##zation, resource dependence"
Paper_00865,Climate Change 2001: The Scientific Basis,"['Richard N. Cooper', 'J. T. Houghton', 'James J. McCarthy', 'Bert Metz']",2002,Foreign Affairs,Journal,,208-208,81,1,10.2307/20033020,"Summary for policymakers Technical summary 1. The climate system - an overview 2. Observed climate variability and change 3. The carbon cycle and atmospheric CO2 4. Atmospheric chemistry and greenhouse gases 5. Aerosols, their direct and indirect effects 6. Radiative forcing of climate change 7. Physical climate processes and feedbacks 8. Model evaluation 9. Projections of future climate change 10. Regional climate simulation - evaluation and projections 11. Changes in sea level 12. Detection of climate change and attribution of causes 13. Climate scenario development 14. Advancing our understanding Glossary Index Appendix.","['Political science', 'Climate change', 'Development economics', 'Economics', 'Geology', 'Oceanography']","climate, observed climate variability, carbon cycle, atmospheric, atmospheric chemistry, greenhouse gases, aerosol, radiative forcing, physical climate processes, feedback, model evaluation, regional climate simulation, sea level, climate scenario development, [PAD], [PAD] [PAD] [PAD], [PAD] [PAD]"
Paper_00866,Harmonizing the Metabolic Syndrome,"['K. G. M. M. Alberti', 'Robert H. Eckel', 'Scott M. Grundy', 'Paul Zimmet', 'James I. Cleeman', 'Karen A. Donato', 'Jean‐Charles Fruchart', 'W. P. T. James', 'Catherine M. Loria', 'Sidney C. Smith']",2009,Circulation,Journal,,1640-1645,120,16,10.1161/circulationaha.109.192644,"A cluster of risk factors for cardiovascular disease and type 2 diabetes mellitus, which occur together more often than by chance alone, have become known as the metabolic syndrome. The risk factors include raised blood pressure, dyslipidemia (raised triglycerides and lowered high-density lipoprotein cholesterol), raised fasting glucose, and central obesity. Various diagnostic criteria have been proposed by different organizations over the past decade. Most recently, these have come from the International Diabetes Federation and the American Heart Association/National Heart, Lung, and Blood Institute. The main difference concerns the measure for central obesity, with this being an obligatory component in the International Diabetes Federation definition, lower than in the American Heart Association/National Heart, Lung, and Blood Institute criteria, and ethnic specific. The present article represents the outcome of a meeting between several major organizations in an attempt to unify criteria. It was agreed that there should not be an obligatory component, but that waist measurement would continue to be a useful preliminary screening tool. Three abnormal findings out of 5 would qualify a person for the metabolic syndrome. A single set of cut points would be used for all components except waist circumference, for which further work is required. In the interim, national or regional cut points for waist circumference can be used.","['Medicine', 'Metabolic syndrome', 'Waist', 'Dyslipidemia', 'Obesity', 'Diabetes mellitus', 'Blood pressure', 'Abdominal obesity', 'Internal medicine', 'Endocrinology']","cardiovascular disease, metabolic syndrome, raised, dyslipidemia, fasting glucose, central obesity, international, central obesity, international, waist measurement, metabolic, waist circumference, waist circumference"
Paper_00867,Single-crystal structure validation with the program<i>PLATON</i>,['Anthony L. Spek'],2003,Journal of Applied Crystallography,Journal,,7-13,36,1,10.1107/s0021889802022112,"The results of a single-crystal structure determination when in CIF format can now be validated routinely by automatic procedures. In this way, many errors in published papers can be avoided. The validation software generates a set of ALERTS detailing issues to be addressed by the experimenter, author, referee and publication journal. Validation was pioneered by the IUCr journal Acta Crystallographica Section C and is currently standard procedure for structures submitted for publication in all IUCr journals. The implementation of validation procedures by other journals is in progress. This paper describes the concepts of validation and the classes of checks that are carried out by the program PLATON as part of the IUCr checkCIF facility. PLATON validation can be run at any stage of the structure refinement, independent of the structure determination package used, and is recommended for use as a routine tool during or at least at the completion of every structure determination. Two examples are discussed where proper validation procedures could have avoided the publication of incorrect structures that had serious consequences for the chemistry involved.","['Computer science', 'Section (typography)', 'Set (abstract data type)', 'Programming language', 'Operating system']","cif, automatic procedures, validation, validation, iucr, validation, validation, platon, iucr, ##cif, platon validation, structure, validation, [PAD]"
Paper_00868,The Amyloid Hypothesis of Alzheimer's Disease: Progress and Problems on the Road to Therapeutics,"['John Hardy', 'Dennis J. Selkoe']",2002,Science,Journal,,353-356,297,5580,10.1126/science.1072994,"It has been more than 10 years since it was first proposed that the neurodegeneration in Alzheimer's disease (AD) may be caused by deposition of amyloid beta-peptide (Abeta) in plaques in brain tissue. According to the amyloid hypothesis, accumulation of Abeta in the brain is the primary influence driving AD pathogenesis. The rest of the disease process, including formation of neurofibrillary tangles containing tau protein, is proposed to result from an imbalance between Abeta production and Abeta clearance.","['Neurodegeneration', 'Pathogenesis', 'Amyloid (mycology)', 'Disease', 'Neuroscience', ""Biochemistry of Alzheimer's disease"", ""Alzheimer's disease"", 'Amyloid beta', 'Amyloid β', 'Medicine', 'Amyloid precursor protein', 'Biology', 'Pathology']","##uro, alzheimer, amyloid hypothesis, ad, neurofibrillary tangles, tau, abeta, abeta clearance, [PAD], [PAD], [PAD] [PAD], [PAD], [PAD] [PAD] [PAD], [PAD], [PAD], [PAD] [PAD], [PAD], [PAD] [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD]"
Paper_00869,GENERAL CIRCULATION EXPERIMENTS WITH THE PRIMITIVE EQUATIONS,['Joseph Smagorinsky'],1963,Monthly Weather Review,Journal,,99-164,91,3,10.1175/1520-0493(1963)091<0099:gcewtp>2.3.co;2,"An extended period numerical integration of a baroclinic primitive equation model has been made for the simulation and the study of the dynamics of the atmosphere's general circulation. The solution corresponding to external gravitational propagation is filtered by requiring the vertically integrated divergence to vanish identically. The vertical structure permits as dependent variables the horizontal wind at two internal levels and a single temperature, with the static stability entering as a parameter. The incoming radiation is a function of latitude only corresponding to the annual mean, and the outgoing radiation is taken to be a function of the local temperature. With the requirement for thermal equilibrium, the domain mean temperature is specified as a parameter. The role of condensation is taken into account only as it effectively reduces the static stability. All other external sources and sinks of heat are assumed to balance each other locally, and are thus omitted. The kinematics are that of a fluid on a sphere bounded by smooth zonal walls at the equator and at approximately 64° latitude. The dissipative sinks are provided by: (a) surface stresses proportional through a drag coefficient to the square of the surface wind which is suitably extrapolated from above, (b) internal convective stresses proportional to the vertical wind shear, and (c) lateral diffusion of momentum and heat through an exchange coefficient which depends on the local horizontal rate of strain—a horizontal length scale entering as the governing parameter. For a given specification of the parameters, an integration for 60 days has been made from initial conditions where random temperature disturbances have been superimposed on a zonally symmetric regime which is baroclinically unstable according to linear theory. This experiment not only displays the scale selective character of baroclinic instability, yielding zonal wave number 5 to 6, but also predicts an index or energy cycle. The period of this cycle is 11 to 12 days for the first 40 days of the experiment, then lengthening to 17 days while diminishing in amplitude during the latter part. The resulting mean zonal velocity profile is in good qualitative agreement with observation, but too intense, presumably because the effective static stability parameter is taken too large. Furthermore this profile is found to be no more than 5 percent super-geostrophic poleward of the angular momentum maximum and no more than 2 percent sub-geostrophic equatorward. The total zonal angular momentum remains constant to within 2 percent irrespective of the phase of the index cycle. This balance is controlled by the surface wind distribution which agrees quite well with observation. The poleward transport is mainly accomplished by the large-scale eddies, whereas the internal vertical flux is predominantly a transfer of the earth's angular momentum by the meridional circulation. The poleward heat transport is primarily accomplished by a Hadley circulation at low latitudes but by the large-scale horizontal eddies in mid-latitudes, where a Ferrel circulation tends to compensate through an equatorward flux. This compensation at mid-latitudes by an indirect meridional circulation is also quite evident, in the potential-kinetic energy transformations. Comparison of the momentum and heat transfer with observed data when available shows reasonably good quantitative agreement. The lateral transfer of momentum and heat by the non-linear diffusion, which parametrically is supposed to simulate the action of motions of sub-grid scale, accounts for a significant portion of the total eddy transfer. Although no direct comparison with the corresponding transfer in the real atmosphere is available, intuitively our small-scale diffusion appears to play too large a role. A diagnosis is made of the transformations among the baratropic and baroclinic parts of the kinetic energy as well as the zonal mean and zonal perturbation parts of the available potential and kinetic energy. This reveals the dominant paths that the energy passes through from source to ultimate sinks and the processes responsible for these transformations. It is found that the partitioning of dissipation by the energy components may differ considerably from estimates made from observation.","['Thermal wind', 'Mechanics', 'Circulation (fluid dynamics)', 'Physics', 'Lapse rate', 'Longitudinal static stability', 'Momentum (technical analysis)', 'Drag', 'Wind shear', 'Classical mechanics', 'Geology', 'Wind speed', 'Meteorology', 'Finance', 'Economics', 'Aerodynamics']","extended period numerical integration, baroclinic primitive equation model, general circulation, external gravitational propagation, vertically integrated divergence, horizontal wind, static stability, domain mean temperature, condensation, static stability, di, ##ve, surface stresses, internal convective stresses, vertical wind shear, lateral diffusion, horizontal length scale, random temperature disturbances, ##ly, baroclinic instability, mean zonal velocity profile, effective static stability parameter, surface wind distribution"
Paper_00871,"A taxonomy for learning, teaching, and assessing : a revision of Bloom's taxonomy of educational objectives","['Lorin W. Anderson', 'David R. Krathwohl']",2001,['SpringerReference'],Unknown,,,,,10.1007/springerreference_301863,"List of Tables and Figures. Preface. Foreword. SECTION I: THE TAXONOMY, EDUCATIONAL OBJECTIVES AND STUDENT LEARNING. 1. Introduction. 2. The Structure, Specificity, and Problems of Objectives. SECTION II: THE REVISED TAXONOMY STRUCTURE. 3. The Taxonomy Table. 4. The Knowledge Dimension. 5. The Cognitive Process Dimension. SECTION III: THE TAXONOMY IN USE. 6. Using the Taxonomy Table. 7. Introduction to the Vignettes. 8. Nutrition Vignette. 9. Macbeth Vignette. 10. Addition Facts Vignette. 11. Parliamentary Acts Vignette. 12. Volcanoes? Here? Vignette. 13. Report Writing Vignette. 14. Addressing Long-standing Problems in Classroom Instruction. APPENDICES. Appendix A: Summary of the Changes from the Original Framework. Appendix B: Condensed Version of the Original Taxonomy of Educational Objectives: Cognitive Domain. References. Credits. Index.","['Vignette', 'Taxonomy (biology)', ""Bloom's taxonomy"", 'Psychology', 'Cognition', 'Computer science', 'Social psychology', 'Ecology', 'Biology', 'Neuroscience']","taxonomy, educational objectives, student learning, specificity, taxonomy table, knowledge dimension, cognitive process dimension, taxonomy table, nutrition vignette, macbeth vignette, addition facts vignette, parliamentary acts, report writing, classroom instruction, educational objectives, cognitive, [PAD], [PAD] [PAD], [PAD], [PAD]"
Paper_00872,MEGA11: Molecular Evolutionary Genetics Analysis Version 11,"['Koichiro Tamura', 'Glen Stecher', 'Sudhir Kumar']",2021,Molecular Biology and Evolution,Journal,,3022-3027,38,7,10.1093/molbev/msab120,"The Molecular Evolutionary Genetics Analysis (MEGA) software has matured to contain a large collection of methods and tools of computational molecular evolution. Here, we describe new additions that make MEGA a more comprehensive tool for building timetrees of species, pathogens, and gene families using rapid relaxed-clock methods. Methods for estimating divergence times and confidence intervals are implemented to use probability densities for calibration constraints for node-dating and sequence sampling dates for tip-dating analyses. They are supported by new options for tagging sequences with spatiotemporal sampling information, an expanded interactive Node Calibrations Editor, and an extended Tree Explorer to display timetrees. Also added is a Bayesian method for estimating neutral evolutionary probabilities of alleles in a species using multispecies sequence alignments and a machine learning method to test for the autocorrelation of evolutionary rates in phylogenies. The computer memory requirements for the maximum likelihood analysis are reduced significantly through reprogramming, and the graphical user interface has been made more responsive and interactive for very big data sets. These enhancements will improve the user experience, quality of results, and the pace of biological discovery. Natively compiled graphical user interface and command-line versions of MEGA11 are available for Microsoft Windows, Linux, and macOS from www.megasoftware.net.","['Biology', 'Sampling (signal processing)', 'Computer science', 'Graphical user interface', 'Node (physics)', 'Software', 'Mega-', 'Bayesian probability', 'Phylogenetic tree', 'Data mining', 'Artificial intelligence', 'Gene', 'Genetics', 'Operating system', 'Physics', 'Structural engineering', 'Filter (signal processing)', 'Astronomy', 'Engineering', 'Computer vision']","molecular evolutionary genetics analysis, mega, computational molecular evolution, time, gene, divergence, confidence intervals, probability densities, ##ration, sequence sampling, spatiotemporal sampling information, extended tree explorer, time, bayesian method, neutral evolutionary probabilities, multispecies sequence alignments, machine learning method, computer memory requirements, maximum likelihood analysis, graphical, mega11, megasoft"
Paper_00873,Graphene: Status and Prospects,['A. K. Geǐm'],2009,Science,Journal,,1530-1534,324,5934,10.1126/science.1158877,"Graphene is a wonder material with many superlatives to its name. It is the thinnest material in the universe and the strongest ever measured. Its charge carriers exhibit giant intrinsic mobility, have the smallest effective mass (it is zero) and can travel micrometer-long distances without scattering at room temperature. Graphene can sustain current densities 6 orders higher than copper, shows record thermal conductivity and stiffness, is impermeable to gases and reconciles such conflicting qualities as brittleness and ductility. Electron transport in graphene is described by a Dirac-like equation, which allows the investigation of relativistic quantum phenomena in a bench-top experiment. What are other surprises that graphene keeps in store for us? This review analyses recent trends in graphene research and applications, and attempts to identify future directions in which the field is likely to develop.","['Graphene', 'Computational biology', 'Nanotechnology', 'Materials science', 'Biology']","graphene, charge carriers, intrinsic mobility, graph, thermal conductivity, stiffness, brittleness, ductility, electron transport, graph, relativistic quantum phenomena, graph, graphene"
Paper_00874,Electrical Energy Storage for the Grid: A Battery of Choices,"['Bruce Dunn', 'Haresh Kamath', 'Jean‐Marie Tarascon']",2011,Science,Journal,,928-935,334,6058,10.1126/science.1212741,"The increasing interest in energy storage for the grid can be attributed to multiple factors, including the capital costs of managing peak demands, the investments needed for grid reliability, and the integration of renewable energy sources. Although existing energy storage is dominated by pumped hydroelectric, there is the recognition that battery systems can offer a number of high-value opportunities, provided that lower costs can be obtained. The battery systems reviewed here include sodium-sulfur batteries that are commercially available for grid applications, redox-flow batteries that offer low cost, and lithium-ion batteries whose development for commercial electronics and electric vehicles is being applied to grid storage.","['Energy storage', 'Renewable energy', 'Grid energy storage', 'Grid', 'Battery (electricity)', 'Reliability (semiconductor)', 'Computer science', 'Capital cost', 'Reliability engineering', 'Electrical engineering', 'Automotive engineering', 'Environmental science', 'Distributed generation', 'Engineering', 'Power (physics)', 'Physics', 'Geometry', 'Mathematics', 'Quantum mechanics']","energy storage, grid reliability, renewable energy sources, pumped hydroelectric, battery systems, electric vehicles, grid storage"
Paper_00876,A method for obtaining digital signatures and public-key cryptosystems,"['Ronald L. Rivest', 'Adi Shamir', 'Leonard M. Adleman']",1983,Communications of the ACM,Journal,,96-99,26,1,10.1145/357980.358017,"An encryption method is presented with the novel property that publicly revealing an encryption key does not thereby reveal the corresponding decryption key. This has two important consequences: Couriers or other secure means are not needed to transmit keys, since a message can be enciphered using an encryption key publicly revealed by the intended recipient. Only he can decipher the message, since only he knows the corresponding decryption key. A message can be “signed” using a privately held decryption key. Anyone can verify this signature using the corresponding publicly revealed encryption key. Signatures cannot be forged, and a signer cannot later deny the validity of his signature. This has obvious applications in “electronic mail” and “electronic funds transfer” systems. A message is encrypted by representing it as a number M, raising M to a publicly specified power e, and then taking the remainder when the result is divided by the publicly specified product, n , of two large secret prime numbers p and q. Decryption is similar; only a different, secret, power d is used, where e * d = 1(mod (p - 1) * (q - 1)). The security of the system rests in part on the difficulty of factoring the published divisor, n .","['Encryption', 'Computer science', 'Digital signature', 'Key (lock)', 'Public-key cryptography', 'Computer security', 'Cryptosystem', 'Signature (topology)', 'Theoretical computer science', 'Mathematics', 'Hash function', 'Geometry']","encryption, encryption, decryption key, courier, ##ryption, ##ryption key, electronic mail ”, electronic funds transfer ” systems"
Paper_00877,"Generalized Gradient Approximation Made Simple [Phys. Rev. Lett. 77, 3865 (1996)]","['John P. Perdew', 'Kieron Burke', 'Matthias Ernzerhof']",1997,Physical Review Letters,Journal,,1396-1396,78,7,10.1103/physrevlett.78.1396,Received 12 December 1996DOI:https://doi.org/10.1103/PhysRevLett.78.1396©1997 American Physical Society,"['Simple (philosophy)', 'Physics', 'Applied mathematics', 'Mathematical physics', 'Statistical physics', 'Quantum electrodynamics', 'Mathematics', 'Philosophy', 'Epistemology']",american
Paper_00879,Multiple emitter location and signal parameter estimation,['René Schmidt'],1986,IEEE Transactions on Antennas and Propagation,Journal,,276-280,34,3,10.1109/tap.1986.1143830,"Processing the signals received on an array of sensors for the location of the emitter is of great enough interest to have been treated under many special case assumptions. The general problem considers sensors with arbitrary locations and arbitrary directional characteristics (gain/phase/polarization) in a noise/interference environment of arbitrary covariance matrix. This report is concerned first with the multiple emitter aspect of this problem and second with the generality of solution. A description is given of the multiple signal classification (MUSIC) algorithm, which provides asymptotically unbiased estimates of 1) number of incident wavefronts present; 2) directions of arrival (DOA) (or emitter locations); 3) strengths and cross correlations among the incident waveforms; 4) noise/interference strength. Examples and comparisons with methods based on maximum likelihood (ML) and maximum entropy (ME), as well as conventional beamforming are included. An example of its use as a multiple frequency estimator operating on time series is included.","['Estimator', 'Beamforming', 'Common emitter', 'Direction of arrival', 'Covariance matrix', 'Computer science', 'Algorithm', 'Principle of maximum entropy', 'Angle of arrival', 'Mathematics', 'Electronic engineering', 'Telecommunications', 'Statistics', 'Antenna (radio)', 'Artificial intelligence', 'Engineering']","arbitrary directional characteristics, multiple emitter, multiple signal classification, ##ally, incident wavefronts, directions of arrival, cross correlations, maximum likelihood, maximum entropy, ##ing, multiple frequency estimator, time series"
Paper_00883,Optical Coherence Tomography,"['David Huang', 'Eric A. Swanson', 'Charles P. Lin', 'Joel S. Schuman', 'William G. Stinson', 'Warren Chang', 'Michael R. Hee', 'Thomas Flotte', 'Kenton W. Gregory', 'Carmen A. Puliafito', 'James G. Fujimoto']",1991,Science,Journal,,1178-1181,254,5035,10.1126/science.1957169,"A technique called optical coherence tomography (OCT) has been developed for noninvasive cross-sectional imaging in biological systems. OCT uses low-coherence interferometry to produce a two-dimensional image of optical scattering from internal tissue microstructures in a way that is analogous to ultrasonic pulse-echo imaging. OCT has longitudinal and lateral spatial resolutions of a few micrometers and can detect reflected signals as small as approximately 10(-10) of the incident optical power. Tomographic imaging is demonstrated in vitro in the peripapillary area of the retina and in the coronary artery, two clinically relevant examples that are representative of transparent and turbid media, respectively.","['Optical coherence tomography', 'Optics', 'Interferometry', 'Tomography', 'Coherence (philosophical gambling strategy)', 'Tomographic reconstruction', 'Materials science', 'Biomedical engineering', 'Physics', 'Medicine', 'Quantum mechanics']","optical coherence tomography, oct, biological systems, optical scattering, internal tissue microstructures, tomographic imaging, peripapillary area, retina, coronary artery, turbid media, [PAD], [PAD] [PAD], [PAD], [PAD]"
Paper_00885,Introduction to information retrieval,"['Christopher D. Manning', 'Prabhakar Raghavan', 'Hinrich Schütze']",2009,Choice Reviews Online,Journal,,46-2715,46,05,10.5860/choice.46-2715,"Class-tested and coherent, this groundbreaking new textbook teaches web-era information retrieval, including web search and the related areas of text classification and text clustering from basic concepts. Written from a computer science perspective by three leading experts in the field, it gives an up-to-date treatment of all aspects of the design and implementation of systems for gathering, indexing, and searching documents; methods for evaluating systems; and an introduction to the use of machine learning methods on text collections. All the important ideas are explained using examples and figures, making it perfect for introductory courses in information retrieval for advanced undergraduates and graduate students in computer science. Based on feedback from extensive classroom experience, the book has been carefully structured in order to make teaching more natural and effective. Although originally designed as the primary text for a graduate or advanced undergraduate course in information retrieval, the book will also create a buzz for researchers and professionals alike.","['Information retrieval', 'Computer science']","web search, text classification, text clustering, computer science, machine learning methods, text collections, information retrieval, graduate students, computer science, information retrieval"
Paper_00886,Adaptive Filter Theory,['S. Haykin'],1986,['Automatica'],Unknown,,567-568,29,2,10.1016/0005-1098(93)90162-m,Background and Overview. 1. Stochastic Processes and Models. 2. Wiener Filters. 3. Linear Prediction. 4. Method of Steepest Descent. 5. Least-Mean-Square Adaptive Filters. 6. Normalized Least-Mean-Square Adaptive Filters. 7. Transform-Domain and Sub-Band Adaptive Filters. 8. Method of Least Squares. 9. Recursive Least-Square Adaptive Filters. 10. Kalman Filters as the Unifying Bases for RLS Filters. 11. Square-Root Adaptive Filters. 12. Order-Recursive Adaptive Filters. 13. Finite-Precision Effects. 14. Tracking of Time-Varying Systems. 15. Adaptive Filters Using Infinite-Duration Impulse Response Structures. 16. Blind Deconvolution. 17. Back-Propagation Learning. Epilogue. Appendix A. Complex Variables. Appendix B. Differentiation with Respect to a Vector. Appendix C. Method of Lagrange Multipliers. Appendix D. Estimation Theory. Appendix E. Eigenanalysis. Appendix F. Rotations and Reflections. Appendix G. Complex Wishart Distribution. Glossary. Abbreviations. Principal Symbols. Bibliography. Index.,"['Adaptive filter', 'Mathematics', 'Recursive least squares filter', 'Least mean squares filter', 'Kalman filter', 'Algorithm', 'Mean squared error', 'Wiener filter', 'Statistics']","stochastic processes, wiener filters, linear prediction, steepest descent, least squares, kalman filters, rls filters, adaptive filters, blind deconvolution, complex variables, ##nge multipliers, estimation theory, rotations, reflections, complex wishart distribution"
Paper_00887,"Production, use, and fate of all plastics ever made","['Roland Geyer', 'Jenna Jambeck', 'Kara Lavender Law']",2017,Science Advances,Journal,,,3,7,10.1126/sciadv.1700782,"We present the first ever global account of the production, use, and end-of-life fate of all plastics ever made by humankind.","['Production (economics)', 'Business', 'Biochemical engineering', 'Environmental science', 'Computer science', 'Engineering', 'Economics', 'Macroeconomics']",plastics
Paper_00891,<i>Ab initio</i> effective core potentials for molecular calculations. Potentials for the transition metal atoms Sc to Hg,"['P. Jeffrey Hay', 'Willard R. Wadt']",1985,The Journal of Chemical Physics,Journal,,270-283,82,1,10.1063/1.448799,"Ab initio effective core potentials (ECP’s) have been generated to replace the Coulomb, exchange, and core-orthogonality effects of the chemically inert core electron in the transition metal atoms Sc to Hg. For the second and third transition series relative ECP’s have been generated which also incorporate the mass–velocity and Darwin relativistic effects into the potential. The ab initio ECP’s should facilitate valence electron calculations on molecules containing transition-metal atoms with accuracies approaching all-electron calculations at a fraction of the computational cost. Analytic fits to the potentials are presented for use in multicenter integral evaluation. Gaussian orbital valence basis sets are developed for the (3d,4s,4p), (4d,5s,5p), and (5d,6s,6p) orbitals of the first, second, and third transition series atoms, respectively. All-electron and valence-electron atomic excitation energies are also compared for the low-lying states of Sc–Hg, and the valence-electron calculations are found to reproduce the all-electron excitation energies (typically within a few tenths of an eV).","['Core electron', 'Atomic physics', 'Chemistry', 'Valence (chemistry)', 'Valence electron', 'Ab initio', 'Atomic orbital', 'Excitation', 'Ab initio quantum chemistry methods', 'Molecular orbital', 'Electron', 'Electron excitation', 'Molecular physics', 'Molecule', 'Physics', 'Quantum mechanics', 'Organic chemistry']","co, transition metal, mass – velocity, darwin relativistic effects, valence electron calculations, multicenter integral evaluation, gaussian orbital valence basis sets"
Paper_00895,The Theory of Island Biogeography,"['Robert H. MacArthur', 'Edward O. Wilson']",2001,Princeton University Press eBooks,Unknown,,,,,10.1515/9781400881376,"Biogeography was stuck in a ""natural history phase"" dominated by the collection of data, the young Princeton biologists Robert H. MacArthur and Edward O. Wilson argued in 1967. In this book, the authors developed a general theory to explain the facts of island biogeography. The theory builds on the first principles of population ecology and genetics to explain how distance and area combine to regulate the balance between immigration and extinction in island populations. The authors then test the theory against data. The Theory of Island Biogeography was never intended as the last word on the subject. Instead, MacArthur and Wilson sought to stimulate new forms of theoretical and empirical studies, which will lead in turn to a stronger general theory. Even a third of a century since its publication, the book continues to serve that purpose well. From popular books like David Quammen's Song of the Dodo to arguments in the professional literature, The Theory of Island Biogeography remains at the center of discussions about the geographic distribution of species. In a new preface, Edward O. Wilson reviews the origins and consequences of this classic book.","['Biogeography', 'Insular biogeography', 'Geography', 'Ecology', 'Biology']","biogeography, natural history, princeton biologist, island biogeography, population ecology, genetics, distance, area, island populations, island biogeography, dodo, island biogeography, geographic distribution"
Paper_00896,Development and use of quantum mechanical molecular models. 76. AM1: a new general purpose quantum mechanical molecular model,"['Michael J. S. Dewar', 'Eve G. Zoebisch', 'Eamonn F. Healy', 'James J. P. Stewart']",1985,Journal of the American Chemical Society,Journal,,3902-3909,107,13,10.1021/ja00299a024,"ADVERTISEMENT RETURN TO ISSUEPREVArticleNEXTDevelopment and use of quantum mechanical molecular models. 76. AM1: a new general purpose quantum mechanical molecular modelMichael J. S. Dewar, Eve G. Zoebisch, Eamonn F. Healy, and James J. P. StewartCite this: J. Am. Chem. Soc. 1985, 107, 13, 3902–3909Publication Date (Print):June 1, 1985Publication History Published online1 May 2002Published inissue 1 June 1985https://pubs.acs.org/doi/10.1021/ja00299a024https://doi.org/10.1021/ja00299a024research-articleACS PublicationsRequest reuse permissionsArticle Views9784Altmetric-Citations12058LEARN ABOUT THESE METRICSArticle Views are the COUNTER-compliant sum of full text article downloads since November 2008 (both PDF and HTML) across all institutions and individuals. These metrics are regularly updated to reflect usage leading up to the last few days.Citations are the number of other articles citing this article, calculated by Crossref and updated daily. Find more information about Crossref citation counts.The Altmetric Attention Score is a quantitative measure of the attention that a research article has received online. Clicking on the donut icon will load a page at altmetric.com with additional details about the score and the social media presence for the given article. Find more information on the Altmetric Attention Score and how the score is calculated. Share Add toView InAdd Full Text with ReferenceAdd Description ExportRISCitationCitation and abstractCitation and referencesMore Options Share onFacebookTwitterWechatLinked InRedditEmail Other access optionsGet e-Alertsclose Get e-Alerts","['Citation', 'Icon', 'Altmetrics', 'Quantum', 'Computer science', 'Social media', 'Information retrieval', 'Data science', 'Physics', 'Library science', 'World Wide Web', 'Quantum mechanics', 'Programming language']","##varticlenext, ##elo, quantum mechanical molecular models, altmetric attention score, social, altmetric attention score, ##d, ##riscitation, abstract, ##ation"
Paper_00897,Transforming Qualitative Information: Thematic Analysis and Code Development,['Richard E. Boyatzis'],1998,['Journal of Nursing Education and Practice'],Unknown,,,6,5,10.5430/jnep.v6n5p100,"The Search for the Codable Moment A Way of Seeing Developing Themes and Codes Deciding on Units of Analysis and Units of Coding as Issues of Sampling Developing Themes and a Code Using the Inductive Method An Example Using Life Stories Developing Themes Using the Theory-Driven and Prior-Research-Driven Method and Then Applying the Code An Example Using a Critical Incident Interview Scoring, Scaling and Clustering Themes Reliability Is Consistency of Judgment Don't Go Breaking My Heart Challenges in Using Thematic Analysis","['Thematic analysis', 'Coding (social sciences)', 'Computer science', 'Consistency (knowledge bases)', 'Code (set theory)', 'Qualitative research', 'Reliability (semiconductor)', 'Cluster analysis', 'Sociology', 'Artificial intelligence', 'Programming language', 'Social science', 'Power (physics)', 'Physics', 'Set (abstract data type)', 'Quantum mechanics']","cod, inductive method, life stories, critical incident interview, clustering, reliability, thematic analysis, [PAD], [PAD] [PAD] [PAD], [PAD] [PAD], [PAD]"
Paper_00901,Evaluation of Factors Related to Late Recurrence - Later than 10 Years after the Initial Treatment - in Primary Breast Cancer,"['Reiki Nishimura', 'Tomofumi Osako', 'Yasuyuki Nishiyama', 'Rumiko Tashima', 'Masahiro Nakano', 'Mamiko Fujisue', 'Yasuo Toyozumi', 'Nobuyuki Arima']",2013,Oncology,Journal,,100-110,85,2,10.1159/000353099,"Tumors can recur years after treatment, and breast cancer is especially noted for long periods of dormancy. The status of the cancer during this period is poorly understood. As a model to study mechanisms of dormancy, we used murine D2.0R mammary carcinoma cells, which are poorly metastatic but form occasional metastases in liver and other organs after long latency. Highly metastatic D2A1 cells provided a positive, metastatic control. Our goals were to learn how the cell lines differ in survival kinetics in a secondary site and to seek evidence for the source of D2.0R dormancy. In spontaneous metastasis assays from mammary fat pad injections, we found evidence for dormancy because of a persistence of large numbers of solitary cells in the liver. To quantify the fate of cells after arrival in liver, experimental metastasis assays were used. To permit identification of cells that had not divided, cells were labeled before injection with fluorescent nanospheres, which were diluted to undetectable levels by cell division. Cancer cells were injected i.v. to target them to the liver and coinjected with reference microspheres to monitor cell survival. Dormancy was defined as retention of nanosphere fluorescence in vivo, as well as negative staining for the proliferation marker Ki67. A large proportion of D2.0R cells persisted as solitary dormant cells. No metastases formed, but viable cells could be recovered from the liver 11 weeks after injection. Large numbers of solitary, dormant, Ki67-negative D2A1 cells were also detected against a background of progressively growing metastases. Thus, this study identified a possible contributor to tumor dormancy: solitary, dormant cells that persist in tissue. If such cells are present in patients, they could contribute to tumor recurrence and would not be susceptible to current therapeutic strategies targeting proliferating cells.","['Metastasis', 'Dormancy', 'Breast cancer', 'Cancer', 'Metastatic breast cancer', 'Cancer research', 'Cancer cell', 'Cell', 'In vivo', 'Liver cancer', 'Pathology', 'Biology', 'Cell division', 'Medicine', 'Internal medicine', 'Botany', 'Germination', 'Genetics', 'Biotechnology']","breast cancer, ##ancy, spontaneous metastasis, mammary fat pad injections, dormancy, solitary cells, metastasis, proliferation, solitary dormant cells, tumor dormancy, tumor rec"
Paper_00903,Pattern classification and scene analysis,"['Richard O. Duda', 'Peter E. Hart']",1973,['Journal of the American Statistical Association'],Unknown,,829,69,347,10.2307/2286028,"Provides a unified, comprehensive and up-to-date treatment of both statistical and descriptive methods for pattern recognition. The topics treated include Bayesian decision theory, supervised and unsupervised learning, nonparametric techniques, discriminant analysis, clustering, preprosessing of pictorial data, spatial filtering, shape description techniques, perspective transformations, projective invariants, linguistic procedures, and artificial intelligence techniques for scene analysis.","['Artificial intelligence', 'Pattern recognition (psychology)', 'Cluster analysis', 'Linear discriminant analysis', 'Computer science', 'Perspective (graphical)', 'Nonparametric statistics', 'Bayesian probability', 'Categorization', 'Machine learning', 'Mathematics', 'Statistics']","descriptive methods, pattern recognition, bayesian decision theory, ##pervised learning, nonparametric techniques, discriminant analysis, clustering, preprosessing, pictorial data, spatial filtering, shape description techniques, perspective transformations, projective invariants, linguistic procedures, artificial intelligence techniques, scene analysis, [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD] [PAD]"
Paper_00904,The PageRank Citation Ranking : Bringing Order to the Web,"['Lawrence M. Page', 'Sergey Brin', 'Rajeev Motwani', 'Terry Winograd']",1999,['Information Processing &amp; Management'],Conference,,800-810,44,2,10.1016/j.ipm.2007.06.006,"The importance of a Web page is an inherently subjective matter, which depends on the readers interests, knowledge and attitudes. But there is still much that can be said objectively about the relative importance of Web pages. This paper describes PageRank, a mathod for rating Web pages objectively and mechanically, effectively measuring the human interest and attention devoted to them. We compare PageRank to an idealized random Web surfer. We show how to efficiently compute PageRank for large numbers of pages. And, we show how to apply PageRank to search and to user navigation.","['PageRank', 'Computer science', 'Ranking (information retrieval)', 'Web page', 'Information retrieval', 'Citation', 'Web search engine', 'World Wide Web', 'Search engine', 'Order (exchange)', 'Web navigation', 'Finance', 'Economics']","web page, web pages, pagerank, web, pagerank, random web surfer, pagerank, pagerank, user navigation"
Paper_00905,Topological insulators and superconductors,"['Xiao-Liang Qi', 'Shou-Cheng Zhang']",2011,Reviews of Modern Physics,Journal,,1057-1110,83,4,10.1103/revmodphys.83.1057,"Topological insulators are new states of quantum matter which can not be adiabatically connected to conventional insulators and semiconductors. They are characterized by a full insulating gap in the bulk and gapless edge or surface states which are protected by time-reversal symmetry. These topological materials have been theoretically predicted and experimentally observed in a variety of systems, including HgTe quantum wells, BiSb alloys, and Bi$_2$Te$_3$ and Bi$_2$Se$_3$ crystals. We review theoretical models, materials properties and experimental results on two-dimensional and three-dimensional topological insulators, and discuss both the topological band theory and the topological field theory. Topological superconductors have a full pairing gap in the bulk and gapless surface states consisting of Majorana fermions. We review the theory of topological superconductors in close analogy to the theory of topological insulators.","['Topological insulator', 'Gapless playback', 'Physics', 'Topological order', 'Topology (electrical circuits)', 'Majorana fermion', 'Pairing', 'MAJORANA', 'Superconductivity', 'Surface states', 'Condensed matter physics', 'Symmetry protected topological order', 'Fermion', 'Topological degeneracy', 'Quantum', 'Surface (topology)', 'Quantum mechanics', 'Geometry', 'Combinatorics', 'Mathematics']","topological insulators, quantum matter, semiconductors, full insulating gap, surface states, topological materials, hgte quantum wells, bis, topological band theory, topological field theory, topological superconductors, pairing gap, ##less surface states, majorana fermions, topological superconductors, topological insulators"
Paper_00906,"Risk Society, Towards a New Modernity","['William Leiss', 'Ulrich Beck', 'Mark Ritter', 'Scott Lash', 'Brian Wynne']",1994,The Canadian Journal of Sociology,Journal,,544-544,19,4,10.2307/3341155,"Introduction - Scott Lash and Brian Wynne PART ONE: LIVING ON THE VOLCANO OF CIVILIZATION - THE CONTOURS OF THE RISK SOCIETY On the Logic of Wealth Distribution and Risk Distribution The Politics of Knowledge in the Risk Society PART TWO: THE INDIVIDUALIZATION OF SOCIAL INEQUALITY - LIFE-FORMS AND THE DEMISE OF TRADITION Beyond Status and Class? 'I am I' Gendered Space and the Conflict Inside and Outside the Family Individualization, Institutionalization and Standardization Life Situations and Biographical Patterns De-Standardization of Labour PART THREE: REFLEXIVE MODERNIZATION: ON THE GENERALIZATION OF SCIENCE AND POLITICS Science Beyond Truth and Enlightenment? Opening up the Political","['Modernity', 'Sociology', 'Risk society', 'Late modernity', 'Social science', 'Epistemology', 'Philosophy']","civilization, risk society, wealth distribution, risk distribution, knowledge, risk society, individual, social inequality, institutional, standardization, biographical patterns, standardization, reflexive modernization, political, [PAD], [PAD]"
Paper_00907,Arlequin (version 3.0): an integrated software package for population genetics data analysis.,"['Laurent Excoffier', 'Guillaume Laval', 'Stefan Schneider']",2007,['Evolutionary Bioinformatics'],Unknown,,,1,,10.1177/117693430500100003,"Arlequin ver 3.0 is a software package integrating several basic and advanced methods for population genetics data analysis, like the computation of standard genetic diversity indices, the estimation of allele and haplotype frequencies, tests of departure from linkage equilibrium, departure from selective neutrality and demographic equilibrium, estimation or parameters from past population expansions, and thorough analyses of population subdivision under the AMOVA framework. Arlequin 3 introduces a completely new graphical interface written in C++, a more robust semantic analysis of input files, and two new methods: a Bayesian estimation of gametic phase from multi-locus genotypes, and an estimation of the parameters of an instantaneous spatial expansion from DNA sequence polymorphism. Arlequin can handle several data types like DNA sequences, microsatellite data, or standard multi-locus genotypes. A Windows version of the software is freely available on http://cmpg.unibe.ch/software/arlequin3.","['Software', 'Population', 'Fixation index', 'Locus (genetics)', 'Population genetics', 'Microsatellite', 'Computer science', 'Bayesian probability', 'Data mining', 'Data science', 'Biology', 'Genetics', 'Allele', 'Programming language', 'Artificial intelligence', 'Medicine', 'Environmental health', 'Gene']","arlequin, population genetics data analysis, genetic diversity indices, haplotype frequencies, linkage equilibrium, selective neutrality, demographic equilibrium, population subdivision, amova, arlequin, semantic analysis, bayesian estimation, gametic phase, instantaneous spatial expansion, dna sequence polymorphism, ##quin, dna sequences, microsatellite data, ##quin"
Paper_00908,Experimental and Quasi-Experimental Designs for Generalized Causal Inference,"['William R. Shadish', 'Thomas D. Cook', 'Donald T. Campbell']",2001,['Journal of the American Statistical Association'],Unknown,,708-708,100,470,10.1198/jasa.2005.s22,"1. Experiments and Generalized Causal Inference 2. Statistical Conclusion Validity and Internal Validity 3. Construct Validity and External Validity 4. Quasi-Experimental Designs That Either Lack a Control Group or Lack Pretest Observations on the Outcome 5. Quasi-Experimental Designs That Use Both Control Groups and Pretests 6. Quasi-Experimentation: Interrupted Time Series Designs 7. Regression Discontinuity Designs 8. Randomized Experiments: Rationale, Designs, and Conditions Conducive to Doing Them 9. Practical Problems 1: Ethics, Participant Recruitment, and Random Assignment 10. Practical Problems 2: Treatment Implementation and Attrition 11. Generalized Causal Inference: A Grounded Theory 12. Generalized Causal Inference: Methods for Single Studies 13. Generalized Causal Inference: Methods for Multiple Studies 14. A Critical Assessment of Our Assumptions","['Causal inference', 'Randomized experiment', 'Random assignment', 'Inference', 'External validity', 'Internal validity', 'Regression discontinuity design', 'Causal model', 'Attrition', 'Construct (python library)', 'Statistical inference', 'Computer science', 'Econometrics', 'Mathematics', 'Statistics', 'Artificial intelligence', 'Medicine', 'Dentistry', 'Programming language']","generalized causal inference, statistical conclusion validity, internal validity, construct validity, external validity, control group, ##s, interrupted time series designs, regression discontinuity designs, randomized experiments, ethics, participant recruitment, random assignment, treatment implementation, attrition, generalized causal inference, grounded theory, generalized causal inference, single studies, generalized causal inference, multiple studies, critical assessment, [PAD] [PAD], [PAD] [PAD] [PAD], [PAD]"
Paper_00909,Pyramid Scene Parsing Network,"['Hengshuang Zhao', 'Jianping Shi', 'Xiaojuan Qi', 'Xiaogang Wang', 'Jiaya Jia']",2017,Unknown,Unknown,,,,,10.1109/cvpr.2017.660,"Scene parsing is challenging for unrestricted open vocabulary and diverse scenes. In this paper, we exploit the capability of global context information by different-region-based context aggregation through our pyramid pooling module together with the proposed pyramid scene parsing network (PSPNet). Our global prior representation is effective to produce good quality results on the scene parsing task, while PSPNet provides a superior framework for pixel-level prediction. The proposed approach achieves state-of-the-art performance on various datasets. It came first in ImageNet scene parsing challenge 2016, PASCAL VOC 2012 benchmark and Cityscapes benchmark. A single PSPNet yields the new record of mIoU accuracy 85.4% on PASCAL VOC 2012 and accuracy 80.2% on Cityscapes.","['Pascal (unit)', 'Computer science', 'Parsing', 'Artificial intelligence', 'Pyramid (geometry)', 'Pooling', 'Exploit', 'Context (archaeology)', 'Benchmark (surveying)', 'Object detection', 'Vocabulary', 'Computer vision', 'Natural language processing', 'Pattern recognition (psychology)', 'Programming language', 'Cartography', 'Paleontology', 'Linguistics', 'Philosophy', 'Physics', 'Computer security', 'Optics', 'Biology', 'Geography']","scene parsing, open vocabulary, global context information, pyramid pooling module, pyramid scene parsing network, pspnet, pspnet, imagenet scene parsing challenge, pascal voc 2012, cityscapes benchmark, miou accuracy, pascal voc, cityscapes, [PAD] [PAD] [PAD], [PAD], [PAD], [PAD], [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD] [PAD], [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD], [PAD] [PAD], [PAD], [PAD], [PAD]"
Paper_00910,"Health Behavior and Health Education: Theory, Research, and Practice","['Karen Glanz', 'Barbara K. Rimer', 'Kasisomayajula Viswanath']",1992,Annals of Internal Medicine,Journal,,350-350,116,4,10.7326/0003-4819-116-4-350_1,"Health behavior change is our greatest hope for reducing the burden of preventable disease and death around the world. Tobacco use, sedentary lifestyle, unhealthy diet, and alcohol use together account for almost one million deaths each year in the United States alone. Smoking prevalence in the United States has dropped by half since the first Surgeon General’s Report on Smoking and Health was published in 1964, but tobacco use still causes over 400,000 premature deaths each year. The World Health Organization has warned that the worldwide spread of the tobacco epidemic could claim one billion lives by the end of this century. The rising prevalence of childhood obesity could place the United States at risk of raising the first generation of children to live sicker and die younger than their parents, and the spreading epidemic of obesity among children and adults threatens staggering global health and economic tolls. The four leading behavioral risks factors and a great many others (for example, nonadherence to prescribed medical screening and prevention and disease management practices, risky sexual practices, drug use, family and gun violence, worksite and motor vehicle injuries) take disproportionate tolls in low-income and disadvantaged racial and ethnic populations, as well as in low-resource communities across the world. Addressing these behavioral risks and disparities, and the behaviors related to global health threats, such as flu pandemics, water shortages, increasingly harmful sun exposure, and the need to protect the health of the planet itself, will be critical to world health in the twenty-first century. In the past two decades since the publication of the first edition of Health Education and Health Behavior: Theory, Research, and Practice in 1990, there has been extraordinary growth in our knowledge about interventions needed to change health behaviors at both individual and population levels. This progress can be measured in the proliferation of science-based recommendations issued by authoritative evidence review panels, including the U.S. Clinical Preventive Services Task Force, the Centers for Disease Prevention and Control Task Force on Community Preventive Services, and the international Cochrane Collaboration. Today, there are evidence-based clinical practice guidelines for most major behavioral health risks, including tobacco use, unhealthy diet, sedentary lifestyle, risky drinking, and diabetes management. And there are parallel research-based guidelines for the health care system changes and policies needed to assure their delivery and use. New community practice guidelines offer additional evidence-based recommendations for a wide array of population-level school-, worksite-, and community-based programs and public policies to improve vaccination rates and physical activity levels for children and adults, improve diabetes self-management, reduce harmful sun exposure, reduce secondhand smoke exposure, prevent youth tobacco use and help adult smokers quit, reduce workplace and motor vehicle injuries, and curb drunk driving and family and gun violence.",['Medicine'],"health behavior, tobacco use, sedentary lifestyle, unhealthy diet, alcohol use, smoking prevalence, tobacco, tobacco, childhood obesity, behavioral risks, risky sexual practices, drug, motor, flu pandemics, water shortages, health education, health behavior, clinical preventive services, community preventive services, behavioral health risks, tobacco, unhealthy diet, sedentary lifestyle, risky drinking, diabetes management"
Paper_00911,Vitamin D Deficiency,['Michael F. Holick'],2007,New England Journal of Medicine,Journal,,266-281,357,3,10.1056/nejmra070553,"Once foods in the United States were fortified with vitamin D, rickets appeared to have been conquered, and many considered major health problems from vitamin D deficiency resolved. But vitamin D deficiency is common. This review considers the role of vitamin D in skeletal and nonskeletal health and suggests strategies for the prevention and treatment of vitamin D deficiency.","['Medicine', 'Rickets', 'vitamin D deficiency', 'Vitamin D and neurology', 'Vitamin', 'Vitamin deficiency', 'Vitamin A deficiency', 'Endocrinology', 'Physiology', 'Pediatrics', 'Retinol']","united, rick, vitamin, vitamin, nonskeletal health, vitamin, [PAD], [PAD], [PAD], [PAD] [PAD]"
Paper_00912,Data clustering,"['Anil K. Jain', 'M. Narasimha Murty', 'Patrick J. Flynn']",1999,ACM Computing Surveys,Journal,,264-323,31,3,10.1145/331499.331504,"Clustering is the unsupervised classification of patterns (observations, data items, or feature vectors) into groups (clusters). The clustering problem has been addressed in many contexts and by researchers in many disciplines; this reflects its broad appeal and usefulness as one of the steps in exploratory data analysis. However, clustering is a difficult problem combinatorially, and differences in assumptions and contexts in different communities has made the transfer of useful generic concepts and methodologies slow to occur. This paper presents an overview of pattern clustering methods from a statistical pattern recognition perspective, with a goal of providing useful advice and references to fundamental concepts accessible to the broad community of clustering practitioners. We present a taxonomy of clustering techniques, and identify cross-cutting themes and recent advances. We also describe some important applications of clustering algorithms such as image segmentation, object recognition, and information retrieval.","['Cluster analysis', 'Computer science', 'Conceptual clustering', 'Consensus clustering', 'Fuzzy clustering', 'Perspective (graphical)', 'Biclustering', 'Artificial intelligence', 'Data mining', 'Clustering high-dimensional data', 'Machine learning', 'Information retrieval', 'CURE data clustering algorithm', 'Data science']","clustering, ##ed, feature vectors, cluster, ##tory data analysis, clustering, pattern clustering methods, statistical pattern recognition, clustering, clustering algorithms, image segmentation, object recognition, information retrieval"
Paper_00915,"Global burden of 369 diseases and injuries in 204 countries and territories, 1990–2019: a systematic analysis for the Global Burden of Disease Study 2019","['Theo Vos', 'Stephen S Lim', 'Cristiana Abbafati', 'Kaja Abbas', 'Mohammad Abbasi', 'Mitra Abbasifard', 'Mohsen Abbasi‐Kangevari', 'Hedayat Abbastabar', 'Foad Abd-Allah', 'Ahmed Abdelalim', 'Mohammad Abdollahi', 'Ibrahim Abdollahpour', 'Hassan Abolhassani', 'Victor Aboyans', 'Elissa M. Abrams', 'Lucas Guimarães Abreu', 'Michael R.M. Abrigo', 'Laith J. Abu‐Raddad', 'Abdelrahman Ibrahim Abushouk', 'Alyssa Acebedo', 'Ilana N. Ackerman', 'Maryam Adabi', 'Abdu A. Adamu', 'Oladimeji Adebayo', 'Victor Adekanmbi', 'Jaimie D. Adelson', 'Olatunji Adetokunboh', 'Davoud Adham', 'Mahdi Afshari', 'Ashkan Afshin', 'Emilie Agardh', 'Gina Agarwal', 'Kareha M Agesa', 'Mohammad Aghaali', 'Seyed Mohammad Kazem Aghamir', 'Anurag Agrawal', 'Tauseef Ahmad', 'Alireza Ahmadi', 'Mehdi Ahmadi', 'Hamid Ahmadieh', 'Ehsan Ahmadpour', 'Temesgen Yihunie Akalu', 'Rufus Akinyemi', 'Tomi Akinyemiju', 'Blessing Akombi-Inyang', 'Ziyad Al‐Aly', 'Khurshid Alam', 'Noore Alam', 'Shazia Alam', 'Shazia Alam', 'Turki Alanzi', 'Samuel B Albertson', 'Jacqueline Elizabeth Alcalde‐Rabanal', 'Niguse Meles Alema', 'Muhammad Ali', 'Saqib Ali', 'Gianfranco Alicandro', 'Mehran Alijanzadeh', 'Cyrus Alinia', 'Vahid Alipour', 'Syed Mohamed Aljunid', 'François Alla', 'Peter Allebeck', 'Amir Almasi‐Hashiani', 'Jordi Alonso', 'Rajaa Al‐Raddadi', 'Khalid A Altirkawi', 'Nelson Alvis‐Guzmán', 'Nelson J. Alvis-Zakzuk', 'GK Mini', 'Mostafa Amini‐Rarani', 'Arya Aminorroaya', 'Fatemeh Amiri', 'Arianna Maever L. Amit', 'Dickson A Amugsi', 'Gianna Gayle Herrera Amul', 'Deanna Anderlini', 'Cătălina Liliana Andrei', 'Tudorel Andrei', 'Mina Anjomshoa', 'Fereshteh Ansari', 'Iman Ansari', 'Alireza Ansari-Moghaddam', 'Carl Abelardo T Antonio', 'Catherine M Antony', 'Ernoiz Antriyandarti', 'Davood Anvari', 'Razique Anwer', 'Jalal Arabloo', 'Morteza Arab‐Zozani', 'Aleksandr Y. Aravkin', 'Filippo Ariani', 'Johan Ärnlöv', 'Kavumpurathu Raman Thankappan', 'Afsaneh Arzani', 'Mehran Asadi-Aliabadi', 'Ali A. Asadi‐Pooya', 'Babak Asghari', 'Charlie Ashbaugh', 'Desta Debalkie Atnafu']",2020,The Lancet,Journal,,1204-1222,396,10258,10.1016/s0140-6736(20)30925-9,"<h2>Summary</h2><h3>Background</h3> In an era of shifting global agendas and expanded emphasis on non-communicable diseases and injuries along with communicable diseases, sound evidence on trends by cause at the national level is essential. The Global Burden of Diseases, Injuries, and Risk Factors Study (GBD) provides a systematic scientific assessment of published, publicly available, and contributed data on incidence, prevalence, and mortality for a mutually exclusive and collectively exhaustive list of diseases and injuries. <h3>Methods</h3> GBD estimates incidence, prevalence, mortality, years of life lost (YLLs), years lived with disability (YLDs), and disability-adjusted life-years (DALYs) due to 369 diseases and injuries, for two sexes, and for 204 countries and territories. Input data were extracted from censuses, household surveys, civil registration and vital statistics, disease registries, health service use, air pollution monitors, satellite imaging, disease notifications, and other sources. Cause-specific death rates and cause fractions were calculated using the Cause of Death Ensemble model and spatiotemporal Gaussian process regression. Cause-specific deaths were adjusted to match the total all-cause deaths calculated as part of the GBD population, fertility, and mortality estimates. Deaths were multiplied by standard life expectancy at each age to calculate YLLs. A Bayesian meta-regression modelling tool, DisMod-MR 2.1, was used to ensure consistency between incidence, prevalence, remission, excess mortality, and cause-specific mortality for most causes. Prevalence estimates were multiplied by disability weights for mutually exclusive sequelae of diseases and injuries to calculate YLDs. We considered results in the context of the Socio-demographic Index (SDI), a composite indicator of income per capita, years of schooling, and fertility rate in females younger than 25 years. Uncertainty intervals (UIs) were generated for every metric using the 25th and 975th ordered 1000 draw values of the posterior distribution. <h3>Findings</h3> Global health has steadily improved over the past 30 years as measured by age-standardised DALY rates. After taking into account population growth and ageing, the absolute number of DALYs has remained stable. Since 2010, the pace of decline in global age-standardised DALY rates has accelerated in age groups younger than 50 years compared with the 1990–2010 time period, with the greatest annualised rate of decline occurring in the 0–9-year age group. Six infectious diseases were among the top ten causes of DALYs in children younger than 10 years in 2019: lower respiratory infections (ranked second), diarrhoeal diseases (third), malaria (fifth), meningitis (sixth), whooping cough (ninth), and sexually transmitted infections (which, in this age group, is fully accounted for by congenital syphilis; ranked tenth). In adolescents aged 10–24 years, three injury causes were among the top causes of DALYs: road injuries (ranked first), self-harm (third), and interpersonal violence (fifth). Five of the causes that were in the top ten for ages 10–24 years were also in the top ten in the 25–49-year age group: road injuries (ranked first), HIV/AIDS (second), low back pain (fourth), headache disorders (fifth), and depressive disorders (sixth). In 2019, ischaemic heart disease and stroke were the top-ranked causes of DALYs in both the 50–74-year and 75-years-and-older age groups. Since 1990, there has been a marked shift towards a greater proportion of burden due to YLDs from non-communicable diseases and injuries. In 2019, there were 11 countries where non-communicable disease and injury YLDs constituted more than half of all disease burden. Decreases in age-standardised DALY rates have accelerated over the past decade in countries at the lower end of the SDI range, while improvements have started to stagnate or even reverse in countries with higher SDI. <h3>Interpretation</h3> As disability becomes an increasingly large component of disease burden and a larger component of health expenditure, greater research and development investment is needed to identify new, more effective intervention strategies. With a rapidly ageing global population, the demands on health services to deal with disabling outcomes, which increase with age, will require policy makers to anticipate these changes. The mix of universal and more geographically specific influences on health reinforces the need for regular reporting on population health in detail and by underlying cause to help decision makers to identify success stories of disease control to emulate, as well as opportunities to improve. <h3>Funding</h3> Bill & Melinda Gates Foundation.","['Years of potential life lost', 'Life expectancy', 'Demography', 'Population', 'Disease burden', 'Medicine', 'Environmental health', 'Cause of death', 'Context (archaeology)', 'Burden of disease', 'Public health', 'Incidence (geometry)', 'Disease', 'Geography', 'Physics', 'Nursing', 'Archaeology', 'Optics', 'Pathology', 'Sociology']","commun, ##ble, risk factors, household surveys, civil registration, vital statistics, disease registries, health service use, air pollution monitors, satellite imaging, disease notifications, cause fraction, spatiotemporal gaussian process regression, excess mortality, prevalence, uncertainty intervals, posterior distribution, global health"
Paper_00918,A New Depression Scale Designed to be Sensitive to Change,"['Stuart Montgomery', 'Marie Åsberg']",1979,The British Journal of Psychiatry,Journal,,382-389,134,4,10.1192/bjp.134.4.382,"Summary The construction of a depression rating scale designed to be particularly sensitive to treatment effects is described. Ratings of 54 English and 52 Swedish patients on a 65 item comprehensive psychopathology scale were used to identify the 17 most commonly occurring symptoms in primary depressive illness in the combined sample. Ratings on these 17 items for 64 patients participating in studies of four different antidepressant drugs were used to create a depression scale consisting of the 10 items which showed the largest changes with treatment and the highest correlation to overall change. The inter-rater reliability of the new depression scale was high. Scores on the scale correlated significantly with scores on a standard rating scale for depression, the Hamilton Rating Scale (HRS), indicating its validity as a general severity estimate. Its capacity to differentiate between responders and non-responders to antidepressant treatment was better than the HRS, indicating greater sensitivity to change. The practical and ethical implications in terms of smaller sample sizes in clinical trials are discussed.","['Rating scale', 'Depression (economics)', 'Psychopathology', 'Antidepressant', 'Scale (ratio)', 'Clinical psychology', 'Psychology', 'Hamilton Rating Scale for Depression', 'Reliability (semiconductor)', 'Psychiatry', 'Medicine', 'Major depressive disorder', 'Mood', 'Anxiety', 'Developmental psychology', 'Physics', 'Power (physics)', 'Quantum mechanics', 'Economics', 'Macroeconomics']","depression rating scale, treatment effects, comprehensive psychopathology scale, primary depressive illness, ##press, hamilton rating scale, [PAD]"
Paper_00919,Job Market Signaling,['Michael Spence'],1973,The Quarterly Journal of Economics,Journal,,355-355,87,3,10.2307/1882010,"1. Introduction, 355. — 2. Hiring as investment under uncertainty, 356. — 3. Applicant signaling, 358. — 4. Informational feedback and the definition of equilibrium, 359. — 5. Properties of informational equilibria: an example, 361. — 6. The informational impact of indices, 368. — Conclusions, 374.","['Economics', 'Investment (military)', 'Microeconomics', 'Law', 'Political science', 'Politics']","hiring, investment, uncertainty, applicant signaling, informational feedback, equilibrium, informational equilibria, informational impact, indices"
Paper_00920,A simple transmit diversity technique for wireless communications,['S.M. Alamouti'],1998,IEEE Journal on Selected Areas in Communications,Journal,,1451-1458,16,8,10.1109/49.730453,"This paper presents a simple two-branch transmit diversity scheme. Using two transmit antennas and one receive antenna the scheme provides the same diversity order as maximal-ratio receiver combining (MRRC) with one transmit antenna, and two receive antennas. It is also shown that the scheme may easily be generalized to two transmit antennas and M receive antennas to provide a diversity order of 2M. The new scheme does not require any bandwidth expansion or any feedback from the receiver to the transmitter and its computation complexity is similar to MRRC.","['Computer science', 'Transmit diversity', 'Transmitter', 'Simple (philosophy)', 'Antenna diversity', 'Bandwidth (computing)', 'Wireless', 'Telecommunications', 'Diversity scheme', 'Diversity gain', 'Antenna (radio)', 'Scheme (mathematics)', 'Electronic engineering', 'MIMO', 'Fading', 'Mathematics', 'Channel (broadcasting)', 'Engineering', 'Philosophy', 'Epistemology', 'Mathematical analysis']","transmit antennas, diversity order, diversity order, bandwidth expansion"
Paper_00922,Mfold web server for nucleic acid folding and hybridization prediction,['Michael Zuker'],2003,Nucleic Acids Research,Journal,,3406-3415,31,13,10.1093/nar/gkg595,"The abbreviated name, 'mfold web server', describes a number of closely related software applications available on the World Wide Web (WWW) for the prediction of the secondary structure of single stranded nucleic acids. The objective of this web server is to provide easy access to RNA and DNA folding and hybridization software to the scientific community at large. By making use of universally available web GUIs (Graphical User Interfaces), the server circumvents the problem of portability of this software. Detailed output, in the form of structure plots with or without reliability information, single strand frequency plots and 'energy dot plots', are available for the folding of single sequences. A variety of 'bulk' servers give less information, but in a shorter time and for up to hundreds of sequences at once. The portal for the mfold web server is http://www.bioinfo.rpi.edu/applications/mfold. This URL will be referred to as 'MFOLDROOT'.","['Web server', 'Software portability', 'Software', 'Biology', 'Computer science', 'Server', 'Nucleic acid', 'Web service', 'Computational biology', 'Bioinformatics', 'The Internet', 'World Wide Web', 'Genetics', 'Operating system']","mfold web server, secondary structure, single stranded nucleic acids, dna folding, hybridization software, graphical user interfaces, structure plots, reliability information, single strand frequency plots, energy dot plots, ##fold web server, ##fold, ##ot, [PAD], [PAD] [PAD], [PAD], [PAD] [PAD] [PAD] [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD], [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD] [PAD]"
Paper_00923,"A Second Generation Force Field for the Simulation of Proteins, Nucleic Acids, and Organic Molecules","['Wendy D. Cornell', 'Piotr Cieplak', 'Christopher I. Bayly', 'Ian R. Gould', 'Kenneth M. Merz', 'David M. Ferguson', 'David C. Spellmeyer', 'Thomas Fox', 'James W. Caldwell', 'Peter A. Kollman']",1995,Journal of the American Chemical Society,Journal,,5179-5197,117,19,10.1021/ja00124a002,"ADVERTISEMENT RETURN TO ISSUEPREVArticleNEXTA Second Generation Force Field for the Simulation of Proteins, Nucleic Acids, and Organic MoleculesWendy D. Cornell, Piotr Cieplak, Christopher I. Bayly, Ian R. Gould, Kenneth M. Merz, David M. Ferguson, David C. Spellmeyer, Thomas Fox, James W. Caldwell, and Peter A. KollmanCite this: J. Am. Chem. Soc. 1995, 117, 19, 5179–5197Publication Date (Print):May 1, 1995Publication History Published online1 May 2002Published inissue 1 May 1995https://pubs.acs.org/doi/10.1021/ja00124a002https://doi.org/10.1021/ja00124a002research-articleACS PublicationsRequest reuse permissionsArticle Views31358Altmetric-Citations11179LEARN ABOUT THESE METRICSArticle Views are the COUNTER-compliant sum of full text article downloads since November 2008 (both PDF and HTML) across all institutions and individuals. These metrics are regularly updated to reflect usage leading up to the last few days.Citations are the number of other articles citing this article, calculated by Crossref and updated daily. Find more information about Crossref citation counts.The Altmetric Attention Score is a quantitative measure of the attention that a research article has received online. Clicking on the donut icon will load a page at altmetric.com with additional details about the score and the social media presence for the given article. Find more information on the Altmetric Attention Score and how the score is calculated. Share Add toView InAdd Full Text with ReferenceAdd Description ExportRISCitationCitation and abstractCitation and referencesMore Options Share onFacebookTwitterWechatLinked InRedditEmail Other access optionsGet e-Alertsclose Get e-Alerts","['Citation', 'Altmetrics', 'Computer science', 'Field (mathematics)', 'Social media', 'Library science', 'Chemistry', 'Information retrieval', 'Art history', 'World Wide Web', 'Art', 'Mathematics', 'Pure mathematics']","nucleic, organic molecules, permissionsar, ##le, ##f, ##f, altmetric attention score, donut, alt, social, altmetric attention score, ##d description export, ##citation, abstract"
Paper_00924,Metagenomic biomarker discovery and explanation,"['Nicola Segata', 'Jacques Izard', 'Levi Waldron', 'Dirk Gevers', 'Larisa Miropolsky', 'Wendy S. Garrett', 'Curtis Huttenhower']",2011,Genome biology,Journal,,,12,6,10.1186/gb-2011-12-6-r60,"Abstract This study describes and validates a new method for metagenomic biomarker discovery by way of class comparison, tests of biological consistency and effect size estimation. This addresses the challenge of finding organisms, genes, or pathways that consistently explain the differences between two or more microbial communities, which is a central problem to the study of metagenomics. We extensively validate our method on several microbiomes and a convenient online interface for the method is provided at http://huttenhower.sph.harvard.edu/lefse/ .","['Metagenomics', 'Biology', 'Computational biology', 'Human genetics', 'Genome Biology', 'Biomarker discovery', 'Evolutionary biology', 'Biomarker', 'Genomics', 'Genetics', 'Bioinformatics', 'Proteomics', 'Genome', 'Gene']","metagenomic biomarker discovery, class comparison, biological consistency, effect size estimation, metagen, online interface"
Paper_00926,Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data,"['John Lafferty', 'Andrew McCallum', 'Fernando C. N. Pereira']",2001,['2010 IEEE International Conference on Data Mining'],Conference,"2010 IEEE 10th International Conference on Data Mining (ICDM), Sydney, Australia",767-772,,,10.1109/icdm.2010.99,"We present conditional random fields , a framework for building probabilistic models to segment and label sequence data. Conditional random fields offer several advantages over hidden Markov models and stochastic grammars for such tasks, including the ability to relax strong independence assumptions made in those models. Conditional random fields also avoid a fundamental limitation of maximum entropy Markov models (MEMMs) and other discriminative Markov models based on directed graphical models, which can be biased towards states with few successor states. We present iterative parameter estimation algorithms for conditional random fields and compare the performance of the resulting models to HMMs and MEMMs on synthetic and natural-language data.","['Conditional random field', 'Maximum-entropy Markov model', 'Graphical model', 'Conditional entropy', 'Conditional independence', 'Variable-order Markov model', 'Discriminative model', 'Computer science', 'Random field', 'Hidden Markov model', 'Probabilistic logic', 'Markov model', 'Markov chain', 'Markov random field', 'Conditional probability', 'Artificial intelligence', 'Principle of maximum entropy', 'Mathematics', 'Machine learning', 'Statistics', 'Segmentation', 'Image segmentation']","conditional random fields, probabilistic models, label, conditional random fields, hidden markov models, stochastic grammars, strong independence assumptions, conditional random fields, maximum entropy markov models, ##tive markov models, directed graphical models, iterative parameter estimation algorithms, conditional random fields"
Paper_00929,Improved methods for building protein models in electron density maps and the location of errors in these models,"['T. Alwyn Jones', 'Jin-yu Zou', 'Sandra W. Cowan', 'Morten Kjeldgaard']",1991,Acta Crystallographica Section A Foundations of Crystallography,Journal,,110-119,47,2,10.1107/s0108767390010224,"Map interpretation remains a critical step in solving the structure of a macromolecule. Errors introduced at this early stage may persist throughout crystallographic refinement and result in an incorrect structure. The normally quoted crystallographic residual is often a poor description for the quality of the model. Strategies and tools are described that help to alleviate this problem. These simplify the model-building process, quantify the goodness of fit of the model on a per-residue basis and locate possible errors in peptide and side-chain conformations.","['Residual', 'Model building', 'Basis (linear algebra)', 'Computer science', 'Interpretation (philosophy)', 'Algorithm', 'Process (computing)', 'Statistical physics', 'Biological system', 'Crystallography', 'Mathematics', 'Chemistry', 'Geometry', 'Physics', 'Biology', 'Quantum mechanics', 'Programming language', 'Operating system']","map interpretation, ##lecule, crystallographic residual, goodness of fit"
Paper_00930,The Scree Test For The Number Of Factors,['Raymond B. Cattell'],1966,Multivariate Behavioral Research,Journal,,245-276,1,2,10.1207/s15327906mbr0102_10,"(1966). The Scree Test For The Number Of Factors. Multivariate Behavioral Research: Vol. 1, No. 2, pp. 245-276.","['Test (biology)', 'Computer science', 'Psychology', 'Statistics', 'Mathematics', 'Geology', 'Paleontology']","scree test, multivariate behavioral research, [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD] [PAD], [PAD] [PAD]"
Paper_00931,The Mouse Brain in Stereotaxic Coordinates,['George Paxinos'],2001,['Psychoneuroendocrinology'],Unknown,,827-828,28,6,10.1016/s0306-4530(03)00088-x,"Mouse Brain in Stereotaxic Coordinates is the most widely used and cited atlas of the mouse brain in print. It provides researchers and students with both accurate stereotaxic coordinates for laboratory use, and detailed delineations and indexing of structures for reference. The accompanying DVD provides drawings of brains structures that can be used as templates for making figures for publication. The 3rd edition is both a major revision and an expansion of previous editions. Delineations and photographs in the horizontal plane of section now complement the coronal and sagittal series, and all the tissue sections are now shown in high resolution digital color photography. The photographs of the sections and the intermediate sections are also provided on the accompanying DVD in high-resolution JP 2000 format. The delineations of structures have been revised, and naming conventions made consistent with Paxinos and Watson's Rat Brain in Stereotaxic Coordinates, 6th Edition. The 3rd edition of this atlas is now in more practical 14x11 format for convenient lab use. This edition is in full color throughout. It includes a CD of all plates and diagrams, as well as Adobe Illustrator files of the diagrams, and a variety of additional useful material. Coronal and sagittal diagrams are completely reworked and updated. Rhombomeric borders are included in sagittal figures, for the first time in mammals. Microscopic plates are scanned with a new method in much higher quality.","['Sagittal plane', 'Brain atlas', 'Coronal plane', 'Computer science', 'Computer graphics (images)', 'Section (typography)', 'Atlas (anatomy)', 'Anatomy', 'Artificial intelligence', 'Medicine', 'Operating system']","mouse brain, stereotaxic coordinates, mouse brain, stereotaxic coordinates, brains, horizontal, sa, high, paxinos, rat brain, stereotaxic coordinates, adobe illustrator, sagittal, rhombomeric borders, sagittal figures"
Paper_00932,"PhysioBank, PhysioToolkit, and PhysioNet","['Ary L. Goldberger', 'Luı́s A. Nunes Amaral', 'Leon Glass', 'Jeffrey M. Hausdorff', 'Plamen Ch. Ivanov', 'Roger G. Mark', 'Joseph E. Mietus', 'G.B. Moody', 'Chung‐Kang Peng', 'H. Eugene Stanley']",2000,Circulation,Journal,,,101,23,10.1161/01.cir.101.23.e215,"The newly inaugurated Research Resource for Complex Physiologic Signals, which was created under the auspices of the National Center for Research Resources of the National Institutes of Health, is intended to stimulate current research and new investigations in the study of cardiovascular and other complex biomedical signals. The resource has 3 interdependent components. PhysioBank is a large and growing archive of well-characterized digital recordings of physiological signals and related data for use by the biomedical research community. It currently includes databases of multiparameter cardiopulmonary, neural, and other biomedical signals from healthy subjects and from patients with a variety of conditions with major public health implications, including life-threatening arrhythmias, congestive heart failure, sleep apnea, neurological disorders, and aging. PhysioToolkit is a library of open-source software for physiological signal processing and analysis, the detection of physiologically significant events using both classic techniques and novel methods based on statistical physics and nonlinear dynamics, the interactive display and characterization of signals, the creation of new databases, the simulation of physiological and other signals, the quantitative evaluation and comparison of analysis methods, and the analysis of nonstationary processes. PhysioNet is an on-line forum for the dissemination and exchange of recorded biomedical signals and open-source software for analyzing them. It provides facilities for the cooperative analysis of data and the evaluation of proposed new algorithms. In addition to providing free electronic access to PhysioBank data and PhysioToolkit software via the World Wide Web (http://www.physionet. org), PhysioNet offers services and training via on-line tutorials to assist users with varying levels of expertise.","['Software', 'Interdependence', 'Resource (disambiguation)', 'Data science', 'Medicine', 'Variety (cybernetics)', 'Computer science', 'Sleep apnea', 'Open data', 'Artificial intelligence', 'World Wide Web', 'Computer network', 'Political science', 'Law', 'Cardiology', 'Programming language']","complex physiologic signals, physiobank, congestive heart failure, sleep apnea, neurological disorders, physiotoolkit, statistical physics, nonlinear dynamics, nonstationary, physionet, ##iotoolkit, ##ion, physionet"
Paper_00934,The Handbook of Social Psychology,"['Arthur E. Gravatt', 'Gardner Lindzey', 'F. Aronson']",1969,The Family Coordinator,Journal,,181-181,18,2,10.2307/582242,"VOLUME 2. Part III: The Social World. 21. EVOLUTIONARY SOCIAL PSYCHOLOGY (Steven L. Neuberg, Douglas T. Kenrick, and Mark Schaller). 22. MORALITY (Jonathan Haidt and Selin Kesebir). 23. AGGRESSION (Brad J. Bushman and L. Rowell Huesmann). 24. AFFILIATION, ACCEPTANCE, AND BELONGING: THE PURSUIT OF INTERPERSONAL CONNECTION (Mark R. Leary). 25. CLOSE RELATIONSHIPS (Margaret S. Clark and Edward P. Lemay, Jr.). 26. INTERPERSONAL STRATIFICATION: STATUS, POWER, AND SUBORDINATION (Susan T. Fiske). 27. SOCIAL CONFLICT: THE EMERGENCE AND CONSEQUENCES OF STRUGGLE AND NEGOTIATION (Carsten K. W. De Dreu). 28. INTERGROUP RELATIONS 1(Vincent Yzerbyt and Stephanie Demoulin). 29. INTERGROUP BIAS (John F. Dovidio and Samuel L. Gaertner). 30. SOCIAL JUSTICE: HISTORY, THEORY, AND RESEARCH (John T. Jost and Aaron C. Kay). 31. INFLUENCE AND LEADERSHIP (Michael A. Hogg). 32. GROUP BEHAVIOR AND PERFORMANCE (J. Richard Hackman and Nancy Katz). 33. ORGANIZATIONAL PREFERENCES AND THEIR CONSEQUENCES (Deborah H. Gruenfeld and Larissa Z. Tiedens). 34. THE PSYCHOLOGICAL UNDERPINNINGS OF POLITICAL BEHAVIOR (Jon A. Krosnick, Penny S. Visser, and Joshua Harder). 35. SOCIAL PSYCHOLOGY AND LAW (Margaret Bull Kovera and Eugene Borgida). 36. SOCIAL PSYCHOLOGY AND LANGUAGE: WORDS, UTTERANCES, AND CONVERSATIONS (Thomas Holtgraves). 37. CULTURAL PSYCHOLOGY (Steven J. Heine). AUTHOR INDEX. SUBJECT INDEX.","['Psychology', 'Applied psychology', 'Psychoanalysis']","social world, evolutionary social psychology, morality, aggression, affiliation, interpersonal connection, close relationships, interpersonal stratification, subordination, social conflict, negotiation, intergroup relations, intergroup bias, social justice, influence, leadership, group behavior, performance, organizational preferences, psychological, political behavior, social psychology, law, social psychology, language, cultural psychology"
Paper_00935,The Timed “Up &amp; Go”: A Test of Basic Functional Mobility for Frail Elderly Persons,"['Diane Podsiadlo', 'Sandra Richardson']",1991,Journal of the American Geriatrics Society,Journal,,142-148,39,2,10.1111/j.1532-5415.1991.tb01616.x,"This study evaluated a modified, timed version of the ""Get-Up and Go"" Test (Mathias et al, 1986) in 60 patients referred to a Geriatric Day Hospital (mean age 79.5 years). The patient is observed and timed while he rises from an arm chair, walks 3 meters, turns, walks back, and sits down again. The results indicate that the time score is (1) reliable (inter-rater and intra-rater); (2) correlates well with log-transformed scores on the Berg Balance Scale (r = -0.81), gait speed (r = -0.61) and Barthel Index of ADL (r = -0.78); and (3) appears to predict the patient's ability to go outside alone safely. These data suggest that the timed ""Up & Go"" test is a reliable and valid test for quantifying functional mobility that may also be useful in following clinical change over time. The test is quick, requires no special equipment or training, and is easily included as part of the routine medical examination.","['Timed Up and Go test', 'Medicine', 'Berg Balance Scale', 'Barthel index', 'Test (biology)', 'Balance (ability)', 'Activities of daily living', 'Physical medicine and rehabilitation', 'Physical therapy', 'Gait', 'Preferred walking speed', 'Gerontology', 'Paleontology', 'Biology']","geriatric day hospital, berg balance scale, gait speed, functional mobility, [PAD] [PAD], [PAD]"
Paper_00936,"Knowledge of the Firm, Combinative Capabilities, and the Replication of Technology","['Bruce Kogut', 'Udo Zander']",1992,Organization Science,Journal,,383-397,3,3,10.1287/orsc.3.3.383,"How should we understand why firms exist? A prevailing view has been that they serve to keep in check the transaction costs arising from the self-interested motivations of individuals. We develop in this article the argument that what firms do better than markets is the sharing and transfer of the knowledge of individuals and groups within an organization. This knowledge consists of information (e.g., who knows what) and of know-how (e.g., how to organize a research team). What is central to our argument is that knowledge is held by individuals, but is also expressed in regularities by which members cooperate in a social community (i.e., group, organization, or network). If knowledge is only held at the individual level, then firms could change simply by employee turnover. Because we know that hiring new workers is not equivalent to changing the skills of a firm, an analysis of what firms can do must understand knowledge as embedded in the organizing principles by which people cooperate within organizations. Based on this discussion, a paradox is identified: efforts by a firm to grow by the replication of its technology enhances the potential for imitation. By considering how firms can deter imitation by innovation, we develop a more dynamic view of how firms create new knowledge. We build up this dynamic perspective by suggesting that firms learn new skills by recombining their current capabilities. Because new ways of cooperating cannot be easily acquired, growth occurs by building on the social relationships that currently exist in a firm. What a firm has done before tends to predict what it can do in the future. In this sense, the cumulative knowledge of the firm provides options to expand in new but uncertain markets in the future. We discuss at length the example of the make/buy decision and propose several testable hypotheses regarding the boundaries of the firm, without appealing to the notion of “opportunism.”","['Imitation', 'Argument (complex analysis)', 'Perspective (graphical)', 'Replication (statistics)', 'Business', 'Knowledge management', 'Transaction cost', 'Knowledge transfer', 'Database transaction', 'Knowledge sharing', 'Organizational learning', 'Industrial organization', 'Computer science', 'Psychology', 'Social psychology', 'Biochemistry', 'Chemistry', 'Statistics', 'Mathematics', 'Finance', 'Artificial intelligence', 'Programming language']","transaction costs, employee turnover, social"
Paper_00937,Convolutional Neural Networks for Sentence Classification,['Yoon Kim'],2014,Unknown,Unknown,,,,,10.3115/v1/d14-1181,"We report on a series of experiments with convolutional neural networks (CNN) trained on top of pre-trained word vectors for sentence-level classification tasks.We show that a simple CNN with little hyperparameter tuning and static vectors achieves excellent results on multiple benchmarks.Learning task-specific vectors through fine-tuning offers further gains in performance.We additionally propose a simple modification to the architecture to allow for the use of both task-specific and static vectors.The CNN models discussed herein improve upon the state of the art on 4 out of 7 tasks, which include sentiment analysis and question classification.","['Convolutional neural network', 'Computer science', 'Sentence', 'Artificial intelligence', 'Natural language processing', 'Speech recognition']","convolutional neural networks, cnn, hyperparameter tuning, static vectors, sentiment analysis, question classification, [PAD], [PAD], [PAD] [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD], [PAD] [PAD], [PAD], [PAD], [PAD] [PAD], [PAD] [PAD], [PAD] [PAD], [PAD] [PAD]"
Paper_00938,Superior Thermal Conductivity of Single-Layer Graphene,"['Alexander A. Balandin', 'Suchismita Ghosh', 'Wenzhong Bao', 'Irene Calizo', 'Desalegne Teweldebrhan', 'Feng Miao', 'Chun Ning Lau']",2008,Nano Letters,Journal,,902-907,8,3,10.1021/nl0731872,We report the measurement of the thermal conductivity of a suspended single-layer graphene. The room temperature values of the thermal conductivity in the range approximately (4.84+/-0.44)x10(3) to (5.30+/-0.48)x10(3) W/mK were extracted for a single-layer graphene from the dependence of the Raman G peak frequency on the excitation laser power and independently measured G peak temperature coefficient. The extremely high value of the thermal conductivity suggests that graphene can outperform carbon nanotubes in heat conduction. The superb thermal conduction property of graphene is beneficial for the proposed electronic applications and establishes graphene as an excellent material for thermal management.,"['Graphene', 'Thermal conductivity', 'Materials science', 'Thermal conduction', 'Raman spectroscopy', 'Carbon nanotube', 'Graphene nanoribbons', 'Excitation', 'Nanotechnology', 'Composite material', 'Optics', 'Physics', 'Quantum mechanics']","thermal conductivity, room temperature values, thermal conductivity, raman g peak frequency, excitation laser power, g peak temperature coefficient, thermal conductivity, heat conduction, superb thermal conduction property, graph, graphene, thermal management, [PAD], [PAD]"
Paper_00940,The large $N$ limit of superconformal field theories and supergravity,['Juan Maldacena'],1998,Advances in Theoretical and Mathematical Physics,Journal,,231-252,2,2,10.4310/atmp.1998.v2.n2.a1,"We show that the large N limit of certain conformal field theories in various dimensions include in their Hilbert space a sector describing supergravity on the product of Anti-deSitter spacetimes, spheres and other compact manifolds.This is shown by taking some branes in the full M/string theory and then taking a low energy limit where the field theory on the brane decouples from the bulk.We observe that, in this limit, we can still trust the near horizon geometry for large N.The enhanced supersymmetries of the near horizon geometry correspond to the extra supersymmetry generators present in the superconformal group (as opposed to just the super-Poincare group).The 't Hooft limit of 3+1 J\f = 4 super-Yang-Mills at the conformal point is shown to contain strings: they are IIB strings.We conjecture that compactifications of M/string theory on various Anti-deSitter spacetimes is dual to various conformal field theories.This leads to a new proposal for a definition of M-theory which could be extended to include five noncompact dimensions. General IdeaIn the last few years it has been extremely fruitful to derive quantum field theories by taking various limits of string or M-theory.In some cases this","['Supergravity', 'Limit (mathematics)', 'Higher-dimensional supergravity', 'Physics', 'Field (mathematics)', 'Mathematical physics', 'Quantum electrodynamics', 'Supersymmetry', 'Theoretical physics', 'Mathematics', 'Pure mathematics', 'Mathematical analysis']","large n limit, conformal field theories, hilbert, supergravity, compact manifolds, low energy limit, near horizon geometry, enhanced supersymmetries, near horizon geometry, ##symmetry generators, superconform, conformal field theories, noncompact dimensions, quantum field theories"
Paper_00941,FastTree 2 – Approximately Maximum-Likelihood Trees for Large Alignments,"['Morgan N. Price', 'Paramvir Dehal', 'Adam P. Arkin']",2010,PLoS ONE,Journal,,e9490-e9490,5,3,10.1371/journal.pone.0009490,"We recently described FastTree, a tool for inferring phylogenies for alignments with up to hundreds of thousands of sequences. Here, we describe improvements to FastTree that improve its accuracy without sacrificing scalability.Where FastTree 1 used nearest-neighbor interchanges (NNIs) and the minimum-evolution criterion to improve the tree, FastTree 2 adds minimum-evolution subtree-pruning-regrafting (SPRs) and maximum-likelihood NNIs. FastTree 2 uses heuristics to restrict the search for better trees and estimates a rate of evolution for each site (the ""CAT"" approximation). Nevertheless, for both simulated and genuine alignments, FastTree 2 is slightly more accurate than a standard implementation of maximum-likelihood NNIs (PhyML 3 with default settings). Although FastTree 2 is not quite as accurate as methods that use maximum-likelihood SPRs, most of the splits that disagree are poorly supported, and for large alignments, FastTree 2 is 100-1,000 times faster. FastTree 2 inferred a topology and likelihood-based local support values for 237,882 distinct 16S ribosomal RNAs on a desktop computer in 22 hours and 5.8 gigabytes of memory.FastTree 2 allows the inference of maximum-likelihood phylogenies for huge alignments. FastTree 2 is freely available at http://www.microbesonline.org/fasttree.","['Computer science', 'Heuristics', 'Scalability', 'Maximum likelihood', 'Inference', 'Pruning', 'Tree (set theory)', 'Statistics', 'Algorithm', 'Data mining', 'Biology', 'Mathematics', 'Artificial intelligence', 'Combinatorics', 'Database', 'Agronomy', 'Operating system']","fasttree, phylogenies, ##s, fasttree, fast, fast, fasttree, heuristics, fasttree, ph, ##l, fasttree, fasttree, fasttree, ribosomal rna, fasttree, fasttree, ##bes"
Paper_00942,Indexing by latent semantic analysis,"['Scott Deerwester', 'Susan Dumais', 'George W. Furnas', 'Thomas K. Landauer', 'Richard A. Harshman']",1990,Journal of the American Society for Information Science,Journal,,391-407,41,6,10.1002/(sici)1097-4571(199009)41:6<391::aid-asi1>3.0.co;2-9,"A new method for automatic indexing and retrieval is described. The approach is to take advantage of implicit higher-order structure in the association of terms with documents (""semantic structure"") in order to improve the detection of relevant documents on the basis of terms found in queries. The particular technique used is singular-value decomposition, in which a large term by document matrix is decomposed into a set of ca. 100 orthogonal factors from which the original matrix can be approximated by linear combination. Documents are represented by ca. 100 item vectors of factor weights. Queries are represented as pseudo-document vectors formed from weighted combinations of terms, and documents with supra-threshold cosine values are returned. Initial tests find this completely automatic method for retrieval to be promising. © 1990 John Wiley & Sons, Inc.","['Singular value decomposition', 'Latent semantic analysis', 'Computer science', 'Search engine indexing', 'Information retrieval', 'Set (abstract data type)', 'Basis (linear algebra)', 'Cosine similarity', 'Vector space model', 'Term (time)', 'Matrix (chemical analysis)', 'Data mining', 'Algorithm', 'Pattern recognition (psychology)', 'Mathematics', 'Artificial intelligence', 'Physics', 'Geometry', 'Materials science', 'Quantum mechanics', 'Composite material', 'Programming language']","automatic indexing, retrieval, semantic structure, orthogonal factors, linear, item vectors, factor weights"
Paper_00943,How to share a secret,['Adi Shamir'],1979,Communications of the ACM,Journal,,612-613,22,11,10.1145/359168.359176,"In this paper we show how to divide data D into n pieces in such a way that D is easily reconstructable from any k pieces, but even complete knowledge of k - 1 pieces reveals absolutely no information about D . This technique enables the construction of robust key management schemes for cryptographic systems that can function securely and reliably even when misfortunes destroy half the pieces and security breaches expose all but one of the remaining pieces.","['Computer science', 'Computer security', 'Key (lock)', 'Cryptography', 'Function (biology)', 'Theoretical computer science', 'Biology', 'Evolutionary biology']","robust key management schemes, cryptographic systems, security breaches, [PAD], [PAD], [PAD], [PAD] [PAD] [PAD], [PAD], [PAD], [PAD], [PAD] [PAD], [PAD]"
Paper_00945,Credit Rationing in Markets with Imperfect Information.,"['Joseph E. Stiglitz', 'Andrew Weiss']",1981,American Economic Review,Journal,,393-410,71,3,10.7916/d8v12ft1,"According to basic economics, if demand exceeds supply, prices will rise, thus decreasing demand or increasing supply until demand and supply are in equilibrium; thus if prices do their job, rationing will not exist. However, credit rationing does exist. This paper demonstrates that even in equilibrium, credit rationing will exist in a loan market. Credit rationing is defined as occurring either (a) among loan applicants who appear identical, and some do and do not receive loans, even though the rejected applicants would pay higher interest rates; or (b) there are groups who, with a given credit supply, cannot obtain loans at any rate, even though with larger credit supply they would. A model is developed to provide the first theoretical justification for true credit rationing. The amount of the loan and the amount of collateral demanded affect the behavior and distribution of borrowers. Consequently, faced with increased credit demand, it may not be profitable to raise interest rates or collateral; instead banks deny loans to borrowers who are observationally indistinguishable from those receiving loans. It is not argued that credit rationing always occurs, but that it occurs under plausible assumptions about lender and borrower behavior. In the model, interest rates serve as screening devices for evaluating risk. Interest rates change the behavior (serve as incentive mechanism) for the borrower, increasing the relative attractiveness of riskier projects; banks ration credit, rather than increase rates when there is excess demand. Banks are shown not to increase collateral as a means of allocating credit; although collateral may have incentivizing effects, it may have adverse selection effects. Equity, nonlinear payment schedules, and contingency contracts may be introduced and yet there still may be rationing. The law of supply and demand is thus a result generated by specific assumptions and is model specific; credit rationing does exist. (TNM)","['Credit rationing', 'Collateral', 'Economics', 'Loan', 'Rationing', 'Credit crunch', 'Interest rate', 'Monetary economics', 'Incentive', 'Installment credit', 'Microeconomics', 'Supply and demand', 'Credit reference', 'Credit risk', 'Credit enhancement', 'Finance', 'Health care', 'Economic growth']","##ning, credit rationing, credit rationing, loan market, credit rationing, credit rationing, credit demand, credit rationing, interest rates, interest rates, equity, nonlinear payment schedules, contingency contracts, credit rationing"
Paper_00946,FLASH: fast length adjustment of short reads to improve genome assemblies,"['Tanja Magoč', 'Steven L. Salzberg']",2011,Bioinformatics,Journal,,2957-2963,27,21,10.1093/bioinformatics/btr507,"Abstract Motivation: Next-generation sequencing technologies generate very large numbers of short reads. Even with very deep genome coverage, short read lengths cause problems in de novo assemblies. The use of paired-end libraries with a fragment size shorter than twice the read length provides an opportunity to generate much longer reads by overlapping and merging read pairs before assembling a genome. Results: We present FLASH, a fast computational tool to extend the length of short reads by overlapping paired-end reads from fragment libraries that are sufficiently short. We tested the correctness of the tool on one million simulated read pairs, and we then applied it as a pre-processor for genome assemblies of Illumina reads from the bacterium Staphylococcus aureus and human chromosome 14. FLASH correctly extended and merged reads &amp;gt;99% of the time on simulated reads with an error rate of &amp;lt;1%. With adequately set parameters, FLASH correctly merged reads over 90% of the time even when the reads contained up to 5% errors. When FLASH was used to extend reads prior to assembly, the resulting assemblies had substantially greater N50 lengths for both contigs and scaffolds. Availability and Implementation: The FLASH system is implemented in C and is freely available as open-source code at http://www.cbcb.umd.edu/software/flash. Contact: t.magoc@gmail.com","['Computer science', 'Contig', 'Flash (photography)', 'Genome', 'Software', 'Sequence assembly', 'k-mer', 'Hybrid genome assembly', 'Correctness', 'Computational biology', 'Algorithm', 'Biology', 'Genetics', 'Operating system', 'Art', 'Gene expression', 'Transcriptome', 'Gene', 'Visual arts']","novo assemblies, flash, fragment, illumina reads, flash"
Paper_00948,ROBINS-I: a tool for assessing risk of bias in non-randomised studies of interventions,"['Jonathan A C Sterne', 'Miguel A. Hernán', 'Barnaby C Reeves', 'Jelena Savović', 'Nancy D Berkman', 'Meera Viswanathan', 'David Henry', 'Douglas G. Altman', 'Mohammed Ansari', 'Isabelle Boutron', 'James R. Carpenter', 'An‐Wen Chan', 'Rachel Churchill', 'Jonathan J Deeks', 'Asbjørn Hróbjartsson', 'Jamie J Kirkham', 'Peter Jüni', 'Yoon K. Loke', 'Theresa D Pigott', 'Craig Ramsay', 'Deborah L. Regidor', 'Hannah R. Rothstein', 'Lakhbir Sandhu', 'Pasqualina Santaguida', 'Holger J. Schünemann', 'Beverly Shea', 'Ian Shrier', 'Peter Tugwell', 'Lucy Turner', 'Jeffrey C. Valentine', 'Hugh Waddington', 'Elizabeth Waters', 'George A. Wells', 'Penny Whiting', 'Julian P. T. Higgins']",2016,BMJ,Journal,,i4919-i4919,,,10.1136/bmj.i4919,"Non-randomised studies of the effects of interventions are critical to many areas of healthcare evaluation, but their results may be biased. It is therefore important to understand and appraise their strengths and weaknesses. We developed ROBINS-I (""Risk Of Bias In Non-randomised Studies - of Interventions""), a new tool for evaluating risk of bias in estimates of the comparative effectiveness (harm or benefit) of interventions from studies that did not use randomisation to allocate units (individuals or clusters of individuals) to comparison groups. The tool will be particularly useful to those undertaking systematic reviews that include non-randomised studies.","['Psychological intervention', 'Medicine', 'Systematic review', 'Strengths and weaknesses', 'Harm', 'Meta-analysis', 'MEDLINE', 'Alternative medicine', 'Psychology', 'Psychiatry', 'Pathology', 'Social psychology', 'Political science', 'Law']","non - randomised studies, interventions, healthcare evaluation, systematic reviews, random"
Paper_00949,CONSORT 2010 Statement: updated guidelines for reporting parallel group randomised trials,"['Kenneth F. Schulz', 'Douglas G. Altman', 'David Moher']",2010,BMC Medicine,Journal,,,8,1,10.1186/1741-7015-8-18,"The CONSORT statement is used worldwide to improve the reporting of randomised controlled trials. Kenneth Schulz and colleagues describe the latest version, CONSORT 2010, which updates the reporting guideline based on new methodological evidence and accumulating experience. To encourage dissemination of the CONSORT 2010 Statement, this article is freely accessible on bmj.com and will also be published in the Lancet, Obstetrics and Gynecology, PLoS Medicine, Annals of Internal Medicine, Open Medicine, Journal of Clinical Epidemiology, BMC Medicine, and Trials.","['Consolidated Standards of Reporting Trials', 'Medicine', 'Alternative medicine', 'Family medicine', 'Guideline', 'Statement (logic)', 'Randomized controlled trial', 'Obstetrics and gynaecology', 'Evidence-based medicine', 'MEDLINE', 'Clinical trial', 'Internal medicine', 'Pregnancy', 'Pathology', 'Biology', 'Political science', 'Law', 'Genetics']","consort statement, randomised controlled trials, consort, consort, obste, ##yne, plos medicine, internal medicine, open medicine, clinical epidemiology, bmc medicine, [PAD] [PAD] [PAD] [PAD]"
Paper_00950,Teleporting an unknown quantum state via dual classical and Einstein-Podolsky-Rosen channels,"['Charles H. Bennett', 'Gilles Brassard', 'Claude Crépeau', 'Richard Jozsa', 'Asher Peres', 'William K. Wootters']",1993,Physical Review Letters,Journal,,1895-1899,70,13,10.1103/physrevlett.70.1895,"An unknown quantum state \ensuremath{\Vert}\ensuremath{\varphi}〉 can be disassembled into, then later reconstructed from, purely classical information and purely nonclassical Einstein-Podolsky-Rosen (EPR) correlations. To do so the sender, ``Alice,'' and the receiver, ``Bob,'' must prearrange the sharing of an EPR-correlated pair of particles. Alice makes a joint measurement on her EPR particle and the unknown quantum system, and sends Bob the classical result of this measurement. Knowing this, Bob can convert the state of his EPR particle into an exact replica of the unknown state \ensuremath{\Vert}\ensuremath{\varphi}〉 which Alice destroyed.","['Physics', 'EPR paradox', 'Quantum mechanics', 'Alice (programming language)', 'State (computer science)', 'Quantum', 'Alice and Bob', 'Electron paramagnetic resonance', 'Mathematical physics', 'Quantum entanglement', 'Mathematics', 'Computer science', 'Algorithm', 'Programming language']",unknown quantum state
Paper_00952,ANNOVAR: functional annotation of genetic variants from high-throughput sequencing data,"['Kai Wang', 'Man Li', 'Hákon Hákonarson']",2010,Nucleic Acids Research,Journal,,e164-e164,38,16,10.1093/nar/gkq603,"High-throughput sequencing platforms are generating massive amounts of genetic variation data for diverse genomes, but it remains a challenge to pinpoint a small subset of functionally important variants. To fill these unmet needs, we developed the ANNOVAR tool to annotate single nucleotide variants (SNVs) and insertions/deletions, such as examining their functional consequence on genes, inferring cytogenetic bands, reporting functional importance scores, finding variants in conserved regions, or identifying variants reported in the 1000 Genomes Project and dbSNP. ANNOVAR can utilize annotation databases from the UCSC Genome Browser or any annotation data set conforming to Generic Feature Format version 3 (GFF3). We also illustrate a 'variants reduction' protocol on 4.7 million SNVs and indels from a human genome, including two causal mutations for Miller syndrome, a rare recessive disease. Through a stepwise procedure, we excluded variants that are unlikely to be causal, and identified 20 candidate genes including the causal gene. Using a desktop computer, ANNOVAR requires ∼4 min to perform gene-based annotation and ∼15 min to perform variants reduction on 4.7 million variants, making it practical to handle hundreds of human genomes in a day. ANNOVAR is freely available at http://www.openbioinformatics.org/annovar/.","['dbSNP', 'Biology', '1000 Genomes Project', 'Annotation', 'Genome', 'Indel', 'Genome browser', 'Genetics', 'Human genome', 'Computational biology', 'DNA sequencing', 'Genomics', 'Genome project', 'Gene', 'Reference genome', 'Single-nucleotide polymorphism', 'Genotype']","genetic variation, diverse genomes, annovar, single nucleotide variants, ##togenetic bands, functional importance scores, 1000 genomes, dbs, ann, ##tion databases, ucsc genome browser, variants reduction, human, causal mutations, miller syndrome, rare recessive disease, annova, ##ovar"
Paper_00953,Leadership and Performance beyond Expectations,"['John M. Longshore', 'Bernard M. Bass']",1987,Academy of Management Review,Journal,,756-756,12,4,10.2307/258081,"The article reviews the book Leadership and Performance Beyond Expectations, by Bernard M. Bass.","['Management', 'Sociology', 'Psychology', 'Business', 'Political science', 'Public relations', 'Economics']","leadership, performance, [PAD], [PAD], [PAD], [PAD]"
Paper_00955,"IntCal13 and Marine13 Radiocarbon Age Calibration Curves 0–50,000 Years cal BP","['Paula Reimer', 'Édouard Bard', 'Alex Bayliss', 'J Beck', 'Paul G. Blackwell', 'Christopher Bronk Ramsey', 'Caitlin E. Buck', 'Hai Cheng', 'R. Lawrence Edwards', 'Michael Friedrich', 'Pieter Meiert Grootes', 'T. P. Guilderson', 'Haflidi Haflidason', 'Irka Hajdas', 'Christine Hatté', 'Timothy Heaton', 'Dirk L. Hoffmann', 'Alan Hogg', 'Konrad A Hughen', 'Klaus Félix Kaiser', 'Bernd Kromer', 'Sturt W. Manning', 'Mu Niu', 'Ron Reimer', 'David A. Richards', 'E. M. Scott', 'John Southon', 'Richard A. Staff', 'Chris Turney', 'J. van der Plicht']",2013,Radiocarbon,Journal,,1869-1887,55,4,10.2458/azu_js_rc.55.16947,"The IntCal09 and Marine09 radiocarbon calibration curves have been revised utilizing newly available and updated data sets from 14 C measurements on tree rings, plant macrofossils, speleothems, corals, and foraminifera. The calibration curves were derived from the data using the random walk model (RWM) used to generate IntCal09 and Marine09, which has been revised to account for additional uncertainties and error structures. The new curves were ratified at the 21st International Radiocarbon conference in July 2012 and are available as Supplemental Material at www.radiocarbon.org. The database can be accessed at http://intcal.qub.ac.uk/intcal13/.","['Radiocarbon dating', 'Macrofossil', 'Geology', 'Calibration', 'Calibration curve', 'Archaeology', 'Physical geography', 'Absolute dating', 'Paleontology', 'Geography', 'Statistics', 'Holocene', 'Mathematics', 'Detection limit']","##cal, marine, radiocarbon calibration curves, tree rings, plant macrofossils, speleothems, corals, foraminifera, cal, ##ration curves, random walk model, ##cal, marine, error structures, radiocarbon conference, ##carbon"
Paper_00958,"How people learn: Brain, mind, experience, and school.","['John D. Bransford', 'Ann L. Brown', 'Rodney R. Cocking']",1999,['PsycEXTRA Dataset'],Unknown,,,,,10.1037/e510822010-008,"New developments in the science of learning science of learning overview mind and brain how experts differ from novices how children learn learning and transfer the learning environment curriculum, instruction and commnity effective teaching - examples in history, mathematics and science teacher learning technology to support learning conclusions from new developments in the science of learning.","['Science learning', 'Learning sciences', 'Mathematics education', 'Curriculum', 'Experiential learning', 'Psychology', 'Active learning (machine learning)', 'Pedagogy', 'Cognitive science', 'Computer science', 'Science education', 'Artificial intelligence']","learning, comm, science"
Paper_00959,Tissue-based map of the human proteome,"['Mathias Uhlén', 'Linn Fagerberg', 'Björn M. Hallström', 'Cecilia Lindskog', 'Per Oksvold', 'Adil Mardinoğlu', 'Åsa Sivertsson', 'Caroline Kampf', 'Evelina Sjöstedt', 'Anna Asplund', 'Ing‐Marie Olsson', 'Karolina Edlund', 'Emma Lundberg', 'Sanjay Navani', 'Cristina Al‐Khalili Szigyarto', 'Jacob Odeberg', 'Dijana Djureinovic', 'Jenny Ottosson Takanen', 'Sophia Hober', 'Tove Alm', 'Per-Henrik Edqvist', 'Holger Berling', 'Hanna Tegel', 'Jan Mulder', 'Johan Rockberg', 'Peter Nilsson', 'Jochen M. Schwenk', 'Marica Hamsten', 'Kalle von Feilitzen', 'Mattias Forsberg', 'Lukas Persson', 'Fredric Johansson', 'Martin Zwahlen', 'Gunnar von Heijne', 'Jens Nielsen', 'Fredrik Pontén']",2015,Science,Journal,,,347,6220,10.1126/science.1260419,"Resolving the molecular details of proteome variation in the different tissues and organs of the human body will greatly increase our knowledge of human biology and disease. Here, we present a map of the human tissue proteome based on an integrated omics approach that involves quantitative transcriptomics at the tissue and organ level, combined with tissue microarray–based immunohistochemistry, to achieve spatial localization of proteins down to the single-cell level. Our tissue-based analysis detected more than 90% of the putative protein-coding genes. We used this approach to explore the human secretome, the membrane proteome, the druggable proteome, the cancer proteome, and the metabolic functions in 32 different tissues and organs. All the data are integrated in an interactive Web-based database that allows exploration of individual proteins, as well as navigation of global expression patterns, in all major tissues and organs in the human body.","['Computational biology', 'Proteome', 'Human proteome project', 'Computer science', 'Biology', 'Proteomics', 'Bioinformatics', 'Biochemistry', 'Gene']","proteome variation, human, human biology, human tissue proteome, integrated omics, quantitative transcriptomics, tissue microarray, spatial, human secretome, membrane proteome, drug, ##ble proteome, cancer proteome, metabolic, global"
Paper_00963,Social Cognitive Theory: An Agentic Perspective,['Albert Bandura'],2001,Annual Review of Psychology,Journal,,1-26,52,1,10.1146/annurev.psych.52.1.1,"▪ Abstract The capacity to exercise control over the nature and quality of one's life is the essence of humanness. Human agency is characterized by a number of core features that operate through phenomenal and functional consciousness. These include the temporal extension of agency through intentionality and forethought, self-regulation by self-reactive influence, and self-reflectiveness about one's capabilities, quality of functioning, and the meaning and purpose of one's life pursuits. Personal agency operates within a broad network of sociostructural influences. In these agentic transactions, people are producers as well as products of social systems. Social cognitive theory distinguishes among three modes of agency: direct personal agency, proxy agency that relies on others to act on one's behest to secure desired outcomes, and collective agency exercised through socially coordinative and interdependent effort. Growing transnational embeddedness and interdependence are placing a premium on collective efficacy to exercise control over personal destinies and national life.","['Sense of agency', 'Agency (philosophy)', 'Embeddedness', 'Social psychology', 'Psychology', 'Interdependence', 'Cognition', 'Consciousness', 'Self', 'Control (management)', 'Sociology', 'Economics', 'Management', 'Social science', 'Neuroscience']","human, human agency, functional consciousness, temporal extension, intentionality, forethought, personal agency, sociostructural influences, social cognitive theory, direct personal agency, proxy agency, collective agency, ##pendent effort, transnational embeddedness, ##dence, collective efficacy, national life"
Paper_00966,AFLP: a new technique for DNA fingerprinting,"['Pieter Vos', 'René C. J. Hogers', 'Marjo Bleeker', 'Martin Reijans', 'Theo van de Lee', 'Miranda Hornes', 'Adrie Friters', 'Jerina Pot', 'Johan Paleman', 'Martin Kuiper', 'Marc Zabeau']",1995,Nucleic Acids Research,Journal,,4407-4414,23,21,10.1093/nar/23.21.4407,"A novel DNA fingerprinting technique called AFLP is described. The AFLP technique is based on the selective PCR amplification of restriction fragments from a total digest of genomic DNA. The technique involves three steps: (i) restriction of the DNA and ligation of oligonucleotide adapters, (ii) selective amplification of sets of restriction fragments, and (iii) gel analysis of the amplified fragments. PCR amplification of restriction fragments is achieved by using the adapter and restriction site sequence as target sites for primer annealing. The selective amplification is achieved by the use of primers that extend into the restriction fragments, amplifying only those fragments in which the primer extensions match the nucleotides flanking the restriction sites. Using this method, sets of restriction fragments may be visualized by PCR without knowledge of nucleotide sequence. The method allows the specific co-amplification of high numbers of restriction fragments. The number of fragments that can be analyzed simultaneously, however, is dependent on the resolution of the detection system. Typically 50—100 restriction fragments are amplified and detected on denaturing polyacrylamide gels. The AFLP technique provides a novel and very powerful DNA fingerprinting technique for DNAs of any origin or complexity.","['Amplified fragment length polymorphism', 'Biology', 'Restriction fragment', 'Restriction site', 'Restriction enzyme', 'Genetics', 'DNA', 'Primer (cosmetics)', 'Restriction digest', 'Molecular biology', 'Terminal restriction fragment length polymorphism', 'Adapter (computing)', 'DNA profiling', 'Restriction fragment length polymorphism', 'Sticky and blunt ends', 'Restriction map', 'EcoRI', 'Polymerase chain reaction', 'Nucleic acid sequence', 'Gene', 'Chemistry', 'Population', 'Demography', 'Electrical engineering', 'Organic chemistry', 'Sociology', 'Genetic diversity', 'Engineering']","dna fingerprinting technique, aflp, aflp, selective pcr amplification, restriction fragments, gen, oligonucleotide adapters, gel analysis, ##r, restriction, restriction, primer annealing, selective, aflp, dna fingerprinting"
Paper_00967,Phenomenological research methods,['Clark E. Moustakas'],1994,Unknown,Unknown,,,,,10.4135/9781412995658,"Human Science Perspectives and Models Transcendental Phenomenology Conceptual Framework Phenomenology and Human Science Inquiry Intentionality, Noema and Noesis Epoche, Phenomenological Reduction, Imaginative Variation and Synthesis Methods and Procedures for Conducting Human Science Research Phenomenological Research Analyses and Examples Summary, Implications and Outcomes A Phenomenological Analysis","['Computer science', 'Psychology', 'Epistemology', 'Philosophy']","human science, transcendental phenomenology, phenomenology, human science inquiry intentionality, noema, noesis, phenomenological reduction, imaginative variation, synthesis, human science, phenomenological research, phenomenological analysis, [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD] [PAD], [PAD], [PAD] [PAD], [PAD], [PAD] [PAD] [PAD] [PAD], [PAD], [PAD] [PAD] [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD] [PAD], [PAD], [PAD], [PAD], [PAD]"
Paper_00971,Superoxide Dismutase,"['Joe M. McCord', 'Irwin Fridovich']",1969,Journal of Biological Chemistry,Journal,,6049-6055,244,22,10.1016/s0021-9258(18)63504-5,"An enzyme which catalyzes the dismutation of superoxide radicals (O2·- + O2·- + 2H+ → O2 + H2O2) has been purified by a simple procedure from bovine erythrocytes. This enzyme, called superoxide dismutase, contains 2 eq of copper per mole of enzyme. The copper may be reversibly removed, and it is required for activity. Superoxide dismutase has been shown to be identical with the previously described copper-containing erythrocuprein (human) and hemocuprein (bovine). Stable solutions of the superoxide radical were generated by the electrolytic reduction of O2 in an aprotic solvent, dimethylformamide. Slow infusion of such solutions into buffered aqueous media permitted the demonstration that O2·- can reduce ferricytochrome c and tetranitromethane, and that superoxide dismutase, by competing for the superoxide radicals, can markedly inhibit these reactions. Superoxide dismutase was used to show that the oxidation of epinephrine to adrenochrome by milk xanthine oxidase is mediated by the superoxide radical. An assay of several tissues indicates that superoxide dismutase is widely distributed within mammalian organisms.","['Superoxide dismutase', 'Chemistry', 'Biochemistry', 'Enzyme']","superoxide radicals, bovine erythrocytes, superoxide dismuta, superoxide dismuta, super, ##tic reduction, dime, ##lforma, superoxide dismutase, super, superoxide dismuta, milk xanthine oxidase, superoxide, superoxide di"
Paper_00972,The Tacit Dimension,['Michael Polanyi'],1966,['Knowledge in Organisations'],Unknown,,135-146,,,10.1016/b978-0-7506-9718-7.50010-x,"'I shall reconsider human knowledge by starting from the fact that we can know more than we can tell', writes Michael Polanyi, whose work paved the way for the likes of Thomas Kuhn and Karl Popper. The Tacit Dimension, originally published in 1967, argues that such tacit knowledge - tradition, inherited practices, implied values, and prejudgments - is a crucial part of scientific knowledge. Back in print for a new generation of students and scholars, this volume challenges the assumption that skepticism, rather than established belief, lies at the heart of scientific discovery.","['Skepticism', 'Tacit knowledge', 'Dimension (graph theory)', 'Epistemology', 'Explicit knowledge', 'Sociology', 'Philosophy', 'Mathematics', 'Pure mathematics']","human knowledge, tacit dimension, ##cit knowledge, inherited practices, implied values, prejudgments, scientific knowledge, scientific discovery, [PAD] [PAD], [PAD], [PAD] [PAD] [PAD] [PAD] [PAD], [PAD], [PAD] [PAD], [PAD] [PAD], [PAD], [PAD] [PAD]"
Paper_00973,Studies in Ethnomethodology.,"['Anthony F. C. Wallace', 'Harold Garfinkel']",1968,American Sociological Review,Journal,,124-124,33,1,10.2307/2092245,1. What is Ethnomethodology?. 2. Studies of the Routine Grounds of Everyday Activities. 3. Common Sense Knowledge of Social Structures: The Documentary Method of Interpretation in Lay and Professional Fact Finding. 4. Some Rules of Correct Decisions that Jurors Respect. 5. Passing and the Managed Achievement of Sex Status in the Intersexed Person. 6. Good Organizational Reasons for a Bada Clinic Records. 7. Methodological Adequacy in the Quantitative Study of Selection Criteria and Selection Practices in Psychiatric Outpatient Clinics. 8. The Rational Properties of Scientific and Common Sense Activities. Appendix.,"['Ethnomethodology', 'Sociology', 'Psychology', 'Anthropology']","ethnomethod, routine grounds, everyday activities, common sense knowledge, social structures, documentary method, professional fact finding, managed achievement, sex status, intersexed person, bada, methodological adequacy, quantitative study, selection criteria, selection practices, psychiatric outpatient clinics, rational properties, common sense activities, [PAD] [PAD] [PAD], [PAD] [PAD], [PAD], [PAD], [PAD] [PAD], [PAD], [PAD], [PAD] [PAD], [PAD] [PAD], [PAD], [PAD] [PAD] [PAD] [PAD], [PAD], [PAD] [PAD], [PAD] [PAD] [PAD], [PAD], [PAD] [PAD] [PAD], [PAD], [PAD] [PAD], [PAD], [PAD] [PAD], [PAD]"
Paper_00975,Reassembling the Social,['Bruno Latour'],2005,Oxford University Press eBooks,Unknown,,,,,10.1093/oso/9780199256044.001.0001,"Abstract Reassembling the Social is a fundamental challenge from one of the world’s leading social theorists to how we understand society and the ‘social ‘. Bruno Latour’s contention is that the word ‘social’, as used by Social Scientists, has become laden with assumptions to the point where it has become misnomer. When the adjective is applied to a phenomenon, it is used to indicate a stablilized state of affairs, a bundle of ties that in due course may be used to account for another phenomenon. But Latour also finds the word used as if it described a type of material, in a comparable way to an adjective such as ‘wooden’ or ‘steely ‘. Rather than simply indicating what is already assembled together, it is now used in a way that makes assumptions about the nature of what is assembled. It has become a word that designates two distinct things: a process of assembling; and a type of material, distinct from others. Latour shows why ‘the social’ cannot be thought of as a kind of material or domain, and disputes attempts to provide a ‘social explanations’ of other states of affairs. While these attempts have been productive (and probably necessary) in the past, the very success of the social sciences mean that they are largely no longer so. At the present stage it is no longer possible to inspect the precise constituents entering the social domain. Latour returns to the original meaning of ‘the social’ to redefine the notion, and allow it to trace connections again. It will then be possible to resume the traditional goal of the social sciences, but using more refined tools. Drawing on his extensive work examining the ‘assemblages’ of nature, Latour finds it necessary to scrutinize thoroughly the exact content of what is assembled under the umbrella of Society. This approach, a ‘sociology of associations’, has become known as Actor-Network-Theory, and this book is an essential introduction both for those seeking to understand Actor-Network Theory, or the ideas of one of its most influential proponents.","['Misnomer', 'Adjective', 'Phenomenon', 'Meaning (existential)', 'Epistemology', 'TRACE (psycholinguistics)', 'Sociology', 'Social phenomenon', 'Aesthetics', 'Linguistics', 'Social science', 'Philosophy', 'Noun', 'Theology']","social theorists, social, social scientists, social explanations, associations"
Paper_00976,Situated Cognition and the Culture of Learning,"['John Seely Brown', 'Allan Collins', 'Paul Duguid']",1989,Educational Researcher,Journal,,32-42,18,1,10.3102/0013189x018001032,"Many teaching practices implicitly assume that conceptual knowledge can be abstracted from the situations in which it is learned and used. This article argues that this assumption inevitably limits the effectiveness of such practices. Drawing on recent research into cognition as it is manifest in everyday activity, the authors argue that knowledge is situated, being in part a product of the activity, context, and culture in which it is developed and used. They discuss how this view of knowledge affects our understanding of learning, and they note that conventional schooling too often ignores the influence of school culture on what is learned in school. As an alternative to conventional practices, they propose cognitive apprenticeship (Collins, Brown, &amp; Newman, in press), which honors the situated nature of knowledge. They examine two examples of mathematics instruction that exhibit certain key features of this approach to teaching.","['Situated', 'Situated cognition', 'Cognitive apprenticeship', 'Situated learning', 'Context (archaeology)', 'Cognition', 'Apprenticeship', 'Product (mathematics)', 'Epistemology', 'Sociology', 'Mathematics education', 'Context effect', 'Psychology', 'Pedagogy', 'Cognitive science', 'Computer science', 'Artificial intelligence', 'Mathematics', 'Paleontology', 'Linguistics', 'Philosophy', 'Geometry', 'Neuroscience', 'Word (group theory)', 'Biology']","teaching practices, conceptual knowledge, cognition, everyday activity, conventional schooling, school culture, cognitive apprenticeship, mathematics instruction"
Paper_00977,APACHE II-A Severity of Disease Classification System,"['William A. Knaus', 'Elizabeth A. Draper', 'Douglas P. Wagner', 'Jack E. Zimmerman']",1986,Critical Care Medicine,Journal,,755-755,14,8,10.1097/00003246-198608000-00028,"Knaus, William A. MD; Draper, Elizabeth A. RN, MS; Wagner, Douglas P. PhD; Zimmerman, Jack E. MD Author Information","['Medicine', 'APACHE II', 'Intensive care medicine', 'Intensive care unit']",
Paper_00978,"Seventh Report of the Joint National Committee on Prevention, Detection, Evaluation, and Treatment of High Blood Pressure","['Aram V. Chobanian', 'George L. Bakris', 'Henry R. Black', 'William C. Cushman', 'Lee A. Green', 'Joseph L. Izzo', 'Daniel W. Jones', 'Barry J. Materson', 'Suzanne Oparil', 'Jackson T. Wright', 'Edward J. Roccella']",2003,Hypertension,Journal,,1206-1252,42,6,10.1161/01.hyp.0000107251.49515.c2,"The National High Blood Pressure Education Program presents the complete Seventh Report of the Joint National Committee on Prevention, Detection, Evaluation, and Treatment of High Blood Pressure. Like its predecessors, the purpose is to provide an evidence-based approach to the prevention and management of hypertension. The key messages of this report are these: in those older than age 50, systolic blood pressure (BP) of greater than 140 mm Hg is a more important cardiovascular disease (CVD) risk factor than diastolic BP; beginning at 115/75 mm Hg, CVD risk doubles for each increment of 20/10 mm Hg; those who are normotensive at 55 years of age will have a 90% lifetime risk of developing hypertension; prehypertensive individuals (systolic BP 120–139 mm Hg or diastolic BP 80–89 mm Hg) require health-promoting lifestyle modifications to prevent the progressive rise in blood pressure and CVD; for uncomplicated hypertension, thiazide diuretic should be used in drug treatment for most, either alone or combined with drugs from other classes; this report delineates specific high-risk conditions that are compelling indications for the use of other antihypertensive drug classes (angiotensin-converting enzyme inhibitors, angiotensin-receptor blockers, beta-blockers, calcium channel blockers); two or more antihypertensive medications will be required to achieve goal BP (&lt;140/90 mm Hg, or &lt;130/80 mm Hg) for patients with diabetes and chronic kidney disease; for patients whose BP is more than 20 mm Hg above the systolic BP goal or more than 10 mm Hg above the diastolic BP goal, initiation of therapy using two agents, one of which usually will be a thiazide diuretic, should be considered; regardless of therapy or care, hypertension will be controlled only if patients are motivated to stay on their treatment plan. Positive experiences, trust in the clinician, and empathy improve patient motivation and satisfaction. This report serves as a guide, and the committee continues to recognize that the responsible physician’s judgment remains paramount.","['Blood pressure', 'Medicine', 'Prehypertension', 'Internal medicine', 'Thiazide', 'Diastole', 'Diabetes mellitus', 'Diuretic', 'Kidney disease', 'Antihypertensive drug', 'Cardiology', 'Risk factor', 'Endocrinology']","high blood pressure education program, high blood pressure, systolic blood pressure, prehypertensive individuals, sy, ##plicated, thiazide di, chronic kidney disease, thiazide di, empathy"
Paper_00980,"Cancer Statistics, 2010","['Ahmedin Jemal', 'Rebecca L. Siegel', 'Jiaquan Xu', 'Elizabeth Ward']",2010,CA A Cancer Journal for Clinicians,Journal,,277-300,60,5,10.3322/caac.20073,"Each year, the American Cancer Society estimates the number of new cancer cases and deaths expected in the United States in the current year and compiles the most recent data regarding cancer incidence, mortality, and survival based on incidence data from the National Cancer Institute, the Centers for Disease Control and Prevention, and the North American Association of Central Cancer Registries and mortality data from the National Center for Health Statistics. Incidence and death rates are age-standardized to the 2000 US standard million population. A total of 1,529,560 new cancer cases and 569,490 deaths from cancer are projected to occur in the United States in 2010. Overall cancer incidence rates decreased in the most recent time period in both men (1.3% per year from 2000 to 2006) and women (0.5% per year from 1998 to 2006), largely due to decreases in the 3 major cancer sites in men (lung, prostate, and colon and rectum [colorectum]) and 2 major cancer sites in women (breast and colorectum). This decrease occurred in all racial/ethnic groups in both men and women with the exception of American Indian/Alaska Native women, in whom rates were stable. Among men, death rates for all races combined decreased by 21.0% between 1990 and 2006, with decreases in lung, prostate, and colorectal cancer rates accounting for nearly 80% of the total decrease. Among women, overall cancer death rates between 1991 and 2006 decreased by 12.3%, with decreases in breast and colorectal cancer rates accounting for 60% of the total decrease. The reduction in the overall cancer death rates translates to the avoidance of approximately 767,000 deaths from cancer over the 16-year period. This report also examines cancer incidence, mortality, and survival by site, sex, race/ethnicity, geographic area, and calendar year. Although progress has been made in reducing incidence and mortality rates and improving survival, cancer still accounts for more deaths than heart disease in persons younger than 85 years. Further progress can be accelerated by applying existing cancer control knowledge across all segments of the population and by supporting new discoveries in cancer prevention, early detection, and treatment. CA Cancer J Clin 2010;60:277-300. © 2010 American Cancer Society, Inc.","['Statistics', 'Mathematics']","american cancer society, central cancer registries, cancer control, american cancer society"
Paper_00982,The measurement of experienced burnout,"['Christina Maslach', 'Sue Jackson']",1981,Journal of Organizational Behavior,Journal,,99-113,2,2,10.1002/job.4030020205,"A scale designed to assess various aspects of the burnout syndrome was administered to a wide range of human services professionals. Three subscales emerged from the data analysis: emotional exhaustion, depersonalization, and personal accomplishment. Various psychometric analyses showed that the scale has both high reliability and validity as a measure of burnout.","['Depersonalization', 'Burnout', 'Emotional exhaustion', 'Psychology', 'Scale (ratio)', 'Clinical psychology', 'Reliability (semiconductor)', 'Psychometrics', 'Occupational burnout', 'Power (physics)', 'Physics', 'Quantum mechanics']","burnout syndrome, human services, emotional exhaustion, depersonalization, personal accomplishment, psychometric, burnout, [PAD], [PAD] [PAD], [PAD], [PAD], [PAD], [PAD], [PAD] [PAD] [PAD] [PAD], [PAD], [PAD], [PAD] [PAD], [PAD] [PAD] [PAD], [PAD], [PAD]"
Paper_00984,Being and Time,"['Ronald W. Hepburn', 'Martín Heidegger', 'John Macquarrie', 'Edward Robinson']",1927,Unknown,Unknown,,,,,10.5040/9781501396267,"Translators' Preface. Author's Preface to the Seventh German Edition. Introduction. Exposition of the Question of the Meaning of Being. 1. The Necessity, Structure, and Priority of the Question of Being. 2. The Twofold Task of Working out the Question of Being. Method and Design of our Investigation. Part I:. The Interpretation of Dasein in Terms of Temporality, and the Explication of Time as the Transcendental Horizon for the Question of Being. 3. Preparatory Fundamental Analysis of Dasein. Exposition of the Task of a Preparatory Analysis of Dasein. Being-in-the-World in General as the Basic State of Dasein. The Worldhood of the World. Being-in-the-World as Being-with and Being-One's-Self. The 'they'. Being-in as Such. Care as the Being of Dasein. 4. Dasein and Temporality. Dasein's Possibility of Being-a-Whole, and Being-Towards-Death. Dasein's Attestation of an Authentic Potentiality-for-Being, and Resoluteness. Dasein's Authentic Potentiality-for-Being-a-Whole, and Temporality as the Ontological Meaning of Care. Temporality and Everydayness. Temporality and Historicality. Temporality and Within-Time-Ness as the Source of the Ordinary Conception of Time. Author's Notes. Glossary of German Terms. Index.","['Temporality', 'Exposition (narrative)', 'Epistemology', 'Meaning (existential)', 'Philosophy', 'Interpretation (philosophy)', 'Glossary', 'Explication', 'Literature', 'Art', 'Linguistics']","temporality, preparatory fundamental analysis, preparatory analysis, world, care, dasein, temporality, temporality, temporality, everydayness, temporality, historicality"
Paper_00985,Electron-energy-loss spectra and the structural stability of nickel oxide: An LSDA+U study,"['S. L. Dudarev', 'Gianluigi A. Botton', 'Sergey Y. Savrasov', 'C. J. Humphreys', 'A. P. Sutton']",1998,"Physical review. B, Condensed matter",Journal,,1505-1509,57,3,10.1103/physrevb.57.1505,We demonstrate how by taking better account of electron correlations in the $3d$ shell of metal ions in nickel oxide it is possible to improve the description of both electron energy loss spectra and parameters characterizing the structural stability of the material compared with local spin density functional theory.,"['Nickel', 'Electron', 'Materials science', 'Oxide', 'Ion', 'Spectral line', 'Density functional theory', 'Structural stability', 'Metal', 'Shell (structure)', 'Stability (learning theory)', 'Condensed matter physics', 'Atomic physics', 'Physics', 'Chemistry', 'Computational chemistry', 'Metallurgy', 'Composite material', 'Structural engineering', 'Astronomy', 'Machine learning', 'Computer science', 'Engineering', 'Quantum mechanics']","electron correlations, metal ions, nickel oxide, electron energy loss spectra, structural stability, local spin density functional theory, [PAD], [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD], [PAD] [PAD], [PAD] [PAD], [PAD] [PAD] [PAD], [PAD] [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD] [PAD] [PAD] [PAD], [PAD] [PAD], [PAD]"
Paper_00990,BEAST: Bayesian evolutionary analysis by sampling trees,"['Alexei J. Drummond', 'Andrew Rambaut']",2007,BMC Evolutionary Biology,Journal,,214-214,7,1,10.1186/1471-2148-7-214,"The evolutionary analysis of molecular sequence variation is a statistical enterprise. This is reflected in the increased use of probabilistic models for phylogenetic inference, multiple sequence alignment, and molecular population genetics. Here we present BEAST: a fast, flexible software architecture for Bayesian analysis of molecular sequences related by an evolutionary tree. A large number of popular stochastic models of sequence evolution are provided and tree-based models suitable for both within- and between-species sequence data are implemented. BEAST version 1.4.6 consists of 81000 lines of Java source code, 779 classes and 81 packages. It provides models for DNA and protein sequence evolution, highly parametric coalescent analysis, relaxed clock phylogenetics, non-contemporaneous sequence data, statistical alignment and a wide range of options for prior distributions. BEAST source code is object-oriented, modular in design and freely available at http://beast-mcmc.googlecode.com/ under the GNU LGPL license. BEAST is a powerful and flexible evolutionary analysis package for molecular sequence variation. It also provides a resource for the further development of new models and statistical methods of evolutionary analysis.","['Coalescent theory', 'Phylogenetic tree', 'Biology', 'Multiple sequence alignment', 'Sequence (biology)', 'Bayesian probability', 'Evolutionary biology', 'Computer science', 'Sequence alignment', 'Artificial intelligence', 'Genetics', 'Gene', 'Peptide sequence']","evolutionary analysis, molecular sequence variation, probabilistic models, phylogenetic inference, multiple sequence alignment, molecular population genetics, beast, ##esian analysis, molecular sequences, evolutionary tree, ##astic models, sequence evolution, beast, java, protein sequence evolution, highly parametric coalescent analysis, relaxed clock phylogenetics, - contemporaneous sequence data, statistical alignment, beast, beast, molecular sequence variation, evolutionary analysis"
Paper_00991,WorldClim 2: new 1‐km spatial resolution climate surfaces for global land areas,"['Stephen E. Fick', 'Robert J. Hijmans']",2017,International Journal of Climatology,Journal,,4302-4315,37,12,10.1002/joc.5086,"ABSTRACT We created a new dataset of spatially interpolated monthly climate data for global land areas at a very high spatial resolution (approximately 1 km 2 ). We included monthly temperature (minimum, maximum and average), precipitation, solar radiation, vapour pressure and wind speed, aggregated across a target temporal range of 1970–2000, using data from between 9000 and 60 000 weather stations. Weather station data were interpolated using thin‐plate splines with covariates including elevation, distance to the coast and three satellite‐derived covariates: maximum and minimum land surface temperature as well as cloud cover, obtained with the MODIS satellite platform. Interpolation was done for 23 regions of varying size depending on station density. Satellite data improved prediction accuracy for temperature variables 5–15% (0.07–0.17 °C), particularly for areas with a low station density, although prediction error remained high in such regions for all climate variables. Contributions of satellite covariates were mostly negligible for the other variables, although their importance varied by region. In contrast to the common approach to use a single model formulation for the entire world, we constructed the final product by selecting the best performing model for each region and variable. Global cross‐validation correlations were ≥ 0.99 for temperature and humidity, 0.86 for precipitation and 0.76 for wind speed. The fact that most of our climate surface estimates were only marginally improved by use of satellite covariates highlights the importance having a dense, high‐quality network of climate station data.","['Environmental science', 'Satellite', 'Cloud cover', 'Precipitation', 'Climatology', 'Wind speed', 'Multivariate interpolation', 'Land cover', 'Elevation (ballistics)', 'Meteorology', 'Covariate', 'Climate model', 'Climate change', 'Atmospheric sciences', 'Geography', 'Land use', 'Cloud computing', 'Statistics', 'Mathematics', 'Geology', 'Computer science', 'Civil engineering', 'Geometry', 'Oceanography', 'Engineering', 'Bilinear interpolation', 'Aerospace engineering', 'Operating system']","spatially, global land areas, monthly, solar radiation, vapour pressure, wind speed, thin ‐ plate, cloud cover, modis satellite platform, prediction, satellite covariates, global cross ‐ validation correlations, climate surface, satellite covariates"
Paper_00994,Wettability of porous surfaces,"['A. B. D. Cassie', 'S. Baxter']",1944,Transactions of the Faraday Society,Journal,,546-546,40,,10.1039/tf9444000546,"A. B. D. Cassie and S. Baxter, Trans. Faraday Soc., 1944, 40, 546 DOI: 10.1039/TF9444000546","['Chemistry', 'Wetting', 'Porosity', 'Chemical engineering', 'Organic chemistry', 'Engineering']","faraday soc, [PAD]"
Paper_00995,Visualization and analysis of atomistic simulation data with OVITO–the Open Visualization Tool,['Alexander Stukowski'],2009,Modelling and Simulation in Materials Science and Engineering,Journal,,015012-015012,18,1,10.1088/0965-0393/18/1/015012,"The Open Visualization Tool (OVITO) is a new 3D visualization software designed for post-processing atomistic data obtained from molecular dynamics or Monte Carlo simulations. Unique analysis, editing and animations functions are integrated into its easy-to-use graphical user interface. The software is written in object-oriented C++, controllable via Python scripts and easily extendable through a plug-in interface. It is distributed as open-source software and can be downloaded from the website http://ovito.sourceforge.net/.","['Visualization', 'Python (programming language)', 'Scripting language', 'Graphical user interface', 'Computer science', 'Software', 'Software visualization', 'Plug-in', 'Computer graphics (images)', 'Computational science', 'Interface (matter)', 'Data visualization', 'Interactive visualization', 'Open source', 'User interface', 'Data mining', 'Programming language', 'Software development', 'Component-based software engineering', 'Operating system', 'Bubble', 'Maximum bubble pressure method']","open visualization tool, ovito, 3d visualization, molecular dynamics, monte carlo simulations, python, ovi, [PAD], [PAD]"
Paper_00996,APACHE II,"['William A. Knaus', 'Elizabeth A. Draper', 'Douglas P. Wagner', 'Jack E. Zimmerman']",1985,Critical Care Medicine,Journal,,818-829,13,10,10.1097/00003246-198510000-00009,"This paper presents the form and validation results of APACHE II, a severity of disease classification system. APACHE II uses a point score based upon initial values of 12 routine physiologic measurements, age, and previous health status to provide a general measure of severity of disease. An increasing score (range 0 to 71) was closely correlated with the subsequent risk of hospital death for 5815 intensive care admissions from 13 hospitals. This relationship was also found for many common diseases.When APACHE II scores are combined with an accurate description of disease, they can prognostically stratify acutely ill patients and assist investigators comparing the success of new or differing forms of therapy. This scoring index can be used to evaluate the use of hospital resources and compare the efficacy of intensive care in different hospitals or over time.","['Medicine', 'APACHE II', 'Intensive care', 'Severity of illness', 'Disease', 'Intensive care medicine', 'Emergency medicine', 'Critically ill', 'Scoring system', 'Intensive care unit', 'Internal medicine']","apache, severity of disease classification system, apache, point score, intensive care, apache, ##ly ill, scoring"
Paper_00997,Lifetime and 12-Month Prevalence of DSM-III-R Psychiatric Disorders in the United States,['Ronald C. Kessler'],1994,Archives of General Psychiatry,Journal,,8-8,51,1,10.1001/archpsyc.1994.03950010008002,"This study presents estimates of lifetime and 12-month prevalence of 14 DSM-III-R psychiatric disorders from the National Comorbidity Survey, the first survey to administer a structured psychiatric interview to a national probability sample in the United States.The DSM-III-R psychiatric disorders among persons aged 15 to 54 years in the noninstitutionalized civilian population of the United States were assessed with data collected by lay interviewers using a revised version of the Composite International Diagnostic Interview.Nearly 50% of respondents reported at least one lifetime disorder, and close to 30% reported at least one 12-month disorder. The most common disorders were major depressive episode, alcohol dependence, social phobia, and simple phobia. More than half of all lifetime disorders occurred in the 14% of the population who had a history of three or more comorbid disorders. These highly comorbid people also included the vast majority of people with severe disorders. Less than 40% of those with a lifetime disorder had ever received professional treatment, and less than 20% of those with a recent disorder had been in treatment during the past 12 months. Consistent with previous risk factor research, it was found that women had elevated rates of affective disorders and anxiety disorders, that men had elevated rates of substance use disorders and antisocial personality disorder, and that most disorders declined with age and with higher socioeconomic status.The prevalence of psychiatric disorders is greater than previously thought to be the case. Furthermore, this morbidity is more highly concentrated than previously recognized in roughly one sixth of the population who have a history of three or more comorbid disorders. This suggests that the causes and consequences of high comorbidity should be the focus of research attention. The majority of people with psychiatric disorders fail to obtain professional treatment. Even among people with a lifetime history of three or more comorbid disorders, the proportion who ever obtain specialty sector mental health treatment is less than 50%. These results argue for the importance of more outreach and more research on barriers to professional help-seeking.","['Psychiatry', 'National Comorbidity Survey', 'Comorbidity', 'Personality disorders', 'Population', 'Anxiety', 'Prevalence of mental disorders', 'Alcohol dependence', 'Psychology', 'Anxiety disorder', 'Major depressive disorder', 'Socioeconomic status', 'Medicine', 'Personality', 'Mood', 'Alcohol', 'Social psychology', 'Biochemistry', 'Chemistry', 'Environmental health']","national comorbidity survey, structured psychiatric interview, ##ins, major depressive episode, alcohol dependence, social phobia, simple phobia, ##rb, severe disorders, risk factor, affective disorders, anxiety disorders, antisocial personality disorder, psychiatric disorders, high, ##rbidi, psychiatric disorders, ##rb, specialty sector mental health treatment"
Paper_00998,The Evolution of Life-histories,"['Tim G. Benton', 'S.C. Stearne']",1993,Journal of Animal Ecology,Journal,,796-796,62,4,10.2307/5403,Prologue Part I: Evolutionary explanation Demography: age and stage structure Quantitative genetics and reaction norms Trade-offs Lineage-specific effects Part II: Age and size at maturity Number and size of offspring Reproductive lifespan and ageing Appendices Glossary References Author index Subject index.,"['Prologue', 'Biology', 'Evolutionary biology', 'Lineage (genetic)', 'Index (typography)', 'Glossary', 'Offspring', 'Ageing', 'Demography', 'Zoology', 'History', 'Genetics', 'Sociology', 'Pregnancy', 'Philosophy', 'Gene', 'Computer science', 'Linguistics', 'Archaeology', 'World Wide Web']","evolutionary explanation demography, age, quantitative genetics, reaction norms, reproductive lifespan, ageing, [PAD]"
Paper_00999,A Combined Corner and Edge Detector,"['Chris Harris', 'Matthew J. Stephens']",1988,Unknown,Unknown,,23.1-23.6,,,10.5244/c.2.23,"The problem we are addressing in Alvey Project MMI149 is that of using computer vision to understand the unconstrained 3D world, in which the viewed scenes will in general contain too wide a diversity of objects for topdown recognition techniques to work. For example, we desire to obtain an understanding of natural scenes, containing roads, buildings, trees, bushes, etc., as typified by the two frames from a sequence illustrated in Figure 1. The solution to this problem that we are pursuing is to use a computer vision system based upon motion analysis of a monocular image sequence from a mobile camera. By extraction and tracking of image features, representations of the 3D analogues of these features can be constructed.","['Computer vision', 'Computer science', 'Artificial intelligence', 'Sequence (biology)', 'Tracking (education)', 'Monocular', 'Image (mathematics)', 'Enhanced Data Rates for GSM Evolution', 'Corner detection', 'Motion (physics)', 'Computer graphics (images)', 'Psychology', 'Pedagogy', 'Genetics', 'Biology']","alvey, mmi, computer vision, ##ined, topdown recognition techniques, natural scenes, computer vision system, motion analysis, monocular image sequence, mobile camera, 3d analogue, [PAD] [PAD]"
Paper_01000,The Social Identity Theory of Intergroup Behavior,"['Henri Tajfel', 'John Turner']",2004,Political Psychology,Journal,,276-293,,,10.4324/9780203505984-16,"This chapter presents an outline of a theory of intergroup conflict and some preliminary data relating to the theory. Much of the work on the psychology of intergroup relations has focused on patterns of individual prejudices and discrimination and on the motivational sequences of interpersonal interaction. The intensity of explicit intergroup conflicts of interests is closely related in human cultures to the degree of opprobrium attached to the notion of renegade or traitor. The basic and highly reliable finding is that the trivial, ad hoc intergroup categorization leads to in-group favoritism and discrimination against the out-group. Many orthodox definitions of social groups are unduly restrictive when applied to the context of intergroup relations. The equation of competition and intergroup conflict rests on the assumptions concerning an ideal type of stratification in which the salient dimensions of intergroup differentiation are those involving scarce resources.","['Social identity theory', 'Identity (music)', 'Psychology', 'Sociology', 'Social psychology', 'Social group', 'Art', 'Aesthetics']","intergroup conflict, intergroup relations, individual prejudices, discrimination, motivational sequences, interpersonal interaction, human cultures, social groups, intergroup relations, intergroup conflict, intergroup differentiation, scarce resources"
Paper_01001,Soil Chemical Analysis,['Marion Jackson'],2014,['Journal of AOAC INTERNATIONAL'],Unknown,,740-740,41,3,10.1093/jaoac/41.3.740a,"Soil chemical analysis , Soil chemical analysis , مرکز فناوری اطلاعات و اطلاع رسانی کشاورزی",['Environmental science'],"soil chemical analysis, soil chemical analysis"
Paper_01003,Principles and Practice of Infectious Diseases.,"['Gerald L. Mandell', 'R. Gordon Douglas', 'John E. Bennett']",1991,Annals of Internal Medicine,Journal,,818-818,114,9,10.7326/0003-4819-114-9-818_5,"This updated and expanded edition now offers 297 chapters that cover the basic principles of diagnosis and management, major clinical syndromes, all important pathogenic microbes and the diseases they cause, plus a number of specialised topics useful to the practitioner. It contains 24 totally-new chapters, offers a whole section on AIDS with seven chapters and a chapter Microsporidium Disease, which deals with a new disease just discovered because of AIDS. The text is designed for clinical pathologists, microbiologists, virologists, medical scientists, mycologists, allergists, general practitioners and lecturers of medicine.","['Medicine', 'Intensive care medicine']","clinical syndromes, pathogenic microbes, microsporidium disease, clinical pathologists, micro, virol, medical scientists, mycol, allergist, general practitioners"
Paper_01004,Fundamentals of Wireless Communication,"['David Tse', 'Pramod Viswanath']",2005,Unknown,Unknown,,,,,10.1017/cbo9780511807213,"The past decade has seen many advances in physical layer wireless communication theory and their implementation in wireless systems. This textbook takes a unified view of the fundamentals of wireless communication and explains the web of concepts underpinning these advances at a level accessible to an audience with a basic background in probability and digital communication. Topics covered include MIMO (multi-input, multi-output) communication, space-time coding, opportunistic communication, OFDM and CDMA. The concepts are illustrated using many examples from real wireless systems such as GSM, IS-95 (CDMA), IS-856 (1 x EV-DO), Flash OFDM and UWB (ultra-wideband). Particular emphasis is placed on the interplay between concepts and their implementation in real systems. An abundant supply of exercises and figures reinforce the material in the text. This book is intended for use on graduate courses in electrical and computer engineering and will also be of great interest to practising engineers.","['Wireless', 'Computer science', 'Telecommunications', 'Communications system', 'Physical layer', 'Electronic engineering', 'Multimedia', 'Engineering']","physical layer wireless communication theory, wireless systems, wireless communication, probability, digital communication, opportunistic communication, ofdm, cdma, real wireless systems, gsm, flash of, electrical"
Paper_01006,Modernity and Self-Identity: Self and Society in the Late Modern Age,['Anthony Giddens'],2020,Routledge eBooks,Unknown,,354-361,,,10.4324/9781003060963-59,"The reflexivity of modernity extends into core of the self. Put in another way, in the context of a post-traditional order, the self becomes a reflexive project. One concerns the primacy of lifestyle — and its inevitability for the individual agent. Lifestyle is not a term which has much applicability to traditional cultures, because it implies choice within plurality of possible options, and is 'adopted' rather than 'handed down'. Lifestyle choices and life planning are not just 'in', or constituent of, the day-to-day life of social agents, but form institutional settings which help to shape their actions. Of course, for all individuals and groups, life chances condition lifestyle choices. Life planning is a specific example of a more general phenomenon that author shall discuss in some detail in subsequent chapter as the 'colonisation of the future'. In the reflexive project of the self, the narrative of self-identity is inherently fragile. Moreover, the pure relationship contains internal tensions and even contradictions.","['Modernity', 'Identity (music)', 'Late modernity', 'Psychoanalysis', 'Sociology', 'Psychology', 'Gender studies', 'History', 'Aesthetics', 'Art', 'Epistemology', 'Anthropology', 'Philosophy']","modern, lifestyle, lifestyle choices, life planning, life planning"
Paper_01007,The structural transformation of the public sphere: an inquiry into a category of bourgeois society,"['Jürgen Habermas', 'Thomas Burgerm']",1990,Choice Reviews Online,Journal,,27-4175,27,07,10.5860/choice.27-4175,"Part 1 Introduction - preliminary demarcation of a type of Bourgeois Public Sphere: the initial question remarks on the type representative publicness on the genesis of the Bourgois Public Sphere. Part 2 Social structures of the Public Sphere: the basic blueprint institutions of the public sphere the Bourgois family and the institutionalization of a privateness oriented to an audience the public sphere in the world of letters in relation to the public sphere in the political realm. Part 3 Political functions of the public sphere: the model case of British development the continental variants civil society as the sphere of private autonomy: private law and a liberalized market the contradictory institutionalization of the public sphere in the Bourgeois constitutional state. Part 4 The bourgeois public sphere - idea and ideology: publicity as the bridging principle between politics and morality, Kant on the dialectic of the public sphere, Hegel and Marx the ambivalent view of the public sphere in the theory of liberalism, John Stuart Mill and Alexis de Tocqueville. Part 5 The social-structural transformation of the public sphere: the tendency toward a mutual infiltration of public and private spheres the polarization of the social sphere and the intimate sphere from a culture-debating (kulturrasonierend) public to a culture-consuming public the blurred blueprint - developmental pathways in the disintegration of the bourgeois public sphere. Part 6 the transformation of the public sphere's political function: from the journalism of private men of letters to the public consumer services of the mass media - the public sphere as a platform for advertising the transmitted function of the principle of publicity manufactured publicity and nonpublic opinions - the voting behaviour of the population the political public sphere and the transformation of the liberal constitutional state into a social-welfare state. Part 7 On the concept of public opinion: public opinion as a fiction of constitutional law-and the social-psychological liquidation of the concept a sociological attempt at clarification.","['Bourgeoisie', 'Transformation (genetics)', 'Public sphere', 'Aesthetics', 'Sociology', 'Political science', 'Art', 'Law', 'Politics', 'Biochemistry', 'Chemistry', 'Gene']","bourgeois public sphere, ##ois public sphere, social structures, british, liberalized market, publicity, liberalism, public opinion"
Paper_01009,PAML 4: Phylogenetic Analysis by Maximum Likelihood,['Yang Zhang'],2007,Molecular Biology and Evolution,Journal,,1586-1591,24,8,10.1093/molbev/msm088,"PAML, currently in version 4, is a package of programs for phylogenetic analyses of DNA and protein sequences using maximum likelihood (ML). The programs may be used to compare and test phylogenetic trees, but their main strengths lie in the rich repertoire of evolutionary models implemented, which can be used to estimate parameters in models of sequence evolution and to test interesting biological hypotheses. Uses of the programs include estimation of synonymous and nonsynonymous rates (dN and dS) between two protein-coding DNA sequences, inference of positive Darwinian selection through phylogenetic comparison of protein-coding genes, reconstruction of ancestral genes and proteins for molecular restoration studies of extinct life forms, combined analysis of heterogeneous data sets from multiple gene loci, and estimation of species divergence times incorporating uncertainties in fossil calibrations. This note discusses some of the major applications of the package, which includes example data sets to demonstrate their use. The package is written in ANSI C, and runs under Windows, Mac OSX, and UNIX systems. It is available at http://abacus.gene.ucl.ac.uk/software/paml.html.","['Biology', 'Phylogenetic tree', 'Nonsynonymous substitution', 'Phylogenetic network', 'Maximum likelihood', 'Phylogenetics', 'Evolutionary biology', 'Maximum parsimony', 'Gene', 'Inference', 'Unix', 'Molecular evolution', 'Computational biology', 'Coding region', 'Genetics', 'Clade', 'Software', 'Statistics', 'Programming language', 'Computer science', 'Artificial intelligence', 'Mathematics', 'Genome']","paml, phylogenetic analyses, protein sequences, maximum likelihood, phylogenetic trees, evolutionary models, sequence evolution, nonsynonymous rates, positive darwinian selection, phylogenetic comparison, molecular restoration, extinct life forms, ##gen, multiple gene loci, species divergence times, fossil calibrations, unix, [PAD], [PAD] [PAD] [PAD] [PAD], [PAD] [PAD], [PAD]"
Paper_01013,A translation approach to portable ontology specifications,['Thomas Gruber'],1993,Knowledge Acquisition,Journal,,199-220,5,2,10.1006/knac.1993.1008,"To support the sharing and reuse of formally represented knowledge among AI systems, it is useful to define the common vocabulary in which shared knowledge is represented. A specification of a representational vocabulary for a shared domain of discourse—definitions of classes, relations, functions, and other objects—is called an ontology. This paper describes a mechanism for defining ontologies that are portable over representation systems. Definitions written in a standard format for predicate calculus are translated by a system called Ontolingua into specialized representations, including frame-based systems as well as relational languages. This allows researchers to share and reuse ontologies, while retaining the computational benefits of specialized implementations. We discuss how the translation approach to portability addresses several technical problems. One problem is how to accommodate the stylistic and organizational differences among representations while preserving declarative content. Another is how to translate from a very expressive language into restricted languages, remaining system-independent while preserving the computational efficiency of implemented systems. We describe how these problems are addressed by basing Ontolingua itself on an ontology of domain-independent, representational idioms.","['Computer science', 'Software portability', 'Implementation', 'Ontology', 'Programming language', 'Vocabulary', 'Reuse', 'Knowledge representation and reasoning', 'Natural language processing', 'Ontology language', 'Software engineering', 'Artificial intelligence', 'Semantic Web', 'Linguistics', 'Philosophy', 'Epistemology', 'Ecology', 'Biology']","formally represented knowledge, ai systems, shared knowledge, representational vocabulary, functions, ontology, ontologies, representation, predicate calculus, ontolingua, relational languages, translation, ##ability, organizational, ##ative content, restricted languages, computational efficiency, ontoling, ##al id, [PAD], [PAD] [PAD] [PAD], [PAD], [PAD], [PAD], [PAD], [PAD] [PAD]"
Paper_00945,Room-Temperature Ionic Liquids: Solvents for Synthesis and Catalysis. 2,"['Jason P. Hallett', 'Tom Welton']",2011,Chemical Reviews,Journal,,3508-3576,111,5,10.1021/cr1003248,"ADVERTISEMENT RETURN TO ISSUEPREVReviewNEXTRoom-Temperature Ionic Liquids: Solvents for Synthesis and Catalysis. 2Jason P. Hallett and Tom Welton*View Author Information Department of Chemistry, Imperial College London, South Kensington Campus, London SW7 2AZ, United Kingdom*E-mail: [email protected]Cite this: Chem. Rev. 2011, 111, 5, 3508–3576Publication Date (Web):April 6, 2011Publication History Received23 September 2010Published online6 April 2011Published inissue 11 May 2011https://pubs.acs.org/doi/10.1021/cr1003248https://doi.org/10.1021/cr1003248review-articleACS PublicationsCopyright © 2011 American Chemical SocietyRequest reuse permissionsArticle Views39839Altmetric-Citations3787LEARN ABOUT THESE METRICSArticle Views are the COUNTER-compliant sum of full text article downloads since November 2008 (both PDF and HTML) across all institutions and individuals. These metrics are regularly updated to reflect usage leading up to the last few days.Citations are the number of other articles citing this article, calculated by Crossref and updated daily. Find more information about Crossref citation counts.The Altmetric Attention Score is a quantitative measure of the attention that a research article has received online. Clicking on the donut icon will load a page at altmetric.com with additional details about the score and the social media presence for the given article. Find more information on the Altmetric Attention Score and how the score is calculated. Share Add toView InAdd Full Text with ReferenceAdd Description ExportRISCitationCitation and abstractCitation and referencesMore Options Share onFacebookTwitterWechatLinked InRedditEmail Other access optionsGet e-AlertscloseSupporting Info (1)»Supporting Information Supporting Information SUBJECTS:Anions,Catalysts,Cations,Salts,Solvents Get e-Alerts","['Citation', 'Ionic liquid', 'World Wide Web', 'Computer science', 'Chemistry', 'Library science', 'Nanotechnology', 'Analytical Chemistry (journal)', 'Catalysis', 'Organic chemistry', 'Materials science']","catalysis, imperial, american, metric, ##f, altmetric attention score, social, altmetric attention score, ##ation, abstract, anions, catalysts, cations, salts, solvents"
Paper_00946,A new method for non‐parametric multivariate analysis of variance,['Marti J. Anderson'],2001,Austral Ecology,Journal,,32-46,26,1,10.1111/j.1442-9993.2001.01070.pp.x,"Abstract Hypothesis‐testing methods for multivariate data are needed to make rigorous probability statements about the effects of factors and their interactions in experiments. Analysis of variance is particularly powerful for the analysis of univariate data. The traditional multivariate analogues, however, are too stringent in their assumptions for most ecological multivariate data sets. Non‐parametric methods, based on permutation tests, are preferable. This paper describes a new non‐parametric method for multivariate analysis of variance, after McArdle and Anderson (in press). It is given here, with several applications in ecology, to provide an alternative and perhaps more intuitive formulation for ANOVA (based on sums of squared distances) to complement the description provided by McArdle and Anderson (in press) for the analysis of any linear model. It is an improvement on previous non‐parametric methods because it allows a direct additive partitioning of variation for complex models. It does this while maintaining the flexibility and lack of formal assumptions of other non‐parametric methods. The test‐statistic is a multivariate analogue to Fisher’s F ‐ratio and is calculated directly from any symmetric distance or dissimilarity matrix. P ‐values are then obtained using permutations. Some examples of the method are given for tests involving several factors, including factorial and hierarchical (nested) designs and tests of interactions.","['Multivariate statistics', 'Multivariate analysis of variance', 'Univariate', 'Permutation (music)', 'Parametric statistics', 'Statistics', 'Multivariate analysis', 'Statistic', 'Mathematics', 'Variance (accounting)', 'Flexibility (engineering)', 'Nonparametric statistics', 'Analysis of variance', 'Computer science', 'Econometrics', 'Accounting', 'Physics', 'Acoustics', 'Business']","abstract hypothesis ‐, multivariate data, probability statements, analysis, variance, univariate data, multivariate, ecological multivariate data, non ‐, ##metric, permutation tests, non ‐ parametric, multivariate analysis, variance, ecology, anova, squared distances, ‐ parametric, additive partitioning, ‐, ##metric, ##variate, f, symmetric distance, dissimilarity matrix, permut"
Paper_00947,Regularization Paths for Generalized Linear Models via Coordinate Descent.,"['Jerome H. Friedman', 'Trevor Hastie', 'Rob Tibshirani']",2010,['Journal of Statistical Software'],Unknown,,1-22,33,1,10.18637/jss.v033.i01,"We develop fast algorithms for estimation of generalized linear models with convex penalties. The models include linear regression, two-class logistic regression, and multinomial regression problems while the penalties include ℓ(1) (the lasso), ℓ(2) (ridge regression) and mixtures of the two (the elastic net). The algorithms use cyclical coordinate descent, computed along a regularization path. The methods can handle large problems and can also deal efficiently with sparse features. In comparative timings we find that the new algorithms are considerably faster than competing methods.","['Coordinate descent', 'Elastic net regularization', 'Lasso (programming language)', 'Regularization (linguistics)', 'Multinomial logistic regression', 'Linear regression', 'Generalized linear model', 'Computer science', 'Linear model', 'Multinomial distribution', 'Mathematical optimization', 'Applied mathematics', 'Regression', 'Mathematics', 'Algorithm', 'Artificial intelligence', 'Statistics', 'Machine learning', 'World Wide Web']","generalized linear models, convex penalties, linear regression, multinomial regression problems, lasso, ridge regression, elastic net, cyclical coordinate descent, regularization path, comparative timings, [PAD] [PAD], [PAD], [PAD], [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD], [PAD] [PAD], [PAD], [PAD] [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD], [PAD], [PAD], [PAD] [PAD] [PAD] [PAD] [PAD], [PAD] [PAD], [PAD] [PAD] [PAD] [PAD] [PAD]"
Paper_00948,"The determination of the elastic field of an ellipsoidal inclusion, and related problems",['J. D. Eshelby'],1957,Proceedings of the Royal Society of London A Mathematical and Physical Sciences,Journal,,376-396,241,1226,10.1098/rspa.1957.0133,"It is supposed that a region within an isotropic elastic solid undergoes a spontaneous change of form which, if the surrounding material were absent, would be some prescribed homogeneous deformation. Because of the presence of the surrounding material stresses will be present both inside and outside the region. The resulting elastic field may be found very simply with the help of a sequence of imaginary cutting, straining and welding operations. In particular, if the region is an ellipsoid the strain inside it is uniform and may be expressed in terms of tabu­lated elliptic integrals. In this case a further problem may be solved. An ellipsoidal region in an infinite medium has elastic constants different from those of the rest of the material; how does the presence of this inhomogeneity disturb an applied stress-field uniform at large distances? It is shown that to answer several questions of physical or engineering interest it is necessary to know only the relatively simple elastic field inside the ellipsoid.","['Ellipsoid', 'Isotropy', 'Field (mathematics)', 'Stress field', 'Simple (philosophy)', 'Mathematical analysis', 'Homogeneous', 'Welding', 'Mathematics', 'Geometry', 'Physics', 'Classical mechanics', 'Materials science', 'Pure mathematics', 'Statistical physics', 'Finite element method', 'Optics', 'Composite material', 'Thermodynamics', 'Philosophy', 'Epistemology', 'Astronomy']","isotropic elastic solid, prescribed homogeneous deformation, elastic field, imaginary cutting, straining, welding operations, ellipsoid, tabulated elliptic integrals, ellipsoidal region, infinite medium, elastic constant"
Paper_00949,Efficient Estimation of Word Representations in Vector Space,"['Tomáš Mikolov', 'Kai Chen', 'Greg S. Corrado', 'Jay B. Dean']",2013,['Journal of Innovations in Engineering Education'],Unknown,,71-77,3,1,10.3126/jiee.v3i1.34327,"We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities.","['Word (group theory)', 'Computer science', 'Similarity (geometry)', 'Set (abstract data type)', 'Artificial intelligence', 'Vector space', 'Natural language processing', 'Task (project management)', 'Test set', 'Semantic similarity', 'Space (punctuation)', 'Vector space model', 'Artificial neural network', 'Mathematics', 'Geometry', 'Management', 'Economics', 'Image (mathematics)', 'Programming language', 'Operating system']","continuous vector representations, word similarity task, neural networks, semantic word similarities, [PAD], [PAD] [PAD] [PAD]"
Paper_00950,Cooperative Diversity in Wireless Networks: Efficient Protocols and Outage Behavior,"['J. Nicholas Laneman', 'David Tse', 'Gregory W. Wornell']",2004,IEEE Transactions on Information Theory,Journal,,3062-3080,50,12,10.1109/tit.2004.838089,"We develop and analyze low-complexity cooperative diversity protocols that combat fading induced by multipath propagation in wireless networks. The underlying techniques exploit space diversity available through cooperating terminals' relaying signals for one another. We outline several strategies employed by the cooperating radios, including fixed relaying schemes such as amplify-and-forward and decode-and-forward, selection relaying schemes that adapt based upon channel measurements between the cooperating terminals, and incremental relaying schemes that adapt based upon limited feedback from the destination terminal. We develop performance characterizations in terms of outage events and associated outage probabilities, which measure robustness of the transmissions to fading, focusing on the high signal-to-noise ratio (SNR) regime. Except for fixed decode-and-forward, all of our cooperative diversity protocols are efficient in the sense that they achieve full diversity (i.e., second-order diversity in the case of two terminals), and, moreover, are close to optimum (within 1.5 dB) in certain regimes. Thus, using distributed antennas, we can provide the powerful benefits of space diversity without need for physical arrays, though at a loss of spectral efficiency due to half-duplex operation and possibly at the cost of additional receive hardware. Applicable to any wireless setting, including cellular or ad hoc networks-wherever space constraints preclude the use of physical arrays-the performance characterizations reveal that large power or energy savings result from the use of these protocols.","['Cooperative diversity', 'Computer science', 'Fading', 'Multipath propagation', 'Wireless', 'Antenna diversity', 'Computer network', 'Robustness (evolution)', 'Wireless network', 'Diversity combining', 'Spectral efficiency', 'Diversity scheme', 'Relay', 'Exploit', 'Channel (broadcasting)', 'Telecommunications', 'Power (physics)', 'Biochemistry', 'Chemistry', 'Physics', 'Computer security', 'Quantum mechanics', 'Gene']","fading, multipath propagation, wireless networks, space diversity, cooperating radios, fixed relaying schemes, selection relaying schemes, channel measurements, incremental relaying schemes, performance characterizations, outage events, outage probabilities, cooperative diversity protocols, distributed antennas, space diversity, physical arrays, spectral efficiency, physical arrays, energy"
Paper_00952,Information Theory and Statistical Mechanics,['E. T. Jaynes'],1957,Physical Review,Journal,,620-630,106,4,10.1103/physrev.106.620,"Information theory provides a constructive criterion for setting up probability distributions on the basis of partial knowledge, and leads to a type of statistical inference which is called the maximum-entropy estimate. It is the least biased estimate possible on the given information; i.e., it is maximally noncommittal with regard to missing information. If one considers statistical mechanics as a form of statistical inference rather than as a physical theory, it is found that the usual computational rules, starting with the determination of the partition function, are an immediate consequence of the maximum-entropy principle. In the resulting ""subjective statistical mechanics,"" the usual rules are thus justified independently of any physical argument, and in particular independently of experimental verification; whether or not the results agree with experiment, they still represent the best estimates that could have been made on the basis of the information available.It is concluded that statistical mechanics need not be regarded as a physical theory dependent for its validity on the truth of additional assumptions not contained in the laws of mechanics (such as ergodicity, metric transitivity, equal a priori probabilities, etc.). Furthermore, it is possible to maintain a sharp distinction between its physical and statistical aspects. The former consists only of the correct enumeration of the states of a system and their properties; the latter is a straightforward example of statistical inference.","['Statistical mechanics', 'Statistical inference', 'Principle of maximum entropy', 'Statistical theory', 'Entropy (arrow of time)', 'Inference', 'Information theory', 'Mathematics', 'Statistical hypothesis testing', 'Physical law', 'Statistical physics', 'Ergodicity', 'Computer science', 'Statistics', 'Physics', 'Artificial intelligence', 'Quantum mechanics']","information theory, probability distributions, partial knowledge, statistical inference, statistical mechanics, statistical inference, computational rules, partition function, subjective statistical mechanics, experimental verification, statistical mechanics, ergodicity, metric transitivity, statistical inference, [PAD]"
Paper_00953,"Global, regional, and national incidence, prevalence, and years lived with disability for 328 diseases and injuries for 195 countries, 1990–2016: a systematic analysis for the Global Burden of Disease Study 2016","['Theo Vos', 'Amanuel Alemu Abajobir', 'Kalkidan Hassen Abate', 'Cristiana Abbafati', 'Kaja Abbas', 'Foad Abd-Allah', 'Rizwan Suliankatchi Abdulkader', 'Abdishakur Abdulle', 'Teshome Abuka Abebo', 'Semaw Ferede Abera', 'Victor Aboyans', 'Laith J. Abu‐Raddad', 'Ilana N. Ackerman', 'Abdu A. Adamu', 'Olatunji Adetokunboh', 'Mohsen Afarideh', 'Ashkan Afshin', 'Sanjay Agarwal', 'Rakesh Aggarwal', 'Anurag Agrawal', 'Sutapa Agrawal', 'Hamid Ahmadieh', 'Muktar Beshir Ahmed', 'Miloud Taki Eddine Aichour', 'Amani Nidhal Aichour', 'Ibtihel Aichour', 'Sneha Aiyar', 'Rufus Akinyemi', 'Nadia Akseer', 'Faris Lami', 'Fares Alahdab', 'Ziyad Al‐Aly', 'Khurshid Alam', 'Noore Alam', 'Shazia Alam', 'Deena Alasfoor', 'Kefyalew Addis Alene', 'Raghib Ali', 'Reza Alizadeh‐Navaei', 'Ala’a Alkerwi', 'François Alla', 'Peter Allebeck', 'Christine A. Allen', 'Fatma Al‐Maskari', 'Rajaa Al‐Raddadi', 'Ubai Alsharif', 'Shirina Alsowaidi', 'Khalid A Altirkawi', 'Azmeraw T. Amare', 'Erfan Amini', 'Walid Ammar', 'Yaw Ampem Amoako', 'Hjalte Holm Andersen', 'Carl Abelardo T. Antonio', 'Palwasha Anwari', 'Johan Ärnlöv', 'Al Artaman', 'Krishna Kumar Aryal', 'Hamid Asayesh', 'Solomon Weldegebreal Asgedom', 'Reza Assadi', 'Tesfay Mehari Atey', 'Niguse Tadele Atnafu', 'Sachin Atre', 'Leticia Ávila‐Burgos', 'Euripide Frinel G Arthur Avokphako', 'Ashish Awasthi', 'Umar Bacha', 'Alaa Badawi', 'Kalpana Balakrishnan', 'Amitava Banerjee', 'Marlena S. Bannick', 'Aleksandra Barać', 'Ryan M Barber', 'Suzanne Barker‐Collo', 'Till Bärnighausen', 'Sı́món Barquera', 'Lars Barregård', 'Lope H Barrero', 'Sanjay Basu', 'Bob Battista', 'Katherine E. Battle', 'Bernhard T. Baune', 'Shahrzad Bazargan‐Hejazi', 'Justin Beardsley', 'Neeraj Bedi', 'Ettore Beghi', 'Yannick Béjot', 'Bayu Begashaw Bekele', 'Michelle L. Bell', 'Derrick Bennett', 'Isabela M. Benseñor', 'Jennifer Benson', 'Adugnaw Berhane', 'Derbew Fikadu Berhe', 'Eduardo Bernabé', 'Balem Demtsu Betsu', 'Mircea Beuran', 'Addisu Shunu Beyene', 'Neeraj Bhala']",2017,The Lancet,Journal,,1211-1259,390,10100,10.1016/s0140-6736(17)32154-2,"<h2>Summary</h2><h3>Background</h3> As mortality rates decline, life expectancy increases, and populations age, non-fatal outcomes of diseases and injuries are becoming a larger component of the global burden of disease. The Global Burden of Diseases, Injuries, and Risk Factors Study 2016 (GBD 2016) provides a comprehensive assessment of prevalence, incidence, and years lived with disability (YLDs) for 328 causes in 195 countries and territories from 1990 to 2016. <h3>Methods</h3> We estimated prevalence and incidence for 328 diseases and injuries and 2982 sequelae, their non-fatal consequences. We used DisMod-MR 2.1, a Bayesian meta-regression tool, as the main method of estimation, ensuring consistency between incidence, prevalence, remission, and cause of death rates for each condition. For some causes, we used alternative modelling strategies if incidence or prevalence needed to be derived from other data. YLDs were estimated as the product of prevalence and a disability weight for all mutually exclusive sequelae, corrected for comorbidity and aggregated to cause level. We updated the Socio-demographic Index (SDI), a summary indicator of income per capita, years of schooling, and total fertility rate. GBD 2016 complies with the Guidelines for Accurate and Transparent Health Estimates Reporting (GATHER). <h3>Findings</h3> Globally, low back pain, migraine, age-related and other hearing loss, iron-deficiency anaemia, and major depressive disorder were the five leading causes of YLDs in 2016, contributing 57·6 million (95% uncertainty interval [UI] 40·8–75·9 million [7·2%, 6·0–8·3]), 45·1 million (29·0–62·8 million [5·6%, 4·0–7·2]), 36·3 million (25·3–50·9 million [4·5%, 3·8–5·3]), 34·7 million (23·0–49·6 million [4·3%, 3·5–5·2]), and 34·1 million (23·5–46·0 million [4·2%, 3·2–5·3]) of total YLDs, respectively. Age-standardised rates of YLDs for all causes combined decreased between 1990 and 2016 by 2·7% (95% UI 2·3–3·1). Despite mostly stagnant age-standardised rates, the absolute number of YLDs from non-communicable diseases has been growing rapidly across all SDI quintiles, partly because of population growth, but also the ageing of populations. The largest absolute increases in total numbers of YLDs globally were between the ages of 40 and 69 years. Age-standardised YLD rates for all conditions combined were 10·4% (95% UI 9·0–11·8) higher in women than in men. Iron-deficiency anaemia, migraine, Alzheimer's disease and other dementias, major depressive disorder, anxiety, and all musculoskeletal disorders apart from gout were the main conditions contributing to higher YLD rates in women. Men had higher age-standardised rates of substance use disorders, diabetes, cardiovascular diseases, cancers, and all injuries apart from sexual violence. Globally, we noted much less geographical variation in disability than has been documented for premature mortality. In 2016, there was a less than two times difference in age-standardised YLD rates for all causes between the location with the lowest rate (China, 9201 YLDs per 100 000, 95% UI 6862–11943) and highest rate (Yemen, 14 774 YLDs per 100 000, 11 018–19 228). <h3>Interpretation</h3> The decrease in death rates since 1990 for most causes has not been matched by a similar decline in age-standardised YLD rates. For many large causes, YLD rates have either been stagnant or have increased for some causes, such as diabetes. As populations are ageing, and the prevalence of disabling disease generally increases steeply with age, health systems will face increasing demand for services that are generally costlier than the interventions that have led to declines in mortality in childhood or for the major causes of mortality in adults. Up-to-date information about the trends of disease and how this varies between countries is essential to plan for an adequate health-system response. <h3>Funding</h3> Bill & Melinda Gates Foundation, and the National Institute on Aging and the National Institute of Mental Health of the National Institutes of Health.","['Medicine', 'Incidence (geometry)', 'Disease burden', 'Burden of disease', 'Life expectancy', 'Demography', 'Years of potential life lost', 'Global health', 'Comorbidity', 'Population', 'Environmental health', 'Pediatrics', 'Public health', 'Psychiatry', 'Physics', 'Nursing', 'Sociology', 'Optics']","mortality, life expectancy, risk factors, ##s, disability weight, health estimates, low back pain, migraine, major depressive disorder"
Paper_00954,Patterns of Attachment: A Psychological Study of the Strange Situation,"['Mary D. Salter Ainsworth', 'Mary C. Blehar', 'Everett Waters', 'Sally N. Wall']",1978,['Journal of Developmental &amp; Behavioral Pediatrics'],Unknown,,519-519,37,6,10.1097/dbp.0000000000000286,Part I: Introduction 1. Theoretical Background Part II: Method 2. Procedures 3. Measures and Methods of Assessment Part III: Results 4. Descriptive Account of Behavior in Each Episode 5. Normative Trends across Episodes 6. An Examination of the Classificatory System: A Multiple Discriminate Function Analysis 7. Relationships between Infant Behavior in the Strange Situation and at Home 8. Relationships between Infant Behavior in the Strange Situation and Maternal Behavior at Home 9. A Review of Strange-Situation Studies of One-Year-Olds 10. A Review of Strange-Situation Studies of Two- to Four-Year-Olds 11. The Effects of Repetition of the Strange Situation 12. Subgroups and Their Usefulness Part IV: Discussion 13. Discussion of Normative Issues 14. Individual Differences: In Light of Contrasting Paradigms 15. An Interpretation of Individual Differences Appendix I: Instructions to Mother Appendix II: Instructions for Coding and Tabulating Frequency of Behaviors Appendix III: Scoring System for Interactive Behaviors Appendix IV: Maternal Caregiving and Interaction Scales Appendix V: Secure Base Behavior At Home Appendix VI: Supplementary Statistical Findings,"['Strange situation', 'Normative', 'Psychology', 'Repetition (rhetorical device)', 'Interpretation (philosophy)', 'Developmental psychology', 'Social psychology', 'Attachment theory', 'Linguistics', 'Epistemology', 'Philosophy']","assessment, descriptive account, normative trends, classificatory system, multiple discriminate function analysis, maternal behavior, subgroups, norma, individual differences, individual differences, scoring system, interactive behaviors, maternal caregiving, interaction scales, secure base behavior, [PAD], [PAD], [PAD] [PAD], [PAD], [PAD] [PAD]"
Paper_00956,The missing term in effective pair potentials,"['Herman J. C. Berendsen', 'J. Raúl Grigera', 'Tjerk P. Straatsma']",1987,The Journal of Physical Chemistry,Journal,,6269-6271,91,24,10.1021/j100308a038,"ADVERTISEMENT RETURN TO ISSUEPREVArticleNEXTThe missing term in effective pair potentialsH. J. C. Berendsen, J. R. Grigera, and T. P. StraatsmaCite this: J. Phys. Chem. 1987, 91, 24, 6269–6271Publication Date (Print):November 1, 1987Publication History Published online1 May 2002Published inissue 1 November 1987https://pubs.acs.org/doi/10.1021/j100308a038https://doi.org/10.1021/j100308a038research-articleACS PublicationsRequest reuse permissionsArticle Views22164Altmetric-Citations10802LEARN ABOUT THESE METRICSArticle Views are the COUNTER-compliant sum of full text article downloads since November 2008 (both PDF and HTML) across all institutions and individuals. These metrics are regularly updated to reflect usage leading up to the last few days.Citations are the number of other articles citing this article, calculated by Crossref and updated daily. Find more information about Crossref citation counts.The Altmetric Attention Score is a quantitative measure of the attention that a research article has received online. Clicking on the donut icon will load a page at altmetric.com with additional details about the score and the social media presence for the given article. Find more information on the Altmetric Attention Score and how the score is calculated. Share Add toView InAdd Full Text with ReferenceAdd Description ExportRISCitationCitation and abstractCitation and referencesMore Options Share onFacebookTwitterWechatLinked InRedditEmail Other access options Get e-Alerts","['Citation', 'Icon', 'Altmetrics', 'Term (time)', 'Computer science', 'Social media', 'Information retrieval', 'Measure (data warehouse)', 'World Wide Web', 'Physics', 'Data mining', 'Quantum mechanics', 'Programming language']","effective pair potentialsh, permissionsarticle views, ##le, ##f, ##f, altmetric attention score, social, altmetric, ##d, ##citation, abstract, ##ation, references"
Paper_00957,An Introduction to Fluid Dynamics,['G. K. Batchelor'],2000,Unknown,Unknown,,,,,10.1017/cbo9780511800955,"First published in 1967, Professor Batchelor's classic text on fluid dynamics is still one of the foremost texts in the subject. The careful presentation of the underlying theories of fluids is still timely and applicable, even in these days of almost limitless computer power. This re-issue should ensure that a new generation of graduate students see the elegance of Professor Batchelor's presentation.","['Presentation (obstetrics)', 'Elegance', 'Subject (documents)', 'Dynamics (music)', 'Computer science', 'Epistemology', 'Psychology', 'Philosophy', 'Library science', 'Medicine', 'Pedagogy', 'Radiology']","fluid dynamics, [PAD]"
Paper_00958,Macroeconomics and Reality,['Christopher A. Sims'],1980,Econometrica,Journal,,1-1,48,1,10.2307/1912017,"Existing strategies for econometric analysis related to macroeconomics are subject to a number of serious objections, some recently formulated, some old. These objections are summarized in this paper, and it is argued that taken together they make it unlikely that macroeconomic models are in fact over identified, as the existing statistical theory usually assumes. The implications of this conclusion are explored, and an example of econometric work in a non-standard style, taking account of the objections to the standard style, is presented. THE STUDY OF THE BUSINESS cycle, fluctuations in aggregate measures of economic activity and prices over periods from one to ten years or so, constitutes or motivates a large part of what we call macroeconomics. Most economists would agree that there are many macroeconomic variables whose cyclical fluctuations are of interest, and would agree further that fluctuations in these series are interrelated. It would seem to follow almost tautologically that statistical models involving large numbers of macroeconomic variables ought to be the arena within which macroeconomic theories confront reality and thereby each other. Instead, though large-scale statistical macroeconomic models exist and are by some criteria successful, a deep vein of skepticism about the value of these models runs through that part of the economics profession not actively engaged in constructing or using them. It is still rare for empirical research in macroeconomics to be planned and executed within the framework of one of the large models. In this lecture I intend to discuss some aspects of this situation, attempting both to offer some explanations and to suggest some means for improvement. I will argue that the style in which their builders construct claims for a connection between these models and reality-the style in which is achieved for these models-is inappropriate, to the point at which claims for identification in these models cannot be taken seriously. This is a venerable assertion; and there are some good old reasons for believing it;2 but there are also some reasons which have been more recently put forth. After developing the conclusion that the identification claimed for existing large-scale models is incredible, I will discuss what ought to be done in consequence. The line of argument is: large-scale models do perform useful forecasting and policy-analysis functions despite their incredible identification; the restrictions imposed in the usual style of identification are neither essential to constructing a model which can perform these functions nor innocuous; an alternative style of identification is available and practical. Finally we will look at some empirical work based on an alternative style of macroeconometrics. A six-variable dynamic system is estimated without using 1 Research for this paper was supported by NSF Grant Soc-76-02482. Lars Hansen executed the computations. The paper has benefited from comments by many people, especially Thomas J. Sargent","['Economics', 'Keynesian economics', 'Macroeconomics']","econometric analysis, macroeconomics, macroeconomic models, business cycle, aggregate measures, economic, macroeconomics, macroeconomic, ##al fluctuations, statistical, macro, macroeconomics"
Paper_00959,Understanding Media: The Extensions of Man,"['Stuart Levine', 'Marshall McLuhan']",1964,American Quarterly,Journal,,646-646,16,4,10.2307/2711172,"This reissue of Understanding Media marks thirtieth anniversary (1964-1994) of Marshall McLuhan's classic expose on state of then emerging phenomenon of mass media. Terms and phrases such as the global village and the medium is message are now part of lexicon, and McLuhan's theories continue to challenge our sensibilities and our assumptions about how and what we communicate. There has been a notable resurgence of interest in McLuhan's work in last few years, fueled by recent and continuing conjunctions between cable companies and regional phone companies, appearance of magazines such as WiRed, and development of new media models and information ecologies, many of which were spawned from MIT's Media Lab. In effect, media now begs to be redefined. In a new introduction to this edition of Understanding Media, Harper's editor Lewis Lapham reevaluates McLuhan's work in light of technological as well as political and social changes that have occurred in last part of this century.","['Sociology', 'Art']","understanding media, mass media, global village, cable companies, regional phone companies, wired, information ecologies, media lab, understanding, [PAD], [PAD]"
Paper_00961,From dissertation abstracts international,[],1974,ACM SIGGRAPH Computer Graphics,Journal,,27-28,8,4,10.1145/988616.988619,"In the following are the graphics related Ph.D. dissertation abstracts that appeared in the January 74 thru October 74 issues of Dissertation Abstracts International. The complete dissertations are available on microfilm or xerographic copies from Xerox University Microfilm; Dissertation copies, P.O. Box 1764, Ann Arbor, Mich., 48106. Standard charge for any microfilmed dissertation is $4.00 and for xerography $10.00 plus shipping, handling, taxes and a possible charge for illustration that cannot be xerographically reproduced. Order by &lt;u&gt;publication number&lt;/u&gt; and &lt;u&gt;author's name&lt;/u&gt; and specify kind of copy wanted (mocrifilm or xerography).","['Microform', 'Library science', 'Computer graphics (images)', 'Order (exchange)', 'Graphics', 'Engineering', 'Operations research', 'Computer science', 'Business', 'Finance']","graphics, dissertation abstracts international, xerox university microfilm, ##ero, mocrifilm, xerography"
Paper_00962,No free lunch theorems for optimization,"['David H. Wolpert', 'William G. Macready']",1997,IEEE Transactions on Evolutionary Computation,Journal,,67-82,1,1,10.1109/4235.585893,"A framework is developed to explore the connection between effective optimization algorithms and the problems they are solving. A number of ""no free lunch"" (NFL) theorems are presented which establish that for any algorithm, any elevated performance over one class of problems is offset by performance over another class. These theorems result in a geometric interpretation of what it means for an algorithm to be well suited to an optimization problem. Applications of the NFL theorems to information-theoretic aspects of optimization and benchmark measures of performance are also presented. Other issues addressed include time-varying optimization problems and a priori ""head-to-head"" minimax distinctions between optimization algorithms, distinctions that result despite the NFL theorems' enforcing of a type of uniformity over all algorithms.","['Minimax', 'Optimization problem', 'Mathematical optimization', 'Class (philosophy)', 'A priori and a posteriori', 'Mathematics', 'Interpretation (philosophy)', 'Computer science', 'L-reduction', 'Algorithm', 'Continuous optimization', 'Artificial intelligence', 'Multi-swarm optimization', 'Philosophy', 'Epistemology', 'Programming language']","effective optimization algorithms, benchmark measures, optimization algorithms"
Paper_00963,Gene Expression Omnibus: NCBI gene expression and hybridization array data repository,['Ron Edgar'],2002,Nucleic Acids Research,Journal,,207-210,30,1,10.1093/nar/30.1.207,"The Gene Expression Omnibus (GEO) project was initiated in response to the growing demand for a public repository for high-throughput gene expression data. GEO provides a flexible and open design that facilitates submission, storage and retrieval of heterogeneous data sets from high-throughput gene expression and genomic hybridization experiments. GEO is not intended to replace in house gene expression databases that benefit from coherent data sets, and which are constructed to facilitate a particular analytic method, but rather complement these by acting as a tertiary, central data distribution hub. The three central data entities of GEO are platforms, samples and series, and were designed with gene expression and genomic hybridization experiments in mind. A platform is, essentially, a list of probes that define what set of molecules may be detected. A sample describes the set of molecules that are being probed and references a single platform used to generate its molecular abundance data. A series organizes samples into the meaningful data sets which make up an experiment. The GEO repository is publicly accessible through the World Wide Web at http://www.ncbi.nlm.nih.gov/geo.","['Biology', 'Computational biology', 'Set (abstract data type)', 'Expression (computer science)', 'Gene expression', 'Data set', 'Gene', 'Gene expression profiling', 'Genomics', 'Database', 'Data mining', 'Computer science', 'Genetics', 'Bioinformatics', 'Genome', 'Artificial intelligence', 'Programming language']","gene expression omnibus, geo, heterogen, genomic hybridization experiments, geo, gene expression databases, genomic, molecular abundance"
Paper_00965,A Paradigm for Developing Better Measures of Marketing Constructs,['Gilbert A. Churchill'],1979,Journal of Marketing Research,Journal,,64-64,16,1,10.2307/3150876,"A critical element in the evolution of a fundamental body of knowledge in marketing, as well as for improved marketing practice, is the development of better measures of the variables with which ma...","['Marketing', 'Business', 'Computer science', 'Psychology', 'Econometrics', 'Economics']","marketing, marketing practice"
Paper_00968,Reaction Kinetics in Differential Thermal Analysis,['H.E. Kissinger'],1957,Analytical Chemistry,Journal,,1702-1706,29,11,10.1021/ac60131a045,"ADVERTISEMENT RETURN TO ISSUEPREVArticleNEXTReaction Kinetics in Differential Thermal AnalysisH. E. KissingerCite this: Anal. Chem. 1957, 29, 11, 1702–1706Publication Date (Print):November 1, 1957Publication History Published online1 May 2002Published inissue 1 November 1957https://pubs.acs.org/doi/10.1021/ac60131a045https://doi.org/10.1021/ac60131a045research-articleACS PublicationsRequest reuse permissionsArticle Views23157Altmetric-Citations10930LEARN ABOUT THESE METRICSArticle Views are the COUNTER-compliant sum of full text article downloads since November 2008 (both PDF and HTML) across all institutions and individuals. These metrics are regularly updated to reflect usage leading up to the last few days.Citations are the number of other articles citing this article, calculated by Crossref and updated daily. Find more information about Crossref citation counts.The Altmetric Attention Score is a quantitative measure of the attention that a research article has received online. Clicking on the donut icon will load a page at altmetric.com with additional details about the score and the social media presence for the given article. Find more information on the Altmetric Attention Score and how the score is calculated. Share Add toView InAdd Full Text with ReferenceAdd Description ExportRISCitationCitation and abstractCitation and referencesMore Options Share onFacebookTwitterWechatLinked InRedditEmail Other access optionsGet e-Alertsclose Get e-Alerts","['Citation', 'Icon', 'Computer science', 'Social media', 'Altmetrics', 'Information retrieval', 'Library science', 'World Wide Web', 'Programming language']","##varticlenextreaction kinetics, differential thermal analysis, permissionsarticle views, ##le, cross, ##f, altmetric attention score, social media, altmetric attention score, ##d, ##citation, abstract, ##ation"
Paper_00969,Language Models are Few-Shot Learners,"['T. B. Brown', 'Benjamin F. Mann', 'Nick Ryder', 'Melanie Subbiah', 'Jared Kaplan', 'Prafulla Dhariwal', 'Arvind Neelakantan', 'Pranav Shyam', 'Girish Sastry', 'Amanda Askell', 'Sandhini Agarwal', 'Ariel Herbert-Voss', 'Gretchen Krueger', 'Tom Henighan', 'Rewon Child', 'Aditya Ramesh', 'Daniel M. Ziegler', 'Jeffrey C.S. Wu', 'Clemens Winter', 'Christopher Hesse', 'Mark Chen', 'Eric J. Sigler', 'Mateusz Litwin', 'Scott Gray', 'Benjamin Chess', 'Jack A. Clark', 'Christopher Berner', 'Sam McCandlish', 'Alec Radford', 'Ilya Sutskever', 'Dario Amodei']",2020,arXiv (Cornell University),Unknown,,,,,10.48550/arxiv.2005.14165,"Recent work has demonstrated substantial gains on many NLP tasks and benchmarks by pre-training on a large corpus of text followed by fine-tuning on a specific task. While typically task-agnostic in architecture, this method still requires task-specific fine-tuning datasets of thousands or tens of thousands of examples. By contrast, humans can generally perform a new language task from only a few examples or from simple instructions - something which current NLP systems still largely struggle to do. Here we show that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even reaching competitiveness with prior state-of-the-art fine-tuning approaches. Specifically, we train GPT-3, an autoregressive language model with 175 billion parameters, 10x more than any previous non-sparse language model, and test its performance in the few-shot setting. For all tasks, GPT-3 is applied without any gradient updates or fine-tuning, with tasks and few-shot demonstrations specified purely via text interaction with the model. GPT-3 achieves strong performance on many NLP datasets, including translation, question-answering, and cloze tasks, as well as several tasks that require on-the-fly reasoning or domain adaptation, such as unscrambling words, using a novel word in a sentence, or performing 3-digit arithmetic. At the same time, we also identify some datasets where GPT-3's few-shot learning still struggles, as well as some datasets where GPT-3 faces methodological issues related to training on large web corpora. Finally, we find that GPT-3 can generate samples of news articles which human evaluators have difficulty distinguishing from articles written by humans. We discuss broader societal impacts of this finding and of GPT-3 in general.","['Computer science', 'Task (project management)', 'Language model', 'Natural language processing', 'Sentence', 'Artificial intelligence', 'Word (group theory)', 'Simple (philosophy)', 'Linguistics', 'Philosophy', 'Management', 'Epistemology', 'Economics']","##p, gp, autoregressive language model, sparse, cl, news"
Paper_00972,Click Chemistry: Diverse Chemical Function from a Few Good Reactions,"['Hartmuth C. Kolb', 'M. G. Finn', 'K. Barry Sharpless']",2001,Angewandte Chemie International Edition,Journal,,2004-2021,40,11,10.1002/1521-3773(20010601)40:11<2004::aid-anie2004>3.0.co;2-5,"Examination of nature's favorite molecules reveals a striking preference for making carbon–heteroatom bonds over carbon–carbon bonds—surely no surprise given that carbon dioxide is nature's starting material and that most reactions are performed in water. Nucleic acids, proteins, and polysaccharides are condensation polymers of small subunits stitched together by carbon–heteroatom bonds. Even the 35 or so building blocks from which these crucial molecules are made each contain, at most, six contiguous C−C bonds, except for the three aromatic amino acids. Taking our cue from nature's approach, we address here the development of a set of powerful, highly reliable, and selective reactions for the rapid synthesis of useful new compounds and combinatorial libraries through heteroatom links (C−X−C), an approach we call ""click chemistry"". Click chemistry is at once defined, enabled, and constrained by a handful of nearly perfect ""spring-loaded"" reactions. The stringent criteria for a process to earn click chemistry status are described along with examples of the molecular frameworks that are easily made using this spartan, but powerful, synthetic strategy.","['Heteroatom', 'Click chemistry', 'Chemistry', 'Molecule', 'Combinatorial chemistry', 'Polymer', 'Polymer science', 'Organic chemistry', 'Carbon fibers', 'Materials science', 'Ring (chemistry)', 'Composite material', 'Composite number']","##ato, nucleic, polysaccharides, condensation polymers, aromatic amino acids, combinatorial libraries, heteroatom links, click chemistry, click chemistry, click"
Paper_00973,First principles methods using CASTEP,"['Stewart J. Clark', 'Matthew Segall', 'Chris J. Pickard', 'P. J. Hasnip', 'Matt Probert', 'Keith Refson', 'M. C. Payne']",2005,Zeitschrift für Kristallographie - Crystalline Materials,Journal,,567-570,220,5-6,10.1524/zkri.220.5.567.65075,"Abstract The CASTEP code for first principles electronic structure calculations will be described. A brief, non-technical overview will be given and some of the features and capabilities highlighted. Some features which are unique to CASTEP will be described and near-future development plans outlined.","['CASTEP', 'Code (set theory)', 'Computer science', 'Programming language', 'Density functional theory', 'Computational chemistry', 'Chemistry', 'Set (abstract data type)']","castep, first principles electronic structure calculations, castep"
Paper_00974,On the Origin of Cancer Cells,['Otto Warbürg'],1956,Science,Journal,,309-314,123,3191,10.1126/science.123.3191.309,"2,9569,249MetricsTotal Downloads2,956Last 6 Months581Last 12 Months1,079Total Citations9,249Last 6 Months365Last 12 Months686View all metrics","['Cancer', 'Cancer cell', 'Biology', 'Computational biology', 'Chemistry', 'Genetics']","##metricstotal downloads, ##total citations, [PAD] [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD] [PAD] [PAD], [PAD], [PAD], [PAD] [PAD], [PAD], [PAD], [PAD], [PAD]"
Paper_00976,Theory of Superconductivity,"['J. Bardeen', 'Leon N. Cooper', 'J. R. Schrieffer']",1957,Physical Review,Journal,,1175-1204,108,5,10.1103/physrev.108.1175,"A theory of superconductivity is presented, based on the fact that the interaction between electrons resulting from virtual exchange of phonons is attractive when the energy difference between the electrons states involved is less than the phonon energy, $\ensuremath{\hbar}\ensuremath{\omega}$. It is favorable to form a superconducting phase when this attractive interaction dominates the repulsive screened Coulomb interaction. The normal phase is described by the Bloch individual-particle model. The ground state of a superconductor, formed from a linear combination of normal state configurations in which electrons are virtually excited in pairs of opposite spin and momentum, is lower in energy than the normal state by amount proportional to an average ${(\ensuremath{\hbar}\ensuremath{\omega})}^{2}$, consistent with the isotope effect. A mutually orthogonal set of excited states in one-to-one correspondence with those of the normal phase is obtained by specifying occupation of certain Bloch states and by using the rest to form a linear combination of virtual pair configurations. The theory yields a second-order phase transition and a Meissner effect in the form suggested by Pippard. Calculated values of specific heats and penetration depths and their temperature variation are in good agreement with experiment. There is an energy gap for individual-particle excitations which decreases from about $3.5k{T}_{c}$ at $T=0\ifmmode^\circ\else\textdegree\fi{}$K to zero at ${T}_{c}$. Tables of matrix elements of single-particle operators between the excited-state superconducting wave functions, useful for perturbation expansions and calculations of transition probabilities, are given.","['Physics', 'Superconductivity', 'Excited state', 'Electron', 'Condensed matter physics', 'Ground state', 'Coulomb', 'Quantum mechanics', 'BCS theory', 'Phonon', 'Atomic physics', 'Pairing']","superconductivity, virtual exchange, phonons, supercon, ##cting, repulsive screened coulomb interaction, superconductor, normal state, isotope effect, bloc, virtual pair, ##ner effect, matrix elements, perturbation expansions, transition probabilities"
Paper_00978,On a Test of Whether one of Two Random Variables is Stochastically Larger than the Other,"['H. B. Mann', 'Douglas R. Whitney']",1947,The Annals of Mathematical Statistics,Journal,,50-60,18,1,10.1214/aoms/1177730491,"Let $x$ and $y$ be two random variables with continuous cumulative distribution functions $f$ and $g$. A statistic $U$ depending on the relative ranks of the $x$'s and $y$'s is proposed for testing the hypothesis $f = g$. Wilcoxon proposed an equivalent test in the Biometrics Bulletin, December, 1945, but gave only a few points of the distribution of his statistic. Under the hypothesis $f = g$ the probability of obtaining a given $U$ in a sample of $n x's$ and $m y's$ is the solution of a certain recurrence relation involving $n$ and $m$. Using this recurrence relation tables have been computed giving the probability of $U$ for samples up to $n = m = 8$. At this point the distribution is almost normal. From the recurrence relation explicit expressions for the mean, variance, and fourth moment are obtained. The 2rth moment is shown to have a certain form which enabled us to prove that the limit distribution is normal if $m, n$ go to infinity in any arbitrary manner. The test is shown to be consistent with respect to the class of alternatives $f(x) > g(x)$ for every $x$.","['Mathematics', 'Combinatorics', 'Moment (physics)', 'Random variable', 'Statistic', 'Statistics', 'Distribution (mathematics)', 'Infinity', 'Normal distribution', 'Test statistic', 'Cumulative distribution function', 'Limit (mathematics)', 'Statistical hypothesis testing', 'Mathematical analysis', 'Probability density function', 'Physics', 'Classical mechanics']","random variables, continuous cumulative distribution functions, stat, biometrics, recurrence relation, recurrence relation, ##rth, limit distribution"
Paper_00979,The Determination of Pore Volume and Area Distributions in Porous Substances. I. Computations from Nitrogen Isotherms,"['Elliott P. Barrett', 'Leslie G. Joyner', 'Paul P. Halenda']",1951,Journal of the American Chemical Society,Journal,,373-380,73,1,10.1021/ja01145a126,"ADVERTISEMENT RETURN TO ISSUEPREVArticleNEXTThe Determination of Pore Volume and Area Distributions in Porous Substances. I. Computations from Nitrogen IsothermsElliott P. Barrett, Leslie G. Joyner, and Paul P. HalendaCite this: J. Am. Chem. Soc. 1951, 73, 1, 373–380Publication Date (Print):January 1, 1951Publication History Published online1 May 2002Published inissue 1 January 1951https://pubs.acs.org/doi/10.1021/ja01145a126https://doi.org/10.1021/ja01145a126research-articleACS PublicationsRequest reuse permissionsArticle Views22005Altmetric-Citations10643LEARN ABOUT THESE METRICSArticle Views are the COUNTER-compliant sum of full text article downloads since November 2008 (both PDF and HTML) across all institutions and individuals. These metrics are regularly updated to reflect usage leading up to the last few days.Citations are the number of other articles citing this article, calculated by Crossref and updated daily. Find more information about Crossref citation counts.The Altmetric Attention Score is a quantitative measure of the attention that a research article has received online. Clicking on the donut icon will load a page at altmetric.com with additional details about the score and the social media presence for the given article. Find more information on the Altmetric Attention Score and how the score is calculated. Share Add toView InAdd Full Text with ReferenceAdd Description ExportRISCitationCitation and abstractCitation and referencesMore Options Share onFacebookTwitterWechatLinked InRedditEmail Other access optionsGet e-Alertsclose Get e-Alerts","['Altmetrics', 'Volume (thermodynamics)', 'Citation', 'Icon', 'Computation', 'Social media', 'Computer science', 'Nitrogen', 'Information retrieval', 'Library science', 'World Wide Web', 'Chemistry', 'Physics', 'Thermodynamics', 'Algorithm', 'Programming language', 'Organic chemistry']","##var, ##e volume, area distributions, porous substances, nitrogen isotherms, permissionsarticle views, ##le, ##f, altmetric attention score, social media, altmetric, ##d, ##citation, abstract, ##ation, references"
Paper_00980,Fast unfolding of communities in large networks,"['Vincent D. Blondel', 'Jean‐Loup Guillaume', 'Renaud Lambiotte', 'Etienne Lefebvre']",2008,Journal of Statistical Mechanics Theory and Experiment,Journal,,P10008-P10008,2008,10,10.1088/1742-5468/2008/10/p10008,"We propose a simple method to extract the community structure of large networks. Our method is a heuristic method that is based on modularity optimization. It is shown to outperform all other known community detection methods in terms of computation time. Moreover, the quality of the communities detected is very good, as measured by the so-called modularity. This is shown first by identifying language communities in a Belgian mobile phone network of 2 million customers and by analysing a web graph of 118 million nodes and more than one billion links. The accuracy of our algorithm is also verified on ad hoc modular networks.","['Modularity (biology)', 'Computer science', 'Heuristic', 'Computation', 'Modular design', 'Simple (philosophy)', 'Graph', 'Mobile phone', 'Community structure', 'Phone', 'Theoretical computer science', 'Distributed computing', 'Data science', 'Data mining', 'Artificial intelligence', 'Algorithm', 'Telecommunications', 'Mathematics', 'Philosophy', 'Linguistics', 'Genetics', 'Epistemology', 'Combinatorics', 'Biology', 'Operating system']","community structure, heuristic method, modularity optimization, community detection methods, computation time, modularity, language communities, belgian mobile phone network, web graph, ad hoc modular networks, [PAD] [PAD], [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD], [PAD] [PAD], [PAD] [PAD] [PAD] [PAD], [PAD] [PAD], [PAD] [PAD], [PAD], [PAD] [PAD] [PAD] [PAD], [PAD] [PAD]"
Paper_00981,A Mathematical Theory of Evidence,['Glenn Shafer'],2020,Unknown,Unknown,,,,,10.2307/j.ctv10vm1qb,"Both in science and in practical affairs we reason by combining facts only inconclusively supported by evidence. Building on an abstract understanding of this process of combination, this book constructs a new theory of epistemic probability. The theory draws on the work of A. P. Dempster but diverges from Depster's viewpoint by identifying his as epistemic probabilities and taking his rule for combining upper and lower as fundamental. The book opens with a critique of the well-known Bayesian theory of epistemic probability. It then proceeds to develop an alternative to the additive set functions and the rule of conditioning of the Bayesian theory: set functions that need only be what Choquet called monotone of order of infinity. and Dempster's rule for combining such set functions. This rule, together with the idea of weights of evidence, leads to both an extensive new theory and a better understanding of the Bayesian theory. The book concludes with a brief treatment of statistical inference and a discussion of the limitations of epistemic probability. Appendices contain mathematical proofs, which are relatively elementary and seldom depend on mathematics more advanced that the binomial theorem.","['Econometrics', 'Computer science', 'Mathematics', 'Mathematical economics']","epistemic probability, epistemic probabilities, bay, epistemic probability, additive set functions, bayesian, set functions, monotone, weights of evidence, bayesian theory, statistical inference, epistemic probability, mathematical proofs, binomial theorem"
Paper_00983,Apoptosis: A Review of Programmed Cell Death,['Susan A. Elmore'],2007,Toxicologic Pathology,Journal,,495-516,35,4,10.1080/01926230701320337,"The process of programmed cell death, or apoptosis, is generally characterized by distinct morphological characteristics and energy-dependent biochemical mechanisms. Apoptosis is considered a vital component of various processes including normal cell turnover, proper development and functioning of the immune system, hormone-dependent atrophy, embryonic development and chemical-induced cell death. Inappropriate apoptosis (either too little or too much) is a factor in many human conditions including neurodegenerative diseases, ischemic damage, autoimmune disorders and many types of cancer. The ability to modulate the life or death of a cell is recognized for its immense therapeutic potential. Therefore, research continues to focus on the elucidation and analysis of the cell cycle machinery and signaling pathways that control cell cycle arrest and apoptosis. To that end, the field of apoptosis research has been moving forward at an alarmingly rapid rate. Although many of the key apoptotic proteins have been identified, the molecular mechanisms of action or inaction of these proteins remain to be elucidated. The goal of this review is to provide a general overview of current knowledge on the process of apoptosis including morphology, biochemistry, the role of apoptosis in health and disease, detection methods, as well as a discussion of potential alternative forms of apoptosis.","['Apoptosis', 'Programmed cell death', 'Biology', 'Cell cycle', 'Cell biology', 'Cell', 'UVB-induced apoptosis', 'Embryonic stem cell', 'Signal transduction', 'Neuroscience', 'Immunology', 'Caspase', 'Biochemistry', 'Gene']","programmed cell death, apoptosis, morphological, apoptosis, normal cell turnover, ##uro, ##erative diseases, ischemic damage, autoimmune disorders, signaling pathways, apoptosis, apoptosis, apoptotic, ##optosis, biochemistry, apoptosis, ##optosis"
Paper_00984,Are we ready for autonomous driving? The KITTI vision benchmark suite,"['Andreas Geiger', 'P Lenz', 'R. Urtasun']",2012,2009 IEEE Conference on Computer Vision and Pattern Recognition,Conference,"2012 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Providence, RI",3354-3361,,,10.1109/cvpr.2012.6248074,"Today, visual recognition systems are still rarely employed in robotics applications. Perhaps one of the main reasons for this is the lack of demanding benchmarks that mimic such scenarios. In this paper, we take advantage of our autonomous driving platform to develop novel challenging benchmarks for the tasks of stereo, optical flow, visual odometry/SLAM and 3D object detection. Our recording platform is equipped with four high resolution video cameras, a Velodyne laser scanner and a state-of-the-art localization system. Our benchmarks comprise 389 stereo and optical flow image pairs, stereo visual odometry sequences of 39.2 km length, and more than 200k 3D object annotations captured in cluttered scenarios (up to 15 cars and 30 pedestrians are visible per image). Results from state-of-the-art algorithms reveal that methods ranking high on established datasets such as Middlebury perform below average when being moved outside the laboratory to the real world. Our goal is to reduce this bias by providing challenging benchmarks with novel difficulties to the computer vision community. Our benchmarks are available online at: www.cvlibs.net/datasets/kitti.","['Artificial intelligence', 'Visual odometry', 'Computer science', 'Computer vision', 'Suite', 'Benchmark (surveying)', 'Odometry', 'Robotics', 'Optical flow', 'Object detection', 'Visualization', 'Robot', 'Image (mathematics)', 'Mobile robot', 'Pattern recognition (psychology)', 'Archaeology', 'Geodesy', 'History', 'Geography']","visual recognition systems, robotics, autonomous driving platform, stereo, optical flow, 3d object detection, high resolution, velodyne laser scanner, stereo visual odometry sequences, middlebury, computer vision"
Paper_00986,Capital in the Twenty-First Century,['Thomas Piketty'],2014,Harvard University Press eBooks,Unknown,,,,,10.4159/9780674369542,"The main driver of inequality--returns on capital that exceed the rate of economic growth--is again threatening to generate extreme discontent and undermine democratic values. Thomas Piketty's findings in this ambitious, original, rigorous work will transform debate and set the agenda for the next generation of thought about wealth and inequality.","['Inequality', 'Capital (architecture)', 'Democracy', 'Work (physics)', 'Economics', 'Neoclassical economics', 'Set (abstract data type)', 'Development economics', 'Political science', 'History', 'Law', 'Engineering', 'Mathematics', 'Politics', 'Computer science', 'Mechanical engineering', 'Mathematical analysis', 'Archaeology', 'Programming language']","economic growth, democratic values, wealth"
Paper_00987,The Psychology of Interpersonal Relations.,"['Theodore M. Newcomb', 'Fritz Heider']",1958,American Sociological Review,Journal,,742-742,23,6,10.2307/2089062,"The psychology of interpersonal relations , The psychology of interpersonal relations , کتابخانه دیجیتال و فن آوری اطلاعات دانشگاه امام صادق(ع)","['Interpersonal communication', 'Psychology', 'Social psychology', 'Interpersonal relationship']","interpersonal relations, interpersonal relations"
Paper_00988,Detection of Postnatal Depression,"['J. L. Cox', 'Joan Holden', 'R. Sagovsky']",1987,The British Journal of Psychiatry,Journal,,782-786,150,6,10.1192/bjp.150.6.782,"The development of a 10-item self-report scale (EPDS) to screen for Postnatal Depression in the community is described. After extensive pilot interviews a validation study was carried out on 84 mothers using the Research Diagnostic Criteria for depressive illness obtained from Goldberg's Standardised Psychiatric Interview. The EPDS was found to have satisfactory sensitivity and specficity, and was also sensitive to change in the severity of depression over time. The scale can be completed in about 5 minutes and has a simple method of scoring. The use of the EPDS in the secondary prevention of Postnatal Depression is discussed.","['Edinburgh Postnatal Depression Scale', 'Depression (economics)', 'Psychiatry', 'Psychology', 'Clinical psychology', 'Medicine', 'Depressive symptoms', 'Anxiety', 'Economics', 'Macroeconomics']","postnatal depression, depressive illness, ##ds, secondary prevention, postnatal depression, [PAD], [PAD] [PAD] [PAD] [PAD]"
Paper_00990,Development of the Alcohol Use Disorders Identification Test (AUDIT): WHO Collaborative Project on Early Detection of Persons with Harmful Alcohol Consumption‐II,"['John B. Saunders', 'Olaf Gjerløw Aasland', 'Thomas F. Babor', 'Juan Ramón De La Fuente', 'Marcus Grant']",1993,Addiction,Journal,,791-804,88,6,10.1111/j.1360-0443.1993.tb02093.x,"Abstract The Alcohol Use Disorders Identification Test (A UDIT) has been developed from a six‐country WHO collaborative project as a screening instrument for hazardous and harmful alcohol consumption. It is a 10‐item questionnaire which covers the domains of alcohol consumption, drinking behaviour, and alcohol‐related problems. Questions were selected from a 150‐item assessment schedule (which was administered to 1888 persons attending representative primary health care facilities) on the basis of their representativeness for these conceptual domains and their perceived usefulness for intervention. Responses to each question are scored from 0 to 4, giving a maximum possible score of 40. Among those diagnosed as having hazardous or harmful alcohol use, 92% had an AUDIT score of 8 or more, and 94% of those with non‐hazardous consumption had a score of less than 8. AUDIT provides a simple method of early detection of hazardous and harmful alcohol use in primary health care settings and is the first instrument of its type to be derived on the basis of a cross‐national study.","['Alcohol Use Disorders Identification Test', 'Audit', 'Environmental health', 'Medicine', 'Test (biology)', 'Representativeness heuristic', 'Alcohol consumption', 'Hazardous waste', 'Alcohol', 'Brief intervention', 'Intervention (counseling)', 'Poison control', 'Injury prevention', 'Psychology', 'Psychiatry', 'Social psychology', 'Engineering', 'Business', 'Paleontology', 'Biochemistry', 'Chemistry', 'Accounting', 'Biology', 'Waste management']","alcohol use disorders identification test, udit, alcohol consumption, drinking behaviour, alcohol ‐, audit, hazardous, primary health care settings"
Paper_00995,Palladium-Catalyzed Cross-Coupling Reactions of Organoboron Compounds,"['Norio Miyaura', 'Akira Suzuki']",1995,Chemical Reviews,Journal,,2457-2483,95,7,10.1021/cr00039a007,"ADVERTISEMENT RETURN TO ISSUEPREVArticleNEXTPalladium-Catalyzed Cross-Coupling Reactions of Organoboron CompoundsNorio. Miyaura and Akira. SuzukiCite this: Chem. Rev. 1995, 95, 7, 2457–2483Publication Date (Print):November 1, 1995Publication History Published online1 May 2002Published inissue 1 November 1995https://pubs.acs.org/doi/10.1021/cr00039a007https://doi.org/10.1021/cr00039a007research-articleACS PublicationsRequest reuse permissionsArticle Views90442Altmetric-Citations11246LEARN ABOUT THESE METRICSArticle Views are the COUNTER-compliant sum of full text article downloads since November 2008 (both PDF and HTML) across all institutions and individuals. These metrics are regularly updated to reflect usage leading up to the last few days.Citations are the number of other articles citing this article, calculated by Crossref and updated daily. Find more information about Crossref citation counts.The Altmetric Attention Score is a quantitative measure of the attention that a research article has received online. Clicking on the donut icon will load a page at altmetric.com with additional details about the score and the social media presence for the given article. Find more information on the Altmetric Attention Score and how the score is calculated. Share Add toView InAdd Full Text with ReferenceAdd Description ExportRISCitationCitation and abstractCitation and referencesMore Options Share onFacebookTwitterWechatLinked InRedditEmail Other access optionsGet e-Alertsclose Get e-Alerts","['Citation', 'Icon', 'Computer science', 'World Wide Web', 'Programming language']","organoboron compounds, suzuki, permissionsar, ##le views, altmetric attention score, social, altmetric attention score, ##ation, abstract, ##ation, references"
Paper_00996,WHO Classification of Tumours of Haematopoietic and Lymphoid Tissues,['S. H. Swerdlow'],2017,['Postgraduate Haematology'],Unknown,,885-887,,,10.1002/9781118853771.ch51,"WHO CLASSIFICATION OF TUMOURS OF HAEMATOPOIETIC AND LYMPHOID TISSUES , WHO CLASSIFICATION OF TUMOURS OF HAEMATOPOIETIC AND LYMPHOID TISSUES , کتابخانه مرکزی دانشگاه علوم پزشکی تهران","['Haematopoiesis', 'Pathology', 'Lymphatic system', 'Biology', 'Medicine', 'Stem cell', 'Genetics']","tumour, ha, ##oi, l, ##phoid tissues, tumour, ha, ##oi, l, ##phoid tissues, [PAD], [PAD], [PAD], [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD], [PAD], [PAD], [PAD] [PAD] [PAD], [PAD] [PAD], [PAD], [PAD] [PAD], [PAD] [PAD] [PAD] [PAD], [PAD], [PAD], [PAD]"
Paper_00997,A new coronavirus associated with human respiratory disease in China,"['Fan Wu', 'Su Zhao', 'Bin Yu', 'Yanmei Chen', 'Wen Wang', 'Zhi-Gang Song', 'Yi Hu', 'Zhao-Wu Tao', 'Jun-Hua Tian', 'Yuan-Yuan Pei', 'Ming-Li Yuan', 'Yu-Ling Zhang', 'Fa-Hui Dai', 'Yi Liu', 'Qimin Wang', 'Jiao-Jiao Zheng', 'Lin Xu', 'Edward C. Holmes', 'Yǒng-Zhèn Zhāng']",2020,Nature,Journal,,265-269,579,7798,10.1038/s41586-020-2008-3,"Abstract Emerging infectious diseases, such as severe acute respiratory syndrome (SARS) and Zika virus disease, present a major threat to public health 1–3 . Despite intense research efforts, how, when and where new diseases appear are still a source of considerable uncertainty. A severe respiratory disease was recently reported in Wuhan, Hubei province, China. As of 25 January 2020, at least 1,975 cases had been reported since the first patient was hospitalized on 12 December 2019. Epidemiological investigations have suggested that the outbreak was associated with a seafood market in Wuhan. Here we study a single patient who was a worker at the market and who was admitted to the Central Hospital of Wuhan on 26 December 2019 while experiencing a severe respiratory syndrome that included fever, dizziness and a cough. Metagenomic RNA sequencing 4 of a sample of bronchoalveolar lavage fluid from the patient identified a new RNA virus strain from the family Coronaviridae , which is designated here ‘WH-Human 1’ coronavirus (and has also been referred to as ‘2019-nCoV’). Phylogenetic analysis of the complete viral genome (29,903 nucleotides) revealed that the virus was most closely related (89.1% nucleotide similarity) to a group of SARS-like coronaviruses (genus Betacoronavirus, subgenus Sarbecovirus) that had previously been found in bats in China 5 . This outbreak highlights the ongoing ability of viral spill-over from animals to cause severe disease in humans.","['Outbreak', 'Coronaviridae', 'Coronavirus', 'Virology', 'Medicine', 'Disease', 'Betacoronavirus', 'Novel virus', 'Epidemiology', 'Human metapneumovirus', 'Virus', 'Infectious disease (medical specialty)', 'Biology', 'Respiratory system', 'Respiratory tract infections', 'Internal medicine', 'Coronavirus disease 2019 (COVID-19)', 'Genome', 'Genetics', 'Gene']","infectious diseases, severe acute respiratory syndrome, zika virus disease, public health, severe respiratory disease, seafood market, ##zziness, metagenomic, ##nchoal, ##olar lavage fluid, corona, betacorona, sarbe"
Paper_00998,Ultrastructural Characterization of the Lower Motor System in a Mouse Model of Krabbe Disease,"['Valentina Cappello', 'Laura Marchetti', 'Paola Parlanti', 'Silvia Landi', 'Ilaria Tonazzini', 'Marco Cecchini', 'Vincenzo Piazza', 'Mauro Gemmi']",2016,Scientific Reports,Journal,,,6,1,10.1038/s41598-016-0001-8,"Abstract Krabbe disease (KD) is a neurodegenerative disorder caused by the lack of β- galactosylceramidase enzymatic activity and by widespread accumulation of the cytotoxic galactosyl-sphingosine in neuronal, myelinating and endothelial cells. Despite the wide use of Twitcher mice as experimental model for KD, the ultrastructure of this model is partial and mainly addressing peripheral nerves. More details are requested to elucidate the basis of the motor defects, which are the first to appear during KD onset. Here we use transmission electron microscopy (TEM) to focus on the alterations produced by KD in the lower motor system at postnatal day 15 (P15), a nearly asymptomatic stage, and in the juvenile P30 mouse. We find mild effects on motorneuron soma, severe ones on sciatic nerves and very severe effects on nerve terminals and neuromuscular junctions at P30, with peripheral damage being already detectable at P15. Finally, we find that the gastrocnemius muscle undergoes atrophy and structural changes that are independent of denervation at P15. Our data further characterize the ultrastructural analysis of the KD mouse model, and support recent theories of a dying-back mechanism for neuronal degeneration, which is independent of demyelination.","['Krabbe disease', 'Ultrastructure', 'Sciatic nerve', 'Denervation', 'Biology', 'Pathology', 'Neuromuscular junction', 'Cell biology', 'Neuroscience', 'Anatomy', 'Medicine', 'Disease', 'Leukodystrophy']","abstract k, ##bbe disease, ##erative disorder, peripheral nerves, transmission electron microscopy, lower motor system, ##nat, as, motor, ##uron soma, sciatic nerves, ##uromus, peripheral damage, gastro, ##ius muscle, ultrastructural analysis, ##al de, dem, ##lina"
Paper_00999,Role of Insulin Resistance in Human Disease,['Gerald M. Reaven'],1988,Diabetes,Journal,,1595-1607,37,12,10.2337/diab.37.12.1595,"Resistance to insulin-stimulated glucose uptake is present in the majority of patients with impaired glucose tolerance (IGT) or non-insulin-dependent diabetes mellitus (NIDDM) and in ∼25% of nonobese individuals with normal oral glucose tolerance. In these conditions, deterioration of glucose tolerance can only be prevented if the β-cell is able to increase its insulin secretory response and maintain a state of chronic hyperinsulinemia. When this goal cannot be achieved, gross decompensation of glucose homeostasis occurs. The relationship between insulin resistance, plasma insulin level, and glucose intolerance is mediated to a significant degree by changes in ambient plasma free-fatty acid (FFA) concentration. Patients with NIDDM are also resistant to insulin suppression of plasma FFA concentration, but plasma FFA concentrations can be reduced by relatively small increments in insulin concentration.Consequently, elevations of circulating plasma FFA concentration can be prevented if large amounts of insulin can be secreted. If hyperinsulinemia cannot be maintained, plasma FFA concentration will not be suppressed normally, and the resulting increase in plasma FFA concentration will lead to increased hepatic glucose production. Because these events take place in individuals who are quite resistant to insulinstimulated glucose uptake, it is apparent that even small increases in hepatic glucose production are likely to lead to significant fasting hyperglycemia under these conditions. Although hyperinsulinemia may prevent frank decompensation of glucose homeostasis in insulin-resistant individuals, this compensatory response of the endocrine pancreas is not without its price. Patients with hypertension, treated or untreated, are insulin resistant, hyperglycemic, and hyperinsulinemic. In addition, a direct relationship between plasma insulin concentration and blood pressure has been noted. Hypertension can also be produced in normal rats when they are fed a fructose-enriched diet, an intervention that also leads to the development of insulin resistance and hyperinsulinemia. The development of hypertension in normal rats by an experimental manipulation known to induce insulin resistance and hyperinsulinemia provides further support for the view that the relationship between the three variables may be a causal one. However, even if insulin resistance and hyperinsulinemia are not involved in the etiology of hypertension, it is likely that the increased risk of coronary artery disease (CAD) in patients with hypertension and the fact that this risk if not reduced with antihypertensive treatment are due to the clustering of risk factors for CAD, in addition to high blood pressure, associated with insulin resistance. These include hyperinsulinemia, IGT, increased plasma triglyceride concentration, and decreased high-density lipoprotein cholesterol concentration, all of which are associated with increased risk for CAD. It is likely that the same risk factors play a significant role in the genesis of CAD in the population as a whole. Based on these considerations the possibility is raised that resistance to insulin-stimulated glucose uptake and hyperinsulinemia are involved in the etiology and clinical course of three major related diseases— NIDDM, hypertension, and CAD.","['Internal medicine', 'Hyperinsulinemia', 'Endocrinology', 'Insulin resistance', 'Insulin', 'Glucose homeostasis', 'Homeostasis', 'Glucose uptake', 'Diabetes mellitus', 'Hyperinsulinism', 'Impaired glucose tolerance', 'Medicine', 'Decompensation']","impaired glucose tolerance, oral glucose tolerance, insulin secretory response, ##patic glucose production, ##ins, coronary artery disease"
Paper_01001,An Integrative Theory of Intergroup Conflict,"['Henri Tajfel', 'John Turner']",2000,Oxford University Press eBooks,Unknown,,56-65,,,10.1093/oso/9780199269464.003.0005,"Abstract The initial stimulus for the theorizing presented here was provided by certain experimental investigations of intergroup behavior. The laboratory analog of real-world ethnocentrism is in-group bias—that is, the tendency to favor the in-group over the out-group in evaluations and behavior. Not only are incompatible group interests not always sufficient to generate conflicts but there is a good deal of experimental evidence that these conditions are not always necessary for the development of competition and discrimination between groups (for example, Ferguson &amp; Kelley, 1964; Rabbie &amp; Wilkens, 1971; Doise &amp; Sinclair, 1973; Doise &amp; Weinberger, 1973).","['Ethnocentrism', 'Group conflict', 'Social psychology', 'Psychology', 'Competition (biology)', 'Stimulus (psychology)', 'Group (periodic table)', 'Cognitive psychology', 'Ecology', 'Chemistry', 'Organic chemistry', 'Biology']","intergroup behavior, discrimination, [PAD]"
Paper_01003,MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications,"['Andrew Howard', 'Menglong Zhu', 'Bo Chen', 'Dmitry Kalenichenko', 'Weijun Wang', 'Tobias Weyand', 'Marco Andreetto', 'Hartwig Adam']",2017,arXiv (Cornell University),Unknown,,,,,10.48550/arxiv.1704.04861,"We present a class of efficient models called MobileNets for mobile and embedded vision applications. MobileNets are based on a streamlined architecture that uses depth-wise separable convolutions to build light weight deep neural networks. We introduce two simple global hyper-parameters that efficiently trade off between latency and accuracy. These hyper-parameters allow the model builder to choose the right sized model for their application based on the constraints of the problem. We present extensive experiments on resource and accuracy tradeoffs and show strong performance compared to other popular models on ImageNet classification. We then demonstrate the effectiveness of MobileNets across a wide range of applications and use cases including object detection, finegrain classification, face attributes and large scale geo-localization.","['Computer science', 'Convolutional neural network', 'Latency (audio)', 'Deep neural networks', 'Artificial intelligence', 'Face (sociological concept)', 'Architecture', 'Deep learning', 'Mobile device', 'Class (philosophy)', 'Object detection', 'Simple (philosophy)', 'Range (aeronautics)', 'Scale (ratio)', 'Machine learning', 'Pattern recognition (psychology)', 'Telecommunications', 'Engineering', 'Cartography', 'Geography', 'Social science', 'Aerospace engineering', 'Sociology', 'Operating system', 'Philosophy', 'Archaeology', 'Epistemology']","mobilenets, embedded vision applications, mobilenets, streamlined architecture, light weight deep neural networks, late, accuracy, imagenet classification, mobilenets, object detection, finegrain classification, face attributes"
Paper_01005,Handbook of Industrial and Organizational Psychology.,"['Tove Helland Hammer', 'John F. Anderson', 'Michael A. Gurdon', 'Todd D. Jick', 'Andre Petit', 'Robert N. Stern', 'Howard Schwartz', 'Yoav Vardi', 'Marvin D. Dunnette']",1977,Administrative Science Quarterly,Journal,,151-151,22,1,10.2307/2391755,"An up-to-date handbook on conceptual and methodological issues relevant to the study of industrial and organizational behavior. Chapters contributed by leading experts from the academic and business communities cover substantive issues at both the individual and organizational level, in both theoretical and practical terms.","['Industrial and organizational psychology', 'Organizational behavior', 'Organization development', 'Organizational engineering', 'Cover (algebra)', 'Sociology', 'Organizational learning', 'Psychology', 'Organizational studies', 'Engineering ethics', 'Management science', 'Management', 'Knowledge management', 'Public relations', 'Political science', 'Social psychology', 'Engineering', 'Computer science', 'Economics', 'Mechanical engineering']","methodological, organizational behavior, business"
Paper_01006,Long-range corrected hybrid density functionals with damped atom–atom dispersion corrections,"['Jeng‐Da Chai', 'Martin Head‐Gordon']",2008,Physical Chemistry Chemical Physics,Journal,,6615-6615,10,44,10.1039/b810189b,"We report re-optimization of a recently proposed long-range corrected (LC) hybrid density functional [J.-D. Chai and M. Head-Gordon, J. Chem. Phys., 2008, 128, 084106] to include empirical atom–atom dispersion corrections. The resulting functional, ωB97X-D yields satisfactory accuracy for thermochemistry, kinetics, and non-covalent interactions. Tests show that for non-covalent systems, ωB97X-D shows slight improvement over other empirical dispersion-corrected density functionals, while for covalent systems and kinetics it performs noticeably better. Relative to our previous functionals, such as ωB97X, the new functional is significantly superior for non-bonded interactions, and very similar in performance for bonded interactions.","['Thermochemistry', 'Atom (system on chip)', 'Dispersion (optics)', 'Range (aeronautics)', 'Covalent bond', 'Density functional theory', 'Chemistry', 'Atomic physics', 'Molecular physics', 'Thermodynamics', 'Computational chemistry', 'Physics', 'Materials science', 'Quantum mechanics', 'Physical chemistry', 'Computer science', 'Composite material', 'Embedded system']","hybrid density functional, atom dispersion corrections, the, covalent, ##valent, ##valent, kinetics, ##9, - bonded, bonded interactions"
Paper_01010,The Metabolic and Molecular Bases of Inherited Disease,['R Charles Scriver'],1995,['Molecular Pathology'],Unknown,,279-279,50,5,10.1136/mp.50.5.279-b,I. INTRODUCTION II. PERSPECTIVES III. GENERAL THEMES IV. CANCER V. CHROMOSOMES VI. DIAGNOSTIC APPROACHES VII. CARBOHYDRATES VIII. AMINO ACIDS IX. ORGANIC ACIDS X. DISORDERS OF MITOCHONDRIAL FUNCTION XI. PURINES AND PYRIMIDINES XII. LIPIDS XIII. PORPHYRINS XIV. METALS XV. PEROXISOMES XVI. LYSOSOMAL DISORDERS XVII. VITAMINS XVIII. HORMONES XIX. BLOOD XX. IMMUNE AND DEFENSE SYSTEMS XXI. MEMBRANE TRANSPORT DISORDERS XXII. CONNECTIVE TISSUE XXIII. CARDIOVASCULAR SYSTEM XXIV. KIDNEY XXV. MUSCLE XXVI. LUNG XXVII. SKIN XXVIII. NEUROGENETICS XXIX. EYE XXX. MULTISYSTEM INBORN ERRORS OF DEVELOPMENT,"['Purine metabolism', 'Chemistry', 'Dermatomyositis', 'Biochemistry', 'Biology', 'Medicine', 'Internal medicine', 'Enzyme']","diagnostic approaches, carbohydrates, amino acids, organic acids, mitochondrial function, purine, ##yrimidine, lipids, por, peroxiso, lysosomal disorders, vitamin, membrane transport disorders, connective tissue, cardiovascular system, kidney, muscle, lung, skin, neurogenetic, eye, multisystem inborn errors, [PAD]"
Paper_01011,Politeness: Some Universals in Language Usage,"['Penelope Brown', 'Stephen C. Levinson']",1987,['STUF - Language Typology and Universals'],Unknown,,135-135,42,1,10.1515/stuf-1989-0124,"This study is about the principles for constructing polite speeches. The core of it first appeared in Questions and Politeness, edited by Esther N. Goody (now out of print). It is here reissued with a fresh introduction that surveys the considerable literature in linguistics, psychology and the social sciences that the original extended essay stimulated, and suggests distinct directions for research. The authors describe and account for some remarkable parallelisms in the linguistic construction of utterances with which people express themselves in different languages and cultures. A motive for these parallels is isolated and a universal model is constructed outlining the abstract principles underlying polite usages. This is based on the detailed study of three unrelated languages and cultures: the Tamil of South India, the Tzeltal spoken by Mayan Indians in Chiapas, Mexico, and the English of the USA and England. This volume will be of special interest to students in linguistic pragmatics, sociolinguistics, applied linguistics, anthropology, and the sociology and social psychology of interaction.","['Politeness', 'Linguistics', 'Problem of universals', 'Sociolinguistics', 'Tamil', 'Pragmatics', 'Sociology', 'Linguistic universal', 'Sociocultural linguistics', 'Parallels', 'Politeness maxims', 'Contrastive linguistics', 'Applied linguistics', 'Theoretical linguistics', 'Philosophy', 'Mechanical engineering', 'Engineering']","polite speeches, questions, politeness, linguistics, psychology, social sciences, polite usages, tamil, ##zeltal, english, linguistic pragmatics, sociolinguistics, applied linguistics, anthropology, social psychology, interaction"
Paper_01012,Building theories from case study research,['Kathleen M. Eisenhardt'],2009,STUDI ORGANIZZATIVI,Journal,,,,2,10.3280/so2008-002004,"- This paper describes the process of inducting theory using case studies from specifying the research questions to reaching closure. Some features of the process, such as problem definition and construct validation, are similar to hypothesis-testing research. Others, such as within-case analysis and replication logic, are unique to the inductive, case-oriented process. Overall, the process described here is highly iterative and tightly linked to data. This research approach is especially appropriate in new topic areas. The resultant theory is often novel, testable, and empirically valid. Finally, framebreaking insights, the tests of good theory (e.g., parsimony, logical coherence), and convincing grounding in the evidence are the key criteria for evaluating this type of research.","['Computer science', 'Construct (python library)', 'Process (computing)', 'Closure (psychology)', 'Coherence (philosophical gambling strategy)', 'Key (lock)', 'Iterative and incremental development', 'Development theory', 'Process theory', 'Management science', 'Theoretical computer science', 'Data science', 'Mathematics', 'Programming language', 'Software engineering', 'Work in process', 'Engineering', 'Statistics', 'Operations management', 'Computer security', 'Economics', 'Market economy']","case studies, problem definition, construct validation, replication logic, framebreak, parsimony, logical coherence, [PAD]"
Paper_01013,Observation of Gravitational Waves from a Binary Black Hole Merger,"['B. P. Abbott', 'R. Abbott', 'T. D. Abbott', 'M. R. Abernathy', 'F. Acernese', 'K. Ackley', 'C. Adams', 'T. Adams', 'P. Addesso', 'R. X. Adhikari', 'V. B. Adya', 'C. Affeldt', 'M. Agathos', 'K. Agatsuma', 'N. Aggarwal', 'O. D. Aguiar', 'L. Aiello', 'A. Ain', 'P. Ajith', 'B. Allen', 'A. Allocca', 'P. A. Altin', 'S. B. Anderson', 'W. G. Anderson', 'K. Arai', 'M. A. Arain', 'M. C. Araya', 'C. C. Arceneaux', 'J. S. Areeda', 'N. Arnaud', 'K. G. Arun', 'S. Ascenzi', 'G. Ashton', 'M. Ast', 'S. M. Aston', 'P. Astone', 'P. Aufmuth', 'C. Aulbert', 'S. Babak', 'P. Bacon', 'M. K. M. Bader', 'P. T. Baker', 'F. Baldaccini', 'G. Ballardin', 'S. W. Ballmer', 'J. C. Barayoga', 'S. E. Barclay', 'B. C. Barish', 'D. Barker', 'F. Barone', 'B. Barr', 'L. Barsotti', 'M. Barsuglia', 'D. Barta', 'J. Bartlett', 'M. A. Barton', 'I. Bartos', 'R. Bassiri', 'A. Basti', 'J. C. Batch', 'C. Baune', 'V. Bavigadda', 'M. Bazzan', 'B. Behnke', 'M. Bejger', 'Krzysztof Belczyński', 'A. S. Bell', 'C. Bell', 'B. K. Berger', 'J. Bergman', 'G. Bergmann', 'C. P. L. Berry', 'D. Bersanetti', 'A. Bertolini', 'J. Betzwieser', 'S. Bhagwat', 'R. Bhandare', 'I. A. Bilenko', 'G. Billingsley', 'J. Birch', 'R. Birney', 'O. Birnholtz', 'S. Biscans', 'A. Bisht', 'M. Bitossi', 'C. Biwer', 'M. A. Bizouard', 'J. K. Blackburn', 'C. D. Blair', 'D. G. Blair', 'R. M. Blair', 'S. Bloemen', 'O. Bock', 'T. P. Bodiya', 'M. Boër', 'G. Bogaert', 'C. Bogan', 'A. Bohé', 'P. Bojtos', 'C. Bond']",2016,Physical Review Letters,Journal,,,116,6,10.1103/physrevlett.116.061102,"On September 14, 2015 at 09:50:45 UTC the two detectors of the Laser Interferometer Gravitational-Wave Observatory simultaneously observed a transient gravitational-wave signal. The signal sweeps upwards in frequency from 35 to 250 Hz with a peak gravitational-wave strain of 1.0×10(-21). It matches the waveform predicted by general relativity for the inspiral and merger of a pair of black holes and the ringdown of the resulting single black hole. The signal was observed with a matched-filter signal-to-noise ratio of 24 and a false alarm rate estimated to be less than 1 event per 203,000 years, equivalent to a significance greater than 5.1σ. The source lies at a luminosity distance of 410(-180)(+160) Mpc corresponding to a redshift z=0.09(-0.04)(+0.03). In the source frame, the initial black hole masses are 36(-4)(+5)M⊙ and 29(-4)(+4)M⊙, and the final black hole mass is 62(-4)(+4)M⊙, with 3.0(-0.5)(+0.5)M⊙c(2) radiated in gravitational waves. All uncertainties define 90% credible intervals. These observations demonstrate the existence of binary stellar-mass black hole systems. This is the first direct detection of gravitational waves and the first observation of a binary black hole merger.","['Gravitational wave', 'Physics', 'Binary number', 'Binary black hole', 'Black hole (networking)', 'Astrophysics', 'Astronomy', 'Classical mechanics', 'Computer science', 'Arithmetic', 'Mathematics', 'Computer network', 'Routing protocol', 'Routing (electronic design automation)', 'Link-state routing protocol']","laser interfer, general relativity, false alarm rate, lu, ##osity distance, reds, black hole masses, gravitational, credible intervals, gravitational waves, binary black hole merger"
Paper_01015,Simultaneous Inference in General Parametric Models,"['Torsten Hothorn', 'Frank Bretz', 'Peter H. Westfall']",2008,Biometrical Journal,Journal,,346-363,50,3,10.1002/bimj.200810425,"Simultaneous inference is a common problem in many areas of application. If multiple null hypotheses are tested simultaneously, the probability of rejecting erroneously at least one of them increases beyond the pre-specified significance level. Simultaneous inference procedures have to be used which adjust for multiplicity and thus control the overall type I error rate. In this paper we describe simultaneous inference procedures in general parametric models, where the experimental questions are specified through a linear combination of elemental model parameters. The framework described here is quite general and extends the canonical theory of multiple comparison procedures in ANOVA models to linear regression problems, generalized linear models, linear mixed effects models, the Cox model, robust linear models, etc. Several examples using a variety of different statistical models illustrate the breadth of the results. For the analyses we use the R add-on package multcomp, which provides a convenient interface to the general approach adopted here.","['Inference', 'Linear model', 'Parametric statistics', 'Generalized linear model', 'Statistical inference', 'General linear model', 'Mathematics', 'Linear regression', 'Computer science', 'Algorithm', 'Applied mathematics', 'Statistics', 'Artificial intelligence']","simultaneous inference, simultaneous inference procedures, simultaneous inference procedures, parametric models, elemental model, multiple comparison procedures, anova models, linear regression problems, generalized linear models, linear mixed effects models, cox model, robust linear models, multcomp, [PAD], [PAD], [PAD], [PAD] [PAD], [PAD] [PAD], [PAD]"
Paper_01018,Consensus Problems in Networks of Agents With Switching Topology and Time-Delays,"['R. Olfati-Saber', 'Richard M. Murray']",2004,IEEE Transactions on Automatic Control,Journal,,1520-1533,49,9,10.1109/tac.2004.834113,"In this paper, we discuss consensus problems for networks of dynamic agents with fixed and switching topologies. We analyze three cases: 1) directed networks with fixed topology; 2) directed networks with switching topology; and 3) undirected networks with communication time-delays and fixed topology. We introduce two consensus protocols for networks with and without time-delays and provide a convergence analysis in all three cases. We establish a direct connection between the algebraic connectivity (or Fiedler eigenvalue) of the network and the performance (or negotiation speed) of a linear consensus protocol. This required the generalization of the notion of algebraic connectivity of undirected graphs to digraphs. It turns out that balanced digraphs play a key role in addressing average-consensus problems. We introduce disagreement functions for convergence analysis of consensus protocols. A disagreement function is a Lyapunov function for the disagreement network dynamics. We proposed a simple disagreement function that is a common Lyapunov function for the disagreement dynamics of a directed network with switching topology. A distinctive feature of this work is to address consensus problems for networks with directed information flow. We provide analytical tools that rely on algebraic graph theory, matrix theory, and control theory. Simulations are provided that demonstrate the effectiveness of our theoretical results.","['Algebraic graph theory', 'Network topology', 'Algebraic connectivity', 'Topology (electrical circuits)', 'Uniform consensus', 'Computer science', 'Consensus', 'Lyapunov function', 'Function (biology)', 'Convergence (economics)', 'Directed graph', 'Mathematics', 'Graph theory', 'Multi-agent system', 'Theoretical computer science', 'Graph', 'Laplacian matrix', 'Algorithm', 'Artificial intelligence', 'Combinatorics', 'Physics', 'Nonlinear system', 'Quantum mechanics', 'Evolutionary biology', 'Economics', 'Biology', 'Economic growth', 'Operating system']","consensus problems, dynamic agents, switching, directed networks, fixed topology, directed networks, switching topology, undirected networks, fixed topology, consensus protocols, convergence analysis, algebraic connectivity, negotiation speed, linear consensus protocol, algebraic connectivity, undirected graphs, dig, ##s, balanced digraphs, disagreement functions, convergence analysis, consensus protocols, disagreement function, lyapunov function, disagreement network dynamics, disagreement function, lya, ##nov function, disagreement dynamics, directed network, switching topology, consensus problems, directed information flow, algebraic graph theory, matrix theory, control theory"
Paper_01021,Asymptotic Confidence Intervals for Indirect Effects in Structural Equation Models,['Michael E. Sobel'],1982,Sociological Methodology,Journal,,290-290,13,,10.2307/270723,"For comments on an earlier draft of this chapter and for detailed advice I am indebted to Robert M. Hauser, Halliman H. Winsborough, and Toni Richards, several anonymous reviewers, and the editor of this volume. I also wish to thank John Raisian, Nancy Rytina, and Barbara Mann for their comments and Mark Wilson for able research assistance. The opinions expressed here are the sole responsibility of the author.","['Structural equation modeling', 'Confidence interval', 'Statistics', 'Mathematics', 'Econometrics', 'Applied mathematics']",
Paper_01022,WordNet: An Electronic Lexical Database,"['Adam Kilgarriff', 'Christiane Fellbaum']",2000,Language,Journal,,706-706,76,3,10.2307/417141,"Part 1 The lexical database: nouns in WordNet, George A. Miller modifiers in WordNet, Katherine J. Miller a semantic network of English verbs, Christiane Fellbaum design and implementation of the WordNet lexical database and searching software, Randee I. Tengi. Part 2: automated discovery of WordNet relations, Marti A. Hearst representing verb alterations in WordNet, Karen T. Kohl et al the formalization of WordNet by methods of relational concept analysis, Uta E. Priss. Part 3 Applications of WordNet: building semantic concordances, Shari Landes et al performance and confidence in a semantic annotation task, Christiane Fellbaum et al WordNet and class-based probabilities, Philip Resnik combining local context and WordNet similarity for word sense identification, Claudia Leacock and Martin Chodorow using WordNet for text retrieval, Ellen M. Voorhees lexical chains as representations of context for the detection and correction of malapropisms, Graeme Hirst and David St-Onge temporal indexing through lexical chaining, Reem Al-Halimi and Rick Kazman COLOR-X - using knowledge from WordNet for conceptual modelling, J.F.M. Burg and R.P. van de Riet knowledge processing on an extended WordNet, Sanda M. Harabagiu and Dan I Moldovan appendix - obtaining and using WordNet.","['Lexical database', 'WordNet', 'Computer science', 'Natural language processing', 'Artificial intelligence', 'Information retrieval', 'Lexical item', 'Linguistics', 'Database', 'Philosophy']","lexical database, nouns, wordnet, modifiers, word, semantic network, english verbs, wordnet lexical database, searching software, wordnet, verb alterations, word, word, relational concept analysis, word, semantic concordances, semantic annotation task, local context, wordnet similarity, word sense identification, wordnet, text retrieval, lexical chains, malapropisms, temporal indexing, lexical chaining, word, conceptual modelling, knowledge processing, word"
Paper_01023,GenAlEx 6.5: genetic analysis in Excel. Population genetic software for teaching and research—an update,"['Rod Peakall', 'Peter E. Smouse']",2012,Bioinformatics,Journal,,2537-2539,28,19,10.1093/bioinformatics/bts460,"GenAlEx: Genetic Analysis in Excel is a cross-platform package for population genetic analyses that runs within Microsoft Excel. GenAlEx offers analysis of diploid codominant, haploid and binary genetic loci and DNA sequences. Both frequency-based (F-statistics, heterozygosity, HWE, population assignment, relatedness) and distance-based (AMOVA, PCoA, Mantel tests, multivariate spatial autocorrelation) analyses are provided. New features include calculation of new estimators of population structure: G'(ST), G''(ST), Jost's D(est) and F'(ST) through AMOVA, Shannon Information analysis, linkage disequilibrium analysis for biallelic data and novel heterogeneity tests for spatial autocorrelation analysis. Export to more than 30 other data formats is provided. Teaching tutorials and expanded step-by-step output options are included. The comprehensive guide has been fully revised.GenAlEx is written in VBA and provided as a Microsoft Excel Add-in (compatible with Excel 2003, 2007, 2010 on PC; Excel 2004, 2011 on Macintosh). GenAlEx, and supporting documentation and tutorials are freely available at: http://biology.anu.edu.au/GenAlEx.rod.peakall@anu.edu.au.","['Population', 'Computer science', 'Software', 'Spatial analysis', 'Statistics', 'Autocorrelation', 'Data mining', 'Programming language', 'Mathematics', 'Demography', 'Sociology']","genalex, genetic analysis, excel, population genetic analyses, microsoft excel, genalex, diploid codominant, hapl, binary genetic loci, dna sequences, heterozygosity, ##we, population assignment, relatedness, ##oa, mantel tests, multivariate spatial autocorrelation, population structure, ##ova, shannon information analysis, linkage disequilibrium analysis, biallelic data, heterogeneity tests, spatial autocorrelation analysis, genalex, genalex"
Paper_01024,THEORY OF PLATES AND SHELLS,"['S. Timoshenko', 'S. Woinowsky-Krieger']",1959,McGraw-Hill eBooks,Unknown,,,,,10.1007/978-3-662-66805-4,CONTENTS: BENDING OF LONG RECTANGULAR PLATES TO A CYLINDRICAL SURFACE PURE BENDING OF PLATES SYMMETRICAL BENDING OF CIRCULAR PLATES SMALL DEFLECTIONS OF LATERALLY LOADED PLATES SIMPLY SUPPORTED RECTANGULAR PLATES RECTANGULAR PLATES WITH VARIOUS EDGE CONDITIONS CONTINUOUS RECTANGULAR PLATES PLATES ON ELASTIC FOUNDATION PLATES OF VARIOUS SHAPES SPECIAL AND APPROXIMATE METHODS IN THEORY OF PLATES BENDING OF ANISTROPIC PLATES BENDING OF PLATES UNDER THE COMBINED ACTION OF LATERAL LOADS AND FORCES IN THE MIDDLE PLANE OF THE PLATE LARGE DEFLECTIONS OF PLATES DEFORMATION OF SHELLS WITHOUT BENDING GENERAL THEORY OF CYLINDRICAL SHELLS SHELLS HAVING THE FORM OF A SURFACE OF REVOLUTION AND LOADED SYMMETRICALLY WITH RESPECT TO THEIR AXIS.,"['Bending', 'Bending of plates', 'Materials science', 'Plate theory', 'Neutral plane', 'Composite material', 'Enhanced Data Rates for GSM Evolution', 'Pure bending', 'Structural engineering', 'Bending stiffness', 'Geometry', 'Finite element method', 'Engineering', 'Mathematics', 'Telecommunications']","cylindrical surface, symmetrical, circular plates, ##le, laterally loaded, elastic foundation, plates, anistropic plates, lateral loads, cylindrical shells, [PAD], [PAD], [PAD], [PAD] [PAD]"
Paper_01025,Bayesian Measures of Model Complexity and Fit,"['David J. Spiegelhalter', 'Nicola Best', 'Bradley P. Carlin', 'Angelika van der Linde']",2002,Journal of the Royal Statistical Society Series B (Statistical Methodology),Journal,,583-639,64,4,10.1111/1467-9868.00353,"Summary We consider the problem of comparing complex hierarchical models in which the number of parameters is not clearly defined. Using an information theoretic argument we derive a measure pD for the effective number of parameters in a model as the difference between the posterior mean of the deviance and the deviance at the posterior means of the parameters of interest. In general pD approximately corresponds to the trace of the product of Fisher's information and the posterior covariance, which in normal models is the trace of the ‘hat’ matrix projecting observations onto fitted values. Its properties in exponential families are explored. The posterior mean deviance is suggested as a Bayesian measure of fit or adequacy, and the contributions of individual observations to the fit and complexity can give rise to a diagnostic plot of deviance residuals against leverages. Adding pD to the posterior mean deviance gives a deviance information criterion for comparing models, which is related to other information criteria and has an approximate decision theoretic justification. The procedure is illustrated in some examples, and comparisons are drawn with alternative Bayesian and classical proposals. Throughout it is emphasized that the quantities required are trivial to compute in a Markov chain Monte Carlo analysis.","['Deviance information criterion', 'Deviance (statistics)', 'Mathematics', 'Bayesian probability', 'Statistics', 'Posterior probability', 'Markov chain Monte Carlo', 'Fisher information', 'Econometrics', 'Information Criteria', 'Exponential family', 'Covariance', 'Applied mathematics', 'Model selection']","complex hierarchical models, information theoretic argument, posterior mean, posterior covariance, exponential families, posterior mean deviance, bayesian measure, adequacy, diagnostic plot, ##ance residuals, posterior mean deviance, deviance information criterion, approximate decision theoretic justification, markov chain monte carlo analysis"
Paper_01029,A method for obtaining digital signatures and public-key cryptosystems,"['Ronald L. Rivest', 'Adi Shamir', 'Leonard M. Adleman']",1978,Communications of the ACM,Journal,,120-126,21,2,10.1145/359340.359342,"An encryption method is presented with the novel property that publicly revealing an encryption key does not thereby reveal the corresponding decryption key. This has two important consequences: (1) Couriers or other secure means are not needed to transmit keys, since a message can be enciphered using an encryption key publicly revealed by the intented recipient. Only he can decipher the message, since only he knows the corresponding decryption key. (2) A message can be “signed” using a privately held decryption key. Anyone can verify this signature using the corresponding publicly revealed encryption key. Signatures cannot be forged, and a signer cannot later deny the validity of his signature. This has obvious applications in “electronic mail” and “electronic funds transfer” systems. A message is encrypted by representing it as a number M, raising M to a publicly specified power e, and then taking the remainder when the result is divided by the publicly specified product, n , of two large secret primer numbers p and q. Decryption is similar; only a different, secret, power d is used, where e * d ≡ 1(mod (p - 1) * (q - 1)). The security of the system rests in part on the difficulty of factoring the published divisor, n .","['Encryption', 'Computer science', 'Public-key cryptography', 'Digital signature', 'Key (lock)', 'Computer security', 'Cryptosystem', 'DECIPHER', 'Signature (topology)', 'Theoretical computer science', 'Mathematics', 'Hash function', 'Geometry', 'Biology', 'Genetics']","encryption, encryption, decryption key, courier, ##ry, privately, decryption key, electronic mail ”, electronic funds transfer ”"
Paper_01030,Anti de Sitter space and holography,['Edward Witten'],1998,Advances in Theoretical and Mathematical Physics,Journal,,253-291,2,2,10.4310/atmp.1998.v2.n2.a2,"Recently, it has been proposed by Maldacena that large N limits of certain conformal field theories in d dimensions can be described in terms of supergravity (and string theory) on the product of d 4-1dimensional AdS space with a compact manifold.Here we elaborate on this idea and propose a precise correspondence between conformal field theory observables and those of supergravity: correlation functions in conformal field theory are given by the dependence of the supergravity action on the asymptotic behavior at infinity.In particular, dimensions of operators in conformal field theory are given by masses of particles in supergravity.As quantitative confirmation of this correspondence, we note that the Kaluza-Klein modes of Type IIB supergravity on AdS^ x S 5 match with the chiral operators of Af = 4 super Yang-Mills theory in four dimensions.With some further assumptions, one can deduce a H'amiltonian version of the correspondence and show that the Af = 4 theory has a large N phase transition related to the thermodynamics of AdS black holes.","['De Sitter space', 'Anti-de Sitter space', 'Space (punctuation)', 'de Sitter–Schwarzschild metric', 'Physics', 'Holography', 'de Sitter invariant special relativity', 'De Sitter universe', 'Mathematical physics', 'Theoretical physics', 'Classical mechanics', 'Philosophy', 'Optics', 'Gravitation', 'Quantum mechanics', 'Universe', 'Linguistics', 'Schwarzschild radius']","conformal field theories, supergravity, string theory, compact manifold, conformal field theory, supergravity, correlation functions, conformal field theory, supergravity action, asymptotic behavior, conformal field theory, chiral operators, thermodyna, ads, [PAD] [PAD]"
Paper_01032,RESISTANCE OF SOLID SURFACES TO WETTING BY WATER,['Robert N. Wenzel'],1936,Industrial & Engineering Chemistry,Journal,,988-994,28,8,10.1021/ie50320a024,"ADVERTISEMENT RETURN TO ISSUEPREVArticleNEXTRESISTANCE OF SOLID SURFACES TO WETTING BY WATERRobert N. WenzelCite this: Ind. Eng. Chem. 1936, 28, 8, 988–994Publication Date (Print):August 1, 1936Publication History Published online1 May 2002Published inissue 1 August 1936https://pubs.acs.org/doi/10.1021/ie50320a024https://doi.org/10.1021/ie50320a024research-articleACS PublicationsRequest reuse permissionsArticle Views32431Altmetric-Citations10610LEARN ABOUT THESE METRICSArticle Views are the COUNTER-compliant sum of full text article downloads since November 2008 (both PDF and HTML) across all institutions and individuals. These metrics are regularly updated to reflect usage leading up to the last few days.Citations are the number of other articles citing this article, calculated by Crossref and updated daily. Find more information about Crossref citation counts.The Altmetric Attention Score is a quantitative measure of the attention that a research article has received online. Clicking on the donut icon will load a page at altmetric.com with additional details about the score and the social media presence for the given article. Find more information on the Altmetric Attention Score and how the score is calculated. Share Add toView InAdd Full Text with ReferenceAdd Description ExportRISCitationCitation and abstractCitation and referencesMore Options Share onFacebookTwitterWechatLinked InRedditEmail Other access options Get e-Alerts","['Citation', 'Icon', 'Social media', 'Wetting', 'Computer science', 'Solid surface', 'Altmetrics', 'Information retrieval', 'World Wide Web', 'Physics', 'Chemical physics', 'Thermodynamics', 'Programming language']","##varticlenextres, solid surfaces, wetting, permissionsarticle views, metricsar, ##le, ##f, ##f, altmetric attention score, social media, altmetric attention score, reference, ##d, ##riscitation, abstract, ##ation, references"
Paper_01033,Savitzky-Golay Smoothing Filters,"['William H. Press', 'Saul A. Teukolsky']",1990,Computers in Physics,Journal,,669-672,4,6,10.1063/1.4822961,First Page,"['Binary Golay code', 'Smoothing', 'Computer science', 'Mathematics', 'Statistics', 'Algorithm']",
Paper_01038,MEGA3: Integrated software for Molecular Evolutionary Genetics Analysis and sequence alignment,"['Sudhir Kumar', 'Koichiro Tamura', 'Masatoshi Nei']",2004,Briefings in Bioinformatics,Journal,,150-163,5,2,10.1093/bib/5.2.150,"With its theoretical basis firmly established in molecular evolutionary and population genetics, the comparative DNA and protein sequence analysis plays a central role in reconstructing the evolutionary histories of species and multigene families, estimating rates of molecular evolution, and inferring the nature and extent of selective forces shaping the evolution of genes and genomes. The scope of these investigations has now expanded greatly owing to the development of high-throughput sequencing techniques and novel statistical and computational methods. These methods require easy-to-use computer programs. One such effort has been to produce Molecular Evolutionary Genetics Analysis (MEGA) software, with its focus on facilitating the exploration and analysis of the DNA and protein sequence variation from an evolutionary perspective. Currently in its third major release, MEGA3 contains facilities for automatic and manual sequence alignment, web-based mining of databases, inference of the phylogenetic trees, estimation of evolutionary distances and testing evolutionary hypotheses. This paper provides an overview of the statistical methods, computational tools, and visual exploration modules for data input and the results obtainable in MEGA.","['Multiple sequence alignment', 'Molecular evolution', 'Phylogenetic tree', 'Alignment-free sequence analysis', 'DNA sequencing', 'Mega-', 'Population genetics', 'Software', 'Inference', 'Human evolutionary genetics', 'Biology', 'Sequence analysis', 'Computational biology', 'Computer science', 'Genome', 'Sequence alignment', 'Evolutionary biology', 'Population', 'Genetics', 'Artificial intelligence', 'Gene', 'Physics', 'Demography', 'Astronomy', 'Sociology', 'Peptide sequence', 'Programming language']","population genetics, protein sequence analysis, evolutionary histories, multigene families, molecular evolution, selective forces, molecular evolutionary genetics analysis, mega, mega, phylogenetic trees, evolutionary distances, evolutionary hypotheses, visual exploration modules"
Paper_01039,Cognitive radio: brain-empowered wireless communications,['S. Haykin'],2005,IEEE Journal on Selected Areas in Communications,Journal,,201-220,23,2,10.1109/jsac.2004.839380,"Cognitive radio is viewed as a novel approach for improving the utilization of a precious natural resource: the radio electromagnetic spectrum. The cognitive radio, built on a software-defined radio, is defined as an intelligent wireless communication system that is aware of its environment and uses the methodology of understanding-by-building to learn from the environment and adapt to statistical variations in the input stimuli, with two primary objectives in mind: /spl middot/ highly reliable communication whenever and wherever needed; /spl middot/ efficient utilization of the radio spectrum. Following the discussion of interference temperature as a new metric for the quantification and management of interference, the paper addresses three fundamental cognitive tasks. 1) Radio-scene analysis. 2) Channel-state estimation and predictive modeling. 3) Transmit-power control and dynamic spectrum management. This work also discusses the emergent behavior of cognitive radio.","['Cognitive radio', 'Computer science', 'Radio resource management', 'Wireless', 'Software-defined radio', 'Interference (communication)', 'Transmitter power output', 'Radio spectrum', 'Transmitter', 'Channel (broadcasting)', 'Spectrum management', 'Telecommunications', 'Wireless network', 'Cognitive network', 'Metric (unit)', 'Electromagnetic interference', 'Control channel', 'Computer network', 'Transmission (telecommunications)', 'Engineering', 'Operations management']","cognitive radio, radio electromagnetic spectrum, cognitive radio, intelligent wireless communication system, statistical, interference temperature, predictive modeling, dynamic spectrum management, ##nt behavior, cognitive radio, [PAD]"
Paper_01040,Biological identifications through DNA barcodes,"['Paul D. N. Hebert', 'Alina Cywinska', 'Shelley L. Ball', 'Jeremy R deWaard']",2003,Proceedings of the Royal Society B Biological Sciences,Journal,,313-321,270,1512,10.1098/rspb.2002.2218,"Although much biological research depends upon species diagnoses, taxonomic expertise is collapsing.We are convinced that the sole prospect for a sustainable identification capability lies in the construction of systems that employ DNA sequences as taxon 'barcodes'.We establish that the mitochondrial gene cytochrome c oxidase I (COI) can serve as the core of a global bioidentification system for animals.First, we demonstrate that COI profiles, derived from the low-density sampling of higher taxonomic categories, ordinarily assign newly analysed taxa to the appropriate phylum or order.Second, we demonstrate that species-level assignments can be obtained by creating comprehensive COI profiles.A model COI profile, based upon the analysis of a single individual from each of 200 closely allied species of lepidopterans, was 100% successful in correctly identifying subsequent specimens.When fully developed, a COI identification system will provide a reliable, cost-effective and accessible solution to the current problem of species identification.Its assembly will also generate important new insights into the diversification of life and the rules of molecular evolution.","['Biology', 'Taxon', 'Evolutionary biology', 'DNA barcoding', 'Identification (biology)', 'Diversification (marketing strategy)', 'Phylum', 'Taxonomic rank', 'Mitochondrial DNA', 'Computational biology', 'Ecology', 'Gene', 'Genetics', 'Marketing', 'Business']","taxonomic, dna sequences, mitochondrial gene cytochrome c oxidase i, coi, coi profiles, coi, le, ##optera, coi, species identification, molecular evolution"
Paper_01043,"Consumer Perceptions of Price, Quality, and Value: A Means-End Model and Synthesis of Evidence",['Valarie A. Zeithaml'],1988,Journal of Marketing,Journal,,2-2,52,3,10.2307/1251446,"Evidence from past research and insights from an exploratory investigation are combined in a conceptual model that defines and relates price, perceived quality, and perceived value. Propositions about the concepts and their relationships are presented, then supported with evidence from the literature. Discussion centers on directions for research and implications for managing price, quality, and value.","['Value (mathematics)', 'Quality (philosophy)', 'Perception', 'Marketing', 'Conceptual model', 'Exploratory research', 'Business', 'Economics', 'Psychology', 'Sociology', 'Computer science', 'Epistemology', 'Neuroscience', 'Database', 'Machine learning', 'Anthropology', 'Philosophy']","price, perceived quality, perceived value, price, value, [PAD], [PAD] [PAD]"
Paper_01045,National Committee for Clinical Laboratory Standards,['Erika Bruck'],1980,PEDIATRICS,Journal,,187-188,65,1,10.1542/peds.65.1.187,"Many members of the Academy of Pediatrics seem to be generally unaware of the fact that your Academy has participated for ten years in a very interesting and valuable organization, the National Committee for Clinical Laboratory Standards (NCCLS). The NCCLS has only three kinds of members: professional organizations, industrial (clinical laboratory instruments and supplies), and government agencies (CDC, FDA, NBS, NIH). Each member is represented by one delegate and one alternate. At present there are close to 110 members, of which 20 are professional societies.","['Delegate', 'Medicine', 'Professional association', 'Government (linguistics)', 'Medical education', 'Family medicine', 'Public relations', 'Political science', 'Linguistics', 'Philosophy', 'Computer science', 'Programming language']","pediatric, clinical laboratory standards, nc, professional organizations, clinical laboratory instruments, government agencies, professional societies"
Paper_01046,Global Consequences of Land Use,"['Jonathan A. Foley', 'Ruth DeFries', 'Gregory P. Asner', 'Carol Barford', 'Gordon B. Bonan', 'Stephen R. Carpenter', 'F. Stuart Chapin', 'Michael T. Coe', 'Gretchen C. Daily', 'Holly Gibbs', 'Joseph H. Helkowski', 'Tracey Holloway', 'E. A. Howard', 'Christopher J. Kucharik', 'Chad Monfreda', 'Jonathan A. Patz', 'I. Colin Prentice', 'Navin Ramankutty', 'P. K. Snyder']",2005,Science,Journal,,570-574,309,5734,10.1126/science.1111772,"Land use has generally been considered a local environmental issue, but it is becoming a force of global importance. Worldwide changes to forests, farmlands, waterways, and air are being driven by the need to provide food, fiber, water, and shelter to more than six billion people. Global croplands, pastures, plantations, and urban areas have expanded in recent decades, accompanied by large increases in energy, water, and fertilizer consumption, along with considerable losses of biodiversity. Such changes in land use have enabled humans to appropriate an increasing share of the planet's resources, but they also potentially undermine the capacity of ecosystems to sustain food production, maintain freshwater and forest resources, regulate climate and air quality, and ameliorate infectious diseases. We face the challenge of managing trade-offs between immediate human needs and maintaining the capacity of the biosphere to provide goods and services in the long term.","['Biodiversity', 'Natural resource economics', 'Business', 'Ecosystem services', 'Land use', 'Biosphere', 'Climate change', 'Environmental resource management', 'Ecosystem', 'Environmental planning', 'Environmental protection', 'Environmental science', 'Ecology', 'Economics', 'Biology']","land use, farmland, urban areas, ##lizer, land use, infectious diseases"
Paper_01047,The role of positive emotions in positive psychology: The broaden-and-build theory of positive emotions.,['Barbara L. Fredrickson'],2001,American Psychologist,Journal,,218-226,56,3,10.1037/0003-066x.56.3.218,"In this article, the author describes a new theoretical perspective on positive emotions and situates this new perspective within the emerging field of positive psychology. The broaden-and-build theory posits that experiences of positive emotions broaden people's momentary thought-action repertoires, which in turn serves to build their enduring personal resources, ranging from physical and intellectual resources to social and psychological resources. Preliminary empirical evidence supporting the broaden-and-build theory is reviewed, and open empirical questions that remain to be tested are identified. The theory and findings suggest that the capacity to experience positive emotions may be a fundamental human strength central to the study of human flourishing.","['Positive psychology', 'Psychology', 'Social psychology', 'Cognitive psychology', 'Epistemology', 'Philosophy']","positive emotions, positive psychology, positive emotions, positive emotions, human strength, human flourishing"
Paper_01049,Modern Information Retrieval,"['Ricardo Baeza‐Yates', 'Berthier Ribeiro‐Neto']",1999,['Library Management'],Unknown,,373-374,32,4/5,10.1108/01435121111132365,"From the Publisher:
This is a rigorous and complete textbook for a first course on information retrieval from the computer science (as opposed to a user-centred) perspective. The advent of the Internet and the enormous increase in volume of electronically stored information generally has led to substantial work on IR from the computer science perspective - this book provides an up-to-date student oriented treatment of the subject.","['Perspective (graphical)', 'Subject (documents)', 'Computer science', 'The Internet', 'Information retrieval', 'World Wide Web', 'Volume (thermodynamics)', 'Information science', 'Data science', 'Library science', 'Artificial intelligence', 'Physics', 'Quantum mechanics']","information retrieval, internet, electronically stored information, ir"
Paper_01052,Five Misunderstandings About Case-Study Research,['Bent Flyvbjerg'],2006,Qualitative Inquiry,Journal,,219-245,12,2,10.1177/1077800405284363,"This article examines five common misunderstandings about case-study research: (a) theoretical knowledge is more valuable than practical knowledge; (b) one cannot generalize from a single case, therefore, the single-case study cannot contribute to scientific development; (c) the case study is most useful for generating hypotheses, whereas other methods are more suitable for hypotheses testing and theory building; (d) the case study contains a bias toward verification; and (e) it is often difficult to summarize specific case studies. This article explains and corrects these misunderstandings one by one and concludes with the Kuhnian insight that a scientific discipline without a large number of thoroughly executed case studies is a discipline without systematic production of exemplars, and a discipline without exemplars is an ineffective one. Social science may be strengthened by the execution of a greater number of good case studies.","['Epistemology', 'Case study research', 'Sociology', 'Single-subject design', 'Computer science', 'Psychology', 'Knowledge management', 'Philosophy', 'Psychotherapist']","theoretical knowledge, practical, hyp, hypotheses, theory building, social science, [PAD], [PAD] [PAD], [PAD], [PAD], [PAD], [PAD], [PAD] [PAD]"
Paper_01053,Image processing with ImageJ,"['Michael D. Abràmoff', 'Paulo Magalhães', 'Sunanda J. Ram']",2004,['Optical Imaging Techniques in Cell Biology'],Unknown,,249-258,11,7,10.1201/9781420005615.ax4,"Wayne Rasband of NIH has created ImageJ, an open source Java-written program that is now at version 1.31 and is used for many imaging applications, including those that that span the gamut from skin analysis to neuroscience. ImageJ is in the public domain and runs on any operating system (OS). ImageJ is easy to use and can do many imaging manipulations. A very large and knowledgeable group makes up the user community for ImageJ. Topics covered are imaging abilities; cross platform; image formats support as of June 2004; extensions, including macros and plug-ins; and imaging library. NIH reports tens of thousands of downloads at a rate of about 24,000 per month currently. ImageJ can read most of the widely used and significant formats used in biomedical images. Manipulations supported are read/write of image files and operations on separate pixels, image regions, entire images, and volumes (stacks in ImageJ). Basic operations supported include convolution, edge detection, Fourier transform, histogram and particle analyses, editing and color manipulation, and more advanced operations, as well as visualization. For assistance in using ImageJ, users e-mail each other, and the user base is highly knowledgeable and will answer requests on the mailing list. A thorough manual with many examples and illustrations has been written by Tony Collins of the Wright Cell Imaging Facility at Toronto Western Research Institute and is available, along with other listed resources, via the Web.","['Computer science', 'Computer graphics (images)', 'Image processing', 'Visualization', 'Artificial intelligence', 'Computer vision', 'Image (mathematics)']","##h, imagej, skin analysis, neuroscience, imagej, imagej, imagej, image formats, ##s, imaging library, imagej, biomedical images, image, convolution, edge detection, fourier transform, ##to, particle analyses, editing, color manipulation, visualization, imagej, wright cell imaging facility, toronto western research institute"
Paper_01054,Accurate transcription initiation by RNA polymerase II in a soluble extract from isolated mammalian nuclei,"['John David Dignam', 'Russell M. Lebovitz', 'R G Roeder']",1983,Nucleic Acids Research,Journal,,1475-1489,11,5,10.1093/nar/11.5.1475,We have developed a procedure for preparing extracts from nuclei of human tissue culture cells that directs accurate transcription initiation in vitro from class II promoters. Conditions of extraction and assay have been optimized for maximum activity using the major late promoter of adenovirus 2. The extract also directs accurate transcription initiation from other adenovirus promoters and cellular promoters. The extract also directs accurate transcription initiation from class III promoters (tRNA and Ad 2 VA).,"['Promoter', 'Biology', 'Transcription (linguistics)', 'RNA polymerase II', 'Molecular biology', 'Transcription factor II D', 'RNA polymerase', 'General transcription factor', 'RNA', 'Genetics', 'Gene', 'Gene expression', 'Linguistics', 'Philosophy']",human tissue culture cells
Paper_01056,Visible-Light Photocatalysis in Nitrogen-Doped Titanium Oxides,"['Ryoji Asahi', 'Takeshi Morikawa', 'Takeshi Ohwaki', 'Koichi Aoki', 'Yasunori Taga']",2001,Science,Journal,,269-271,293,5528,10.1126/science.1061051,"To use solar irradiation or interior lighting efficiently, we sought a photocatalyst with high reactivity under visible light. Films and powders of TiO(2-x)N(x) have revealed an improvement over titanium dioxide (TiO2) under visible light (wavelength < 500 nanometers) in optical absorption and photocatalytic activity such as photodegradations of methylene blue and gaseous acetaldehyde and hydrophilicity of the film surface. Nitrogen doped into substitutional sites of TiO2 has proven to be indispensable for band-gap narrowing and photocatalytic activity, as assessed by first-principles calculations and x-ray photoemission spectroscopy.","['Photocatalysis', 'Visible spectrum', 'Titanium dioxide', 'Materials science', 'Methylene blue', 'Photochemistry', 'Doping', 'Irradiation', 'Acetaldehyde', 'Absorption (acoustics)', 'X-ray photoelectron spectroscopy', 'Nitrogen', 'Titanium', 'Band gap', 'Titanium oxide', 'Nanometre', 'Optoelectronics', 'Chemical engineering', 'Chemistry', 'Catalysis', 'Organic chemistry', 'Physics', 'Nuclear physics', 'Ethanol', 'Engineering', 'Metallurgy', 'Composite material']","solar irradiation, interior lighting, photocatalyst, visible, titanium, ti, optical absorption, photocatalytic activity, ##grad, gaseous, substitutional sites, ti, photocatalytic activity"
Paper_01059,Overview of the<i>CCP</i>4 suite and current developments,"['Martyn Winn', 'Charles Ballard', 'Kevin Cowtan', 'E.J. Dodson', 'Paul Emsley', 'Phil Evans', 'Ronan M. Keegan', 'Eugene Krissinel', 'Andrew G. W. Leslie', 'Airlie J. McCoy', 'Stuart McNicholas', 'Garib N. Murshudov', 'Neesh Pannu', 'Elizabeth Potterton', 'Harold R. Powell', 'Randy J. Read', 'Alexei A. Vagin', 'Keith S. Wilson']",2011,Acta Crystallographica Section D Biological Crystallography,Journal,,235-242,67,4,10.1107/s0907444910045749,"The CCP4 (Collaborative Computational Project, Number 4) software suite is a collection of programs and associated data and software libraries which can be used for macromolecular structure determination by X-ray crystallography. The suite is designed to be flexible, allowing users a number of methods of achieving their aims. The programs are from a wide variety of sources but are connected by a common infrastructure provided by standard file formats, data objects and graphical interfaces. Structure solution by macromolecular crystallo­graphy is becoming increasingly automated and the CCP4 suite includes several automation pipelines. After giving a brief description of the evolution of CCP4 over the last 30 years, an overview of the current suite is given. While detailed descriptions are given in the accompanying articles, here it is shown how the individual programs contribute to a complete software package.","['Suite', 'Software suite', 'Computer science', 'Software', 'Variety (cybernetics)', 'Software engineering', 'Automation', 'File format', 'Data science', 'Programming language', 'Engineering', 'Artificial intelligence', 'Geography', 'Mechanical engineering', 'Archaeology']","ccp, collaborative computational project, software libraries, macromolecular structure determination, graphical interfaces, macromolecular crystal, ccp, automation, ccp, [PAD] [PAD], [PAD] [PAD], [PAD] [PAD] [PAD]"
Paper_01061,The Determination of Enzyme Dissociation Constants,"['Hans Lineweaver', 'Dean Burk']",1934,Journal of the American Chemical Society,Journal,,658-666,56,3,10.1021/ja01318a036,"ADVERTISEMENT RETURN TO ISSUEPREVArticleNEXTThe Determination of Enzyme Dissociation ConstantsHans Lineweaver and Dean BurkCite this: J. Am. Chem. Soc. 1934, 56, 3, 658–666Publication Date (Print):March 1, 1934Publication History Published online1 May 2002Published inissue 1 March 1934https://doi.org/10.1021/ja01318a036RIGHTS & PERMISSIONSArticle Views17226Altmetric-Citations9769LEARN ABOUT THESE METRICSArticle Views are the COUNTER-compliant sum of full text article downloads since November 2008 (both PDF and HTML) across all institutions and individuals. These metrics are regularly updated to reflect usage leading up to the last few days.Citations are the number of other articles citing this article, calculated by Crossref and updated daily. Find more information about Crossref citation counts.The Altmetric Attention Score is a quantitative measure of the attention that a research article has received online. Clicking on the donut icon will load a page at altmetric.com with additional details about the score and the social media presence for the given article. Find more information on the Altmetric Attention Score and how the score is calculated. Share Add toView InAdd Full Text with ReferenceAdd Description ExportRISCitationCitation and abstractCitation and referencesMore Options Share onFacebookTwitterWechatLinked InReddit PDF (854 KB) Get e-Alertsclose Get e-Alerts","['Citation', 'Icon', 'Social media', 'Computer science', 'Dissociation (chemistry)', 'Information retrieval', 'Altmetrics', 'World Wide Web', 'Chemistry', 'Physical chemistry', 'Programming language']","enzyme dissociation constant, permissionsar, ##le views, cross, ##f, crossref, altmetric attention score, don, alt, social media, altmetric attention score, ##ation, abstract, ##ation"
Paper_01062,Understanding the difficulty of training deep feedforward neural networks,"['Xavier Glorot', 'Yoshua Bengio']",2010,['Pramana'],Conference,,35-42,40,1,10.1007/bf02898040,"Whereas before 2006 it appears that deep multilayer neural networks were not successfully trained, since then several algorithms have been shown to successfully train them, with experimental results showing the superiority of deeper vs less deep architectures. All these experimental results were obtained with new initialization or training mechanisms. Our objective here is to understand better why standard gradient descent from random initialization is doing so poorly with deep neural networks, to better understand these recent relative successes and help design better algorithms in the future. We first observe the influence of the non-linear activations functions. We find that the logistic sigmoid activation is unsuited for deep networks with random initialization because of its mean value, which can drive especially the top hidden layer into saturation. Surprisingly, we find that saturated units can move out of saturation by themselves, albeit slowly, and explaining the plateaus sometimes seen when training neural networks. We find that a new non-linearity that saturates less can often be beneficial. Finally, we study how activations and gradients vary across layers and during training, with the idea that training may be more difficult when the singular values of the Jacobian associated with each layer are far from 1. Based on these considerations, we propose a new initialization scheme that brings substantially faster convergence. 1 Deep Neural Networks Deep learning methods aim at learning feature hierarchies with features from higher levels of the hierarchy formed by the composition of lower level features. They include Appearing in Proceedings of the 13 International Conference on Artificial Intelligence and Statistics (AISTATS) 2010, Chia Laguna Resort, Sardinia, Italy. Volume 9 of JMLR: WC Weston et al., 2008). Much attention has recently been devoted to them (see (Bengio, 2009) for a review), because of their theoretical appeal, inspiration from biology and human cognition, and because of empirical success in vision (Ranzato et al., 2007; Larochelle et al., 2007; Vincent et al., 2008) and natural language processing (NLP) (Collobert & Weston, 2008; Mnih & Hinton, 2009). Theoretical results reviewed and discussed by Bengio (2009), suggest that in order to learn the kind of complicated functions that can represent high-level abstractions (e.g. in vision, language, and other AI-level tasks), one may need deep architectures. Most of the recent experimental results with deep architecture are obtained with models that can be turned into deep supervised neural networks, but with initialization or training schemes different from the classical feedforward neural networks (Rumelhart et al., 1986). Why are these new algorithms working so much better than the standard random initialization and gradient-based optimization of a supervised training criterion? Part of the answer may be found in recent analyses of the effect of unsupervised pretraining (Erhan et al., 2009), showing that it acts as a regularizer that initializes the parameters in a “better” basin of attraction of the optimization procedure, corresponding to an apparent local minimum associated with better generalization. But earlier work (Bengio et al., 2007) had shown that even a purely supervised but greedy layer-wise procedure would give better results. So here instead of focusing on what unsupervised pre-training or semi-supervised criteria bring to deep architectures, we focus on analyzing what may be going wrong with good old (but deep) multilayer neural networks. Our analysis is driven by investigative experiments to monitor activations (watching for saturation of hidden units) and gradients, across layers and across training iterations. We also evaluate the effects on these of choices of activation function (with the idea that it might affect saturation) and initialization procedure (since unsupervised pretraining is a particular form of initialization and it has a drastic impact).","['Initialization', 'Computer science', 'Artificial neural network', 'Artificial intelligence', 'Deep neural networks', 'Deep learning', 'Gradient descent', 'Jacobian matrix and determinant', 'Sigmoid function', 'Machine learning', 'Mathematics', 'Applied mathematics', 'Programming language']","deep multilayer neural networks, training mechanisms, random initialization, deep neural networks, - linear, logistic sigmoid activation, random initialization, saturated units, deep neural networks deep learning methods, artificial intelligence, human cognition, natural language processing"
Paper_01063,Ventilation with Lower Tidal Volumes as Compared with Traditional Tidal Volumes for Acute Lung Injury and the Acute Respiratory Distress Syndrome,"['Roy G. Brower', 'Michael A. Matthay', 'Alan H. Morris', 'David Schoenfeld', 'Bruce Thompson', 'Arthur P. Wheeler']",2000,New England Journal of Medicine,Journal,,1301-1308,342,18,10.1056/nejm200005043421801,Original Article from The New England Journal of Medicine — Ventilation with Lower Tidal Volumes as Compared with Traditional Tidal Volumes for Acute Lung Injury and the Acute Respiratory Distress Syndrome,"['Medicine', 'Tidal volume', 'Ventilation (architecture)', 'Mechanical ventilation', 'Anesthesia', 'Plateau pressure', 'Respiratory minute volume', 'Randomization', 'Kilogram', 'Respiratory rate', 'Respiratory distress', 'Randomized controlled trial', 'Respiratory system', 'Internal medicine', 'Body weight', 'Heart rate', 'Blood pressure', 'Mechanical engineering', 'Engineering']","ventilation, tidal volumes, acute lung injury, acute respiratory distress syndrome, [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD], [PAD] [PAD], [PAD], [PAD] [PAD] [PAD], [PAD] [PAD] [PAD], [PAD], [PAD] [PAD] [PAD], [PAD] [PAD], [PAD] [PAD], [PAD] [PAD], [PAD] [PAD] [PAD], [PAD] [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD] [PAD] [PAD], [PAD] [PAD] [PAD], [PAD], [PAD], [PAD] [PAD], [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD], [PAD] [PAD] [PAD], [PAD] [PAD] [PAD], [PAD], [PAD] [PAD] [PAD], [PAD] [PAD], [PAD] [PAD] [PAD] [PAD], [PAD] [PAD], [PAD], [PAD], [PAD], [PAD], [PAD] [PAD] [PAD] [PAD], [PAD], [PAD], [PAD], [PAD], [PAD] [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD]"
Paper_01064,Discrete-Time Signal Processing,"['Alan V. Oppenheim', 'Ronald W. Schafer']",1989,['Electronics and Power'],Unknown,,157,23,2,10.1049/ep.1977.0078,"For senior/graduate-level courses in Discrete-Time Signal Processing. THE definitive, authoritative text on DSP -- ideal for those with an introductory-level knowledge of signals and systems. Written by prominent, DSP pioneers, it provides thorough treatment of the fundamental theorems and properties of discrete-time linear systems, filtering, sampling, and discrete-time Fourier Analysis. By focusing on the general and universal concepts in discrete-time signal processing, it remains vital and relevant to the new challenges arising in the field --without limiting itself to specific technologies with relatively short life spans.","['Digital signal processing', 'Discrete-time signal', 'Signal processing', 'Computer science', 'Discrete time and continuous time', 'Ideal (ethics)', 'Multidimensional signal processing', 'SIGNAL (programming language)', 'Sampling (signal processing)', 'Discrete Fourier transform (general)', 'Fourier transform', 'Computer engineering', 'Theoretical computer science', 'Algorithm', 'Analog signal', 'Filter (signal processing)', 'Mathematics', 'Fourier analysis', 'Computer hardware', 'Signal transfer function', 'Statistics', 'Computer vision', 'Mathematical analysis', 'Philosophy', 'Epistemology', 'Fractional Fourier transform', 'Programming language']","dsp, ds, filtering, sampling, [PAD], [PAD] [PAD], [PAD] [PAD]"
Paper_01065,A Proportional Hazards Model for the Subdistribution of a Competing Risk,"['Jason P. Fine', 'Malcolm H. Ray']",1999,Journal of the American Statistical Association,Journal,,496-509,94,446,10.1080/01621459.1999.10474144,"Abstract With explanatory covariates, the standard analysis for competing risks data involves modeling the cause-specific hazard functions via a proportional hazards assumption. Unfortunately, the cause-specific hazard function does not have a direct interpretation in terms of survival probabilities for the particular failure type. In recent years many clinicians have begun using the cumulative incidence function, the marginal failure probabilities for a particular cause, which is intuitively appealing and more easily explained to the nonstatistician. The cumulative incidence is especially relevant in cost-effectiveness analyses in which the survival probabilities are needed to determine treatment utility. Previously, authors have considered methods for combining estimates of the cause-specific hazard functions under the proportional hazards formulation. However, these methods do not allow the analyst to directly assess the effect of a covariate on the marginal probability function. In this article we propose a novel semiparametric proportional hazards model for the subdistribution. Using the partial likelihood principle and weighting techniques, we derive estimation and inference procedures for the finite-dimensional regression parameter under a variety of censoring scenarios. We give a uniformly consistent estimator for the predicted cumulative incidence for an individual with certain covariates; confidence intervals and bands can be obtained analytically or with an easy-to-implement simulation technique. To contrast the two approaches, we analyze a dataset from a breast cancer clinical trial under both models. Key Words: Hazard of subdistributionMartingalePartial likelihoodTransformation model","['Covariate', 'Proportional hazards model', 'Censoring (clinical trials)', 'Inverse probability weighting', 'Statistics', 'Estimator', 'Weighting', 'Econometrics', 'Cumulative incidence', 'Nominal level', 'Inference', 'Hazard', 'Mathematics', 'Confidence interval', 'Computer science', 'Medicine', 'Artificial intelligence', 'Cohort', 'Chemistry', 'Organic chemistry', 'Radiology']","explanatory covariates, competing, proportional hazards assumption, survival probabilities, cumulative incidence function, marginal failure probabilities, cumulative, survival probabilities, treatment, proportional hazards formulation, marginal probability function, semiparametric proportional hazards model, partial likelihood principle, weighting techniques, cumulative incidence, breast cancer clinical trial, ##bution"
Paper_01068,Applied Multivariate Statistical Analysis.,"['Andrea Johnson', 'Dean W. Wichern']",1988,Biometrics,Journal,,920-920,44,3,10.2307/2531616,"(NOTE: Each chapter begins with an Introduction, and concludes with Exercises and References.) I. GETTING STARTED. 1. Aspects of Multivariate Analysis. Applications of Multivariate Techniques. The Organization of Data. Data Displays and Pictorial Representations. Distance. Final Comments. 2. Matrix Algebra and Random Vectors. Some Basics of Matrix and Vector Algebra. Positive Definite Matrices. A Square-Root Matrix. Random Vectors and Matrices. Mean Vectors and Covariance Matrices. Matrix Inequalities and Maximization. Supplement 2A Vectors and Matrices: Basic Concepts. 3. Sample Geometry and Random Sampling. The Geometry of the Sample. Random Samples and the Expected Values of the Sample Mean and Covariance Matrix. Generalized Variance. Sample Mean, Covariance, and Correlation as Matrix Operations. Sample Values of Linear Combinations of Variables. 4. The Multivariate Normal Distribution. The Multivariate Normal Density and Its Properties. Sampling from a Multivariate Normal Distribution and Maximum Likelihood Estimation. The Sampling Distribution of 'X and S. Large-Sample Behavior of 'X and S. Assessing the Assumption of Normality. Detecting Outliners and Data Cleaning. Transformations to Near Normality. II. INFERENCES ABOUT MULTIVARIATE MEANS AND LINEAR MODELS. 5. Inferences About a Mean Vector. The Plausibility of ...m0 as a Value for a Normal Population Mean. Hotelling's T 2 and Likelihood Ratio Tests. Confidence Regions and Simultaneous Comparisons of Component Means. Large Sample Inferences about a Population Mean Vector. Multivariate Quality Control Charts. Inferences about Mean Vectors When Some Observations Are Missing. Difficulties Due To Time Dependence in Multivariate Observations. Supplement 5A Simultaneous Confidence Intervals and Ellipses as Shadows of the p-Dimensional Ellipsoids. 6. Comparisons of Several Multivariate Means. Paired Comparisons and a Repeated Measures Design. Comparing Mean Vectors from Two Populations. Comparison of Several Multivariate Population Means (One-Way MANOVA). Simultaneous Confidence Intervals for Treatment Effects. Two-Way Multivariate Analysis of Variance. Profile Analysis. Repealed Measures, Designs, and Growth Curves. Perspectives and a Strategy for Analyzing Multivariate Models. 7. Multivariate Linear Regression Models. The Classical Linear Regression Model. Least Squares Estimation. Inferences About the Regression Model. Inferences from the Estimated Regression Function. Model Checking and Other Aspects of Regression. Multivariate Multiple Regression. The Concept of Linear Regression. Comparing the Two Formulations of the Regression Model. Multiple Regression Models with Time Dependant Errors. Supplement 7A The Distribution of the Likelihood Ratio for the Multivariate Regression Model. III. ANALYSIS OF A COVARIANCE STRUCTURE. 8. Principal Components. Population Principal Components. Summarizing Sample Variation by Principal Components. Graphing the Principal Components. Large-Sample Inferences. Monitoring Quality with Principal Components. Supplement 8A The Geometry of the Sample Principal Component Approximation. 9. Factor Analysis and Inference for Structured Covariance Matrices. The Orthogonal Factor Model. Methods of Estimation. Factor Rotation. Factor Scores. Perspectives and a Strategy for Factor Analysis. Structural Equation Models. Supplement 9A Some Computational Details for Maximum Likelihood Estimation. 10. Canonical Correlation Analysis Canonical Variates and Canonical Correlations. Interpreting the Population Canonical Variables. The Sample Canonical Variates and Sample Canonical Correlations. Additional Sample Descriptive Measures. Large Sample Inferences. IV. CLASSIFICATION AND GROUPING TECHNIQUES. 11. Discrimination and Classification. Separation and Classification for Two Populations. Classifications with Two Multivariate Normal Populations. Evaluating Classification Functions. Fisher's Discriminant Function...nSeparation of Populations. Classification with Several Populations. Fisher's Method for Discriminating among Several Populations. Final Comments. 12. Clustering, Distance Methods and Ordination. Similarity Measures. Hierarchical Clustering Methods. Nonhierarchical Clustering Methods. Multidimensional Scaling. Correspondence Analysis. Biplots for Viewing Sample Units and Variables. Procustes Analysis: A Method for Comparing Configurations. Appendix. Standard Normal Probabilities. Student's t-Distribution Percentage Points. ...c2 Distribution Percentage Points. F-Distribution Percentage Points. F-Distribution Percentage Points (...a = .10). F-Distribution Percentage Points (...a = .05). F-Distribution Percentage Points (...a = .01). Data Index. Subject Index.","['Mathematics', 'Multivariate normal distribution', 'Matrix t-distribution', 'Statistics', 'Multivariate statistics', 'Scatter matrix', 'Covariance matrix', 'Multivariate t-distribution', 'Estimation of covariance matrices', 'Multivariate random variable', 'Sampling distribution', 'Sample size determination', 'Population', 'Random variable', 'Demography', 'Sociology']","multivariate analysis, multivariate techniques, data displays, pictorial representations, matrix algebra, random vectors, vector algebra, positive definite matrices, random vectors, mean vectors, covariance matrices, matrix inequalities, sample geometry, random sampling, covariance matrix, generalized variance, co, sample, multivariate normal distribution, multivariate normal density, multivariate normal distribution, maximum likelihood estimation, sampling distribution, mean, likelihood, confidence regions, simultaneous, multivariate quality control charts, mean, time, ellipses, repeated measures design, ##variate population, simultaneous confidence intervals, treatment, profile analysis, repealed measures, growth curves, multivariate linear regression, classical linear regression model, least squares estimation, model checking, multivariate multiple regression, linear regression, multiple regression models, time"
Paper_01069,Atoms in molecules : a quantum theory,['Richard F. W. Bader'],1990,['Annual Review of Physical Chemistry'],Unknown,,251-280,15,1,10.1146/annurev.pc.15.100164.001343,List of symbols 1. Atoms in chemistry 2. Atoms and the topology of the charge desnity 3. Molecular structure and its change 4. Mathematical models of structural change 5. The quantum atom 6. The mechanics of an atom in a molecule 7. Chemical models and the Laplacian of the charge density 8. The action principle for a quantunm subsystem Appendix - Tables of data Index,"['Atoms in molecules', 'Atom (system on chip)', 'Charge (physics)', 'Quantum chemistry', 'Molecule', 'Laplace operator', 'Quantum mechanics', 'Action (physics)', 'Quantum', 'Charge density', 'Physics', 'Quantum chemical', 'Density functional theory', 'Theoretical physics', 'Topology (electrical circuits)', 'Computational chemistry', 'Chemistry', 'Mathematics', 'Computer science', 'Combinatorics', 'Supramolecular chemistry', 'Embedded system']","topology, charge desnity, molecular structure, mathematical models, structural change, quantum atom, chemical models, laplacian, charge density, action principle, quantun, data index, [PAD] [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD] [PAD], [PAD] [PAD], [PAD] [PAD]"
Paper_01070,A New Two-Constant Equation of State,"['Ding‐Yu Peng', 'Donald B. Robinson']",1976,Industrial & Engineering Chemistry Fundamentals,Journal,,59-64,15,1,10.1021/i160057a011,"ADVERTISEMENT RETURN TO ISSUEPREVArticleNEXTA New Two-Constant Equation of StateDing-Yu Peng and Donald B. RobinsonCite this: Ind. Eng. Chem. Fundamen. 1976, 15, 1, 59–64Publication Date (Print):February 1, 1976Publication History Published online1 May 2002Published inissue 1 February 1976https://pubs.acs.org/doi/10.1021/i160057a011https://doi.org/10.1021/i160057a011research-articleACS PublicationsRequest reuse permissionsArticle Views21168Altmetric-Citations9849LEARN ABOUT THESE METRICSArticle Views are the COUNTER-compliant sum of full text article downloads since November 2008 (both PDF and HTML) across all institutions and individuals. These metrics are regularly updated to reflect usage leading up to the last few days.Citations are the number of other articles citing this article, calculated by Crossref and updated daily. Find more information about Crossref citation counts.The Altmetric Attention Score is a quantitative measure of the attention that a research article has received online. Clicking on the donut icon will load a page at altmetric.com with additional details about the score and the social media presence for the given article. Find more information on the Altmetric Attention Score and how the score is calculated. Share Add toView InAdd Full Text with ReferenceAdd Description ExportRISCitationCitation and abstractCitation and referencesMore Options Share onFacebookTwitterWechatLinked InRedditEmail Other access options Get e-Alerts","['Citation', 'Icon', 'Computer science', 'Constant (computer programming)', 'Social media', 'Altmetrics', 'World Wide Web', 'Programming language']","permissionsarticle views, ##le, cross, ##f, cross, ##f, altmetric attention score, social media presence, altmetric attention score, reference, ##riscitation, abstract, ##ation, references"
Paper_01075,Sorafenib in Advanced Hepatocellular Carcinoma,"['Josep M. Llovet', 'Sergio Ricci', 'Vincenzo Mazzaferro', 'Philip Hilgard', 'Edward Gane', 'Jean Frédéric Blanc', 'André Cosme de Oliveira', 'Armando Santoro', 'Jean‐Luc Raoul', 'Alejandro Forner', 'Myron Schwartz', 'Camillo Porta', 'Stefan Zeuzem', 'Luigi Bolondi', 'Tim F. Greten', 'Peter R. Galle', 'Jean François Seitz', 'Ivan Borbath', 'Dieter Häussinger', 'Tom Giannaris', 'Minghua Shan', 'M. Moscovici', 'D. Voliotis', 'Jordi Bruix']",2008,New England Journal of Medicine,Journal,,378-390,359,4,10.1056/nejmoa0708857,"No effective systemic therapy exists for patients with advanced hepatocellular carcinoma. A preliminary study suggested that sorafenib, an oral multikinase inhibitor of the vascular endothelial growth factor receptor, the platelet-derived growth factor receptor, and Raf may be effective in hepatocellular carcinoma.","['Sorafenib', 'Hepatocellular carcinoma', 'Medicine', 'Internal medicine', 'Vascular endothelial growth factor', 'Carcinoma', 'VEGF receptors', 'Oncology', 'Cancer research']","systemic therapy, sorafeni, oral multikinase inhibitor, vascular endothelial growth factor receptor, raf, ##pa, ##cellular carcinoma, [PAD] [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD], [PAD] [PAD], [PAD], [PAD], [PAD] [PAD], [PAD] [PAD] [PAD] [PAD], [PAD], [PAD] [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD], [PAD] [PAD], [PAD], [PAD], [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD], [PAD], [PAD], [PAD]"
Paper_01077,A default mode of brain function,"['Marcus E. Raichle', 'Ann Mary MacLeod', 'Abraham Z. Snyder', 'William J. Powers', 'Debra A. Gusnard', 'Gordon L. Shulman']",2001,Proceedings of the National Academy of Sciences,Journal,,676-682,98,2,10.1073/pnas.98.2.676,"A baseline or control state is fundamental to the understanding of most complex systems. Defining a baseline state in the human brain, arguably our most complex system, poses a particular challenge. Many suspect that left unconstrained, its activity will vary unpredictably. Despite this prediction we identify a baseline state of the normal adult human brain in terms of the brain oxygen extraction fraction or OEF. The OEF is defined as the ratio of oxygen used by the brain to oxygen delivered by flowing blood and is remarkably uniform in the awake but resting state (e.g., lying quietly with eyes closed). Local deviations in the OEF represent the physiological basis of signals of changes in neuronal activity obtained with functional MRI during a wide variety of human behaviors. We used quantitative metabolic and circulatory measurements from positron-emission tomography to obtain the OEF regionally throughout the brain. Areas of activation were conspicuous by their absence. All significant deviations from the mean hemisphere OEF were increases, signifying deactivations, and resided almost exclusively in the visual system. Defining the baseline state of an area in this manner attaches meaning to a group of areas that consistently exhibit decreases from this baseline, during a wide variety of goal-directed behaviors monitored with positron-emission tomography and functional MRI. These decreases suggest the existence of an organized, baseline default mode of brain function that is suspended during specific goal-directed behaviors.","['Default mode network', 'Human brain', 'Baseline (sea)', 'Resting state fMRI', 'Positron emission tomography', 'Neuroscience', 'Brain activity and meditation', 'Psychology', 'Functional magnetic resonance imaging', 'Electroencephalography', 'Biology', 'Fishery']","human brain, brain oxygen extraction fraction, ne, functional mri, quantitative metabolic, circulatory measurements, mean hemisphere"
Paper_01078,"Prejudice, social stress, and mental health in lesbian, gay, and bisexual populations: Conceptual issues and research evidence.",['Ilan H. Meyer'],2003,Psychological Bulletin,Journal,,674-697,129,5,10.1037/0033-2909.129.5.674,"In this article the author reviews research evidence on the prevalence of mental disorders in lesbians, gay men, and bisexuals (LGBs) and shows, using meta-analyses, that LGBs have a higher prevalence of mental disorders than heterosexuals. The author offers a conceptual framework for understanding this excess in prevalence of disorder in terms of minority stress--explaining that stigma, prejudice, and discrimination create a hostile and stressful social environment that causes mental health problems. The model describes stress processes, including the experience of prejudice events, expectations of rejection, hiding and concealing, internalized homophobia, and ameliorative coping processes. This conceptual framework is the basis for the review of research evidence, suggestions for future research directions, and exploration of public policy implications.","['Prejudice (legal term)', 'Mental health', 'Psychology', 'Minority stress', 'Lesbian', 'Stigma (botany)', 'Homosexuality', 'Social psychology', 'Coping (psychology)', 'Social stigma', 'Mental illness', 'Clinical psychology', 'Sexual orientation', 'Sexual minority', 'Psychotherapist', 'Psychiatry', 'Medicine', 'Psychoanalysis', 'Family medicine', 'Human immunodeficiency virus (HIV)']","mental disorders, lesbian, gay men, bisexual, lgb, minority stress, prejudice, stress processes, prejudice, internalized homophobia, ameliorative coping processes, public policy"
Paper_01079,Estimating Nonresponse Bias in Mail Surveys,"['J. Scott Armstrong', 'Terry Overton']",1977,Journal of Marketing Research,Journal,,396-396,14,3,10.2307/3150783,"Valid predictions for the direction of nonresponse bias were obtained from subjective estimates and extrapolations in an analysis of mail survey data from published studies. For estimates of the magnitude of bias, the use of extrapolations led to substantial improvements over a strategy of not using extrapolations.","['Non-response bias', 'Econometrics', 'Postal service', 'Statistics', 'Psychology', 'Advertising', 'Computer science', 'Business', 'Economics', 'Mathematics', 'Political science', 'Public administration']","nonresponse bias, subjective estimates, extra, ##ations, mail survey data, extra, ##ations, ##ations, [PAD], [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD], [PAD], [PAD]"
Paper_01080,Trim and Fill: A Simple Funnel‐Plot–Based Method of Testing and Adjusting for Publication Bias in Meta‐Analysis,"['Sue Duval', 'Richard L. Tweedie']",2000,Biometrics,Journal,,455-463,56,2,10.1111/j.0006-341x.2000.00455.x,"We study recently developed nonparametric methods for estimating the number of missing studies that might exist in a meta-analysis and the effect that these studies might have had on its outcome. These are simple rank-based data augmentation techniques, which formalize the use of funnel plots. We show that they provide effective and relatively powerful tests for evaluating the existence of such publication bias. After adjusting for missing studies, we find that the point estimate of the overall effect size is approximately correct and coverage of the effect size confidence intervals is substantially improved, in many cases recovering the nominal confidence levels entirely. We illustrate the trim and fill method on existing meta-analyses of studies in clinical trials and psychometrics.","['Publication bias', 'Funnel plot', 'Meta-analysis', 'Confidence interval', 'Statistics', 'Nonparametric statistics', 'Computer science', 'Point estimation', 'Econometrics', 'Missing data', 'Covariate', 'Simple (philosophy)', 'Sample size determination', 'Trim', 'Statistical hypothesis testing', 'Mathematics', 'Medicine', 'Philosophy', 'Epistemology', 'Internal medicine', 'Operating system']","nonparametric methods, missing studies, funnel plots, publication bias, effect size confidence intervals, clinical trials, psychometrics"
Paper_01081,The Sciences of the Artificial,['Herbert A. Simon'],1969,['The American Journal of Psychology'],Unknown,,139,83,1,10.2307/1420867,"Continuing his exploration of the organization of complexity and the science of design, this new edition of Herbert Simon's classic work on artificial intelligence adds a chapter that sorts out the current themes and tools -- chaos, adaptive systems, genetic algorithms -- for analyzing complexity and complex systems. There are updates throughout the book as well. These take into account important advances in cognitive psychology and the science of design while confirming and extending the book's basic thesis: that a physical symbol system has the necessary and sufficient means for intelligent action. The chapter Economic Reality has also been revised to reflect a change in emphasis in Simon's thinking about the respective roles of organizations and markets in economic systems.","['Cognitive science', 'Action (physics)', 'Complex adaptive system', 'Computer science', 'Management science', 'Symbol (formal)', 'Artificial intelligence', 'Cognition', 'Data science', 'Engineering', 'Psychology', 'Physics', 'Quantum mechanics', 'Neuroscience', 'Programming language']","design, artificial intelligence, chaos, adaptive systems, genetic algorithms, complex systems, cognitive psychology, design, physical symbol system, economic reality, economic systems"
Paper_01083,Bioconductor: open software development for computational biology and bioinformatics,"['Robert Gentleman', 'Vincent J. Carey', 'Douglas M. Bates', 'Ben Bolstad', 'Marcel Dettling', 'Sandrine Dudoit', 'Byron Ellis', 'Laurent Gautier', 'Yongchao Ge', 'Jeff Gentry', 'Kurt Hornik', 'Torsten Hothorn', 'Wolfgang Huber', 'Stefano M. Iacus', 'Rafael A. Irizarry', 'Friedrich Leisch', 'Cheng Li', 'Martin Maechler', 'Anthony Rossini', 'Günther Sawitzki', 'Colin A. Smith', 'Gordon K. Smyth', 'Luke Tierney', 'Jean Yang', 'Jianhua Zhang']",2004,Genome biology,Journal,,,5,10,10.1186/gb-2004-5-10-r80,"Abstract The Bioconductor project is an initiative for the collaborative creation of extensible software for computational biology and bioinformatics. The goals of the project include: fostering collaborative development and widespread use of innovative software, reducing barriers to entry into interdisciplinary scientific research, and promoting the achievement of remote reproducibility of research results. We describe details of our aims and methods, identify current challenges, compare Bioconductor to other open bioinformatics projects, and provide working examples.","['Bioconductor', 'Software', 'Biology', 'Data science', 'Bioinformatics', 'Computer science', 'Computational biology', 'Software engineering', 'Genetics', 'Programming language', 'Gene']","bio, ##ductor, extensible software, computational biology, bioinformatics, collaborative development, interdisciplinary scientific research, remote reproducibility, open bioinformatics"
Paper_01084,Detailed Balance Limit of Efficiency of <i>p-n</i> Junction Solar Cells,"['W. Shockley', 'H. J. Queisser']",1961,Journal of Applied Physics,Journal,,510-519,32,3,10.1063/1.1736034,"In order to find an upper theoretical limit for the efficiency of p‐n junction solar energy converters, a limiting efficiency, called the detailed balance limit of efficiency, has been calculated for an ideal case in which the only recombination mechanism of hole‐electron pairs is radiative as required by the principle of detailed balance. The efficiency is also calculated for the case in which radiative recombination is only a fixed fraction fc of the total recombination, the rest being nonradiative. Efficiencies at the matched loads have been calculated with band gap and fc as parameters, the sun and cell being assumed to be blackbodies with temperatures of 6000°K and 300°K, respectively. The maximum efficiency is found to be 30% for an energy gap of 1.1 ev and fc = 1. Actual junctions do not obey the predicted current‐voltage relationship, and reasons for the difference and its relevance to efficiency are discussed.","['Detailed balance', 'Radiative transfer', 'Band gap', 'Physics', 'Energy conversion efficiency', 'Limit (mathematics)', 'Spontaneous emission', 'Energy balance', 'Recombination', 'Atomic physics', 'Solar cell efficiency', 'Electron', 'Solar cell', 'Computational physics', 'Condensed matter physics', 'Chemistry', 'Thermodynamics', 'Optics', 'Optoelectronics', 'Quantum mechanics', 'Mathematics', 'Mathematical analysis', 'Laser', 'Biochemistry', 'Gene']","solar energy converters, detailed balance limit, recombination mechanism, detailed balance, ra, ##tive rec, matched loads, band gap"
Paper_01085,Physical chemistry of surfaces,['Arthur W. Adamson'],1998,Choice Reviews Online,Journal,,35-4499,35,08,10.5860/choice.35-4499,"Capillarity. The Nature and Thermodynamics of Liquid Interfaces. Surface Films on Liquid Substrates. Electrical Aspects of Surface Chemistry. Long--Range Forces. Surfaces of Solids. Surfaces of Solids: Microscopy and Spectroscopy. The Formation of a New Phase--Nucleation and Crystal Growth. The Solid--Liquid Interface--Contact Angle. The Solid--Liquid Interface--Adsorption from Solution. Frication, Lubrication, and Adhesion. Wetting, Flotation, and Detergency. Emulsions, Foams, and Aerosols. Macromolecular Surface Films, Charged Films, and Langmuir--Blodgett Layers. The Solid--Gas Interface--General Considerations. Adsorption of Gases and Vapors on Solids. Chemisorption and Catalysis. Index.","['Chemistry', 'Polymer science']","capillarity, the, liquid interfaces, surface films, liquid substrates, electrical, surface chemistry, surfaces, surfaces, microscopy, spectroscopy, nucleation, crystal growth, contact angle, frication, lubrication, adhesion, wetting, flotation, detergency, emulsion, foam, aerosols, macromolecular surface films, charged films, ##t, adsor, chemisorption, catalysis"
Paper_01088,An Integrative Theory of Prefrontal Cortex Function,"['Earl K. Miller', 'Jonathan D. Cohen']",2001,Annual Review of Neuroscience,Journal,,167-202,24,1,10.1146/annurev.neuro.24.1.167,"▪ Abstract The prefrontal cortex has long been suspected to play an important role in cognitive control, in the ability to orchestrate thought and action in accordance with internal goals. Its neural basis, however, has remained a mystery. Here, we propose that cognitive control stems from the active maintenance of patterns of activity in the prefrontal cortex that represent goals and the means to achieve them. They provide bias signals to other brain structures whose net effect is to guide the flow of activity along neural pathways that establish the proper mappings between inputs, internal states, and outputs needed to perform a given task. We review neurophysiological, neurobiological, neuroimaging, and computational studies that support this theory and discuss its implications as well as further issues to be addressed","['Prefrontal cortex', 'Neuroscience', 'Neurophysiology', 'Self-reference effect', 'Cognition', 'Neuroimaging', 'Psychology', 'Functional neuroimaging', 'Cognitive psychology', 'Task (project management)', 'Consumer neuroscience', 'Cognitive science', 'Action (physics)', 'Physics', 'Management', 'Quantum mechanics', 'Economics']","prefrontal cortex, cognitive control, cognitive control, pre, ##al cortex, bias signals, neuroimaging, computational studies"
Paper_01089,Scale-space and edge detection using anisotropic diffusion,"['Pietro Perona', 'Jitendra Malik']",1990,IEEE Transactions on Pattern Analysis and Machine Intelligence,Journal,,629-639,12,7,10.1109/34.56205,"A new definition of scale-space is suggested, and a class of algorithms used to realize a diffusion process is introduced. The diffusion coefficient is chosen to vary spatially in such a way as to encourage intraregion smoothing rather than interregion smoothing. It is shown that the 'no new maxima should be generated at coarse scales' property of conventional scale space is preserved. As the region boundaries in the approach remain sharp, a high-quality edge detector which successfully exploits global information is obtained. Experimental results are shown on a number of images. Parallel hardware implementations are made feasible because the algorithm involves elementary, local operations replicated over the image.< <ETX xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">&gt;</ETX>","['Scale space', 'Smoothing', 'Anisotropic diffusion', 'Scale (ratio)', 'Computer science', 'Maxima and minima', 'Diffusion', 'Space (punctuation)', 'Class (philosophy)', 'Edge detection', 'Enhanced Data Rates for GSM Evolution', 'Boundary (topology)', 'Algorithm', 'Artificial intelligence', 'Computer vision', 'Image (mathematics)', 'Mathematics', 'Image processing', 'Mathematical analysis', 'Physics', 'Quantum mechanics', 'Thermodynamics', 'Operating system']","diffusion process, diffusion coefficient, intraregion smoothing, interregion smoothing, scale space, region boundaries, parallel hardware implementations, local operations, xlink"
Paper_01091,Rectified Linear Units Improve Restricted Boltzmann Machines,"['Vinod Nair', 'Geoffrey E. Hinton']",2010,['IEEE Transactions on Neural Networks and Learning Systems'],Conference,,4806-4815,31,11,10.1109/tnnls.2019.2958103,"Restricted Boltzmann machines were developed using binary stochastic hidden units. These can be generalized by replacing each binary unit by an infinite number of copies that all have the same weights but have progressively more negative biases. The learning and inference rules for these Stepped Sigmoid Units are unchanged. They can be approximated efficiently by noisy, rectified linear units. Compared with binary units, these units learn features that are better for object recognition on the NORB dataset and face verification on the Labeled Faces in the Wild dataset. Unlike binary units, rectified linear units preserve information about relative intensities as information travels through multiple layers of feature detectors.","['Boltzmann machine', 'Binary number', 'Sigmoid function', 'Computer science', 'Object (grammar)', 'Restricted Boltzmann machine', 'Artificial intelligence', 'Inference', 'Pattern recognition (psychology)', 'Feature (linguistics)', 'Cognitive neuroscience of visual object recognition', 'Algorithm', 'Mathematics', 'Computer vision', 'Deep learning', 'Arithmetic', 'Artificial neural network', 'Linguistics', 'Philosophy']","restricted boltzmann machines, binary stochastic hidden units, learning, inference rules, stepped sigmoid units, ##fied linear units, object recognition, norb, face verification, wild dataset, binary units, ##fied linear units, relative intensities, feature detectors, [PAD], [PAD]"
Paper_01093,"SwissADME: a free web tool to evaluate pharmacokinetics, drug-likeness and medicinal chemistry friendliness of small molecules","['Antoine Daina', 'Olivier Michielin', 'Vincent Zoete']",2017,Scientific Reports,Journal,,,7,1,10.1038/srep42717,"To be effective as a drug, a potent molecule must reach its target in the body in sufficient concentration, and stay there in a bioactive form long enough for the expected biologic events to occur. Drug development involves assessment of absorption, distribution, metabolism and excretion (ADME) increasingly earlier in the discovery process, at a stage when considered compounds are numerous but access to the physical samples is limited. In that context, computer models constitute valid alternatives to experiments. Here, we present the new SwissADME web tool that gives free access to a pool of fast yet robust predictive models for physicochemical properties, pharmacokinetics, drug-likeness and medicinal chemistry friendliness, among which in-house proficient methods such as the BOILED-Egg, iLOGP and Bioavailability Radar. Easy efficient input and interpretation are ensured thanks to a user-friendly interface through the login-free website http://www.swissadme.ch. Specialists, but also nonexpert in cheminformatics or computational chemistry can predict rapidly key parameters for a collection of molecules to support their drug discovery endeavours.","['Cheminformatics', 'ADME', 'Drug discovery', 'Context (archaeology)', 'Computer science', 'Interface (matter)', 'Login', 'Pharmacokinetics', 'Biochemical engineering', 'Data science', 'Chemistry', 'Pharmacology', 'Bioinformatics', 'Molecule', 'Computational chemistry', 'Medicine', 'Biology', 'Engineering', 'Organic chemistry', 'Computer network', 'Gibbs isotherm', 'Paleontology']","drug development, ##cre, computer models, swissadme, predictive, ##ysicochemical properties, pharmacokinetics, medicinal chemistry, ilogp, bioavailability radar, swissad, cheminformatics, computational chemistry"
Paper_01095,Discourse and Social Change.,"['Dwight Fee', 'Norman Fairclough']",1993,Contemporary Sociology A Journal of Reviews,Journal,,732-732,22,5,10.2307/2074659,"Approaches to discourse analysis Michel Foucault and analysis of discourse a social theory of discourse intertextuality text analysis - constructing social relations and the self, constructing social reality discourse and social change in contemporary society doing discourse analysis.","['Sociology', 'Political science']","discourse analysis, analysis, discourse, social theory, discourse intertextuality text analysis, social relations, social reality, social change, contemporary society, discourse analysis, [PAD] [PAD]"
Paper_01096,Negative Refraction Makes a Perfect Lens,['J. B. Pendry'],2000,Physical Review Letters,Journal,,3966-3969,85,18,10.1103/physrevlett.85.3966,"With a conventional lens sharpness of the image is always limited by the wavelength of light. An unconventional alternative to a lens, a slab of negative refractive index material, has the power to focus all Fourier components of a 2D image, even those that do not propagate in a radiative manner. Such ""superlenses"" can be realized in the microwave band with current technology. Our simulations show that a version of the lens operating at the frequency of visible light can be realized in the form of a thin slab of silver. This optical version resolves objects only a few nanometers across.","['Lens (geology)', 'Optics', 'Superlens', 'Slab', 'Refractive index', 'Negative refraction', 'Wavelength', 'Refraction', 'Focus (optics)', 'Fourier transform', 'Physics', 'Metamaterial', 'Materials science', 'Optoelectronics', 'Quantum mechanics', 'Geophysics']","negative refractive index material, fourier components, microwave band"
Paper_01097,Mechanisms of Salinity Tolerance,"['Rana Munns', 'Mark Tester']",2008,Annual Review of Plant Biology,Journal,,651-681,59,1,10.1146/annurev.arplant.59.032607.092911,"The physiological and molecular mechanisms of tolerance to osmotic and ionic components of salinity stress are reviewed at the cellular, organ, and whole-plant level. Plant growth responds to salinity in two phases: a rapid, osmotic phase that inhibits growth of young leaves, and a slower, ionic phase that accelerates senescence of mature leaves. Plant adaptations to salinity are of three distinct types: osmotic stress tolerance, Na(+) or Cl() exclusion, and the tolerance of tissue to accumulated Na(+) or Cl(). Our understanding of the role of the HKT gene family in Na(+) exclusion from leaves is increasing, as is the understanding of the molecular bases for many other transport processes at the cellular level. However, we have a limited molecular understanding of the overall control of Na(+) accumulation and of osmotic stress tolerance at the whole-plant level. Molecular genetics and functional genomics provide a new opportunity to synthesize molecular and physiological knowledge to improve the salinity tolerance of plants relevant to food production and environmental sustainability.","['Salinity', 'Osmotic shock', 'Biology', 'Osmotic pressure', 'Botany', 'Functional genomics', 'Biochemistry', 'Biophysics', 'Gene', 'Genomics', 'Genome', 'Ecology']","salinity stress, plant growth, osmotic stress tolerance, hkt, osmotic stress tolerance, molecular genetics, functional genomics, salinity tolerance, food production, environmental sustainability"
Paper_01099,Naturalis Biodiversity Center (NL) - Botany,['Jeroen Creuwels'],2017,Unknown,Unknown,,,,,10.15468/ib5ypt,"This database contains specimen records from the former herbarium of the Leiden University within the botanical collection of the Naturalis Biodiversity Center (Leiden, Netherlands). The Department of Botany houses the National Herbarium of the Netherlands (NHN) which consists of herbarium collections of the universities of Leiden, Wageningen and Utrecht. In 2010 the collection of the University of Amsterdam also moved to Naturalis.The focal areas of the collection are Southeast Asia, tropical America, tropical Africa and the Netherlands. The former herbarium of the Leiden University (acronym: L) contains about 4 million specimens and has extensive collections from Southeast Asia, especially from Indonesia and New Guinea, but it also holds a large collection of palearctic plants, and is the principle herbarium for Dutch plants. As the oldest Dutch herbarium, it also contains several historic collections.","['Herbarium', 'Geography', 'Biodiversity', 'Botanical garden', 'Archaeology', 'Library science', 'Botany', 'Ecology', 'Biology', 'Computer science']","natural, southeast asia, tropical america, tropical africa, palearctic plants"
Paper_01100,"Cancer statistics, 2013","['Rebecca L. Siegel', 'Deepa Naishadham', 'Ahmedin Jemal']",2013,CA A Cancer Journal for Clinicians,Journal,,11-30,63,1,10.3322/caac.21166,"Abstract Each year, the American Cancer Society estimates the numbers of new cancer cases and deaths expected in the United States in the current year and compiles the most recent data on cancer incidence, mortality, and survival based on incidence data from the National Cancer Institute, the Centers for Disease Control and Prevention, and the North American Association of Central Cancer Registries and mortality data from the National Center for Health Statistics. A total of 1,660,290 new cancer cases and 580,350 cancer deaths are projected to occur in the United States in 2013. During the most recent 5 years for which there are data (2005‐2009), delay‐adjusted cancer incidence rates declined slightly in men (by 0.6% per year) and were stable in women, while cancer death rates decreased by 1.8% per year in men and by 1.5% per year in women. Overall, cancer death rates have declined 20% from their peak in 1991 (215.1 per 100,000 population) to 2009 (173.1 per 100,000 population). Death rates continue to decline for all 4 major cancer sites (lung, colorectum, breast, and prostate). Over the past 10 years of data (2000‐2009), the largest annual declines in death rates were for chronic myeloid leukemia (8.4%), cancers of the stomach (3.1%) and colorectum (3.0%), and non‐Hodgkin lymphoma (3.0%). The reduction in overall cancer death rates since 1990 in men and 1991 in women translates to the avoidance of approximately 1.18 million deaths from cancer, with 152,900 of these deaths averted in 2009 alone. Further progress can be accelerated by applying existing cancer control knowledge across all segments of the population, with an emphasis on those groups in the lowest socioeconomic bracket and other underserved populations. CA Cancer J Clin 2013;. © 2013 American Cancer Society.","['Medicine', 'Cancer', 'Demography', 'Population', 'Mortality rate', 'Prostate cancer', 'Lung cancer', 'Breast cancer', 'Incidence (geometry)', 'Cancer registry', 'Cause of death', 'Stomach cancer', 'Disease', 'Internal medicine', 'Environmental health', 'Physics', 'Sociology', 'Optics']","american cancer society, central cancer registries, women, women, chronic myeloid leukemia, non ‐ hod, women, cancer control, american cancer society"
Paper_01102,Harrison's Principles of Internal Medicine.,"[""edotir's Eugene Braunwald...""]",1988,Annals of Internal Medicine,Journal,,499-499,108,3,10.7326/0003-4819-108-3-499_2,"Introduction To Clinical Medicine Cardinal Manifestations Of Disease Genetics And Disease Clinical Pharmacology Nutrition Infectious Disease Disorders Of The Cardiovascular System Disorders Of The Kidney And Urinary Tract Disorders Of The Gastrointestinal System Disorders Of The Immune System, Connective Tissue And Joints Hematology And Oncology Endocrinology And Metabolism Neurologic Disorders Environmental And Occupational Hazards.",['Medicine'],"clinical medicine, infectious disease, cardiovascular system, urinary tract, gastrointestinal system, ##ive, joints, metabolism, occupational hazards, [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD]"
Paper_01103,The Theory of Social and Economic Organization.,"['Gottfried Salomon Delatour', 'Max Weber', 'A. M. Henderson', 'Talcott Parsons']",1948,American Sociological Review,Journal,,349-349,13,3,10.2307/2086579,"The Theory of Social and Economic Organization grew out of Weber’s philosophical inquiries into the nature of authority and how it is transmitted. He identified three types of authority: the charismatic, based on the individual qualities of a leader and reverence for them among his or her followers; the traditional, based on custom and usage; and the rational-legal, based on the rule of objective law.","['Sociology', 'Political science', 'Psychology', 'Positive economics', 'Neoclassical economics', 'Economics']","social, economic organization, authority, charismatic, objective law"
Paper_01104,Towards a Methodology for Developing Evidence‐Informed Management Knowledge by Means of Systematic Review,"['David Tranfield', 'David Denyer', 'Palie Smart']",2003,British Journal of Management,Journal,,207-222,14,3,10.1111/1467-8551.00375,"Undertaking a review of the literature is an important part of any research project. The researcher both maps and assesses the relevant intellectual territory in order to specify a research question which will further develop the knowledge base. However, traditional 'narrative' reviews frequently lack thoroughness, and in many cases are not undertaken as genuine pieces of investigatory science. Consequently they can lack a means for making sense of what the collection of studies is saying. These reviews can be biased by the researcher and often lack rigour. Furthermore, the use of reviews of the available evidence to provide insights and guidance for intervention into operational needs of practitioners and policymakers has largely been of secondary importance. For practitioners, making sense of a mass of often-contradictory evidence has become progressively harder. The quality of evidence underpinning decision-making and action has been questioned, for inadequate or incomplete evidence seriously impedes policy formulation and implementation. In exploring ways in which evidence-informed management reviews might be achieved, the authors evaluate the process of systematic review used in the medical sciences. Over the last fifteen years, medical science has attempted to improve the review process by synthesizing research in a systematic, transparent, and reproducible manner with the twin aims of enhancing the knowledge base and informing policymaking and practice. This paper evaluates the extent to which the process of systematic review can be applied to the management field in order to produce a reliable knowledge stock and enhanced practice by developing context-sensitive research. The paper highlights the challenges in developing an appropriate methodology.","['Rigour', 'Systematic review', 'Context (archaeology)', 'Underpinning', 'Engineering ethics', 'Process (computing)', 'Narrative', 'Knowledge base', 'Management science', 'Psychology', 'Public relations', 'Knowledge management', 'Computer science', 'Political science', 'MEDLINE', 'Epistemology', 'Engineering', 'Paleontology', 'Philosophy', 'Linguistics', 'Civil engineering', 'World Wide Web', 'Law', 'Biology', 'Operating system']","operational, systematic review, medical sciences, medical science, systematic review"
Paper_01107,Sources of Method Bias in Social Science Research and Recommendations on How to Control It,"['Philip M. Podsakoff', 'Scott MacKenzie', 'Nathan P. Podsakoff']",2011,Annual Review of Psychology,Journal,,539-569,63,1,10.1146/annurev-psych-120710-100452,"Despite the concern that has been expressed about potential method biases, and the pervasiveness of research settings with the potential to produce them, there is disagreement about whether they really are a problem for researchers in the behavioral sciences. Therefore, the purpose of this review is to explore the current state of knowledge about method biases. First, we explore the meaning of the terms ""method"" and ""method bias"" and then we examine whether method biases influence all measures equally. Next, we review the evidence of the effects that method biases have on individual measures and on the covariation between different constructs. Following this, we evaluate the procedural and statistical remedies that have been used to control method biases and provide recommendations for minimizing method bias.","['Psychology', 'Control (management)', 'Meaning (existential)', 'Cognitive psychology', 'Behavioural sciences', 'Response bias', 'Common-method variance', 'Social psychology', 'Computer science', 'Artificial intelligence', 'Psychotherapist']","method biases, research settings, behavioral, method biases, method bias, method biases, method biases, ##var, statistical, method biases, method bias"
Paper_01108,Lounging in a lysosome: the intracellular lifestyle of Coxiella burnetii,"['Daniel E. Voth', 'Robert A. Heinzen']",2007,Cellular Microbiology,Journal,,829-840,9,4,10.1111/j.1462-5822.2007.00901.x,"Most intracellular parasites employ sophisticated mechanisms to direct biogenesis of a vacuolar replicative niche that circumvents default maturation through the endolysosomal cascade. However, this is not the case of the Q fever bacterium, Coxiella burnetii. This hardy, obligate intracellular pathogen has evolved to not only survive, but to thrive, in the harshest of intracellular compartments: the phagolysosome. Following internalization, the nascent Coxiella phagosome ultimately develops into a large and spacious parasitophorous vacuole (PV) that acquires lysosomal characteristics such as acidic pH, acid hydrolases and cationic peptides, defences designed to rid the host of intruders. However, transit of Coxiella to this environment is initially stalled, a process that is apparently modulated by interactions with the autophagic pathway. Coxiella actively participates in biogenesis of its PV by synthesizing proteins that mediate phagosome stalling, autophagic interactions, and development and maintenance of the mature vacuole. Among the potential mechanisms mediating these processes is deployment of a type IV secretion system to deliver effector proteins to the host cytosol. Here we summarize our current understanding of the cellular events that occur during parasitism of host cells by Coxiella.","['Coxiella burnetii', 'Biology', 'Phagosome', 'Vacuole', 'Cell biology', 'Phagolysosome', 'Biogenesis', 'Intracellular parasite', 'Secretion', 'Intracellular', 'Lysosome', 'Obligate', 'Effector', 'ESCRT', 'Endosome', 'Autophagy', 'Microbiology', 'Biochemistry', 'Cytoplasm', 'Ecology', 'Gene', 'Apoptosis', 'Enzyme']","intracellular parasites, va, ##olar replicative niche, q fever, coxiel, phagolysos, cox, ##sit, ##ous vacuole, acidic ph, acid hydrolases, cationic peptides, ##phagic pathway, ##la, autophagic interactions"
Paper_01109,"Cancer statistics, 2015","['Rebecca L. Siegel', 'Kimberly D. Miller', 'Ahmedin Jemal']",2015,CA A Cancer Journal for Clinicians,Journal,,5-29,65,1,10.3322/caac.21254,"Abstract Each year the American Cancer Society estimates the numbers of new cancer cases and deaths that will occur in the United States in the current year and compiles the most recent data on cancer incidence, mortality, and survival. Incidence data were collected by the National Cancer Institute (Surveillance, Epidemiology, and End Results [SEER] Program), the Centers for Disease Control and Prevention (National Program of Cancer Registries), and the North American Association of Central Cancer Registries. Mortality data were collected by the National Center for Health Statistics. A total of 1,658,370 new cancer cases and 589,430 cancer deaths are projected to occur in the United States in 2015. During the most recent 5 years for which there are data (2007‐2011), delay‐adjusted cancer incidence rates (13 oldest SEER registries) declined by 1.8% per year in men and were stable in women, while cancer death rates nationwide decreased by 1.8% per year in men and by 1.4% per year in women. The overall cancer death rate decreased from 215.1 (per 100,000 population) in 1991 to 168.7 in 2011, a total relative decline of 22%. However, the magnitude of the decline varied by state, and was generally lowest in the South (∼15%) and highest in the Northeast (≥20%). For example, there were declines of 25% to 30% in Maryland, New Jersey, Massachusetts, New York, and Delaware, which collectively averted 29,000 cancer deaths in 2011 as a result of this progress. Further gains can be accelerated by applying existing cancer control knowledge across all segments of the population. CA Cancer J Clin 2015;65:5–29. © 2015 American Cancer Society.","['Medicine', 'Cancer', 'Demography', 'Incidence (geometry)', 'Epidemiology', 'Population', 'Cancer incidence', 'Mortality rate', 'Health statistics', 'Cancer prevention', 'Relative survival', 'Gerontology', 'Cancer registry', 'Environmental health', 'Surgery', 'Internal medicine', 'Physics', 'Sociology', 'Optics']","american cancer society, central cancer registries, women, women, cancer control, american cancer society"
Paper_01110,Childhood and Society,['Erik H. Erikson'],1950,['Journal of Mental Science'],Unknown,,673-673,43,182,10.1192/bjp.43.182.673,"The original and vastly influential ideas of Erik H. Erikson underlie much of our understanding of human development. His insights into the interdependence of the individuals' growth and historical change, his now-famous concepts of identity, growth, and the life cycle, have changed the way we perceive ourselves and society. Widely read and cited, his works have won numerous awards including the Pulitzer Prize and the National Book Award. Combining the insights of clinical psychoanalysis with new approach to cultural anthropology, Childhood and Society deals with the relationships between childhood training and cultural accomplishment, analyzing the infantile and the mature, the modern and the archaic elements in human motivation. It was hailed upon its first publication as a rare and living combination of European and American thought in the human sciences (Margaret Mead, The American Scholar). Translated into numerous foreign languages, it has gone on to become classic in the study of the social significance of childhood.","[""Erikson's stages of psychosocial development"", 'Early childhood', 'Identity (music)', 'Psychoanalysis', 'Sociology', 'History', 'Psychology', 'Anthropology', 'Environmental ethics', 'Developmental psychology', 'Aesthetics', 'Art', 'Philosophy']","human development, life cycle, clinical psychoanalysis, cultural anthropology, childhood training, cultural accomplishment, human motivation, american scholar, social significance, [PAD], [PAD] [PAD], [PAD]"
Paper_01111,"Safety, Activity, and Immune Correlates of Anti–PD-1 Antibody in Cancer","['Suzanne L. Topalian', 'F. Stephen Hodi', 'Julie R. Brahmer', 'Scott Gettinger', 'David C. Smith', 'David F. McDermott', 'John D. Powderly', 'Richard D. Carvajal', 'Jeffrey A. Sosman', 'Michael B. Atkins', 'Philip D. Leming', 'David R. Spigel', 'Scott Antonia', 'Leora Horn', 'Charles G. Drake', 'Drew M. Pardoll', 'Lieping Chen', 'William H. Sharfman', 'Robert A. Anders', 'Janis M. Taube', 'Tracee L. McMiller', 'Haiying Xu', 'Alan J. Korman', 'Maria Jure–Kunkel', 'Shruti Agrawal', 'D. G. McDonald', 'Georgia Kollia', 'Ashok Gupta', 'Jon M. Wigginton', 'Mario Sznol']",2012,New England Journal of Medicine,Journal,,2443-2454,366,26,10.1056/nejmoa1200690,"Blockade of programmed death 1 (PD-1), an inhibitory receptor expressed by T cells, can overcome immune resistance. We assessed the antitumor activity and safety of BMS-936558, an antibody that specifically blocks PD-1.","['Medicine', 'Adverse effect', 'Melanoma', 'Cancer', 'Internal medicine', 'Lung cancer', 'Immune system', 'Prostate cancer', 'Gastroenterology', 'Antibody', 'Renal cell carcinoma', 'Oncology', 'Immunology', 'Cancer research']","programmed death, inhibitory receptor, t, immune resistance, antitumor activity, [PAD], [PAD], [PAD] [PAD] [PAD] [PAD], [PAD], [PAD] [PAD], [PAD] [PAD], [PAD]"
Paper_01112,The benefits of being present: Mindfulness and its role in psychological well-being.,"['Kirk Warren Brown', 'Richard M. Ryan']",2003,Journal of Personality and Social Psychology,Journal,,822-848,84,4,10.1037/0022-3514.84.4.822,"Mindfulness is an attribute of consciousness long believed to promote well-being. This research provides a theoretical and empirical examination of the role of mindfulness in psychological well-being. The development and psychometric properties of the dispositional Mindful Attention Awareness Scale (MAAS) are described. Correlational, quasi-experimental, and laboratory studies then show that the MAAS measures a unique quality of consciousness that is related to a variety of well-being constructs, that differentiates mindfulness practitioners from others, and that is associated with enhanced self-awareness. An experience-sampling study shows that both dispositional and state mindfulness predict self-regulated behavior and positive emotional states. Finally, a clinical intervention study with cancer patients demonstrates that increases in mindfulness over time relate to declines in mood disturbance and stress.","['Mindfulness', 'Psychology', 'Experience sampling method', 'Mood', 'Well-being', 'Clinical psychology', 'Consciousness', 'Psychotherapist', 'Intervention (counseling)', 'Social psychology', 'Neuroscience', 'Psychiatry']","mindfulness, consciousness, mindfulness, psychometric, dispositional mindful attention awareness scale, clinical intervention, cancer patients, mood disturbance"
Paper_01113,Phase Transitions and Critical Phenomena,"['C. Domb', 'Melville S. Green', 'Joel L. Lebowitz']",2016,CRC Press eBooks,Unknown,,199-222,,,10.1201/9781439850541-13,"The field of phase transitions and critical phenomena continues to be active in research, producing a steady stream of interesting and fruitful results. It has moved into a central place in condensed matter studies. Statistical physics, and more specifically, the theory of transitions between states of matter, more or less defines what we know about 'everyday' matter and its transformations. The major aim of this serial is to provide review articles that can serve as standard references for research workers in the field, and for graduate students and others wishing to obtain reliable information on important recent developments.","['Materials science', 'Statistical physics', 'Physics']","phase transitions, critical phenomena, condensed matter studies, statistical physics, transitions, states, [PAD] [PAD] [PAD], [PAD]"
Paper_01114,Linear Models and Empirical Bayes Methods for Assessing Differential Expression in Microarray Experiments,['Gordon K. Smyth'],2004,Statistical Applications in Genetics and Molecular Biology,Journal,,1-25,3,1,10.2202/1544-6115.1027,"The problem of identifying differentially expressed genes in designed microarray experiments is considered. Lonnstedt and Speed (2002) derived an expression for the posterior odds of differential expression in a replicated two-color experiment using a simple hierarchical parametric model. The purpose of this paper is to develop the hierarchical model of Lonnstedt and Speed (2002) into a practical approach for general microarray experiments with arbitrary numbers of treatments and RNA samples. The model is reset in the context of general linear models with arbitrary coefficients and contrasts of interest. The approach applies equally well to both single channel and two color microarray experiments. Consistent, closed form estimators are derived for the hyperparameters in the model. The estimators proposed have robust behavior even for small numbers of arrays and allow for incomplete data arising from spot filtering or spot quality weights. The posterior odds statistic is reformulated in terms of a moderated t-statistic in which posterior residual standard deviations are used in place of ordinary standard deviations. The empirical Bayes approach is equivalent to shrinkage of the estimated sample variances towards a pooled estimate, resulting in far more stable inference when the number of arrays is small. The use of moderated t-statistics has the advantage over the posterior odds that the number of hyperparameters which need to estimated is reduced; in particular, knowledge of the non-null prior for the fold changes are not required. The moderated t-statistic is shown to follow a t-distribution with augmented degrees of freedom. The moderated t inferential approach extends to accommodate tests of composite null hypotheses through the use of moderated F-statistics. The performance of the methods is demonstrated in a simulation study. Results are presented for two publicly available data sets.","[""Bayes' theorem"", 'Mathematics', 'Statistics', 'Estimator', 'Bayes factor', 'Computer science', 'Bayesian probability']","differentially expressed genes, posterior odds, hierarchical parametric model, hierarchical model, spot filtering, spot quality weights, posterior odds statistic, posterior residual standard deviations, empirical bayes, augmented degrees of freedom, moderated, composite null hypotheses"
Paper_01116,The Impact of Trade on Intra-Industry Reallocations and Aggregate Industry Productivity,['Marc J. Melitz'],2003,Econometrica,Journal,,1695-1725,71,6,10.1111/1468-0262.00467,"This paper develops a dynamic industry model with heterogeneous firms to analyze the intra-industry effects of international trade. The model shows how the exposure to trade will induce only the more productive firms to enter the export market (while some less productive firms continue to produce only for the domestic market) and will simultaneously force the least productive firms to exit. It then shows how further increases in the industry's exposure to trade lead to additional inter-firm reallocations towards more productive firms. The paper also shows how the aggregate industry productivity growth generated by the reallocations contributes to a welfare gain, thus highlighting a benefit from trade that has not been examined theoretically before. The paper adapts Hopenhayn's (1992a) dynamic industry model to monopolistic competition in a general equilibrium setting. In so doing, the paper provides an extension of Krugman's (1980) trade model that incorporates firm level productivity differences. Firms with different productivity levels coexist in an industry because each firm faces initial uncertainty concerning its productivity before making an irreversible investment to enter the industry. Entry into the export market is also costly, but the firm's decision to export occurs after it gains knowledge of its productivity.","['Productivity', 'Aggregate (composite)', 'Intra-industry trade', 'Economics', 'Industrial organization', 'Business', 'International trade', 'Trade barrier', 'Macroeconomics', 'Materials science', 'Composite material']","dynamic industry model, heterogeneous firms, international trade, aggregate industry productivity growth, welfare gain, dynamic industry model, monopolistic competition, general, firm level productivity differences"
Paper_01121,Explicating dynamic capabilities: the nature and microfoundations of (sustainable) enterprise performance,['David J. Teece'],2007,Strategic Management Journal,Journal,,1319-1350,28,13,10.1002/smj.640,"Abstract This paper draws on the social and behavioral sciences in an endeavor to specify the nature and microfoundations of the capabilities necessary to sustain superior enterprise performance in an open economy with rapid innovation and globally dispersed sources of invention, innovation, and manufacturing capability. Dynamic capabilities enable business enterprises to create, deploy, and protect the intangible assets that support superior long‐ run business performance. The microfoundations of dynamic capabilities—the distinct skills, processes, procedures, organizational structures, decision rules, and disciplines—which undergird enterprise‐level sensing, seizing, and reconfiguring capacities are difficult to develop and deploy. Enterprises with strong dynamic capabilities are intensely entrepreneurial. They not only adapt to business ecosystems, but also shape them through innovation and through collaboration with other enterprises, entities, and institutions. The framework advanced can help scholars understand the foundations of long‐run enterprise success while helping managers delineate relevant strategic considerations and the priorities they must adopt to enhance enterprise performance and escape the zero profit tendency associated with operating in markets open to global competition. Copyright © 2007 John Wiley &amp; Sons, Ltd.","['Microfoundations', 'Dynamic capabilities', 'Ambidexterity', 'Enterprise systems engineering', 'Business', 'Industrial organization', 'Knowledge management', 'Enterprise life cycle', 'Enterprise software', 'Profit (economics)', 'Enterprise integration', 'Process management', 'Economics', 'Computer science', 'Enterprise architecture', 'Microeconomics', 'Architecture', 'Art', 'Visual arts', 'Macroeconomics']","open economy, rapid innovation, globally, manufacturing capability, dynamic capabilities, business enterprises, ##unda, dynamic capabilities, organizational structures, decision rules, dynamic capabilities, global"
Paper_01122,Representation Learning: A Review and New Perspectives,"['Yoshua Bengio', 'Aaron Courville', 'P. M. Durai Raj Vincent']",2013,IEEE Transactions on Pattern Analysis and Machine Intelligence,Journal,,1798-1828,35,8,10.1109/tpami.2013.50,"The success of machine learning algorithms generally depends on data representation, and we hypothesize that this is because different representations can entangle and hide more or less the different explanatory factors of variation behind the data. Although specific domain knowledge can be used to help design representations, learning with generic priors can also be used, and the quest for AI is motivating the design of more powerful representation-learning algorithms implementing such priors. This paper reviews recent work in the area of unsupervised feature learning and deep learning, covering advances in probabilistic models, autoencoders, manifold learning, and deep networks. This motivates longer term unanswered questions about the appropriate objectives for learning good representations, for computing representations (i.e., inference), and the geometrical connections between representation learning, density estimation, and manifold learning.","['Artificial intelligence', 'Feature learning', 'Computer science', 'Machine learning', 'Representation (politics)', 'Inference', 'Nonlinear dimensionality reduction', 'Unsupervised learning', 'Deep learning', 'Prior probability', 'External Data Representation', 'Probabilistic logic', 'Feature (linguistics)', 'Domain knowledge', 'Active learning (machine learning)', 'Semi-supervised learning', 'Bayesian probability', 'Dimensionality reduction', 'Linguistics', 'Philosophy', 'Politics', 'Political science', 'Law']","machine learning algorithms, data representation, domain knowledge, unsupervised feature learning, deep learning, probabilistic models, autoencoders, manifold learning, deep networks, representation learning, density estimation, manifold learning"
Paper_01123,WebLogo: A Sequence Logo Generator: Figure 1,"['Gavin E. Crooks', 'Gary C. Hon', 'John‐Marc Chandonia', 'Steven E. Brenner']",2004,Genome Research,Journal,,1188-1190,14,6,10.1101/gr.849004,"WebLogo generates sequence logos, graphical representations of the patterns within a multiple sequence alignment. Sequence logos provide a richer and more precise description of sequence similarity than consensus sequences and can rapidly reveal significant features of the alignment otherwise difficult to perceive. Each logo consists of stacks of letters, one stack for each position in the sequence. The overall height of each stack indicates the sequence conservation at that position (measured in bits), whereas the height of symbols within the stack reflects the relative frequency of the corresponding amino or nucleic acid at that position. WebLogo has been enhanced recently with additional features and options, to provide a convenient and highly configurable sequence logo generator. A command line interface and the complete, open WebLogo source code are available for local installation and customization.","['Sequence logo', 'Sequence (biology)', 'Generator (circuit theory)', 'Stack (abstract data type)', 'Position (finance)', 'Logos Bible Software', 'Biology', 'Similarity (geometry)', 'Computer science', 'Logo (programming language)', 'Sequence alignment', 'Artificial intelligence', 'Consensus sequence', 'Base sequence', 'Genetics', 'Programming language', 'Peptide sequence', 'DNA', 'Physics', 'Image (mathematics)', 'Power (physics)', 'Finance', 'Quantum mechanics', 'Gene', 'Economics', 'Operating system']","weblogo, sequence logos, multiple sequence alignment, sequence logos, sequence similarity, consensus sequences, sequence conservation, nucleic, weblogo, command, weblogo, [PAD]"
Paper_01125,Molecular Classification of Cancer: Class Discovery and Class Prediction by Gene Expression Monitoring,"['Todd R. Golub', 'Donna K. Slonim', 'Pablo Tamayo', 'C. Huard', 'Michelle Gaasenbeek', 'Jill P. Mesirov', 'Hilary A. Coller', 'Mignon L. Loh', 'James R. Downing', 'M. A. Caligiuri', 'C. D. Bloomfield', 'Eric S. Lander']",1999,Science,Journal,,531-537,286,5439,10.1126/science.286.5439.531,"Although cancer classification has improved over the past 30 years, there has been no general approach for identifying new cancer classes (class discovery) or for assigning tumors to known classes (class prediction). Here, a generic approach to cancer classification based on gene expression monitoring by DNA microarrays is described and applied to human acute leukemias as a test case. A class discovery procedure automatically discovered the distinction between acute myeloid leukemia (AML) and acute lymphoblastic leukemia (ALL) without previous knowledge of these classes. An automatically derived class predictor was able to determine the class of new leukemia cases. The results demonstrate the feasibility of cancer classification based solely on gene expression monitoring and suggest a general strategy for discovering and predicting cancer classes for other types of cancer, independent of previous biological knowledge.","['DNA microarray', 'Cancer', 'Class (philosophy)', 'Myeloid leukemia', 'Computational biology', 'Leukemia', 'Gene', 'Lymphoblastic Leukemia', 'Biology', 'Bioinformatics', 'Gene expression', 'Artificial intelligence', 'Computer science', 'Genetics', 'Cancer research']","cancer classification, class discovery, class prediction, cancer classification, gene expression monitoring, dna microarrays, human acute leukemias, class discovery, acute myeloid leukemia, acute lymphoblastic leukemia, automatically, cancer classification, gene expression monitoring, [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"
Paper_01126,Qualitative Analysis for Social Scientists,['Anselm L. Strauss'],1987,Unknown,Unknown,,,,,10.1017/cbo9780511557842,"The teaching of qualitative analysis in the social sciences is rarely undertaken in a structured way. This handbook is designed to remedy that and to present students and researchers with a systematic method for interpreting qualitative data', whether derived from interviews, field notes, or documentary materials. The special emphasis of the book is on how to develop theory through qualitative analysis. The reader is provided with the tools for doing qualitative analysis, such as codes, memos, memo sequences, theoretical sampling and comparative analysis, and diagrams, all of which are abundantly illustrated by actual examples drawn from the author's own varied qualitative research and research consultations, as well as from his research seminars. Many of the procedural discussions are concluded with rules of thumb that can usefully guide the researchers' analytic operations. The difficulties that beginners encounter when doing qualitative analysis and the kinds of persistent questions they raise are also discussed, as is the problem of how to integrate analyses. In addition, there is a chapter on the teaching of qualitative analysis and the giving of useful advice during research consultations, and there is a discussion of the preparation of material for publication. The book has been written not only for sociologists but for all researchers in the social sciences and in such fields as education, public health, nursing, and administration who employ qualitative methods in their work.","['Qualitative research', 'Qualitative analysis', 'Field (mathematics)', 'Rule of thumb', 'Management science', 'Engineering ethics', 'Sociology', 'Mathematics education', 'Social science', 'Psychology', 'Computer science', 'Engineering', 'Mathematics', 'Algorithm', 'Pure mathematics']","qualitative analysis, social sciences, field notes, qualitative analysis, ##alitative, codes, memos, memo sequences, theoretical sampling, comparative analysis, qualitative, qualitative analysis, social, education, public health, nursing, administration, ##alitative methods"
Paper_01127,Should We STOP Angiotensin Converting Enzyme Inhibitors/Angiotensin Receptor Blockers in Advanced Kidney Disease?,"['Aimun Ahmed', 'Tom Jorna', 'Sunil Bhandari']",2016,The Nephron journals/Nephron journals,Journal,,147-158,133,3,10.1159/000447068,"Chronic kidney disease (CKD) is a worldwide public health problem associated with a high prevalence of cardiovascular disease (CVD) and impaired quality of life. Previous research for preventing loss of glomerular filtration rate (GFR) has focused on reducing blood pressure (BP) and proteinuria. Angiotensin converting enzyme inhibitors (ACEi) and angiotensin II receptor antagonists (ARB) are commonly used in patients with early CKD, but their value in advanced CKD (estimated GFR (eGFR) ≤30 ml/min/1.73 m2) is unknown. There remains a debate about the omission of ACEi/ARB in patients with advanced CKD and their use in association with CVD or heart failure. Does the potential gain in eGFR with ACEi/ARB cessation outweigh the potential adverse cardiovascular outcomes? This paper reviews the current literature that addresses this issue. Several controversies are discussed. Although lowering BP reduces cardiovascular events, evidence suggests that ACEi/ARBs are not superior to other antihypertensive agents. There are no studies assessing the benefits of ACEi/ARB therapy in cardiovascular risk reduction in advanced non-dialysis CKD. The STOP ACEi trial will strengthen the evidence base and shed light on the potential merits and dangers of ACEi/ARB use in advanced CKD on renal function and cardiovascular outcomes.","['Medicine', 'Renal function', 'Kidney disease', 'Internal medicine', 'Blood pressure', 'Angiotensin-converting enzyme', 'Angiotensin Receptor Blockers', 'Proteinuria', 'Dialysis', 'Heart failure', 'Disease', 'Intensive care medicine', 'ACE inhibitor', 'Cardiology', 'Angiotensin receptor', 'Angiotensin II', 'Pharmacology', 'Kidney']","chronic kidney disease, public health, cardiovascular disease, glom, protein, angiotensin converting enzyme inhibitors, angiot, cardiovascular risk reduction"
Paper_01128,Nanostructured High‐Entropy Alloys with Multiple Principal Elements: Novel Alloy Design Concepts and Outcomes,"['J.‐W. Yeh', 'Swe-Kai Chen', 'Sung‐Jan Lin', 'Jie Gan', 'T.S. Chin', 'Tao-Tsung Shun', 'Chun-Huei Tsau', 'Shu–Jen Chang']",2004,Advanced Engineering Materials,Journal,,299-303,6,5,10.1002/adem.200300567,"A new approach for the design of alloys is presented in this study. These ""high-entropy alloys"" with multi-principal elements were synthesized using well-developed processing technologies. Preliminary results demonstrate examples of the alloys with simple crystal structures, nanostructures, and promising mechanical properties. This approach may be opening a new era in materials science and engineering.","['High entropy alloys', 'Materials science', 'Alloy', 'Nanostructure', 'Principal (computer security)', 'Entropy (arrow of time)', 'Crystal structure', 'Mechanical engineering', 'Nanotechnology', 'Metallurgy', 'Thermodynamics', 'Computer science', 'Crystallography', 'Engineering', 'Physics', 'Chemistry', 'Operating system']","nanostructures, mechanical properties, materials, [PAD], [PAD], [PAD], [PAD] [PAD], [PAD] [PAD], [PAD], [PAD] [PAD], [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD], [PAD] [PAD]"
Paper_01129,"Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning","['Christian Szegedy', 'Sergey Ioffe', 'Vincent Vanhoucke', 'Alexander A. Alemi']",2017,Proceedings of the AAAI Conference on Artificial Intelligence,Conference,Association for the Advancement of Artificial Intelligence,,31,1,10.1609/aaai.v31i1.11231,"Very deep convolutional networks have been central to the largest advances in image recognition performance in recent years. One example is the Inception architecture that has been shown to achieve very good performance at relatively low computational cost. Recently, the introduction of residual connections in conjunction with a more traditional architecture has yielded state-of-the-art performance in the 2015 ILSVRC challenge; its performance was similar to the latest generation Inception-v3 network. This raises the question: Are there any benefits to combining Inception architectures with residual connections? Here we give clear empirical evidence that training with residual connections accelerates the training of Inception networks significantly. There is also some evidence of residual Inception networks outperforming similarly expensive Inception networks without residual connections by a thin margin. We also present several new streamlined architectures for both residual and non-residual Inception networks. These variations improve the single-frame recognition performance on the ILSVRC 2012 classification task significantly. We further demonstrate how proper activation scaling stabilizes the training of very wide residual Inception networks. With an ensemble of three residual and one Inception-v4 networks, we achieve 3.08% top-5 error on the test set of the ImageNet classification (CLS) challenge.","['Residual', 'Residual neural network', 'Computer science', 'Margin (machine learning)', 'Artificial intelligence', 'Set (abstract data type)', 'Test set', 'Network architecture', 'Scaling', 'Frame (networking)', 'Machine learning', 'Algorithm', 'Telecommunications', 'Computer network', 'Mathematics', 'Geometry', 'Programming language']","image recognition performance, inception architecture, residual connections, ils, inception architectures, residual connections, residual connections, inception networks, residual inception networks, inception networks, residual connections, activation scaling, residual inception, imagenet classification"
Paper_01131,Eigenfaces vs. Fisherfaces: recognition using class specific linear projection,"['Peter N. Belhumeur', 'João P. Hespanha', 'David Kriegman']",1997,IEEE Transactions on Pattern Analysis and Machine Intelligence,Journal,,711-720,19,7,10.1109/34.598228,"We develop a face recognition algorithm which is insensitive to large variation in lighting direction and facial expression. Taking a pattern classification approach, we consider each pixel in an image as a coordinate in a high-dimensional space. We take advantage of the observation that the images of a particular face, under varying illumination but fixed pose, lie in a 3D linear subspace of the high dimensional image space-if the face is a Lambertian surface without shadowing. However, since faces are not truly Lambertian surfaces and do indeed produce self-shadowing, images will deviate from this linear subspace. Rather than explicitly modeling this deviation, we linearly project the image into a subspace in a manner which discounts those regions of the face with large deviation. Our projection method is based on Fisher's linear discriminant and produces well separated classes in a low-dimensional subspace, even under severe variation in lighting and facial expressions. The eigenface technique, another method based on linearly projecting the image space to a low dimensional subspace, has similar computational requirements. Yet, extensive experimental results demonstrate that the proposed ""Fisherface"" method has error rates that are lower than those of the eigenface technique for tests on the Harvard and Yale face databases.","['Eigenface', 'Subspace topology', 'Facial recognition system', 'Artificial intelligence', 'Projection (relational algebra)', 'Pattern recognition (psychology)', 'Linear discriminant analysis', 'Face (sociological concept)', 'Computer vision', 'Pixel', 'Computer science', 'Mathematics', 'Algorithm', 'Social science', 'Sociology']","face recognition algorithm, lighting direction, facial expression, pattern classification, lambertian surface, lambertian surfaces, linear discriminant, facial expressions, eigenface technique, fisher, eigenface, yale"
Paper_01132,APE: Analyses of Phylogenetics and Evolution in R language,"['Emmanuel Paradis', 'Julien Claude', 'Korbinian Strimmer']",2004,Bioinformatics,Journal,,289-290,20,2,10.1093/bioinformatics/btg412,"Analysis of Phylogenetics and Evolution (APE) is a package written in the R language for use in molecular evolution and phylogenetics. APE provides both utility functions for reading and writing data and manipulating phylogenetic trees, as well as several advanced methods for phylogenetic and evolutionary analysis (e.g. comparative and population genetic methods). APE takes advantage of the many R functions for statistics and graphics, and also provides a flexible framework for developing and implementing further statistical methods for the analysis of evolutionary processes. The program is free and available from the official R package archive at http://cran.r-project.org/src/contrib/PACKAGES.html#ape. APE is licensed under the GNU General Public License.","['Phylogenetic tree', 'Phylogenetics', 'Computer science', 'R package', 'Evolutionary biology', 'Population', 'Biology', 'Programming language', 'Genetics', 'Gene', 'Demography', 'Sociology']","phylogenetic, ape, r, molecular evolution, phylogenetics, ape, utility functions, phylogenetic trees, evolutionary analysis, population genetic methods, ape, statistics, graphics, statistical methods, evolutionary processes, [PAD] [PAD]"
Paper_01133,Trace Elements in Soils and Plants,['Alina Kabata‐Pendias'],2010,CRC Press eBooks,Unknown,,,,,10.1201/b10158,Chapter 1 The Biosphere Chapter 2 The Anthroposphere Introduction Air Pollution Water Pollution Soil Plants Chapter 3 Soils and Soil Processes Introduction Weathering Processes Pedogenic Processes Chapter 4 Soil Constituents Introduction Trace Elements Minerals Organic Matter Organisms in Soils Chapter 5 Trace Elements in Plants Introduction Absorption Translocation Availability Essentiality and Deficiency Toxicity and Tolerance Speciation Interaction Chapter 6 Elements of Group 1 (Previously Group Ia) Introduction Lithium Rubidium Cesium Chapter 7 Elements of Group 2 (Previously Group IIa) Beryllium Strontium Barium Radium Chapter 8 Elements of Group 3 (Previously Group IIIb) Scandium Yttrium Lanthanides Actinides Chapter 9 Elements of Group 4 (Previously Group IVb) Titanium Zirconium Hafnium Chapter 10 Elements of Group 5 (Previously Group Vb) Vanadium Niobium Tantalum Chapter 11 Elements of Group 6 (Previously Group VIb) Chromium Molybdenum Tungsten Chapter 12 Elements of Group 7 (Previously Group VIIb) Manganese Technetium Rhenium Chapter 13 Elements of Group 8 (Previously Part of Group VIII) Iron Ruthenium Osmium Chapter 14 Elements of Group 9 (Previously Part of Group VIII) Cobalt Rhodium Iridium Chapter 15 Elements of Group 10 (Previously Part of Group VIII) Nickel Palladium Platinum Chapter 16 Elements of Group 11 (Previously Group Ib) Copper Silver Gold Chapter 17 Trace Elements of Group 12 (Previously of Group IIb) Zinc Cadmium Mercury Chapter 18 Elements of Group 13 (Previously Group IIIa) Boron Aluminum Gallium Indium Thallium Chapter 19 Elements of Group I4 (Previously Group IVa) Silicon Germanium Tin Lead Chapter 20 Elements of Group 15 (Previously Group Va) Arsenic Antimony Bismuth Chapter 21 Elements of Group 16 (Previously Group VIa) Selenium Tellurium Polonium Chapter 22 Elements of Group 17 (Previously Group VIIa) Fluorine Chlorine Bromine Iodine,"['TRACE (psycholinguistics)', 'Soil water', 'Environmental science', 'Environmental chemistry', 'Earth science', 'Geology', 'Soil science', 'Chemistry', 'Philosophy', 'Linguistics']","##sphere, anthroposphere, air pollution, soil processes, weathering, ##dogenic, soil constituents, trace elements, soils, deficiency toxicity, tolerance spec, beryl, scan, titanium, van, manganese, iron, cobalt, nickel palladium platinum, copper silver gold, zinc cad, bo, silicon germanium tin lead, arsenic antimony bis, selenium tellurium polonium"
Paper_01135,Rapid isolation of high molecular weight plant DNA,"['Michael G. Murray', 'William F. Thompson']",1980,Nucleic Acids Research,Journal,,4321-4326,8,19,10.1093/nar/8.19.4321,"A method is presented for the rapid isolation of high molecular weight plant DNA (50,000 base pairs or more in length) which is free of contaminants which interfere with complete digestion by restriction endonucleases. The procedure yields total cellular DNA (i.e. nuclear, chloroplast, and mitochondrial DNA). The technique is ideal for the rapid isolation of small amounts of DNA from many different species and is also useful for large scale isolations.","['Biology', 'DNA', 'Restriction enzyme', 'Isolation (microbiology)', 'Mitochondrial DNA', 'Chloroplast DNA', 'Nuclear DNA', 'Digestion (alchemy)', 'Molecular biology', 'Genetics', 'Chloroplast', 'Gene', 'Chromatography', 'Bioinformatics', 'Chemistry']","restriction endonucleases, total cellular dna, mitochondrial dna, [PAD]"
Paper_01136,CBTRUS Statistical Report: Primary Brain and Central Nervous System Tumors Diagnosed in the United States in 2006-2010,"['Quinn T. Ostrom', 'Haley Gittleman', 'P Farah', 'A. Ondracek', 'Yaning Chen', 'Yingli Wolinsky', 'N. E. Stroup', 'Carol Kruchko', 'Jill S. Barnholtz‐Sloan']",2013,Neuro-Oncology,Journal,,ii1-ii56,15,suppl 2,10.1093/neuonc/not151,"The Central Brain Tumor Registry of the United States (CBTRUS), in collaboration with the Centers for Disease Control (CDC) and National Cancer Institute (NCI), is the largest population-based registry focused exclusively on primary brain and other central nervous system (CNS) tumors in the United States (US) and represents the entire US population. This report contains the most up-to-date population-based data on primary brain tumors (malignant and non-malignant) and supersedes all previous CBTRUS reports in terms of completeness and accuracy. All rates (incidence and mortality) are age-adjusted using the 2000 US standard population and presented per 100,000 population. The average annual age-adjusted incidence rate (AAAIR) of all malignant and non-malignant brain and other CNS tumors was 23.79 (Malignant AAAIR=7.08, non-Malignant AAAIR=16.71). This rate was higher in females compared to males (26.31 versus 21.09), Blacks compared to Whites (23.88 versus 23.83), and non-Hispanics compared to Hispanics (24.23 versus 21.48). The most commonly occurring malignant brain and other CNS tumor was glioblastoma (14.5% of all tumors), and the most common non-malignant tumor was meningioma (38.3% of all tumors). Glioblastoma was more common in males, and meningioma was more common in females. In children and adolescents (age 0-19 years), the incidence rate of all primary brain and other CNS tumors was 6.14. An estimated 83,830 new cases of malignant and non-malignant brain and other CNS tumors are expected to be diagnosed in the US in 2020 (24,970 malignant and 58,860 non-malignant). There were 81,246 deaths attributed to malignant brain and other CNS tumors between 2013 and 2017. This represents an average annual mortality rate of 4.42. The 5-year relative survival rate following diagnosis of a malignant brain and other CNS tumor was 23.5% and for a non-malignant brain and other CNS tumor was 82.4%.","['Medicine', 'Brain tumor', 'Incidence (geometry)', 'Population', 'Cancer registry', 'Meningioma', 'Cancer', 'Disease', 'Glioblastoma', 'Central nervous system', 'Glioma', 'Oncology', 'Pathology', 'Internal medicine', 'Physics', 'Environmental health', 'Cancer research', 'Optics']","central brain tumor registry, g, ##ma, meningioma, g, men, ##a, adolescents"
Paper_01137,Absence of Diffusion in Certain Random Lattices,['P. W. Anderson'],1958,Physical Review,Journal,,1492-1505,109,5,10.1103/physrev.109.1492,"This paper presents a simple model for such processes as spin diffusion or conduction in the ""impurity band."" These processes involve transport in a lattice which is in some sense random, and in them diffusion is expected to take place via quantum jumps between localized sites. In this simple model the essential randomness is introduced by requiring the energy to vary randomly from site to site. It is shown that at low enough densities no diffusion at all can take place, and the criteria for transport to occur are given.","['Randomness', 'Diffusion', 'Statistical physics', 'Lattice (music)', 'Simple (philosophy)', 'Anomalous diffusion', 'Condensed matter physics', 'Thermal conduction', 'Molecular diffusion', 'Conduction band', 'Physics', 'Quantum mechanics', 'Electron', 'Computer science', 'Mathematics', 'Innovation diffusion', 'Metric (unit)', 'Philosophy', 'Statistics', 'Knowledge management', 'Operations management', 'Epistemology', 'Acoustics', 'Economics']","spin diffusion, conduction, impurity band, quantum jumps, localized sites, essential randomness"
Paper_01138,Fundamentals of Statistical Signal Processing: Estimation Theory,['Sailes K. Sengijpta'],1995,Technometrics,Journal,,465-466,37,4,10.1080/00401706.1995.10484391,"""Fundamentals of Statistical Signal Processing: Estimation Theory."" Technometrics, 37(4), pp. 465–466","['Estimation', 'Computer science', 'Statistical signal processing', 'Signal processing', 'Econometrics', 'SIGNAL (programming language)', 'Statistical theory', 'Statistics', 'Algorithm', 'Mathematics', 'Economics', 'Digital signal processing', 'Management', 'Computer hardware', 'Programming language']","statistical signal processing, estimation, technometrics, [PAD], [PAD] [PAD], [PAD], [PAD] [PAD] [PAD], [PAD], [PAD] [PAD], [PAD] [PAD], [PAD]"
Paper_01139,The coding manual for qualitative researchers,['Johnny Saldaña'],2016,['American Journal of Qualitative Research'],Unknown,,232-237,6,1,10.29333/ajqr/12085,"An introduction to codes and coding -- Writing analytic memos -- First cycle coding methods -- After first cycle coding -- Second cycle coding methods -- After second cycle coding -- Post-coding and pre-writing -- Appendix A. A glossary of coding methods -- Appendix B. A glossary of analytic recommendations -- Appendix C. Field note, interview transcript, and document samples for coding -- Appendix D. Exercises and activities for coding and qualitative data analytic skill development.","['Glossary', 'Coding (social sciences)', 'Tunstall coding', 'Computer science', 'Shannon–Fano coding', 'Variable-length code', 'Natural language processing', 'Linguistics', 'Statistics', 'Mathematics', 'Philosophy']","codes, first cycle coding methods, coding, interview transcript, document samples, qualitative data analytic skill development"
Paper_01142,<i>Molecular Theory of Gases and Liquids</i>,"['Joseph O. Hirschfelder', 'C. F. Curtiss', 'R. Byron Bird']",1955,Physics Today,Journal,,17-17,8,3,10.1063/1.3061949,"Molecular theory of gases and liquids , Molecular theory of gases and liquids , مرکز فناوری اطلاعات و اطلاع رسانی کشاورزی","['Theoretical physics', 'Physics', 'Statistical physics']","molecular theory, gases, liquids, molecular theory, gases, liquids"
Paper_01071,Real and Complex Analysis.,"['G. A. Garreau', 'Walter Rudin']",1987,Journal of the Royal Statistical Society Series D (The Statistician),Journal,,423-423,36,4,10.2307/2348852,"Preface Prologue: The Exponential Function Chapter 1: Abstract Integration Set-theoretic notations and terminology The concept of measurability Simple functions Elementary properties of measures Arithmetic in [0, ] Integration of positive functions Integration of complex functions The role played by sets of measure zero Exercises Chapter 2: Positive Borel Measures Vector spaces Topological preliminaries The Riesz representation theorem Regularity properties of Borel measures Lebesgue measure Continuity properties of measurable functions Exercises Chapter 3: Lp-Spaces Convex functions and inequalities The Lp-spaces Approximation by continuous functions Exercises Chapter 4: Elementary Hilbert Space Theory Inner products and linear functionals Orthonormal sets Trigonometric series Exercises Chapter 5: Examples of Banach Space Techniques Banach spaces Consequences of Baire's theorem Fourier series of continuous functions Fourier coefficients of L1-functions The Hahn-Banach theorem An abstract approach to the Poisson integral Exercises Chapter 6: Complex Measures Total variation Absolute continuity Consequences of the Radon-Nikodym theorem Bounded linear functionals on Lp The Riesz representation theorem Exercises Chapter 7: Differentiation Derivatives of measures The fundamental theorem of Calculus Differentiable transformations Exercises Chapter 8: Integration on Product Spaces Measurability on cartesian products Product measures The Fubini theorem Completion of product measures Convolutions Distribution functions Exercises Chapter 9: Fourier Transforms Formal properties The inversion theorem The Plancherel theorem The Banach algebra L1 Exercises Chapter 10: Elementary Properties of Holomorphic Functions Complex differentiation Integration over paths The local Cauchy theorem The power series representation The open mapping theorem The global Cauchy theorem The calculus of residues Exercises Chapter 11: Harmonic Functions The Cauchy-Riemann equations The Poisson integral The mean value property Boundary behavior of Poisson integrals Representation theorems Exercises Chapter 12: The Maximum Modulus Principle Introduction The Schwarz lemma The Phragmen-Lindelof method An interpolation theorem A converse of the maximum modulus theorem Exercises Chapter 13: Approximation by Rational Functions Preparation Runge's theorem The Mittag-Leffler theorem Simply connected regions Exercises Chapter 14: Conformal Mapping Preservation of angles Linear fractional transformations Normal families The Riemann mapping theorem The class L Continuity at the boundary Conformal mapping of an annulus Exercises Chapter 15: Zeros of Holomorphic Functions Infinite Products The Weierstrass factorization theorem An interpolation problem Jensen's formula Blaschke products The Muntz-Szas theorem Exercises Chapter 16: Analytic Continuation Regular points and singular points Continuation along curves The monodromy theorem Construction of a modular function The Picard theorem Exercises Chapter 17: Hp-Spaces Subharmonic functions The spaces Hp and N The theorem of F. and M. Riesz Factorization theorems The shift operator Conjugate functions Exercises Chapter 18: Elementary Theory of Banach Algebras Introduction The invertible elements Ideals and homomorphisms Applications Exercises Chapter 19: Holomorphic Fourier Transforms Introduction Two theorems of Paley and Wiener Quasi-analytic classes The Denjoy-Carleman theorem Exercises Chapter 20: Uniform Approximation by Polynomials Introduction Some lemmas Mergelyan's theorem Exercises Appendix: Hausdorff's Maximality Theorem Notes and Comments Bibliography List of Special Symbols Index",['Computer science'],"exponential function, meas, ##bility, measures, positive, complex functions, banach spaces, local cauchy, power, maximum mod, conformal mapping, riemann"
Paper_01073,Social Capital: Its Origins and Applications in Modern Sociology,['Alejandro Portes'],1998,Annual Review of Sociology,Journal,,1-24,24,1,10.1146/annurev.soc.24.1.1,"This paper reviews the origins and definitions of social capital in the writings of Bourdieu, Loury, and Coleman, among other authors. It distinguishes four sources of social capital and examines their dynamics. Applications of the concept in the sociological literature emphasize its role in social control, in family support, and in benefits mediated by extrafamilial networks. I provide examples of each of these positive functions. Negative consequences of the same processes also deserve attention for a balanced picture of the forces at play. I review four such consequences and illustrate them with relevant examples. Recent writings on social capital have extended the concept from an individual asset to a feature of communities and even nations. The final sections describe this conceptual stretch and examine its limitations. I argue that, as shorthand for the positive consequences of sociability, social capital has a definite place in sociological theory. However, excessive extensions of the concept may jeopardize its heuristic value.","['Sociology', 'Social capital', 'Social reproduction', 'Positive economics', 'Epistemology', 'Value (mathematics)', 'Capital (architecture)', 'Asset (computer security)', 'Individual capital', 'Social science', 'Neoclassical economics', 'Financial capital', 'Economics', 'Computer science', 'History', 'Profit (economics)', 'Philosophy', 'Computer security', 'Archaeology', 'Machine learning']","social capital, social capital, social control, family support, extrafamilial networks, social capital, individual asset, communities, sociability, social capital, sociological, [PAD] [PAD] [PAD], [PAD], [PAD] [PAD] [PAD], [PAD], [PAD], [PAD], [PAD] [PAD], [PAD]"
Paper_01077,ESTIMATION OF AVERAGE HETEROZYGOSITY AND GENETIC DISTANCE FROM A SMALL NUMBER OF INDIVIDUALS,['Masatoshi Nei'],1978,Genetics,Journal,,583-590,89,3,10.1093/genetics/89.3.583,"ABSTRACT The magnitudes of the systematic biases involved in sample heterozygosity and sample genetic distances are evaluated, and formulae for obtaining unbiased estimates of average heterozygosity and genetic distance are developed. It is also shown that the number of individuals to be used for estimating average heterozygosity can be very small if a large number of loci are studied and the average heterozygosity is low. The number of individuals to be used for estimating genetic distance can also be very small if the genetic distance is large and the average heterozygosity of the two species compared is low.","['Loss of heterozygosity', 'Biology', 'Genetic distance', 'Genetics', 'Sample size determination', 'Evolutionary biology', 'Statistics', 'Genetic variation', 'Mathematics', 'Allele', 'Gene']","systematic biases, sample heterozygosity, sample genetic distances, average heterozygosity, genetic distance, average heterozygosity, genetic distance, [PAD] [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD], [PAD] [PAD], [PAD] [PAD], [PAD], [PAD] [PAD] [PAD] [PAD]"
Paper_01079,TopHat: discovering splice junctions with RNA-Seq,"['Cole Trapnell', 'Lior Pachter', 'Steven L. Salzberg']",2009,Bioinformatics,Journal,,1105-1111,25,9,10.1093/bioinformatics/btp120,"Abstract Motivation: A new protocol for sequencing the messenger RNA in a cell, known as RNA-Seq, generates millions of short sequence fragments in a single run. These fragments, or ‘reads’, can be used to measure levels of gene expression and to identify novel splice variants of genes. However, current software for aligning RNA-Seq data to a genome relies on known splice junctions and cannot identify novel ones. TopHat is an efficient read-mapping algorithm designed to align reads from an RNA-Seq experiment to a reference genome without relying on known splice sites. Results: We mapped the RNA-Seq reads from a recent mammalian RNA-Seq experiment and recovered more than 72% of the splice junctions reported by the annotation-based software from that study, along with nearly 20 000 previously unreported junctions. The TopHat pipeline is much faster than previous systems, mapping nearly 2.2 million reads per CPU hour, which is sufficient to process an entire RNA-Seq experiment in less than a day on a standard desktop computer. We describe several challenges unique to ab initio splice site discovery from RNA-Seq reads that will require further algorithm development. Availability: TopHat is free, open-source software available from http://tophat.cbcb.umd.edu Contact: cole@cs.umd.edu Supplementary information: Supplementary data are available at Bioinformatics online.","['splice', 'Computational biology', 'RNA-Seq', 'Computer science', 'Pipeline (software)', 'RNA splicing', 'Annotation', 'RNA', 'Reference genome', 'Software', 'Gene Annotation', 'Genome', 'Genome browser', 'Gene', 'Biology', 'Genetics', 'Genomics', 'Transcriptome', 'Gene expression', 'Operating system']","gene expression, ##lice variants, ##lice, tophat, ##lice, tophat, tophat, bioinformatics"
Paper_01080,The detection of disease clustering and a generalized regression approach.,['Nathan Mantel'],1967,['Cancer Research'],Unknown,,2495-2496,76,9,10.1158/0008-5472.can-16-0883,"The problem of identifying subtle time-space clustering of disease, as may be occurring in leukemia, is described and reviewed. Published approaches, generally associated with studies of leukemia, not dependent on knowledge of the underlying population for their validity, are directed towards identifying clustering by establishing a relationship between the temporal and the spatial separations for the n ( n - 1)/2 possible pairs which can be formed from the n observed cases of disease. Here it is proposed that statistical power can be improved by applying a reciprocal transform to these separations. While a permutational approach can give valid probability levels for any observed association, for reasons of practicability, it is suggested that the observed association be tested relative to its permutational variance. Formulas and computational procedures for doing so are given.

While the distance measures between points represent symmetric relationships subject to mathematical and geometric regularities, the variance formula developed is appropriate for arbitrary relationships. Simplified procedures are given for the case of symmetric and skew-symmetric relationships. The general procedure is indicated as being potentially useful in other situations as, for example, the study of interpersonal relationships. Viewing the procedure as a regression approach, the possibility for extending it to nonlinear and multivariate situations is suggested.

Other aspects of the problem and of the procedure developed are discussed.

Similarly, pure temporal clustering can be identified by a study of incidence rates in periods of widespread epidemics. In point of fact, many epidemics of communicable diseases are somewhat local in nature and so these do actually constitute temporal-spatial clusters. For leukemia and similar diseases in which cases seem to arise substantially at random rather than as clear-cut epidemics, it is necessary to devise sensitive and efficient procedures for detecting any nonrandom component of disease occurrence.

Various ingenious procedures which statisticians have developed for the detection of disease clustering are reviewed here. These procedures can be generalized so as to increase their statistical validity and efficiency. The technic to be given below for imparting statistical validity to the procedures already in vogue can be viewed as a generalized form of regression with possible useful application to problems arising in quite different contexts.","['Cluster analysis', 'Population', 'Mathematics', 'Variance (accounting)', 'Statistics', 'Reciprocal', 'Computer science', 'Medicine', 'Linguistics', 'Philosophy', 'Environmental health', 'Accounting', 'Business']","leukemia, leukemia, clustering, spatial separations, statistical power, reciprocal transform, ##al variance, computational procedures, distance measures, symmetric relationships, geometric regularities, variance formula, interpersonal relationships, pure temporal clustering, incidence rates, communicable diseases, leukemia, disease clustering"
Paper_01081,Model Evaluation Guidelines for Systematic Quantification of Accuracy in Watershed Simulations,"['Daniel N. Moriasi', 'J. G. Arnold', 'M. W. Van Liew', 'Ronald L. Bingner', 'R. Daren Harmel', 'Tamie L. Veith']",2007,Transactions of the ASABE,Journal,,885-900,50,3,10.13031/2013.23153,"Watershed models are powerful tools for simulating the effect of watershed processes and management on soil and water resources. However, no comprehensive guidance is available to facilitate model evaluation in terms of the accuracy of simulated data compared to measured flow and constituent values. Thus, the objectives of this research were to: (1) determine recommended model evaluation techniques (statistical and graphical), (2) review reported ranges of values and corresponding performance ratings for the recommended statistics, and (3) establish guidelines for model evaluation based on the review results and project-specific considerations; all of these objectives focus on simulation of streamflow and transport of sediment and nutrients. These objectives were achieved with a thorough review of relevant literature on model application and recommended model evaluation methods. Based on this analysis, we recommend that three quantitative statistics, Nash-Sutcliffe efficiency (NSE), percent bias (PBIAS), and ratio of the root mean square error to the standard deviation of measured data (RSR), in addition to the graphical techniques, be used in model evaluation. The following model evaluation performance ratings were established for each recommended statistic. In general, model simulation can be judged as satisfactory if NSE > 0.50 and RSR < 0.70, and if PBIAS + 25% for streamflow, PBIAS + 55% for sediment, and PBIAS + 70% for N and P. For PBIAS, constituent-specific performance ratings were determined based on uncertainty of measured data. Additional considerations related to model evaluation guidelines are also discussed. These considerations include: single-event simulation, quality and quantity of measured data, model calibration procedure, evaluation time step, and project scope and magnitude. A case study illustrating the application of the model evaluation guidelines is also provided.","['Watershed', 'Computer science', 'Streamflow', 'Statistic', 'Calibration', 'Environmental science', 'Standard deviation', 'Hydrology (agriculture)', 'Statistics', 'Data mining', 'Mathematics', 'Machine learning', 'Geology', 'Drainage basin', 'Cartography', 'Geotechnical engineering', 'Geography']","watershed models, watershed processes, model evaluation, constituent values, performance, quantitative statistics, percent bias, root mean square error, model evaluation performance ratings, model calibration procedure"
Paper_01082,Parkinsonism,"['Margaret M. Hoehn', 'Melvin D. Yahr']",1967,Neurology,Journal,,427-427,17,5,10.1212/wnl.17.5.427,"PARKINSONISM, described in its entirety over one hundred and fifty years ago,' rarely presents itself as a diagnostic problem.In consequence, little scrutiny has been directed to the marked variability of this frequently encountered neurological syndrome and to the progression of the disease in large groups of patients.As with most chronic neurological disorders, marked diversity can be expected to exist in age and mode of onset, relative prominence of the cardinal signs and symptoms, rate of progression, and resultant degree of functional impairment.Controversy over the effectiveness of therapeutic measures for parkinsonism is due partially to this wide variability and to the paucity of clinical information about the natural history of the syndrome.It is also re-","['Medicine', 'Parkinsonism', 'Internal medicine', 'Disease']","parkinsonism, chronic neurological disorders, functional impairment, therapeutic measures, parkinsonism"
Paper_01083,Ant system: optimization by a colony of cooperating agents,"['Marco Dorigo', 'Vittorio Maniezzo', 'A. Colorni']",1996,IEEE Transactions on Systems Man and Cybernetics Part B (Cybernetics),Journal,,29-41,26,1,10.1109/3477.484436,"An analogy with the way ant colonies function has suggested the definition of a new computational paradigm, which we call ant system (AS). We propose it as a viable new approach to stochastic combinatorial optimization. The main characteristics of this model are positive feedback, distributed computation, and the use of a constructive greedy heuristic. Positive feedback accounts for rapid discovery of good solutions, distributed computation avoids premature convergence, and the greedy heuristic helps find acceptable solutions in the early stages of the search process. We apply the proposed methodology to the classical traveling salesman problem (TSP), and report simulation results. We also discuss parameter selection and the early setups of the model, and compare it with tabu search and simulated annealing using TSP. To demonstrate the robustness of the approach, we show how the ant system (AS) can be applied to other optimization problems like the asymmetric traveling salesman, the quadratic assignment and the job-shop scheduling. Finally we discuss the salient characteristics-global data structure revision, distributed communication and probabilistic transitions of the AS.","['Travelling salesman problem', 'Mathematical optimization', 'Computer science', 'Quadratic assignment problem', 'Ant colony optimization algorithms', 'Combinatorial optimization', 'Metaheuristic', 'Extremal optimization', 'Computation', 'Greedy algorithm', 'Robustness (evolution)', 'Tabu search', 'Optimization problem', 'Mathematics', 'Algorithm', 'Meta-optimization', 'Biochemistry', 'Chemistry', 'Gene']","ant colonies, ant system, stochastic combinatorial optimization, positive feedback, distributed computation, constructive greedy heuristic, positive feedback, distributed computation, premature convergence, greedy heuristic, classical traveling salesman problem, parameter selection, tabu search, simulated annealing, ant, optimization, asymmetric traveling salesman, quadratic assignment, global data structure revision, distributed communication, probabilistic transitions"
Paper_01086,Bacterial Biofilms: A Common Cause of Persistent Infections,"['J. William Costerton', 'Philip S. Stewart', 'E. Peter Greenberg']",1999,Science,Journal,,1318-1322,284,5418,10.1126/science.284.5418.1318,"Bacteria that attach to surfaces aggregate in a hydrated polymeric matrix of their own synthesis to form biofilms. Formation of these sessile communities and their inherent resistance to antimicrobial agents are at the root of many persistent and chronic bacterial infections. Studies of biofilms have revealed differentiated, structured groups of cells with community properties. Recent advances in our understanding of the genetic and molecular basis of bacterial community behavior point to therapeutic targets that may provide a means for the control of biofilm infections.","['Biofilm', 'Microbiology', 'Bacteria', 'Antimicrobial', 'Antibiotic resistance', 'Biology', 'Antibiotics', 'Genetics']","hydrated polymeric matrix, biofilm, ##ro, biofilm, bacterial community behavior, [PAD], [PAD], [PAD]"
Paper_01089,"Prevalence, Severity, and Comorbidity of 12-Month DSM-IV Disorders in the National Comorbidity Survey Replication","['Ronald C. Kessler', 'Wai Tat Chiu', 'Olga Demler', 'Ellen E. Walters']",2005,Archives of General Psychiatry,Journal,,617-617,62,6,10.1001/archpsyc.62.6.617,"<h3>Background</h3> Little is known about the general population prevalence or severity of<i>DSM-IV</i>mental disorders. <h3>Objective</h3> To estimate 12-month prevalence, severity, and comorbidity of<i>DSM-IV</i>anxiety, mood, impulse control, and substance disorders in the recently completed US National Comorbidity Survey Replication. <h3>Design and Setting</h3> Nationally representative face-to-face household survey conducted between February 2001 and April 2003 using a fully structured diagnostic interview, the World Health Organization World Mental Health Survey Initiative version of the Composite International Diagnostic Interview. <h3>Participants</h3> Nine thousand two hundred eighty-two English-speaking respondents 18 years and older. <h3>Main Outcome Measures</h3> Twelve-month<i>DSM-IV</i>disorders. <h3>Results</h3> Twelve-month prevalence estimates were anxiety, 18.1%; mood, 9.5%; impulse control, 8.9%; substance, 3.8%; and any disorder, 26.2%. Of 12-month cases, 22.3% were classified as serious; 37.3%, moderate; and 40.4%, mild. Fifty-five percent carried only a single diagnosis; 22%, 2 diagnoses; and 23%, 3 or more diagnoses. Latent class analysis detected 7 multivariate disorder classes, including 3 highly comorbid classes representing 7% of the population. <h3>Conclusion</h3> Although mental disorders are widespread, serious cases are concentrated among a relatively small proportion of cases with high comorbidity.","['Comorbidity', 'National Comorbidity Survey', 'Anxiety', 'Mood disorders', 'Psychiatry', 'Mood', 'Population', 'Medicine', 'Latent class model', 'Medical diagnosis', 'Anxiety disorder', 'Psychology', 'Clinical psychology', 'Statistics', 'Mathematics', 'Environmental health', 'Pathology']","general population prevalence, mental disorders, comorbidity, impulse control, substance disorders, fully structured diagnostic interview, world, anxiety, impulse control, latent class analysis, multivariate disorder classes, highly comorbid classes, mental disorders, ##rb"
Paper_01090,Human Breast Cancer: Correlation of Relapse and Survival with Amplification of the HER-2/ <i>neu</i> Oncogene,"['Dennis J. Slamon', 'Gary M. Clark', 'Steven Wong', 'Wendy J. Levin', 'Axel Ullrich', 'William McGuire']",1987,Science,Journal,,177-182,235,4785,10.1126/science.3798106,"The HER-2/ neu oncogene is a member of the erb B-like oncogene family, and is related to, but distinct from, the epidermal growth factor receptor. This gene has been shown to be amplified in human breast cancer cell lines. In the current study, alterations of the gene in 189 primary human breast cancers were investigated. HER-2/ neu was found to be amplified from 2- to greater than 20-fold in 30% of the tumors. Correlation of gene amplification with several disease parameters was evaluated. Amplification of the HER-2/ neu gene was a significant predictor of both overall survival and time to relapse in patients with breast cancer. It retained its significance even when adjustments were made for other known prognostic factors. Moreover, HER-2/ neu amplification had greater prognostic value than most currently used prognostic factors, including hormonal-receptor status, in lymph node-positive disease. These data indicate that this gene may play a role in the biologic behavior and/or pathogenesis of human breast cancer.","['Gene duplication', 'Breast cancer', 'Oncogene', 'Lymph node', 'Biology', 'Cancer research', 'Cancer', 'Oncology', 'Gene', 'Disease', 'Internal medicine', 'HER2/neu', 'Mammary gland', 'Medicine', 'Immunology', 'Cell cycle', 'Genetics']","epidermal growth factor receptor, human breast cancer, gene, breast cancer"
Paper_01092,Improved tools for biological sequence comparison.,"['William R. Pearson', 'David J. Lipman']",1988,Proceedings of the National Academy of Sciences,Journal,,2444-2448,85,8,10.1073/pnas.85.8.2444,"We have developed three computer programs for comparisons of protein and DNA sequences. They can be used to search sequence data bases, evaluate similarity scores, and identify periodic structures based on local sequence similarity. The FASTA program is a more sensitive derivative of the FASTP program, which can be used to search protein or DNA sequence data bases and can compare a protein sequence to a DNA sequence data base by translating the DNA data base as it is searched. FASTA includes an additional step in the calculation of the initial pairwise similarity score that allows multiple regions of similarity to be joined to increase the score of related sequences. The RDF2 program can be used to evaluate the significance of similarity scores using a shuffling method that preserves local sequence composition. The LFASTA program can display all the regions of local similarity between two sequences with scores greater than a threshold, using the same scoring parameters and a similar alignment algorithm; these local similarities can be displayed as a ""graphic matrix"" plot or as individual alignments. In addition, these programs have been generalized to allow comparison of DNA or protein sequences based on a variety of alternative scoring matrices.","['Alignment-free sequence analysis', 'Similarity (geometry)', 'Sequence (biology)', 'Pairwise comparison', 'Sequence alignment', 'Shuffling', 'Smith–Waterman algorithm', 'Sequence database', 'Multiple sequence alignment', 'Computer science', 'Computational biology', 'Data mining', 'DNA sequencing', 'Protein sequencing', 'Bioinformatics', 'Genetics', 'DNA', 'Artificial intelligence', 'Biology', 'Peptide sequence', 'Gene', 'Image (mathematics)', 'Programming language']","computer programs, sequence data bases, similarity scores, periodic structures, local sequence similarity, fasta, fastp, fasta, pairwise similarity score, rdf, similarity scores, shuffling method, local sequence composition, ##fasta, local similarity, graphic matrix, [PAD]"
Paper_01093,Room-Temperature Ionic Liquids. Solvents for Synthesis and Catalysis,['Tom Welton'],1999,Chemical Reviews,Journal,,2071-2084,99,8,10.1021/cr980032t,"ADVERTISEMENT RETURN TO ISSUEPREVArticleNEXTRoom-Temperature Ionic Liquids. Solvents for Synthesis and CatalysisThomas WeltonView Author Information Department of Chemistry, Imperial College of Science Technology and Medicine, South Kensington, London SW7 2AY, U.K. Cite this: Chem. Rev. 1999, 99, 8, 2071–2084Publication Date (Web):July 7, 1999Publication History Received23 November 1998Revised13 April 1999Published online7 July 1999Published inissue 11 August 1999https://pubs.acs.org/doi/10.1021/cr980032thttps://doi.org/10.1021/cr980032tresearch-articleACS PublicationsCopyright © 1999 American Chemical SocietyRequest reuse permissionsArticle Views59145Altmetric-Citations11083LEARN ABOUT THESE METRICSArticle Views are the COUNTER-compliant sum of full text article downloads since November 2008 (both PDF and HTML) across all institutions and individuals. These metrics are regularly updated to reflect usage leading up to the last few days.Citations are the number of other articles citing this article, calculated by Crossref and updated daily. Find more information about Crossref citation counts.The Altmetric Attention Score is a quantitative measure of the attention that a research article has received online. Clicking on the donut icon will load a page at altmetric.com with additional details about the score and the social media presence for the given article. Find more information on the Altmetric Attention Score and how the score is calculated. Share Add toView InAdd Full Text with ReferenceAdd Description ExportRISCitationCitation and abstractCitation and referencesMore Options Share onFacebookTwitterWechatLinked InRedditEmail Other access optionsGet e-Alertsclose SUBJECTS:Anions,Catalysts,Ions,Salts,Solvents Get e-Alerts","['Citation', 'Ionic liquid', 'Computer science', 'Chemistry', 'World Wide Web', 'Library science', 'Nanotechnology', 'Analytical Chemistry (journal)', 'Catalysis', 'Organic chemistry', 'Materials science']","solvents, catalysis, american, ##le, ##f, altmetric attention score, social, altmetric attention score, ##citation, abstract, anions"
Paper_01101,An algorithm for the machine calculation of complex Fourier series,"['J.W. Cooley', 'John W. Tukey']",1965,Mathematics of Computation,Journal,,297-301,19,90,10.1090/s0025-5718-1965-0178586-1,"An efficient method for the calculation of the interactions of a 2m factorial experiment was introduced by Yates and is widely known by his name.The generalization to 3m was given by Box et al. [1].Good [2] generalized these methods and gave elegant algorithms for which one class of applications is the calculation of Fourier series.In their full generality, Good's methods are applicable to certain problems in which one must multiply an JV-vector by an JV X N matrix which can be factored into m sparse matrices, where m is proportional to log JV.This results in a procedure requiring a number of operations proportional to JV log JV rather than JV2.These methods are applied here to the calculation of complex Fourier series.They are useful in situations where the number of data points is, or can be chosen to be, a highly composite number.The algorithm is here derived and presented in a rather different form.Attention is given to the choice of JV.It is also shown how special advantage can be obtained in the use of a binary computer with JV = 2m and how the entire calculation can be performed within the array of JV data storage locations used for the given Fourier coefficients.Consider the problem of calculating the complex Fourier series","['Mathematics', 'Series (stratigraphy)', 'Fourier series', 'Algorithm', 'Mathematical analysis', 'Paleontology', 'Biology']","fourier series, sparse matrices, complex fourier series, binary computer, complex fourier series, [PAD]"
Paper_01102,The Problem of Social Cost,['Ronald H. Coase'],2016,['The American Journal of Economics and Sociology'],Unknown,,399-416,26,4,10.1111/j.1536-7150.1967.tb01019.x,"This paper is concerned with those actions of business firms which have harmful effects on others. The standard example is that of a factory the smoke from which has harmful effects on those occupying neighbouring properties. The economic analysis of such a situation has usually proceeded in terms of a divergence between the private and social product of the factory, in which economists have largely followed the treatment of Pigou in The Economics of Welfare. The conclusions to which this kind of analysis seems to have led most economists is that it would be desirable to make the owner of the factory liable for the damage caused to those injured by the smoke, or alternatively, to place a tax on the factory owner varying with the amount of smoke produced and equivalent in money terms to the damage it would cause, or finally, to exclude the factory from residential districts (and presumably from other areas in which the emission of smoke would have harmful effects on others). It is my contention that the suggested courses of action are inappropriate, in that they lead to results which are not necessarily, or even usually, desirable.","['Factory (object-oriented programming)', 'Pigou effect', 'Product (mathematics)', 'Action (physics)', 'Welfare', 'Smoke', 'Social cost', 'Economics', 'Social Welfare', 'Competition (biology)', 'Public economics', 'Business', 'Engineering', 'Microeconomics', 'Market economy', 'Political science', 'Law', 'Waste management', 'Macroeconomics', 'Computer science', 'Ecology', 'Physics', 'Geometry', 'Mathematics', 'Quantum mechanics', 'Biology', 'Programming language']","business firms, welfare"
Paper_01103,American Economic Review,"['Edward F. Denison', '陽一 高橋']",2019,AEA Papers and Proceedings,Journal,,612-626,109,,10.1257/pandp.109.612,"by an editor, several coeditors, and a staff located in Pittsburgh, using an Internet-based manuscript management software system.Papers are submitted online, processed by the Pittsburgh office staff, and then distributed by the editor to one of the coeditors",['Environmental science'],manuscript management software
Paper_01105,Squeeze-and-Excitation Networks,"['Jie Hu', 'Li Shen', 'Samuel Albanie', 'Gang Sun', 'Enhua Wu']",2019,IEEE Transactions on Pattern Analysis and Machine Intelligence,Journal,,2011-2023,42,8,10.1109/tpami.2019.2913372,"The central building block of convolutional neural networks (CNNs) is the convolution operator, which enables networks to construct informative features by fusing both spatial and channel-wise information within local receptive fields at each layer. A broad range of prior research has investigated the spatial component of this relationship, seeking to strengthen the representational power of a CNN by enhancing the quality of spatial encodings throughout its feature hierarchy. In this work, we focus instead on the channel relationship and propose a novel architectural unit, which we term the ""Squeeze-and-Excitation"" (SE) block, that adaptively recalibrates channel-wise feature responses by explicitly modelling interdependencies between channels. We show that these blocks can be stacked together to form SENet architectures that generalise extremely effectively across different datasets. We further demonstrate that SE blocks bring significant improvements in performance for existing state-of-the-art CNNs at slight additional computational cost. Squeeze-and-Excitation Networks formed the foundation of our ILSVRC 2017 classification submission which won first place and reduced the top-5 error to 2.251 percent, surpassing the winning entry of 2016 by a relative improvement of -25 percent. Models and code are available at https://github.com/hujie-frank/SENet.","['Computer science', 'Artificial intelligence']","convolutional neural networks, cnns, convolution operator, informative features, local receptive fields, representational power, spatial encodings, feature hierarchy, channel relationship, inter, ##penden, senet architectures, ils"
Paper_01108,Aspirin plus Clopidogrel as Secondary Prevention after Stroke or Transient Ischemic Attack: A Systematic Review and Meta-Analysis,"['Qinghua Zhang', 'Chao Wang', 'Maoyong Zheng', 'Yanxia Li', 'Jincun Li', 'Liping Zhang', 'Xiao Shang', 'Chuanzhu Yan']",2014,Cerebrovascular Diseases,Journal,,13-22,39,1,10.1159/000369778,"Emerging studies suggest that early administration of dual antiplatelet therapy may be better than monotherapy for prevention of early recurrent stroke and cardiovascular outcomes in acute ischemic stroke and transient ischemic attack (TIA). We performed a meta-analysis of randomized, controlled trials evaluating dual versus mono antiplatelet therapy for acute noncardioembolic ischemic stroke or TIA.We assessed randomized, controlled trials investigating dual versus mono antiplatelet therapy published up to November 2012 and the CHANCE trial (Clopidogrel in High-risk patients with Acute Non-disabling Cerebrovascular Events), for efficacy and safety outcomes in adult patients with acute noncardioembolic ischemic stroke or TIA with treatment initiated within 3 days of ictus. In total, 14 studies of 9012 patients were included in the systematic review and meta-analysis. Dual antiplatelet therapy significantly reduced risk of stroke recurrence (risk ratio, 0.69; 95% confidence interval, 0.60-0.80; P<0.001) and the composite outcome of stroke, TIA, acute coronary syndrome, and all death (risk ratio, 0.71; 95% confidence interval, 0.63-0.81; P<0.001) when compared with monotherapy, and nonsignificantly increased risk of major bleeding (risk ratio, 1.35; 95% confidence interval, 0.70-2.59, P=0.37). Analyses restricted to the CHANCE Trial or the 7 double-blind randomized, controlled trials showed similar results.For patients with acute noncardioembolic ischemic stroke or TIA, dual therapy was more effective than monotherapy in reducing risks of early recurrent stroke. The results of the CHANCE study are consistent with previous studies done in other parts of the world.","['Medicine', 'Clopidogrel', 'Aspirin', 'Internal medicine', 'Stroke (engine)', 'Randomized controlled trial', 'Confidence interval', 'Acute coronary syndrome', 'Platelet aggregation inhibitor', 'Meta-analysis', 'Cardiology', 'Myocardial infarction', 'Mechanical engineering', 'Engineering']","dual antiplatelet therapy, monotherapy, cardiovascular outcomes, acute ischemic stroke, transient ischemic attack, chance, ##op, dual"
Paper_01112,Capacity of Multi‐antenna Gaussian Channels,['Emre Telatar'],1999,European Transactions on Telecommunications,Journal,,585-595,10,6,10.1002/ett.4460100604,"Abstract We investigate the use of multiple transmitting and/or receiving antennas for single user communications over the additive Gaussian channel with and without fading. We derive formulas for the capacities and error exponents of such channels, and describe computational procedures to evaluate such formulas. We show that the potential gains of such multi‐antenna systems over single‐antenna systems is rather large under independenceassumptions for the fades and noises at different receiving antennas.","['Antenna (radio)', 'Fading', 'Gaussian', 'Computer science', 'Channel (broadcasting)', 'Electronic engineering', 'Topology (electrical circuits)', 'Telecommunications', 'Algorithm', 'Mathematics', 'Physics', 'Engineering', 'Quantum mechanics', 'Combinatorics']","single user communications, additive gaussian channel, error exponents, multi ‐ antenna, single ‐ antenna systems, independenceassumptions"
Paper_01114,Qualitative Interviewing: The Art of Hearing Data,"['Frank B. Brooks', 'Herbert J. Rubin', 'Irene S. Rubin']",1996,Modern Language Journal,Journal,,555-555,80,4,10.2307/329757,"Chapter 1. Listening, Hearing, and Sharing Chapter 2. Research Philosophy and Qualitative Interviews Chapter 3. Qualitative Data Gathering Methods and Style Chapter 4. Designing Research for the Responsive Interviewing Model Chapter 5. Designing for Quality Chapter 6. Conversational Partnerships Chapter 7. The Responsive Interview as an Extended Conversation Chapter 8. Structure of the Responsive Interview Chapter 9. Designing Main Questions and Probes Chapter 10. Preparing Follow-Up Questions Chapter 11. Variants of the Responsive Interviewing Model Chapter 12. Data Analysis in the Responsive Interviewing Model Chapter 13. Sharing the Results Chapter 14. Personal Reflections on Responsive Interviewing","['Interview', 'Active listening', 'Conversation', 'Qualitative research', 'Psychology', 'Computer science', 'Sociology', 'Communication', 'Social science', 'Anthropology']","research philosophy, qualitative interviews, qualitative data gathering methods, style, responsive interviewing model, conversational partnerships, responsive interview, responsive interview, responsive interviewing, data analysis, responsive interviewing model, personal reflections, responsive interviewing"
Paper_01115,Methods for the Economic Evaluation of Health Care Programmes,"['Michael E Drummond', 'Mark Sculpher', 'George W. Torrance', 'Bernie J. OʼBrien', 'Greg L. Stoddart']",2005,Oxford University Press eBooks,Unknown,,,,,10.1093/oso/9780198529446.001.0001,"Abstract The highly successful textbook Methods for the Economic Evaluation of Health Care is now available in its third edition. Over the years it has become the standard textbook in the field world-wide. It mirrors the huge expansion of the field of economic evaluation in health care. This new edition builds on the strengths of previous editions being clearly written in a style accessible to a wide readership. Key methodological principles are outlined using a critical appraisal checklist that can be applied to any published study. The methodological features of the basic forms of analysis are then explained in more detail with special emphasis of the latest views on productivity costs, the characterization of uncertainty and the concept of net benefit. The book has been greatly revised and expanded especially concerning analyzing patient-level data and decision-analytic modeling. There is discussion of new methodological approaches, including cost effectiveness acceptability curves, net benefit regression, probalistic sensitivity analysis and value of information analysis. There is an expanded chapter on the use of economic evaluation, including discussion of the use of cost-effectiveness thresholds, equity considerations and the transferability of economic data. This new edition is required for anyone commissioning, undertaking or using economic evaluations in health care, and will be popular with health service professionals, health economists, pharmacists and health care decision makers. It is especially relevant for those taking pharmacoeconomics courses.","['Economic evaluation', 'Health care', 'Checklist', 'Pharmacoeconomics', 'Critical appraisal', 'Equity (law)', 'Management science', 'Medicine', 'Psychology', 'Political science', 'Alternative medicine', 'Economics', 'Economic growth', 'Pathology', 'Law', 'Cognitive psychology']","economic evaluation, health care, economic evaluation, health care, critical appraisal checklist, productivity costs, uncertainty, net benefit, cost effectiveness acceptability curves, net benefit regression, probalistic sensitivity analysis, economic evaluation, equity considerations, economic evaluations, health, health service professionals, health economists, pharmac, health care decision makers, ph, ##aco, ##s"
Paper_01116,Stages of embryonic development of the zebrafish,"['Charles B. Kimmel', 'William W. Ballard', 'Seth R. Kimmel', 'Bonnie Ullmann', 'Thomas F. Schilling']",1995,Developmental Dynamics,Journal,,253-310,203,3,10.1002/aja.1002030302,"Abstract We describe a series of stages for development of the embryo of the zebrafish, Danio (Brachydanio) rerio . We define seven broad periods of embryogenesis—the zygote, cleavage, blastula, gastrula, segmentation, pharyngula, and hatching periods. These divisions highlight the changing spectrum of major developmental processes that occur during the first 3 days after fertilization, and we review some of what is known about morphogenesis and other significant events that occur during each of the periods. Stages subdivide the periods. Stages are named, not numbered as in most other series, providing for flexibility and continued evolution of the staging series as we learn more about development in this species. The stages, and their names, are based on morphological features, generally readily identified by examination of the live embryo with the dissecting stereomicroscope. The descriptions also fully utilize the optical transparancy of the live embryo, which provides for visibility of even very deep structures when the embryo is examined with the compound microscope and Nomarski interference contrast illumination. Photomicrographs and composite camera lucida line drawings characterize the stages pictorially. Other figures chart the development of distinctive characters used as staging aid signposts. ©1995 Wiley‐Liss, Inc.","['Biology', 'Blastula', 'Zygote', 'Blastoderm', 'Embryo', 'Zebrafish', 'Embryogenesis', 'Hatching', 'Danio', 'Anatomy', 'Morphogenesis', 'Gastrulation', 'Evolutionary biology', 'Cell biology', 'Genetics', 'Ecology', 'Gene']","zebrafish, danio, ##dan, zygote, blast, gastrula, segmentation, pharyng, hatching periods, ##phogen, morphological, disse, optical transparancy, compound microscope, no, ##ski interference contrast illumination, ##mic, composite camera lucida line drawings, staging aid"
Paper_01117,An Iterative Image Registration Technique with an Application to Stereo Vision,"['Bruce D. Lucas', 'Takeo Kanade']",1981,"['Lecture Notes in Computer Science', 'Medical Image Computing and Computer Assisted Intervention – MICCAI 2023']",Unknown,,602-612,,,10.1007/978-3-031-43999-5_57,"Image registration finds a variety of applications in computer vision. Unfortunately, traditional image registration techniques tend to be costly. We present a new image registration technique that makes use of the spatial intensity gradient of the images to find a good match using a type of Newton-Raphson iteration. Our technique is taster because it examines far fewer potential matches between the images than existing techniques Furthermore, this registration technique can be generalized to handle rotation, scaling and shearing. We show how our technique can be adapted tor use in a stereo vision system.","['Computer vision', 'Artificial intelligence', 'Computer science', 'Image registration', 'Stereopsis', 'Image (mathematics)']","image registration, computer vision, image registration, image registration technique, spatial intensity gradient, rotation, scaling, shearing, stereo vision system, [PAD], [PAD] [PAD], [PAD] [PAD], [PAD] [PAD], [PAD], [PAD] [PAD] [PAD], [PAD] [PAD], [PAD], [PAD] [PAD] [PAD] [PAD], [PAD], [PAD], [PAD] [PAD], [PAD], [PAD] [PAD], [PAD], [PAD] [PAD], [PAD] [PAD] [PAD], [PAD], [PAD], [PAD], [PAD] [PAD] [PAD] [PAD]"
Paper_01119,"Global, regional, and national incidence, prevalence, and years lived with disability for 354 diseases and injuries for 195 countries and territories, 1990–2017: a systematic analysis for the Global Burden of Disease Study 2017","['Spencer L James', 'Degu Abate', 'Kalkidan Hassen Abate', 'Solomón Mequanente Abay', 'Cristiana Abbafati', 'Nooshin Abbasi', 'Hedayat Abbastabar', 'Foad Abd-Allah', 'Jemal Abdela', 'Ahmed Abdelalim', 'Ibrahim Abdollahpour', 'Rizwan Suliankatchi Abdulkader', 'Abebe Zegeye', 'Semaw Ferede Abera', 'Olifan Zewdie Abil', 'Haftom Niguse Abraha', 'Laith J. Abu‐Raddad', 'Niveen M E Abu-Rmeileh', 'Manfred Accrombessi', 'Dilaram Acharya', 'Pawan Acharya', 'Ilana N. Ackerman', 'Abdu A. Adamu', 'Oladimeji Adebayo', 'Victor Adekanmbi', 'Olatunji Adetokunboh', 'Mina G Adib', 'José Carmelo Adsuar', 'Kossivi Agbélénko Afanvi', 'Mohsen Afarideh', 'Ashkan Afshin', 'Gina Agarwal', 'Kareha M Agesa', 'Rakesh Aggarwal', 'Sargis A. Aghayan', 'Sutapa Agrawal', 'Alireza Ahmadi', 'Mehdi Ahmadi', 'Hamid Ahmadieh', 'Muktar Beshir Ahmed', 'Amani Nidhal Aichour', 'Ibtihel Aichour', 'Miloud Taki Eddine Aichour', 'Tomi Akinyemiju', 'Nadia Akseer', 'Ziyad Al‐Aly', 'Ayman Al‐Eyadhy', 'Hesham M. Al‐Mekhlafi', 'Rajaa Al‐Raddadi', 'Fares Alahdab', 'Khurshid Alam', 'Shazia Alam', 'Alaa Alashi', 'Seyed Moayed Alavian', 'Kefyalew Addis Alene', 'Mehran Alijanzadeh', 'Reza Alizadeh‐Navaei', 'Syed Mohamed Aljunid', 'Ala’a Alkerwi', 'François Alla', 'Peter Allebeck', 'Mohamed M L Alouani', 'Khalid A Altirkawi', 'Nelson Alvis‐Guzmán', 'Azmeraw T. Amare', 'Léopold Ndemnge Aminde', 'Walid Ammar', 'Yaw Ampem Amoako', 'Nahla Anber', 'Cătălina Liliana Andrei', 'Sofia Androudi', 'Megbaru Debalkie Animut', 'Mina Anjomshoa', 'Mustafa Geleto Ansha', 'Carl Abelardo T. Antonio', 'Palwasha Anwari', 'Jalal Arabloo', 'Antonio Araúz', 'Olatunde Aremu', 'Filippo Ariani', 'Bahram Armoon', 'Johan Ärnlöv', 'Amit Arora', 'Al Artaman', 'Kavumpurathu Raman Thankappan', 'Hamid Asayesh', 'Rana Jawad Asghar', 'Zerihun Ataro', 'Sachin Atre', 'Marcel Ausloos', 'Leticia Ávila‐Burgos', 'Euripide Frinel G Arthur Avokpaho', 'Ashish Awasthi', 'Beatriz Paulina Ayala Quintanilla', 'Rakesh Ayer', 'Peter Azzopardi', 'Arefeh Babazadeh', 'Hamid Badali', 'Alaa Badawi', 'Ayele Geleto']",2018,The Lancet,Journal,,1789-1858,392,10159,10.1016/s0140-6736(18)32279-7,"BackgroundThe Global Burden of Diseases, Injuries, and Risk Factors Study 2017 (GBD 2017) includes a comprehensive assessment of incidence, prevalence, and years lived with disability (YLDs) for 354 causes in 195 countries and territories from 1990 to 2017. Previous GBD studies have shown how the decline of mortality rates from 1990 to 2016 has led to an increase in life expectancy, an ageing global population, and an expansion of the non-fatal burden of disease and injury. These studies have also shown how a substantial portion of the world's population experiences non-fatal health loss with considerable heterogeneity among different causes, locations, ages, and sexes. Ongoing objectives of the GBD study include increasing the level of estimation detail, improving analytical strategies, and increasing the amount of high-quality data.MethodsWe estimated incidence and prevalence for 354 diseases and injuries and 3484 sequelae. We used an updated and extensive body of literature studies, survey data, surveillance data, inpatient admission records, outpatient visit records, and health insurance claims, and additionally used results from cause of death models to inform estimates using a total of 68 781 data sources. Newly available clinical data from India, Iran, Japan, Jordan, Nepal, China, Brazil, Norway, and Italy were incorporated, as well as updated claims data from the USA and new claims data from Taiwan (province of China) and Singapore. We used DisMod-MR 2.1, a Bayesian meta-regression tool, as the main method of estimation, ensuring consistency between rates of incidence, prevalence, remission, and cause of death for each condition. YLDs were estimated as the product of a prevalence estimate and a disability weight for health states of each mutually exclusive sequela, adjusted for comorbidity. We updated the Socio-demographic Index (SDI), a summary development indicator of income per capita, years of schooling, and total fertility rate. Additionally, we calculated differences between male and female YLDs to identify divergent trends across sexes. GBD 2017 complies with the Guidelines for Accurate and Transparent Health Estimates Reporting.FindingsGlobally, for females, the causes with the greatest age-standardised prevalence were oral disorders, headache disorders, and haemoglobinopathies and haemolytic anaemias in both 1990 and 2017. For males, the causes with the greatest age-standardised prevalence were oral disorders, headache disorders, and tuberculosis including latent tuberculosis infection in both 1990 and 2017. In terms of YLDs, low back pain, headache disorders, and dietary iron deficiency were the leading Level 3 causes of YLD counts in 1990, whereas low back pain, headache disorders, and depressive disorders were the leading causes in 2017 for both sexes combined. All-cause age-standardised YLD rates decreased by 3·9% (95% uncertainty interval [UI] 3·1–4·6) from 1990 to 2017; however, the all-age YLD rate increased by 7·2% (6·0–8·4) while the total sum of global YLDs increased from 562 million (421–723) to 853 million (642–1100). The increases for males and females were similar, with increases in all-age YLD rates of 7·9% (6·6–9·2) for males and 6·5% (5·4–7·7) for females. We found significant differences between males and females in terms of age-standardised prevalence estimates for multiple causes. The causes with the greatest relative differences between sexes in 2017 included substance use disorders (3018 cases [95% UI 2782–3252] per 100 000 in males vs s1400 [1279–1524] per 100 000 in females), transport injuries (3322 [3082–3583] vs 2336 [2154–2535]), and self-harm and interpersonal violence (3265 [2943–3630] vs 5643 [5057–6302]).InterpretationGlobal all-cause age-standardised YLD rates have improved only slightly over a period spanning nearly three decades. However, the magnitude of the non-fatal disease burden has expanded globally, with increasing numbers of people who have a wide spectrum of conditions. A subset of conditions has remained globally pervasive since 1990, whereas other conditions have displayed more dynamic trends, with different ages, sexes, and geographies across the globe experiencing varying burdens and trends of health loss. This study emphasises how global improvements in premature mortality for select conditions have led to older populations with complex and potentially expensive diseases, yet also highlights global achievements in certain domains of disease and injury.FundingBill & Melinda Gates Foundation.","['Medicine', 'Life expectancy', 'Incidence (geometry)', 'Demography', 'Population', 'China', 'Estimation', 'Disease burden', 'Population ageing', 'Environmental health', 'Gerontology', 'Geography', 'Physics', 'Archaeology', 'Management', 'Sociology', 'Optics', 'Economics']","risk factors, surveillance, inpatient admission records, outpatient visit records, health insurance claims, cause of death, ##s, oral disorders, headache disorders, ha, ##oglobino, haemolytic anaemias, oral disorders, headache disorders, tuberculosis, latent tuberculosis infection"
Paper_01120,Studies of Illness in the Aged,['Sidney Katz'],1963,JAMA,Journal,,914-914,185,12,10.1001/jama.1963.03060120024016,"The Index of ADL was developed to study results of treatment and prognosis in the elderly and chronically ill. Grades of the Index summarize over-all performance in bathing, dressing, going to toilet, transferring, continence, and feeding. More than 2,000 evaluations of 1,001 individuals demonstrated use of the Index as a survey instrument, as an objective guide to the course of chronic illness, as a tool for studying the aging process, and as an aid in rehabilitation teaching. Of theoretical interest is the observation that the order of recovery of Index functions in disabled patients is remarkably similar to the order of development of primary functions in children. This parallelism, and similarity to the behavior of primitive peoples, suggests that the Index is based on primary biological and psychosocial function, reflecting the adequacy of organized neurological and locomotor response.","['Medicine', 'Bathing', 'Psychosocial', 'Rehabilitation', 'Index (typography)', 'Toilet', 'Gerontology', 'Physical therapy', 'Physical medicine and rehabilitation', 'Psychiatry', 'Pathology', 'World Wide Web', 'Computer science']","adl, prognosis, chronically ill, continence, rehabilitation teaching, index functions, disabled patients, primary functions, primitive peoples, psychosocial function, locomotor response"
Paper_01121,"Happiness is everything, or is it? Explorations on the meaning of psychological well-being.",['Carol D. Ryff'],1989,Journal of Personality and Social Psychology,Journal,,1069-1081,57,6,10.1037/0022-3514.57.6.1069,Caracterización de,"['Happiness', 'Psychology', 'Meaning (existential)', 'Social psychology', 'Well-being', 'Psychological well-being', 'Psychotherapist']","caracteriza, [PAD], [PAD] [PAD] [PAD], [PAD], [PAD], [PAD] [PAD] [PAD], [PAD] [PAD], [PAD] [PAD] [PAD], [PAD], [PAD], [PAD] [PAD], [PAD] [PAD], [PAD], [PAD] [PAD]"
Paper_01125,Climate Change 2013 – The Physical Science Basis,[],2014,Cambridge University Press eBooks,Unknown,,,,,10.1017/cbo9781107415324,"This latest Fifth Assessment Report of the Intergovernmental Panel on Climate Change (IPCC) will again form the standard scientific reference for all those concerned with climate change and its consequences, including students and researchers in environmental science, meteorology, climatology, biology, ecology and atmospheric chemistry. It provides invaluable material for decision makers and stakeholders: international, national, local; and in all branches: government, businesses, and NGOs. This volume provides: • An authoritative and unbiased overview of the physical science basis of climate change • A more extensive assessment of changes observed throughout the climate system than ever before • New dedicated chapters on sea-level change, biogeochemical cycles, clouds and aerosols, and regional climate phenomena • A more extensive coverage of model projections, both near-term and long-term climate projections • A detailed assessment of climate change observations, modelling, and attribution for every continent • A new comprehensive atlas of global and regional climate projections for 35 regions of the world","['Climate change', 'Geography', 'Climatology', 'Environmental science', 'Climate model', 'Environmental resource management', 'Oceanography', 'Geology']","##govern, climate change, ip, climate, environmental science, meteorology, climatology, biology, ecology, atmospheric chemistry, biogeochemical cycles, clouds, aerosols, regional climate phenomena"
Paper_01126,BUSCO: assessing genome assembly and annotation completeness with single-copy orthologs,"['Felipe A. Simão', 'Robert M. Waterhouse', 'Panagiotis Ioannidis', 'Evgenia V. Kriventseva', 'Evgeny M. Zdobnov']",2015,Bioinformatics,Journal,,3210-3212,31,19,10.1093/bioinformatics/btv351,"Genomics has revolutionized biological research, but quality assessment of the resulting assembled sequences is complicated and remains mostly limited to technical measures like N50.We propose a measure for quantitative assessment of genome assembly and annotation completeness based on evolutionarily informed expectations of gene content. We implemented the assessment procedure in open-source software, with sets of Benchmarking Universal Single-Copy Orthologs, named BUSCO.Software implemented in Python and datasets available for download from http://busco.ezlab.org.evgeny.zdobnov@unige.chSupplementary data are available at Bioinformatics online.","['Python (programming language)', 'Annotation', 'Benchmarking', 'Computer science', 'Software', 'Genome', 'Genomics', 'Gene Annotation', 'Computational biology', 'Download', 'Biology', 'Gene', 'Genetics', 'Artificial intelligence', 'World Wide Web', 'Programming language', 'Marketing', 'Business']","genomics, biological research, quality assessment, n50, quantitative assessment, genome assembly, annotation completeness, gene content, busco, bioinformatics online, [PAD], [PAD], [PAD] [PAD], [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"
Paper_01127,The Norm of Reciprocity: A Preliminary Statement,['Alvin W. Gouldner'],1960,American Sociological Review,Journal,,161-161,25,2,10.2307/2092623,"The manner in which the concept of reciprocity is implicated in functional theory is explored, enabling a reanalysis of the concepts of survival and exploitation. The need to distinguish between the concepts of complementarity and reciprocity is stressed. Distinctions are also drawn between (1) reciprocity as a pattern of mutually contingent exchange of gratifications, (2) the existential or folk belief in reciprocity, and (3) the generalized moral norm of reciprocity. Reciprocity as a moral norm is analyzed; it is hypothesized that it is one of the universal principal components of moral codes. As Westermarck states, To requite a benefit, or to be grateful to him who bestows it, is probably everywhere, at least under certain circumstances, regarded as a duty. This is a subject which in the present connection calls for special consideration. Ways in which the norm of reciprocity is implicated in the maintenance of stable social systems are examined.","['Reciprocity (cultural anthropology)', 'Norm (philosophy)', 'Statement (logic)', 'Mathematical economics', 'Mathematics', 'Psychology', 'Sociology', 'Political science', 'Social psychology', 'Law']","reciprocity, functional theory, survival, exploitation, complementarity, reciprocity, reciprocity, mutually contingent exchange, gratifications, folk belief, reciprocity, generalized moral norm, reciprocity, ##iprocity, moral norm, moral codes, reciprocity, stable social systems, [PAD], [PAD], [PAD], [PAD], [PAD]"
Paper_01128,Triblock Copolymer Syntheses of Mesoporous Silica with Periodic 50 to 300 Angstrom Pores,"['Dongyuan Zhao', 'Jianglin Feng', 'Qisheng Huo', 'Nicholas A. Melosh', 'Glenn H. Fredrickson', 'Bradley F. Chmelka', 'Galen D. Stucky']",1998,Science,Journal,,548-552,279,5350,10.1126/science.279.5350.548,"Use of amphiphilic triblock copolymers to direct the organization of polymerizing silica species has resulted in the preparation of well-ordered hexagonal mesoporous silica structures (SBA-15) with uniform pore sizes up to approximately 300 angstroms. The SBA-15 materials are synthesized in acidic media to produce highly ordered, two-dimensional hexagonal (space group p6mm) silica-block copolymer mesophases. Calcination at 500 degrees C gives porous structures with unusually large interlattice d spacings of 74.5 to 320 angstroms between the (100) planes, pore sizes from 46 to 300 angstroms, pore volume fractions up to 0.85, and silica wall thicknesses of 31 to 64 angstroms. SBA-15 can be readily prepared over a wide range of uniform pore sizes and pore wall thicknesses at low temperature (35 degrees to 80 degrees C), using a variety of poly(alkylene oxide) triblock copolymers and by the addition of cosolvent organic molecules. The block copolymer species can be recovered for reuse by solvent extraction with ethanol or removed by heating at 140 degrees C for 3 hours, in both cases, yielding a product that is thermally stable in boiling water.","['Copolymer', 'Calcination', 'Mesoporous material', 'Angstrom', 'Materials science', 'Chemical engineering', 'Porosity', 'Solvent', 'Mesoporous silica', 'Hexagonal crystal system', 'Boiling', 'Crystallography', 'Polymer chemistry', 'Chemistry', 'Composite material', 'Organic chemistry', 'Catalysis', 'Polymer', 'Engineering']","amphiphilic triblock copolymers, polymerizing silica species, acidic media, ##lat, pore volume fraction, silica wall thicknesses, ##e wall thickness, solvent extraction"
Paper_01129,"Cancer statistics, 2014","['Rebecca L. Siegel', 'Jiemin Ma', 'Zhaohui Zou', 'Ahmedin Jemal']",2014,CA A Cancer Journal for Clinicians,Journal,,9-29,64,1,10.3322/caac.21208,"Each year, the American Cancer Society estimates the numbers of new cancer cases and deaths that will occur in the United States in the current year and compiles the most recent data on cancer incidence, mortality, and survival. Incidence data were collected by the National Cancer Institute, the Centers for Disease Control and Prevention, and the North American Association of Central Cancer Registries and mortality data were collected by the National Center for Health Statistics. A total of 1,665,540 new cancer cases and 585,720 cancer deaths are projected to occur in the United States in 2014. During the most recent 5 years for which there are data (2006-2010), delay-adjusted cancer incidence rates declined slightly in men (by 0.6% per year) and were stable in women, while cancer death rates decreased by 1.8% per year in men and by 1.4% per year in women. The combined cancer death rate (deaths per 100,000 population) has been continuously declining for 2 decades, from a peak of 215.1 in 1991 to 171.8 in 2010. This 20% decline translates to the avoidance of approximately 1,340,400 cancer deaths (952,700 among men and 387,700 among women) during this time period. The magnitude of the decline in cancer death rates from 1991 to 2010 varies substantially by age, race, and sex, ranging from no decline among white women aged 80 years and older to a 55% decline among black men aged 40 years to 49 years. Notably, black men experienced the largest drop within every 10-year age group. Further progress can be accelerated by applying existing cancer control knowledge across all segments of the population.","['Demography', 'Medicine', 'Cancer', 'Incidence (geometry)', 'Health statistics', 'Population', 'Mortality rate', 'Cancer prevention', 'Gerontology', 'Environmental health', 'Surgery', 'Internal medicine', 'Physics', 'Sociology', 'Optics']","american cancer society, central cancer registries, women, white, black, black, cancer control"
Paper_01130,Profiling of complex microbial populations by denaturing gradient gel electrophoresis analysis of polymerase chain reaction-amplified genes coding for 16S rRNA,"['Gerard Muyzer', 'Ellen C. de Waal', 'André G. Uitterlinden']",1993,Applied and Environmental Microbiology,Journal,,695-700,59,3,10.1128/aem.59.3.695-700.1993,"We describe a new molecular approach to analyzing the genetic diversity of complex microbial populations. This technique is based on the separation of polymerase chain reaction-amplified fragments of genes coding for 16S rRNA, all the same length, by denaturing gradient gel electrophoresis (DGGE). DGGE analysis of different microbial communities demonstrated the presence of up to 10 distinguishable bands in the separation pattern, which were most likely derived from as many different species constituting these populations, and thereby generated a DGGE profile of the populations. We showed that it is possible to identify constituents which represent only 1% of the total population. With an oligonucleotide probe specific for the V3 region of 16S rRNA of sulfate-reducing bacteria, particular DNA fragments from some of the microbial populations could be identified by hybridization analysis. Analysis of the genomic DNA from a bacterial biofilm grown under aerobic conditions suggests that sulfate-reducing bacteria, despite their anaerobicity, were present in this environment. The results we obtained demonstrate that this technique will contribute to our understanding of the genetic diversity of uncharacterized microbial populations.","['Temperature gradient gel electrophoresis', 'Biology', 'Polymerase chain reaction', '16S ribosomal RNA', 'Gel electrophoresis', 'genomic DNA', 'DNA profiling', 'Gene', 'Bacteria', 'Ribosomal RNA', 'Genetics', 'Population', 'DNA', 'Demography', 'Sociology']","genetic diversity, complex microbial populations, gradient gel electrophoresis, oligonucleotide probe, hybridization analysis, aerobic, genetic diversity, ##terized microbial populations, [PAD]"
Paper_01131,Educating the reflective practitioner,['Donald A. Schön'],1987,"['Lecture Notes in Mechanical Engineering', 'Architecture and Design for Industry 4.0']",Unknown,,133-149,,,10.1007/978-3-031-36922-3_9,"Building on the concepts of professional competence that he introduced in his classic The Reflective Practitioner, Schon offers an approach for educating professional in all areas that will prepare them to handle the complex and unpredictable problems of actual practice with confidence, skill, and care.","['Reflective practice', 'Competence (human resources)', 'Medical education', 'Psychology', 'Professional development', 'Pedagogy', 'Engineering ethics', 'Nursing', 'Medicine', 'Engineering', 'Social psychology']","professional competence, reflective practitioner, [PAD], [PAD] [PAD]"
Paper_01132,The chemical basis of morphogenesis,['Alan Turing'],1952,"Philosophical transactions of the Royal Society of London. Series B, Biological sciences",Journal,,37-72,237,641,10.1098/rstb.1952.0012,"It is suggested that a system of chemical substances, called morphogens, reacting together and diffusing through a tissue, is adequate to account for the main phenomena of morphogenesis. Such a system, although it may originally be quite homogeneous, may later develop a pattern or structure due to an instability of the homogeneous equilibrium, which is triggered off by random disturbances. Such reaction-diffusion systems are considered in some detail in the case of an isolated ring of cells, a mathematically convenient, though biologically unusual system. The investigation is chiefly concerned with the onset of instability. It is found that there are six essentially different forms which this may take. In the most interesting form stationary waves appear on the ring. It is suggested that this might account, for instance, for the tentacle patterns on Hydra and for whorled leaves. A system of reactions and diffusion on a sphere is also considered. Such a system appears to account for gastrulation. Another reaction system in two dimensions gives rise to patterns reminiscent of dappling. It is also suggested that stationary waves in two dimensions could account for the phenomena of phyllotaxis. The purpose of this paper is to discuss a possible mechanism by which the genes of a zygote may determine the anatomical structure of the resulting organism. The theory does not make any new hypotheses; it merely suggests that certain well-known physical laws are sufficient to account for many of the facts. The full understanding of the paper requires a good knowledge of mathematics, some biology, and some elementary chemistry. Since readers cannot be expected to be experts in all of these subjects, a number of elementary facts are explained, which can be found in text-books, but whose omission would make the paper difficult reading.","['Phyllotaxis', 'Autowave', 'Excitable medium', 'Morphogenesis', 'Pattern formation', 'Instability', 'Diffusion', 'Basis (linear algebra)', 'Reaction–diffusion system', 'Homogeneous', 'Organism', 'Statistical physics', 'Physics', 'Biology', 'Mathematics', 'Classical mechanics', 'Mechanics', 'Neuroscience', 'Geometry', 'Mathematical analysis', 'Paleontology', 'Biochemistry', 'Genetics', 'Gene', 'Meristem', 'Thermodynamics']","chemical substances, morphogens, morphogenesis, homogeneous equilibrium, random disturbances, stationary waves, tentacle patterns, hydra, whorled leaves, diffusion, gastrulation, dappling, stationary waves, phyllotaxis, ##y, anatomical"
Paper_01133,Democracy and Education,['John Dewey'],2015,Routledge eBooks,Unknown,,291-320,,,10.4324/9781315712383-22,"First published in 1916, this classic continues to influence contemporary educational thought. Considered one of the great American philosophers, Dewey grapples with the nature of knowledge and learning as well as formal education's place, purpose, and process within a democratic society.","['Democracy', 'Political science', 'Sociology', 'Law', 'Politics']","educational, knowledge, formal education, democratic"
Paper_01134,"Critical Review of rate constants for reactions of hydrated electrons, hydrogen atoms and hydroxyl radicals (⋅OH/⋅O− in Aqueous Solution","['George V. Buxton', 'C.L. Greenstock', 'W. Phillips Helman', 'Alberta B. Ross']",1988,Journal of Physical and Chemical Reference Data,Journal,,513-886,17,2,10.1063/1.555805,"Kinetic data for the radicals H⋅ and ⋅OH in aqueous solution,and the corresponding radical anions, ⋅O− and eaq−, have been critically pulse radiolysis, flash photolysis and other methods. Rate constants for over 3500 reaction are tabulated, including reaction with molecules, ions and other radicals derived from inorganic and organic solutes.","['Radiolysis', 'Chemistry', 'Radical', 'Flash photolysis', 'Solvated electron', 'Reaction rate constant', 'Aqueous solution', 'Photochemistry', 'Photodissociation', 'Molecule', 'Radiation chemistry', 'Chemical reaction', 'Hydroxyl radical', 'Hydrogen', 'Reaction mechanism', 'Inorganic chemistry', 'Self-ionization of water', 'Ion', 'Kinetics', 'Physical chemistry', 'Organic chemistry', 'Catalysis', 'Physics', 'Quantum mechanics']","kinetic, ##queous solution, radical an, pulse radiolysis, flash photolysis, rate constant, organic solutes"
Paper_01135,On the Einstein Podolsky Rosen paradox,['J. S. Bell'],1964,Physics Physique Fizika,Journal,,195-200,1,3,10.1103/physicsphysiquefizika.1.195,Received 4 November 1964DOI:https://doi.org/10.1103/PhysicsPhysiqueFizika.1.195Copyright © 1964 Physics Publishing Co.,"['Einstein', 'Physics', 'EPR paradox', 'Publishing', 'Theoretical physics', 'Philosophy', 'Mathematical physics', 'Quantum mechanics', 'Art', 'Quantum', 'Literature', 'Quantum entanglement']","physics, physics publishing"
Paper_01137,Aspects of the Theory of Syntax,['Noam Chomsky'],1965,['The Philosophical Quarterly'],Unknown,,393,16,65,10.2307/2218520,Abstract : Contents: Methodological preliminaries: Generative grammars as theories of linguistic competence; theory of performance; organization of a generative grammar; justification of grammars; formal and substantive grammars; descriptive and explanatory theories; evaluation procedures; linguistic theory and language learning; generative capacity and its linguistic relevance Categories and relations in syntactic theory: Scope of the base; aspects of deep structure; illustrative fragment of the base component; types of base rules Deep structures and grammatical transformations Residual problems: Boundaries of syntax and semantics; structure of the lexicon,"['Generative grammar', 'Linguistics', 'Rule-based machine translation', 'Syntax', 'Word grammar', 'Computer science', 'Linguistic competence', 'Generalized phrase structure grammar', 'Natural language processing', 'Affix grammar', 'Relational grammar', 'Emergent grammar', 'Artificial intelligence', 'Lexicon', 'Phrase structure grammar', 'Grammar', 'Minimalist program', 'Context-free grammar', 'Philosophy']","methodological, generative grammars, linguistic competence, theory, performance, generative grammar, justification of, substantive grammars, ##planatory theories, evaluation procedures, linguistic theory, language learning, generative capacity, linguistic relevance, syntactic theory, deep structure, ##rative fragment, base rules, grammatical transformations, syntax, semantics, lexi"
Paper_01138,Diagnosis and Management of the Metabolic Syndrome,"['Scott M. Grundy', 'James I. Cleeman', 'Stephen R. Daniels', 'Karen A. Donato', 'Robert H. Eckel', 'Barry A. Franklin', 'David J. Gordon', 'Ronald M. Krauss', 'Peter J. Savage', 'Sidney C. Smith', 'John A. Spertus', 'Fernando Costa']",2005,Circulation,Journal,,2735-2752,112,17,10.1161/circulationaha.105.169404,"The metabolic syndrome has received increased attention in the past few years. This statement from the American Heart Association (AHA) and the National Heart, Lung, and Blood Institute (NHLBI) is intended to provide up-to-date guidance for professionals on the diagnosis and management of the metabolic syndrome in adults.

The metabolic syndrome is a constellation of interrelated risk factors of metabolic origin— metabolic risk factors —that appear to directly promote the development of atherosclerotic cardiovascular disease (ASCVD).1 Patients with the metabolic syndrome also are at increased risk for developing type 2 diabetes mellitus. Another set of conditions, the underlying risk factors , give rise to the metabolic risk factors. In the past few years, several expert groups have attempted to set forth simple diagnostic criteria to be used in clinical practice to identify patients who manifest the multiple components of the metabolic syndrome. These criteria have varied somewhat in specific elements, but in general they include a combination of both underlying and metabolic risk factors.

The most widely recognized of the metabolic risk factors are atherogenic dyslipidemia, elevated blood pressure, and elevated plasma glucose. Individuals with these characteristics commonly manifest a prothrombotic state and a pro-inflammatory state as well. Atherogenic dyslipidemia consists of an aggregation of lipoprotein abnormalities including elevated serum triglyceride and apolipoprotein B (apoB), increased small LDL particles, and a reduced level of HDL cholesterol (HDL-C). The metabolic syndrome is often referred to as if it were a discrete entity with a single cause. Available data suggest that it truly is a syndrome, ie, a grouping of ASCVD risk factors, but one that probably has more than one cause. Regardless of cause, the syndrome identifies individuals at an elevated risk for ASCVD. The magnitude of the increased risk can vary according to which components of the syndrome are …","['Metabolic syndrome', 'Medicine', 'Dyslipidemia', 'Diabetes mellitus', 'Internal medicine', 'Risk factor', 'Apolipoprotein B', 'Type 2 Diabetes Mellitus', 'Disease', 'Endocrinology', 'Cholesterol']","metabolic syndrome, american heart association, metabolic syndrome, metabolic risk factors, at, ##os, ##rotic cardiovascular disease, as, metabolic, metabolic risk factors, atherogenic dyslipidemia, elevated, atherogenic d"
Paper_01139,Back-Translation for Cross-Cultural Research,['Richard W. Brislin'],1970,Journal of Cross-Cultural Psychology,Journal,,185-216,1,3,10.1177/135910457000100301,"Two aspects of translation were investigated: (1) factors that affect translation quality, and (2) how equivalence between source and target versions can be evaluated. The variables of language, content, and difficulty were studied through an analysis of variance design. Ninety-four bilinguals from the University of Guam, representing ten languages, translated or back-translated six essays incorporating three content areas and two levels of difficulty. The five criteria for equivalence were based on comparisons of meaning or predictions of similar responses to original or translated versions. The factors of content, difficulty, language and content-language interaction were significant, and the five equivalence criteria proved workable. Conclusions are that translation quality can be predicted, and that a functionally equivalent translation can be demonstrated when responses to the original and target versions are studied.","['Equivalence (formal languages)', 'Translation (biology)', 'Natural language processing', 'Computer science', 'Linguistics', 'Dynamic and formal equivalence', 'Variance (accounting)', 'Meaning (existential)', 'Content (measure theory)', 'Artificial intelligence', 'Psychology', 'Mathematics', 'Machine translation', 'Philosophy', 'Mathematical analysis', 'Biochemistry', 'Chemistry', 'Accounting', 'Messenger RNA', 'Business', 'Psychotherapist', 'Gene']","translation, translation quality, variance design, equivalence, translation quality, [PAD] [PAD], [PAD]"
Paper_01141,Qualitative Research Design: An Interactive Approach,['Joseph A. Maxwell'],1996,['Anthropology &amp; Education Quarterly'],Unknown,,499-501,29,4,10.1525/aeq.1998.29.4.499,Chapter 1. A Model for Qualitative Research Design Chapter 2. Goals: Why Are You Doing This Study? Chapter 3. Conceptual Framework: What Do You Think Is Going On? Chapter 4. Research Questions: What Do You Want to Understand? Chapter 5. Methods: What Will You Actually Do? Chapter 6. Validity: How Might You Be Wrong? Chapter 7. Research Proposals: Presenting and Justifying a Qualitative Study Appendix A. A Proposal for a Study of Medical School Teaching Appendix B. A Proposal for a Study of Online Learning by Teachers,"['Qualitative research', 'Management science', 'Research design', 'Computer science', 'Mathematics education', 'Engineering ethics', 'Psychology', 'Sociology', 'Engineering', 'Social science']","qualitative research design, conceptual framework, qualitative study, medical school teaching, online learning, teachers, [PAD] [PAD] [PAD] [PAD]"
Paper_01142,"The measurement and antecedents of affective, continuance and normative commitment to the organization","['Natalie J. Allen', 'John P. Meyer']",1990,Journal of Occupational Psychology,Journal,,1-18,63,1,10.1111/j.2044-8325.1990.tb00506.x,"Organizational commitment has been conceptualized and measured in various ways. The two studies reported here were conducted to test aspects of a three-component model of commitment which integrates these various conceptualizations. The affective component of organizational commitment, proposed by the model, refers to employees' emotional attachment to, identification with, and involvement in, the organization. The continuance component refers to commitment based on the costs that employees associate with leaving the organization. Finally, the normative component refers to employees' feelings of obligation to remain with the organization. In Study 1, scales were developed to measure these components. Relationships among the components of commitment and with variables considered their antecedents were examined in Study 2. Results of a canonical correlation analysis suggested that, as predicted by the model, the affective and continuance components of organizational commitment are empirically distinguishable constructs with different correlates. The affective and normative components, although distinguishable, appear to be somewhat related. The importance of differentiating the components of commitment, both in research and practice, is discussed.","['Organizational commitment', 'Continuance', 'Psychology', 'Normative', 'Social psychology', 'Obligation', 'Feeling', 'Affective events theory', 'Component (thermodynamics)', 'Organizational identification', 'Identification (biology)', 'Job satisfaction', 'Job performance', 'Epistemology', 'Philosophy', 'Physics', 'Botany', 'Job attitude', 'Biology', 'Political science', 'Law', 'Thermodynamics']","organizational commitment, commitment, affective component, organizational commitment, continuance, normative, canonical correlation analysis, continuance components, organizational commitment, normative"
Paper_01143,The descent of man and selection in relation to sex,"['ダーウィン チャールス', '田中 茂穂']",1907,Tokyo Jinrui Gakkai zasshi,Journal,,495-514,22,258,10.1537/ase1887.22.495,"Introduction <sc>The</sc> nature of the following work will be best understood by a brief account of how it came to be written. During many years I collected notes on the origin or descent of man, without any intention of publishing on the subject, but...","['Descent (aeronautics)', 'Relation (database)', 'Selection (genetic algorithm)', 'Genealogy', 'Evolutionary biology', 'Biology', 'History', 'Computer science', 'Artificial intelligence', 'Geography', 'Data mining', 'Meteorology']",
Paper_01144,Multivariate data analysis : a global perspective,['Joseph F. Hair'],2010,['GeoJournal'],Unknown,,69-83,88,S1,10.1007/s10708-021-10520-4,1 Introduction: Models and Model Building Section I Understanding and Preparing for Multivariate Analysis 2 Cleaning and Transforming Data 3 Factor Analysis Section II Analysis Using Dependece Techniques 4 Simple and Multiple Regression Analysis 5 Canonical correlation 6 Conjoint analysis 7 Multiple Discriminant Analysis and Logistic Regression 8 ANOVA and MANOVA Section III Analysis using Interdependence Techniques 9 Group data and Cluster Analysis 10 MDS and Correspondence Analysis Structural Equation Modeling 11 SEM: An Introduction 12 Application of SEM,"['Multivariate analysis of variance', 'Linear discriminant analysis', 'Correspondence analysis', 'Canonical correlation', 'Statistics', 'Multivariate statistics', 'Multivariate analysis', 'Logistic regression', 'Regression analysis', 'Multiple correspondence analysis', 'Canonical analysis', 'Analysis of variance', 'Mathematics', 'Cluster (spacecraft)', 'Perspective (graphical)', 'Section (typography)', 'Principal component analysis', 'Computer science', 'Artificial intelligence', 'Programming language', 'Operating system']","model building, multivariate analysis, factor analysis, dependece techniques, multiple regression analysis, canonical correlation, conjoint analysis, multiple discriminant analysis, logistic regression, anova, manova, interdependence techniques, group data, cluster analysis, ##s, correspondence analysis structural equation modeling"
Paper_01145,Neighborhoods and Violent Crime: A Multilevel Study of Collective Efficacy,"['Robert J. Sampson', 'Stephen W. Raudenbush', 'Felton J. Earls']",1997,Science,Journal,,918-924,277,5328,10.1126/science.277.5328.918,"It is hypothesized that collective efficacy, defined as social cohesion among neighbors combined with their willingness to intervene on behalf of the common good, is linked to reduced violence. This hypothesis was tested on a 1995 survey of 8782 residents of 343 neighborhoods in Chicago, Illinois. Multilevel analyses showed that a measure of collective efficacy yields a high between-neighborhood reliability and is negatively associated with variations in violence, when individual-level characteristics, measurement error, and prior violence are controlled. Associations of concentrated disadvantage and residential instability with violence are largely mediated by collective efficacy.","['Collective efficacy', 'Multilevel model', 'Psychology', 'Disadvantage', 'Social psychology', 'Criminology', 'Cohesion (chemistry)', 'Poison control', 'Informal social control', 'Sociology', 'Environmental health', 'Political science', 'Medicine', 'Statistics', 'Social control', 'Mathematics', 'Social science', 'Chemistry', 'Organic chemistry', 'Law']","collective efficacy, social cohesion, neighbors, reduced, collective efficacy, measurement error, prior violence, concentrated disadvantage, residential instability, collective efficacy, [PAD], [PAD], [PAD], [PAD] [PAD]"
Paper_01146,Modularity and community structure in networks,['M. E. J. Newman'],2006,Proceedings of the National Academy of Sciences,Journal,,8577-8582,103,23,10.1073/pnas.0601602103,"Many networks of interest in the sciences, including a variety of social and biological networks, are found to divide naturally into communities or modules. The problem of detecting and characterizing this community structure has attracted considerable recent attention. One of the most sensitive detection methods is optimization of the quality function known as ""modularity"" over the possible divisions of a network, but direct application of this method using, for instance, simulated annealing is computationally costly. Here we show that the modularity can be reformulated in terms of the eigenvectors of a new characteristic matrix for the network, which we call the modularity matrix, and that this reformulation leads to a spectral algorithm for community detection that returns results of better quality than competing methods in noticeably shorter running times. We demonstrate the algorithm with applications to several network data sets.","['Modularity (biology)', 'Computer science', 'Community structure', 'Eigenvalues and eigenvectors', 'Clique percolation method', 'Complex network', 'Function (biology)', 'Quality (philosophy)', 'Theoretical computer science', 'Network analysis', 'Data mining', 'Artificial intelligence', 'Data science', 'Mathematics', 'World Wide Web', 'Biology', 'Engineering', 'Quantum mechanics', 'Philosophy', 'Genetics', 'Physics', 'Epistemology', 'Combinatorics', 'Evolutionary biology', 'Electrical engineering']","social, biological networks, quality function, modularity, simulated annealing, modularity, eigenve, characteristic matrix, modularity matrix, spectral algorithm, community detection"
Paper_01147,Managing Legitimacy: Strategic and Institutional Approaches,['Mark C. Suchman'],1995,Academy of Management Review,Journal,,571-610,20,3,10.5465/amr.1995.9508080331,"This article synthesizes the large but diverse literature on organizational legitimacy, highlighting similarities and disparities among the leading strategic and institutional approaches. The analysis identifies three primary forms of legitimacy: pragmatic, based on audience self-interest; moral, based on normative approval: and cognitive, based on comprehensibility and taken-for-grantedness. The article then examines strategies for gaining, maintaining, and repairing legitimacy of each type, suggesting both the promises and the pitfalls of such instrumental manipulations.","['Legitimacy', 'Strategic planning', 'Institutional theory', 'Business', 'Management', 'Sociology', 'Political science', 'Public relations', 'Economics', 'Marketing', 'Politics', 'Law']","organizational legitimacy, institutional approaches, legitimacy, pragmatic, moral, normative approval, cognitive, comprehensibility"
Paper_01148,Social Foundations of Thought and Action: A Social Cognitive Theory,['Albert Bandura'],1985,['The Academy of Management Review'],Unknown,,169,12,1,10.2307/258004,1. Models of Human Nature and Casualty. 2. Observational Learning. 3. Enactive Learning. 4. Social Diffusion and Innovation. 5. Predictive Knowledge and Forethought. 6. Incentive Motivators. 7. Vicarious Motivators. 8. Self-Regulatory Mechanisms. 9. Self-Efficacy. 10. Cognitive Regulators. References. Index.,"['Observational learning', 'Social cognitive theory', 'Psychology', 'Action (physics)', 'Social learning', 'Incentive', 'Cognition', 'Observational study', 'Social learning theory', 'Cognitive psychology', 'Cognitive science', 'Social psychology', 'Epistemology', 'Mathematics education', 'Experiential learning', 'Medicine', 'Pedagogy', 'Neuroscience', 'Philosophy', 'Economics', 'Physics', 'Pathology', 'Quantum mechanics', 'Microeconomics']","human nature, observational learning, enactive learning, social diffusion, innovation, predictive knowledge, forethought, incentive motivators, vicarious motivators, cognitive regulators, [PAD] [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD]"
Paper_01149,Practical Nonparametric Statistics,"['David J. Groggel', 'W. J. Conover']",2000,Technometrics,Journal,,317-317,42,3,10.2307/1271101,Probability Theory. Statistical Inference. Some Tests Based on the Binomial Distribution. Contingency Tables. Some Methods Based on Ranks. Statistics of the Kolmogorov-Smirnov Type. References. Appendix Tables. Answers to Odd-Numbered Exercises. Index.,"['Contingency table', 'Nonparametric statistics', 'Statistics', 'Statistical inference', 'Mathematics', 'Index (typography)', 'Mathematical statistics', 'Binomial (polynomial)', 'Binomial distribution', 'Statistical hypothesis testing', 'Econometrics', 'Negative binomial distribution', 'Statistical theory', 'Computer science', 'Poisson distribution', 'World Wide Web']","probability theory, statistical inference, binomial distribution, contingency tables, ranks, [PAD] [PAD], [PAD] [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD] [PAD], [PAD], [PAD] [PAD]"
Paper_01150,The SIESTA method for<i>ab initio</i>order-<i>N</i>materials simulation,"['José M. Soler', 'Emilio Artacho', 'Julian D. Gale', 'Alberto Garcı́a', 'Javier Junquera', 'Pablo Ordejón', 'Daniel Sánchez‐Portal']",2002,Journal of Physics Condensed Matter,Journal,,2745-2779,14,11,10.1088/0953-8984/14/11/302,"We have developed and implemented a self-consistent density functional method using standard norm-conserving pseudopotentials and a flexible, numerical LCAO basis set, which includes multiple-zeta and polarization orbitals. Exchange and correlation are treated with the local spin density or generalized gradient approximations. The basis functions and the electron density are projected on a real-space grid, in order to calculate the Hartree and exchange-correlation potentials and matrix elements, with a number of operations that scales linearly with the size of the system. We use a modified energy functional, whose minimization produces orthogonal wavefunctions and the same energy and density as the Kohn-Sham energy functional, without the need of an explicit orthogonalization. Additionally, using localized Wannier-like electron wavefunctions allows the computation time and memory, required to minimize the energy, to also scale linearly with the size of the system. Forces and stresses are also calculated efficiently and accurately, thus allowing structural relaxation and molecular dynamics simulations.","['Linear combination of atomic orbitals', 'Basis set', 'Wannier function', 'Wave function', 'SIESTA (computer program)', 'Basis function', 'Density functional theory', 'Statistical physics', 'Quantum mechanics', 'Atomic orbital', 'Linear scale', 'Physics', 'Ab initio quantum chemistry methods', 'Electron', 'Molecule', 'Geodesy', 'Geography']","##ao basis set, polarization orbitals, local spin density, generalized gradient approximations, basis, electron density, modified energy functional, orthogonal wavefunctions, stresses, structural relaxation, molecular dynamics simulations"
Paper_01151,Business Research Methods,"['Emma Bell', 'Alan Bryman', 'Bill Harley']",2022,Oxford University Press eBooks,Unknown,,,,,10.1093/hebz/9780198869443.001.0001,"<italic>Business Research Methods</italic> contains new and revised chapters on quantitative methods and visual research, while cutting-edge material on inclusivity and bias in research, feminist perspectives, and decolonial and indigenous research is also introduced. The book is composed of four parts. The first part looks at the research process. It covers research strategies and designs, as well as ethics in business research and writing up business research. Part 2 looks at quantitative research and details the nature of quantitative research, sampling, structured interviewing, and questions. It also looks at secondary analysis and statistics. The next part is about qualitative research. This part examines ethnography, participant observation, interviewing, focus groups, language, and document data. The final part is about mixed methods of research.","['Interview', 'Ethnography', 'Research design', 'Qualitative research', 'Research method', 'Focus (optics)', 'Sociology', 'Participant observation', 'Visual research', 'Indigenous', 'Engineering ethics', 'Computer science', 'Engineering', 'Social science', 'Visual arts', 'Anthropology', 'Business administration', 'Physics', 'Optics', 'Business', 'Art', 'Ecology', 'Biology']","business research methods, quantitative methods, visual research, inclusivity, bias, feminist perspectives, indigenous research, ethics, business research, business research, quantitative research, quantitative research, sampling, structured interviewing, secondary analysis, statistics, qualitative research, ethnography, participant observation, interviewing, focus groups, language, document data, mixed methods"
Paper_01153,A Fast Iterative Shrinkage-Thresholding Algorithm for Linear Inverse Problems,"['Amir Beck', 'Marc Teboulle']",2009,SIAM Journal on Imaging Sciences,Journal,,183-202,2,1,10.1137/080716542,"We consider the class of iterative shrinkage-thresholding algorithms (ISTA) for solving linear inverse problems arising in signal/image processing. This class of methods, which can be viewed as an extension of the classical gradient algorithm, is attractive due to its simplicity and thus is adequate for solving large-scale problems even with dense matrix data. However, such methods are also known to converge quite slowly. In this paper we present a new fast iterative shrinkage-thresholding algorithm (FISTA) which preserves the computational simplicity of ISTA but with a global rate of convergence which is proven to be significantly better, both theoretically and practically. Initial promising numerical results for wavelet-based image deblurring demonstrate the capabilities of FISTA which is shown to be faster than ISTA by several orders of magnitude.","['Deblurring', 'Thresholding', 'Algorithm', 'Rate of convergence', 'Shrinkage', 'Inverse problem', 'Mathematics', 'Wavelet', 'Iterative method', 'Image (mathematics)', 'Image processing', 'Inverse', 'Simplicity', 'Computer science', 'Mathematical optimization', 'Applied mathematics', 'Image restoration', 'Artificial intelligence', 'Mathematical analysis', 'Computer network', 'Channel (broadcasting)', 'Statistics', 'Philosophy', 'Geometry', 'Epistemology']","linear inverse problems, classical gradient algorithm, dense matrix data, fista, global rate of convergence, fista"
Paper_01155,The expression of the emotions in man and animals.,['Charles Darwin'],1872,John Murray eBooks,Unknown,,,,,10.1037/10001-000,"Acknowledgments List of Illustrations Figures Plates Preface to the Anniversary Edition by Paul Ekman Preface to the Third Edition by Paul Ekman Preface to the Second Edition by Francis Darwin Introduction to the Third Edition by Paul Ekman The Expression of the Emotions in Man and Animals Introduction to the First Edition 1. General Principles of Expression 2. General Principles of Expression -- continued 3. General Principles of Expression -- continued 4. Means of Expression in Animals 5. Special Expressions of Animals 6. Special Expressions of Man: Suffering and Weeping 7. Low Spirits, Anxiety, Grief, Dejection, Despair 8. Joy, High Spirits, Love, Tender Feelings, Devotion 9. Reflection - Meditation - Ill-temper - Sulkiness - Determination 10. Hatred and Anger 11. Disdain - Contempt - Disgust - Guilt - Pride, Etc. - Helplessness - Patience - Affirmation and Negation 12. Surprise - Astonishment - Fear - Horror 13. Self-attention - Shame - Shyness - Modesty: Blushing 14. Concluding Remarks and Summary Afterword, by Paul Ekman APPENDIX I: Charles Darwin's Obituary, by T. H. Huxley APPENDIX II: Changes to the Text, by Paul Ekman APPENDIX III: Photography and The Expression of the Emotions, by Phillip Prodger APPENDIX IV: A Note on the Orientation of the Plates, by Phillip Prodger and Paul Ekman APPENDIX V: Concordance of Illustrations, by Phillip Prodger APPENDIX VI: List of Head Words from the Index to the First Edition NOTES NOTES TO THE COMMENTARIES INDEX","['Expression (computer science)', 'Psychology', 'Communication', 'Cognitive psychology', 'Computer science', 'Programming language']","weeping, low spirits, anxiety, grief, ##ion, despair, joy, hatred, anger, disdain, negation"
Paper_01156,Preoperative assessment of liver function: a comparison of <sup>99m</sup>Tc‐Mebrofenin scintigraphy with indocyanine green clearance test,"['Deha Erdogan', 'Bob H. M. Heijnen', 'Roelof J. Bennink', 'M.F.J. Kok', 'S. Dinant', 'Irene H. Straatsburg', 'Dirk J. Gouma', 'Thomas M. van Gulik']",2004,Liver International,Journal,,117-123,24,2,10.1111/j.1478-3231.2004.00901.x,"Background/aims: The indocyanine green (ICG) clearance test is the most frequently used test for preoperative assessment of liver parenchymal function but has its limitations. The aim of this study was to investigate the correlation between ICG clearance test and the liver uptake of 99‐Technetium‐labelled ( 99m Tc)‐Mebrofenin ( 99m Tc‐Mebrofenin) as measured with hepatobiliary scintigraphy. Methods: Fifty‐four patients were diagnosed as hepatocellular carcinoma ( n =9), hilar tumours ( n =20) and 25 patients with non‐parenchymal tumours including colorectal metastasis ( n =15) and miscellaneous tumours ( n =10). One day prior to operation, hepatobiliary 99m Tc‐Mebrofenin scintigraphy was performed after intravenous injection of 85 MBq and the 15‐min clearance rate of ICG (ICG‐C15) was measured. Results: The mean ICG‐C15 was 86.86±1.19% (SEM). The mean 99m Tc‐Mebrofenin uptake rate was 12.87±0.52%/min. A significant correlation was obtained between 99m Tc‐Mebrofenin uptake rate by scintigraphy and ICG‐C15 ( r =0.73, P &lt;0.0001). The mean clearance capacity of the right liver segments (79.83±1.63, range 47.75–95.97%) was larger than that of the left segments (20.24±1.55, range 6.51–52.51%). Conclusion: 99m Tc‐Mebrofenin uptake rate as assessed by scintigraphy is an efficient method for determining liver function and correlates well with ICG clearance. At the same time, 99m Tc‐Mebrofenin scintigraphy provides information of segmental functional liver tissue, which is of additional use when planning liver resection.","['Indocyanine green', 'Scintigraphy', 'Medicine', 'Technetium-99m', 'Technetium', 'Liver function', 'Nuclear medicine', 'Clearance rate', 'Hepatocellular carcinoma', 'Parenchyma', 'Gastroenterology', 'Internal medicine', 'Surgery', 'Pathology']","indocyanine green, ##operative assessment, liver parenchymal function, icg, liver uptake, hepatobiliary scintigraphy, hepatocellular carcinoma, hilar tumours, non ‐ paren, ##mal tumours, colorectal metastasis, miscellaneous tumours, mebrofenin scintigraphy, ##brofen, mean, mebrofen, scintigraphy, liver function, icg, ##brofenin scintigraphy, segmental functional liver tissue, liver resection"
Paper_01157,A contribution to the mathematical theory of epidemics,"['W. O. Kermack', 'A. G. McKendrick']",1927,Proceedings of the Royal Society of London Series A Containing Papers of a Mathematical and Physical Character,Journal,,700-721,115,772,10.1098/rspa.1927.0118,"(1) One of the most striking features in the study of epidemics is the difficulty of finding a causal factor which appears to be adequate to account for the magnitude of the frequent epidemics of disease which visit almost every population. It was with a view to obtaining more insight regarding the effects of the various factors which govern the spread of contagious epidemics that the present investigation was undertaken. Reference may here be made to the work of Ross and Hudson (1915-17) in which the same problem is attacked. The problem is here carried to a further stage, and it is considered from a point of view which is in one sense more general. The problem may be summarised as follows: One (or more) infected person is introduced into a community of individuals, more or less susceptible to the disease in question. The disease spreads from the affected to the unaffected by contact infection. Each infected person runs through the course of his sickness, and finally is removed from the number of those who are sick, by recovery or by death. The chances of recovery or death vary from day to day during the course of his illness. The chances that the affected may convey infection to the unaffected are likewise dependent upon the stage of the sickness. As the epidemic spreads, the number of unaffected members of the community becomes reduced. Since the course of an epidemic is short compared with the life of an individual, the population may be considered as remaining constant, except in as far as it is modified by deaths due to the epidemic disease itself. In the course of time the epidemic may come to an end. One of the most important probems in epidemiology is to ascertain whether this termination occurs only when no susceptible individuals are left, or whether the interplay of the various factors of infectivity, recovery and mortality, may result in termination, whilst many susceptible individuals are still present in the unaffected population. It is difficult to treat this problem in its most general aspect. In the present communication discussion will be limited to the case in which all members of the community are initially equally susceptible to the disease, and it will be further assumed that complete immunity is conferred by a single infection.","['Disease', 'Population', 'Epidemic disease', 'Contagious disease', 'Demography', 'Medicine', 'Virology', 'Sociology', 'Pathology']","causal factor, contagious epidemics, ##idemi, in, complete immunity"
Paper_01159,"""Why Should I Trust You?""","['Marco Túlio Ribeiro', 'Sameer Singh', 'Carlos Guestrin']",2016,Unknown,Unknown,,1135-1144,,,10.1145/2939672.2939778,"Despite widespread adoption, machine learning models remain mostly black boxes. Understanding the reasons behind predictions is, however, quite important in assessing trust, which is fundamental if one plans to take action based on a prediction, or when choosing whether to deploy a new model. Such understanding also provides insights into the model, which can be used to transform an untrustworthy model or prediction into a trustworthy one.","['Trustworthiness', 'Computer science', 'Action (physics)', 'Data science', 'Data modeling', 'Artificial intelligence', 'Computer security', 'Software engineering', 'Physics', 'Quantum mechanics']","machine learning models, trust, ##trust, [PAD], [PAD], [PAD] [PAD]"
Paper_01160,Consumer Acceptance and Use of Information Technology: Extending the Unified Theory of Acceptance and Use of Technology,"['Venkatesh', 'Thong', 'Xu']",2012,MIS Quarterly,Journal,,157-157,36,1,10.2307/41410412,"This paper extends the unified theory of acceptance and use of technology (UTAUT) to study acceptance and use of technology in a consumer context. Our proposed UTAUT2 incorporates three constructs into UTAUT: hedonic motivation, price value, and habit. Individual differences--namely, age, gender, and experience--are hypothesized to moderate the effects of these constructs on behavioral intention and technology use. Results from a two-stage online survey, with technology use data collected four months after the first survey, of 1,512 mobile Internet consumers supported our model. Compared to UTAUT, the extensions proposed in UTAUT2 produced a substantial improvement in the variance explained in behavioral intention (56 percent to 74 percent) and technology use (40 percent to 52 percent). The theoretical and managerial implications of these results are discussed.","['Technology acceptance model', 'Unified theory of acceptance and use of technology', 'Information technology', 'Theory of planned behavior', 'Social acceptance', 'Acceptance testing', 'Business', 'Marketing', 'Engineering', 'Computer science', 'Psychology', 'Usability', 'Economics', 'Management', 'Human–computer interaction', 'Social psychology', 'Social influence', 'Control (management)', 'Software engineering', 'Operating system']","unified theory, utaut, consumer context, utaut, utaut, hedonic motivation, price value, habit, gender, behavioral intention, technology use, technology use, mobile internet consumers, utaut, utaut, behavioral intention, technology, managerial"
Paper_01162,The Hungarian method for the assignment problem,['Harold W. Kuhn'],1955,Naval Research Logistics Quarterly,Journal,,83-97,2,1-2,10.1002/nav.3800020109,"Abstract Assuming that numerical scores are available for the performance of each of n persons on each of n jobs, the “assignment problem” is the quest for an assignment of persons to jobs so that the sum of the n scores so obtained is as large as possible. It is shown that ideas latent in the work of two Hungarian mathematicians may be exploited to yield a new method of solving this problem.","['Assignment problem', 'Computer science', 'Hungarian algorithm', 'Yield (engineering)', 'Work (physics)', 'Mathematical optimization', 'Mathematics', 'Engineering', 'Mechanical engineering', 'Materials science', 'Metallurgy']",numerical scores
Paper_01163,Technical Change and the Aggregate Production Function,['Robert M. Solow'],1957,The Review of Economics and Statistics,Journal,,312-312,39,3,10.2307/1926047,"В статье производится анализ агрегированной производственной функции, вводится аппарат, позволяющий различать движение вдоль такой функции от ее сдвигов. На основании сделанных в статье предположений делаются выводы о характере технического прогресса и технологических изменений. Существенное внимание уделяется вариантам применения концепции агрегированной производственной функции.","['Production (economics)', 'Aggregate (composite)', 'Function (biology)', 'Economics', 'Production function', 'Econometrics', 'Microeconomics', 'Materials science', 'Evolutionary biology', 'Composite material', 'Biology']",
Paper_01164,Sequential extraction procedure for the speciation of particulate trace metals,"['André Tessier', 'Peter G. C. Campbell', 'M. B�isson']",1979,Analytical Chemistry,Journal,,844-851,51,7,10.1021/ac50043a017,"ADVERTISEMENT RETURN TO ISSUEPREVArticleNEXTSequential extraction procedure for the speciation of particulate trace metalsA. Tessier, P. G. C. Campbell, and M. BissonCite this: Anal. Chem. 1979, 51, 7, 844–851Publication Date (Print):June 1, 1979Publication History Published online1 May 2002Published inissue 1 June 1979https://pubs.acs.org/doi/10.1021/ac50043a017https://doi.org/10.1021/ac50043a017research-articleACS PublicationsRequest reuse permissionsArticle Views24132Altmetric-Citations8471LEARN ABOUT THESE METRICSArticle Views are the COUNTER-compliant sum of full text article downloads since November 2008 (both PDF and HTML) across all institutions and individuals. These metrics are regularly updated to reflect usage leading up to the last few days.Citations are the number of other articles citing this article, calculated by Crossref and updated daily. Find more information about Crossref citation counts.The Altmetric Attention Score is a quantitative measure of the attention that a research article has received online. Clicking on the donut icon will load a page at altmetric.com with additional details about the score and the social media presence for the given article. Find more information on the Altmetric Attention Score and how the score is calculated. Share Add toView InAdd Full Text with ReferenceAdd Description ExportRISCitationCitation and abstractCitation and referencesMore Options Share onFacebookTwitterWechatLinked InRedditEmail Other access optionsGet e-Alertsclose Get e-Alerts","['Citation', 'TRACE (psycholinguistics)', 'Computer science', 'Altmetrics', 'Social media', 'Icon', 'Information retrieval', 'Citation database', 'Library science', 'Data science', 'World Wide Web', 'Chemistry', 'MEDLINE', 'Philosophy', 'Linguistics', 'Biochemistry', 'Scopus', 'Programming language']","##varticlene, ##sequential extraction procedure, speciation, particulate trace metals, ##sar, ##le, ##f, altmetric attention score, social, altmetric attention score, ##d, ##citation, abstract, ##ation, references"
Paper_01166,Activating Mutations in the Epidermal Growth Factor Receptor Underlying Responsiveness of Non–Small-Cell Lung Cancer to Gefitinib,"['Thomas J. Lynch', 'Daphne W. Bell', 'Raffaella Sordella', 'Sarada Gurubhagavatula', 'Ross A. Okimoto', 'Brian W. Brannigan', 'Patricia L. Harris', 'Sara M. Haserlat', 'Jeffrey G. Supko', 'Frank G. Haluska', 'David N. Louis', 'David C. Christiani', 'Jeff Settleman', 'Daniel A. Haber']",2004,New England Journal of Medicine,Journal,,2129-2139,350,21,10.1056/nejmoa040938,"Most patients with non–small-cell lung cancer have no response to the tyrosine kinase inhibitor gefitinib, which targets the epidermal growth factor receptor (EGFR). However, about 10 percent of patients have a rapid and often dramatic clinical response. The molecular mechanisms underlying sensitivity to gefitinib are unknown.","['Gefitinib', 'Epidermal growth factor receptor', 'Lung cancer', 'Cancer research', 'Tyrosine kinase', 'Medicine', 'Epidermal growth factor', 'Tyrosine-kinase inhibitor', 'Mutation', 'Biology', 'Cancer', 'Internal medicine', 'Receptor', 'Gene', 'Genetics']","tyrosine kinase, gefitinib, epidermal growth factor receptor, egf, gefitin, [PAD] [PAD], [PAD] [PAD] [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD] [PAD] [PAD], [PAD], [PAD] [PAD], [PAD], [PAD] [PAD] [PAD], [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD], [PAD], [PAD] [PAD], [PAD], [PAD], [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"
Paper_01167,"Photocatalysis on TiO2 Surfaces: Principles, Mechanisms, and Selected Results","['Amy Linsebigler', 'Guangquan Lu', 'John T. Yates']",1995,Chemical Reviews,Journal,,735-758,95,3,10.1021/cr00035a013,"ADVERTISEMENT RETURN TO ISSUEPREVArticleNEXTPhotocatalysis on TiO2 Surfaces: Principles, Mechanisms, and Selected ResultsAmy L. Linsebigler, Guangquan Lu, and John T. Yates Jr.Cite this: Chem. Rev. 1995, 95, 3, 735–758Publication Date (Print):May 1, 1995Publication History Published online1 May 2002Published inissue 1 May 1995https://pubs.acs.org/doi/10.1021/cr00035a013https://doi.org/10.1021/cr00035a013research-articleACS PublicationsRequest reuse permissionsArticle Views59339Altmetric-Citations10180LEARN ABOUT THESE METRICSArticle Views are the COUNTER-compliant sum of full text article downloads since November 2008 (both PDF and HTML) across all institutions and individuals. These metrics are regularly updated to reflect usage leading up to the last few days.Citations are the number of other articles citing this article, calculated by Crossref and updated daily. Find more information about Crossref citation counts.The Altmetric Attention Score is a quantitative measure of the attention that a research article has received online. Clicking on the donut icon will load a page at altmetric.com with additional details about the score and the social media presence for the given article. Find more information on the Altmetric Attention Score and how the score is calculated. Share Add toView InAdd Full Text with ReferenceAdd Description ExportRISCitationCitation and abstractCitation and referencesMore Options Share onFacebookTwitterWechatLinked InRedditEmail Other access optionsGet e-Alertsclose Get e-Alerts","['Citation', 'Icon', 'Altmetrics', 'Social media', 'Computer science', 'World Wide Web', 'Information retrieval', 'Library science', 'Programming language']","##varticlenextphotocatalysis, ti, permissionsar, ##le views, ##le, ##f, ##f, altmetric attention score, social, altmetric, ##d, ##citation, abstract, ##ation, references"
Paper_01169,Electrodynamics of continuous media,"['L.D. LANDAU', 'E.M. LIFSHITZ', 'J. B. Sykes', 'J. S. Bell', 'Ellis H. Dill']",1960,['Encyclopedia of Condensed Matter Physics'],Unknown,,14-24,,,10.1016/b0-12-369401-9/00438-1,Electrostatics of conductors Static magnetic field Superconductivity The propagation of electromagnetic waves Spatial dispersion Diffraction of X rays in crystals.,"['Physics', 'Quantum electrodynamics']","electrostatic, conductors static magnetic field superconductivity, electromagnetic waves spatial dispersion diffraction, x rays, [PAD] [PAD]"
Paper_01170,Guidelines for the Process of Cross-Cultural Adaptation of Self-Report Measures,"['Dorcas Beaton', 'Claire Bombardier', 'Françis Guillemin', 'Marcos Bosi Ferraz']",2000,Spine,Journal,,3186-3191,25,24,10.1097/00007632-200012150-00014,"Beaton, Dorcas E. BScOT, MSc, PhD; Bombardier, Claire MD, FRCP; Guillemin, Francis MD, MSc; Ferraz, Marcos Bosi MD, MSc, PhD Author Information","['Medicine', 'Adaptation (eye)', 'Neuroscience', 'Psychology']",author information
Paper_01173,"Cancer statistics, 2023","['Rebecca L. Siegel', 'Kimberly D. Miller', 'Nikita Sandeep Wagle', 'Ahmedin Jemal']",2023,CA A Cancer Journal for Clinicians,Journal,,17-48,73,1,10.3322/caac.21763,"Each year, the American Cancer Society estimates the numbers of new cancer cases and deaths in the United States and compiles the most recent data on population-based cancer occurrence and outcomes using incidence data collected by central cancer registries and mortality data collected by the National Center for Health Statistics. In 2023, 1,958,310 new cancer cases and 609,820 cancer deaths are projected to occur in the United States. Cancer incidence increased for prostate cancer by 3% annually from 2014 through 2019 after two decades of decline, translating to an additional 99,000 new cases; otherwise, however, incidence trends were more favorable in men compared to women. For example, lung cancer in women decreased at one half the pace of men (1.1% vs. 2.6% annually) from 2015 through 2019, and breast and uterine corpus cancers continued to increase, as did liver cancer and melanoma, both of which stabilized in men aged 50 years and older and declined in younger men. However, a 65% drop in cervical cancer incidence during 2012 through 2019 among women in their early 20s, the first cohort to receive the human papillomavirus vaccine, foreshadows steep reductions in the burden of human papillomavirus-associated cancers, the majority of which occur in women. Despite the pandemic, and in contrast with other leading causes of death, the cancer death rate continued to decline from 2019 to 2020 (by 1.5%), contributing to a 33% overall reduction since 1991 and an estimated 3.8 million deaths averted. This progress increasingly reflects advances in treatment, which are particularly evident in the rapid declines in mortality (approximately 2% annually during 2016 through 2020) for leukemia, melanoma, and kidney cancer, despite stable/increasing incidence, and accelerated declines for lung cancer. In summary, although cancer mortality rates continue to decline, future progress may be attenuated by rising incidence for breast, prostate, and uterine corpus cancers, which also happen to have the largest racial disparities in mortality.","['Medicine', 'Cancer', 'Cervical cancer', 'Demography', 'Incidence (geometry)', 'Population', 'Prostate cancer', 'Lung cancer', 'Cohort', 'Breast cancer', 'Oncology', 'Internal medicine', 'Environmental health', 'Physics', 'Sociology', 'Optics']","american cancer society, incidence data, central cancer registries, mortality data, prostate cancer, lung cancer, women, ##erine, liver cancer, melanoma, cervical cancer, leukemia, mel, kidney cancer, lung cancer, uterine corpus cancers"
Paper_01174,Classification of subtype of acute ischemic stroke. Definitions for use in a multicenter clinical trial. TOAST. Trial of Org 10172 in Acute Stroke Treatment.,"['Harold P. Adams', 'Birgitte H. Bendixen', 'L. Jaap Kappelle', 'José Biller', 'Betsy B. Love', 'David Gordon', 'E. Eugene Marsh']",1993,Stroke,Journal,,35-41,24,1,10.1161/01.str.24.1.35,"The etiology of ischemic stroke affects prognosis, outcome, and management. Trials of therapies for patients with acute stroke should include measurements of responses as influenced by subtype of ischemic stroke. A system for categorization of subtypes of ischemic stroke mainly based on etiology has been developed for the Trial of Org 10172 in Acute Stroke Treatment (TOAST). A classification of subtypes was prepared using clinical features and the results of ancillary diagnostic studies. ""Possible"" and ""probable"" diagnoses can be made based on the physician's certainty of diagnosis. The usefulness and interrater agreement of the classification were tested by two neurologists who had not participated in the writing of the criteria. The neurologists independently used the TOAST classification system in their bedside evaluation of 20 patients, first based only on clinical features and then after reviewing the results of diagnostic tests. The TOAST classification denotes five subtypes of ischemic stroke: 1) large-artery atherosclerosis, 2) cardioembolism, 3) small-vessel occlusion, 4) stroke of other determined etiology, and 5) stroke of undetermined etiology. Using this rating system, interphysician agreement was very high. The two physicians disagreed in only one patient. They were both able to reach a specific etiologic diagnosis in 11 patients, whereas the cause of stroke was not determined in nine. The TOAST stroke subtype classification system is easy to use and has good interobserver agreement. This system should allow investigators to report responses to treatment among important subgroups of patients with ischemic stroke. Clinical trials testing treatments for acute ischemic stroke should include similar methods to diagnose subtypes of stroke.","['Medicine', 'Etiology', 'Stroke (engine)', 'Acute stroke', 'Clinical trial', 'Internal medicine', 'Medical diagnosis', 'Physical therapy', 'Pediatrics', 'Pathology', 'Tissue plasminogen activator', 'Mechanical engineering', 'Engineering']","et, ischemic stroke, the, acute stroke, is, ##mic stroke, ischemic stroke, etiology, acute stroke treatment, interrater agreement, toast classification system, toast classification, ##ian agreement, toast stroke, ##ver, acute, [PAD]"
Paper_01175,Researching Lived Experience: Human Science for an Action Sensitive Pedagogy,['Max van Manen'],1990,['Phenomenology + Pedagogy'],Unknown,,361-366,,,10.29173/pandp15124,"Preface Preface to the 2nd Edition 1. Human Science Introduction Why Do Human Science Research? What Is a Hermeneutic Phenomenological Human Science? What Does it Mean to Be Rational? What a Human Science Cannot Do Description or Interpretation? Research-Procedures, Techniques, and Methods Methodical Structure of Human Science Research 2. Turning to the Nature of Lived Experience The Nature of Lived Experience Orienting to the Phenomenon Formulating the Phenomenological Question Explicating Assumptions and Pre-understandings 3. Investigating Experience as We Live It The Nature of Data (datum: thing given or granted) Using Personal Experience as a Starting Point Tracing Etymologjcal Sources Searching Idiomatic Phrases Obtaining Experiential Descriptions from Others Protocol Writing (lived-experience descriptions) Interviewing (the personal life story) Observing (the experiential anecdote) Experiential Descriptions in Literature Biography as a Resource for Experiential Material Diaries, Journals, and Logs as Sources of Lived Experiences Art as a Source of Lived Experience Consulting Phenomenological Literature 4. Hermeneutic Phenomenological Rel1ectlon Conducting Thematic Analysis Situations Seeking Meaning What Is a Theme? The Pedagogy of Theme Uncovering Thematic Aspects Isolating Thematic Statements Composing Linguistic Transformations Gleaning Thematic Descriptions from Artistic Sources Interpretation through Conversation Collaborative Analysis: The Research Seminar/Group Lifeworld Existentials as Guides to Reflection Determining Incidental and Essential Themes 5. Hermeneutic Phenomenological Writing Attending to the Speaking of Language Silence-the Limits and Power of Language Anecdote as a Methodological Device The Value of Anecdotal Narrative Varying the Examples Writing Mediates Reflection and Action To Write is to Measure Our Thoughtfulness Writing Exercises the Ability to See The Write is to Show Something To Write is to Rewrite 6. Maintaining a Strong and Oriented Relation The Relation Between Research/Writing and Pedagogy On the Ineffability of Pedagogy Seeing Pedagogy The Pedagogic Practice of Textuality Human Science as Critically Oriented Action Research Action Sensitive Knowledge Leads to Pedagogic Competence 7. Balancing the Research Context by Considering Parts and Whole The Research Proposal Effects and Ethics of Human Science Research Plan and Context of a Research Project Working the Text Glossary Bibliography Index","['Experiential learning', 'Anecdote', 'Interpretation (philosophy)', 'Psychology', 'Theme (computing)', 'Narrative', 'Epistemology', 'Pedagogy', 'Linguistics', 'Literature', 'Art', 'Philosophy', 'Computer science', 'Operating system']","human science, her, ##eutic ph, human, personal experience, idiomatic phrases, experiential anecdote, exper, ##ial, textual"
Paper_01176,A tutorial on particle filters for online nonlinear/non-Gaussian Bayesian tracking,"['M.S. Arulampalam', 'Simon Maskell', 'Neil Gordon', 'Tim C Clapp']",2002,IEEE Transactions on Signal Processing,Journal,,174-188,50,2,10.1109/78.978374,"Increasingly, for many application areas, it is becoming important to include elements of nonlinearity and non-Gaussianity in order to model accurately the underlying dynamics of a physical system. Moreover, it is typically crucial to process data on-line as it arrives, both from the point of view of storage costs as well as for rapid adaptation to changing signal characteristics. In this paper, we review both optimal and suboptimal Bayesian algorithms for nonlinear/non-Gaussian tracking problems, with a focus on particle filters. Particle filters are sequential Monte Carlo methods based on point mass (or ""particle"") representations of probability densities, which can be applied to any state-space model and which generalize the traditional Kalman filtering methods. Several variants of the particle filter such as SIR, ASIR, and RPF are introduced within a generic framework of the sequential importance sampling (SIS) algorithm. These are discussed and compared with the standard EKF through an illustrative example.","['Particle filter', 'Computer science', 'Nonlinear system', 'Extended Kalman filter', 'Kalman filter', 'Algorithm', 'Gaussian process', 'Bayesian probability', 'Gaussian', 'State-space representation', 'Importance sampling', 'Monte Carlo method', 'Focus (optics)', 'State space', 'Auxiliary particle filter', 'Tracking (education)', 'Ensemble Kalman filter', 'Mathematical optimization', 'Artificial intelligence', 'Mathematics', 'Statistics', 'Physics', 'Psychology', 'Pedagogy', 'Quantum mechanics', 'Optics']","nonlinearity, non - gaussianity, storage costs, ##optimal bayesian algorithms, particle filters, particle filters, sequential monte carlo methods, point mass, probability densities, kalman filtering methods, particle filter, sir, asir, rpf, sequential importance sampling, sis, ek, [PAD] [PAD] [PAD], [PAD], [PAD] [PAD], [PAD], [PAD] [PAD], [PAD] [PAD], [PAD], [PAD], [PAD], [PAD], [PAD] [PAD], [PAD] [PAD] [PAD] [PAD], [PAD], [PAD], [PAD], [PAD] [PAD] [PAD], [PAD], [PAD]"
Paper_01178,A training algorithm for optimal margin classifiers,"['Bernhard E. Boser', 'Isabelle Guyon', 'Vladimir Vapnik']",1992,Unknown,Unknown,,144-152,,,10.1145/130385.130401,"A training algorithm that maximizes the margin between the training patterns and the decision boundary is presented. The technique is applicable to a wide variety of the classification functions, including Perceptrons, polynomials, and Radial Basis Functions. The effective number of parameters is adjusted automatically to match the complexity of the problem. The solution is expressed as a linear combination of supporting patterns. These are the subset of training patterns that are closest to the decision boundary. Bounds on the generalization performance based on the leave-one-out method and the VC-dimension are given. Experimental results on optical character recognition problems demonstrate the good generalization obtained when compared with other learning algorithms.","['Margin (machine learning)', 'Decision boundary', 'Generalization', 'Perceptron', 'Computer science', 'Algorithm', 'Dimension (graph theory)', 'Artificial intelligence', 'Boundary (topology)', 'Variety (cybernetics)', 'Pattern recognition (psychology)', 'Machine learning', 'Mathematics', 'Artificial neural network', 'Support vector machine', 'Mathematical analysis', 'Pure mathematics']","training algorithm, decision boundary, classification functions, perceptrons, polynomials, radial basis functions, decision, ##ization performance, optical character recognition problems"
Paper_01180,Use of Chemotherapy plus a Monoclonal Antibody against HER2 for Metastatic Breast Cancer That Overexpresses HER2,"['Dennis J. Slamon', 'Brian Leyland‐Jones', 'Steven Shak', 'H. Fuchs', 'Virginia Paton', 'Alex Bajamonde', 'Thomas Fleming', 'W. Eiermann', 'Janet Wolter', 'Mark D. Pegram', 'José Baselga', 'Larry Norton']",2001,New England Journal of Medicine,Journal,,783-792,344,11,10.1056/nejm200103153441101,"The HER2 gene, which encodes the growth factor receptor HER2, is amplified and HER2 is overexpressed in 25 to 30 percent of breast cancers, increasing the aggressiveness of the tumor.","['Medicine', 'Trastuzumab', 'Epirubicin', 'Anthracycline', 'Internal medicine', 'Breast cancer', 'Oncology', 'Cyclophosphamide', 'Chemotherapy', 'Doxorubicin', 'Metastatic breast cancer', 'Paclitaxel', 'Cancer', 'Gastroenterology']","her, growth factor receptor her, her, breast, [PAD], [PAD], [PAD]"
Paper_01181,In silico prediction of protein-protein interactions in human macrophages,"['Oussema Souiai', 'Fatma Z. Guerfali', 'Slimane Ben Miled', 'Christine Brun', 'Alia Benkahla']",2014,BMC Research Notes,Journal,,157-157,7,1,10.1186/1756-0500-7-157,"Protein-protein interaction (PPI) network analyses are highly valuable in deciphering and understanding the intricate organisation of cellular functions. Nevertheless, the majority of available protein-protein interaction networks are context-less, i.e. without any reference to the spatial, temporal or physiological conditions in which the interactions may occur. In this work, we are proposing a protocol to infer the most likely protein-protein interaction (PPI) network in human macrophages.We integrated the PPI dataset from the Agile Protein Interaction DataAnalyzer (APID) with different meta-data to infer a contextualized macrophage-specific interactome using a combination of statistical methods. The obtained interactome is enriched in experimentally verified interactions and in proteins involved in macrophage-related biological processes (i.e. immune response activation, regulation of apoptosis). As a case study, we used the contextualized interactome to highlight the cellular processes induced upon Mycobacterium tuberculosis infection.Our work confirms that contextualizing interactomes improves the biological significance of bioinformatic analyses. More specifically, studying such inferred network rather than focusing at the gene expression level only, is informative on the processes involved in the host response. Indeed, important immune features such as apoptosis are solely highlighted when the spotlight is on the protein interaction level.","['Interactome', 'In silico', 'Protein–protein interaction', 'Computational biology', 'Interaction network', 'Context (archaeology)', 'Protein Interaction Networks', 'Biology', 'Proteomics', 'Bioinformatics', 'Computer science', 'Gene', 'Genetics', 'Paleontology']","cellular functions, human, agile protein interaction dataanalyzer, statistical, immune response activation, apoptosis, mycobacter, ##informatic analyses, apoptosis"
Paper_01183,Caffe,"['Yangqing Jia', 'Evan Shelhamer', 'Jeff Donahue', 'Sergey Karayev', 'Jonathan Long', 'Ross Girshick', 'Sergio Guadarrama', 'Trevor Darrell']",2014,Unknown,Unknown,,,,,10.1145/2647868.2654889,"Caffe provides multimedia scientists and practitioners with a clean and modifiable framework for state-of-the-art deep learning algorithms and a collection of reference models. The framework is a BSD-licensed C++ library with Python and MATLAB bindings for training and deploying general-purpose convolutional neural networks and other deep models efficiently on commodity architectures. Caffe fits industry and internet-scale media needs by CUDA GPU computation, processing over 40 million images a day on a single K40 or Titan GPU (approx 2 ms per image). By separating model representation from actual implementation, Caffe allows experimentation and seamless switching among platforms for ease of development and deployment from prototyping machines to cloud environments.","['Computer science', 'Deep learning', 'Python (programming language)', 'CUDA', 'Artificial intelligence', 'Titan (rocket family)', 'Convolutional neural network', 'Software deployment', 'Cloud computing', 'Artificial neural network', 'MATLAB', 'Computer architecture', 'Software engineering', 'Parallel computing', 'Operating system', 'Engineering', 'Aerospace engineering']","caffe, multimedia, deep learning algorithms, reference models, ##lab, commodity architectures, caffe, cuda gpu computation, titan gpu, caffe, cloud environments"
Paper_01184,Statistical Methods for Research Workers,['Ronald Aylmer Fisher'],1945,American Journal of Clinical Pathology,Journal,,552.3-552,15,11,10.1093/ajcp/15.11.552b,"The prime object of this book is to put into the hands of research workers, and especially of biologists, the means of applying statistical tests accurately to numerical data accumulated in their own laboratories or available in the literature.","['Statistical analysis', 'Prime (order theory)', 'Object (grammar)', 'Computer science', 'Data science', 'Statistics', 'Mathematics', 'Artificial intelligence', 'Combinatorics']","biologist, statistical tests, numerical data"
Paper_01185,Qualitative inquiry & research design : choosing among five approaches,['John W. Creswell'],2013,['Health Promotion Practice'],Unknown,,473-475,16,4,10.1177/1524839915580941,Chapter 1. Introduction Chapter 2. Philosophical Assumptions and Interpretive Frameworks Chapter 3. Designing a Qualitative Study Chapter 4. Five Qualitative Approaches to Inquiry Chapter 5. Five Different Qualitative Studies Chapter 6. Introducing and Focusing the Study Chapter 7. Data Collection Chapter 8. Data Analysis and Representation Chapter 9. Writing a Qualitative Study Chapter 10. Standards of Validation and Reliability in Qualitative Research Chapter 11. Turning the Story and Conclusion Appendix A. An Annotated Glossary of Terms Appendix B. A Narrative Research Study Appendix C. A Phenomenological Study Appendix D. A Grounded Theory Study Appendix E. An Ethnography Appendix F. A Case Study,"['Glossary', 'Qualitative research', 'Narrative', 'Representation (politics)', 'Management science', 'Epistemology', 'Mathematics education', 'Computer science', 'Psychology', 'Sociology', 'Linguistics', 'Social science', 'Engineering', 'Philosophy', 'Political science', 'Politics', 'Law']","philosophical assumptions, interpretive frameworks, qualitative study, qualitative approaches, inquiry, qualitative studies, data collection, data analysis, representation, qualitative study, validation, reliability, qualitative research, ##ted glossary, narrative research study, phenomenological study, grounded theory study, ethnography, case study"
Paper_01186,Mean shift: a robust approach toward feature space analysis,"['Dorin Comaniciu', 'Peter Meer']",2002,IEEE Transactions on Pattern Analysis and Machine Intelligence,Journal,,603-619,24,5,10.1109/34.1000236,"A general non-parametric technique is proposed for the analysis of a complex multimodal feature space and to delineate arbitrarily shaped clusters in it. The basic computational module of the technique is an old pattern recognition procedure: the mean shift. For discrete data, we prove the convergence of a recursive mean shift procedure to the nearest stationary point of the underlying density function and, thus, its utility in detecting the modes of the density. The relation of the mean shift procedure to the Nadaraya-Watson estimator from kernel regression and the robust M-estimators; of location is also established. Algorithms for two low-level vision tasks discontinuity-preserving smoothing and image segmentation - are described as applications. In these algorithms, the only user-set parameter is the resolution of the analysis, and either gray-level or color images are accepted as input. Extensive experimental results illustrate their excellent performance.","['Mean-shift', 'Estimator', 'Smoothing', 'Pattern recognition (psychology)', 'Artificial intelligence', 'Density estimation', 'Mathematics', 'Kernel density estimation', 'Computer science', 'Algorithm', 'Feature vector', 'Kernel (algebra)', 'Feature (linguistics)', 'Computer vision', 'Statistics', 'Linguistics', 'Philosophy', 'Combinatorics']","- parametric, complex multimodal feature space, ##ily, pattern recognition procedure, mean shift, discrete data, recursive mean shift procedure, underlying, mean shift procedure, kernel regression, image segmentation"
Paper_01187,"Semiconductor Clusters, Nanocrystals, and Quantum Dots",['A. Paul Alivisatos'],1996,Science,Journal,,933-937,271,5251,10.1126/science.271.5251.933,Current research into semiconductor clusters is focused on the properties of quantum dots—fragments of semiconductor consisting of hundreds to many thousands of atoms—with the bulk bonding geometry and with surface states eliminated by enclosure in a material that has a larger band gap. Quantum dots exhibit strongly size-dependent optical and electrical properties. The ability to join the dots into complex assemblies creates many opportunities for scientific discovery.,"['Quantum dot', 'Semiconductor', 'Nanocrystal', 'Materials science', 'Band gap', 'Nanotechnology', 'Optoelectronics']","semiconductor clusters, quantum dots, fragments, bulk bonding geometry, surface states, band gap, quantum, [PAD] [PAD], [PAD] [PAD], [PAD], [PAD], [PAD] [PAD]"
Paper_01188,Updated world map of the Köppen-Geiger climate classification,"['Murray C. Peel', 'Brian Finlayson', 'Thomas A. McMahon']",2007,Hydrology and earth system sciences,Journal,,1633-1644,11,5,10.5194/hess-11-1633-2007,"Abstract. Although now over 100 years old, the classification of climate originally formulated by Wladimir Köppen and modified by his collaborators and successors, is still in widespread use. It is widely used in teaching school and undergraduate courses on climate. It is also still in regular use by researchers across a range of disciplines as a basis for climatic regionalisation of variables and for assessing the output of global climate models. Here we have produced a new global map of climate using the Köppen-Geiger system based on a large global data set of long-term monthly precipitation and temperature station time series. Climatic variables used in the Köppen-Geiger system were calculated at each station and interpolated between stations using a two-dimensional (latitude and longitude) thin-plate spline with tension onto a 0.1°×0.1° grid for each continent. We discuss some problems in dealing with sites that are not uniquely classified into one climate type by the Köppen-Geiger system and assess the outcomes on a continent by continent basis. Globally the most common climate type by land area is BWh (14.2%, Hot desert) followed by Aw (11.5%, Tropical savannah). The updated world Köppen-Geiger climate map is freely available electronically in the Supplementary Material Section.","['Geiger counter', 'Climatology', 'Latitude', 'Climate change', 'Environmental science', 'Geography', 'Longitude', 'Precipitation', 'Meteorology', 'Geology', 'Geodesy', 'Oceanography', 'Physics', 'Optics']","global climate models, temperature station time series, hot desert, tropical savannah"
Paper_01191,Prevention of Type 2 Diabetes Mellitus by Changes in Lifestyle among Subjects with Impaired Glucose Tolerance,"['Jaakko Tuomilehto', 'Jaana Lindström', 'Johan G. Eriksson', 'Timo T. Valle', 'Helena Hämäläinen', 'Pirjo Ilanne‐Parikka', 'Sirkka Keinänen‐Kiukaanniemi', 'Mauri Laakso', 'Anne Louheranta', 'Merja Rastas', 'Virpi Salminen', 'Sirkka Aunola', 'Žygimantas Čepaitis', 'Vladislav Moltchanov', 'M. O. K. Hakumäki', 'Marjo Mannelin', 'V. Martikkala', 'Jouko Sundvall', 'Matti Uusitupa']",2001,New England Journal of Medicine,Journal,,1343-1350,344,18,10.1056/nejm200105033441801,"Type 2 diabetes mellitus is increasingly common, primarily because of increases in the prevalence of a sedentary lifestyle and obesity. Whether type 2 diabetes can be prevented by interventions that affect the lifestyles of subjects at high risk for the disease is not known.","['Medicine', 'Overweight', 'Diabetes mellitus', 'Impaired glucose tolerance', 'Body mass index', 'Confidence interval', 'Obesity', 'Type 2 diabetes', 'Weight loss', 'Internal medicine', 'Incidence (geometry)', 'Type 2 Diabetes Mellitus', 'Physical therapy', 'Endocrinology', 'Physics', 'Optics']","sedentary lifestyle, [PAD] [PAD], [PAD]"
Paper_01192,Tissue Plasminogen Activator for Acute Ischemic Stroke,['The National Institute of Neurological Disorders and Stroke rt-PA Stroke Study Group'],1995,New England Journal of Medicine,Journal,,1581-1588,333,24,10.1056/nejm199512143332401,"Thrombolytic therapy for acute ischemic stroke has been approached cautiously because there were high rates of intracerebral hemorrhage in early clinical trials. We performed a randomized, double-blind trial of intravenous recombinant tissue plasminogen activator (t-PA) for ischemic stroke after recent pilot studies suggested that t-PA was beneficial when treatment was begun within three hours of the onset of stroke.","['Medicine', 'Tissue plasminogen activator', 'Recombinant tissue plasminogen activator', 'Intracerebral hemorrhage', 'Stroke (engine)', 'Ischemic stroke', 'Clinical trial', 'Randomized controlled trial', 'T-plasminogen activator', 'Brain ischemia', 'Internal medicine', 'Acute stroke', 'Fibrinolytic agent', 'Ischemia', 'Cardiology', 'Surgery', 'Subarachnoid hemorrhage', 'Modified Rankin Scale', 'Mechanical engineering', 'Engineering']","thrombolytic therapy, acute ischemic stroke, intracerebral hemorrhage, intra, ##ous rec, ische, [PAD], [PAD]"
Paper_01193,Estimation and Hypothesis Testing of Cointegration Vectors in Gaussian Vector Autoregressive Models,['Søren Johansen'],1991,Econometrica,Journal,,1551-1551,59,6,10.2307/2938278,"This paper contains the likelihood analysis of vector autoregressive models allowing for cointegration. The author derives the likelihood ratio test for cointegrating rank and finds it asymptotic distribution. He shows that the maximum likelihood estimator of the cointegrating relations can be found by reduced rank regression and derives the likelihood ratio test of structural hypotheses about these relations. The author shows that the asymptotic distribution of the maximum likelihood estimator is mixed Gaussian, allowing inference for hypotheses on the cointegrating relation to be conducted using the Chi( squared) distribution. Copyright 1991 by The Econometric Society.","['Cointegration', 'Autoregressive model', 'Econometrics', 'Gaussian', 'Statistical hypothesis testing', 'Mathematics', 'STAR model', 'Applied mathematics', 'Economics', 'Statistics', 'Autoregressive integrated moving average', 'Time series', 'Physics', 'Quantum mechanics']","likelihood analysis, vector autoregressive models, cointegration, likelihood ratio test, cointegrating rank, asymptotic distribution, maximum likelihood estimator, cointegrating relations, reduced rank regression, likelihood ratio test, structural hypotheses, asymptotic distribution, maximum likelihood estimator, mixed gaussian, cointegrating relation, econometric society"
Paper_01194,The Economic Institutions of Capitalism,['Paolo Leon'],1986,The Antitrust Bulletin,Journal,,827-834,31,3,10.1177/0003603x8603100308,"The 2008 crash has left all the established economic doctrines - equilibrium models, real business cycles, disequilibria models - in disarray. Part of the problem is due to Smith’s veil of ignorance: individuals unknowingly pursue society’s interest and, as a result, have no clue as to the macroeconomic effects of their actions: witness the Keynes and Leontief multipliers, the concept of value added, fiat money, Engel’s law and technical progress, to name but a few of the macrofoundations of microeconomics. A good viewpoint to take bearings anew lies in comparing the post-Great Depression institutions with those emerging from Thatcher and Reagan’s economic policies: deregulation, exogenous vs. endoge- nous money, shadow banking vs. Volcker’s Rule. Very simply, the banks, whose lending determined deposits after Roosevelt, and were a public service became private enterprises whose deposits determine lending. These underlay the great moderation preceding 2006, and the subsequent crash.","['Capitalism', 'Institutional economics', 'Market economy', 'Economics', 'Business', 'Economic system', 'Political science', 'Neoclassical economics', 'Politics', 'Law']","equilibrium models, real business cycles, disequilibria models, macro, ##f, value added, fiat money, micro, deregulation, shadow banking, banks, private enterprises, [PAD], [PAD], [PAD] [PAD], [PAD]"
Paper_01195,Making sense of Cronbach's alpha,"['Mohsen Tavakol', 'Reg Dennick']",2011,International Journal of Medical Education,Journal,,53-55,2,,10.5116/ijme.4dfb.8dfd,"Medical educators attempt to create reliable and valid tests and questionnaires in order to enhance the accuracy of their assessment and evaluations. Validity and reliability are two fundamental elements in the evaluation of a measurement instrument. Instruments can be conventional knowledge, skill or attitude tests, clinical simulations or survey questionnaires. Instruments can measure concepts, psychomotor skills or affective values. Validity is concerned with the extent to which an instrument measures what it is intended to measure. Reliability is concerned with the ability of an instrument to measure consistently.1 It should be noted that the reliability of an instrument is closely associated with its validity. An instrument cannot be valid unless it is reliable. However, the reliability of an instrument does not depend on its validity.2 It is possible to objectively measure the reliability of an instrument and in this paper we explain the meaning of Cronbach’s alpha, the most widely used objective measure of reliability.

Calculating alpha has become common practice in medical education research when multiple-item measures of a concept or construct are employed. This is because it is easier to use in comparison to other estimates (e.g. test-retest reliability estimates)3 as it only requires one test administration. However, in spite of the widespread use of alpha in the literature the meaning, proper use and interpretation of alpha is not clearly understood. 2, 4, 5 We feel it is important, therefore, to further explain the underlying assumptions behind alpha in order to promote its more effective use. It should be emphasised that the purpose of this brief overview is just to focus on Cronbach’s alpha as an index of reliability. Alternative methods of measuring reliability based on other psychometric methods, such as generalisability theory or item-response theory, can be used for monitoring and improving the quality of OSCE examinations 6-10, but will not be discussed here.

What is Cronbach alpha?
Alpha was developed by Lee Cronbach in 195111 to provide a measure of the internal consistency of a test or scale; it is expressed as a number between 0 and 1. Internal consistency describes the extent to which all the items in a test measure the same concept or construct and hence it is connected to the inter-relatedness of the items within the test. Internal consistency should be determined before a test can be employed for research or examination purposes to ensure validity. In addition, reliability estimates show the amount of measurement error in a test. Put simply, this interpretation of reliability is the correlation of test with itself. Squaring this correlation and subtracting from 1.00 produces the index of measurement error. For example, if a test has a reliability of 0.80, there is 0.36 error variance (random error) in the scores (0.80×0.80 = 0.64; 1.00 – 0.64 = 0.36).12 As the estimate of reliability increases, the fraction of a test score that is attributable to error will decrease.2 It is of note that the reliability of a test reveals the effect of measurement error on the observed score of a student cohort rather than on an individual student. To calculate the effect of measurement error on the observed score of an individual student, the standard error of measurement must be calculated (SEM).13

If the items in a test are correlated to each other, the value of alpha is increased. However, a high coefficient alpha does not always mean a high degree of internal consistency. This is because alpha is also affected by the length of the test. If the test length is too short, the value of alpha is reduced.2, 14 Thus, to increase alpha, more related items testing the same concept should be added to the test. It is also important to note that alpha is a property of the scores on a test from a specific sample of testees. Therefore investigators should not rely on published alpha estimates and should measure alpha each time the test is administered.14


Use of Cronbach’s alpha
Improper use of alpha can lead to situations in which either a test or scale is wrongly discarded or the test is criticised for not generating trustworthy results. To avoid this situation an understanding of the associated concepts of internal consistency, homogeneity or unidimensionality can help to improve the use of alpha. Internal consistency is concerned with the interrelatedness of a sample of test items, whereas homogeneity refers to unidimensionality. A measure is said to be unidimensional if its items measure a single latent trait or construct. Internal consistency is a necessary but not sufficient condition for measuring homogeneity or unidimensionality in a sample of test items. 5, 15 Fundamentally, the concept of reliability assumes that unidimensionality exists in a sample of test items16 and if this assumption is violated it does cause a major underestimate of reliability. It has been well documented that a multidimensional test does not necessary have a lower alpha than a unidimensional test. Thus a more rigorous view of alpha is that it cannot simply be interpreted as an index for the internal consistency of a test. 5, 15, 17

Factor Analysis can be used to identify the dimensions of a test.18 Other reliable techniques have been used and we encourage the reader to consult the paper “Applied Dimensionality and Test Structure Assessment with the START-M Mathematics Test” and to compare methods for assessing the dimensionality and underlying structure of a test.19

Alpha, therefore, does not simply measure the unidimensionality of a set of items, but can be used to confirm whether or not a sample of items is actually unidimensional.5 On the other hand if a test has more than one concept or construct, it may not make sense to report alpha for the test as a whole as the larger number of questions will inevitable inflate the value of alpha. In principle therefore, alpha should be calculated for each of the concepts rather than for the entire test or scale. 2, 3 The implication for a summative examination containing heterogeneous, case-based questions is that alpha should be calculated for each case.

More importantly, alpha is grounded in the ‘tau equivalent model’ which assumes that each test item measures the same latent trait on the same scale. Therefore, if multiple factors/traits underlie the items on a scale, as revealed by Factor Analysis, this assumption is violated and alpha underestimates the reliability of the test.17 If the number of test items is too small it will also violate the assumption of tau-equivalence and will underestimate reliability.20 When test items meet the assumptions of the tau-equivalent model, alpha approaches a better estimate of reliability. In practice, Cronbach’s alpha is a lower-bound estimate of reliability because heterogeneous test items would violate the assumptions of the tau-equivalent model.5 If the calculation of “standardised item alpha” in SPSS is higher than “Cronbach’s alpha”, a further examination of the tau-equivalent measurement in the data may be essential.


Numerical values of alpha
As pointed out earlier, the number of test items, item inter-relatedness and dimensionality affect the value of alpha.5 There are different reports about the acceptable values of alpha, ranging from 0.70 to 0.95. 2, 21, 22 A low value of alpha could be due to a low number of questions, poor inter-relatedness between items or heterogeneous constructs. For example if a low alpha is due to poor correlation between items then some should be revised or discarded. The easiest method to find them is to compute the correlation of each test item with the total score test; items with low correlations (approaching zero) are deleted. If alpha is too high it may suggest that some items are redundant as they are testing the same question but in a different guise. A maximum alpha value of 0.90 has been recommended.14


Summary
High quality tests are important to evaluate the reliability of data supplied in an examination or a research study. Alpha is a commonly employed index of test reliability. Alpha is affected by the test length and dimensionality. Alpha as an index of reliability should follow the assumptions of the essentially tau-equivalent approach. A low alpha appears if these assumptions are not meet. Alpha does not simply measure test homogeneity or unidimensionality as test reliability is a function of test length. A longer test increases the reliability of a test regardless of whether the test is homogenous or not. A high value of alpha (> 0.90) may suggest redundancies and show that the test length should be shortened.","[""Cronbach's alpha"", 'Reliability (semiconductor)', 'Psychology', 'Measure (data warehouse)', 'Meaning (existential)', 'Test (biology)', 'Construct validity', 'Validity', 'Psychometrics', 'Social psychology', 'Applied psychology', 'Computer science', 'Clinical psychology', 'Data mining', 'Psychotherapist', 'Paleontology', 'Power (physics)', 'Physics', 'Quantum mechanics', 'Biology']","medical educators, valid tests, questionnaires, validity, reliability, skill, attitude tests, clinical simulations, survey questionnaires, psychomotor skills, affective values, validity, reliability, alpha, medical education, alpha, reliability, psychometric, generalisability theory, alpha, internal consistency, internal consistency, internal consistency, reliability, measurement"
Paper_01196,Gaussian Processes for Machine Learning,"['Carl Edward Rasmussen', 'Christopher K. I. Williams']",2005,Unknown,Unknown,,,,,10.7551/mitpress/3206.001.0001,"A comprehensive and self-contained introduction to Gaussian processes, which provide a principled, practical, probabilistic approach to learning in kernel machines. Gaussian processes (GPs) provide a principled, practical, probabilistic approach to learning in kernel machines. GPs have received increased attention in the machine-learning community over the past decade, and this book provides a long-needed systematic and unified treatment of theoretical and practical aspects of GPs in machine learning. The treatment is comprehensive and self-contained, targeted at researchers and students in machine learning and applied statistics. The book deals with the supervised-learning problem for both regression and classification, and includes detailed algorithms. A wide variety of covariance (kernel) functions are presented and their properties discussed. Model selection is discussed both from a Bayesian and a classical perspective. Many connections to other well-known techniques from machine learning and statistics are discussed, including support-vector machines, neural networks, splines, regularization networks, relevance vector machines and others. Theoretical issues including learning curves and the PAC-Bayesian framework are treated, and several approximation methods for learning with large datasets are discussed. The book contains illustrative examples and exercises, and code and datasets are available on the Web. Appendixes provide mathematical background and a discussion of Gaussian Markov processes.","['Machine learning', 'Artificial intelligence', 'Computer science', 'Online machine learning', 'Gaussian process', 'Probabilistic logic', 'Relevance vector machine', 'Support vector machine', 'Kernel method', 'Artificial neural network', 'Gaussian', 'Physics', 'Quantum mechanics']","gaussian processes, kernel machines, gaussian processes, gps, kernel machines, machine learning, machine learning, applied statistics, covariance, model selection, machine learning, statistics, neural networks, splines, regularization networks, relevance vector machines, learning curves, approximation methods, gaussian markov processes"
Paper_01197,16S ribosomal DNA amplification for phylogenetic study,"['W G Weisburg', 'Susan M. Barns', 'Dale A. Pelletier', 'David Lane']",1991,Journal of Bacteriology,Journal,,697-703,173,2,10.1128/jb.173.2.697-703.1991,"A set of oligonucleotide primers capable of initiating enzymatic amplification (polymerase chain reaction) on a phylogenetically and taxonomically wide range of bacteria is described along with methods for their use and examples. One pair of primers is capable of amplifying nearly full-length 16S ribosomal DNA (rDNA) from many bacterial genera; the additional primers are useful for various exceptional sequences. Methods for purification of amplified material, direct sequencing, cloning, sequencing, and transcription are outlined. An obligate intracellular parasite of bovine erythrocytes, Anaplasma marginale, is used as an example; its 16S rDNA was amplified, cloned, sequenced, and phylogenetically placed. Anaplasmas are related to the genera Rickettsia and Ehrlichia. In addition, 16S rDNAs from several species were readily amplified from material found in lyophilized ampoules from the American Type Culture Collection. By use of this method, the phylogenetic study of extremely fastidious or highly pathogenic bacterial species can be carried out without the need to culture them. In theory, any gene segment for which polymerase chain reaction primer design is possible can be derived from a readily obtainable lyophilized bacterial culture.","['Biology', 'Ribosomal DNA', '16S ribosomal RNA', 'Polymerase chain reaction', 'Phylogenetic tree', 'Genetics', 'Primer (cosmetics)', 'Thermus aquaticus', 'Anaplasma', 'Ribosomal RNA', 'DNA', 'Molecular biology', 'Gene', 'Virology', 'Chemistry', 'Organic chemistry', 'Tick']","oligonucleotide primers, enzymatic amplification, polymerase chain reaction, ##liga, bovine erythrocytes, anaplasma, ##plasmas, rickettsia, ehrlichia, american type culture collection"
Paper_01199,5. The Practice of Everyday Life,['Michel de Certeau'],2000,University of California Press eBooks,Unknown,,109-130,,,10.1525/9780520923478-008,Preface General Introduction PART I: A VERY ORDINARY CULTURE I. A Common Place: Ordinary Language II. Popular Cultures: Ordinary Language III. Making Do: Uses and Tactics PART II: THEORIES OF THE ART OF PRACTICE IV. Foucault and Bourdieu V. The Arts of Theory VI. Story Time PART III: SPATIAL PRACTICES VII. Walking in the City VIII. Railway Navigation and Incarceration IX. Spatial Stories PART IV: Uses of Language X. The Scriptural Economy XI. Quotations of Voices XII. Reading as Poaching PART V: WAYS OF BELIEVING XIII. Believing and Making People Believe XIV. The Unnamable Indeterminate Notes,"['Everyday life', 'Psychology', 'Epistemology', 'Philosophy']","popular cultures, story time, spatial practices, railway navigation, incarceration, spatial stories, scriptural economy, quotations, unnamable indeterminate notes"
Paper_01201,Advances in Neural Information Processing Systems 19,[],2007,The MIT Press eBooks,Unknown,,,,,10.7551/mitpress/7503.001.0001,"Papers from the 2006 flagship meeting on neural computation, with contributions from physicists, neuroscientists, mathematicians, statisticians, and computer scientists. The annual Neural Information Processing Systems (NIPS) conference is the flagship meeting on neural computation and machine learning. It draws a diverse group of attendees—physicists, neuroscientists, mathematicians, statisticians, and computer scientists—interested in theoretical and applied aspects of modeling, simulating, and building neural-like or intelligent systems. The presentations are interdisciplinary, with contributions in algorithms, learning theory, cognitive science, neuroscience, brain imaging, vision, speech and signal processing, reinforcement learning, and applications. Only twenty-five percent of the papers submitted are accepted for presentation at NIPS, so the quality is exceptionally high. This volume contains the papers presented at the December 2006 meeting, held in Vancouver. Bradford Books imprint","['Presentation (obstetrics)', 'Computer science', 'Artificial intelligence', 'Artificial neural network', 'Neural system', 'Information processing', 'Computation', 'Cognitive science', 'Computational neuroscience', 'Data science', 'Psychology', 'Neuroscience', 'Medicine', 'Algorithm', 'Radiology']","neural computation, ##scient, stat, computer, neural information processing systems, ##ps, neural computation, machine learning, learning theory, cognitive science, neuroscience, brain imaging, vision, signal processing, reinforcement learning"
Paper_01204,An Introduction to Genetic Algorithms,['Melanie Mitchell'],1996,Unknown,Unknown,,,,,10.7551/mitpress/3927.001.0001,"Genetic algorithms have been used in science and engineering as adaptive algorithms for solving practical problems and as computational models of natural evolutionary systems. This brief, accessible introduction describes some of the most interesting research in the field and also enables readers to implement and experiment with genetic algorithms on their own. It focuses in depth on a small set of important and interesting topics—particularly in machine learning, scientific modeling, and artificial life—and reviews a broad span of research, including the work of Mitchell and her colleagues. The descriptions of applications and modeling projects stretch beyond the strict boundaries of computer science to include dynamical systems theory, game theory, molecular biology, ecology, evolutionary biology, and population genetics, underscoring the exciting ""general purpose"" nature of genetic algorithms as search methods that can be employed across disciplines. An Introduction to Genetic Algorithms is accessible to students and researchers in any scientific discipline. It includes many thought and computer exercises that build on and reinforce the reader's understanding of the text. The first chapter introduces genetic algorithms and their terminology and describes two provocative applications in detail. The second and third chapters look at the use of genetic algorithms in machine learning (computer programs, data analysis and prediction, neural networks) and in scientific models (interactions among learning, evolution, and culture; sexual selection; ecosystems; evolutionary activity). Several approaches to the theory of genetic algorithms are discussed in depth in the fourth chapter. The fifth chapter takes up implementation, and the last chapter poses some currently unanswered questions and surveys prospects for the future of evolutionary computation. Bradford Books imprint","['Computer science', 'Algorithm']","genetic algorithms, adaptive algorithms, computational models, natural evolutionary systems, genetic algorithms, machine learning, scientific modeling, artificial life —, dynamical systems theory, game theory, molecular biology, ecology, evolutionary biology, population genetics, genetic algorithms, genetic algorithms, genetic algorithms, genetic algorithms, machine learning, computer programs, data analysis, neural networks, scientific models, culture, sexual selection, ecosystems, evolutionary activity, genetic algorithms, evolutionary computation"
Paper_01207,"Exit, Voice and Loyalty: Responses to Decline in Firms, Organizations, and States.","['Gordon Tullock', 'Albert O. Hirschman']",1970,The Journal of Finance,Journal,,1194-1194,25,5,10.2307/2325604,"1. Introduction and Doctrinal Background Enter and Latitude for deterioration, and slack in economic thought Exit and voice as impersonations of economics and politics 2. Exit How the exit option works Competition as collusive behavior 3. Voice Voice as a residual of exit Voice as an alternative to exit 4. A Special Difficulty in Combining Exit and Voice 5. How Monopoly Can be Comforted by Competition 6. On Spatial Duopoly and the Dynamics of Two-Party Systems 7. A Theory of Loyalty The activation of voice as a function of loyalty Loyalist behavior as modified by severe initiation and high penalties for exit Loyalty and the difficult exit from public goods (and evils) 8. Exit and Voice in American Ideology and Practice 9. The Elusive Optimal Mix of Exit and Voice Appendixes A. A simple diagrammatic representation of voice and exit B. The choice between voice and exit C. The reversal phenomenon D. Consumer reactions to price rise and quality decline in the case of several connoisseur goods F. The effects of severity of initiation on activism: design for an experiment (in collaboration with Philip G. Zimbardo and Mark Snyder) Index","['Loyalty', 'Business', 'Marketing']","##trinal background, latitude, economic thought, voice, politics, exit, collusive behavior, voice voice, exit voice, spatial duopoly, loyalty, voice, loyalty loyalist behavior, exit, voice, american ideology, ##matic representation, reversal phenomenon, consumer reactions, price rise, quality decline, ##ur goods, activism, [PAD], [PAD], [PAD]"
Paper_01209,SWISS‐MODEL and the Swiss‐Pdb Viewer: An environment for comparative protein modeling,"['Nicolas Guex', 'Manuel C. Peitsch']",1997,Electrophoresis,Journal,,2714-2723,18,15,10.1002/elps.1150181505,"Comparative protein modeling is increasingly gaining interest since it is of great assistance during the rational design of mutagenesis experiments. The availability of this method, and the resulting models, has however been restricted by the availability of expensive computer hardware and software. To overcome these limitations, we have developed an environment for comparative protein modeling that consists of SWISS-MODEL, a server for automated comparative protein modeling and of the SWISS-PdbViewer, a sequence to structure workbench. The Swiss-PdbViewer not only acts as a client for SWISS-MODEL, but also provides a large selection of structure analysis and display tools. In addition, we provide the SWISS-MODEL Repository, a database containing more than 3500 automatically generated protein models. By making such tools freely available to the scientific community, we hope to increase the use of protein structures and models in the process of experiment design.","['Workbench', 'Computer science', 'Software', 'Process (computing)', 'Protein Data Bank (RCSB PDB)', 'Software engineering', 'CASP', 'Protein structure prediction', 'Data mining', 'Protein structure', 'Visualization', 'Operating system', 'Biology', 'Biochemistry']","comparative protein modeling, rational design, mutagenesis experiments, comparative protein modeling, automated comparative protein modeling, automatically, [PAD]"
Paper_01212,Atoms in Molecules,['Richard F. W. Bader'],1990,Oxford University Press eBooks,Unknown,,,,,10.1093/oso/9780198551683.001.0001,"Abstract The molecular structure hypothesis - that a molecule is a collection of atoms linked by a network of bonds - was forged in the crucible of nineteenth-century experimental chemistry and has continued to serve as the principal means of ordering and classifying the observations of chemistry. There is a difficulty with the hypothesis, however, in that it is not related directly to the physics which governs the motions of the nuclei and electrons that make up the atoms and the bonds. It is the purpose of this important new book to show that a theory can be developed to underpin the molecular structure hypothesis - that the atoms in a molecule are real, with properties predicted and defined by the laws of quantum mechanics, and that the structure their presence imparts to a molecule is indeed a consequence of the underlying physics. As a result the classification based upon the concept of atoms in molecules is freed from its empirical constraints and the full predictive power of quantum mechanics. As a result the full predictive power of quantum mechanics can be incorporated into the resulting theory - a theory of atoms in molecules. The book is aimed at those scientists responsible for performing the experiments and collecting the observations on the properties of matter at the atomic level, in the belief that the transformation of qualitative concepts into a quantitative theory will serve to deepen our understanding of chemistry.","['Atoms in molecules', 'Molecule', 'Theoretical physics', 'Physics', 'Quantum chemistry', 'Chemical physics', 'Quantum mechanics', 'Chemistry', 'Supramolecular chemistry']","molecular structure hypothesis, molecular structure hypothesis, quantum mechanics, predictive, quantum mechanics, predictive, quantum mechanics"
Paper_01213,The VideoToolbox software for visual psychophysics: transforming numbers into movies,['Denis G. Pelli'],1997,Spatial Vision,Journal,,437-442,10,4,10.1163/156856897x00366,"The VideoToolbox is a free collection of two hundred C subroutines for Macintosh computers that calibrates and controls the computer-display interface to create accurately specified visual stimuli. High-level platform-independent languages like MATLAB are best for creating the numbers that describe the desired images. Low-level, computer-specific VideoToolbox routines control the hardware that transforms those numbers into a movie. Transcending the particular computer and language, we discuss the nature of the computer-display interface, and how to calibrate and control it.","['Computer science', 'Interface (matter)', 'Subroutine', 'MATLAB', 'Software', 'Psychophysics', 'Computer graphics (images)', 'Human–computer interaction', 'Control (management)', 'Computer vision', 'Artificial intelligence', 'Computer hardware', 'Programming language', 'Psychology', 'Perception', 'Operating system', 'Neuroscience', 'Bubble', 'Maximum bubble pressure method']","videotoolbox, macintosh computers, matlab, ##tool"
Paper_01214,Two-dimensional atomic crystals,"['Kostya S. Novoselov', 'Da Jiang', 'F. Schedin', 'Timothy J. Booth', 'V. V. Khotkevich', 'С. В. Морозов', 'A. K. Geǐm']",2005,Proceedings of the National Academy of Sciences,Journal,,10451-10453,102,30,10.1073/pnas.0502848102,"We report free-standing atomic crystals that are strictly 2D and can be viewed as individual atomic planes pulled out of bulk crystals or as unrolled single-wall nanotubes. By using micromechanical cleavage, we have prepared and studied a variety of 2D crystals including single layers of boron nitride, graphite, several dichalcogenides, and complex oxides. These atomically thin sheets (essentially gigantic 2D molecules unprotected from the immediate environment) are stable under ambient conditions, exhibit high crystal quality, and are continuous on a macroscopic scale.","['Boron nitride', 'Atomic units', 'Cleavage (geology)', 'Graphite', 'Crystal (programming language)', 'Materials science', 'Crystallography', 'Chemical physics', 'Nanotechnology', 'Boron', 'Hexagonal boron nitride', 'Molecule', 'Chemistry', 'Physics', 'Composite material', 'Graphene', 'Organic chemistry', 'Quantum mechanics', 'Fracture (geology)', 'Computer science', 'Programming language']","bulk crystals, micromechanical cleavage, 2d crystals, boron ni, graphite, dichal, complex oxides"
Paper_01218,Organizational Learning: A Theory of Action Perspective,"['Ch. Argyris', 'Donald A. Schön']",1997,Revista Española de Investigaciones Sociológicas,Journal,,345-345,,77/78,10.2307/40183951,"«... Intervenir es entrar en un conjunto de relaciones en desarrollo con el proposito de ser util. El tipo de ayuda en el que nos vamos a centrar consiste en aumentar la capacidad para una buena dialectica organizativa —es decir, la capacidad de indagacion organizativa para encajar errores, incongruencias e incompatibilidades en una teoria organizativa de la accion la cual necesariamente emerge a medida que el sistema organizativo/ambiental cambia» (p. 158). «... Nuestra actividad en la intervencion debe por tanto ocuparse de tres propositos. Estos son: 1) ayudar al cliente a ser consciente y a descongelar sus teorias al uso del Modelo I y sistemas de aprendizaje O-I, y 2) educar al cliente a usar el Modelo II y a crear sistemas de aprendizaje O-II, para 3) usar este nuevo conocimiento con el fin de lograr una buena dialectica organizativa. Llamamos a la actividad de intervencion que incluye las tres intenciones una intervencion extensa» (p. 166).","['Perspective (graphical)', 'Action (physics)', 'Organizational theory', 'Action learning', 'Sociology', 'Organizational learning', 'Epistemology', 'Management', 'Pedagogy', 'Economics', 'Computer science', 'Philosophy', 'Artificial intelligence', 'Teaching method', 'Physics', 'Quantum mechanics', 'Cooperative learning']",
Paper_01222,Imagined Communities: Reflections on the Origin and Spread of Nationalism,['Stephen Sweet'],1984,Telos,Journal,,227-231,1984,60,10.3817/0684060227,"Benedict Anderson, Imagined Communities: Reflections on the Origin and Spread of Nationalism, (London: New Left Books, 1983).","['Nationalism', 'Sociology', 'Gender studies', 'History', 'Media studies', 'Political science', 'Law', 'Politics']","imagined communities, nationalism, [PAD] [PAD] [PAD], [PAD] [PAD], [PAD], [PAD], [PAD] [PAD] [PAD], [PAD] [PAD]"
Paper_01224,Trust: The Social Virtues and the Creation of Prosperity,"['Peter A. Schneider', 'Francis Fukuyama']",1996,Journal of Marketing,Journal,,129-129,60,3,10.2307/1251846,"In his bestselling The End of History and the Last Man, Francis Fukuyama argued that the end of the Cold War would also mean the beginning of a struggle for position in the rapidly emerging order of 21st-century capitalism. In Trust, a penetrating assessment of the emerging global economic order after History, he explains the social principles of economic life and tells us what we need to know to win the coming struggle for world dominance. Challenging orthodoxies of both the left and right, Fukuyama examines a wide range of national cultures in order to divine the underlying principles that foster social and economic prosperity. Insisting that we cannot divorce economic life from cultural life, he contends that in an era when social capital may be as important as physical capital, only those societies with a high degree of social trust will be able to create the flexible, large-scale business organizations that are needed to compete in the new global economy. A brilliant study of the interconnectedness of economic life with cultural life, Trust is also an essential antidote to the increasing drift of American culture into extreme forms of individualism, which, if unchecked, will have dire consequences for the nation's economic health.","['Prosperity', 'Capitalism', 'Dominance (genetics)', 'Political economy', 'Individualism', 'Social order', 'Order (exchange)', 'Social capital', 'Sociology', 'Political science', 'Politics', 'Economics', 'Social science', 'Law', 'Biochemistry', 'Chemistry', 'Finance', 'Gene']","trust, economic life, national cultures, social capital, social trust, economic life, cultural life, trust, american, individual"
Paper_01225,Singular Integrals and Differentiability Properties of Functions.,['Elias M. Stein'],1971,['Bulletin of the London Mathematical Society'],Unknown,,121-122,5,1,10.1112/blms/5.1.121,"Singular integrals are among the most interesting and important objects of study in analysis, one of the three main branches of mathematics. They deal with real and complex numbers and their functions. In this book, Princeton professor Elias Stein, a leading mathematical innovator as well as a gifted expositor, produced what has been called the most influential mathematics text in the last thirty-five years. One reason for its success as a text is its almost legendary presentation: Stein takes arcane material, previously understood only by specialists, and makes it accessible even to beginning graduate students. Readers have reflected that when you read this book, not only do you see that the greats of the past have done exciting work, but you also feel inspired that you can master the subject and contribute to it yourself. Singular integrals were known to only a few specialists when Stein's book was first published. Over time, however, the book has inspired a whole generation of researchers to apply its methods to a broad range of problems in many disciplines, including engineering, biology, and finance. Stein has received numerous awards for his research, including the Wolf Prize of Israel, the Steele Prize, and the National Medal of Science. He has published eight books with Princeton, including Real Analysis in 2005.","['Presentation (obstetrics)', 'Medal', 'Innovator', 'Subject (documents)', 'Mathematics', 'Mathematics education', 'Computer science', 'Mathematical economics', 'Calculus (dental)', 'Library science', 'Art history', 'History', 'Medicine', 'Dentistry', 'Radiology', 'Intellectual property', 'Operating system']","singular integrals, analysis, complex numbers, princeton, singular integrals, finance, real analysis"
Paper_01226,Structural Equation Models with Unobservable Variables and Measurement Error: Algebra and Statistics,"['Claes Fornell', 'David F. Larcker']",1981,Journal of Marketing Research,Journal,,382-388,18,3,10.1177/002224378101800313,"Several issues relating to goodness of fit in structural equations are examined. The convergence and differentiation criteria, as applied by Bagozzi, are shown not to stand up under mathematical or statistical analysis. The authors argue that the choice of interpretative statistic must be based on the research objective. They demonstrate that when this is done the Fornell-Larcker testing system is internally consistent and that it conforms to the rules of correspondence for relating data to abstract variables.","['Unobservable', 'Statistic', 'Structural equation modeling', 'Goodness of fit', 'Statistics', 'Mathematics', 'Econometrics', 'Mathematical statistics', 'Convergence (economics)', 'Applied mathematics', 'Computer science', 'Calculus (dental)', 'Economics', 'Medicine', 'Dentistry', 'Economic growth']","goodness of fit, structural equations, convergence, differentiation criteria, statistical analysis, interpretative statistic, abstract variables, [PAD] [PAD], [PAD], [PAD] [PAD], [PAD], [PAD] [PAD], [PAD], [PAD], [PAD]"
Paper_01229,Database resources of the National Center for Biotechnology Information: update,['David Wheeler'],2003,Nucleic Acids Research,Journal,,35D-40,32,90001,10.1093/nar/gkh073,"In addition to maintaining the GenBank nucleic acid sequence database, the National Center for Biotechnology Information (NCBI) provides analysis and retrieval resources for the data in GenBank and other biological data made available through NCBI's Web site. NCBI resources include Entrez, the Entrez Programming Utilities, MyNCBI, PubMed, PubMed Central, Entrez Gene, the NCBI Taxonomy Browser, BLAST, BLAST Link (BLink), Electronic PCR, OrfFinder, Spidey, Splign, RefSeq, UniGene, HomoloGene, ProtEST, dbMHC, dbSNP, Cancer Chromosomes, Entrez Genomes and related tools, the Map Viewer, Model Maker, Evidence Viewer, Clusters of Orthologous Groups, Retroviral Genotyping Tools, HIV-1, Human Protein Interaction Database, SAGEmap, Gene Expression Omnibus, Entrez Probe, GENSAT, Online Mendelian Inheritance in Man, Online Mendelian Inheritance in Animals, the Molecular Modeling Database, the Conserved Domain Database, the Conserved Domain Architecture Retrieval Tool and the PubChem suite of small molecule databases. Augmenting many of the Web applications are custom implementations of the BLAST program optimized to search specialized datasets. All of the resources can be accessed through the NCBI home page at: http://www.ncbi.nlm.nih.gov.","['RefSeq', 'UniGene', 'GenBank', 'OMIM : Online Mendelian Inheritance in Man', 'Biology', 'UniProt', 'dbSNP', 'Ensembl', 'Database', 'Biological database', 'Sequence database', 'World Wide Web', 'Bioinformatics', 'Genome', 'Genetics', 'Genomics', 'Computer science', 'Expressed sequence tag', 'Gene', 'Genotype', 'Single-nucleotide polymorphism', 'Phenotype']","genbank, ##bi, retrieval, ##bi, ##bi, entrez, entrez programming utilities, ##ncbi, pubmed, pubmed central, entrez, ncbi, blast, blast link, blink, electronic pcr, orffinder, spidey, splign, refseq, unigene, homologene, protest, db, dbsnp, cancer chromosomes, entrez, map viewer, model maker, evidence viewer, retroviral genotyping tools, human protein interaction database, sagemap, gene expression omnibus, entrez, gensat, online mendelian inheritance, online mendelian inheritance, molecular modeling database, conserved domain database, conserved domain architecture retrieval tool, pubchem, small molecule databases, blast program"
Paper_01230,Working knowledge: how organizations manage what they know,"['Thomas H. Davenport', 'Lawrence Prusak']",1998,Choice Reviews Online,Journal,,35-5167,35,09,10.5860/choice.35-5167,"From the Publisher:
The definitive primer on knowledge management, this book will establish the enduring vocabulary and concepts and serve as the hands-on resource of choice for fast companies that recognize knowledge as the only sustainable source of competitive advantage. Drawing on their work with more than 30 knowledge-rich firms, the authors-experienced consultants with a track record of success-examine how all types of companies can effectively understand, analyze, measure, and manage their intellectual assets, turning corporate knowledge into market value. They consider such questions as: What key cultural and behavioral issues must managers address to use knowledge effectively?; What are the best ways to incorporate technology into knowledge work?; What does a successful knowledge project look like-and how do you know when it has succeeded? In the end, say the authors, the human qualities of knowledge-experience, intuition, and beliefs-are the most valuable and the most difficult to manage. Applying the insights of Working Knowledge is every manager's first step on that rewarding road to long-term success. A Library Journal Best Business Book of the Year. For an entire company...to have knowledge, that information must be coordinated and made accessible. Thomas H. Davenport...and Laurence Prusak... offer an elegantly simple overview of the 'knowledge market' aimed at fulfilling that goal.... Working Knowledge provides practical advice about implementing a knowledge-management system....A solid dose of common sense for any company looking to acquire -- or maintain -- a competitive edge.--Upside, June 1998","['Knowledge management', 'Competitive advantage', 'Knowledge value chain', 'Personal knowledge management', 'Need to know', 'Knowledge economy', 'Domain knowledge', 'Best practice', 'Business', 'Organizational learning', 'Computer science', 'Marketing', 'Management', 'Economics', 'Computer security']","knowledge management, competitive advantage, corporate, library journal, knowledge market, working"
Paper_01231,Finding groups in data: an introduction to cluster analysis,[],1991,Choice Reviews Online,Journal,,28-4558,28,08,10.5860/choice.28-4558,1. Introduction. 2. Partitioning Around Medoids (Program PAM). 3. Clustering large Applications (Program CLARA). 4. Fuzzy Analysis. 5. Agglomerative Nesting (Program AGNES). 6. Divisive Analysis (Program DIANA). 7. Monothetic Analysis (Program MONA). Appendix 1. Implementation and Structure of the Programs. Appendix 2. Running the Programs. Appendix 3. Adapting the Programs to Your Needs. Appendix 4. The Program CLUSPLOT. References. Author Index. Subject Index.,"['Cluster (spacecraft)', 'Computer science', 'Genealogy', 'History', 'Computer network']","partition, medoids, cluster, fuzzy analysis, agglomerative nesting, divisive analysis, monothetic analysis, program, [PAD] [PAD], [PAD] [PAD], [PAD] [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD] [PAD], [PAD], [PAD], [PAD] [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD], [PAD] [PAD], [PAD] [PAD] [PAD] [PAD] [PAD], [PAD] [PAD], [PAD], [PAD] [PAD], [PAD] [PAD] [PAD] [PAD]"
Paper_01233,Median-joining networks for inferring intraspecific phylogenies,"['H. -J. Bandelt', 'Patrick Forster', 'Andrew L. Rohl']",1999,Molecular Biology and Evolution,Journal,,37-48,16,1,10.1093/oxfordjournals.molbev.a026036,"Reconstructing phylogenies from intraspecific data (such as human mitochondrial DNA variation) is often a challenging task because of large sample sizes and small genetic distances between individuals. The resulting multitude of plausible trees is best expressed by a network which displays alternative potential evolutionary paths in the form of cycles. We present a method (""median joining"" [MJ]) for constructing networks from recombination-free population data that combines features of Kruskal's algorithm for finding minimum spanning trees by favoring short connections, and Farris's maximum-parsimony (MP) heuristic algorithm, which sequentially adds new vertices called ""median vectors"", except that our MJ method does not resolve ties. The MJ method is hence closely related to the earlier approach of Foulds, Hendy, and Penny for estimating MP trees but can be adjusted to the level of homoplasy by setting a parameter epsilon. Unlike our earlier reduced median (RM) network method, MJ is applicable to multistate characters (e.g., amino acid sequences). An additional feature is the speed of the implemented algorithm: a sample of 800 worldwide mtDNA hypervariable segment I sequences requires less than 3 h on a Pentium 120 PC. The MJ method is demonstrated on a Tibetan mitochondrial DNA RFLP data set.","['Biology', 'Intraspecific competition', 'Set (abstract data type)', 'Minimum spanning tree', 'Mitochondrial DNA', 'Heuristic', 'Tree (set theory)', 'Population', 'Maximum parsimony', 'Evolutionary biology', 'Algorithm', 'Phylogenetic tree', 'Combinatorics', 'Genetics', 'Computer science', 'Mathematics', 'Artificial intelligence', 'Clade', 'Gene', 'Programming language', 'Ecology', 'Demography', 'Sociology']","human mitochondrial dna variation, genetic distances, median joining, median vectors, reduced median, multistate, amino, worldwide, tibetan mitochondrial dna rflp data"
Paper_01234,Fast algorithms for mining association rules,"['Rakesh Agrawal', 'Ramakrishnan Srikant']",1998,"['Studies in Fuzziness and Soft Computing', 'Data Mining, Rough Sets and Granular Computing']",Conference,,23-45,,,10.1007/978-3-7908-1791-1_2,"We consider the problem of discovering association rules between items in a large database of sales transactions. We present two new algorithms for solving thii problem that are fundamentally different from the known algorithms. Empirical evaluation shows that these algorithms outperform the known algorithms by factors ranging from three for small problems to more than an order of magnitude for large problems. We also show how the best features of the two proposed algorithms can be combined into a hybrid algorithm, called AprioriHybrid. Scale-up experiments show that AprioriHybrid scales linearly with the number of transactions. AprioriHybrid also has excellent scale-up properties with respect to the transaction size and the number of items in the database.","['Association rule learning', 'Computer science', 'Database transaction', 'Algorithm', 'Data mining', 'Scale (ratio)', 'Database', 'Physics', 'Quantum mechanics']","association rules, sales transactions, thii problem, hybrid algorithm, apriorihybrid, apriorihybrid, apriorihybrid, [PAD]"
Paper_01235,Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network,"['Christian Ledig', 'Lucas Theis', 'Ferenc Huszár', 'José Caballero', 'Andrew Cunningham', 'Alejandro Acosta', 'Andrew P. Aitken', 'Alykhan Tejani', 'Johannes Totz', 'Zehan Wang', 'Wenzhe Shi']",2017,Unknown,Unknown,,105-114,,,10.1109/cvpr.2017.19,"Despite the breakthroughs in accuracy and speed of single image super-resolution using faster and deeper convolutional neural networks, one central problem remains largely unsolved: how do we recover the finer texture details when we super-resolve at large upscaling factors? The behavior of optimization-based super-resolution methods is principally driven by the choice of the objective function. Recent work has largely focused on minimizing the mean squared reconstruction error. The resulting estimates have high peak signal-to-noise ratios, but they are often lacking high-frequency details and are perceptually unsatisfying in the sense that they fail to match the fidelity expected at the higher resolution. In this paper, we present SRGAN, a generative adversarial network (GAN) for image super-resolution (SR). To our knowledge, it is the first framework capable of inferring photo-realistic natural images for 4x upscaling factors. To achieve this, we propose a perceptual loss function which consists of an adversarial loss and a content loss. The adversarial loss pushes our solution to the natural image manifold using a discriminator network that is trained to differentiate between the super-resolved images and original photo-realistic images. In addition, we use a content loss motivated by perceptual similarity instead of similarity in pixel space. Our deep residual network is able to recover photo-realistic textures from heavily downsampled images on public benchmarks. An extensive mean-opinion-score (MOS) test shows hugely significant gains in perceptual quality using SRGAN. The MOS scores obtained with SRGAN are closer to those of the original high-resolution images than to those obtained with any state-of-the-art method.","['Discriminator', 'Artificial intelligence', 'Computer science', 'Similarity (geometry)', 'Image (mathematics)', 'Mean opinion score', 'Residual', 'Pattern recognition (psychology)', 'Convolutional neural network', 'Deep learning', 'Pixel', 'Computer vision', 'Algorithm', 'Metric (unit)', 'Telecommunications', 'Operations management', 'Detector', 'Economics']","convolutional neural networks, objective function, mean squared reconstruction error, srgan, generative adversarial network, gan, perceptual loss function, adversarial loss, content loss, advers, natural image manifold, discriminator network, content loss, ##ual similarity, deep residual network, per, ##ual quality, mos, srgan"
Paper_01236,Ad hoc On-Demand Distance Vector (AODV) Routing,"['Colin Perkins', 'Elizabeth M. Belding‐Royer', 'S. Das']",2003,Unknown,Unknown,,,,,10.17487/rfc3561,"The Ad hoc On-Demand Distance Vector (AODV) routing protocol is intended for use by mobile nodes in an ad hoc network. It offers quick adaptation to dynamic link conditions, low processing and memory overhead, low network utilization, and determines unicast routes to destinations within the ad hoc network. It uses destination sequence numbers to ensure loop freedom at all times (even in the face of anomalous delivery of routing control messages), avoiding problems (such as counting to infinity) associated with classical distance vector protocols.","['Ad hoc On-Demand Distance Vector Routing', 'Computer science', 'Distance-vector routing protocol', 'Destination-Sequenced Distance Vector routing', 'Computer network', 'Routing (electronic design automation)', 'Dynamic Source Routing', 'Routing protocol']","ao, routing protocol, mobile nodes, ad hoc network, dynamic link conditions, memory overhead, un, ##st routes, destination sequence numbers, loop freedom, routing control messages, classical distance vector protocols, [PAD] [PAD], [PAD] [PAD] [PAD], [PAD] [PAD], [PAD] [PAD] [PAD], [PAD] [PAD] [PAD], [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD]"
Paper_01237,Improved Synthesis of Graphene Oxide,"['Daniela C. Marcano', 'Dmitry V. Kosynkin', 'Jacob M. Berlin', 'Alexander Sinitskii', 'Zhengzong Sun', 'Alexander Slesarev', 'Lawrence B. Alemany', 'Wei Lu', 'James M. Tour']",2010,ACS Nano,Journal,,4806-4814,4,8,10.1021/nn1006368,"An improved method for the preparation of graphene oxide (GO) is described. Currently, Hummers' method (KMnO4, NaNO3, H2SO4) is the most common method used for preparing graphene oxide. We have found that excluding the NaNO3, increasing the amount of KMnO4, and performing the reaction in a 9:1 mixture of H2SO4/H3PO4 improves the efficiency of the oxidation process. This improved method provides a greater amount of hydrophilic oxidized graphene material as compared to Hummers' method or Hummers' method with additional KMnO4. Moreover, even though the GO produced by our method is more oxidized than that prepared by Hummers' method, when both are reduced in the same chamber with hydrazine, chemically converted graphene (CCG) produced from this new method is equivalent in its electrical conductivity. In contrast to Hummers' method, the new method does not generate toxic gas and the temperature is easily controlled. This improved synthesis of GO may be important for large-scale production of GO as well as the construction of devices composed of the subsequent CCG.","['Graphene', 'Oxide', 'Materials science', 'Graphene oxide paper', 'Hydrazine (antidepressant)', 'Chemical engineering', 'Nanotechnology', 'Conductivity', 'Nano-', 'Chemistry', 'Composite material', 'Chromatography', 'Physical chemistry', 'Engineering', 'Metallurgy']","graphene oxide, kmno, nano, ##so, graphene, nano, hydrophilic oxidized graphene, electrical conductivity"
Paper_01238,"Nudge: improving decisions about health, wealth, and happiness","['Richard H. Thaler', 'Cass R. Sunstein']",2008,Choice Reviews Online,Journal,,46-0977,46,02,10.5860/choice.46-0977,"A groundbreaking discussion of how we can apply the new science of to nudge people toward decisions that will improve their lives by making them healthier, wealthier, and more free Every day, we make decisions on topics ranging from personal investments to schools for our children to the meals we eat to the causes we champion. Unfortunately, we often choose poorly. Nobel laureate Richard Thaler and legal scholar and bestselling author Cass Sunstein explain in this important exploration of that, being human, we all are susceptible to various biases that can lead us to blunder. Our mistakes make us poorer and less healthy; we often make bad decisions involving education, personal finance, health care, mortgages and credit cards, the family, and even the planet itself. In Nudge, Thaler and Sunstein invite us to enter an alternative world, one that takes our humanness as a given. They show that by knowing how people think, we can design environments that make it easier for people to choose what is best for themselves, their families, and their society. Using colorful examples from the most important aspects of life, Thaler and Sunstein demonstrate how thoughtful choice architecture can be established to nudge us in beneficial directions without restricting freedom of choice. Nudge offers a unique new take-from neither the left nor the right-on many hot-button issues, for individuals and governments alike. This is one of the most engaging and provocative books to come along in many years.","['Happiness', 'Nudge theory', 'Economics', 'Public economics', 'Psychology', 'Social psychology']","personal investments, personal finance, health care, mortgages, credit cards, nudge, choice architecture, nudge"
Paper_01239,Projections of Global Mortality and Burden of Disease from 2002 to 2030,"['Colin Mathers', 'Dejan Lončar']",2006,PLoS Medicine,Journal,,e442-e442,3,11,10.1371/journal.pmed.0030442,"Background Global and regional projections of mortality and burden of disease by cause for the years 2000, 2010, and 2030 were published by Murray and Lopez in 1996 as part of the Global Burden of Disease project. These projections, which are based on 1990 data, continue to be widely quoted, although they are substantially outdated; in particular, they substantially underestimated the spread of HIV/AIDS. To address the widespread demand for information on likely future trends in global health, and thereby to support international health policy and priority setting, we have prepared new projections of mortality and burden of disease to 2030 starting from World Health Organization estimates of mortality and burden of disease for 2002. This paper describes the methods, assumptions, input data, and results. Methods and Findings Relatively simple models were used to project future health trends under three scenarios—baseline, optimistic, and pessimistic—based largely on projections of economic and social development, and using the historically observed relationships of these with cause-specific mortality rates. Data inputs have been updated to take account of the greater availability of death registration data and the latest available projections for HIV/AIDS, income, human capital, tobacco smoking, body mass index, and other inputs. In all three scenarios there is a dramatic shift in the distribution of deaths from younger to older ages and from communicable, maternal, perinatal, and nutritional causes to noncommunicable disease causes. The risk of death for children younger than 5 y is projected to fall by nearly 50% in the baseline scenario between 2002 and 2030. The proportion of deaths due to noncommunicable disease is projected to rise from 59% in 2002 to 69% in 2030. Global HIV/AIDS deaths are projected to rise from 2.8 million in 2002 to 6.5 million in 2030 under the baseline scenario, which assumes coverage with antiretroviral drugs reaches 80% by 2012. Under the optimistic scenario, which also assumes increased prevention activity, HIV/AIDS deaths are projected to drop to 3.7 million in 2030. Total tobacco-attributable deaths are projected to rise from 5.4 million in 2005 to 6.4 million in 2015 and 8.3 million in 2030 under our baseline scenario. Tobacco is projected to kill 50% more people in 2015 than HIV/AIDS, and to be responsible for 10% of all deaths globally. The three leading causes of burden of disease in 2030 are projected to include HIV/AIDS, unipolar depressive disorders, and ischaemic heart disease in the baseline and pessimistic scenarios. Road traffic accidents are the fourth leading cause in the baseline scenario, and the third leading cause ahead of ischaemic heart disease in the optimistic scenario. Under the baseline scenario, HIV/AIDS becomes the leading cause of burden of disease in middle- and low-income countries by 2015. Conclusions These projections represent a set of three visions of the future for population health, based on certain explicit assumptions. Despite the wide uncertainty ranges around future projections, they enable us to appreciate better the implications for health and health policy of currently observed trends, and the likely impact of fairly certain future trends, such as the ageing of the population, the continued spread of HIV/AIDS in many regions, and the continuation of the epidemiological transition in developing countries. The results depend strongly on the assumption that future mortality trends in poor countries will have a relationship to economic and social development similar to those that have occurred in the higher-income countries.","['Disease burden', 'Environmental health', 'Global health', 'Medicine', 'Burden of disease', 'Disease', 'Baseline (sea)', 'Demography', 'Mortality rate', 'Public health', 'Gerontology', 'Population', 'Oceanography', 'Nursing', 'Internal medicine', 'Geology', 'Pathology', 'Sociology']","regional projections, 203, global burden of disease, international, world, social, death registration, human capital, tobacco smoking, body mass index, non, ##ble, non, ##icable, antiretroviral drugs, unipolar depressive disorders"
Paper_01240,QUADAS-2: A Revised Tool for the Quality Assessment of Diagnostic Accuracy Studies,['Penny Whiting'],2011,Annals of Internal Medicine,Journal,,529-529,155,8,10.7326/0003-4819-155-8-201110180-00009,"In 2003, the QUADAS tool for systematic reviews of diagnostic accuracy studies was developed. Experience, anecdotal reports, and feedback suggested areas for improvement; therefore, QUADAS-2 was developed. This tool comprises 4 domains: patient selection, index test, reference standard, and flow and timing. Each domain is assessed in terms of risk of bias, and the first 3 domains are also assessed in terms of concerns regarding applicability. Signalling questions are included to help judge risk of bias. The QUADAS-2 tool is applied in 4 phases: summarize the review question, tailor the tool and produce review-specific guidance, construct a flow diagram for the primary study, and judge bias and applicability. This tool will allow for more transparent rating of bias and applicability of primary diagnostic accuracy studies.","['Medicine', 'Diagnostic accuracy', 'Medical physics', 'Diagnostic test', 'Selection bias', 'Radiology', 'Pathology', 'Pediatrics']","quadas, systematic reviews, diagnostic accuracy studies, anecdotal reports, feedback, quadas, patient selection, index test, reference standard, quadas, flow diagram, ##bility, [PAD], [PAD], [PAD] [PAD], [PAD] [PAD] [PAD] [PAD] [PAD], [PAD], [PAD], [PAD], [PAD]"
Paper_01242,Metascape provides a biologist-oriented resource for the analysis of systems-level datasets,"['Yingyao Zhou', 'Bin Zhou', 'Lars Pache', 'Max W. Chang', 'Alireza Hadj Khodabakhshi', 'Olga Tanaseichuk', 'Christopher Benner', 'Sumit K. Chanda']",2019,Nature Communications,Journal,,,10,1,10.1038/s41467-019-09234-6,"Abstract A critical component in the interpretation of systems-level studies is the inference of enriched biological pathways and protein complexes contained within OMICs datasets. Successful analysis requires the integration of a broad set of current biological databases and the application of a robust analytical pipeline to produce readily interpretable results. Metascape is a web-based portal designed to provide a comprehensive gene list annotation and analysis resource for experimental biologists. In terms of design features, Metascape combines functional enrichment, interactome analysis, gene annotation, and membership search to leverage over 40 independent knowledgebases within one integrated portal. Additionally, it facilitates comparative analyses of datasets across multiple independent and orthogonal experiments. Metascape provides a significantly simplified user experience through a one-click Express Analysis interface to generate interpretable outputs. Taken together, Metascape is an effective and efficient tool for experimental biologists to comprehensively analyze and interpret OMICs-based studies in the big data era.","['Computer science', 'Interactome', 'Annotation', 'Inference', 'Pipeline (software)', 'Leverage (statistics)', 'Resource (disambiguation)', 'Data science', 'Data mining', 'Computational biology', 'Artificial intelligence', 'Biology', 'Gene', 'Computer network', 'Biochemistry', 'Programming language']","enriched biological pathways, protein complexes, omics datasets, biological databases, robust analytical pipeline, metascape, gene list, experimental biologists, metascape, functional enrichment, interactome analysis, gene annotation, membership search, metascape, metascape, experimental biologist"
Paper_01243,A model of saliency-based visual attention for rapid scene analysis,"['Laurent Itti', 'Christof Koch', 'Ernst Niebur']",1998,IEEE Transactions on Pattern Analysis and Machine Intelligence,Journal,,1254-1259,20,11,10.1109/34.730558,"A visual attention system, inspired by the behavior and the neuronal architecture of the early primate visual system, is presented. Multiscale image features are combined into a single topographical saliency map. A dynamical neural network then selects attended locations in order of decreasing saliency. The system breaks down the complex problem of scene understanding by rapidly selecting, in a computationally efficient manner, conspicuous locations to be analyzed in detail.","['Artificial intelligence', 'Computer science', 'Computer vision', 'Visual attention', 'Visualization', 'Pattern recognition (psychology)', 'Image (mathematics)', 'Human visual system model', 'Saliency map', 'Artificial neural network', 'Perception', 'Neuroscience', 'Biology']","visual attention system, neuronal architecture, primate visual system, multiscale, topographical saliency map, dynamical neural network, scene understanding, [PAD], [PAD], [PAD] [PAD], [PAD], [PAD] [PAD] [PAD] [PAD], [PAD]"
Paper_01244,Spintronics: A Spin-Based Electronics Vision for the Future,"['Stefan Wolf', 'D. D. Awschalom', 'R. A. Buhrman', 'J.M. Daughton', 'S. von Molnár', 'M. L. Roukes', 'Almadena Chtchelkanova', 'Daryl Treger']",2001,Science,Journal,,1488-1495,294,5546,10.1126/science.1065389,"This review describes a new paradigm of electronics based on the spin degree of freedom of the electron. Either adding the spin degree of freedom to conventional charge-based electronic devices or using the spin alone has the potential advantages of nonvolatility, increased data processing speed, decreased electric power consumption, and increased integration densities compared with conventional semiconductor devices. To successfully incorporate spins into existing semiconductor technology, one has to resolve technical issues such as efficient injection, transport, control and manipulation, and detection of spin polarization as well as spin-polarized currents. Recent advances in new materials engineering hold the promise of realizing spintronic devices in the near future. We review the current state of the spin-based devices, efforts in new materials fabrication, issues in spin transport, and optical spin manipulation.","['Spintronics', 'Electronics', 'Spin transistor', 'Spin (aerodynamics)', 'Spinplasmonics', 'Spin pumping', 'Spins', 'Nanotechnology', 'Spin polarization', 'Semiconductor', 'Engineering physics', 'Spin engineering', 'Electrical engineering', 'Spin Hall effect', 'Computer science', 'Physics', 'Engineering', 'Materials science', 'Electron', 'Condensed matter physics', 'Mechanical engineering', 'Quantum mechanics', 'Ferromagnetism']","spin degree of freedom, spin degree of freedom, nonvolatility, data processing speed, electric power consumption, integration densities, spin polar, spin, ##ic devices, spin transport, optical spin manipulation"
Paper_01245,"Blast2GO: a universal tool for annotation, visualization and analysis in functional genomics research","['Sebastian Rokitta', 'Peter von Dassow', 'B. Rost', 'Uwe John']",2005,Bioinformatics,Journal,,3674-3676,21,18,10.1093/bioinformatics/bti610,"We present here Blast2GO (B2G), a research tool designed with the main purpose of enabling Gene Ontology (GO) based data mining on sequence data for which no GO annotation is yet available. B2G joints in one application GO annotation based on similarity searches with statistical analysis and highlighted visualization on directed acyclic graphs. This tool offers a suitable platform for functional genomics research in non-model species. B2G is an intuitive and interactive desktop application that allows monitoring and comprehension of the whole annotation and analysis process.Blast2GO is freely available via Java Web Start at http://www.blast2go.de.http://www.blast2go.de -> Evaluation.","['Annotation', 'Computer science', 'Visualization', 'Java', 'Process (computing)', 'Software', 'Information retrieval', 'Functional genomics', 'Genomics', 'Gene Annotation', 'World Wide Web', 'Data mining', 'Genome', 'Artificial intelligence', 'Programming language', 'Biology', 'Biochemistry', 'Gene']","blast, ##go, b2g, gene ontology, data mining, sequence data, ##2g, ##tion, similarity searches, statistical analysis, directed acyclic graphs, functional genomics research, b2g, blast, ##go, blast"
Paper_01247,Deep Contextualized Word Representations,"['Matthew E. Peters', 'Mark E Neumann', 'Mohit Iyyer', 'Matt Gardner', 'Christopher Clark', 'Kenton Lee', 'Luke Zettlemoyer']",2018,Unknown,Unknown,,,,,10.18653/v1/n18-1202,"Matthew E. Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Kenton Lee, Luke Zettlemoyer. Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers). 2018.","['Linguistics', 'Human language', 'Word (group theory)', 'Computer science', 'Computational linguistics', 'Cognitive science', 'Artificial intelligence', 'Natural language processing', 'Philosophy', 'Psychology']","computational linguistics, human language technologies, [PAD], [PAD], [PAD]"
Paper_01248,A Stepwise Huisgen Cycloaddition Process: Copper(I)-Catalyzed Regioselective “Ligation” of Azides and Terminal Alkynes,"['Vsevolod V. Rostovtsev', 'Luke G. Green', 'Valery V. Fokin', 'K. Barry Sharpless']",2002,Angewandte Chemie International Edition,Journal,,2596-2599,41,14,10.1002/1521-3773(20020715)41:14<2596::aid-anie2596>3.0.co;2-4,"By simply stirring in water, organic azides and terminal alkynes are readily and cleanly converted into 1,4-disubstituted 1,2,3-triazoles through a highly efficient and regioselective copper(I)-catalyzed process (see scheme for an example). Supporting information for this article is available on the WWW under http://www.angewandte.org or from the author. Supporting information for this article is available on the WWW under http://www.wiley-vch.de/contents/jc_2002/2002/z19191_s.pdf or from the author. Please note: The publisher is not responsible for the content or functionality of any supporting information supplied by the authors. Any queries (other than missing content) should be directed to the corresponding author for the article.","['Regioselectivity', 'Cycloaddition', 'Terminal (telecommunication)', 'Copper', 'Chemistry', 'Catalysis', 'Combinatorial chemistry', 'Process (computing)', 'Research article', 'Computer science', 'Organic chemistry', 'Operating system', 'Library science', 'Telecommunications']","organic azides, terminal alkynes"
Paper_01249,Astropy: A community Python package for astronomy,"['Thomas Robitaille', 'Erik Tollerud', 'P. Greenfield', 'Michael Droettboom', 'Erik M. Bray', 'Tom Aldcroft', 'M. Ryleigh Davis', 'Adam Ginsburg', 'Adrian M. Price-Whelan', 'Wolfgang Kerzendorf', 'Alexander Conley', 'Neil H. M. Crighton', 'K. Barbary', 'Demitri Muna', 'Henry C. Ferguson', 'Frédéric Grollier', 'Madhura M. Parikh', 'Prasanth H. Nair', 'Hans Moritz Günther', 'Christoph Deil', 'J. Woillez', 'Simon Conseil', 'Roban Hultman Kramer', 'James Turner', 'L. P. Singer', 'Ryan Fox', 'Benjamin Weaver', 'V. Zabalza', 'Zachary Edwards', 'K. Azalee Bostroem', 'D. J. Burke', 'Andrew R. Casey', 'Steven M. Crawford', 'Nadia Dencheva', 'Justin Ely', 'T. Jenness', 'Kathleen Labrie', 'Pey Lian Lim', 'F. Pierfederici', 'Andrew Pontzen', 'A. Ptak', 'Brian L. Refsdal', 'M. Servillat', 'O. Streicher']",2013,Astronomy and Astrophysics,Journal,,A33-A33,558,,10.1051/0004-6361/201322068,"We present the first public version (v0.2) of the open-source and community-developed Python package, Astropy. This package provides core astronomy-related functionality to the community, including support for domain-specific file formats such as Flexible Image Transport System (FITS) files, Virtual Observatory (VO) tables, and common ASCII table formats, unit and physical quantity conversions, physical constants specific to astronomy, celestial coordinate and time transformations, world coordinate system (WCS) support, generalized containers for representing gridded as well as tabular data, and a framework for cosmological transformations and conversions. Significant functionality is under active development, such as a model fitting framework, VO client and server tools, and aperture and point spread function (PSF) photometry tools. The core development team is actively making additions and enhancements to the current code base, and we encourage anyone interested to participate in the development of future Astropy versions.","['Python (programming language)', 'ASCII', 'Computer science', 'Virtual observatory', 'Computer graphics (images)', 'File format', 'Photometry (optics)', 'Astronomy', 'Physics', 'World Wide Web', 'Programming language', 'Operating system', 'Stars']","python, astropy, flexible image transport system, virtual observatory, ascii table, physical, physical constants, celestial coordinate, time transformations, world coordinate system, generalized containers, tabular, cosmological transformations, model fitting framework, point spread function, astropy"
Paper_01250,Constructing Grounded Theory. A Practical Guide Through Qualitative Analysis,[],2006,QMiP Bulletin,Journal,,36-38,1,2,10.53841/bpsqmip.2006.1.2.36,การวจยเชงคณภาพ เปนเครองมอสำคญอยางหนงสำหรบทำความเขาใจสงคมและพฤตกรรมมนษย การวจยแบบการสรางทฤษฎจากขอมล กเปนหนงในหลายระเบยบวธการวจยเชงคณภาพทกำลงไดรบความสนใจ และเปนทนยมเพมสงขนเรอยๆ จากนกวชาการ และนกวจยในสาขาสงคมศาสตร และศาสตรอนๆ เชน พฤตกรรมศาสตร สงคมวทยา สาธารณสขศาสตร พยาบาลศาสตร จตวทยาสงคม ศกษาศาสตร รฐศาสตร และสารสนเทศศกษา ดงนน หนงสอเรอง “ConstructingGrounded Theory: A Practical Guide through Qualitative Analysis” หรอ “การสรางทฤษฎจากขอมล:แนวทางการปฏบตผานการวเคราะหเชงคณภาพ” จะชวยใหผอานมความรความเขาใจถงพฒนาการของปฏบตการวจยแบบสรางทฤษฎจากขอมล ตลอดจนแนวทาง และกระบวนการปฏบตการวจยอยางเปนระบบ จงเปนหนงสอทควรคาแกการอานโดยเฉพาะนกวจยรนใหม เพอเปนแนวทางในการนำความรความเขาใจไประยกตในงานวจยของตน อกทงนกวจยผเชยวชาญสามารถอานเพอขยายมโนทศนดานวจยใหกวางขวางขน,"['Grounded theory', 'Qualitative research', 'Qualitative analysis', 'Computer science', 'Sociology', 'Epistemology', 'Social science', 'Philosophy']","constructinggrounded theory, qualitative analysis, [PAD], [PAD], [PAD] [PAD], [PAD] [PAD], [PAD], [PAD], [PAD] [PAD] [PAD] [PAD], [PAD] [PAD], [PAD]"
Paper_01253,Comprehensive molecular portraits of human breast tumours,"['Daniel C. Koboldt', 'Robert S. Fulton', 'Michael D. McLellan', 'Heather K. Schmidt', 'Joelle Kalicki-Veizer', 'Joshua F. McMichael', 'Lucinda Fulton', 'David J. Dooling', 'Li Ding', 'Elaine R. Mardis', 'Richard K. Wilson', 'Adrian Ally', 'Miruna Balasundaram', 'Yaron S.N. Butterfield', 'Rebecca Carlsen', 'Candace Carter', 'Andy Chu', 'Eric Chuah', 'Hye Jung E. Chun', 'Robin Coope', 'Noreen Dhalla', 'Ranabir Guin', 'Carrie Hirst', 'Martin Hirst', 'Robert A. Holt', 'Darlene Lee', 'Haiyan I. Li', 'Michael Mayo', 'Richard A. Moore', 'Andrew J. Mungall', 'Erin Pleasance', 'A. Gordon Robertson', 'Jacqueline E. Schein', 'Arash Shafiei', 'Payal Sipahimalani', 'Jared R. Slobodan', 'Dominik Stoll', 'Angela Tam', 'Nina Thiessen', 'Richard Varhol', 'Natasja Wye', 'Thomas Zeng', 'Yongjun Zhao', 'İnanç Birol', 'Steven J.M. Jones', 'Marco A. Marra', 'Andrew D. Cherniack', 'Gordon Saksena', 'Robert C. Onofrio', 'Nam Pho', 'Scott L. Carter', 'Steven E. Schumacher', 'Barbara Tabak', 'Bryan Hernandez', 'Jeff Gentry', 'Huy Nguyen', 'Andrew Crenshaw', 'Kristin Ardlie', 'Rameen Beroukhim', 'Wendy Winckler', 'Gad Getz', 'Stacey Gabriel', 'Matthew Meyerson', 'Lynda Chin', 'Raju Kucherlapati', 'Katherine A. Hoadley', 'J. Todd Auman', 'Huihui Fan', 'Yidi J. Turman', 'Yan Shi', 'Ling Li', 'Michael D. Topal', 'Xiaping He', 'Hann Hsiang Chao', 'Aleix Prat', 'Grace O. Silva', 'Michael D. Iglesia', 'Zhao Wei', 'Jerry Usary', 'Jonathan S. Berg', 'Michael C. C. Adams', 'Jessica K. Booker', 'Junyuan Wu', 'Anisha Gulabani', 'Tom Bodenheimer', 'Alan P. Hoyle', 'Janae V. Simons', 'Matthew G. Soloway', 'Lisle E. Mose', 'Joshua M. Stuart', 'Saianand Balu', 'Peter J. Park', 'D. Neil Hayes', 'Charles M. Perou', 'Simeen Malik', 'Swapna Mahurkar‐Joshi', 'Hui Shen', 'Daniel J. Weisenberger', 'Timothy J. Triche', 'Phillip H. Lai']",2012,Nature,Journal,,61-70,490,7418,10.1038/nature11412,"We analysed primary breast cancers by genomic DNA copy number arrays, DNA methylation, exome sequencing, messenger RNA arrays, microRNA sequencing and reverse-phase protein arrays. Our ability to integrate information across platforms provided key insights into previously defined gene expression subtypes and demonstrated the existence of four main breast cancer classes when combining data from five platforms, each of which shows significant molecular heterogeneity. Somatic mutations in only three genes (TP53, PIK3CA and GATA3) occurred at >10% incidence across all breast cancers; however, there were numerous subtype-associated and novel gene mutations including the enrichment of specific mutations in GATA3, PIK3CA and MAP3K1 with the luminal A subtype. We identified two novel protein-expression-defined subgroups, possibly produced by stromal/microenvironmental elements, and integrated analyses identified specific signalling pathways dominant in each molecular subtype including a HER2/phosphorylated HER2/EGFR/phosphorylated EGFR signature within the HER2-enriched expression subtype. Comparison of basal-like breast tumours with high-grade serous ovarian tumours showed many molecular commonalities, indicating a related aetiology and similar therapeutic opportunities. The biological finding of the four main breast cancer subtypes caused by different subsets of genetic and epigenetic abnormalities raises the hypothesis that much of the clinically observable plasticity and heterogeneity occurs within, and not across, these major biological subtypes of breast cancer. The Cancer Genome Atlas Network describe their multifaceted analyses of primary breast cancers, shedding light on breast cancer heterogeneity; although only three genes (TP53, PIK3CA and GATA3) are mutated at a frequency greater than 10% across all breast cancers, numerous subtype-associated and novel mutations were identified. This Article from the Cancer Genome Atlas consortium describes a multifaceted analysis of primary breast cancers in 825 people. Exome sequencing, copy number variation, DNA methylation, messenger RNA arrays, microRNA sequencing and proteomic analyses were performed and integrated to shed light on breast-cancer heterogeneity. Just three genes — TP53, PIK3CA and GATA3 — are mutated at greater than 10% frequency across all breast cancers. Many subtype-associated and novel mutations were identified, as well as two breast-cancer subgroups with specific signalling-pathway signatures. The analyses also suggest that much of the clinically observable plasticity and heterogeneity occurs within, and not across, the major subtypes of breast cancer.","['Biology', 'Breast cancer', 'Epigenetics', 'GATA3', 'Cancer research', 'Gene', 'microRNA', 'DNA methylation', 'Cancer', 'Genetics', 'Gene expression', 'Transcription factor']","primary breast cancers, genomic dna copy number arrays, dna methylation, exome sequencing, messenger rna arrays, breast cancer, cancer, cancer genome atlas consortium, exome sequencing, copy number variation, dna, messenger rna arrays, microrna sequencing, proteomic analyses"
Paper_01254,Frame Analysis: An Essay on the Organization of Experience.,['Erving Goffman'],1975,Contemporary Sociology A Journal of Reviews,Journal,,603-603,4,6,10.2307/2064022,"Erving Goffman will influence the thinking and perceptions of generations to come. In Frame Analysis, the brilliant theorist writes about the ways in which people determine their answers to the questions What is going on here? and Under what circumstances do we think things are real? ","['Frame analysis', 'Frame (networking)', 'Sociology', 'Political science', 'Psychology', 'Social science', 'Computer science', 'Content analysis', 'Telecommunications']","frame analysis, [PAD] [PAD]"
Paper_01256,Handbook of applied cryptography,"['Alfred Menezes', 'Scott A. Vanstone', 'Paul C. van Oorschot']",1997,Choice Reviews Online,Journal,,34-4512,34,08,10.5860/choice.34-4512,"From the Publisher:
A valuable reference for the novice as well as for the expert who needs a wider scope of coverage within the area of cryptography, this book provides easy and rapid access of information and includes more than 200 algorithms and protocols; more than 200 tables and figures; more than 1,000 numbered definitions, facts, examples, notes, and remarks; and over 1,250 significant references, including brief comments on each paper.","['Scope (computer science)', 'Computer science', 'Cryptography', 'Computer security', 'Information retrieval', 'Data science', 'Theoretical computer science', 'Programming language']","cryptography, [PAD], [PAD], [PAD]"
Paper_01258,Preferred reporting items for systematic review and meta-analysis protocols (PRISMA-P) 2015: elaboration and explanation,"['Larissa Shamseer', 'David Moher', 'Mike Clarke', 'Davina Ghersi', 'A. Liberati', 'Mark Petticrew', 'Paul Shekelle', 'Lesley Stewart']",2015,BMJ,Journal,,g7647-g7647,349,jan02 1,10.1136/bmj.g7647,"Protocols of systematic reviews and meta-analyses allow for planning and documentation of review methods, act as a guard against arbitrary decision making during review conduct, enable readers to assess for the presence of selective reporting against completed reviews, and, when made publicly available, reduce duplication of efforts and potentially prompt collaboration. Evidence documenting the existence of selective reporting and excessive duplication of reviews on the same or similar topics is accumulating and many calls have been made in support of the documentation and public availability of review protocols. Several efforts have emerged in recent years to rectify these problems, including development of an international register for prospective reviews (PROSPERO) and launch of the first open access journal dedicated to the exclusive publication of systematic review products, including protocols (BioMed Central's <i>Systematic Reviews</i>). Furthering these efforts and building on the PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-analyses) guidelines, an international group of experts has created a guideline to improve the transparency, accuracy, completeness, and frequency of documented systematic review and meta-analysis protocols—PRISMA-P (for protocols) 2015. The PRISMA-P checklist contains 17 items considered to be essential and minimum components of a systematic review or meta-analysis protocol. This PRISMA-P 2015 Explanation and Elaboration paper provides readers with a full understanding of and evidence about the necessity of each item as well as a model example from an existing published protocol. This paper should be read together with the PRISMA-P 2015 statement. Systematic review authors and assessors are strongly encouraged to make use of PRISMA-P when drafting and appraising review protocols.","['Systematic review', 'Checklist', 'Documentation', 'Protocol (science)', 'Guideline', 'Meta-analysis', 'Transparency (behavior)', 'MEDLINE', 'Computer science', 'Medicine', 'Psychology', 'Alternative medicine', 'Political science', 'Pathology', 'Computer security', 'Law', 'Cognitive psychology', 'Programming language']","systematic reviews, review methods, selective reporting, selective reporting, international register, prospero, open access, biomed central, systematic, prisma, systematic review"
Paper_01259,SciPy 1.0: fundamental algorithms for scientific computing in Python,"['Pauli Virtanen', 'Ralf Gommers', 'Travis E. Oliphant', 'Matt Haberland', 'Tyler Reddy', 'David Cournapeau', 'Evgeni Burovski', 'Pearu Peterson', 'Warren Weckesser', 'Jonathan Bright', 'Stéfan van der Walt', 'Matthew Brett', 'Joshua Wilson', 'K. Jarrod Millman', 'Nikolay Mayorov', 'Andrew Nelson', 'Eric D. Jones', 'Robert Kern', 'Eric R. Larson', 'CJ Carey', 'İlhan Polat', 'Yu Feng', 'Eric Moore', 'Jake Vanderplas', 'Denis Laxalde', 'Josef Perktold', 'Robert Cimrman', 'Ian Henriksen', 'E. A. Quintero', 'C. R. Harris', 'Anne M. Archibald', 'Antônio H. Ribeiro', 'Fabian Pedregosa', 'Paul van Mulbregt', 'A. Vijaykumar', 'Alessandro Pietro Bardelli', 'Alex Rothberg', 'Andreas Hilboll', 'Andreas Kloeckner', 'Anthony Scopatz', 'Antony Lee', 'Ariel Rokem', 'Charles Woods', 'Chad Fulton', 'Charles Masson', 'Christian Häggström', 'C Fitzgerald', 'David Nicholson', 'David Hagen', 'Dmitrii V. Ṗasechnik', 'Emanuele Olivetti', 'Éric Martin', 'Eric Wieser', 'Fabrice Silva', 'Felix Lenders', 'Florian Wilhelm', 'George S. Young', 'Gavin A Price', 'Gert‐Ludwig Ingold', 'Gregory E. Allen', 'Gregory R. Lee', 'Hervé Audren', 'Irvin Probst', 'J. P. Dietrich', 'Jacob Silterra', 'James T. Webber', 'Janko Slavič', 'Joel Nothman', 'Johannes Büchner', 'Johannes Kulick', 'Johannes L. Schönberger', 'Josè Vinícius de Miranda Cardoso', 'Joscha Reimer', 'Joseph Harrington', 'Juan Luis Cano', 'Juan Nunez-Iglesias', 'Justin Kuczynski', 'K. Tritz', 'Martin Thoma', 'M. Newville', 'Matthias Kümmerer', 'Maximilian Bolingbroke', 'Michael Tartre', 'M. Pak', 'Nathaniel J. Smith', 'Nikolai Nowaczyk', 'Nikolay Shebanov', 'Oleksandr Pavlyk', 'Per A. Brodtkorb', 'Perry Lee', 'Robert T. McGibbon', 'Roman Feldbauer', 'Sam Lewis', 'Sam Tygier', 'Scott Sievert', 'Sebastiano Vigna', 'Stefan Peterson', 'Surhud More', 'Tadeusz Pudlik', '拓也 大嶋']",2020,Nature Methods,Journal,,261-272,17,3,10.1038/s41592-019-0686-2,"SciPy is an open-source scientific computing library for the Python programming language. Since its initial release in 2001, SciPy has become a de facto standard for leveraging scientific algorithms in Python, with over 600 unique code contributors, thousands of dependent packages, over 100,000 dependent repositories and millions of downloads per year. In this work, we provide an overview of the capabilities and development practices of SciPy 1.0 and highlight some recent technical developments.","['Python (programming language)', 'Computer science', 'Algorithm', 'Programming language']","scipy, scientific computing, python programming language, scipy, scientific algorithms, python, scipy, [PAD], [PAD] [PAD]"
Paper_01260,Fast and accurate long-read alignment with Burrows–Wheeler transform,"['Heng Li', 'Richard Durbin']",2010,Bioinformatics,Journal,,589-595,26,5,10.1093/bioinformatics/btp698,"Abstract Motivation: Many programs for aligning short sequencing reads to a reference genome have been developed in the last 2 years. Most of them are very efficient for short reads but inefficient or not applicable for reads &amp;gt;200 bp because the algorithms are heavily and specifically tuned for short queries with low sequencing error rate. However, some sequencing platforms already produce longer reads and others are expected to become available soon. For longer reads, hashing-based software such as BLAT and SSAHA2 remain the only choices. Nonetheless, these methods are substantially slower than short-read aligners in terms of aligned bases per unit time. Results: We designed and implemented a new algorithm, Burrows-Wheeler Aligner's Smith-Waterman Alignment (BWA-SW), to align long sequences up to 1 Mb against a large sequence database (e.g. the human genome) with a few gigabytes of memory. The algorithm is as accurate as SSAHA2, more accurate than BLAT, and is several to tens of times faster than both. Availability: http://bio-bwa.sourceforge.net Contact: rd@sanger.ac.uk","['Computer science', 'Software', 'Hash function', 'Sanger sequencing', 'Hash table', 'Sequence (biology)', 'Reference genome', 'DNA sequencing', 'Operating system', 'Biology', 'Genetics', 'Programming language', 'DNA']","reference genome, sequencing error rate, blat, ssaha2, human genome, ##aha, ##lat"
Paper_01261,Estimation of the number of nucleotide substitutions in the control region of mitochondrial DNA in humans and chimpanzees.,"['Koichiro Tamura', 'M Nei']",1993,Molecular Biology and Evolution,Journal,,,,,10.1093/oxfordjournals.molbev.a040023,"Examining the pattern of nucleotide substitution for the control region of mitochondrial DNA (mtDNA) in humans and chimpanzees, we developed a new mathematical method for estimating the number of transitional and transversional substitutions per site, as well as the total number of nucleotide substitutions. In this method, excess transitions, unequal nucleotide frequencies, and variation of substitution rate among different sites are all taken into account. Application of this method to human and chimpanzee data suggested that the transition/transversion ratio for the entire control region was approximately 15 and nearly the same for the two species. The 95% confidence interval of the age of the common ancestral mtDNA was estimated to be 80,000-480,000 years in humans and 0.57-2.72 Myr in common chimpanzees.","['Transversion', 'Biology', 'Mitochondrial DNA', 'mtDNA control region', 'Genetics', 'Nucleotide', 'Transition (genetics)', 'Substitution (logic)', 'Evolutionary biology', 'Molecular clock', 'Phylogenetics', 'Mutation', 'Gene', 'Haplotype', 'Genotype', 'Computer science', 'Programming language']","nucleotide substitution, mitochondrial dna, ##dna, chimp, transversional substitutions, nucleotide substitutions, excess transitions, unequal nucleotide frequencies, common chimpanzee, [PAD]"
Paper_01262,Book: Crossing the Quality Chasm: A New Health System for the 21st Century,['Alexi Baker'],2001,BMJ,Journal,,1192-1192,323,7322,10.1136/bmj.323.7322.1192,"Institute of Medicine National Academy Press, $44.95, pp 364 ISBN 0 309 07280 8 See http://www.nap.edu/catalog/10027.html for ordering details Rating: ![Graphic][1]</img> ![Graphic][2]</img> ![Graphic][3]</img> ![Graphic][4]</img> Even with catchy titles, committee reports are unlikely bestsellers. This one has the background and intention to be different. The committee members, who were appointed by the US National Academy of Science for their creative thinking and knowledge of medicine, healthcare, and commerce, provide excellently researched evidence for the failure of the US healthcare system. They justify radical change and establish six aims and 10 simple rules for a completely different … [1]: /embed/inline-graphic-1.gif [2]: /embed/inline-graphic-2.gif [3]: /embed/inline-graphic-3.gif [4]: /embed/inline-graphic-4.gif","['IMG', 'Computer science', 'Library science', 'Operating system']",us
Paper_01263,<i>WinGX</i>and<i>ORTEP for Windows</i>: an update,['Louis J. Farrugia'],2012,Journal of Applied Crystallography,Journal,,849-854,45,4,10.1107/s0021889812029111,"The WinGX suite provides a complete set of programs for the treatment of small-molecule single-crystal diffraction data, from data reduction and processing, structure solution, model refinement and visualization, and metric analysis of molecular geometry and crystal packing, to final report preparation in the form of a CIF. It includes several well known pieces of software and provides a repository for programs when the original authors no longer wish to, or are unable to, maintain them. It also provides menu items to execute external software, such as the SIR and SHELX suites of programs. The program ORTEP for Windows provides a graphical user interface (GUI) for the classic ORTEP program, which is the original software for the illustration of anisotropic displacement ellipsoids. The GUI code provides input capabilities for a wide variety of file formats, and extra functionality such as geometry calculations and ray-traced outputs. The programs WinGX and ORTEP for Windows have been distributed over the internet for about 15 years, and this article describes some of the more modern features of the programs.","['Computer science', 'Software', 'Graphical user interface', 'Computer graphics (images)', 'Suite', 'Visualization', 'Variety (cybernetics)', 'Set (abstract data type)', 'Interface (matter)', 'Computational science', 'Source code', 'Programming language', 'Code (set theory)', 'Software versioning', 'Operating system', 'Data mining', 'Archaeology', 'Bubble', 'Artificial intelligence', 'Maximum bubble pressure method', 'History']","wingx, data reduction, structure solution, model refinement, visualization, metric analysis, molecular geometry, crystal packing, final report preparation, cif, shelx, windows, graphical user interface, ortep, anisotropic displacement ellipsoids, geometry calculations, wingx, ortep"
Paper_01264,"REACTIVE OXYGEN SPECIES: Metabolism, Oxidative Stress, and Signal Transduction","['Klaus Apel', 'Heribert Hirt']",2004,Annual Review of Plant Biology,Journal,,373-399,55,1,10.1146/annurev.arplant.55.031903.141701,"Several reactive oxygen species (ROS) are continuously produced in plants as byproducts of aerobic metabolism. Depending on the nature of the ROS species, some are highly toxic and rapidly detoxified by various cellular enzymatic and nonenzymatic mechanisms. Whereas plants are surfeited with mechanisms to combat increased ROS levels during abiotic stress conditions, in other circumstances plants appear to purposefully generate ROS as signaling molecules to control various processes including pathogen defense, programmed cell death, and stomatal behavior. This review describes the mechanisms of ROS generation and removal in plants during development and under biotic and abiotic stress conditions. New insights into the complexity and roles that ROS play in plants have come from genetic analyses of ROS detoxifying and signaling mutants. Considering recent ROS-induced genome-wide expression analyses, the possible functions and mechanisms for ROS sensing and signaling in plants are compared with those in animals and yeast.","['Reactive oxygen species', 'Abiotic component', 'Signal transduction', 'Cell biology', 'Oxidative stress', 'Abiotic stress', 'Biology', 'Cell signaling', 'Metabolism', 'Biochemistry', 'Chemistry', 'Ecology', 'Gene']","reactive oxygen species, aerobic metabolism, ##nzymatic, abiotic stress conditions, pathogen defense, programmed cell death, stomatal behavior, ##s, genetic, signaling mutants, ##s"
Paper_01265,The Selfish Gene,['Richard Dawkins'],1976,['The Encyclopedia of Public Choice'],Unknown,,844-845,,,10.1007/978-0-306-47828-4_186,"Science need not be dull and bogged down by jargon, as Richard Dawkins proves in this entertaining look at evolution. The themes he takes up are the concepts of altruistic and selfish behaviour; the genetical definition of selfish interest; the evolution of aggressive behaviour; kinship theory; sex ratio theory; reciprocal altruism; deceit; and the natural selection of sex differences. Readership: general; students of biology, zoology, animal behaviour, psychology.","['Altruism (biology)', 'Kinship', 'Jargon', 'Natural selection', 'Reciprocal altruism', 'Sociobiology', 'Evolutionary theory', 'Psychology', 'Epistemology', 'Selection (genetic algorithm)', 'Sociology', 'Social psychology', 'Philosophy', 'Linguistics', 'Computer science', 'Anthropology', 'Artificial intelligence']","altruistic, selfish behaviour, genetical definition, selfish interest, aggressive behaviour, kinship theory, sex ratio theory, reciprocal altruism, deceit, natural selection, sex differences, zoology, animal behaviour, psychology, [PAD] [PAD], [PAD], [PAD], [PAD], [PAD] [PAD], [PAD]"
Paper_01266,Local Indicators of Spatial Association—LISA,['Luc Anselin'],1995,Geographical Analysis,Journal,,93-115,27,2,10.1111/j.1538-4632.1995.tb00338.x,"The capabilities for visualization, rapid data retrieval, and manipulation in geographic information systems (GIS) have created the need for new techniques of exploratory data analysis that focus on the “spatial” aspects of the data. The identification of local patterns of spatial association is an important concern in this respect. In this paper, I outline a new general class of local indicators of spatial association (LISA) and show how they allow for the decomposition of global indicators, such as Moran's I, into the contribution of each observation. The LISA statistics serve two purposes. On one hand, they may be interpreted as indicators of local pockets of nonstationarity, or hot spots, similar to the G i and G* i statistics of Getis and Ord (1992). On the other hand, they may be used to assess the influence of individual locations on the magnitude of the global statistic and to identify “outliers,” as in Anselin's Moran scatterplot (1993a). An initial evaluation of the properties of a LISA statistic is carried out for the local Moran, which is applied in a study of the spatial pattern of conflict for African countries and in a number of Monte Carlo simulations.","['Statistic', 'Outlier', 'Spatial analysis', 'Identification (biology)', 'Geography', 'Statistics', 'Cartography', 'Association (psychology)', 'Computer science', 'Econometrics', 'Data science', 'Mathematics', 'Remote sensing', 'Psychology', 'Botany', 'Psychotherapist', 'Biology']","visualization, rapid data retrieval, geographic information systems, gis, exploratory data analysis, spatial ”, local patterns, spatial association, local indicators, spatial association, lisa statistics, ##ty, hot, global statistic, moran scatterplot, lisa, spatial pattern of, african, monte carlo simulations"
Paper_01267,World Medical Association Declaration of Helsinki: Ethical Principles for Medical Research Involving Human Subjects,"['Rebecca J. Cook', 'Bernard M. Dickens', 'Mahmoud F. Fathalla']",2003,Oxford University Press eBooks,Unknown,,428-432,,,10.1093/acprof:oso/9780199241323.003.0025,"Abstract This chapter outlines the provisions of the World Medical Association's Declaration of Helsinki, which was developed as a statement of ethical principles to provide guidance to physicians and other participants in medical research involving human subjects. Medical research involving human subjects includes research on identifiable human material or identifiable data.","['Declaration of Helsinki', 'Declaration', 'Medical research', 'Helsinki declaration', 'Statement (logic)', 'Association (psychology)', 'Human research', 'Medical ethics', 'Informed consent', 'Engineering ethics', 'Medicine', 'Family medicine', 'Political science', 'Psychology', 'Alternative medicine', 'Law', 'Engineering', 'Pathology', 'Psychotherapist']","world medical association, ethical principles, human, medical, identifiable human material, identifiable data, [PAD], [PAD], [PAD], [PAD] [PAD] [PAD], [PAD], [PAD], [PAD], [PAD] [PAD], [PAD], [PAD], [PAD], [PAD], [PAD]"
Paper_01268,A method for estimating the probability of adverse drug reactions,"['C. A. Naranjo', 'U. Busto', 'Edward M. Sellers', 'Paul Sandor', 'Inés Ruiz', 'E A Roberts', 'E Janecek', 'C Domecq', 'D J Greenblatt']",1981,Clinical Pharmacology & Therapeutics,Journal,,239-245,30,2,10.1038/clpt.1981.154,"The estimation of the probability that a drug caused an adverse clinical event is usually based on clinical judgment. Lack of a method for establishing causality generates large between-raters and within-raters variability in assessment. Using the conventional categories and definitions of definite, probable, possible, and doubtful adverse drug reactions (ADRs), the between-raters agreement of two physicians and four pharmacists who independently assessed 63 randomly selected alleged ADRs was 38% to 63%, kappa (k, a chance-corrected index of agreement) varied from 0.21 to 0.40, and the intraclass correlation coefficient of reliability (R[est]) was 0.49. Six (testing) and 22 wk (retesting) later the same observers independently reanalyzed the 63 cases by assigning a weighted score (ADR probability scale) to each of the components that must be considered in establishing causal associations between drug(s) and adverse events (e.g., temporal sequence). The cases were randomized to minimize the influence of learning. The event was assigned a probability category from the total score. The between-raters reliability (range: percent agreement = 83% to 92%; κ = 0.69 to 0.86; r = 0.91 to 0.95; R(est) = 0.92) and within-raters reliability (range: percent agreement = 80% to 97%; κ = 0.64 to 0.95; r = 0.91 to 0.98) improved (p < 0.001). The between-raters reliability was maintained on retesting (range: r = 0.84 to 0.94; R(est) = 0.87). The between-raters reliability of three attending physicians who independently assessed 28 other prospectively collected cases of alleged ADRs was very high (range: r = 0.76 to 0.87; R(est) = 0.80). It was also shown that the ADR probability scale has consensual, content, and concurrent validity. This systematic method offers a sensitive way to monitor ADRs and may be applicable to postmarketing drug surveillance. Clinical Pharmacology and Therapeutics (1981) 30, 239–245; doi:10.1038/clpt.1981.154","['Intraclass correlation', 'Kappa', 'Reliability (semiconductor)', 'Medicine', 'Adverse effect', ""Cohen's kappa"", 'Concordance', 'Drug reaction', 'Causality (physics)', 'Statistics', 'Internal medicine', 'Drug', 'Mathematics', 'Psychometrics', 'Psychiatry', 'Power (physics)', 'Physics', 'Geometry', 'Quantum mechanics']","clinical judgment, causality, doubtful adverse drug reactions, intraclass correlation coefficient of, weighted score, ##r probability scale, causal, temporal, percent, ##r probability scale, concurrent validity, ##market, clinical pharmacology, therapeutic"
Paper_01199,Scoping studies: advancing the methodology,"['Danielle Levac', 'Heather Colquhoun', 'Kelly K. O’Brien']",2010,Implementation Science,Journal,,,5,1,10.1186/1748-5908-5-69,"Scoping studies are an increasingly popular approach to reviewing health research evidence. In 2005, Arksey and O'Malley published the first methodological framework for conducting scoping studies. While this framework provides an excellent foundation for scoping study methodology, further clarifying and enhancing this framework will help support the consistency with which authors undertake and report scoping studies and may encourage researchers and clinicians to engage in this process.We build upon our experiences conducting three scoping studies using the Arksey and O'Malley methodology to propose recommendations that clarify and enhance each stage of the framework. Recommendations include: clarifying and linking the purpose and research question (stage one); balancing feasibility with breadth and comprehensiveness of the scoping process (stage two); using an iterative team approach to selecting studies (stage three) and extracting data (stage four); incorporating a numerical summary and qualitative thematic analysis, reporting results, and considering the implications of study findings to policy, practice, or research (stage five); and incorporating consultation with stakeholders as a required knowledge translation component of scoping study methodology (stage six). Lastly, we propose additional considerations for scoping study methodology in order to support the advancement, application and relevance of scoping studies in health research.Specific recommendations to clarify and enhance this methodology are outlined for each stage of the Arksey and O'Malley framework. Continued debate and development about scoping study methodology will help to maximize the usefulness and rigor of scoping study findings within healthcare research and practice.","['Health services research', 'Knowledge translation', 'Rigour', 'Thematic analysis', 'Process (computing)', 'Management science', 'Health informatics', 'Process management', 'Relevance (law)', 'Health care', 'Qualitative research', 'Medicine', 'Health administration', 'Knowledge management', 'Computer science', 'Public health', 'Nursing', 'Engineering', 'Political science', 'Sociology', 'Social science', 'Geometry', 'Mathematics', 'Law', 'Operating system']","scoping studies, health research evidence, ##ological framework, scoping studies, scoping study methodology, iterative team, numerical summary, qualitative thematic analysis, required knowledge translation, scoping, scoping study methodology, scoping studies, health research, scoping, healthcare"
Paper_01200,Computational Electrodynamics: The Finite-Difference Time-Domain Method,['Allen Taflove'],1995,['Journal of Atmospheric and Terrestrial Physics'],Unknown,,1817-1818,58,15,10.1016/0021-9169(96)80449-1,"Part 1 Reinventing electromagnetics: background history of space-grid time-domain techniques for Maxwell's equations scaling to very large problem sizes defense applications dual-use electromagnetics technology. Part 2 The one-dimensional scalar wave equation: propagating wave solutions finite-difference approximation of the scalar wave equation dispersion relations for the one-dimensional wave equation numerical group velocity numerical stability. Part 3 Introduction to Maxwell's equations and the Yee algorithm: Maxwell's equations in three dimensions reduction to two dimensions equivalence to the wave equation in one dimension. Part 4 Numerical stability: TM mode time eigenvalue problem space eigenvalue problem extension to the full three-dimensional Yee algorithm. Part 5 Numerical dispersion: comparison with the ideal dispersion case reduction to the ideal dispersion case for special grid conditions dispersion-optimized basic Yee algorithm dispersion-optimized Yee algorithm with fourth-order accurate spatial differences. Part 6 Incident wave source conditions for free space and waveguides: requirements for the plane wave source condition the hard source total-field/scattered field formulation pure scattered field formulation choice of incident plane wave formulation. Part 7 Absorbing boundary conditions for free space and waveguides: Bayliss-Turkel scattered-wave annihilating operators Engquist-Majda one-way wave equations Higdon operator Liao extrapolation Mei-Fang superabsorption Berenger perfectly-matched layer (PML) absorbing boundary conditions for waveguides. Part 8 Near-to-far field transformation: obtaining phasor quantities via discrete fourier transformation surface equivalence theorem extension to three dimensions phasor domain. Part 9 Dispersive, nonlinear, and gain materials: linear isotropic case recursive convolution method linear gyrontropic case linear isotropic case auxiliary differential equation method, Lorentz gain media. Part 10 Local subcell models of the fine geometrical features: basis of contour-path FD-TD modelling the simplest contour-path subcell models the thin wire conformal modelling of curved surfaces the thin material sheet relativistic motion of PEC boundaries. Part 11 Explicit time-domain solution of Maxwell's equations using non-orthogonal and unstructured grids, Stephen Gedney and Faiza Lansing: nonuniform, orthogonal grids globally orthogonal global curvilinear co-ordinates irregular non-orthogonal unstructured grids analysis of printed circuit devices using the planar generalized Yee algorithm. Part 12 The body of revolution FD-TD algorithm, Thomas Jurgens and Gregory Saewert: field expansion difference equations for on-axis cells numerical stability PML absorbing boundary condition. Part 13 Modelling of electromagnetic fields in high-speed electronic circuits, Piket-May and Taflove. (part contents).","['Mathematics', 'Mathematical analysis', ""Maxwell's equations"", 'Plane wave', 'Boundary value problem', 'Wave equation', 'Perfectly matched layer', 'Electromagnetics', 'Physics', 'Optics', 'Engineering physics']","prop, ##ting, numerical dispersion, incident wave source, waveguide, absorbing boundary, ##asor, linear isotropic case recursive convolution, lorentz gain, thin wire conformal modelling, thin material sheet re"
Paper_01203,"Bevacizumab plus Irinotecan, Fluorouracil, and Leucovorin for Metastatic Colorectal Cancer","['Herbert I. Hurwitz', 'Louis Fehrenbacher', 'William Novotny', 'Thomas H. Cartwright', 'John D. Hainsworth', 'W. Heim', 'Jordan Berlin', 'Ari David Baron', 'S. Griffing', 'Eric Holmgren', 'Napoleone Ferrara', 'Gwen Fyfe', 'Beth Rogers', 'Robert W. Ross', 'Fairooz F. Kabbinavar']",2004,New England Journal of Medicine,Journal,,2335-2342,350,23,10.1056/nejmoa032691,"Bevacizumab, a monoclonal antibody against vascular endothelial growth factor, has shown promising preclinical and clinical activity against metastatic colorectal cancer, particularly in combination with chemotherapy.","['Medicine', 'Irinotecan', 'Bevacizumab', 'Fluorouracil', 'Colorectal cancer', 'Oncology', 'Internal medicine', 'Chemotherapy', 'Cancer']","bevacizuma, vascular endothelial growth factor, metastatic colorectal cancer, chemotherapy, [PAD], [PAD], [PAD], [PAD]"
Paper_01204,Returns to Buying Winners and Selling Losers: Implications for Stock Market Efficiency,"['Narasimhan Jegadeesh', 'Sheridan Titman']",1993,The Journal of Finance,Journal,,65-91,48,1,10.1111/j.1540-6261.1993.tb04702.x,"ABSTRACT This paper documents that strategies which buy stocks that have performed well in the past and sell stocks that have performed poorly in the past generate significant positive returns over 3‐to 12‐month holding periods. We find that the profitability of these strategies are not due to their systematic risk or to delayed stock price reactions to common factors. However, part of the abnormal returns generated in the first year after portfolio formation dissipates in the following two years. A similar pattern of returns around the earnings announcements of past winners and losers is also documented.","['Profitability index', 'Stock (firearms)', 'Earnings', 'Portfolio', 'Financial economics', 'Economics', 'Monetary economics', 'Business', 'Market efficiency', 'Finance', 'Mechanical engineering', 'Engineering']","holding periods, profit, stock price, portfolio formation, earnings announcements"
Paper_01207,"First-principles simulation: ideas, illustrations and the CASTEP code","['Matthew Segall', 'Philip J. D. Lindan', 'Matt Probert', 'Chris J. Pickard', 'P. J. Hasnip', 'Stewart J. Clark', 'M. C. Payne']",2002,Journal of Physics Condensed Matter,Journal,,2717-2744,14,11,10.1088/0953-8984/14/11/301,"First-principles simulation, meaning density-functional theory calculations with plane waves and pseudopotentials, has become a prized technique in condensed-matter theory. Here I look at the basics of the suject, give a brief review of the theory, examining the strengths and weaknesses of its implementation, and illustrating some of the ways simulators approach problems through a small case study. I also discuss why and how modern software design methods have been used in writing a completely new modular version of the CASTEP code.","['CASTEP', 'Modular design', 'Code (set theory)', 'Computer science', 'Meaning (existential)', 'Strengths and weaknesses', 'Density functional theory', 'Computational science', 'Programming language', 'Epistemology', 'Physics', 'Quantum mechanics', 'Set (abstract data type)', 'Philosophy']","plane waves, pseudopotentials, software design methods, castep"
Paper_01209,The ORCA program system,['Frank Neese'],2011,Wiley Interdisciplinary Reviews Computational Molecular Science,Journal,,73-78,2,1,10.1002/wcms.81,"Abstract ORCA is a general‐purpose quantum chemistry program package that features virtually all modern electronic structure methods (density functional theory, many‐body perturbation and coupled cluster theories, and multireference and semiempirical methods). It is designed with the aim of generality, extendibility, efficiency, and user friendliness. Its main field of application is larger molecules, transition metal complexes, and their spectroscopic properties. ORCA uses standard Gaussian basis functions and is fully parallelized. The article provides an overview of its current possibilities and documents its efficiency. © 2011 John Wiley &amp; Sons, Ltd. This article is categorized under: Software &gt; Quantum Chemistry","['Generality', 'Quantum chemistry', 'Coupled cluster', 'Computer science', 'Gaussian', 'Perturbation theory (quantum mechanics)', 'Electronic structure', 'Quantum', 'Field (mathematics)', 'Software', 'Computational chemistry', 'Density functional theory', 'Quantum chemical', 'Computational science', 'Theoretical computer science', 'Chemistry', 'Statistical physics', 'Molecule', 'Physics', 'Quantum mechanics', 'Mathematics', 'Programming language', 'Pure mathematics', 'Psychology', 'Supramolecular chemistry', 'Psychotherapist']","abstract orca, quantum chemistry, electronic structure methods, density functional theory, coupled cluster theories, semi, ##rical methods, ##ity, extendibility, user, larger molecules, transition metal complexes, spectroscopic properties, ##ca, gaussian basis functions, quantum chemistry"
Paper_01211,Dabigatran versus Warfarin in Patients with Atrial Fibrillation,"['Stuart J. Connolly', 'Michael D. Ezekowitz', 'Salim Yusuf', 'John W. Eikelboom', 'Jonas Oldgren', 'Amit Parekh', 'Janice Pogue', 'Paul Reilly', 'Ellison Themeles', 'Jeanne Varrone', 'Susan Wang', 'Marco Alings', 'Denis Xavier', 'Jun Zhu', 'Rafael Díaz', 'Basil S. Lewis', 'Harald Darius', 'Hans‐Christoph Diener', 'Campbell Joyner', 'Lars Wallentin']",2009,New England Journal of Medicine,Journal,,1139-1151,361,12,10.1056/nejmoa0905561,Warfarin reduces the risk of stroke in patients with atrial fibrillation but increases the risk of hemorrhage and is difficult to use. Dabigatran is a new oral direct thrombin inhibitor.,"['Dabigatran', 'Medicine', 'Warfarin', 'Atrial fibrillation', 'Stroke (engine)', 'Confidence interval', 'Anesthesia', 'Internal medicine', 'Relative risk', 'Direct thrombin inhibitor', 'Mechanical engineering', 'Engineering']","warfar, atrial fibrillation, dabigatran, oral direct thrombin inhibitor, [PAD], [PAD], [PAD] [PAD], [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD], [PAD], [PAD] [PAD], [PAD] [PAD] [PAD], [PAD], [PAD] [PAD] [PAD], [PAD] [PAD], [PAD], [PAD] [PAD], [PAD], [PAD] [PAD] [PAD] [PAD], [PAD] [PAD], [PAD], [PAD], [PAD] [PAD] [PAD], [PAD]"
Paper_01214,A comprehensive review of ZnO materials and devices,"['Ümit Özgür', 'Ya. I. Alivov', 'C. Liu', 'Ali Teke', 'M. A. Reshchikov', 'S. Doğan', 'V. Avrutin', 'S.-J. Cho', 'H. Morkoç̌']",2005,Journal of Applied Physics,Journal,,,98,4,10.1063/1.1992666,"The semiconductor ZnO has gained substantial interest in the research community in part because of its large exciton binding energy (60meV) which could lead to lasing action based on exciton recombination even above room temperature. Even though research focusing on ZnO goes back many decades, the renewed interest is fueled by availability of high-quality substrates and reports of p-type conduction and ferromagnetic behavior when doped with transitions metals, both of which remain controversial. It is this renewed interest in ZnO which forms the basis of this review. As mentioned already, ZnO is not new to the semiconductor field, with studies of its lattice parameter dating back to 1935 by Bunn [Proc. Phys. Soc. London 47, 836 (1935)], studies of its vibrational properties with Raman scattering in 1966 by Damen et al. [Phys. Rev. 142, 570 (1966)], detailed optical studies in 1954 by Mollwo [Z. Angew. Phys. 6, 257 (1954)], and its growth by chemical-vapor transport in 1970 by Galli and Coker [Appl. Phys. Lett. 16, 439 (1970)]. In terms of devices, Au Schottky barriers in 1965 by Mead [Phys. Lett. 18, 218 (1965)], demonstration of light-emitting diodes (1967) by Drapak [Semiconductors 2, 624 (1968)], in which Cu2O was used as the p-type material, metal-insulator-semiconductor structures (1974) by Minami et al. [Jpn. J. Appl. Phys. 13, 1475 (1974)], ZnO∕ZnSe n-p junctions (1975) by Tsurkan et al. [Semiconductors 6, 1183 (1975)], and Al∕Au Ohmic contacts by Brillson [J. Vac. Sci. Technol. 15, 1378 (1978)] were attained. The main obstacle to the development of ZnO has been the lack of reproducible and low-resistivity p-type ZnO, as recently discussed by Look and Claflin [Phys. Status Solidi B 241, 624 (2004)]. While ZnO already has many industrial applications owing to its piezoelectric properties and band gap in the near ultraviolet, its applications to optoelectronic devices has not yet materialized due chiefly to the lack of p-type epitaxial layers. Very high quality what used to be called whiskers and platelets, the nomenclature for which gave way to nanostructures of late, have been prepared early on and used to deduce much of the principal properties of this material, particularly in terms of optical processes. The suggestion of attainment of p-type conductivity in the last few years has rekindled the long-time, albeit dormant, fervor of exploiting this material for optoelectronic applications. The attraction can simply be attributed to the large exciton binding energy of 60meV of ZnO potentially paving the way for efficient room-temperature exciton-based emitters, and sharp transitions facilitating very low threshold semiconductor lasers. The field is also fueled by theoretical predictions and perhaps experimental confirmation of ferromagnetism at room temperature for potential spintronics applications. This review gives an in-depth discussion of the mechanical, chemical, electrical, and optical properties of ZnO in addition to the technological issues such as growth, defects, p-type doping, band-gap engineering, devices, and nanostructures.","['Semiconductor', 'Condensed matter physics', 'Ohmic contact', 'Exciton', 'Schottky diode', 'Lasing threshold', 'Materials science', 'Doping', 'Optoelectronics', 'Diode', 'Nanotechnology', 'Physics', 'Wavelength', 'Layer (electronics)']","semiconductor zno, exciton binding energy, lasing, exciton rec, ferromagne, transitions metals, vibrational properties, raman scattering, cu2o, ohmic contacts, ##lin, pie, band gap, near ultraviolet"
Paper_01215,GMRES: A Generalized Minimal Residual Algorithm for Solving Nonsymmetric Linear Systems,"['Yousef Saad', 'Martin H. Schultz']",1986,SIAM Journal on Scientific and Statistical Computing,Journal,,856-869,7,3,10.1137/0907058,"We present an iterative method for solving linear systems, which has the property of minimizing at every step the norm of the residual vector over a Krylov subspace. The algorithm is derived from the Arnoldi process for constructing an $l_2 $-orthogonal basis of Krylov subspaces. It can be considered as a generalization of Paige and Saunders’ MINRES algorithm and is theoretically equivalent to the Generalized Conjugate Residual (GCR) method and to ORTHODIR. The new algorithm presents several advantages over GCR and ORTHODIR.","['Generalized minimal residual method', 'Krylov subspace', 'Residual', 'Mathematics', 'Conjugate residual method', 'Conjugate gradient method', 'Linear subspace', 'Linear system', 'Algorithm', 'Applied mathematics', 'Orthogonalization', 'Iterative method', 'Norm (philosophy)', 'Generalization', 'Mathematical optimization', 'Computer science', 'Mathematical analysis', 'Pure mathematics', 'Gradient descent', 'Machine learning', 'Artificial neural network', 'Political science', 'Law']","iterative method, linear systems, residual vector, ##ov subspace, ##ov subspaces, minres algorithm, generalized conjugate residual, gcr, orthodir, ##cr, orthodir"
Paper_01217,The Promise of Entrepreneurship as a Field of Research,"['Scott Shane', 'S. Venkataraman']",2000,Academy of Management Review,Journal,,217-226,25,1,10.5465/amr.2000.2791611,"To date, the phenomenon of entrepreneurship has lacked a conceptual framework. In this note we draw upon previous research conducted in the different social science disciplines and applied fields of business to create a conceptual framework for the field. With this framework we explain a set of empirical phenomena and predict a set of outcomes not explained or predicted by conceptual frameworks already in existence in other fields.","['Entrepreneurship', 'Field (mathematics)', 'Conceptual framework', 'Phenomenon', 'Sociology', 'Set (abstract data type)', 'Management science', 'Conceptual model', 'Empirical research', 'Knowledge management', 'Epistemology', 'Engineering ethics', 'Social science', 'Computer science', 'Political science', 'Engineering', 'Mathematics', 'Pure mathematics', 'Law', 'Philosophy', 'Programming language']","entrepreneurship, social science, business"
Paper_01218,SWISS-MODEL: homology modelling of protein structures and complexes,"['Andrew Waterhouse', 'Martino Bertoni', 'Stefan Bienert', 'Gabriel Studer', 'Gerardo Tauriello', 'Rafal Gumienny', 'Florian Heer', 'Tjaart de Beer', 'Christine Rempfer', 'Lorenza Bordoli', 'Rosalba Lepore', 'Torsten Schwede']",2018,Nucleic Acids Research,Journal,,W296-W303,46,W1,10.1093/nar/gky427,"Homology modelling has matured into an important technique in structural biology, significantly contributing to narrowing the gap between known protein sequences and experimentally determined structures. Fully automated workflows and servers simplify and streamline the homology modelling process, also allowing users without a specific computational expertise to generate reliable protein models and have easy access to modelling results, their visualization and interpretation. Here, we present an update to the SWISS-MODEL server, which pioneered the field of automated modelling 25 years ago and been continuously further developed. Recently, its functionality has been extended to the modelling of homo- and heteromeric complexes. Starting from the amino acid sequences of the interacting proteins, both the stoichiometry and the overall structure of the complex are inferred by homology modelling. Other major improvements include the implementation of a new modelling engine, ProMod3 and the introduction a new local model quality estimation method, QMEANDisCo. SWISS-MODEL is freely available at https://swissmodel.expasy.org.","['Homology modeling', 'Workflow', 'Biology', 'Homology (biology)', 'Computational biology', 'Visualization', 'Computer science', 'Bioinformatics', 'Data mining', 'Amino acid', 'Genetics', 'Database', 'Biochemistry', 'Enzyme']","homology modelling, structural biology, homology modelling, automated modelling, amino, stoichi, homology modelling, promod3, local model quality estimation method, qmeandis, [PAD], [PAD], [PAD], [PAD], [PAD] [PAD]"
Paper_01219,"Chronic Kidney Disease and the Risks of Death, Cardiovascular Events, and Hospitalization","['Alan S. Go', 'Glenn M. Chertow', 'Dongjie Fan', 'Charles E. McCulloch', 'Chi‐yuan Hsu']",2004,New England Journal of Medicine,Journal,,1296-1305,351,13,10.1056/nejmoa041031,"End-stage renal disease substantially increases the risks of death, cardiovascular disease, and use of specialized health care, but the effects of less severe kidney dysfunction on these outcomes are less well defined.We estimated the longitudinal glomerular filtration rate (GFR) among 1,120,295 adults within a large, integrated system of health care delivery in whom serum creatinine had been measured between 1996 and 2000 and who had not undergone dialysis or kidney transplantation. We examined the multivariable association between the estimated GFR and the risks of death, cardiovascular events, and hospitalization.The median follow-up was 2.84 years, the mean age was 52 years, and 55 percent of the group were women. After adjustment, the risk of death increased as the GFR decreased below 60 ml per minute per 1.73 m2 of body-surface area: the adjusted hazard ratio for death was 1.2 with an estimated GFR of 45 to 59 ml per minute per 1.73 m2 (95 percent confidence interval, 1.1 to 1.2), 1.8 with an estimated GFR of 30 to 44 ml per minute per 1.73 m2 (95 percent confidence interval, 1.7 to 1.9), 3.2 with an estimated GFR of 15 to 29 ml per minute per 1.73 m2 (95 percent confidence interval, 3.1 to 3.4), and 5.9 with an estimated GFR of less than 15 ml per minute per 1.73 m2 (95 percent confidence interval, 5.4 to 6.5). The adjusted hazard ratio for cardiovascular events also increased inversely with the estimated GFR: 1.4 (95 percent confidence interval, 1.4 to 1.5), 2.0 (95 percent confidence interval, 1.9 to 2.1), 2.8 (95 percent confidence interval, 2.6 to 2.9), and 3.4 (95 percent confidence interval, 3.1 to 3.8), respectively. The adjusted risk of hospitalization with a reduced estimated GFR followed a similar pattern.An independent, graded association was observed between a reduced estimated GFR and the risk of death, cardiovascular events, and hospitalization in a large, community-based population. These findings highlight the clinical and public health importance of chronic renal insufficiency.","['Medicine', 'Hazard ratio', 'Renal function', 'Confidence interval', 'Kidney disease', 'Dialysis', 'Creatinine', 'Internal medicine', 'Body surface area', 'Transplantation', 'Kidney transplantation', 'Urology', 'Surgery']","cardiovascular disease, specialized health care, longitudinal glomerular filtration rate, hospital, women"
Paper_01220,The RAST Server: Rapid Annotations using Subsystems Technology,"['Ramy K. Aziz', 'Daniela Bartels', 'Aaron A. Best', 'Matthew DeJongh', 'T. Disz', 'Robert A. Edwards', 'Kevin Formsma', 'Svetlana Gerdes', 'Elizabeth M. Glass', 'Michael Kubal', 'Folker Meyer', 'Gary J. Olsen', 'Robert Olson', 'Andrei L. Osterman', 'Ross Overbeek', 'Leslie Klis McNeil', 'Daniel Paarmann', 'Tobias Paczian', 'Bruce Parrello', 'Gordon D. Pusch', 'Claudia I. Reich', 'Rick Stevens', 'Olga Vassieva', 'Veronika Vonstein', 'Andreas Wilke', 'Olga Zagnitko']",2008,BMC Genomics,Journal,,,9,1,10.1186/1471-2164-9-75,"Abstract Background The number of prokaryotic genome sequences becoming available is growing steadily and is growing faster than our ability to accurately annotate them. Description We describe a fully automated service for annotating bacterial and archaeal genomes. The service identifies protein-encoding, rRNA and tRNA genes, assigns functions to the genes, predicts which subsystems are represented in the genome, uses this information to reconstruct the metabolic network and makes the output easily downloadable for the user. In addition, the annotated genome can be browsed in an environment that supports comparative analysis with the annotated genomes maintained in the SEED environment. The service normally makes the annotated genome available within 12–24 hours of submission, but ultimately the quality of such a service will be judged in terms of accuracy, consistency, and completeness of the produced annotations. We summarize our attempts to address these issues and discuss plans for incrementally enhancing the service. Conclusion By providing accurate, rapid annotation freely to the community we have created an important community resource. The service has now been utilized by over 120 external users annotating over 350 distinct genomes.","['Annotation', 'Genome', 'Consistency (knowledge bases)', 'Computer science', 'Service (business)', 'Resource (disambiguation)', 'Biology', 'Computational biology', 'Gene Annotation', 'Genome project', 'Bacterial genome size', 'Gene', 'Genetics', 'Artificial intelligence', 'Computer network', 'Economy', 'Economics']","prokaryotic genome sequences, archaeal genomes, tr, metabolic network, comparative analysis"
Paper_01222,The rise of the network society,['Manuel Castells'],1996,Unknown,Unknown,,,,,10.1002/9781444319514,"From the Publisher:
This ambitious book is an account of the economic and social dynamics of the new age of information. Based on research in the USA, Asia, Latin America, and Europe, it aims to formulate a systematic theory of the information society which takes account of the fundamental effects of information technology on the contemporary world. 
The global economy is now characterized by the almost instantaneous flow and exchange of information, capital and cultural communication. These flows order and condition both consumption and production. The networks themselves reflect and create distinctive cultures. Both they and the traffic they carry are largely outside national regulation. Our dependence on the new modes of informational flow gives enormous power to those in a position to control them to control us. The main political arena is now the media, and the media are not politically answerable. 
Manuel Castells describes the accelerating pace of innovation and application. He examines the processes of globalization that have marginalized and now threaten to make redundant whole countries and peoples excluded from informational networks. He investigates the culture, institutions and organizations of the network enterprise and the concomitant transformation of work and employment. He points out that in the advanced economies production is now concentrated on an educated section of the population aged between 25 and 40: many economies can do without a third or more of their people. He suggests that the effect of this accelerating trend may be less mass unemployment than the extreme flexibilization of work and individualization of labor, and, in consequence, a highly segmented socialstructure. 
The author concludes by examining the effects and implications of technological change on mass media culture (the culture of real virtuality), on urban life, global politics, and the nature of time and history. Written by one of the worlds leading social thinkers and researchers The Rise of the Network Society is the first of three linked investigations of contemporary global, economic, political and social change. It is a work of outstanding penetration, originality, and importance.","['Network society', 'Globalization', 'Population', 'Information Age', 'Information society', 'Consumption (sociology)', 'Politics', 'Political science', 'Economy', 'Economic system', 'Political economy', 'Development economics', 'Economics', 'Sociology', 'Market economy', 'Social science', 'Demography', 'Law']","social dynamics, information society, information technology, global economy, capital, cultural communication, network, mass, urban life, global politics, network society"
Paper_01224,A Formal Basis for the Heuristic Determination of Minimum Cost Paths,"['Peter Hart', 'Nils J. Nilsson', 'Bertram Raphael']",1968,IEEE Transactions on Systems Science and Cybernetics,Journal,,100-107,4,2,10.1109/tssc.1968.300136,"Although the problem of determining the minimum cost path through a graph arises naturally in a number of interesting applications, there has been no underlying theory to guide the development of efficient search procedures. Moreover, there is no adequate conceptual framework within which the various ad hoc search strategies proposed to date can be compared. This paper describes how heuristic information from the problem domain can be incorporated into a formal mathematical theory of graph searching and demonstrates an optimality property of a class of search strategies.","['Computer science', 'Incremental heuristic search', 'Graph theory', 'Heuristic', 'Mathematical optimization', 'Basis (linear algebra)', 'Graph', 'Theoretical computer science', 'Bidirectional search', 'Property (philosophy)', 'Search algorithm', 'Mathematics', 'Beam search', 'Algorithm', 'Artificial intelligence', 'Philosophy', 'Epistemology', 'Combinatorics', 'Geometry']","minimum cost path, ad hoc search strategies, heuristic information, graph searching, optimality property, search strategies"
Paper_01225,Toxicity and response criteria of the Eastern Cooperative Oncology Group,"['Martin M. Oken', 'Richard H. Creech', 'Douglass C. Tormey', 'John Horton', 'Thomas E. Davis', 'Eleanor McFadden', 'Paul P. Carbone']",1982,American Journal of Clinical Oncology,Journal,,649-656,5,6,10.1097/00000421-198212000-00014,STANDARD CRITERIA FOR TOXICITY and for response to treatment are important prerequisites to the conduct of cancer trials. The Eastern Cooperative Oncology Group criteria for toxicity and response are presented to facilitate future reference and to encourage further standardization among those conducting clinical trials.,"['Medicine', 'Toxicity', 'Standardization', 'Oncology', 'Clinical trial', 'Internal medicine', 'Clinical Oncology', 'Precision oncology', 'Medical physics', 'Cancer', 'Political science', 'Law']","toxicity, cancer, eastern cooperative oncology group, toxicity"
Paper_01226,Backpropagation Applied to Handwritten Zip Code Recognition,"['Yann LeCun', 'Bernhard E. Boser', 'J. S. Denker', 'D. Henderson', 'Richard Howard', 'W. Hubbard', 'L. D. Jackel']",1989,Neural Computation,Journal,,541-551,1,4,10.1162/neco.1989.1.4.541,"The ability of learning networks to generalize can be greatly enhanced by providing constraints from the task domain. This paper demonstrates how such constraints can be integrated into a backpropagation network through the architecture of the network. This approach has been successfully applied to the recognition of handwritten zip code digits provided by the U.S. Postal Service. A single network learns the entire recognition operation, going from the normalized image of the character to the final classification.","['Backpropagation', 'Computer science', 'Code (set theory)', 'Artificial neural network', 'Artificial intelligence', 'Pattern recognition (psychology)', 'Domain (mathematical analysis)', 'Task (project management)', 'Character recognition', 'Zip code', 'Machine learning', 'Speech recognition', 'Image (mathematics)', 'Mathematics', 'Engineering', 'Database', 'Set (abstract data type)', 'Systems engineering', 'Programming language', 'Mathematical analysis']","learning networks, task domain, backpropagation network, handwritten zip code digits, postal service, normalized image, [PAD], [PAD], [PAD], [PAD] [PAD], [PAD], [PAD], [PAD], [PAD], [PAD]"
Paper_01227,A new family of mesoporous molecular sieves prepared with liquid crystal templates,"['Jeffrey S. Beck', 'J.C. Vartuli', 'Wiesław J. Roth', 'M. E. Leonowicz', 'Charles T. Kresge', 'Kirk D. Schmitt', 'Cynthia T. W. Chu', 'David H. Olson', 'E. W. Sheppard', 'S.B. McCullen', 'John B. Higgins', 'J.L. Schlenker']",1992,Journal of the American Chemical Society,Journal,,10834-10843,114,27,10.1021/ja00053a020,"ADVERTISEMENT RETURN TO ISSUEPREVarticleNEXTA new family of mesoporous molecular sieves prepared with liquid crystal templatesJ. S. Beck, J. C. Vartuli, W. J. Roth, M. E. Leonowicz, C. T. Kresge, K. D. Schmitt, C. T. W. Chu, D. H. Olson, E. W. Sheppard, S. B. McCullen, J. B. Higgins, and J. L. SchlenkerCite this: J. Am. Chem. Soc. 1992, 114, 27, 10834–10843Publication Date (Print):December 1, 1992Publication History Published online1 December 1992Published inissue 1 December 1992https://pubs.acs.org/doi/10.1021/ja00053a020https://doi.org/10.1021/ja00053a020research-articleACS PublicationsCopyright © 1992 American Chemical SocietyRequest reuse permissionsArticle Views42942Altmetric-Citations9716LEARN ABOUT THESE METRICSArticle Views are the COUNTER-compliant sum of full text article downloads since November 2008 (both PDF and HTML) across all institutions and individuals. These metrics are regularly updated to reflect usage leading up to the last few days.Citations are the number of other articles citing this article, calculated by Crossref and updated daily. Find more information about Crossref citation counts.The Altmetric Attention Score is a quantitative measure of the attention that a research article has received online. Clicking on the donut icon will load a page at altmetric.com with additional details about the score and the social media presence for the given article. Find more information on the Altmetric Attention Score and how the score is calculated. Share Add toView InAdd Full Text with ReferenceAdd Description ExportRISCitationCitation and abstractCitation and referencesMore Options Share onFacebookTwitterWechatLinked InRedditEmail Other access optionsGet e-Alertsclose Get e-Alerts","['Citation', 'Mesoporous material', 'Crystal (programming language)', 'Computer science', 'World Wide Web', 'Nanotechnology', 'Library science', 'Information retrieval', 'Chemistry', 'Materials science', 'Organic chemistry', 'Programming language', 'Catalysis']","mesoporous molecular sieves, liquid crystal templates, american chemical society, cross, ##f, altmetric attention score, social media presence, altmetric attention score, ##riscitation, abstract, ##ation, references"
Paper_01228,An interactive web-based dashboard to track COVID-19 in real time,"['Ensheng Dong', 'Hongru Du', 'Lauren Gardner']",2020,The Lancet Infectious Diseases,Journal,,533-534,20,5,10.1016/s1473-3099(20)30120-1,"In December, 2019, a local outbreak of pneumonia of initially unknown cause was detected in Wuhan (Hubei, China), and was quickly determined to be caused by a novel coronavirus,1WHOWHO statement regarding cluster of pneumonia cases in Wuhan, China.https://www.who.int/china/news/detail/09-01-2020-who-statement-regarding-cluster-of-pneumonia-cases-in-wuhan-chinaDate: Jan 9, 2020Date accessed: February 11, 2020Google Scholar namely severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2). The outbreak has since spread to every province of mainland China as well as 27 other countries and regions, with more than 70 000 confirmed cases as of Feb 17, 2020.2WHOCoronavirus disease 2019 (COVID-19) situation reports.https://www.who.int/emergencies/diseases/novel-coronavirus-2019/situation-reportsDate accessed: February 17, 2020Google Scholar In response to this ongoing public health emergency, we developed an online interactive dashboard, hosted by the Center for Systems Science and Engineering (CSSE) at Johns Hopkins University, Baltimore, MD, USA, to visualise and track reported cases of coronavirus disease 2019 (COVID-19) in real time. The dashboard, first shared publicly on Jan 22, illustrates the location and number of confirmed COVID-19 cases, deaths, and recoveries for all affected countries. It was developed to provide researchers, public health authorities, and the general public with a user-friendly tool to track the outbreak as it unfolds. All data collected and displayed are made freely available, initially through Google Sheets and now through a GitHub repository, along with the feature layers of the dashboard, which are now included in the Esri Living Atlas. The dashboard reports cases at the province level in China; at the city level in the USA, Australia, and Canada; and at the country level otherwise. During Jan 22–31, all data collection and processing were done manually, and updates were typically done twice a day, morning and night (US Eastern Time). As the outbreak evolved, the manual reporting process became unsustainable; therefore, on Feb 1, we adopted a semi-automated living data stream strategy. Our primary data source is DXY, an online platform run by members of the Chinese medical community, which aggregates local media and government reports to provide cumulative totals of COVID-19 cases in near real time at the province level in China and at the country level otherwise. Every 15 min, the cumulative case counts are updated from DXY for all provinces in China and for other affected countries and regions. For countries and regions outside mainland China (including Hong Kong, Macau, and Taiwan), we found DXY cumulative case counts to frequently lag behind other sources; we therefore manually update these case numbers throughout the day when new cases are identified. To identify new cases, we monitor various Twitter feeds, online news services, and direct communication sent through the dashboard. Before manually updating the dashboard, we confirm the case numbers with regional and local health departments, including the respective centres for disease control and prevention (CDC) of China, Taiwan, and Europe, the Hong Kong Department of Health, the Macau Government, and WHO, as well as city-level and state-level health authorities. For city-level case reports in the USA, Australia, and Canada, which we began reporting on Feb 1, we rely on the US CDC, the government of Canada, the Australian Government Department of Health, and various state or territory health authorities. All manual updates (for countries and regions outside mainland China) are coordinated by a team at Johns Hopkins University. The case data reported on the dashboard aligns with the daily Chinese CDC3Chinese Center for Disease Control and PreventionTracking the epidemic.http://weekly.chinacdc.cn/news/TrackingtheEpidemic.htmDate accessed: February 11, 2020Google Scholar and WHO situation reports2WHOCoronavirus disease 2019 (COVID-19) situation reports.https://www.who.int/emergencies/diseases/novel-coronavirus-2019/situation-reportsDate accessed: February 17, 2020Google Scholar for within and outside of mainland China, respectively (figure). Furthermore, the dashboard is particularly effective at capturing the timing of the first reported case of COVID-19 in new countries or regions (appendix). With the exception of Australia, Hong Kong, and Italy, the CSSE at Johns Hopkins University has reported newly infected countries ahead of WHO, with Hong Kong and Italy reported within hours of the corresponding WHO situation report. Given the popularity and impact of the dashboard to date, we plan to continue hosting and managing the tool throughout the entirety of the COVID-19 outbreak and to build out its capabilities to establish a standing tool to monitor and report on future outbreaks. We believe our efforts are crucial to help inform modelling efforts and control measures during the earliest stages of the outbreak. This online publication has been corrected. The corrected version first appeared at thelancet.com/infection on June 12, 2020 This online publication has been corrected. The corrected version first appeared at thelancet.com/infection on June 12, 2020 We declare no competing interests. We are grateful for the technical support from the Esri Living Atlas team and the Johns Hopkins University Applied Physics Lab. Download .pdf (.29 MB) Help with pdf files Supplementary appendix Correction to Lancet Infect Dis 2020; 20: 533–34Dong E, Du H, Gardner L. An interactive web-based dashboard to track COVID-19 in real time. Lancet Infect Dis 2020; 20: 533–34—In this Correspondence, on the y-axis of the graph in figure A, ""500"" has been corrected to ""5000"". This correction has been made to the online version as of June 12, 2020. Full-Text PDF SeroTracker: a global SARS-CoV-2 seroprevalence dashboardAs the initial phase of the COVID-19 pandemic passes its peak in many countries, serological studies are becoming increasingly important in guiding public health responses. Antibody testing is crucial for monitoring the evolution of the pandemic, providing a more complete picture of the total number of people infected with severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) than molecular diagnostic testing alone.1 All individuals with SARS-CoV-2-specific antibodies have been exposed to the virus, so antibody testing can highlight differences in past exposure between regions, demographic groups, and occupations. Full-Text PDF Mental health services in Italy during the COVID-19 outbreakAs of March 24, 2020, 63 927 confirmed cases and 6077 deaths due to coronavirus disease 2019 (COVID-19) make Italy one of the most severely affected countries of what has been defined a global pandemic by WHO.1 In Lombardy, the epicentre of the outbreak in Italy, large metropolitan hospitals in cities like Milan and Bergamo are struggling to contain an exponential growth of severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) case presentations requiring hospitalisation. Full-Text PDF An eventful 20 yearsThis issue marks 20 years of publication of The Lancet Infectious Diseases. In the issue, we publish two Reviews that reflect themes from the journal's first year of publication. The first paper published (in the April, 2001, preview issue) was a Review of the history of hand hygiene by Didier Pittet and John M Boyce. In this issue, Pittet and colleagues (with Nasim Lotfinejad as first author) return to this life-saving topic in infection control with a Review of 20 years of progress in promotion of hand hygiene. Full-Text PDF","['Dashboard', 'Coronavirus disease 2019 (COVID-19)', 'Outbreak', 'Mainland China', 'Severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2)', 'China', 'Public health', 'Track (disk drive)', '2019-20 coronavirus outbreak', 'Coronavirus', 'Fast track', 'Mainland', 'Pneumonia', 'Geography', 'Medicine', 'Computer science', 'Virology', 'Disease', 'Infectious disease (medical specialty)', 'Data science', 'Operating system', 'Nursing', 'Internal medicine', 'Archaeology', 'Surgery']","severe acute respiratory syndrome coronavirus, ##whocorona, systems science, github, esri, dxy"
Paper_01230,Bayes Factors,"['Robert E. Kass', 'Adrian E. Raftery']",1995,Journal of the American Statistical Association,Journal,,773-795,90,430,10.1080/01621459.1995.10476572,"Abstract In a 1935 paper and in his book Theory of Probability, Jeffreys developed a methodology for quantifying the evidence in favor of a scientific theory. The centerpiece was a number, now called the Bayes factor, which is the posterior odds of the null hypothesis when the prior probability on the null is one-half. Although there has been much discussion of Bayesian hypothesis testing in the context of criticism of P-values, less attention has been given to the Bayes factor as a practical tool of applied statistics. In this article we review and discuss the uses of Bayes factors in the context of five scientific applications in genetics, sports, ecology, sociology, and psychology. We emphasize the following points: •From Jeffreys' Bayesian viewpoint, the purpose of hypothesis testing is to evaluate the evidence in favor of a scientific theory.•Bayes factors offer a way of evaluating evidence in favor of a null hypothesis.•Bayes factors provide a way of incorporating external information into the evaluation of evidence about a hypothesis.•Bayes factors are very general and do not require alternative models to be nested.•Several techniques are available for computing Bayes factors, including asymptotic approximations that are easy to compute using the output from standard packages that maximize likelihoods.•In ""nonstandard"" statistical models that do not satisfy common regularity conditions, it can be technically simpler to calculate Bayes factors than to derive non-Bayesian significance tests.•The Schwarz criterion (or BIC) gives a rough approximation to the logarithm of the Bayes factor, which is easy to use and does not require evaluation of prior distributions.•When one is interested in estimation or prediction, Bayes factors may be converted to weights to be attached to various models so that a composite estimate or prediction may be obtained that takes account of structural or model uncertainty.•Algorithms have been proposed that allow model uncertainty to be taken into account when the class of models initially considered is very large.•Bayes factors are useful for guiding an evolutionary model-building process.•It is important, and feasible, to assess the sensitivity of conclusions to the prior distributions used.","[""Bayes' theorem"", 'Statistics', 'Mathematics', 'Computer science', 'Bayesian probability']","probability, scientific theory, bayes factor, posterior odds, bayesian hypothesis testing, bayes factor, bayes factors, genetics, sports, ecology, sociology, hypothesis testing, bayes factors, bayes factors, bayes factors, bayes factors, asymptotic approximations, regularity conditions, schwarz criterion, bi, bayes, prior distributions, bayes factors, composite estimate, model uncertainty, bayes factors, prior distributions, [PAD]"
Paper_01232,GSVA: gene set variation analysis for microarray and RNA-Seq data,"['Sonja Hänzelmann', 'Robert Castelo', 'Justin Guinney']",2013,BMC Bioinformatics,Journal,,,14,1,10.1186/1471-2105-14-7,"Abstract Background Gene set enrichment (GSE) analysis is a popular framework for condensing information from gene expression profiles into a pathway or signature summary. The strengths of this approach over single gene analysis include noise and dimension reduction, as well as greater biological interpretability. As molecular profiling experiments move beyond simple case-control studies, robust and flexible GSE methodologies are needed that can model pathway activity within highly heterogeneous data sets. Results To address this challenge, we introduce Gene Set Variation Analysis (GSVA), a GSE method that estimates variation of pathway activity over a sample population in an unsupervised manner. We demonstrate the robustness of GSVA in a comparison with current state of the art sample-wise enrichment methods. Further, we provide examples of its utility in differential pathway activity and survival analysis. Lastly, we show how GSVA works analogously with data from both microarray and RNA-seq experiments. Conclusions GSVA provides increased power to detect subtle pathway activity changes over a sample population in comparison to corresponding methods. While GSE methods are generally regarded as end points of a bioinformatic analysis, GSVA constitutes a starting point to build pathway-centric models of biology. Moreover, GSVA contributes to the current need of GSE methods for RNA-seq data. GSVA is an open source software package for R which forms part of the Bioconductor project and can be downloaded at http://www.bioconductor.org .","['Bioconductor', 'Interpretability', 'Microarray analysis techniques', 'Data mining', 'Robustness (evolution)', 'Gene expression profiling', 'DNA microarray', 'Computational biology', 'Computer science', 'Significance analysis of microarrays', 'Population', 'Biology', 'Gene', 'Gene expression', 'Genetics', 'Artificial intelligence', 'Demography', 'Sociology']","abstract background gene set enrichment, gene expression profiles, single gene analysis, noise, dimension reduction, biological interpretability, molecular profiling, gene set variation analysis, gsva, gsva, differential pathway activity, survival analysis, gsva, gsva, gsva, gsva, gsva, bioconductor"
Paper_01233,Proximal Policy Optimization Algorithms,"['John Schulman', 'Filip Wolski', 'Prafulla Dhariwal', 'Alec Radford', 'Oleg Klimov']",2017,arXiv (Cornell University),Unknown,,,,,10.48550/arxiv.1707.06347,"We propose a new family of policy gradient methods for reinforcement learning, which alternate between sampling data through interaction with the environment, and optimizing a ""surrogate"" objective function using stochastic gradient ascent. Whereas standard policy gradient methods perform one gradient update per data sample, we propose a novel objective function that enables multiple epochs of minibatch updates. The new methods, which we call proximal policy optimization (PPO), have some of the benefits of trust region policy optimization (TRPO), but they are much simpler to implement, more general, and have better sample complexity (empirically). Our experiments test PPO on a collection of benchmark tasks, including simulated robotic locomotion and Atari game playing, and we show that PPO outperforms other online policy gradient methods, and overall strikes a favorable balance between sample complexity, simplicity, and wall-time.","['Computer science', 'Optimization algorithm', 'Algorithm', 'Mathematical optimization', 'Mathematics']","policy gradient methods, reinforcement learning, stochastic gradient ascent, policy gradient methods, objective function, ##ch, proximal policy optimization, trust region policy optimization, ##o, simulated robotic locomotion, atari game playing, ppo, online policy gradient methods, [PAD], [PAD], [PAD] [PAD], [PAD] [PAD] [PAD] [PAD]"
Paper_01235,The Evolution of Reciprocal Altruism,['Robert Trivers'],1971,The Quarterly Review of Biology,Journal,,35-57,46,1,10.1086/406755,"A model is presented to account for the natural selection of what is termed reciprocally altruistic behavior. The model shows how selection can operate against the cheater (non-reciprocator) in the system. Three instances of altruistic behavior are discussed, the evolution of which the model can explain: (1) behavior involved in cleaning symbioses; (2) warning cries in birds; and (3) human reciprocal altruism. Regarding human reciprocal altruism, it is shown that the details of the psychological system that regulates this altruism can be explained by the model. Specifically, friendship, dislike, moralistic aggression, gratitude, sympathy, trust, suspicion, trustworthiness, aspects of guilt, and some forms of dishonesty and hypocrisy can be explained as important adaptations to regulate the altruistic system. Each individual human is seen as possessing altruistic and cheating tendencies, the expression of which is sensitive to developmental variables that were selected to set the tendencies at a balance appropriate to the local social and ecological environment.","['Altruism (biology)', 'Social psychology', 'Psychology', 'Reciprocal altruism', 'Sympathy', 'Dishonesty', 'Strong reciprocity', 'Gratitude', 'Cheating', 'Reciprocal', 'Reciprocity (cultural anthropology)', 'Embarrassment', 'Economics', 'Game theory', 'Microeconomics', 'Linguistics', 'Philosophy', 'Repeated game']","natural selection, reciprocally altruistic behavior, altruistic behavior, cleaning symbioses, warning cries, birds, human reciprocal altruism, human reciprocal altruism, friendship, dislike, moralistic aggression, gratitude, sympathy, trust, suspicion, trustworthiness, guilt, dishonesty, hypocrisy, cheating tendencies, developmental, [PAD] [PAD] [PAD] [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD] [PAD] [PAD], [PAD] [PAD]"
Paper_01236,"Thinking, Fast and Slow",['Daniel Kahneman'],2011,['Common Knowledge'],Unknown,,139-140,20,1,10.1215/0961754x-2374961,"Buku terlaris New York Times
Pemenang Penghargaan Buku Terbaik Akademi Sains Nasional pada tahun 2012
Dipilih oleh New York Times Book Review sebagai salah satu dari sepuluh buku terbaik tahun 2011
A Globe and Mail Judul Buku Terbaik Tahun 2011
Salah Satu Buku The Economist tahun 2011
Salah Satu Buku Nonfiksi Terbaik The Wall Street Journal of the Year 2011
2013 Presidential Medal of Freedom Recipient
Pekerjaan Kahneman dengan Amos Tversky adalah subyek dari Proyek Undoing Michael Lewis: Persahabatan yang Mengubah Pikiran Kita

Dalam buku terlaris internasional, Berpikir, Cepat, dan Lambat, Daniel Kahneman, psikolog terkenal dan pemenang Hadiah Nobel dalam Ekonomi, membawa kita pada perjalanan pemikiran yang inovatif dan menjelaskan dua sistem yang mendorong cara kita berpikir. Sistem 1 cepat, intuitif, dan emosional; Sistem 2 lebih lambat, lebih deliberatif, dan lebih logis. Dampak dari terlalu percaya pada strategi perusahaan, kesulitan memprediksi apa yang akan membuat kita bahagia di masa depan, efek mendalam dari bias kognitif dalam segala hal mulai dari bermain pasar saham hingga merencanakan liburan kita berikutnya ― masing-masing dapat dipahami hanya dengan mengetahui bagaimana kedua sistem tersebut membentuk penilaian dan keputusan kami.

Melibatkan pembaca dalam percakapan yang hidup tentang bagaimana kita berpikir, Kahneman mengungkapkan di mana kita bisa dan tidak dapat mempercayai intuisi kita dan bagaimana kita dapat memanfaatkan manfaat dari pemikiran yang lambat. Dia menawarkan wawasan praktis dan mencerahkan tentang bagaimana pilihan dibuat baik dalam bisnis kita dan kehidupan pribadi kita ― dan bagaimana kita dapat menggunakan teknik yang berbeda untuk menjaga gangguan mental yang sering membawa kita ke dalam masalah. Pemenang Penghargaan Buku Terbaik Akademi Sains Nasional dan Hadiah Buku Los Angeles Times dan dipilih oleh The New York Times Book Review sebagai salah satu dari sepuluh buku terbaik tahun 2011, Berpikir, Cepat dan Lambat ditakdirkan menjadi klasik.","['Humanities', 'Mathematics', 'Art']",
Paper_01237,Official Methods of Analysis of AOAC International,"['William Horwitz', 'GEORGE W. LATIMER']",2006,Unknown,Unknown,,,,1,10.1093/9780197610145.001.0001,"Official methods of analysis of AOAC International , Official methods of analysis of AOAC International , مرکز فناوری اطلاعات و اطلاع رسانی کشاورزی",['Political science'],"aoac, aoac, [PAD] [PAD]"
Paper_01238,Minimap2: pairwise alignment for nucleotide sequences,['Heng Li'],2018,Bioinformatics,Journal,,3094-3100,34,18,10.1093/bioinformatics/bty191,"Motivation: Recent advances in sequencing technologies promise ultra-long reads of $\sim$100 kilo bases (kb) in average, full-length mRNA or cDNA reads in high throughput and genomic contigs over 100 mega bases (Mb) in length. Existing alignment programs are unable or inefficient to process such data at scale, which presses for the development of new alignment algorithms. Results: Minimap2 is a general-purpose alignment program to map DNA or long mRNA sequences against a large reference database. It works with accurate short reads of $\ge$100bp in length, $\ge$1kb genomic reads at error rate $\sim$15%, full-length noisy Direct RNA or cDNA reads, and assembly contigs or closely related full chromosomes of hundreds of megabases in length. Minimap2 does split-read alignment, employs concave gap cost for long insertions and deletions (INDELs) and introduces new heuristics to reduce spurious alignments. It is 3-4 times faster than mainstream short-read mappers at comparable accuracy and $\ge$30 times faster at higher accuracy for both genomic and mRNA reads, surpassing most aligners specialized in one type of alignment. Availability and implementation: https://github.com/lh3/minimap2 Contact: hengli@broadinstitute.org","['Pairwise comparison', 'Nucleotide', 'Multiple sequence alignment', 'Sequence alignment', 'Computational biology', 'Computer science', 'Genetics', 'Biology', 'Artificial intelligence', 'Gene', 'Peptide sequence']","sequencing technologies, gen, minimap, ##na, minimap, concave gap cost, ##uri, ##p"
Paper_01239,"A Theory of Fairness, Competition, and Cooperation","['Ernst Fehr', 'Klaus M. Schmidt']",1999,The Quarterly Journal of Economics,Journal,,817-868,114,3,10.1162/003355399556151,"There is strong evidence that people exploit their bargaining power in competitive markets but not in bilateral bargaining situations. There is also strong evidence that people exploit free-riding opportunities in voluntary cooperation games. Yet, when they are given the opportunity to punish free riders, stable cooperation is maintained, although punishment is costly for those who punish. This paper asks whether there is a simple common principle that can explain this puzzling evidence. We show that if some people care about equity the puzzles can be resolved. It turns out that the economic environment determines whether the fair types or the selfish types dominate equilibrium behavior.","['Exploit', 'Economics', 'Punishment (psychology)', 'Microeconomics', 'Equity (law)', 'Bargaining power', 'Simple (philosophy)', 'Competition (biology)', 'Free riding', 'Inequity aversion', 'Inequality', 'Social psychology', 'Law', 'Psychology', 'Biology', 'Philosophy', 'Mathematical analysis', 'Computer security', 'Mathematics', 'Epistemology', 'Incentive', 'Computer science', 'Political science', 'Ecology']","bargaining power, competitive markets, bilateral bargaining situations, voluntary cooperation games, stable cooperation, fair, selfish, [PAD] [PAD] [PAD]"
Paper_01244,Large-Area Synthesis of High-Quality and Uniform Graphene Films on Copper Foils,"['Xuesong Li', 'Weiwei Cai', 'Jinho An', 'Seyoung Kim', 'Junghyo Nah', 'Dongxing Yang', 'Richard D. Piner', 'Aruna Velamakanni', 'Inhwa Jung', 'Emanuel Tutuc', 'Sanjay K. Banerjee', 'Luigi Colombo', 'Rodney S. Ruoff']",2009,Science,Journal,,1312-1314,324,5932,10.1126/science.1171245,"Graphene has been attracting great interest because of its distinctive band structure and physical properties. Today, graphene is limited to small sizes because it is produced mostly by exfoliating graphite. We grew large-area graphene films of the order of centimeters on copper substrates by chemical vapor deposition using methane. The films are predominantly single-layer graphene, with a small percentage (less than 5%) of the area having few layers, and are continuous across copper surface steps and grain boundaries. The low solubility of carbon in copper appears to help make this growth process self-limiting. We also developed graphene film transfer processes to arbitrary substrates, and dual-gated field-effect transistors fabricated on silicon/silicon dioxide substrates showed electron mobilities as high as 4050 square centimeters per volt per second at room temperature.","['Graphene', 'Materials science', 'Graphite', 'Chemical vapor deposition', 'Copper', 'Silicon', 'Nanotechnology', 'Layer (electronics)', 'Graphene oxide paper', 'Optoelectronics', 'Chemical engineering', 'Composite material', 'Metallurgy', 'Engineering']","graphene, band structure, graph, ##folia, copper substrates, chemical vapor deposition, methane, copper surface steps, grain boundaries, sol, graphene film transfer processes, electron mobilities"
Paper_01245,"Cancer statistics, 2012","['Rebecca L. Siegel', 'Deepa Naishadham', 'Ahmedin Jemal']",2012,CA A Cancer Journal for Clinicians,Journal,,10-29,62,1,10.3322/caac.20138,"Abstract Each year, the American Cancer Society estimates the numbers of new cancer cases and deaths expected in the United States in the current year and compiles the most recent data on cancer incidence, mortality, and survival based on incidence data from the National Cancer Institute, the Centers for Disease Control and Prevention, and the North American Association of Central Cancer Registries and mortality data from the National Center for Health Statistics. A total of 1,638,910 new cancer cases and 577,190 deaths from cancer are projected to occur in the United States in 2012. During the most recent 5 years for which there are data (2004‐2008), overall cancer incidence rates declined slightly in men (by 0.6% per year) and were stable in women, while cancer death rates decreased by 1.8% per year in men and by 1.6% per year in women. Over the past 10 years of available data (1999‐2008), cancer death rates have declined by more than 1% per year in men and women of every racial/ethnic group with the exception of American Indians/Alaska Natives, among whom rates have remained stable. The most rapid declines in death rates occurred among African American and Hispanic men (2.4% and 2.3% per year, respectively). Death rates continue to decline for all 4 major cancer sites (lung, colorectum, breast, and prostate), with lung cancer accounting for almost 40% of the total decline in men and breast cancer accounting for 34% of the total decline in women. The reduction in overall cancer death rates since 1990 in men and 1991 in women translates to the avoidance of about 1,024,400 deaths from cancer. Further progress can be accelerated by applying existing cancer control knowledge across all segments of the population, with an emphasis on those groups in the lowest socioeconomic bracket. CA Cancer J Clin 2012. © 2012 American Cancer Society.","['Medicine', 'Demography', 'Cancer', 'Breast cancer', 'Lung cancer', 'Incidence (geometry)', 'Prostate cancer', 'Mortality rate', 'Cause of death', 'Cancer registry', 'Disease', 'Gerontology', 'Internal medicine', 'Physics', 'Sociology', 'Optics']","american cancer society, central cancer registries, women, women, cancer, cancer control, american cancer society"
Paper_01246,Effects of Configuration Interaction on Intensities and Phase Shifts,['U. Fano'],1961,Physical Review,Journal,,1866-1878,124,6,10.1103/physrev.124.1866,"The interference of a discrete autoionized state with a continuum gives rise to characteristically asymmetric peaks in excitation spectra. The earlier qualitative interpretation of this phenomenon is extended and revised. A theoretical formula is fitted to the shape of the $2s2p^{1}P$ resonance of He observed in the inelastic scattering of electrons. The fitting determines the parameters of the $2s2p^{1}P$ resonance as follows: $E=60.1$ ev, $\ensuremath{\Gamma}\ensuremath{\sim}0.04$ ev, $f\ensuremath{\sim}2 \mathrm{to} 4\ifmmode\times\else\texttimes\fi{}{10}^{\ensuremath{-}3}$. The theory is extended to the interaction of one discrete level with two or more continua and of a set of discrete levels with one continuum. The theory can also give the position and intensity shifts produced in a Rydberg series of discrete levels by interaction with a level of another configuration. The connection with the nuclear theory of resonance scattering is indicated.","['Physics', 'Atomic physics', 'Rydberg formula', 'Resonance (particle physics)', 'Excitation', 'Inelastic scattering', 'Spectral line', 'Scattering', 'Configuration interaction', 'Electron', 'Connection (principal bundle)', 'Quantum mechanics', 'Ionization', 'Excited state', 'Ion', 'Structural engineering', 'Engineering']","discrete autoionized state, continuum, ##ally asymmetric peaks, excitation spectra, inelastic scattering, intensity shifts, rydberg series, nuclear theory, resonance scattering, [PAD], [PAD], [PAD]"
Paper_01248,Food Security: The Challenge of Feeding 9 Billion People,"['Hubert Charles', 'J. R. Beddington', 'I. R. Crute', 'Lawrence Haddad', 'David P. Lawrence', 'James Muir', 'Jules Pretty', 'Sherman Robinson', 'Sandy M Thomas', 'Camilla Toulmin']",2010,Science,Journal,,812-818,327,5967,10.1126/science.1185383,"Continuing population and consumption growth will mean that the global demand for food will increase for at least another 40 years. Growing competition for land, water, and energy, in addition to the overexploitation of fisheries, will affect our ability to produce food, as will the urgent requirement to reduce the impact of the food system on the environment. The effects of climate change are a further threat. But the world can produce more food and can ensure that it is used more efficiently and equitably. A multifaceted and linked global strategy is needed to ensure sustainable and equitable food security, different components of which are explored here.","['Food security', 'Overexploitation', 'Natural resource economics', 'Business', 'Climate change', 'Food systems', 'Population', 'Population growth', 'Consumption (sociology)', 'Agricultural economics', 'Environmental resource management', 'Development economics', 'Economics', 'Environmental health', 'Agriculture', 'Fishery', 'Ecology', 'Biology', 'Medicine', 'Social science', 'Sociology']",climate change
Paper_01249,A Statistical Distribution Function of Wide Applicability,['Waloddi Weibull'],1951,Journal of Applied Mechanics,Journal,,293-297,18,3,10.1115/1.4010337,Abstract This paper discusses the applicability of statistics to a wide field of problems. Examples of simple and complex distributions are given.,"['Simple (philosophy)', 'Statistical physics', 'Computer science', 'Field (mathematics)', 'Distribution (mathematics)', 'Function (biology)', 'Distribution function', 'Applied mathematics', 'Calculus (dental)', 'Mathematics', 'Mathematical analysis', 'Physics', 'Thermodynamics', 'Medicine', 'Philosophy', 'Dentistry', 'Epistemology', 'Pure mathematics', 'Evolutionary biology', 'Biology']",statistics
Paper_01251,Kinetics of Phase Change. I General Theory,['Melvin Avrami'],1939,The Journal of Chemical Physics,Journal,,1103-1112,7,12,10.1063/1.1750380,"The theory of the kinetics of phase change is developed with the experimentally supported assumptions that the new phase is nucleated by germ nuclei which already exist in the old phase, and whose number can be altered by previous treatment. The density of germ nuclei diminishes through activation of some of them to become growth nuclei for grains of the new phase, and ingestion of others by these growing grains. The quantitative relations between the density of germ nuclei, growth nuclei, and transformed volume are derived and expressed in terms of a characteristic time scale for any given substance and process. The geometry and kinetics of a crystal aggregate are studied from this point of view, and it is shown that there is strong evidence of the existence, for any given substance, of an isokinetic range of temperatures and concentrations in which the characteristic kinetics of phase change remains the same. The determination of phase reaction kinetics is shown to depend upon the solution of a functional equation of a certain type. Some of the general properties of temperature-time and transformation-time curves, respectively, are described and explained.","['Kinetics', 'Phase (matter)', 'Thermodynamics', 'Chemistry', 'Range (aeronautics)', 'Volume (thermodynamics)', 'Transformation (genetics)', 'Chemical physics', 'Materials science', 'Physics', 'Classical mechanics', 'Organic chemistry', 'Composite material', 'Biochemistry', 'Gene']","phase change, germ nuclei, ge, growth nuclei, growth nuclei, transformed volume, characteristic time scale, crystal aggregate, isokinetic range, phase reaction kinetics, functional equation"
Paper_01252,Neural Networks for Pattern Recognition,['Chris Bishop'],1995,Oxford University Press eBooks,Unknown,,,,,10.1093/oso/9780198538493.001.0001,"Abstract This book provides the first comprehensive treatment of feed-forward neural networks from the perspective of statistical pattern recognition. After introducing the basic concepts of pattern recognition, the book describes techniques for modelling probability density functions, and discusses the properties and relative merits of the multi-layer perceptron and radial basis function network models. It also motivates the use of various forms of error functions, and reviews the principal algorithms for error function minimization. As well as providing a detailed discussion of learning and generalization in neural networks, the book also covers the important topics of data processing, feature extraction, and prior knowledge. The book concludes with an extensive treatment of Bayesian techniques and their applications to neural networks.","['Computer science', 'Artificial neural network', 'Artificial intelligence', 'Generalization', 'Perceptron', 'Bayesian probability', 'Feature (linguistics)', 'Perspective (graphical)', 'Principal (computer security)', 'Pattern recognition (psychology)', 'Machine learning', 'Function (biology)', 'Minification', 'Mathematics', 'Mathematical analysis', 'Linguistics', 'Philosophy', 'Evolutionary biology', 'Biology', 'Programming language', 'Operating system']","statistical pattern recognition, pattern, probability density functions, radial basis function network models, error functions, error function minimization, neural networks, data processing, feature extraction, prior knowledge, bayesian techniques, neural networks, [PAD] [PAD], [PAD]"
Paper_01253,Statistical Methods for Meta-Analysis,"['Stanley Wasserman', 'Larry V. Hedges', 'Ingram Olkin']",1988,Journal of Educational Statistics,Journal,,75-75,13,1,10.2307/1164953,Preface. Introduction. Data Sets. Tests of Statistical Significance of Combined Results. Vote-Counting Methods. Estimation of a Single Effect Size: Parametric and Nonparametric Methods. Parametric Estimation of Effect Size from a Series of Experiments. Fitting Parametric Fixed Effect Models to Effect Sizes: Categorical Methods. Fitting Parametric Fixed Effect Models to Effect Sizes: General Linear Models. Random Effects Models for Effect Sizes. Multivariate Models for Effect Sizes. Combining Estimates of Correlation Coefficients. Diagnostic Procedures for Research Synthesis Models. Clustering Estimates of Effect Magnitude. Estimation of Effect Size When Not All Study Outcomes Are Observed. Meta-Analysis in the Physical and Biological Sciences. Appendix. References. Index.,"['Nonparametric statistics', 'Random effects model', 'Statistics', 'Parametric statistics', 'Categorical variable', 'Multivariate statistics', 'Mathematics', 'Cluster analysis', 'Econometrics', 'Parametric model', 'Estimation', 'Series (stratigraphy)', 'Sample size determination', 'Meta-analysis', 'Medicine', 'Paleontology', 'Management', 'Internal medicine', 'Economics', 'Biology']","statistical significance, single effect size, nonparametric, parametric estimation, effect size, parametric fixed effect models, categorical methods, parametric fixed effect models, general, random effects models, multivariate models, correlation coefficients, diagnostic procedures, research synthesis models, clustering estimates, effect magnitude, [PAD] [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD] [PAD], [PAD], [PAD], [PAD]"
Paper_01254,Gene expression patterns of breast carcinomas distinguish tumor subclasses with clinical implications,"['Thérese Sørlie', 'Charles M. Perou', 'Robert Tibshirani', 'Turid Aas', 'Stephanie Geisler', 'Hilde Johnsen', 'Trevor Hastie', 'Michael B. Eisen', 'Matt van de Rijn', 'Stefanie S. Jeffrey', 'Thor Thorsen', 'H. Quist', 'John C. Matese', 'Patrick O. Brown', 'David Botstein', 'Per Eystein Lønning', 'Anne‐Lise Børresen‐Dale']",2001,Proceedings of the National Academy of Sciences,Journal,,10869-10874,98,19,10.1073/pnas.191367098,"The purpose of this study was to classify breast carcinomas based on variations in gene expression patterns derived from cDNA microarrays and to correlate tumor characteristics to clinical outcome. A total of 85 cDNA microarray experiments representing 78 cancers, three fibroadenomas, and four normal breast tissues were analyzed by hierarchical clustering. As reported previously, the cancers could be classified into a basal epithelial-like group, an ERBB2 -overexpressing group and a normal breast-like group based on variations in gene expression. A novel finding was that the previously characterized luminal epithelial/estrogen receptor-positive group could be divided into at least two subgroups, each with a distinctive expression profile. These subtypes proved to be reasonably robust by clustering using two different gene sets: first, a set of 456 cDNA clones previously selected to reflect intrinsic properties of the tumors and, second, a gene set that highly correlated with patient outcome. Survival analyses on a subcohort of patients with locally advanced breast cancer uniformly treated in a prospective study showed significantly different outcomes for the patients belonging to the various groups, including a poor prognosis for the basal-like subtype and a significant difference in outcome for the two estrogen receptor-positive groups.","['Breast cancer', 'Biology', 'Complementary DNA', 'Microarray', 'Gene expression', 'Estrogen receptor', 'DNA microarray', 'Basal (medicine)', 'Gene', 'Tissue microarray', 'Breast carcinoma', 'Gene expression profiling', 'Cancer', 'Fibroadenoma', 'Microarray analysis techniques', 'Oncology', 'Internal medicine', 'Cancer research', 'Pathology', 'Medicine', 'Genetics', 'Endocrinology', 'Insulin']","breast carcinomas, gene expression patterns, cdna microarrays, tumor characteristics, cdna micro, normal breast tissues, hierarchical clustering, cdna, survival analyses"
Paper_01255,The Need for a New Medical Model: A Challenge for Biomedicine,['George L. Engel'],1977,Science,Journal,,129-136,196,4286,10.1126/science.847460,"The dominant model of disease today is biomedical, and it leaves no room within its framework for the social, psychological, and behavioral dimensions of illness. A biopsychosocial model is proposed that provides a blueprint for research, a framework for teaching, and a design for action in the real world of health care.","['Biopsychosocial model', 'Blueprint', 'Biomedicine', 'Action (physics)', 'Health care', 'Medical care', 'Psychology', 'Management science', 'Cognitive science', 'Computer science', 'Psychotherapist', 'Medicine', 'Engineering', 'Nursing', 'Political science', 'Bioinformatics', 'Mechanical engineering', 'Physics', 'Quantum mechanics', 'Law', 'Biology']","biomedical, biopsychosocial model, health, [PAD] [PAD] [PAD], [PAD] [PAD], [PAD] [PAD]"
Paper_01256,Finite Element Procedures,['Klaus‐Jürgen Bathe'],1995,"['Computational Fluid and Solid Mechanics', 'Discontinuous Finite Elements in Fluid Dynamics and Heat Transfer']",Unknown,,21-43,,,10.1007/1-84628-205-5_2,"1. An Introduction to the Use of Finite Element Procedures. 2. Vectors, Matrices and Tensors. 3. Some Basic Concepts of Engineering Analysis and an Introduction to the Finite Element Methods. 4. Formulation of the Finite Element Method -- Linear Analysis in Solid and Structural Mechanics. 5. Formulation and Calculation of Isoparametric Finite Element Matrices. 6. Finite Element Nonlinear Analysis in Solid and Structural Mechanics. 7. Finite Element Analysis of Heat Transfer, Field Problems, and Incompressible Fluid Flows. 8. Solution of Equilibrium Equations in State Analysis. 9. Solution of Equilibrium Equations in Dynamic Analysis. 10. Preliminaries to the Solution of Eigenproblems. 11. Solution Methods for Eigenproblems. 12. Implementation of the Finite Element Method. References. Index.","['Finite element method', 'Extended finite element method', 'Smoothed finite element method', 'Mixed finite element method', 'Finite element limit analysis', 'hp-FEM', 'Mathematics', 'Pressure-correction method', 'Boundary knot method', 'Nonlinear system', 'Applied mathematics', 'Mathematical analysis', 'Physics', 'Thermodynamics', 'Boundary element method', 'Quantum mechanics']","finite element procedures, matrices, tensors, engineering analysis, finite element methods, finite, linear analysis, structural mechanics, isoparametric finite element matrices, finite element nonlinear analysis, structural mechanics, finite element analysis, heat transfer, field problems, incompressible fluid flows, equilibrium equations, state analysis, equilibrium equations, dynamic analysis, eigen, ##blems, solution methods, eigenproblems, finite element method"
Paper_01257,Self-Organizing Maps,['Teuvo Kohonen'],1995,"['Series in Electrical and Computer Engineering', 'Neural Networks and Computing']",Unknown,,173-211,,,10.1142/9781860949692_0005,"The Self-Organising Map (SOM) algorithm was introduced by the author in 1981. Its theory and many applications form one of the major approaches to the contemporary artificial neural networks field, and new technologies have already been based on it. The most important practical applications are in exploratory data analysis, pattern recognition, speech analysis, robotics, industrial and medical diagnostics, instrumentation, and control, and literally hundreds of other tasks. In this monograph the mathematical preliminaries, background, basic ideas, and implications are expounded in a manner which is accessible without prior expert knowledge.","['Artificial intelligence', 'Field (mathematics)', 'Computer science', 'Robotics', 'Artificial neural network', 'Self-organizing map', 'Instrumentation (computer programming)', 'Expert system', 'Data science', 'Robot', 'Mathematics', 'Pure mathematics', 'Operating system']","artificial neural networks, exploratory data analysis, pattern recognition, speech analysis, robotics, medical diagnostics, instrumentation, control"
Paper_01258,An index to quantify an individual's scientific research output,['J. E. Hirsch'],2005,Proceedings of the National Academy of Sciences,Journal,,16569-16572,102,46,10.1073/pnas.0507655102,"I propose the index h, defined as the number of papers with citation number > or =h, as a useful index to characterize the scientific output of a researcher.","['Index (typography)', 'Computer science', 'Statistics', 'Information retrieval', 'Data science', 'Mathematics', 'World Wide Web']",citation number
Paper_01259,Linear Statistical Inference and its Applications,['C. Radhakrishna Rao'],1973,Wiley series in probability and statistics,Unknown,,,,,10.1002/9780470316436,"Algebra of Vectors and Matrices. Probability Theory, Tools and Techniques. Continuous Probability Models. The Theory of Least Squares and Analysis of Variance. Criteria and Methods of Estimation. Large Sample Theory and Methods. Theory of Statistical Inference. Multivariate Analysis. Publications of the Author. Author Index. Subject Index.","['Statistical inference', 'Inference', 'Computer science', 'Econometrics', 'Mathematics', 'Statistics', 'Artificial intelligence']","probability, continuous probability models, least squares, analysis, variance, large sample theory, statistical inference, multivariate analysis, [PAD], [PAD], [PAD] [PAD], [PAD], [PAD] [PAD], [PAD], [PAD] [PAD], [PAD] [PAD], [PAD], [PAD] [PAD]"
Paper_01261,Plastic waste inputs from land into the ocean,"['Jenna Jambeck', 'Roland Geyer', 'Chris Wilcox', 'Theodore R. Siegler', 'Miriam Elaine Perryman', 'Anthony L. Andrady', 'Ramáni Narayan', 'Kara Lavender Law']",2015,Science,Journal,,768-771,347,6223,10.1126/science.1260352,"Plastic debris in the marine environment is widely documented, but the quantity of plastic entering the ocean from waste generated on land is unknown. By linking worldwide data on solid waste, population density, and economic status, we estimated the mass of land-based plastic waste entering the ocean. We calculate that 275 million metric tons (MT) of plastic waste was generated in 192 coastal countries in 2010, with 4.8 to 12.7 million MT entering the ocean. Population size and the quality of waste management systems largely determine which countries contribute the greatest mass of uncaptured waste available to become plastic marine debris. Without waste management infrastructure improvements, the cumulative quantity of plastic waste available to enter the ocean from land is predicted to increase by an order of magnitude by 2025.","['Plastic waste', 'Environmental science', 'Debris', 'Tonne', 'Waste management', 'Population', 'Municipal solid waste', 'Environmental engineering', 'Meteorology', 'Geography', 'Engineering', 'Demography', 'Sociology']","plastic debris, solid waste, population density, economic status, plastic waste, waste management, plastic"
Paper_01262,The chemistry of graphene oxide,"['Daniel R. Dreyer', 'Sungjin Park', 'Christopher W. Bielawski', 'Rodney S. Ruoff']",2009,Chemical Society Reviews,Journal,,228-240,39,1,10.1039/b917103g,"The chemistry of graphene oxide is discussed in this critical review. Particular emphasis is directed toward the synthesis of graphene oxide, as well as its structure. Graphene oxide as a substrate for a variety of chemical transformations, including its reduction to graphene-like materials, is also discussed. This review will be of value to synthetic chemists interested in this emerging field of materials science, as well as those investigating applications of graphene who would find a more thorough treatment of the chemistry of graphene oxide useful in understanding the scope and limitations of current approaches which utilize this material (91 references).","['Graphene', 'Oxide', 'Nanotechnology', 'Scope (computer science)', 'Materials science', 'Chemistry', 'Computer science', 'Metallurgy', 'Programming language']","graphene oxide, graphene oxide, graphene oxide, synthetic chemist, materials science, graph, graphene oxide"
Paper_01264,"Beiträge zur Optik trüber Medien, speziell kolloidaler Metallösungen",['Gustav Mie'],1908,Annalen der Physik,Journal,,377-445,330,3,10.1002/andp.19083300302,~+ 5 ) ( 2 v + 7 ) '??+ ' * ' ),"['Humanities', 'Physics', 'Engineering physics', 'Art']",
Paper_01268,Ad-hoc on-demand distance vector routing,"['Charles E. Perkins', 'E.M. Royer']",1999,Unknown,Unknown,,,,,10.1109/mcsa.1999.749281,"An ad-hoc network is the cooperative engagement of a collection of mobile nodes without the required intervention of any centralized access point or existing infrastructure. We present Ad-hoc On Demand Distance Vector Routing (AODV), a novel algorithm for the operation of such ad-hoc networks. Each mobile host operates as a specialized router, and routes are obtained as needed (i.e., on-demand) with little or no reliance on periodic advertisements. Our new routing algorithm is quite suitable for a dynamic self starting network, as required by users wishing to utilize ad-hoc networks. AODV provides loop-free routes even while repairing broken links. Because the protocol does not require global periodic routing advertisements, the demand on the overall bandwidth available to the mobile nodes is substantially less than in those protocols that do necessitate such advertisements. Nevertheless we can still maintain most of the advantages of basic distance vector routing mechanisms. We show that our algorithm scales to large populations of mobile nodes wishing to form ad-hoc networks. We also include an evaluation methodology and simulation results to verify the operation of our algorithm.","['Computer science', 'Computer network', 'Optimized Link State Routing Protocol', 'Ad hoc On-Demand Distance Vector Routing', 'Destination-Sequenced Distance Vector routing', 'Wireless Routing Protocol', 'Dynamic Source Routing', 'Distance-vector routing protocol', 'Wireless ad hoc network', 'Ad hoc wireless distribution service', 'Distributed computing', 'Adaptive quality of service multi-hop routing', 'Mobile ad hoc network', 'Link-state routing protocol', 'Routing protocol', 'Routing (electronic design automation)', 'Telecommunications', 'Wireless', 'Network packet']","cooperative, distance vector routing, aodv, dynamic self starting network, aodv, distance vector routing mechanisms, simulation, [PAD]"
Paper_01270,ON THE PRICING OF CORPORATE DEBT: THE RISK STRUCTURE OF INTEREST RATES*,['Robert C. Merton'],1974,The Journal of Finance,Journal,,449-470,29,2,10.1111/j.1540-6261.1974.tb03058.x,"The value of a particular issue of corporate debt depends essentially on three items: (1) the required rate of return on riskless (in terms of default) debt (e.g., government bonds or very high grade corporate bonds); (2) the various provisions and restrictions contained in the indenture (e.g., maturity date, coupon rate, call terms, seniority in the event of default, sinking fund, etc.); (3) the probability that the firm will be unable to satisfy some or all of the indenture requirements (i.e., the probability of default). While a number of theories and empirical studies has been published on the term structure of interest rates (item 1), there has been no systematic development of a theory for pricing bonds when there is a significant probability of default. The purpose of this paper is to present such a theory which might be called a theory of the risk structure of interest rates. The use of the term “risk” is restricted to the possible gains or losses to bondholders as a result of (unanticipated) changes in the probability of default and does not include the gains or losses inherent to all bonds caused by (unanticipated) changes in interest rates in general. Throughout most of the analysis, a given term structure is assumed and hence, the price differentials among bonds will be solely caused by differences in the probability of default. In a seminal paper, Black and Scholes 1 present a complete general equilibrium theory of option pricing which is particularly attractive because the final formula is a function of “observable” variables. Therefore, the model is subject to direct empirical tests which they 2 performed with some success. Merton 5 clarified and extended the Black-Scholes model. While options are highly specialized and relatively unimportant financial instruments, both Black and Scholes 1 and Merton 5, 6 recognized that the same basic approach could be applied in developing a pricing theory for corporate liabilities in general. In Section II of the paper, the basic equation for the pricing of financial instruments is developed along Black-Scholes lines. In Section III, the model is applied to the simplest form of corporate debt, the discount bond where no coupon payments are made, and a formula for computing the risk structure of interest rates is presented. In Section IV, comparative statics are used to develop graphs of the risk structure, and the question of whether the term premium is an adequate measure of the risk of a bond is answered. In Section V, the validity in the presence of bankruptcy of the famous Modigliani-Miller theorem 7 is proven, and the required return on debt as a function of the debt-to-equity ratio is deduced. In Section VI, the analysis is extended to include coupon and callable bonds. The dynamics for the value of the firm, V, through time can be described by a diffusion-type stochastic process with stochastic differential equation α is the instantaneous expected rate of return on the firm per unit time, C is the total dollar payouts by the firm per unit time to either its shareholders or liabilities-holders (e.g., dividends or interest payments) if positive, and it is the net dollars received by the firm from new financing if negative; σ 2 is the instantaneous variance of the return on the firm per unit time; dz is a standard Gauss-Wiener process. Many of these assumptions are not necessary for the model to obtain but are chosen for expositional convenience. In particular, the “perfect market” assumptions (A.1-A.4) can be substantially weakened. A.6 is actually proved as part of the analysis and A.7 is chosen so as to clearly distinguish risk structure from term structure effects on pricing. A.5 and A.8 are the critical assumptions. Basically, A.5 requires that the market for these securities is open for trading most of time. A.8 requires that price movements are continuous and that the (unanticipated) returns on the securities be serially independent which is consistent with the “efficient markets hypothesis” of Fama 3 and Samuelson 9.11 Of course, this assumption does not rule out serial dependence in the earnings of the firm. See Samuelson 10 for a discussion. In closing this section, it is important to note which variables and parameters appear in (7) (and hence, affect the value of the security) and which do not. In addition to the value of the firm and time, F depends on the interest rate, the volatility of the firm's value (or its business risk) as measured by the variance, the payout policy of the firm, and the promised payout policy to the holders of the security. However, F does not depend on the expected rate of return on the firm nor on the riskȁpreferences of investors nor on the characteristics of other assets available to investors beyond the three mentioned. Thus, two investors with quite different utility functions and different expectations for the company's future but who agree on the volatility of the firm's value will for a given interest rate and current firm value, agree on the value of the particular security, F. Also all the parameters and variables except the variance are directly observable and the variance can be reasonably estimated from time series data. As a specific application of the formulation of the previous section, we examine the simplest case of corporate debt pricing. Suppose the corporation has two classes of claims: (1) a single, homogenous class of debt and (2) the residual claim, equity. Suppose further that the indenture of the bond issue contains the following provisions and restrictions: (1) the firm promises to pay a total of B dollars to the bondholders on the specified calendar date T; (2) in the event this payment is not met, the bondholders immediately take over the company (and the shareholders receive nothing); (3) the firm cannot issue any new senior (or of equivalent rank) claims on the firm nor can it pay cash dividends or do share repurchase prior to the maturity of the debt. For a given maturity, the risk premium is a function of only two variables: (1) the variance (or volatility) of the firm's operations, σ 2 and (2) the ratio of the present value (at the riskless rate) of the promised payment to the current value of the firm, d. Because d is the debt-to-firm value ratio where debt is valued at the riskless rate, it is a biased upward estimate of the actual (market-value) debt-to-firm value ratio. Since Merton 5 has solved the option pricing problem when the term structure is not “flat” and is stochastic, (by again using the isomorphic correspondence between options and levered equity) we could deduce the risk structure with a stochastic term structure. The formulae (13) and (14) would be the same in this case except that we would replace “ exp [ − r τ ]” by the price of a riskless discount bond which pays one dollar at time τ in the future and “ σ 2 τ ” by a generalized variance term defined in 5. In the derivation of the fundamental equation for pricing of corporate liabilities, (7), it was assumed that the Modigliani-Miller theorem held so that the value of the firm could be treated as exogeneous to the analysis. If, for example, due to bankruptcy costs or corporate taxes, the M-M theorem does not obtain and the value of the firm does depend on the debt-equity ratio, then the formal analysis of the paper is still valid. However, the linear property of (7) would be lost, and instead, a non-linear, simultaneous solution, F = F [ V ( F ) , τ ] , would be required. Fortunately, in the absence of these imperfections, the formal hedging analysis used in Section II to deduce (7), simultaneously, stands as a proof of the M-M theorem even in the presence of bankruptcy. To see this, imagine that there are two firms identical with respect to their investment decisions, but one firm issues debt and the other does not. The investor can “create” a security with a payoff structure identical to the risky bond by following a portfolio strategy of mixing the equity of the unlevered firm with holdings of riskless debt. The correct portfolio strategy is to hold ( F v V ) dollars of the equity and ( F – F v V ) dollars of riskless bonds where V is the value of the unlevered firm, and F and F v are determined by the solution of (7). Since the value of the “manufactured” risky debt is always F, the debt issued by the other firm can never sell for more than F. In a similar fashion, one could create levered equity by a portfolio strategy of holding ( f v V ) dollars of the unlevered equity and ( f – f v V ) dollars of borrowing on margin which would have a payoff structure identical to the equity issued by the levering firm. Hence, the value of the levered firm's equity can never sell for more than f. But, by construction, f + F = V, the value of the unlevered firm. Therefore, the value of the levered firm can be no larger than the unlevered firm, and it cannot be less. Note, unlike in the analysis by Stiglitz 11, we did not require a specialized theory of capital market equilibrium (e.g., the Arrow-Debreu model or the capital asset pricing model) to prove the theorem when bankruptcy is possible. Contrary to what many might believe, the relative riskiness of the debt can decline as either the business risk of the firm or the time until maturity increases. Inspection of (33) shows that this is the case if d > 1 (i.e., the present value of the promised payment is less than the current value of the firm). To see why this result is not unreasonable, consider the following: for small T (i.e., σ 2 or τ: small), the chances that the debt will become equity through default are large, and this will be reflected in the risk characteristics of the debt through a large g. By increasing T (through an increase in σ 2 or τ), the chances are better that the firm value will increase enough to meet the promised payment. It is also true that the chances that the firm value will be lower are increased. However, remember that g is a measure of how much the risky debt behaves like equity versus debt. Since for g large, the debt is already more aptly described by equity than riskless debt. (E.g., for d > 1 , g > 1 2 and the “replicating” portfolio will contain more than half equity.) Thus, the increased probability of meeting the promised payment dominates, and g declines. For d < 1 , g will be less than a half, and the argument goes just the opposite way. In the “watershed” case when d = 1 , g equals a half; the “replicating” portfolio is exactly half equity and half riskless debt, and the two effects cancel leaving g unchanged. In closing this section, we examine a classical problem in corporate finance: given a fixed investment decision, how does the required return on debt and equity change, as alternative debt-equity mixes are chosen? Because the investment decision is assumed fixed, and the Modigliani-Miller theorem obtains, V, σ 2 , and α (the required expected return on the firm) are fixed. For simplicity, suppose that the maturity of the debt, τ, is fixed, and the promised payment at maturity per bond is $1. Then, the debt-equity mix is determined by choosing the number of bonds to be issued. Since in our previous analysis, F is the value of the whole debt issue and B is the total promised payment for the whole issue, B will be the number of bonds (promising $1 at maturity) in the current analysis, and F /B will be the price of one bond. In the usual analysis of (default-free) bonds in term structure studies, the derivation of a pricing relationship for pure discount bonds for every maturity would be sufficient because the value of a default-free coupon bond can be written as the sum of discount bonds' values weighted by the size of the coupon payment at each maturity. Unfortunately, no such simple formula exists for risky coupon bonds. The reason for this is that if the firm defaults on a coupon payment, then all subsequent coupon payments (and payments of principal) are also defaulted on. Thus, the default on one of the “mini” bonds associated with a given maturity is not independent of the event of default on the “mini” bond associated with a later maturity. However, the apparatus developed in the previous sections is sufficient to solve the coupon problem. Moreover, even for those cases where closed-form solutions cannot be found, powerful numerical integration techniques have been developed for solving equations like (7) or (41). Hence, computation and empirical testing of these pricing theories is entirely feasible. Note that in deducing (40), it was assumed that coupon payments were made uniformly and continuously. In fact, coupon payments are usually only made semi-annually or annually in discrete lumps. However, it is a simple matter to take this into account by replacing “ C ¯ ” in (40) by “ Σ i C ¯ i δ ( τ − τ i ) ” where δ( ) is the dirac delta function and τ i is the length of time until maturity when the i th coupon payment of C ¯ i dollars is made. We have developed a method for pricing corporate liabilities which is grounded in solid economic analysis, requires inputs which are on the whole observable; can be used to price almost any type of financial instrument. The method was applied to risky discount bonds to deduce a risk structure of interest rates. The Modigliani-Miller theorem was shown to obtain in the presence of bankruptcy provided that there are no differential tax benefits to corporations or transactions costs. The analysis was extended to include callable, coupon bonds.","['Bond', 'Debt', 'Economics', 'Seniority', 'Coupon', 'Interest rate', 'Financial economics', 'Bond valuation', 'Yield curve', 'Probability of default', 'Corporate bond', 'Actuarial science', 'Black–Scholes model', 'Default', 'Callable bond', 'Econometrics', 'Credit risk', 'Monetary economics', 'Finance', 'Volatility (finance)', 'Political science', 'Law']","corporate debt, government bonds, maturity date, coupon rate, call terms, sinking fund, term structure, interest rates, risk structure, interest rates, bond, interest, price differential, general equilibrium theory, option pricing, corporate liabilities, financial instruments, corporate debt, discount bond, coupon payments, interest, comparative statics"
Paper_01271,"Structure, function and diversity of the healthy human microbiome","['Curtis Huttenhower', 'Dirk Gevers', 'Rob Knight', 'Sahar Abubucker', 'Jonathan H. Badger', 'Asif Chinwalla', 'Heather H. Creasy', 'Ashlee M. Earl', 'Michael G. FitzGerald', 'Robert S. Fulton', 'Michelle Giglio', 'Kymberlie Hallsworth-Pepin', 'Elizabeth A. Lobos', 'Ramana Madupu', 'Vincent Magrini', 'John Martin', 'Makedonka Mitreva', 'Donna M. Muzny', 'Erica Sodergren', 'James Versalovic', 'Aye Wollam', 'Kim C. Worley', 'Jennifer R. Wortman', 'Sarah Young', 'Qiandong Zeng', 'Kjersti M. Aagaard', 'Olukemi O. Abolude', 'Emma Allen‐Vercoe', 'Eric J. Alm', 'Lucia Alvarado', 'Gary L. Andersen', 'Scott Anderson', 'Elizabeth L. Appelbaum', 'Harindra Arachchi', 'Gary C. Armitage', 'Cesar Arze', 'Tulin Ayvaz', 'Carl C. Baker', 'Lisa Begg', 'Tsegahiwot Belachew', 'Veena Bhonagiri', 'Monika Bihan', 'Martin J. Blaser', 'Toby Bloom', 'Vivien Bonazzi', 'J. Paul Brooks', 'Gregory A. Buck', 'Christian Buhay', 'Dana Busam', 'Joseph L. Campbell', 'Shane R. Canon', 'Brandi L. Cantarel', 'Patrick Chain', 'I.-Min A. Chen', 'Lei Chen', 'Shaila Chhibba', 'Ken Chu', 'Dawn Ciulla', 'José C. Clemente', 'Sandra W. Clifton', 'Sean Conlan', 'Jonathan Crabtree', 'Mary A. Cutting', 'Noam J. Davidovics', 'Catherine Davis', 'Todd Z. DeSantis', 'Carolyn Deal', 'Kimberley D. Delehaunty', 'Floyd E. Dewhirst', 'Elena Deych', 'Yan Ding', 'David J. Dooling', 'Shannon Dugan', 'W. Michael Dunne', 'A. Scott Durkin', 'R. C. Edgar', 'Rachel Erlich', 'Candace N. Farmer', 'Ruth M. Farrell', 'Karoline Faust', 'Michael Feldgarden', 'Victor Felix', 'Sheila Fisher', 'Anthony A. Fodor', 'Larry J. Forney', 'Leslie Foster', 'Valentina Di Francesco', 'Jonathan Friedman', 'Dennis C. Friedrich', 'Catrina C. Fronick', 'Lucinda Fulton', 'Hongyu Gao', 'M. Nathalia Garcia', 'Georgia Giannoukos', 'Christina Giblin', 'Maria Y. Giovanni', 'Jonathan M. Goldberg', 'Johannes B. Goll', 'Antonio González', 'Allison Griggs']",2012,Nature,Journal,,207-214,486,7402,10.1038/nature11234,"Studies of the human microbiome have revealed that even healthy individuals differ remarkably in the microbes that occupy habitats such as the gut, skin and vagina. Much of this diversity remains unexplained, although diet, environment, host genetics and early microbial exposure have all been implicated. Accordingly, to characterize the ecology of human-associated microbial communities, the Human Microbiome Project has analysed the largest cohort and set of distinct, clinically relevant body habitats so far. We found the diversity and abundance of each habitat's signature microbes to vary widely even among healthy subjects, with strong niche specialization both within and among individuals. The project encountered an estimated 81–99% of the genera, enzyme families and community configurations occupied by the healthy Western microbiome. Metagenomic carriage of metabolic pathways was stable among individuals despite variation in community structure, and ethnic/racial background proved to be one of the strongest associations of both pathways and microbes with clinical metadata. These results thus delineate the range of structural and functional configurations normal in the microbial communities of a healthy population, enabling future characterization of the epidemiology, ecology and translational applications of the human microbiome. The Human Microbiome Project Consortium reports the first results of their analysis of microbial communities from distinct, clinically relevant body habitats in a human cohort; the insights into the microbial communities of a healthy population lay foundations for future exploration of the epidemiology, ecology and translational applications of the human microbiome. The Human Microbiome Project (HMP), supported by the National Institutes of Health Common Fund, has the goal of characterizing the microbial communities that inhabit and interact with the human body in sickness and in health. In two Articles in this issue of Nature, the HMP Consortium presents the first population-scale details of the organismal and functional composition of the microbiota across five areas of the body. An associated News & Views discusses the initial results — which, along with those of a series of co-publications, already constitute the most extensive catalogue of organisms and genes related to the human microbiome yet published — and highlights some of the major questions that the project will tackle in the next few years.","['Microbiome', 'Metagenomics', 'Biology', 'Ecology', 'Human Microbiome Project', 'Niche', 'Human microbiome', 'Community', 'Population', 'Habitat', 'Microbial ecology', 'Evolutionary biology', 'Genetics', 'Medicine', 'Environmental health', 'Gene', 'Bacteria']","human microbiome, healthy, host genetics, early microbial exposure, human microbiome, ##omic, clinical, human microbiome, ##p"
Paper_01274,Estimating Standard Errors in Finance Panel Data Sets: Comparing Approaches,['Mitchell A. Petersen'],2008,Review of Financial Studies,Journal,,435-480,22,1,10.1093/rfs/hhn053,"Journal Article Estimating Standard Errors in Finance Panel Data Sets: Comparing Approaches Get access Mitchell A. Petersen Mitchell A. Petersen Search for other works by this author on: Oxford Academic Google Scholar The Review of Financial Studies, Volume 22, Issue 1, January 2009, Pages 435–480, https://doi.org/10.1093/rfs/hhn053 Published: 03 June 2008","['Econometrics', 'Intuition', 'Panel data', 'Economics', 'Standard error', 'Corporate finance', 'Asset (computer security)', 'Capital asset pricing model', 'Actuarial science', 'Computer science', 'Finance', 'Statistics', 'Mathematics', 'Philosophy', 'Computer security', 'Epistemology']","standard errors, finance panel data sets, financial studies"
Paper_01275,Statistical Comparisons of Classifiers over Multiple Data Sets,['Janez Demšar'],2006,"['Lecture Notes in Computer Science', 'Neural Information Processing']",Journal,,548-555,7,1,10.1007/978-3-319-12640-1_66,"While methods for comparing two learning algorithms on a single data set have been scrutinized for quite some time already, the issue of statistical tests for comparisons of more algorithms on multiple data sets, which is even more essential to typical machine learning studies, has been all but ignored. This article reviews the current practice and then theoretically and empirically examines several suitable tests. Based on that, we recommend a set of simple, yet safe and robust non-parametric tests for statistical comparisons of classifiers: the Wilcoxon signed ranks test for comparison of two classifiers and the Friedman test with the corresponding post-hoc tests for comparison of more classifiers over multiple data sets. Results of the latter can also be neatly presented with the newly introduced CD (critical difference) diagrams.","['Computer science', 'Statistical hypothesis testing', 'Wilcoxon signed-rank test', 'Machine learning', 'Artificial intelligence', 'Data set', 'Multiple comparisons problem', 'Set (abstract data type)', 'Parametric statistics', 'Simple (philosophy)', 'Statistical learning', 'Training set', 'Post hoc', 'Data mining', 'Mathematics', 'Statistics', 'Medicine', 'Philosophy', 'Dentistry', 'Epistemology', 'Programming language', 'Mann–Whitney U test']","learning algorithms, statistical tests, machine learning, - parametric, statistical comparisons, wilcoxon signed ranks test, friedman test, critical difference"
Paper_01276,The Multidimensional Scale of Perceived Social Support,"['Gregory D. Zimet', 'Nancy Wray Dahlem', 'Sara G. Zimet', 'Gordon K. Farley']",1988,Journal of Personality Assessment,Journal,,30-41,52,1,10.1207/s15327752jpa5201_2,"Abstract The development of a self-report measure of subjectively assessed social support, the Multidimensional Scale of Perceived Social Support (MSPSS), is described. Subjects included 136 female and 139 male university undergraduates. Three subscales, each addressing a different source of support, were identified and found to have strong factorial validity: (a) Family, (b) Friends, and (c) Significant Other. In addition, the research demonstrated that the MSPSS has good internal and test-retest reliability as well as moderate construct validity. As predicted, high levels of perceived social support were associated with low levels of depression and anxiety symptomatology as measured by the Hopkins Symptom Checklist. Gender differences with respect to the MSPSS are also presented. The value of the MSPSS as a research instrument is discussed, along with implications for future research.","['Psychology', 'Social support', 'Checklist', 'Reliability (semiconductor)', 'Clinical psychology', 'Construct validity', 'Test validity', 'Psychometrics', 'Scale (ratio)', 'Anxiety', 'Social anxiety', 'Developmental psychology', 'Social psychology', 'Psychiatry', 'Physics', 'Quantum mechanics', 'Power (physics)', 'Cognitive psychology']","subjective, multidimensional scale of perceived social support, mspss, university undergraduates, factorial validity, anxiety symptomatology, hopkins symptom checklist, gender differences, mspss"
Paper_01278,pROC: an open-source package for R and S+ to analyze and compare ROC curves,"['Xavier Robin', 'Natacha Turck', 'Alexandre Hainard', 'Natalia Tiberti', 'Frédérique Lisacek', 'Jean-Charles Sanchez', 'Markus Müller']",2011,BMC Bioinformatics,Journal,,,12,1,10.1186/1471-2105-12-77,"Receiver operating characteristic (ROC) curves are useful tools to evaluate classifiers in biomedical and bioinformatics applications. However, conclusions are often reached through inconsistent use or insufficient statistical analysis. To support researchers in their ROC curves analysis we developed pROC, a package for R and S+ that contains a set of tools displaying, analyzing, smoothing and comparing ROC curves in a user-friendly, object-oriented and flexible interface. With data previously imported into the R or S+ environment, the pROC package builds ROC curves and includes functions for computing confidence intervals, statistical tests for comparing total or partial area under the curve or the operating points of different classifiers, and methods for smoothing ROC curves. Intermediary and final results are visualised in user-friendly interfaces. A case study based on published clinical and biomarker data shows how to perform a typical ROC analysis with pROC. pROC is a package for R and S+ specifically dedicated to ROC analysis. It proposes multiple statistical tests to compare ROC curves, and in particular partial areas under the curve, allowing proper ROC interpretation. pROC is available in two versions: in the R programming language or with a graphical user interface in the S+ statistical software. It is accessible at http://expasy.org/tools/pROC/ under the GNU General Public License. It is also distributed through the CRAN and CSAN public repositories, facilitating its installation.","['Receiver operating characteristic', 'Computer science', 'Graphical user interface', 'Software', 'R package', 'Data mining', 'Smoothing', 'Interface (matter)', 'Cutoff', 'Machine learning', 'Artificial intelligence', 'Pattern recognition (psychology)', 'Operating system', 'Programming language', 'Computer vision', 'Physics', 'Bubble', 'Quantum mechanics', 'Maximum bubble pressure method']","receiver operating characteristic, classifiers, bioinformatics, statistical analysis, roc curves, proc, roc, proc, roc, confidence intervals, statistical tests, proc, roc, statistical tests, proc, graphical, ##an, [PAD], [PAD], [PAD], [PAD]"
Paper_01279,"Exploration, normalization, and summaries of high density oligonucleotide array probe level data","['Rafael A. Irizarry', 'Bridget G. Hobbs', 'François Collin', 'Yasmin Beazer-Barclay', 'Kristen J Antonellis', 'Uwe Scherf', 'Terence P. Speed']",2003,Biostatistics,Journal,,249-264,4,2,10.1093/biostatistics/4.2.249,"In this paper we report exploratory analyses of high‐density oligonucleotide array data from the Affymetrix GeneChip® system with the objective of improving upon currently used measures of gene expression. Our analyses make use of three data sets: a small experimental study consisting of five MGU74A mouse GeneChip® arrays, part of the data from an extensive spike‐in study conducted by Gene Logic and Wyeth's Genetics Institute involving 95 HG‐U95A human GeneChip® arrays; and part of a dilution study conducted by Gene Logic involving 75 HG‐U95A GeneChip® arrays. We display some familiar features of the perfect match and mismatch probe (PM and MM) values of these data, and examine the variance–mean relationship with probe‐level data from probes believed to be defective, and so delivering noise only. We explain why we need to normalize the arrays to one another using probe level intensities. We then examine the behavior of the PM and MM using spike‐in data and assess three commonly used summary measures: Affymetrix's (i) average difference (AvDiff) and (ii) MAS 5.0 signal, and (iii) the Li and Wong multiplicative model‐based expression index (MBEI). The exploratory data analyses of the probe level data motivate a new summary measure that is a robust multi‐array average (RMA) of background‐adjusted, normalized, and log‐transformed PM values. We evaluate the four expression summary measures using the dilution study data, assessing their behavior in terms of bias, variance and (for MBEI and RMA) model fit. Finally, we evaluate the algorithms in terms of their ability to detect known levels of differential expression using the spike‐in data. We conclude that there is no obvious downside to using RMA and attaching a standard error (SE) to this quantity using a linear model which removes probe‐specific affinities.","['Gene chip analysis', 'Normalization (sociology)', 'Multiplicative function', 'Computer science', 'Variance (accounting)', 'Data mining', 'Statistics', 'Mathematics', 'DNA microarray', 'Biology', 'Genetics', 'Gene expression', 'Gene', 'Mathematical analysis', 'Business', 'Accounting', 'Sociology', 'Anthropology']","high ‐ density oligonucleotide array data, affymetrix, gene expression, mouse, gene logic, gene logic, perfect, mismatch probe, probe level intensities, spike ‐, affy, ##rix, average difference, robust multi ‐ array average, dilution, differential expression, spike, linear model, ##fin"
Paper_01283,Matrix Factorization Techniques for Recommender Systems,"['Yehuda Koren', 'Robert Bell', 'Chris Volinsky']",2009,Computer,Journal,,30-37,42,8,10.1109/mc.2009.263,"As the Netflix Prize competition has demonstrated, matrix factorization models are superior to classic nearest neighbor techniques for producing product recommendations, allowing the incorporation of additional information such as implicit feedback, temporal effects, and confidence levels.","['Recommender system', 'Computer science', 'Matrix decomposition', 'Factorization', 'Product (mathematics)', 'Matrix (chemical analysis)', 'Non-negative matrix factorization', 'Artificial intelligence', 'Information retrieval', 'Theoretical computer science', 'Algorithm', 'Mathematics', 'Eigenvalues and eigenvectors', 'Physics', 'Materials science', 'Quantum mechanics', 'Composite material', 'Geometry']","netflix, matrix factorization models, nearest neighbor techniques, product recommendations, implicit feedback, temporal effects, confidence levels, [PAD], [PAD] [PAD] [PAD] [PAD] [PAD], [PAD], [PAD] [PAD], [PAD] [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD], [PAD], [PAD], [PAD] [PAD] [PAD] [PAD], [PAD] [PAD]"
Paper_01285,Job Burnout,"['Christina Maslach', 'Wilmar B. Schaufeli', 'Michael P. Leiter']",2001,Annual Review of Psychology,Journal,,397-422,52,1,10.1146/annurev.psych.52.1.397,"▪ Abstract Burnout is a prolonged response to chronic emotional and interpersonal stressors on the job, and is defined by the three dimensions of exhaustion, cynicism, and inefficacy. The past 25 years of research has established the complexity of the construct, and places the individual stress experience within a larger organizational context of people's relation to their work. Recently, the work on burnout has expanded internationally and has led to new conceptual models. The focus on engagement, the positive antithesis of burnout, promises to yield new perspectives on interventions to alleviate burnout. The social focus of burnout, the solid research basis concerning the syndrome, and its specific ties to the work domain make a distinct and valuable contribution to people's health and well-being.","['Burnout', 'Cynicism', 'Psychology', 'Emotional exhaustion', 'Social psychology', 'Stressor', 'Context (archaeology)', 'Interpersonal communication', 'Job satisfaction', 'Psychological intervention', 'Applied psychology', 'Clinical psychology', 'Psychiatry', 'Paleontology', 'Politics', 'Political science', 'Law', 'Biology']","abstract burnout, interpersonal stressors, exhaustion, cynicism, inefficacy, individual stress experience, burnout, engagement, burnout, burn"
Paper_01286,Agency Problems and the Theory of the Firm,['Eugene F. Fama'],1980,Journal of Political Economy,Journal,,288-307,88,2,10.1086/260866,"This paper attempts to explain how the separation of security ownership and control, typical of large corporations, can be an efficient form of economic organization. We first set aside the presumption that a corporation has owners in any meaningful sense. The entrepreneur is also laid to rest, at least for the purposes of the large modern corporation. The two functions usually attributed to the entrepreneur--management and risk bearing--are treated as naturally separate factors within the set of contracts called a firm. The firm is disciplined by competition from other firms, which forces the evolution of devides for efficiently monitoring the performance of the entire team and of its individual members. Individual participants in the firm, and in particular its managers, face both the discipline and opportunities provided by the markets for their services, both within and outside the firm.","['Presumption', 'Corporation', 'Competition (biology)', 'Theory of the firm', 'Business', 'Agency (philosophy)', 'Aside', 'Principal–agent problem', 'Set (abstract data type)', 'Control (management)', 'Face (sociological concept)', 'Capital call', 'Industrial organization', 'Rest (music)', 'Agency cost', 'Economics', 'Market economy', 'Finance', 'Management', 'Law', 'Corporate governance', 'Shareholder', 'Sociology', 'Art', 'Human capital', 'Ecology', 'Literature', 'Computer science', 'Biology', 'Financial capital', 'Political science', 'Cardiology', 'Programming language', 'Medicine', 'Individual capital', 'Social science']","security ownership, large corporations, economic organization, risk bearing"
Paper_01287,Sarcopenia: European consensus on definition and diagnosis,"['Alfonso J. Cruz‐Jentoft', 'Jean‐Pierre Baeyens', 'Jürgen M. Bauer', 'Yves Boirie\u200c', 'Tommy Cederholm', 'Francesco Landi', 'Finbarr C. Martin', 'Jean‐Pierre Michel', 'Yves Rolland', 'S. Schneider', 'Eva Topinková', 'M. Vandewoude', 'Mauro Zamboni']",2010,Age and Ageing,Journal,,412-423,39,4,10.1093/ageing/afq034,"Abstract The European Working Group on Sarcopenia in Older People (EWGSOP) developed a practical clinical definition and consensus diagnostic criteria for age-related sarcopenia. EWGSOP included representatives from four participant organisations, i.e. the European Geriatric Medicine Society, the European Society for Clinical Nutrition and Metabolism, the International Association of Gerontology and Geriatrics—European Region and the International Association of Nutrition and Aging. These organisations endorsed the findings in the final document. The group met and addressed the following questions, using the medical literature to build evidence-based answers: (i) What is sarcopenia? (ii) What parameters define sarcopenia? (iii) What variables reflect these parameters, and what measurement tools and cut-off points can be used? (iv) How does sarcopenia relate to cachexia, frailty and sarcopenic obesity? For the diagnosis of sarcopenia, EWGSOP recommends using the presence of both low muscle mass + low muscle function (strength or performance). EWGSOP variously applies these characteristics to further define conceptual stages as ‘presarcopenia’, ‘sarcopenia’ and ‘severe sarcopenia’. EWGSOP reviewed a wide range of tools that can be used to measure the specific variables of muscle mass, muscle strength and physical performance. Our paper summarises currently available data defining sarcopenia cut-off points by age and gender; suggests an algorithm for sarcopenia case finding in older individuals based on measurements of gait speed, grip strength and muscle mass; and presents a list of suggested primary and secondary outcome domains for research. Once an operational definition of sarcopenia is adopted and included in the mainstream of comprehensive geriatric assessment, the next steps are to define the natural course of sarcopenia and to develop and define effective treatment.","['Sarcopenia', 'Medicine', 'Geriatrics', 'Sarcopenic obesity', 'Gerontology', 'Grip strength', 'Muscle mass', 'Physical medicine and rehabilitation', 'Physical therapy', 'Internal medicine', 'Psychiatry']","sarcopenia, older people, ewgsop, clinical definition, consensus diagnostic criteria, ##wgsop, european geriatric medicine society, clinical nutrition, sar, sarcope, sarcopenia, cachexia, frailty, sarcopenic obesity, sar, ##sop, low, ##wgsop, presarcopenia, ‘ sarcopenia, severe sarcopenia, ##sop, sar, sar, gait speed, grip strength, muscle mass, sar, ##nia, comprehensive geriatric assessment, sarcope"
Paper_01288,The SAGE handbook of qualitative research,"['Norman K. Denzin', 'Yvonna S. Lincoln']",2005,Choice Reviews Online,Journal,,43-1330,43,03,10.5860/choice.43-1330,"Publie anterieurement sous le titre : Handbook of qualitative research, 1994 Comprend des references bibliographiques Comprend un index","['SAGE', 'Sociology', 'Library science', 'History', 'Computer science', 'Nuclear physics', 'Physics']","anterie, qualitative research, ##bl, [PAD] [PAD], [PAD], [PAD]"
Paper_01290,Google Earth Engine: Planetary-scale geospatial analysis for everyone,"['Noel Gorelick', 'M. Hancher', 'Mike Dixon', 'Simon Ilyushchenko', 'David Thau', 'Rebecca Moore']",2017,Remote Sensing of Environment,Journal,,18-27,202,,10.1016/j.rse.2017.06.031,"Google Earth Engine is a cloud-based platform for planetary-scale geospatial analysis that brings Google's massive computational capabilities to bear on a variety of high-impact societal issues including deforestation, drought, disaster, disease, food security, water management, climate monitoring and environmental protection. It is unique in the field as an integrated platform designed to empower not only traditional remote sensing scientists, but also a much wider audience that lacks the technical capacity needed to utilize traditional supercomputers or large-scale commodity cloud computing resources.","['Geospatial analysis', 'Cloud computing', 'Scale (ratio)', 'Remote sensing', 'Earth observation', 'Variety (cybernetics)', 'Deforestation (computer science)', 'Computer science', 'Field (mathematics)', 'Data science', 'Earth science', 'Geography', 'Engineering', 'Satellite', 'Geology', 'Cartography', 'Mathematics', 'Aerospace engineering', 'Artificial intelligence', 'Pure mathematics', 'Programming language', 'Operating system']","google, def, food security, water management, climate monitoring, environmental protection"
Paper_01291,Functional Porous Coordination Polymers,"['Susumu Kitagawa', 'Ryo Kitaura', 'Shin‐ichiro Noro']",2004,Angewandte Chemie International Edition,Journal,,2334-2375,43,18,10.1002/anie.200300610,"The chemistry of the coordination polymers has in recent years advanced extensively, affording various architectures, which are constructed from a variety of molecular building blocks with different interactions between them. The next challenge is the chemical and physical functionalization of these architectures, through the porous properties of the frameworks. This review concentrates on three aspects of coordination polymers: 1). the use of crystal engineering to construct porous frameworks from connectors and linkers (""nanospace engineering""), 2). characterizing and cataloging the porous properties by functions for storage, exchange, separation, etc., and 3). the next generation of porous functions based on dynamic crystal transformations caused by guest molecules or physical stimuli. Our aim is to present the state of the art chemistry and physics of and in the micropores of porous coordination polymers.","['Porosity', 'Polymer', 'Crystal engineering', 'Porous medium', 'Nanotechnology', 'Materials science', 'Molecule', 'Chemistry', 'Organic chemistry', 'Supramolecular chemistry', 'Composite material']","coordination polymers, molecular building blocks, porous properties, coordination polymers, crystal engineering, porous frameworks, link, nanospace engineering, por, por, dynamic crystal transformations, micropore, porous coordination polymers"
Paper_01292,An application-specific protocol architecture for wireless microsensor networks,"['Wendi Heinzelman', 'Anantha P. Chandrakasan', 'Hari Balakrishnan']",2002,IEEE Transactions on Wireless Communications,Journal,,660-670,1,4,10.1109/twc.2002.804190,"Networking together hundreds or thousands of cheap microsensor nodes allows users to accurately monitor a remote environment by intelligently combining the data from the individual nodes. These networks require robust wireless communication protocols that are energy efficient and provide low latency. We develop and analyze low-energy adaptive clustering hierarchy (LEACH), a protocol architecture for microsensor networks that combines the ideas of energy-efficient cluster-based routing and media access together with application-specific data aggregation to achieve good performance in terms of system lifetime, latency, and application-perceived quality. LEACH includes a new, distributed cluster formation technique that enables self-organization of large numbers of nodes, algorithms for adapting clusters and rotating cluster head positions to evenly distribute the energy load among all the nodes, and techniques to enable distributed signal processing to save communication resources. Our results show that LEACH can improve system lifetime by an order of magnitude compared with general-purpose multihop approaches.","['Computer science', 'Computer network', 'Latency (audio)', 'Cluster analysis', 'Distributed computing', 'Wireless', 'Routing protocol', 'Wireless sensor network', 'Efficient energy use', 'Protocol (science)', 'Energy consumption', 'Routing (electronic design automation)', 'Telecommunications', 'Medicine', 'Alternative medicine', 'Pathology', 'Ecology', 'Machine learning', 'Electrical engineering', 'Biology', 'Engineering']","microsensor nodes, robust wireless communication protocols, low, leach, protocol architecture, microsensor networks, media access, leach, distributed cluster formation technique, rotating cluster head positions, distributed signal processing, leach"
Paper_01293,LIII. <i>On lines and planes of closest fit to systems of points in space</i>,['Karl Pearson'],1901,The London Edinburgh and Dublin Philosophical Magazine and Journal of Science,Journal,,559-572,2,11,10.1080/14786440109462720,"(1901). LIII. On lines and planes of closest fit to systems of points in space. The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science: Vol. 2, No. 11, pp. 559-572.","['Space (punctuation)', 'Geometry', 'Mathematics', 'Computer science', 'Operating system']","lines, planes, closest fit, points, space"
Paper_01295,A human gut microbial gene catalogue established by metagenomic sequencing,"['Junjie Qin', 'Ruiqiang Li', 'Jeroen Raes', 'Manimozhiyan Arumugam', 'Kristoffer Sølvsten Burgdorf', 'Chaysavanh Manichanh', 'Trine Nielsen', 'Nicolas Pons', 'Florence Levenez', 'Takuji Yamada', 'Daniel R. Mende', 'Junhua Li', 'Junming Xu', 'Shaochuan Li', 'Dongfang Li', 'Jianjun Cao', 'Bo Wang', 'Huiqing Liang', 'Huisong Zheng', 'Yinlong Xie', 'Julien Tap', 'Patricia Lepage', 'Marcelo Bertalan', 'Jean-Michel Batto', 'Torben Hansen', 'Denis Le Paslier', 'Allan Linneberg', 'Henrik Bjørn Nielsen', 'Éric Pelletier', 'Pierre Renault', 'Thomas Sicheritz‐Pontén', 'A. Keith Turner', 'Hongmei Zhu', 'Chang Yu', 'Shengting Li', 'Min Jian', 'Yan Zhou', 'Rui Li', 'Xiuqing Zhang', 'Songgang Li', 'Nan Qin', 'Huanming Yang', 'Jian Wang', 'Søren Brunak', 'Joël Doré', 'Francisco Guarner', 'Karsten Kristiansen', 'Oluf Pedersen', 'Julian Parkhill', 'Jean Weissenbach', 'Peer Bork', 'S. Dusko Ehrlich', 'Jun Wang']",2010,Nature,Journal,,59-65,464,7285,10.1038/nature08821,"To understand the impact of gut microbes on human health and well-being it is crucial to assess their genetic potential. Here we describe the Illumina-based metagenomic sequencing, assembly and characterization of 3.3 million non-redundant microbial genes, derived from 576.7 gigabases of sequence, from faecal samples of 124 European individuals. The gene set, ∼150 times larger than the human gene complement, contains an overwhelming majority of the prevalent (more frequent) microbial genes of the cohort and probably includes a large proportion of the prevalent human intestinal microbial genes. The genes are largely shared among individuals of the cohort. Over 99% of the genes are bacterial, indicating that the entire cohort harbours between 1,000 and 1,150 prevalent bacterial species and each individual at least 160 such species, which are also largely shared. We define and describe the minimal gut metagenome and the minimal gut bacterial genome in terms of functions present in all individuals and most bacteria, respectively. The human body plays host to an estimated 100 trillion microbial cells, most of them in the gut where they have a profound influence on human physiology and nutrition — and are now regarded as crucial for human life. Gut microbes contribute to the energy harvest from food, and changes of gut microbiome may be associated with bowel diseases or obesity. Now the international MetaHIT (Metagenomics of the Human Intestinal Tract) project has published a gene catalogue of the human gut microbiome derived from 124 healthy, overweight and obese human adults, as well as inflammatory disease patients, from Denmark and Spain. The resulting data provide the first insights into this gene set — which is over 150 times larger than the human gene complement — and show that the genes are largely shared among individuals. Based on the variety of functions encoded by the gene set, it is possible to define both a minimal gut metagenome and a minimal gut bacterial genome. Deep metagenomic sequencing and characterization of the human gut microbiome from healthy and obese individuals, as well as those suffering from inflammatory bowel disease, provide the first insights into this gene set and how much of it is shared among individuals. The minimal gut metagenome as well as the minimal gut bacterial genome is also described.","['Metagenomics', 'Microbiome', 'Biology', 'Gene', 'Human Microbiome Project', 'Human microbiome', 'Gut flora', 'Human gastrointestinal tract', 'Genetics', 'Genome', 'Microbial genetics', 'Computational biology', 'Bacteria', 'Immunology']","gut microbes, human intestinal microbial genes, minimal gut metagenome, minimal gut bacterial genome, inflammatory disease patients, minimal gut metagenome, minimal gut bacterial genome, deep metagenomic sequencing, inflammatory bowel disease, minimal, minimal gut bacterial genome"
Paper_01296,"The use of fast Fourier transform for the estimation of power spectra: A method based on time averaging over short, modified periodograms",['P. D. Welch'],1967,IEEE Transactions on Audio and Electroacoustics,Journal,,70-73,15,2,10.1109/tau.1967.1161901,"The use of the fast Fourier transform in power spectrum analysis is described. Principal advantages of this method are a reduction in the number of computations and in required core storage, and convenient application in nonstationarity tests. The method involves sectioning the record and averaging modified periodograms of the sections.","['Spectral density estimation', 'Fast Fourier transform', 'Discrete Fourier transform (general)', 'Fourier transform', 'Non-uniform discrete Fourier transform', 'Spectral density', 'Computation', 'Short-time Fourier transform', 'Algorithm', 'Power (physics)', 'Time–frequency analysis', 'Discrete-time Fourier transform', 'Mathematics', 'Reduction (mathematics)', 'Harmonic wavelet transform', 'Fourier analysis', 'Computer science', 'Statistics', 'Artificial intelligence', 'Physics', 'Mathematical analysis', 'Wavelet transform', 'Filter (signal processing)', 'Computer vision', 'Quantum mechanics', 'Discrete wavelet transform', 'Geometry', 'Wavelet']","fast fourier transform, power spectrum analysis, core storage, nonstationarity tests, [PAD], [PAD] [PAD], [PAD] [PAD], [PAD], [PAD], [PAD], [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD]"
Paper_01298,Heat Shock Protein A12B Protects Vascular Endothelial Cells Against Sepsis-Induced Acute Lung Injury in Mice,"['Yi Chen', 'Lei Wang', 'Qiuxiang Kang', 'Xu Zhang', 'Guifang Yu', 'Xiaojian Wan', 'Jiafeng Wang', 'Keming Zhu']",2017,Cellular Physiology and Biochemistry,Journal,,156-168,42,1,10.1159/000477308,"Pulmonary endothelium is an active organ possessing numerous physiological, immunological, and metabolic functions. These functions may be altered early in acute lung injury (ALI) and further contribute to the development of acute respiratory distress syndrome (ARDS). Pulmonary endothelium is strategically located to filter the entire blood before it enters the systemic circulation; consequently its integrity is essential for the maintenance of adequate homeostasis in both the pulmonary and systemic circulations. Noxious agents that affect pulmonary endothelium induce alterations in hemodynamics and hemofluidity, promote interactions with circulating blood cells, and lead to increased vascular permeability and pulmonary edema formation. We highlight pathogenic mechanisms of pulmonary endothelial injury and their clinical implications in ALI/ARDS patients.","['Sepsis', 'Heat shock protein', 'Lung', 'Medicine', 'Endothelial stem cell', 'Shock (circulatory)', 'Cell biology', 'Immunology', 'Cancer research', 'Biology', 'Internal medicine', 'In vitro', 'Gene', 'Biochemistry']","pulmonary endothelium, acute lung injury, acute respiratory distress syndrome, pulmonary endothelium, systemic circulation, noxious agents, pulmonary endothelium, hemodynamics, hemofluidity, circulating blood cells, vascular permeability, pulmonary edema formation, pathogen, pulmonary endothelial injury"
Paper_01299,"Petri nets: Properties, analysis and applications",['T. Murata'],1989,Proceedings of the IEEE,Journal,,541-580,77,4,10.1109/5.24143,"Starts with a brief review of the history and the application areas considered in the literature. The author then proceeds with introductory modeling examples, behavioral and structural properties, three methods of analysis, subclasses of Petri nets and their analysis. In particular, one section is devoted to marked graphs, the concurrent system model most amenable to analysis. Introductory discussions on stochastic nets with their application to performance modeling, and on high-level nets with their application to logic programming, are provided. Also included are recent results on reachability criteria. Suggestions are provided for further reading on many subject areas of Petri nets.< <ETX xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">&gt;</ETX>","['Reachability', 'Petri net', 'Computer science', 'Reading (process)', 'Programming language', 'Section (typography)', 'Stochastic Petri net', 'Theoretical computer science', 'Artificial intelligence', 'Political science', 'Law', 'Operating system']","structural properties, petri nets, marked graphs, concurrent system model, stochastic nets, performance modeling, logic programming, reachability criteria, petri nets, xml, ##ink"
Paper_01300,The continental crust: Its composition and evolution,"['Stuart Ross Taylor', 'S. M. McLennan']",1985,['Physics of the Earth and Planetary Interiors'],Unknown,,196-197,42,3,10.1016/0031-9201(86)90093-2,"This book describes the composition of the present upper crust, and deals with possible compositions for the total crust and the inferred composition of the lower crust. The question of the uniformity of crustal composition throughout geological time is discussed. It describes the Archean crust and models for crustal evolution in Archean and Post-Archean time. The rate of growth of the crust through time is assessed, and the effects of the extraction of the crust on mantle compositions. The question of early pre-geological crusts on the Earth is discussed and comparisons are given with crusts on the Moon, Mercury, Mars, Venus and the Galilean Satellites.","['Archean', 'Crust', 'Geology', 'Continental crust', 'Earth science', 'Geochemistry', 'Oceanic crust', 'Mantle (geology)', 'Astrobiology', 'Paleontology', 'Subduction', 'Tectonics', 'Physics']","archean crust, crustal evolution, mantle compositions, mercury, venus, gal, ##an satellites"
Paper_01301,Mathematical model for studying genetic variation in terms of restriction endonucleases.,"['M Nei', 'Wen‐Hsiung Li']",1979,Proceedings of the National Academy of Sciences,Journal,,5269-5273,76,10,10.1073/pnas.76.10.5269,"A mathematical model for the evolutionary change of restriction sites in mitochondrial DNA is developed. Formulas based on this model are presented for estimating the number of nucleotide substitutions between two populations or species. To express the degree of polymorphism in a population at the nucleotide level, a measure called ""nucleotide diversity"" is proposed.","['Mitochondrial DNA', 'Restriction enzyme', 'Nucleotide diversity', 'Genetics', 'Biology', 'Nucleotide', 'Evolutionary biology', 'Population', 'Population genetics', 'Computational biology', 'DNA', 'Gene', 'Genotype', 'Demography', 'Sociology', 'Haplotype']","evolutionary change, restriction sites, mitochondrial dna, nucleotide substitutions, poly, nucleotide diversity, [PAD], [PAD], [PAD], [PAD] [PAD] [PAD] [PAD], [PAD], [PAD] [PAD] [PAD], [PAD] [PAD]"
Paper_01302,Estimates of the Regression Coefficient Based on Kendall's Tau,['Pranab Kumar Sen'],1968,Journal of the American Statistical Association,Journal,,1379-1389,63,324,10.1080/01621459.1968.10480934,"Abstract The least squares estimator of a regression coefficient β is vulnerable to gross errors and the associated confidence interval is, in addition, sensitive to non-normality of the parent distribution. In this paper, a simple and robust (point as well as interval) estimator of β based on Kendall's [6] rank correlation tau is studied. The point estimator is the median of the set of slopes (Yj - Yi )/(tj-ti ) joining pairs of points with ti ≠ ti , and is unbiased. The confidence interval is also determined by two order statistics of this set of slopes. Various properties of these estimators are studied and compared with those of the least squares and some other nonparametric estimators.","['Mathematics', 'Estimator', 'Statistics', 'Confidence interval', 'Nonparametric statistics', 'Asymptotic distribution', 'Simple linear regression', 'Rank (graph theory)', 'Linear regression', 'Combinatorics']","least squares estimator, regression coefficient, gross errors, confidence interval, rank correlation tau, confidence interval, least, ##parametric estimators"
Paper_01303,Dynamical Theory of Crystal Lattices,"['Max Born', 'Kun Huang', 'M. Lax']",1955,American Journal of Physics,Journal,,474-474,23,7,10.1119/1.1934059,First Page,"['Physics', 'Theoretical physics', 'Crystal (programming language)', 'Classical mechanics', 'Statistical physics', 'Quantum mechanics', 'Computer science', 'Programming language']",
Paper_01304,Subjective well-being: Three decades of progress.,"['Ed Diener', 'Eunkook M. Suh', 'Richard E. Lucas', 'Heidi Smith']",1999,Psychological Bulletin,Journal,,276-302,125,2,10.1037/0033-2909.125.2.276,"W. Wilson's (1967) review of the area of subjective well-being (SWB) advanced several conclusions regarding those who report high levels of A number of his conclusions have been overturned: youth and modest aspirations no longer are seen as prerequisites of SWB. E. Diener's (1984) review placed greater emphasis on theories that stressed psychological factors. In the current article, the authors review current evidence for Wilson's conclusions and discuss modern theories of SWB that stress dispositional influences, adaptation, goals, and coping strategies. The next steps in the evolution of the field are to comprehend the interaction of psychological factors with life circumstances in producing SWB, to understand the causal pathways leading to happiness, understand the processes underlying adaptation to events, and develop theories that explain why certain variables differentially influence the different components of SWB (life satisfaction, pleasant affect, and unpleasant affect). In 1967, Warner Wilson presented a broad review of subjective well-being (SWB) research entitled, Correlates of Avowed Happiness. Based on the limited data available at that time, Wilson concluded that the happy person is a young, healthy, welleducated, well-paid, extroverted, optimistic, worry-free, religious, married person with high self-esteem, job morale, modest aspirations, of either sex and of a wide range of intelligence (p. 294). In the three decades since Wilson's review, investigations into SWB have evolved. Although researchers now know a great deal more about the correlates of SWB, they are less interested in simply describing the demographic characteristics that correlate with it. Instead, they focus their effort on understanding the processes that underlie happiness. This trend represents a greater recognition of the central role played by people's goals, coping efforts, and dispositions. In this article, we review research on several major theoretical approaches to well-being and then indicate how these theories clarify the findings on demographic correlates of SWB. Throughout the review we suggest four directions that researchers should pursue in the decades ahead. These are by no means the only questions left to answer, but we believe they are the most interesting issues left to resolve. First, the causal direction of the correlates of happiness must be examined through more sophisticated methodologies. Although the causal priority of demographic factors such as marriage and income is intuitively appealing, it is by no means certain. Second, researchers must focus greater attention on the interaction between internal factors (such as personality traits) and external circumstances. As we shall see, demographic factors have surprisingly small effects on SWB, but these effects may depend on the personalities of those individuals being studied. Thus, future research must take Person X Situation interactions into account. Third, researchers must strive to understand the processes underlying adaptation. Considerable adaptation to both good and bad circumstances often occurs, yet the processes responsible for these effects are poorly understood. Research that examines how habituation, coping strategies, and changing goals influence adaptation will shed much light on the processes responsible for SWB. Finally, theories must be refined to make specific predictions about how input variables differentially influence the components of SWB. In the past, many researchers have treated SWB as a monolithic entity, but it is now clear that there are separable components that exhibit unique patterns of relations with different variables. In each section of this article we discuss progress and opportunities in these four areas.","['Psychology', 'Cognitive psychology']","subjective well, youth, modest aspirations, psychological factors, dispositional influences, coping strategies, psychological factors, life circumstances, ##b, causal pathways, life satisfaction, pleasant affect, unpleasant affect, avowed happiness, job morale, modest aspirations, demographic factors, marriage, income"
Paper_01305,Increasing Returns and Economic Geography,['Paúl Krugman'],1991,Journal of Political Economy,Journal,,483-499,99,3,10.1086/261763,"This paper develops a simple model that shows how a country can endogenously become differentiated into an industrialized ""core"" and an agricultural ""periphery."" In order to realize scale economies while minimizing transport costs, manufacturing firms tend to locate in the region with larger demand, but the location of demand itself depends on the distribution of manufacturing. Emergence of a core-periphery pattern depends on transportation costs, economies of scale, and the share of manufacturing in national income.","['Economies of scale', 'Core (optical fiber)', 'Order (exchange)', 'Returns to scale', 'Distribution (mathematics)', 'Economic geography', 'Scale (ratio)', 'Economics', 'Agriculture', 'Business', 'Industrial organization', 'Microeconomics', 'Production (economics)', 'Geography', 'Finance', 'Engineering', 'Telecommunications', 'Mathematical analysis', 'Mathematics', 'Cartography', 'Archaeology']","scale, transport costs, manufacturing firms, transportation costs"
Paper_01306,Nonlinear and adaptive control design,"['Miroslav Krstić', 'P.V. Kokotović', 'I. Kanellakopoulos']",1995,['1993 American Control Conference'],Unknown,,,,,10.23919/acc.1993.4793094,"From the Publisher:
Using a pedagogical style along with detailed proofs and illustrative examples, this book opens a view to the largely unexplored area of nonlinear systems with uncertainties. The focus is on adaptive nonlinear control results introduced with the new recursive design methodology--adaptive backstepping. Describes basic tools for nonadaptive backstepping design with state and output feedbacks.","['Backstepping', 'Nonlinear system', 'Mathematical proof', 'Adaptive control', 'Strict-feedback form', 'Computer science', 'Focus (optics)', 'Control theory (sociology)', 'Control engineering', 'State (computer science)', 'Control (management)', 'Mathematics', 'Engineering', 'Artificial intelligence', 'Algorithm', 'Physics', 'Geometry', 'Quantum mechanics', 'Optics']","##da, nonlinear systems, adaptive nonlinear control results, recursive design methodology, adaptive backstepping, nonadaptive backstepping design, output feedbacks, [PAD] [PAD]"
Paper_01307,A Unified Approach to Interpreting Model Predictions,"['Scott Lundberg', 'Su‐In Lee']",2017,arXiv (Cornell University),Unknown,,,,,10.48550/arxiv.1705.07874,"Understanding why a model makes a certain prediction can be as crucial as the prediction's accuracy in many applications. However, the highest accuracy for large modern datasets is often achieved by complex models that even experts struggle to interpret, such as ensemble or deep learning models, creating a tension between accuracy and interpretability. In response, various methods have recently been proposed to help users interpret the predictions of complex models, but it is often unclear how these methods are related and when one method is preferable over another. To address this problem, we present a unified framework for interpreting predictions, SHAP (SHapley Additive exPlanations). SHAP assigns each feature an importance value for a particular prediction. Its novel components include: (1) the identification of a new class of additive feature importance measures, and (2) theoretical results showing there is a unique solution in this class with a set of desirable properties. The new class unifies six existing methods, notable because several recent methods in the class lack the proposed desirable properties. Based on insights from this unification, we present new methods that show improved computational performance and/or better consistency with human intuition than previous approaches.","['Interpretability', 'Computer science', 'Unification', 'Machine learning', 'Class (philosophy)', 'Artificial intelligence', 'Consistency (knowledge bases)', 'Intuition', 'Unified Model', 'Shapley value', 'Feature (linguistics)', 'Theoretical computer science', 'Mathematics', 'Game theory', 'Philosophy', 'Linguistics', 'Physics', 'Mathematical economics', 'Epistemology', 'Meteorology', 'Programming language']","deep learning models, ##p, shapley additive explanations, additive feature importance measures, computational performance, human intuition"
Paper_01310,Introduction to Fourier optics,['Joseph W. Goodman'],1968,['The Physics Teacher'],Unknown,,364-368,45,6,10.1119/1.2768695,"The second edition of this respected text considerably expands the original and reflects the tremendous advances made in the discipline since 1968. All material has been thoroughly updated and several new sections explore recent progress in important areas, such as wavelength modulation, analog information processing, and holography. Fourier analysis is a ubiquitous tool with applications in diverse areas of physics and engineering. This book explores these applications in the field of optics with a special emphasis on applications to diffraction, imaging, optical data processing, and holography. This book can be used as a textbook to satisfy the needs of several different types of courses, and it is directed toward both engineers ad physicists. By varying the emphasis on different topics and specific applications, the book can be used successfully in a wide range of basic Fourier Optics or Optical Signal Processing courses.","['Emphasis (telecommunications)', 'Holography', 'Computer science', 'Fourier transform', 'Field (mathematics)', 'Fourier optics', 'Optics', 'Signal processing', 'Physics', 'Digital signal processing', 'Telecommunications', 'Mathematics', 'Quantum mechanics', 'Pure mathematics', 'Computer hardware']","wavelength modulation, analog information processing, holography, fourier analysis, diffraction, imaging, optical data processing, holography, fourier optics, optical signal processing, [PAD] [PAD] [PAD], [PAD], [PAD], [PAD] [PAD]"
Paper_01311,The DeLone and McLean Model of Information Systems Success: A Ten-Year Update,"['William DeLone', 'Ephraim R. McLean']",2003,Journal of Management Information Systems,Journal,,9-30,19,4,10.1080/07421222.2003.11045748,"Abstract Ten years ago, we presented the DeLone and McLean Information Systems (IS) Success Model as a framework and model for measuring the complex-dependent variable in IS research. In this paper, we discuss many of the important IS success research contributions of the last decade, focusing especially on research efforts that apply, validate, challenge, and propose enhancements to our original model. Based on our evaluation of those contributions, we propose minor refinements to the model and propose an updated DeLone and McLean IS Success Model. We discuss the utility of the updated model for measuring e-commerce system success. Finally, we make a series of recommendations regarding current and future measurement of IS success. Keywords: EVALUATION OF INFORMATION SYSTEMSIMPACT OF INFORMATION TECHNOLOGYINFORMATION QUALITYINFORMATION SYSTEMS SUCCESSSERVICE QUALITYSYSTEMSQUALITYUSE OF INFORMATION SYSTEMSUSER SATISFACTION","['Computer science', 'Information system', 'Success factors', 'Data science', 'Knowledge management', 'Engineering', 'Electrical engineering', 'Business administration', 'Business']","delone, mclean information systems, information, ##form, ##formation, ##vic, quality, ##quality, information systems"
Paper_01314,Low-density parity-check codes,['Robert G. Gallager'],1962,IEEE Transactions on Information Theory,Journal,,21-28,8,1,10.1109/tit.1962.1057683,"A low-density parity-check code is a code specified by a parity-check matrix with the following properties: each column contains a small fixed number <tex xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">j \geq 3</tex> of l's and each row contains a small fixed number <tex xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">k &gt; j</tex> of l's. The typical minimum distance of these codes increases linearly with block length for a fixed rate and fixed <tex xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">j</tex> . When used with maximum likelihood decoding on a sufficiently quiet binary-input symmetric channel, the typical probability of decoding error decreases exponentially with block length for a fixed rate and fixed <tex xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">j</tex> . A simple but nonoptimum decoding scheme operating directly from the channel a posteriori probabilities is described. Both the equipment complexity and the data-handling capacity in bits per second of this decoder increase approximately linearly with block length. For <tex xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">j &gt; 3</tex> and a sufficiently low rate, the probability of error using this decoder on a binary symmetric channel is shown to decrease at least exponentially with a root of the block length. Some experimental results show that the actual probability of decoding error is much smaller than this theoretical bound.","['Decoding methods', 'Binary number', 'Discrete mathematics', 'Binary symmetric channel', 'Code (set theory)', 'Mathematics', 'Channel (broadcasting)', 'Combinatorics', 'Algorithm', 'Statistics', 'Computer science', 'Low-density parity-check code', 'Arithmetic', 'Telecommunications', 'Set (abstract data type)', 'Programming language']","minimum distance, binary symmetric channel"
Paper_01316,Creating the CIPRES Science Gateway for inference of large phylogenetic trees,"['Mark A. Miller', 'Wayne Pfeiffer', 'Terri Schwartz']",2010,Unknown,Unknown,,,,,10.1109/gce.2010.5676129,"Understanding the evolutionary history of living organisms is a central problem in biology. Until recently the ability to infer evolutionary relationships was limited by the amount of DNA sequence data available, but new DNA sequencing technologies have largely removed this limitation. As a result, DNA sequence data are readily available or obtainable for a wide spectrum of organisms, thus creating an unprecedented opportunity to explore evolutionary relationships broadly and deeply across the Tree of Life. Unfortunately, the algorithms used to infer evolutionary relationships are NP-hard, so the dramatic increase in available DNA sequence data has created a commensurate increase in the need for access to powerful computational resources. Local laptop or desktop machines are no longer viable for analysis of the larger data sets available today, and progress in the field relies upon access to large, scalable high-performance computing resources. This paper describes development of the CIPRES Science Gateway, a web portal designed to provide researchers with transparent access to the fastest available community codes for inference of phylogenetic relationships, and implementation of these codes on scalable computational resources. Meeting the needs of the community has included developing infrastructure to provide access, working with the community to improve existing community codes, developing infrastructure to insure the portal is scalable to the entire systematics community, and adopting strategies that make the project sustainable by the community. The CIPRES Science Gateway has allowed more than 1800 unique users to run jobs that required 2.5 million Service Units since its release in December 2009. (A Service Unit is a CPU-hour at unit priority).","['Scalability', 'Computer science', 'Laptop', 'Data science', 'Gateway (web page)', 'Inference', 'Service (business)', 'Data access', 'World Wide Web', 'Artificial intelligence', 'Database', 'Economy', 'Economics', 'Operating system']","evolutionary history, living organisms, evolutionary relationships, dna sequencing, dna, evolutionary, desktop machines, cipres science gateway, web portal, community, phylogenetic relationships, scalable computational resources, cipres science gateway"
Paper_01317,Corporate Ownership Around the World,"['Rafael La Porta', 'Florencio López‐de‐Silanes', 'Andrei Shleifer']",1999,The Journal of Finance,Journal,,471-517,54,2,10.1111/0022-1082.00115,"ABSTRACT We use data on ownership structures of large corporations in 27 wealthy economies to identify the ultimate controlling shareholders of these firms. We find that, except in economies with very good shareholder protection, relatively few of these firms are widely held, in contrast to Berle and Means's image of ownership of the modern corporation. Rather, these firms are typically controlled by families or the State. Equity control by financial institutions is far less common. The controlling shareholders typically have power over firms significantly in excess of their cash flow rights, primarily through the use of pyramids and participation in management.","['Shareholder', 'Equity (law)', 'Corporation', 'Business', 'Cash flow', 'Control (management)', 'State ownership', 'State (computer science)', 'Market economy', 'Finance', 'Monetary economics', 'Corporate governance', 'Financial system', 'Accounting', 'Economics', 'Emerging markets', 'Law', 'Management', 'Algorithm', 'Political science', 'Computer science']","ownership structures, large corporations, wealthy economies, controlling shareholders, shareholder protection, equity control, financial institutions, controlling shareholders, cash flow rights, pyramids, participation, [PAD] [PAD], [PAD], [PAD] [PAD], [PAD]"
Paper_01318,The cornerstones of competitive advantage: A resource‐based view,['Margaret A. Peteraf'],1993,Strategic Management Journal,Journal,,179-191,14,3,10.1002/smj.4250140303,"Abstract This paper elucidates the underlying economics of the resource‐based view of competitive advantage and integrates existing perspectives into a parsimonious model of resources and firm performance. The essence of this model is that four conditions underlie sustained competitive advantage, all of which must be met. These include superior resources (heterogeneity within an industry), ex post limits to competition, imperfect resource mobility, and ex ante limits to competition. In the concluding section, applications of the model for both single business strategy and corporate strategy are discussed.","['Competitive advantage', 'Competition (biology)', 'Resource (disambiguation)', 'Industrial organization', 'Ex-ante', 'Business', 'Resource-based view', 'Economics', 'Imperfect', 'Imperfect competition', 'Microeconomics', 'Computer science', 'Marketing', 'Ecology', 'Computer network', 'Linguistics', 'Philosophy', 'Macroeconomics', 'Biology']","competitive advantage, firm performance, sustained competitive advantage, superior resources, imperfect resource mobility, single business strategy, corporate strategy, [PAD] [PAD], [PAD] [PAD], [PAD] [PAD]"
Paper_01319,<b>mice</b>: Multivariate Imputation by Chained Equations in<i>R</i>,"['Stef van Buuren', 'Catharina G. M. Groothuis‐Oudshoorn']",2011,Journal of Statistical Software,Journal,,,45,3,10.18637/jss.v045.i03,"The R package <b>mice</b> imputes incomplete multivariate data by chained equations. The software mice 1.0 appeared in the year 2000 as an S-PLUS library, and in 2001 as an R package. mice 1.0 introduced predictor selection, passive imputation and automatic pooling. This article documents mice, which extends the functionality of mice 1.0 in several ways. In <b>mice</b>, the analysis of imputed data is made completely general, whereas the range of models under which pooling works is substantially extended. <b>mice</b> adds new functionality for imputing multilevel data, automatic predictor selection, data handling, post-processing imputed values, specialized pooling routines, model selection tools, and diagnostic graphs. Imputation of categorical data is improved in order to bypass problems caused by perfect prediction. Special attention is paid to transformations, sum scores, indices and interactions using passive imputation, and to the proper setup of the predictor matrix. <b>mice</b> can be downloaded from the Comprehensive R Archive Network. This article provides a hands-on, stepwise approach to solve applied incomplete data problems.","['Pooling', 'Imputation (statistics)', 'Categorical variable', 'Multivariate statistics', 'Computer science', 'R package', 'Missing data', 'Data mining', 'Statistics', 'Artificial intelligence', 'Mathematics', 'Machine learning', 'Programming language']","incomplete multivariate data, chained equations, mice, mice, predictor selection, passive imputation, automatic pooling, mice, ##uted data, ##lev, automatic predictor selection, pooling routines, model selection tools, diagnostic graphs, categorical data, sum scores, indices, passive imputation, predictor matrix, r archive network, incomplete data problems"
Paper_01322,Antenna theory : analysis and design,['Constantine A. Balanis'],2005,['Proceedings of the IEEE'],Unknown,,989-990,72,7,10.1109/proc.1984.12959,"The most-up-to-date resource available on antenna theory and design. Expanded coverage of design procedures and equations makes meeting ABET design requirements easy and prepares readers for authentic situations in industry. New coverage of microstrip antennas exposes readers to information vital to a wide variety of practical applications.Computer programs at end of each chapter and the accompanying disk assist in problem solving, design projects and data plotting.-- Includes updated material on moment methods, radar cross section, mutual impedances, aperture and horn antennas, and antenna measurements.-- Outstanding 3-dimensional illustrations help readers visualize the entire antenna radiation pattern.","['Antenna (radio)', 'Computer science', 'Variety (cybernetics)', 'Antenna measurement', 'Electronic engineering', 'Engineering', 'Electrical engineering', 'Telecommunications', 'Artificial intelligence']","antenna theory, microstrip antennas, computer programs, design, data plotting, moment methods, radar cross section, mutual impedances, horn antennas, antenna measurements, antenna radiation pattern, [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"
Paper_01323,Handbook of Physiology.,['F. Plum'],1960,Archives of Neurology,Journal,,360-360,2,3,10.1001/archneur.1960.03840090124020,"This is the first volume of the proposed many-sectioned ""Handbook"" in which the American Physiological Society intends to present comprehensively the entire field of physiology. The scope and depth of the work may be estimated by realizing that the Section on Neurophysiology alone will comprise three volumes. The present work covers the following principal topics, all but the first of which are divided into several chapters: History of Neurophysiology (M. A. B. Brazier), Neuron Physiology (Introduction, J. C. Eccles), Brain Potentials and Rhythms (Introduction, A. Fessard), Sensory Mechanisms (Introduction, Lord Adrian), and Vision (Introduction, H. K. Hartline). To a large degree, the individual contributors have overcome the difficult task of presenting both the fundamentals and the most recent advances pertaining to their subjects. The historical development of knowledge and hypotheses about most of the particular topics is given detailed consideration, and this aspect alone should help to prevent the material","['Scope (computer science)', 'Principal (computer security)', 'Cognitive science', 'Neuroscience', 'Task (project management)', 'Neurophysiology', 'Psychology', 'Physiology', 'Computer science', 'Medicine', 'Engineering', 'Systems engineering', 'Programming language', 'Operating system']","american physiological society, neurophysiology, neurophysiology, neuron physiology, brain potentials, rhythms, sensory mechanisms, vision"
Paper_01324,Planetary boundaries: Guiding human development on a changing planet,"['Will Steffen', 'Katherine Richardson', 'Johan Rockström', 'Sarah Cornell', 'Ingo Fetzer', 'Elena M. Bennett', 'Reinette Biggs', 'Stephen R. Carpenter', 'W. de Vries', 'Cynthia A. de Wit', 'Carl Folke', 'Dieter Gerten', 'Jens Heinke', 'Georgina M. Mace', 'Linn Persson', 'V. Ramanathan', 'Belinda Reyers', 'Sverker Sörlin']",2015,Science,Journal,,,347,6223,10.1126/science.1259855,"Crossing the boundaries in global sustainability The planetary boundary (PB) concept, introduced in 2009, aimed to define the environmental limits within which humanity can safely operate. This approach has proved influential in global sustainability policy development. Steffen et al. provide an updated and extended analysis of the PB framework. Of the original nine proposed boundaries, they identify three (including climate change) that might push the Earth system into a new state if crossed and that also have a pervasive influence on the remaining boundaries. They also develop the PB framework so that it can be applied usefully in a regional context. Science , this issue 10.1126/science.1259855","['Planetary boundaries', 'Planet', 'Humanity', 'Sustainability', 'Earth system science', 'Context (archaeology)', 'Boundary (topology)', 'Astrobiology', 'Political science', 'Global change', 'Sustainable development', 'Climate change', 'Geography', 'Environmental ethics', 'Geology', 'Physics', 'Ecology', 'Oceanography', 'Paleontology', 'Astronomy', 'Biology', 'Mathematics', 'Philosophy', 'Law', 'Mathematical analysis']","global sustainability, planetary boundary, p, environmental limits, global sustainability policy development, climate change, [PAD] [PAD]"
Paper_01326,Significance analysis of microarrays applied to the ionizing radiation response,"['Virginia Goss Tusher', 'Robert Tibshirani', 'Gilbert Chu']",2001,Proceedings of the National Academy of Sciences,Journal,,5116-5121,98,9,10.1073/pnas.091062498,"Microarrays can measure the expression of thousands of genes to identify changes in expression between different biological states. Methods are needed to determine the significance of these changes while accounting for the enormous number of genes. We describe a method, Significance Analysis of Microarrays (SAM), that assigns a score to each gene on the basis of change in gene expression relative to the standard deviation of repeated measurements. For genes with scores greater than an adjustable threshold, SAM uses permutations of the repeated measurements to estimate the percentage of genes identified by chance, the false discovery rate (FDR). When the transcriptional response of human cells to ionizing radiation was measured by microarrays, SAM identified 34 genes that changed at least 1.5-fold with an estimated FDR of 12%, compared with FDRs of 60 and 84% by using conventional methods of analysis. Of the 34 genes, 19 were involved in cell cycle regulation and 3 in apoptosis. Surprisingly, four nucleotide excision repair genes were induced, suggesting that this repair pathway for UV-damaged DNA might play a previously unrecognized role in repairing DNA damaged by ionizing radiation.","['DNA microarray', 'Gene', 'Significance analysis of microarrays', 'Biology', 'Ionizing radiation', 'Gene expression', 'DNA repair', 'Genetics', 'Microarray', 'Gene expression profiling', 'Biological pathway', 'Computational biology', 'DNA', 'Molecular biology', 'Irradiation', 'Physics', 'Nuclear physics']","microarrays, significance analysis of, false discovery rate, transcriptional response, ##izing, microarray, cell cycle regulation, apoptosis, nucleotide excision repair genes"
Paper_01327,Mixed Methods Research: A Research Paradigm Whose Time Has Come,"['R. Burke Johnson', 'Anthony J. Onwuegbuzie']",2004,Educational Researcher,Journal,,14-26,33,7,10.3102/0013189x033007014,"The purposes of this article are to position mixed methods research ( mixed research is a synonym) as the natural complement to traditional qualitative and quantitative research, to present pragmatism as offering an attractive philosophical partner for mixed methods research, and to provide a framework for designing and conducting mixed methods research. In doing this, we briefly review the paradigm “wars” and incompatibility thesis, we show some commonalities between quantitative and qualitative research, we explain the tenets of pragmatism, we explain the fundamental principle of mixed research and how to apply it, we provide specific sets of designs for the two major types of mixed methods research ( mixed-model designs and mixed-method designs), and, finally, we explain mixed methods research as following (recursively) an eight-step process. A key feature of mixed methods research is its methodological pluralism or eclecticism, which frequently results in superior research (compared to monomethod research). Mixed methods research will be successful as more investigators study and help advance its concepts and as they regularly practice it.","['Multimethodology', 'Eclecticism', 'Pragmatism', 'Management science', 'Qualitative research', 'Research design', 'Pluralism (philosophy)', 'Epistemology', 'Computer science', 'Sociology', 'Social science', 'Philosophy', 'Theology', 'Economics']","mixed methods research, mixed research, quantitative, pragmatism, mixed methods, mixed methods, incompatibility, qu, ##tative, pragmatism, mixed research, mixed methods, mixed methods, mixed methods, methodological pluralism, eclecticism, monomethod research, mixed methods"
Paper_01331,Telling more than we can know: Verbal reports on mental processes.,"['Richard E. Nisbett', 'Timothy D. Wilson']",1977,Psychological Review,Journal,,231-259,84,3,10.1037/0033-295x.84.3.231,"Evidence is reviewed which suggests that there may be little or no direct introspective access to higher order cognitive processes. Subjects are sometimes (a) unaware of the existence of a stimulus that importantly influenced a response, (b) unaware of the existence of the response, and (c) unaware that the stimulus has affected the response. It is proposed that when people attempt to report on their cognitive processes, that is, on the processes mediating the effects of a stimulus on a response, they do not do so on the basis of any true introspection. Instead, their reports are based on a priori, implicit causal theories, or judgments about the extent to which a particular stimulus is a plausible cause of a given response. This suggests that though people may not be able to observe directly their cognitive processes, they will sometimes be able to report accurately about them. Accurate reports will occur when influential stimuli are salient and are plausible causes of the responses they produce, and will not occur when stimuli are not salient or are not plausible causes.","['Psychology', 'Cognitive psychology', 'Nonverbal communication', 'Developmental psychology']","introspective access, higher order cognitive processes, implicit causal theories"
Paper_01332,Experimental Design and Data Analysis for Biologists,"['Gerry P. Quinn', 'Michael J. Keough']",2002,Unknown,Unknown,,,,,10.1017/cbo9780511806384,"An essential textbook for any student or researcher in biology needing to design experiments, sample programs or analyse the resulting data. The text begins with a revision of estimation and hypothesis testing methods, covering both classical and Bayesian philosophies, before advancing to the analysis of linear and generalized linear models. Topics covered include linear and logistic regression, simple and complex ANOVA models (for factorial, nested, block, split-plot and repeated measures and covariance designs), and log-linear models. Multivariate techniques, including classification and ordination, are then introduced. Special emphasis is placed on checking assumptions, exploratory data analysis and presentation of results. The main analyses are illustrated with many examples from published papers and there is an extensive reference list to both the statistical and biological literature. The book is supported by a website that provides all data sets, questions for each chapter and links to software.","['Computer science', 'Exploratory data analysis', 'Linear model', 'Bayesian probability', 'Data mining', 'Generalized linear mixed model', 'Multivariate statistics', 'Data science', 'Statistics', 'Mathematics', 'Machine learning', 'Artificial intelligence']","biology, sample programs, hypothesis testing, bay, generalized linear models, factor, repeated, covariance designs, multivariate techniques, classification, ordination, exploratory data analysis"
Paper_01334,Spintronics: Fundamentals and applications,"['Igor Žutić', 'Jaroslav Fabian', 'S. Das Sarma']",2004,Reviews of Modern Physics,Journal,,323-410,76,2,10.1103/revmodphys.76.323,"Spintronics, or spin electronics, involves the study of active control and manipulation of spin degrees of freedom in solid-state systems. This article reviews the current status of this subject, including both recent advances and well-established results. The primary focus is on the basic physical principles underlying the generation of carrier spin polarization, spin dynamics, and spin-polarized transport in semiconductors and metals. Spin transport differs from charge transport in that spin is a nonconserved quantity in solids due to spin-orbit and hyperfine coupling. The authors discuss in detail spin decoherence mechanisms in metals and semiconductors. Various theories of spin injection and spin-polarized transport are applied to hybrid structures relevant to spin-based devices and fundamental studies of materials properties. Experimental work is reviewed with the emphasis on projected applications, in which external electric and magnetic fields and illumination by light will be used to control spin and charge dynamics to create new functionalities not feasible or ineffective with conventional electronics.","['Spintronics', 'Spin engineering', 'Physics', 'Spinplasmonics', 'Spin pumping', 'Spin transistor', 'Spin (aerodynamics)', 'Spin polarization', 'Quantum decoherence', 'Condensed matter physics', 'Spin Hall effect', 'Engineering physics', 'Quantum mechanics', 'Electron', 'Ferromagnetism', 'Quantum', 'Thermodynamics']","spintronics, spin electronics, active control, spin degrees of freedom, carrier spin polarization, spin dynamics, spin transport, charge transport, hyperfine coupling, spin decoherence mechanisms, spin, hybrid structures, materials properties, illumination, charge dynamics"
Paper_01335,A PHOTOMETRIC ADAPTATION OF THE SOMOGYI METHOD FOR THE DETERMINATION OF GLUCOSE,['Norton Nelson'],1944,Journal of Biological Chemistry,Journal,,375-380,153,2,10.1016/s0021-9258(18)71980-7,"The reliability of the various Somogyi-Shaffer-Hartmann (1, 2) copper reagents for glucose determination in biological material has been established. Adaptation of these reagents to calorimetric use may be accomplished by omission of the iodide and iodate in their preparation, since these interfere with the molybdate color reagents. This omission produces no especial change in the character of the reagents. KI, however, inhibits the autoreduction of the copper and in its absence an unstable reagent results. Nevertheless, if the copper is added to the rest of the reagent on the day of its use, this difficulty is avoided. When the Somogyi micro reagent (2) is used in this way with almost any of the various phosphomolybdate reagents, very satisfactory proportionality is found between color density and glucose taken over a wide range of values. However, all of the phosphomolybdate reagents tried left much to be desired in reproducibility from time to time and lacked the desired stability of color. We therefore tried various color reagents, which led to the development of a new arsenomolybdate reagent. When this reagent was used with Somogyi’s micro reagent, it gave satisfactory stability and reproducibility of color. By this means it has been possible to utilize the copper reagents in a photometric procedure for practically all the uses to which the titrimetric procedures are adapted. These include tissue sugar, glycogen, urine reduction equivalent, maltose, glucuronic acid, etc. However, diastase determinations have not been successful because of the effect of the undigested starch on the clarity of the final colored solution. The reactions involved in the molybdenum blue reaction are uncertain and beyond the scope of this report. Woods and Mellon (3) discuss and give references to the various interpretations of the reaction. Reagents-Analytical reagent grade or the equivalent. 1. Copper Reagent A. Dissolve 25 gm. of N&C03 (anhydrous), 25 gm. of Rochelle salt, 20 gm. of NaHCOs, and 200 gm. of NaiSOa (anhydrous) in about 800 ml. of water and dilute to 1 liter. Filter if necessary.’ This","['Adaptation (eye)', 'Photometry (optics)', 'Chemistry', 'Chromatography', 'Astrophysics', 'Physics', 'Optics', 'Stars']","glucose determination, ##orimetric, color density, color re, photometric, tissue sugar, glycogen, urine reduction equivalent, maltose, glucuronic, ##stase, ##sted, ##um blue, copper, rochelle salt"
Paper_01336,Tree View: An application to display phylogenetic trees on personal computers,['Roderic Page'],1996,Bioinformatics,Journal,,357-358,12,4,10.1093/bioinformatics/12.4.357,"TreeView is a simple, easy to use phylogenetic tree viewing utility that runs under both MacOS (on Apple Macintosh computers) and under Microsoft Windows on Intel based computers, the two most common personal computers used by biologists. Some phylogeny programs, such as PAUP (Swofford, 1993) and MacClade (Maddison and Maddison, 1992) already provide excellent tree drawing and printing facilities, however at present these programs are restricted to Apple Macintosh computers. Furthermore, they require the user to load a data set before any trees can be displayed which is inconvenient if the user simply wants to view the trees. More portable programs, such as DRAWGRAM and DRAWTREE in the PHYLIP package (Felsenstein, 1993) can run on both MacOS and Windows computers, but make little, if any use of the graphical interface features available under those operating systems. TreeView runs as a native application on either MacOS or Windows computers, enables the user to use the standard fonts installed on their machine, their printer, and supports the relevant native graphics format (PICT and Windows metafile) for either creating graphics files or pasting pictures to other applications via the clipboard. The program also supports standard file operations, such as 'drag and drop' whereby dragging a file's icon onto the program opens that file. TreeView can read a range of tree file formats (see below) and can display trees in a range of styles (Fig. 1). Additional information, such as edge lengths and internal node labels can also be displayed. The order of the terminal taxa in the tree can be altered, and the tree can be rerooted. If the tree file contains more than one tree the user can view each tree in turn. The program can also save trees in a variety of file formats, so that it can be used to move trees between programs that use different file formats.","['Computer science', 'Tree (set theory)', 'Graphics', 'Computer graphics (images)', 'File format', 'Graphical user interface', 'Set (abstract data type)', 'Node (physics)', 'Software', 'Operating system', 'Database', 'Programming language', 'Mathematics', 'Mathematical analysis', 'Structural engineering', 'Engineering']","treeview, phylogenetic tree viewing, personal computers, macclade, tree drawing, drawgram, drawtree, phylip, graphical, treeview, native graphics format, ##t, windows meta, treeview, tree file, edge lengths, internal node labels, [PAD], [PAD]"
Paper_01337,Introduction to Functional Grammar,"['Christian M.I.M. Matthiessen', 'Mark Halliday']",1989,Language,Journal,,862-862,65,4,10.2307/414947,"This third edition of An Introduction to Functional Grammar has been extensively revised. While retaining the organization and coverage of the earlier editions, it incorporates a considerable amount of new material. This includes strengthening the grammar through the use of data from a large-scale corpus, upgrading the description throughout, and giving greater emphasis to the systemic perspective, in which grammaticalization is understood in the context of an overall model of language.The approach taken in the book overcomes the distinction between theoretical and applied linguistics. The description of grammar is grounded in a comprehensive theory, but it is a theory which evolves in the process of being applied.","['Grammaticalization', 'Grammar', 'Linguistics', 'Emergent grammar', 'Perspective (graphical)', 'Computer science', 'Context (archaeology)', 'Process (computing)', 'Relational grammar', 'Artificial intelligence', 'Philosophy', 'History', 'Programming language', 'Archaeology']","functional grammar, systemic, grammaticalization, grammar, [PAD] [PAD] [PAD], [PAD], [PAD], [PAD]"
Paper_01338,Fostering implementation of health services research findings into practice: a consolidated framework for advancing implementation science,"['Laura J. Damschroder', 'David C. Aron', 'Rosalind E. Keith', 'Susan Kirsh', 'J Alexander', 'Julie C. Lowery']",2009,Implementation Science,Journal,,,4,1,10.1186/1748-5908-4-50,"Many interventions found to be effective in health services research studies fail to translate into meaningful patient care outcomes across multiple contexts. Health services researchers recognize the need to evaluate not only summative outcomes but also formative outcomes to assess the extent to which implementation is effective in a specific setting, prolongs sustainability, and promotes dissemination into other settings. Many implementation theories have been published to help promote effective implementation. However, they overlap considerably in the constructs included in individual theories, and a comparison of theories reveals that each is missing important constructs included in other theories. In addition, terminology and definitions are not consistent across theories. We describe the Consolidated Framework For Implementation Research (CFIR) that offers an overarching typology to promote implementation theory development and verification about what works where and why across multiple contexts. We used a snowball sampling approach to identify published theories that were evaluated to identify constructs based on strength of conceptual or empirical support for influence on implementation, consistency in definitions, alignment with our own findings, and potential for measurement. We combined constructs across published theories that had different labels but were redundant or overlapping in definition, and we parsed apart constructs that conflated underlying concepts. The CFIR is composed of five major domains: intervention characteristics, outer setting, inner setting, characteristics of the individuals involved, and the process of implementation. Eight constructs were identified related to the intervention (e.g., evidence strength and quality), four constructs were identified related to outer setting (e.g., patient needs and resources), 12 constructs were identified related to inner setting (e.g., culture, leadership engagement), five constructs were identified related to individual characteristics, and eight constructs were identified related to process (e.g., plan, evaluate, and reflect). We present explicit definitions for each construct. The CFIR provides a pragmatic structure for approaching complex, interacting, multi-level, and transient states of constructs in the real world by embracing, consolidating, and unifying key constructs from published implementation theories. It can be used to guide formative evaluations and build the implementation knowledge base across multiple studies and settings.","['Implementation research', 'Health services research', 'Nursing research', 'Health administration', 'Health informatics', 'Terminology', 'Conceptual framework', 'Snowball sampling', 'Rigour', 'Formative assessment', 'Health care', 'Qualitative research', 'Psychological intervention', 'Medicine', 'Management science', 'Computer science', 'Public health', 'Psychology', 'Nursing', 'Sociology', 'Mathematics education', 'Epistemology', 'Social science', 'Linguistics', 'Philosophy', 'Pathology', 'Economics', 'Economic growth']","health services research, patient care outcomes, health services, ##ive outcomes, implementation research, cfir, snowball sampling, intervention characteristics, evidence strength, patient needs, leadership engagement"
Paper_01339,"<i>Numerical Recipes, The Art of Scientific Computing</i>","['William H. Press', 'Brian P. Flannery', 'Saul A. Teukolsky', 'William T. Vetterling', 'Harvey Gould']",1987,American Journal of Physics,Journal,,90-91,55,1,10.1119/1.14981,First Page,"['Physics', 'Theoretical physics', 'Computational science', 'Physics education', 'Computer graphics (images)', 'Engineering physics', 'Data science', 'Quantum mechanics', 'Computer science']",
Paper_01340,Observation of a new particle in the search for the Standard Model Higgs boson with the ATLAS detector at the LHC,"['G. Aad', 'T. Abajyan', 'B. Abbott', 'J. Abdallah', 'S. Abdel Khalek', 'A. A. Abdelalim', 'O. Abdinov', 'R. Aben', 'B. Abi', 'M. Abolins', 'O. S. AbouZeid', 'H. Abramowicz', 'H. Abreu', 'B. S. Acharya', 'L. Adamczyk', 'D. L. Adams', 'T. N. Addy', 'J. Adelman', 'S. Adomeit', 'P. Adragna', 'T. Adye', 'S. Aefsky', 'J. A. Aguilar–Saavedra', 'M. Agustoni', 'M. Aharrouche', 'S. P. Ahlen', 'F. Ahles', 'A. Ahmad', 'M. Ahsan', 'G. Aielli', 'T. Akdoğan', 'T. P. A. Åkesson', 'G. Akimoto', 'A. V. Akimov', 'M. S. Alam', 'M. A. Alam', 'J. Albert', 'S. Albrand', 'M. Aleksa', 'I. N. Aleksandrov', 'F. Alessandria', 'C. Alexa', 'G. Alexander', 'G. Alexandre', 'T. Alexopoulos', 'M. Alhroob', 'M. Aliev', 'G. Alimonti', 'J. Alison', 'B. M. M. Allbrooke', 'P. P. Allport', 'S. E. Allwood-Spiers', 'J. Almond', 'A. Aloisio', 'R. Alon', 'A. Alonso', 'F. Alonso', 'A. Altheimer', 'B. Álvarez González', 'M. G. Alviggi', 'K. Amako', 'C. Amelung', 'V. V. Ammosov', 'D. Roda Dos Santos', 'A. Amorim', 'N. Amram', 'C. Anastopoulos', 'L. S. Ancu', 'N. Andari', 'T. Andeen', 'C. F. Anders', 'C. F. Anders', 'K. J. Anderson', 'A. Andreazza', 'V. Andrei', 'M.-L. Andrieux', 'X. S. Anduaga', 'S. Angelidakis', 'P. Anger', 'A. Angerami', 'F. Anghinolfi', 'A. V. Anisenkov', 'N. Anjos', 'A. Annovi', 'A. Antonaki', 'M. Antonelli', 'А. Антонов', 'J. Antoš', 'F. Anulli', 'M. Aoki', 'S. Aoun', 'L. Aperio Bella', 'R. Apolle', 'G. Arabidze', 'I. Aracena', 'Y. Arai', 'A. T. H. Arce', 'S. Arfaoui', 'J-F. Arguin', 'E. Arık']",2012,Physics Letters B,Journal,,1-29,716,1,10.1016/j.physletb.2012.08.020,"A search for the Standard Model Higgs boson in proton-proton collisions with the ATLAS detector at the LHC is presented. The datasets used correspond to integrated luminosities of approximately 4.8 fb^-1 collected at sqrt(s) = 7 TeV in 2011 and 5.8 fb^-1 at sqrt(s) = 8 TeV in 2012. Individual searches in the channels H->ZZ^(*)->llll, H->gamma gamma and H->WW->e nu mu nu in the 8 TeV data are combined with previously published results of searches for H->ZZ^(*), WW^(*), bbbar and tau^+tau^- in the 7 TeV data and results from improved analyses of the H->ZZ^(*)->llll and H->gamma gamma channels in the 7 TeV data. Clear evidence for the production of a neutral boson with a measured mass of 126.0 +/- 0.4(stat) +/- 0.4(sys) GeV is presented. This observation, which has a significance of 5.9 standard deviations, corresponding to a background fluctuation probability of 1.7x10^-9, is compatible with the production and decay of the Standard Model Higgs boson.","['Physics', 'Particle physics', 'Higgs boson', 'Large Hadron Collider', 'Standard Model (mathematical formulation)', 'Atlas detector', 'Boson', 'Atlas (anatomy)', 'Nuclear physics', 'ATLAS experiment', 'Physics beyond the Standard Model', 'Paleontology', 'Biology', 'Archaeology', 'Gauge (firearms)', 'History']","standard model higgs boson, atlas detector, ##hc, integrated luminosities, ##bar, neutral boson, background flu"
Paper_01341,Optimization and Nonsmooth Analysis,['Frank H. Clarke'],1990,Unknown,Unknown,,,,,10.1137/1.9781611971309,1. Introduction and Preview 2. Generalized Gradients 3. Differential Inclusions 4. The Calculus of Variations 5. Optimal Control 6. Mathematical Programming 7. Topics in Analysis.,"['Differential calculus', 'Differential inclusion', 'Calculus (dental)', 'Optimal control', 'Mathematical optimization', 'Computer science', 'Differential (mechanical device)', 'Calculus of variations', 'Mathematics', 'Applied mathematics', 'Mathematical analysis', 'Engineering', 'Medicine', 'Dentistry', 'Aerospace engineering']","generalized gradients, differential inclusions, calculus of variations, optimal control, mathematical programming, [PAD] [PAD], [PAD], [PAD] [PAD], [PAD], [PAD], [PAD], [PAD], [PAD] [PAD] [PAD], [PAD] [PAD] [PAD], [PAD] [PAD], [PAD] [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD] [PAD] [PAD], [PAD] [PAD] [PAD], [PAD] [PAD] [PAD], [PAD] [PAD]"
Paper_01342,Bodies That Matter,['Judith Butler'],2011,Routledge eBooks,Unknown,,,,,10.4324/9780203828274,"In Bodies That Matter, renowned theorist and philosopher Judith Butler argues that theories of gender need to return to the most material dimension of sex and sexuality: the body. Butler offers a brilliant reworking of the body, examining how the power of heterosexual hegemony forms the ""matter"" of bodies, sex, and gender. Butler argues that power operates to constrain sex from the start, delimiting what counts as a viable sex. She clarifies the notion of ""performativity"" introduced in Gender Trouble and via bold readings of Plato, Irigaray, Lacan, and Freud explores the meaning of a citational politics. She also draws on documentary and literature with compelling interpretations of the film Paris is Burning, Nella Larsen's Passing,&nbsp; and short stories by Willa Cather.",['Business'],"gender, heterosexual hegemony, gender, performativity, gender trouble, plato, literature"
Paper_01343,The Two Micron All Sky Survey (2MASS),"['Michael F. Skrutskie', 'R. M. Cutri', 'R. Stiening', 'Martin D. Weinberg', 'Stephen E. Schneider', 'John M. Carpenter', 'Charles Beichman', 'R. W. Capps', 'T. J. Chester', 'J. H. Elias', 'J. P. Huchra', 'James Liebert', 'C. J. Lonsdale', 'D. G. Monet', 'S. Price', 'Patrick Seitzer', 'T. H. Jarrett', 'J. Davy Kirkpatrick', 'John E. Gizis', 'Eric Howard', 'T. Evans', 'J. W. Fowler', 'L. Fullmer', 'Robert L. Hurt', 'R. M. Light', 'E. L. Kopan', 'K. A. Marsh', 'H. McCallon', 'Raymond Tam', 'Schuyler D. Van Dyk', 'S. Wheelock']",2006,The Astronomical Journal,Journal,,1163-1183,131,2,10.1086/498708,"Between 1997 June and 2001 February the Two Micron All Sky Survey (2MASS) collected 25.4 Tbytes of raw imaging data covering 99.998% of the celestial sphere in the near-infrared J (1.25 μm), H (1.65 μm), and Ks (2.16 μm) bandpasses. Observations were conducted from two dedicated 1.3 m diameter telescopes located at Mount Hopkins, Arizona, and Cerro Tololo, Chile. The 7.8 s of integration time accumulated for each point on the sky and strict quality control yielded a 10 σ point-source detection level of better than 15.8, 15.1, and 14.3 mag at the J, H, and Ks bands, respectively, for virtually the entire sky. Bright source extractions have 1 σ photometric uncertainty of <0.03 mag and astrometric accuracy of order 100 mas. Calibration offsets between any two points in the sky are <0.02 mag. The 2MASS All-Sky Data Release includes 4.1 million compressed FITS images covering the entire sky, 471 million source extractions in a Point Source Catalog, and 1.6 million objects identified as extended in an Extended Source Catalog.","['Sky', 'Physics', 'Point source', 'Celestial sphere', 'Astronomy', 'Astrophysics', 'Infrared astronomy', 'Remote sensing', 'Calibration', 'Infrared', 'Optics', 'Geography', 'Quantum mechanics']","two micron all sky survey, 2mass, strict quality control, bright source extractions, astro, cal, ##ration offset, compressed fits images, point source catalog"
Paper_01345,Designing qualitative research,"['Catherine Marshall', 'Gretchen Rossman']",1989,Choice Reviews Online,Journal,,27-1232,27,02,10.5860/choice.27-1232,"Introduction The Substance of the Study Framing the Research Question How To Conduct the Study Designing the Research Data Collection Methods Recording, Managing, and Analyzing Data Managing Time and Resources Defending the Value and Logic of Qualitative Research","['Qualitative research', 'Sociology', 'Social science']","data collection methods, qualitative research, [PAD] [PAD], [PAD] [PAD], [PAD], [PAD], [PAD]"
Paper_01347,Missing data: Our view of the state of the art.,"['Joseph L. Schafer', 'John W. Graham']",2002,Psychological Methods,Journal,,147-177,7,2,10.1037/1082-989x.7.2.147,"Statistical procedures for missing data have vastly improved, yet misconception and unsound practice still abound. The authors frame the missing-data problem, review methods, offer advice, and raise issues that remain unresolved. They clear up common misunderstandings regarding the missing at random (MAR) concept. They summarize the evidence against older procedures and, with few exceptions, discourage their use. They present, in both technical and practical language, 2 general approaches that come highly recommended: maximum likelihood (ML) and Bayesian multiple imputation (MI). Newer developments are discussed, including some for dealing with missing data that are not MAR. Although not yet in the mainstream, these procedures may eventually extend the ML and MI methods that currently represent the state of the art.","['Missing data', 'Imputation (statistics)', 'Computer science', 'Bayesian probability', 'Mainstream', 'Data science', 'Econometrics', 'Artificial intelligence', 'Mathematics', 'Machine learning', 'Political science', 'Law']","statistical procedures, missing data, unsound practice, maximum likelihood, bayesian multiple imputation"
Paper_01348,Origin of the Overpotential for Oxygen Reduction at a Fuel-Cell Cathode,"['Jens K. Nørskov', 'Jan Rossmeisl', 'Á. Logadóttir', 'L. Lindqvist', 'John R. Kitchin', 'Thomas Bligaard', 'Hannes Jónsson']",2004,The Journal of Physical Chemistry B,Journal,,17886-17892,108,46,10.1021/jp047349j,"We present a method for calculating the stability of reaction intermediates of electrochemical processes on the basis of electronic structure calculations. We used that method in combination with detailed density functional calculations to develop a detailed description of the free-energy landscape of the electrochemical oxygen reduction reaction over Pt(111) as a function of applied bias. This allowed us to identify the origin of the overpotential found for this reaction. Adsorbed oxygen and hydroxyl are found to be very stable intermediates at potentials close to equilibrium, and the calculated rate constant for the activated proton/electron transfer to adsorbed oxygen or hydroxyl can account quantitatively for the observed kinetics. On the basis of a database of calculated oxygen and hydroxyl adsorption energies, the trends in the oxygen reduction rate for a large number of different transition and noble metals can be accounted for. Alternative reaction mechanisms involving proton/electron transfer to adsorbed molecular oxygen were also considered, and this peroxide mechanism was found to dominate for the most noble metals. The model suggests ways to improve the electrocatalytic properties of fuel-cell cathodes.","['Overpotential', 'Chemistry', 'Electrochemistry', 'Electron transfer', 'Oxygen', 'Adsorption', 'Inorganic chemistry', 'Reaction rate constant', 'Cathode', 'Redox', 'Photochemistry', 'Physical chemistry', 'Chemical physics', 'Kinetics', 'Electrode', 'Organic chemistry', 'Physics', 'Quantum mechanics']","reaction intermediates, electrochemical processes, electronic structure calculations, density functional calculations, electrochemical oxygen reduction reaction, overpot, ads, ##bed oxygen, ##l adsorption energies, oxygen reduction rate, noble, ##cat, ##tic properties"
Paper_01349,The New York Botanical Garden Herbarium (NY) - Vascular Plant Collection,['Ae c B a d a B a c a'],2015,Unknown,Unknown,,,,,10.15468/6e8nje,Vascular specimens from The New York Botanical Garden's William and Lynda Steere Herbarium.,"['Herbarium', 'Botanical garden', 'Vascular plant', 'Geography', 'Forestry', 'Archaeology', 'Biology', 'Botany', 'Ecology', 'Species richness']",vascular
Paper_01350,Automated docking using a Lamarckian genetic algorithm and an empirical binding free energy function,"['Garrett M. Morris', 'David S. Goodsell', 'Robert S. Halliday', 'Ruth Huey', 'William E. Hart', 'Richard K. Belew', 'Arthur J. Olson']",1998,Journal of Computational Chemistry,Journal,,1639-1662,19,14,10.1002/(sici)1096-987x(19981115)19:14<1639::aid-jcc10>3.0.co;2-b,"A novel and robust automated docking method that predicts the bound conformations of flexible ligands to macromolecular targets has been developed and tested, in combination with a new scoring function that estimates the free energy change upon binding. Interestingly, this method applies a Lamarckian model of genetics, in which environmental adaptations of an individual's phenotype are reverse transcribed into its genotype and become heritable traits (sic). We consider three search methods, Monte Carlo simulated annealing, a traditional genetic algorithm, and the Lamarckian genetic algorithm, and compare their performance in dockings of seven protein–ligand test systems having known three-dimensional structure. We show that both the traditional and Lamarckian genetic algorithms can handle ligands with more degrees of freedom than the simulated annealing method used in earlier versions of AUTODOCK, and that the Lamarckian genetic algorithm is the most efficient, reliable, and successful of the three. The empirical free energy function was calibrated using a set of 30 structurally known protein–ligand complexes with experimentally determined binding constants. Linear regression analysis of the observed binding constants in terms of a wide variety of structure-derived molecular properties was performed. The final model had a residual standard error of 9.11 kJ mol−1 (2.177 kcal mol−1) and was chosen as the new energy function. The new search methods and empirical free energy function are available in AUTODOCK, version 3.0. © 1998 John Wiley & Sons, Inc. J Comput Chem 19: 1639–1662, 1998","['AutoDock', 'Simulated annealing', 'Docking (animal)', 'Genetic algorithm', 'Algorithm', 'Monte Carlo method', 'Computer science', 'Mathematics', 'Mathematical optimization', 'Chemistry', 'Statistics', 'In silico', 'Medicine', 'Nursing', 'Biochemistry', 'Gene']","automated docking method, bound conformations, flexible ligands, ##lecular, scoring function, free energy change, lamarckian model, genetics, her, ##ble, monte carlo simulated annealing, lamarckian genetic algorithm, simulated annealing, ##dock, lamar, ##an genetic algorithm, linear regression, empirical free energy function, ##dock"
Paper_01351,"Greengenes, a Chimera-Checked 16S rRNA Gene Database and Workbench Compatible with ARB","['Todd Z. DeSantis', 'Philip Hugenholtz', 'N. Larsen', 'Mark Rojas', 'Eoin Brodie', 'Keith Keller', 'Thomas Huber', 'Daniel Dalevi', 'Pengwei Hu', 'Gary L. Andersen']",2006,Applied and Environmental Microbiology,Journal,,5069-5072,72,7,10.1128/aem.03006-05,"A 16S rRNA gene database (http://greengenes.lbl.gov ) addresses limitations of public repositories by providing chimera screening, standard alignment, and taxonomic classification using multiple published taxonomies. It was found that there is incongruent taxonomic nomenclature among curators even at the phylum level. Putative chimeras were identified in 3% of environmental sequences and in 0.2% of records derived from isolates. Environmental sequences were classified into 100 phylum-level lineages in the Archaea and Bacteria.","['Phylum', '16S ribosomal RNA', 'Biology', 'Workbench', 'Bacterial taxonomy', 'Chimera (genetics)', 'Archaea', 'Ribosomal RNA', 'Gene', 'Computational biology', 'Taxonomic rank', 'Genetics', 'Database', 'Data mining', 'Ecology', 'Computer science', 'Taxon', 'Visualization']","16, chimera screening, standard alignment, taxonomic classification, taxonomic nomenclature, putative chimeras, environmental sequences, [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD], [PAD], [PAD], [PAD] [PAD], [PAD], [PAD], [PAD]"
Paper_01352,Electronic Population Analysis on LCAO–MO Molecular Wave Functions. I,['Robert S. Mulliken'],1955,The Journal of Chemical Physics,Journal,,1833-1840,23,10,10.1063/1.1740588,"With increasing availability of good all‐electron LCAO MO (LCAO molecular orbital) wave functions for molecules, a systematic procedure for obtaining maximum insight from such data has become desirable. An analysis in quantitative form is given here in terms of breakdowns of the electronic population into partial and total ``gross atomic populations,'' or into partial and total ``net atomic populations'' together with ``overlap populations.'' ``Gross atomic populations'' distribute the electrons almost perfectly among the various AOs (atomic orbitals) of the various atoms in the molecule. From these numbers, a definite figure is obtained for the amount of promotion (e.g., from 2s to 2p) in each atom; and also for the gross charge Q on each atom if the bonds are polar. The total overlap population for any pair of atoms in a molecule is in general made up of positive and negative contributions. If the total overlap population between two atoms is positive, they are bonded; if negative, they are antibonded.Tables of gross atomic populations and overlap populations, also gross atomic charges Q, computed from SCF (self‐consistent field) LCAO‐MO data on CO and H2O, are given. The amount of s‐p promotion is found to be nearly the same for the O atom in CO and in H2O (0.14 electron in CO and 0.15e in H2O). For the C atom in CO it is 0.50e. For the N atom in N2 it is 0.26e according to calculations by Scherr. In spite of very strong polarity in the π bonds in CO, the σ and π overlap populations are very similar to those in N2. In CO the total overlap population for the π electrons is about twice that for the σ electrons. The most easily ionized electrons of CO are in an MO such that its gross atomic population is 94% localized on the carbon atom; these electrons account for the (weak) electron donor properties of CO. A comparison between changes of bond lengths observed on removal of an electron from one or another MO of CO and H2, and corresponding changes in computed overlap populations, shows good correlation. Several other points of interest are discussed.","['Linear combination of atomic orbitals', 'Atom (system on chip)', 'Atomic physics', 'Molecular orbital', 'Atomic orbital', 'Population', 'Chemistry', 'Molecule', 'Electron', 'Partial charge', 'Computational chemistry', 'Physics', 'Quantum mechanics', 'Demography', 'Organic chemistry', 'Sociology', 'Computer science', 'Embedded system']","wave functions, gross atomic populations, gross atomic populations, overlap populations, gross atomic charges, π, π, π, σ"
Paper_01354,Aplikasi Analisis Multivariate Dengan Program IBM SPSS 25,['H. Imam Ghozali'],2018,Unknown,Unknown,,,,,10.31219/osf.io/fwex8,"Bab 1 : Skala Pengukuran dan Metode Analisis Data
Bab 2 : Pengnalan Program SPSS, Aplikasi Statistik Deskriptif
dan Crosstab.
Bab 3 : Data Screening dan Transformasi data
Bab 4 : Uji Validitas dan Reliabilitas Suatu Konstruk
Bab 5 : Uji Beda, ANOVA, ANCOVA dan MANOVA
Bab 6 : Analisis Regresi
Bab 7 : Uji Asumsi Klasik
Bab 8 : Regresi dengan Asumsi Klasik, Variabel Dummy dan
Chow test
Bab 9 : Model Regresi dengan Bentuk Fungsional
Bab 10 : Analisis Regresi Moderasi
Bab 11 : Regresi dengan Variabel Mediator
Bab 12 : Regresi dengan Variabel Moderator
Bab 13 : Analisis Diskriminan

Bab 14 : Logistic Regression
Bab 15 : Korelasi Kanonikal
Bab 16 : Analisis Conjoint
Bab 17 : Analisis Faktor
Bab 18 : Analisis Kluster
Bab 19 : Multidimensional Scaling
Bab 20 : Loglinear Analisis","['Mathematics', 'Statistics', 'Test (biology)', 'Paleontology', 'Biology']","skala penguk, met, pengnal, aplikasi statistik, data screening, transformasi data, ##ji validitas, ##liabil, anova, an, man, anal, ##bel, model regres, anal, ##s, ##i, analisis diskriminan, logistic regression, korelasi kan, analisis, analisis faktor, analisis kluster, multidimensional scaling, loglinear analisis"
Paper_01355,Language and Symbolic Power.,"['William A. Corsaro', 'Pierre Bourdieu']",1992,Social Forces,Journal,,242-242,71,1,10.2307/2579985,Preface Editor's Introduction General Introduction Part I The Economy of Linguistic Exchanges Introduction 1. The Production and Reproduction of Legitimate Language 2. Price Formation and the Anticipation of Profits Appendix: Did You Say 'Popular'? Part II The Social Institution of Symbolic Power Introduction 3. Authorized Language: The Social Conditions for the Effectiveness of Ritual Discourse 4. Rites of Institution 5. Description and Prescription: The Conditions of Possibility and the Limits of Political Effectiveness 6. Censorship and the Imposition of Form Part III Symbolic Power and the Political Field 7. On Symbolic Power 8. Political Representation: Elements for a Theory of the Political Field 9. Delegation and Political Fetishism 10. Identity and Representation: Elements for a Critical Reflection on the Idea of Region 11. Social Space and the Genesis of 'Classes' Note Index,"['Symbolic power', 'Institution', 'Politics', 'Sociology', 'Field (mathematics)', 'Power (physics)', 'The Symbolic', 'Symbolic capital', 'Identity (music)', 'Linguistics', 'Epistemology', 'Social science', 'Law', 'Political science', 'Aesthetics', 'Psychology', 'Philosophy', 'Mathematics', 'Physics', 'Quantum mechanics', 'Psychoanalysis', 'Pure mathematics']","linguistic exchanges, legitimate language, price formation, profits, social institution, symbolic power, ritual discourse, political effectiveness, censorship, symbolic power, political field, symbolic power, political representation, delegation, political fetishism, identity, social space, [PAD]"
Paper_01357,Investment Under Uncertainty.,"['Eduardo S. Schwartz', 'Avinash Dixit', 'Robert S. Pindyck']",1994,The Journal of Finance,Journal,,1924-1924,49,5,10.2307/2329279,"How should firms decide whether and when to invest in new capital equipment, additions to their workforce, or the development of new products? Why have traditional economic models of investment failed to explain the behavior of investment spending in the United States and other countries? In this book, Avinash Dixit and Robert Pindyck provide the first detailed exposition of a new theoretical approach to the capital investment decisions of firms, stressing the irreversibility of most investment decisions, and the ongoing uncertainty of the economic environment in which these decisions are made. In so doing, they answer important questions about investment decisions and the behavior of investment spending.This new approach to investment recognizes the option value of waiting for better (but never complete) information. It exploits an analogy with the theory of options in financial markets, which permits a much richer dynamic framework than was possible with the traditional theory of investment. The authors present the new theory in a clear and systematic way, and consolidate, synthesize, and extend the various strands of research that have come out of the theory. Their book shows the importance of the theory for understanding investment behavior of firms; develops the implications of this theory for industry dynamics and for government policy concerning investment; and shows how the theory can be applied to specific industries and to a wide variety of business problems.","['Economics', 'Investment (military)', 'Business', 'Political science', 'Law', 'Politics']","capital, economic models, investment, investment spending, capital investment decisions, investment spending, options, financial markets, investment behavior, industry dynamics, government policy"
Paper_01358,Unified Approach for Molecular Dynamics and Density-Functional Theory,"['Roberto Car', 'Michele Parrinello']",1985,Physical Review Letters,Journal,,2471-2474,55,22,10.1103/physrevlett.55.2471,"We present a unified scheme that, by combining molecular dynamics and density-functional theory, profoundly extends the range of both concepts. Our approach extends molecular dynamics beyond the usual pair-potential approximation, thereby making possible the simulation of both covalently bonded and metallic systems. In addition it permits the application of density-functional theory to much larger systems than previously feasible. The new technique is demonstrated by the calculation of some static and dynamic properties of crystalline silicon within a self-consistent pseudopotential framework.","['Pseudopotential', 'Density functional theory', 'Molecular dynamics', 'Statistical physics', 'Range (aeronautics)', 'Functional theory', 'Physics', 'Computer science', 'Materials science', 'Quantum mechanics', 'Composite material']","unified scheme, molecular dynamics, molecular dynamics, covalently, metallic systems, dynamic properties, crystalline silicon, [PAD], [PAD]"
Paper_01359,THE PREPARATION OF 131I-LABELLED HUMAN GROWTH HORMONE OF HIGH SPECIFIC RADIOACTIVITY,"['FC Greenwood', 'WM Hunter', 'J. Glover']",1963,Biochemical Journal,Journal,,114-123,89,1,10.1042/bj0890114,"A simple and rapid method is presented for the preparation of I/sup 131/- labeled human growth hormone of high specific radioactivity (240-300 mu C/ mu g). Low amounts of carrierfree I/sup 131/ iodide (2 mC) are allowed to react, without prior treatment, with small quantities of protein (5 mu g) in a highyield reaction (approx. 70% transfer of I/sup 131/ to protein). The degree of chemical substitution is minimized (0.5- 1.0 atom of iodine/molecule of protein) by the use of carrier-free I/sup 131/ iodide. The I/sup 131/-labeled hormone (up to 300 mu C/ mu g) contains no detectable degradation products and is immunologically identical with the unlabeled hormone. The loss of immunological reactivity at high specific radioactivities or at high levels of chemical substitution with STAI/sup 127/!iodine is demonstrated. (auth)","['Radiochemistry', 'Chemistry', 'Human growth hormone', 'Hormone', 'Biochemistry', 'Chromatography', 'Growth hormone', 'Endocrinology', 'Biology']","human growth hormone, ##eld"
Paper_01361,Information Systems Success: The Quest for the Dependent Variable,"['William DeLone', 'Ephraim R. McLean']",1992,Information Systems Research,Journal,,60-95,3,1,10.1287/isre.3.1.60,"A large number of studies have been conducted during the last decade and a half attempting to identify those factors that contribute to information systems success. However, the dependent variable in these studies—I/S success—has been an elusive one to define. Different researchers have addressed different aspects of success, making comparisons difficult and the prospect of building a cumulative tradition for I/S research similarly elusive. To organize this diverse research, as well as to present a more integrated view of the concept of I/S success, a comprehensive taxonomy is introduced. This taxonomy posits six major dimensions or categories of I/S success—SYSTEM QUALITY, INFORMATION QUALITY, USE, USER SATISFACTION, INDIVIDUAL IMPACT, and ORGANIZATIONAL IMPACT. Using these dimensions, both conceptual and empirical studies are then reviewed (a total of 180 articles are cited) and organized according to the dimensions of the taxonomy. Finally, the many aspects of I/S success are drawn together into a descriptive model and its implications for future I/S research are discussed.","['Taxonomy (biology)', 'Knowledge management', 'Information system', 'Computer science', 'Empirical research', 'Information quality', 'Management science', 'Data science', 'Political science', 'Engineering', 'Mathematics', 'Statistics', 'Botany', 'Law', 'Biology']","information systems success, system quality, information quality, use, user satisfaction, individual impact, organizational impact, descriptive model"
Paper_01362,Aggregated Residual Transformations for Deep Neural Networks,"['Saining Xie', 'Ross Girshick', 'Piotr Dollár', 'Zhuowen Tu', 'Kaiming He']",2017,Unknown,Unknown,,,,,10.1109/cvpr.2017.634,"We present a simple, highly modularized network architecture for image classification. Our network is constructed by repeating a building block that aggregates a set of transformations with the same topology. Our simple design results in a homogeneous, multi-branch architecture that has only a few hyper-parameters to set. This strategy exposes a new dimension, which we call cardinality (the size of the set of transformations), as an essential factor in addition to the dimensions of depth and width. On the ImageNet-1K dataset, we empirically show that even under the restricted condition of maintaining complexity, increasing cardinality is able to improve classification accuracy. Moreover, increasing cardinality is more effective than going deeper or wider when we increase the capacity. Our models, named ResNeXt, are the foundations of our entry to the ILSVRC 2016 classification task in which we secured 2nd place. We further investigate ResNeXt on an ImageNet-5K set and the COCO detection set, also showing better results than its ResNet counterpart. The code and models are publicly available online.","['Cardinality (data modeling)', 'Set (abstract data type)', 'Computer science', 'Dimension (graph theory)', 'Simple (philosophy)', 'Block (permutation group theory)', 'Artificial neural network', 'Residual', 'Code (set theory)', 'Architecture', 'Theoretical computer science', 'Homogeneous', 'Artificial intelligence', 'Machine learning', 'Algorithm', 'Data mining', 'Mathematics', 'Programming language', 'Combinatorics', 'Art', 'Philosophy', 'Epistemology', 'Visual arts']","highly modularized network architecture, image classification, cardinality, cardinality, classification, cardinality, resnext, ilsvr, coco detection set, res"
Paper_01366,On enantiomorph-polarity estimation,['H. D. Flack'],1983,Acta Crystallographica Section A Foundations of Crystallography,Journal,,876-881,39,6,10.1107/s0108767383001762,"The behaviour of Rogers's η parameter for enantiomorph-polarity estimation is examined theoretically and experimentally on simulated intensity data for seven well-assorted compounds. An alternative parameter x, based on incoherent scattering from twin components related by a centre of symmetry, is also considered. It is found that both parameters are very well adapted to implementation in a least-squares program and converge well. The η parameter can give false and over-precise indications of chirality-polarity for structures which are nearly centrosymmetric, whereas the x parameter does not have this fault and converges more rapidly than η.","['Polarity (international relations)', 'Symmetry (geometry)', 'Fault (geology)', 'Chirality (physics)', 'Estimation theory', 'Scattering', 'Least-squares function approximation', 'Statistical physics', 'Physics', 'Computer science', 'Mathematics', 'Algorithm', 'Optics', 'Statistics', 'Chemistry', 'Symmetry breaking', 'Geology', 'Quantum mechanics', 'Geometry', 'Biochemistry', 'Estimator', 'Seismology', 'Nambu–Jona-Lasinio model', 'Cell', 'Chiral symmetry breaking']","η parameter, simulated intensity data, incoherent scattering, twin components, centre of symmetry, [PAD] [PAD] [PAD] [PAD]"
Paper_01370,IMPROVEMENTS IN EPOXY RESIN EMBEDDING METHODS,['John H. Luft'],1961,The Journal of Cell Biology,Journal,,409-414,9,2,10.1083/jcb.9.2.409,"Epoxy embedding methods of Glauert and Kushida have been modified so as to yield rapid, reproducible, and convenient embedding methods for electron microscopy. The sections are robust and tissue damage is less than with methacrylate embedding.","['Epoxy', 'Embedding', 'Yield (engineering)', 'Methacrylate', 'Electron microscope', 'Materials science', 'Composite material', 'Mathematics', 'Computer science', 'Artificial intelligence', 'Polymer', 'Physics', 'Optics', 'Copolymer']","epoxy embedding methods, embedding, electron microscopy, tissue damage, methacr, ##te embedding"
Paper_01371,Synchronization in chaotic systems,"['Louis M. Pecora', 'Thomas L. Carroll']",1990,Physical Review Letters,Journal,,821-824,64,8,10.1103/physrevlett.64.821,"Certain subsystems of nonlinear, chaotic systems can be made to synchronize by linking them with common signals. The criterion for this is the sign of the sub-Lyapunov exponents. We apply these ideas to a real set of synchronizing chaotic circuits.","['Synchronizing', 'Lyapunov exponent', 'Chaotic', 'Synchronization of chaos', 'Synchronization (alternating current)', 'Chaotic systems', 'Nonlinear system', 'Computer science', 'Electronic circuit', 'Sign (mathematics)', 'Set (abstract data type)', 'Control theory (sociology)', 'Statistical physics', 'Physics', 'Mathematics', 'Mathematical analysis', 'Quantum mechanics', 'Telecommunications', 'Artificial intelligence', 'Channel (broadcasting)', 'Control (management)', 'Transmission (telecommunications)', 'Programming language']",synchronizing chaotic circuits
Paper_01374,"Risk, Uncertainty and Profit",['Frank H. Knight'],1921,['The Quarterly Journal of Economics'],Unknown,,682,36,4,10.2307/1884757,"Examines the role played by true uncertainty, defined as the possibility of alternative outcomes whose probabilities are not capable of measurement, in an economic system, and distinguishes uncertainty from risk. Classical economic theory teaches that perfect competition ought to drive an economy into equilibrium and eliminate opportunities for economic profit. Nevertheless, economic profit persists in the real world. The introductory sections of the book provide a historical and critical review of early attempts to reconcile theory and observation. Then, beginning with a simplified model economy of individuals as producers-and-consumers, the author derives familiar features of static economics. The model goes through further refinements of joint production, and changes with uncertainty absent with similar results. The final model is one that demonstrates how perfect competition tends to eliminate profit. The author then takes up the question of how risk and uncertainty may upset the equilibrium. Risk is the possibility of alternative outcomes whose probabilities are capable of measurement; uncertainty is the possibility of alternative outcome whose probabilities are not capable of measurement. When probabilities are known, adverse outcomes may be insured against. Uncertainty is handled by judgment, an unequally distributed ability. The successful entrepreneur is one who has the sound judgment, either in the direction of the enterprise itself or in the selection of its managers (as shareholders do). The recompense for this talent is profit. (CAR)","['Profit (economics)', 'Economics', 'Shareholder', 'Adverse selection', 'Outcome (game theory)', 'Microeconomics', 'Competition (biology)', 'Finance', 'Ecology', 'Corporate governance', 'Biology']","true uncertainty, alternative outcomes, pro, risk, classical economic theory, perfect competition, economic profit, static economics, joint production, perfect competition, risk, uncertainty"
Paper_01375,Perry's chemical engineers' handbook,"['Robert Howard Perry', 'Don Wesley Green', 'James O Maloney']",2008,Choice Reviews Online,Journal,,45-4393,45,08,10.5860/choice.45-4393,"Section 1: Conversion Factors and Mathematical Symbols Section 2: Physical and Chemical Data Section 3: Mathematics Section 4: Thermodynamics Section 5: Heat and Mass Transfer Section 6: Fluid and Plastic Dynamics Section 7: Reaction Kinetics Section 8: Process Control Section 9: Process Economics Section 10: Transport and Storage of Fluids Section 11: Heat-Transfer Equipment Section 12: Psychrometry, Evaporative Cooling, and Solids Drying Section 13: Distillation Section 14: Equipment for Distillation, Gas Absorption, Phase Dispersion, and Phase Separation Section 15: Liquid-Liquid Extraction and Other Liquid-Liquid Operations and Equipment Section 16: Adsorption and Ion Exchange Section 17: Gas-Solid Operations and Equipment Section 18: Liquid-Solid Operations and Equipment Section 19: Reactors Section 20: Alternative Separation Processes Section 21: Solid-Solid Operations and Processing Section 22: Waste Management Section 23: Process Safety Section 24: Energy Resources, Conversion, and Utilization Section 25: Materials of Construction Index",['Engineering'],"conversion factors, mathematical symbols, chemical data, mathematics, thermodyna, mass transfer, plastic dynamics, reaction kinetics, process control, process economics, psychrometry, evaporative cooling, solids drying, distillation, distillation, gas absorption, phase dispersion, phase separation, adsorption, ion exchange, reactors, alternative separation processes, waste management, process safety, energy resources, utilization, materials of construction, [PAD] [PAD] [PAD]"
Paper_01377,Construct validity in psychological tests.,"['Lee J. Cronbach', 'Paul E. Meehl']",1955,Psychological Bulletin,Journal,,281-302,52,4,10.1037/h0040957,"Validation of psychological tests has not yet been adequately conceptualized, as the APA Committee on Psychological Tests learned when it undertook (1950-54) to specify what qualities should be investigated before a test is published. In order to make coherent recommendations the Committee found it necessary to distinguish four types of validity, established by different types of research and requiring different interpretation. The chief innovation in the Committee's report was the term construct validity.[2] This idea was first formulated by a subcommittee (Meehl and R. C. Challman) studying how proposed recommendations would apply to projective techniques, and later modified and clarified by the entire Committee (Bordin, Challman, Conrad, Humphreys, Super, and the present writers). The statements agreed upon by the Committee (and by committees of two other associations) were published in the Technical Recommendations (59). The present interpretation of construct validity is not official and deals with some areas where the Committee would probably not be unanimous. The present writers are solely responsible for this attempt to explain the concept and elaborate its implications.","['Construct validity', 'Psychology', 'Construct (python library)', 'Psychological testing', 'Test validity', 'Psychometrics', 'Social psychology', 'Cognitive psychology', 'Clinical psychology', 'Computer science', 'Programming language']","psychological tests, apa, psychological tests, term construct validity, projective techniques, construct validity"
Paper_01378,Posttraumatic Stress Disorder in the National Comorbidity Survey,['Ronald C. Kessler'],1995,Archives of General Psychiatry,Journal,,1048-1048,52,12,10.1001/archpsyc.1995.03950240066012,"Data were obtained on the general population epidemiology of DSM-III-R posttraumatic stress disorder (PTSD), including information on estimated life-time prevalence, the kinds of traumas most often associated with PTSD, sociodemographic correlates, the comorbidity of PTSD with other lifetime psychiatric disorders, and the duration of an index episode.Modified versions of the DSM-III-R PTSD module from the Diagnostic Interview Schedule and of the Composite International Diagnostic Interview were administered to a representative national sample of 5877 persons aged 15 to 54 years in the part II subsample of the National Comorbidity Survey.The estimated lifetime prevalence of PTSD is 7.8%. Prevalence is elevated among women and the previously married. The traumas most commonly associated with PTSD are combat exposure and witnessing among men and rape and sexual molestation among women. Posttraumatic stress disorder is strongly comorbid with other lifetime DSM-III-R disorders. Survival analysis shows that more than one third of people with an index episode of PTSD fail to recover even after many years.Posttraumatic stress disorder is more prevalent than previously believed, and is often persistent. Progress in estimating age-at-onset distributions, cohort effects, and the conditional probabilities of PTSD from different types of trauma will require future epidemiologic studies to assess PTSD for all lifetime traumas rather than for only a small number of retrospectively reported ""most serious"" traumas.","['Comorbidity', 'National Comorbidity Survey', 'Psychiatry', 'Posttraumatic stress', 'Epidemiology', 'Population', 'Psychology', 'Clinical psychology', 'Medicine', 'Internal medicine', 'Environmental health']","general population epidemiology, posttraumatic stress disorder, diagnostic interview, combat exposure, sexual molestation, women, ##tra, survival, posttraumatic stress disorder"
Paper_01379,Fast robust automated brain extraction,['Stephen M. Smith'],2002,Human Brain Mapping,Journal,,143-155,17,3,10.1002/hbm.10062,"Abstract An automated method for segmenting magnetic resonance head images into brain and non‐brain has been developed. It is very robust and accurate and has been tested on thousands of data sets from a wide variety of scanners and taken with a wide variety of MR sequences. The method, Brain Extraction Tool (BET), uses a deformable model that evolves to fit the brain's surface by the application of a set of locally adaptive model forces. The method is very fast and requires no preregistration or other pre‐processing before being applied. We describe the new method and give examples of results and the results of extensive quantitative testing against “gold‐standard” hand segmentations, and two other popular automated methods. Hum. Brain Mapping 17:143–155, 2002. © 2002 Wiley‐Liss, Inc.","['Computer science', 'Artificial intelligence', 'Segmentation', 'Set (abstract data type)', 'Automated method', 'Gold standard (test)', 'Pattern recognition (psychology)', 'Variety (cybernetics)', 'Computer vision', 'Image processing', 'Data set', 'Head (geology)', 'Image (mathematics)', 'Mathematics', 'Biology', 'Paleontology', 'Statistics', 'Programming language']","automated method, magnetic resonance head images, non ‐, mr, brain extraction tool, deformable model, locally adaptive model forces, quantitative testing, hand segmentations, brain mapping"
Paper_01380,Applied Multivariate Statistics for the Social Sciences,['James P. Stevens'],2012,Routledge eBooks,Unknown,,,,,10.4324/9780203843130,"This best-selling text is written for those who use, rather than develop, advanced statistical methods. Dr. Stevens focuses on a conceptual understanding of the material rather than proving results. Helpful narrative and numerous examples enhance understanding, and a chapter on matrix algebra serves as a review. Printouts from SPSS and SAS with annotations indicate what the numbers mean and encourage interpretation of the results. In addition to demonstrating how to use the packages effectively, the author stresses the importance of checking the data, assessing the assumptions, and ensuring adequate sample size (by providing guidelines) so that the results can be generalized. The new edition features a CD-ROM with the data sets and many new exercises. Ideal for courses on advanced or multivariate statistics found in psychology, education, and business departments, the book also appeals to practicing researchers with little or no training in multivariate methods. Prerequisites include a course on factorial analysis of variance. It does not assume a working knowledge of matrix algebra.","['Multivariate statistics', 'Statistics', 'Multivariate analysis', 'Social statistics', 'Econometrics', 'Mathematics']","advanced statistical methods, matrix algebra, ##ss, multivariate statistics, business, multivariate methods, factorial analysis, variance, matrix algebra"
Paper_01381,The Fagerström Test for Nicotine Dependence: a revision of the Fagerstrom Tolerance Questionnaire,"['Todd F. Heatherton', 'Lynn T. Kozlowski', 'Richard C. Frecker', 'Karl‐Olov Fagerström']",1991,British Journal of Addiction,Journal,,1119-1127,86,9,10.1111/j.1360-0443.1991.tb01879.x,"We examine and refine the Fagerström Tolerance Questionnaire (FTQ: Fagerström, 1978). The relation between each FTQ item and biochemical measures of heaviness of smoking was examined in 254 smokers. We found that the nicotine rating item and the inhalation item were unrelated to any of our biochemical measures and these two items were primary contributors to psychometric deficiencies in the FTQ. We also found that a revised scoring of time to the first cigarette of the day (TTF) and number of cigarettes smoked per day (CPD) improved the scale. We present a revision of the FTQ: the Fagerström Test for Nicotine Dependence (FTND).","['Nicotine', 'Nicotine dependence', 'Test (biology)', 'Psychology', 'Rating scale', 'Psychometric testing', 'Clinical psychology', 'Medicine', 'Psychometrics', 'Psychiatry', 'Developmental psychology', 'Internal consistency', 'Paleontology', 'Biology']","fagerstrom tolerance questionnaire, ft, biochemical measures, heaviness, nicotine rating item, inhalation item, psychometric deficiencies, fagerstrom test, nicotine dependence, [PAD] [PAD] [PAD] [PAD] [PAD], [PAD] [PAD], [PAD]"
Paper_01382,jModelTest: Phylogenetic Model Averaging,['David Posada'],2008,Molecular Biology and Evolution,Journal,,1253-1256,25,7,10.1093/molbev/msn083,"jModelTest is a new program for the statistical selection of models of nucleotide substitution based on ""Phyml"" (Guindon and Gascuel 2003. A simple, fast, and accurate algorithm to estimate large phylogenies by maximum likelihood. Syst Biol. 52:696–704.). It implements 5 different selection strategies, including ""hierarchical and dynamical likelihood ratio tests,"" the ""Akaike information criterion,"" the ""Bayesian information criterion,"" and a ""decision-theoretic performance-based"" approach. This program also calculates the relative importance and model-averaged estimates of substitution parameters, including a model-averaged estimate of the phylogeny. jModelTest is written in Java and runs under Mac OSX, Windows, and Unix systems with a Java Runtime Environment installed. The program, including documentation, can be freely downloaded from the software section at http://darwin.uvigo.es.","['Akaike information criterion', 'Bayesian information criterion', 'Biology', 'Java', 'Model selection', 'Substitution (logic)', 'Phylogenetic tree', 'Unix', 'Software', 'Darwin (ADL)', 'Maximum likelihood', 'Bayesian probability', 'Selection (genetic algorithm)', 'Computer science', 'Bayes factor', ""Bayes' theorem"", 'Statistics', 'Machine learning', 'Artificial intelligence', 'Programming language', 'Mathematics', 'Genetics', 'Software engineering', 'Gene']","jmodeltest, statistical selection, nucleotide substitution, phyml, ##ylogen, maximum likelihood, ##st, hierarchical, dynamical likelihood ratio tests, akaike information criterion, bayesian information criterion, substitution, jmodeltest, unix, java"
Paper_01386,Textbook of Medical Physiology,"['Arthur C. Guyton', 'John E. Hall']",1966,Annals of Internal Medicine,Journal,,1363-1363,64,6,10.7326/0003-4819-64-6-1363_2,"Textbook of medical physiology , Textbook of medical physiology , کتابخانه دیجیتال جندی شاپور اهواز","['Medicine', 'Physiology', 'Intensive care medicine']","medical physiology, medical physiology, [PAD]"
Paper_01387,Whatever happened to qualitative description?,['Margarete Sandelowski'],2000,Research in Nursing & Health,Journal,,334-340,23,4,10.1002/1098-240x(200008)23:4<334::aid-nur9>3.0.co;2-g,"The general view of descriptive research as a lower level form of inquiry has influenced some researchers conducting qualitative research to claim methods they are really not using and not to claim the method they are using: namely, qualitative description. Qualitative descriptive studies have as their goal a comprehensive summary of events in the everyday terms of those events. Researchers conducting qualitative descriptive studies stay close to their data and to the surface of words and events. Qualitative descriptive designs typically are an eclectic but reasonable combination of sampling, and data collection, analysis, and re-presentation techniques. Qualitative descriptive study is the method of choice when straight descriptions of phenomena are desired. © 2000 John Wiley & Sons, Res Nurs Health 23:334–340, 2000.","['Qualitative research', 'Descriptive research', 'Descriptive statistics', 'Presentation (obstetrics)', 'Qualitative property', 'Data collection', 'Data presentation', 'Research design', 'Psychology', 'Qualitative analysis', 'Computer science', 'Sociology', 'Medicine', 'Statistics', 'Mathematics', 'Social science', 'Radiology', 'Machine learning']","descriptive research, qualitative research, qualitative description, qualitative descriptive studies, qualitative descriptive studies, qualitative descriptive designs, qualitative descriptive study"
Paper_01388,Signal detection theory and psychophysics,"['David Marvin Green', 'John A. Swets']",1966,['Journal of Sound and Vibration'],Unknown,,519-521,5,3,10.1016/0022-460x(67)90197-6,Book on statistical decision theory and sensory processes in signal detection theory and psychophysics,"['Psychophysics', 'Detection theory', 'SIGNAL (programming language)', 'Computer science', 'Psychology', 'Cognitive science', 'Neuroscience', 'Perception', 'Telecommunications', 'Detector', 'Programming language']","statistical decision theory, sensory processes, signal detection theory, psychophysics, [PAD] [PAD] [PAD], [PAD], [PAD], [PAD], [PAD] [PAD] [PAD], [PAD] [PAD], [PAD] [PAD] [PAD], [PAD] [PAD], [PAD] [PAD], [PAD], [PAD], [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD], [PAD] [PAD], [PAD] [PAD], [PAD] [PAD] [PAD], [PAD], [PAD] [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD]"
Paper_01389,Second-generation PLINK: rising to the challenge of larger and richer datasets,"['Christopher Chang', 'Carson C. Chow', 'Laurent CAM Tellier', 'Shashaank Vattikuti', 'Shaun Purcell', 'James J. Lee']",2015,GigaScience,Journal,,,4,1,10.1186/s13742-015-0047-8,"PLINK 1 is a widely used open-source C/C++ toolset for genome-wide association studies (GWAS) and research in population genetics. However, the steady accumulation of data from imputation and whole-genome sequencing studies has exposed a strong need for even faster and more scalable implementations of key functions. In addition, GWAS and population-genetic data now frequently contain probabilistic calls, phase information, and/or multiallelic variants, none of which can be represented by PLINK 1's primary data format. To address these issues, we are developing a second-generation codebase for PLINK. The first major release from this codebase, PLINK 1.9, introduces extensive use of bit-level parallelism, O(sqrt(n))-time/constant-space Hardy-Weinberg equilibrium and Fisher's exact tests, and many other algorithmic improvements. In combination, these changes accelerate most operations by 1-4 orders of magnitude, and allow the program to handle datasets too large to fit in RAM. This will be followed by PLINK 2.0, which will introduce (a) a new data format capable of efficiently representing probabilities, phase, and multiallelic variants, and (b) extensions of many functions to account for the new types of information. The second-generation versions of PLINK will offer dramatic improvements in performance and compatibility. For the first time, users without access to high-end computing resources can perform several essential analyses of the feature-rich and very large genetic datasets coming into use.","['Genome-wide association study', 'Linkage disequilibrium', 'Imputation (statistics)', 'Genetic association', 'Population stratification', 'Computer science', 'Population', 'Computational biology', 'Data mining', 'Biology', 'Genetics', 'Machine learning', 'Single-nucleotide polymorphism', 'Genotype', 'Missing data', 'Medicine', 'Gene', 'Environmental health']","plink, population genetics, probabilistic calls, phase information, multiallelic variants, plink, plink, plink, multiallelic variants, plink"
Paper_01390,The logic of practice,['Pierre Bourdieu'],1980,['The Journal of Philosophy'],Unknown,,246,31,9,10.2307/2015968,"Preface. Part I: Critique of Theoretical Reason. Foreword. 1. Objectifying Objectification. 2. The Imaginary Anthropology of Subjectivism. 3. Structures, Habitus, Practices. 4. Belief and the Body. 5. The Logic of Practice. 6. The Work of Time. 7. Symbolic Capital. 8. Modes of Domination. 9. The Objectivity of the Subjective. Part II: Practical Logics. 1. Land and Matrimonial Strategies. 2. The social uses of kinship. 3. Irresistible Analogy. Appendix. Bibliography. Index.","['Objectification', 'Objectivity (philosophy)', 'Analogy', 'Venn diagram', 'Habitus', 'Kinship', 'Epistemology', 'Sociology', 'Subjectivism', 'The Imaginary', 'Symbolic capital', 'Social science', 'Anthropology', 'Philosophy', 'Psychology', 'Cultural capital', 'Psychoanalysis', 'Mathematics education']","theoretical reason, objectifying objectification, imaginary anthropology, subjectivism, structures, habit, belief, logic, symbolic capital, modes, objectivity, practical logics, land, matrimonial strategies, social uses, kinship, irresistible analogy"
Paper_01391,Toward a New Conception of the Environment-Competitiveness Relationship,"['Michael E. Porter', 'Claas van der Linde']",1995,The Journal of Economic Perspectives,Journal,,97-118,9,4,10.1257/jep.9.4.97,"Accepting a fixed trade-off between environmental regulation and competitiveness unnecessarily raises costs and slows down environmental progress. Studies finding high environmental compliance costs have traditionally focused on static cost impacts, ignoring any offsetting productivity benefits from innovation. They typically overestimated compliance costs, neglected innovation offsets, and disregarded the affected industry's initial competitiveness. Rather than simply adding to cost, properly crafted environmental standards can trigger innovation offsets, allowing companies to improve their resource productivity. Shifting the debate from pollution control to pollution prevention was a step forward. It is now necessary to make the next step and focus on resource productivity.","['Productivity', 'Environmental regulation', 'Resource (disambiguation)', 'Porter hypothesis', 'Industrial organization', 'Control (management)', 'Economics', 'Environmental compliance', 'Business', 'Natural resource economics', 'Resource productivity', 'Environmental pollution', 'Environmental economics', 'Resource allocation', 'Environmental protection', 'Economic growth', 'Market economy', 'Environmental science', 'Computer network', 'Management', 'Computer science']","environmental regulation, competitiveness, environmental compliance costs, static cost impacts, productivity benefits, compliance costs, innovation offsets, environmental standards, innovation, resource productivity, pollution control, pollution prevention, resource productivity"
Paper_01393,Applied Longitudinal Data Analysis,"['J. David Singer', 'John B. Willett']",2003,Oxford University Press eBooks,Unknown,,,,,10.1093/acprof:oso/9780195152968.001.0001,"Abstract Change is constant in everyday life. Infants crawl and then walk, children learn to read and write, teenagers mature in myriad ways, and the elderly become frail and forgetful. Beyond these natural processes and events, external forces and interventions instigate and disrupt change: test scores may rise after a coaching course, drug abusers may remain abstinent after residential treatment. By charting changes over time and investigating whether and when events occur, researchers reveal the temporal rhythms of our lives. This book is concerned with behavioral, social, and biomedical sciences. It offers a presentation of two of today's most popular statistical methods: multilevel models for individual change and hazard/survival models for event occurrence (in both discrete- and continuous-time). Using data sets from published studies, the book takes you step by step through complete analyses, from simple exploratory displays that reveal underlying patterns through sophisticated specifications of complex statistical models.","['Coaching', 'Presentation (obstetrics)', 'Psychology', 'Hazard', 'Test (biology)', 'Psychological intervention', 'Longitudinal data', 'Event (particle physics)', 'Computer science', 'Data science', 'Cognitive psychology', 'Psychotherapist', 'Data mining', 'Medicine', 'Paleontology', 'Chemistry', 'Physics', 'Organic chemistry', 'Quantum mechanics', 'Biology', 'Radiology', 'Psychiatry']","test scores, coaching, drug abuse, temporal rhythms, biomedical, statistical, multilevel models, individual change, ##tory"
Paper_01394,The Occurrence of Sleep-Disordered Breathing among Middle-Aged Adults,"['Terry Young', 'Mari Palta', 'Jerome A. Dempsey', 'James B. Skatrud', 'Steven Weber', 'Safwan Badr']",1993,New England Journal of Medicine,Journal,,1230-1235,328,17,10.1056/nejm199304293281704,"Limited data have suggested that sleep-disordered breathing, a condition of repeated episodes of apnea and hypopnea during sleep, is prevalent among adults. Data from the Wisconsin Sleep Cohort Study, a longitudinal study of the natural history of cardiopulmonary disorders of sleep, were used to estimate the prevalence of undiagnosed sleep-disordered breathing among adults and address its importance to the public health.","['Medicine', 'Hypopnea', 'Polysomnography', 'Sleep apnea', 'Apnea', 'Apnea–hypopnea index', 'Breathing', 'Sleep disordered breathing', 'Central sleep apnea', 'Cohort', 'Obstructive sleep apnea', 'Physical therapy', 'Pediatrics', 'Internal medicine', 'Anesthesia']","apnea, hypop, adults, wisconsin sleep cohort study, cardiopulmonary disorders, [PAD], [PAD] [PAD] [PAD], [PAD] [PAD], [PAD], [PAD] [PAD] [PAD]"
Paper_01397,"Global analyses of sea surface temperature, sea ice, and night marine air temperature since the late nineteenth century","['Nick A Rayner', 'D. E. Parker', 'E. B. Horton', 'C. K. Folland', 'Lisa V. Alexander', 'David P. Rowell', 'Elizabeth C. Kent', 'Alexey Kaplan']",2003,Journal of Geophysical Research Atmospheres,Journal,,,108,D14,10.1029/2002jd002670,"We present the Met Office Hadley Centre's sea ice and sea surface temperature (SST) data set, HadISST1, and the nighttime marine air temperature (NMAT) data set, HadMAT1. HadISST1 replaces the global sea ice and sea surface temperature (GISST) data sets and is a unique combination of monthly globally complete fields of SST and sea ice concentration on a 1° latitude‐longitude grid from 1871. The companion HadMAT1 runs monthly from 1856 on a 5° latitude‐longitude grid and incorporates new corrections for the effect on NMAT of increasing deck (and hence measurement) heights. HadISST1 and HadMAT1 temperatures are reconstructed using a two‐stage reduced‐space optimal interpolation procedure, followed by superposition of quality‐improved gridded observations onto the reconstructions to restore local detail. The sea ice fields are made more homogeneous by compensating satellite microwave‐based sea ice concentrations for the impact of surface melt effects on retrievals in the Arctic and for algorithm deficiencies in the Antarctic and by making the historical in situ concentrations consistent with the satellite data. SSTs near sea ice are estimated using statistical relationships between SST and sea ice concentration. HadISST1 compares well with other published analyses, capturing trends in global, hemispheric, and regional SST well, containing SST fields with more uniform variance through time and better month‐to‐month persistence than those in GISST. HadMAT1 is more consistent with SST and with collocated land surface air temperatures than previous NMAT data sets.","['Sea ice', 'Sea surface temperature', 'Sea ice concentration', 'Climatology', 'Environmental science', 'Latitude', 'Satellite', 'Arctic ice pack', 'Geology', 'Longitude', 'Sea ice thickness', 'Atmospheric sciences', 'Geodesy', 'Aerospace engineering', 'Engineering']","met, sea, hadisst, nighttime marine air temperature, nmat, hadmat, hadisst, global, sea, hadmat, hadisst, hadmat, grid, sea ice, surface melt effects, arctic, antarctic, situ concentrations, statistical, sea, had, ##t, hadmat, collocated"
Paper_01398,"Cancer Statistics, 2008","['Ahmedin Jemal', 'Rebecca L. Siegel', 'Elizabeth Ward', 'Yongping Hao', 'Jiaquan Xu', 'Thomas S. Murray', 'M. J. Thun']",2008,CA A Cancer Journal for Clinicians,Journal,,71-96,58,2,10.3322/ca.2007.0010,"Each year, the American Cancer Society estimates the number of new cancer cases and deaths expected in the United States in the current year and compiles the most recent data on cancer incidence, mortality, and survival based on incidence data from the National Cancer Institute, Centers for Disease Control and Prevention, and the North American Association of Central Cancer Registries and mortality data from the National Center for Health Statistics. Incidence and death rates are age-standardized to the 2000 US standard million population. A total of 1,437,180 new cancer cases and 565,650 deaths from cancer are projected to occur in the United States in 2008. Notable trends in cancer incidence and mortality include stabilization of incidence rates for all cancer sites combined in men from 1995 through 2004 and in women from 1999 through 2004 and a continued decrease in the cancer death rate since 1990 in men and since 1991 in women. Overall cancer death rates in 2004 compared with 1990 in men and 1991 in women decreased by 18.4% and 10.5%, respectively, resulting in the avoidance of over a half million deaths from cancer during this time interval. This report also examines cancer incidence, mortality, and survival by site, sex, race/ethnicity, education, geographic area, and calendar year, as well as the proportionate contribution of selected sites to the overall trends. Although much progress has been made in reducing mortality rates, stabilizing incidence rates, and improving survival, cancer still accounts for more deaths than heart disease in persons under age 85 years. Further progress can be accelerated by supporting new discoveries and by applying existing cancer control knowledge across all segments of the population.","['Medicine', 'Cancer', 'Demography', 'Incidence (geometry)', 'Mortality rate', 'Population', 'Cancer registry', 'Disease', 'Gerontology', 'Environmental health', 'Surgery', 'Internal medicine', 'Physics', 'Sociology', 'Optics']","american cancer society, survival, central cancer registries, women, cancer death, women, cancer, women, cancer control"
Paper_01332,The Cambridge Structural Database: a quarter of a million crystal structures and rising,['Frank H. Allen'],2002,Acta Crystallographica Section B Structural Science,Journal,,380-388,58,3,10.1107/s0108768102003890,"The Cambridge Structural Database (CSD) now contains data for more than a quarter of a million small-molecule crystal structures. The information content of the CSD, together with methods for data acquisition, processing and validation, are summarized, with particular emphasis on the chemical information added by CSD editors. Nearly 80% of new structural data arrives electronically, mostly in CIF format, and the CCDC acts as the official crystal structure data depository for 51 major journals. The CCDC now maintains both a CIF archive (more than 73,000 CIFs dating from 1996), as well as the distributed binary CSD archive; the availability of data in both archives is discussed. A statistical survey of the CSD is also presented and projections concerning future accession rates indicate that the CSD will contain at least 500,000 crystal structures by the year 2010.","['Quarter (Canadian coin)', 'Database', 'Accession', 'Statistical survey', 'Computer science', 'Binary number', 'Library science', 'History', 'Archaeology', 'Arithmetic', 'Statistics', 'Mathematics', 'Business', 'European union', 'Economic policy']","cambridge structural database, data acquisition, csd, ci, crystal structure data, cif, distributed binary csd archive, statistical survey, [PAD]"
Paper_01333,Exact stochastic simulation of coupled chemical reactions,['Daniel T. Gillespie'],1977,The Journal of Physical Chemistry,Journal,,2340-2361,81,25,10.1021/j100540a008,"ADVERTISEMENT RETURN TO ISSUEPREVArticleNEXTExact stochastic simulation of coupled chemical reactionsDaniel T. GillespieCite this: J. Phys. Chem. 1977, 81, 25, 2340–2361Publication Date (Print):December 1, 1977Publication History Published online1 May 2002Published inissue 1 December 1977https://pubs.acs.org/doi/10.1021/j100540a008https://doi.org/10.1021/j100540a008research-articleACS PublicationsRequest reuse permissionsArticle Views28765Altmetric-Citations7236LEARN ABOUT THESE METRICSArticle Views are the COUNTER-compliant sum of full text article downloads since November 2008 (both PDF and HTML) across all institutions and individuals. These metrics are regularly updated to reflect usage leading up to the last few days.Citations are the number of other articles citing this article, calculated by Crossref and updated daily. Find more information about Crossref citation counts.The Altmetric Attention Score is a quantitative measure of the attention that a research article has received online. Clicking on the donut icon will load a page at altmetric.com with additional details about the score and the social media presence for the given article. Find more information on the Altmetric Attention Score and how the score is calculated. Share Add toView InAdd Full Text with ReferenceAdd Description ExportRISCitationCitation and abstractCitation and referencesMore Options Share onFacebookTwitterWechatLinked InRedditEmail Other access options Get e-Alerts","['Citation', 'Computer science', 'Icon', 'Social media', 'Altmetrics', 'Information retrieval', 'Data science', 'Library science', 'World Wide Web', 'Programming language']","stochastic simulation, coupled chemical reactions, permissionsarticle views, ##le, cross, ##f, ##f, altmetric attention score, social media presence, altmetric attention score, reference, exportriscitation, abstract, references"
Paper_01334,An inventory for measuring clinical anxiety: Psychometric properties.,"['Aaron T. Beck', 'Norman B. Epstein', 'Gary Brown', 'Robert A. Steer']",1988,Journal of Consulting and Clinical Psychology,Journal,,893-897,56,6,10.1037//0022-006x.56.6.893,"Un nouvel inventaire auto-administre destine a mesurer l'anxiete pathologique, le «Beck Anxiety Cheklist» (BAI) est decrit, evalue et compare au «Hamilton Anxiety Rating Scale» (test avec lequel des correlations moderees sont trouvees)","['Psychology', 'Anxiety', 'Rating scale', 'Beck Anxiety Inventory', 'Psychometrics', 'Clinical psychology', 'Test validity', 'Validation test', 'Developmental psychology', 'Psychiatry', 'Beck Depression Inventory']","beck anxiety che, hamilton anxiety rating scale"
Paper_01336,Conditional Heteroskedasticity in Asset Returns: A New Approach,['Daniel B. Nelson'],1991,Econometrica,Journal,,347-347,59,2,10.2307/2938260,"This paper introduces an ARCH model (exponential ARCH) that (1) allows correlation between returns and volatility innovations (an important feature of stock market volatility changes), (2) eliminates the need for inequality constraints on parameters, and (3) allows for a straightforward interpretation of the persistence of shocks to volatility. In the above respects, it is an improvement over the widely-used GARCH model. The model is applied to study volatility changes and the risk premium on the CRSP Value-Weighted Market Index from 1962 to 1987. Copyright 1991 by The Econometric Society.","['Heteroscedasticity', 'Economics', 'Econometrics', 'Financial economics', 'Asset (computer security)', 'Computer science', 'Computer security']","arch model, exponential arch, volatility innovations, stock market volatility changes, inequality constraints, volati, garch model, volatility changes, risk premium, econometric society"
Paper_01337,<tt>emcee</tt>: The MCMC Hammer,"['Daniel Foreman-Mackey', 'David W. Hogg', 'Dustin Lang', 'Jonathan Goodman']",2013,Publications of the Astronomical Society of the Pacific,Journal,,306-312,125,925,10.1086/670067,"We introduce a stable, well tested Python implementation of the affine-invariant ensemble sampler for Markov chain Monte Carlo (MCMC) proposed by Goodman & Weare (2010). The code is open source and has already been used in several published projects in the astrophysics literature. The algorithm behind emcee has several advantages over traditional MCMC sampling methods and it has excellent performance as measured by the autocorrelation time (or function calls per independent sample). One major advantage of the algorithm is that it requires hand-tuning of only 1 or 2 parameters compared to ∼N2 for a traditional algorithm in an N-dimensional parameter space. In this document, we describe the algorithm and the details of our implementation. Exploiting the parallelism of the ensemble method, emcee permits any user to take advantage of multiple CPU cores without extra effort. The code is available online at http://dan.iel.fm/emcee under the GNU General Public License v2.","['Markov chain Monte Carlo', 'Python (programming language)', 'Computer science', 'Algorithm', 'Autocorrelation', 'Source code', 'Scripting language', 'Bayesian probability', 'Statistics', 'Mathematics', 'Programming language', 'Artificial intelligence']","python, markov chain monte carlo, astrophysics, em, ##mc, autocorrelation time, function calls, emcee, cpu cores"
Paper_01338,Robust Locally Weighted Regression and Smoothing Scatterplots,['William S. Cleveland'],1979,Journal of the American Statistical Association,Journal,,829-836,74,368,10.1080/01621459.1979.10481038,"Abstract The visual information on a scatterplot can be greatly enhanced, with little additional cost, by computing and plotting smoothed points. Robust locally weighted regression is a method for smoothing a scatterplot, (x i , y i ), i = 1, …, n, in which the fitted value at z k is the value of a polynomial fit to the data using weighted least squares, where the weight for (x i , y i ) is large if x i is close to x k and small if it is not. A robust fitting procedure is used that guards against deviant points distorting the smoothed points. Visual, computational, and statistical issues of robust locally weighted regression are discussed. Several examples, including data on lead intoxication, are used to illustrate the methodology.","['Smoothing', 'Robust regression', 'Mathematics', 'Polynomial regression', 'Regression', 'Regression analysis', 'Polynomial', 'Statistics', 'Value (mathematics)', 'Least-squares function approximation', 'Linear regression', 'Computer science', 'Algorithm', 'Applied mathematics', 'Mathematical analysis', 'Estimator']","scatter, ##ot, smoothed points, robust locally weighted regression, scatter, polynomial fit, weighted least squares, robust fitting procedure, devi, robust locally weighted regression, lead intoxication, [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD], [PAD]"
Paper_01339,Basics of qualitative research,['Anselm L. Strauss'],1990,['Journal of Marketing Research'],Unknown,,382,29,3,10.2307/3172751,"Basics of qualitative research , Basics of qualitative research , کتابخانه دیجیتال جندی شاپور اهواز","['Qualitative research', 'Sociology', 'Social science']","qualitative research, qualitative research, [PAD] [PAD]"
Paper_01340,Amyloid Oligomers Exacerbate Tau Pathology in a Mouse Model of Tauopathy,"['Maj-Linda B. Selenica', 'Milene L. Brownlow', 'Jeffy P. Jimenez', 'Daniel C. Lee', 'Gabriela Peña', 'Chad A. Dickey', 'Marcia N. Gordon', 'Dave Morgan']",2012,Neurodegenerative Diseases,Journal,,165-181,11,4,10.1159/000337230,"We have extensively analyzed the biochemical and histochemical profiles of the tau protein from the rTg4510 transgenic mouse model in which the animals uniquely develop forebrain tau pathologies similar to those found in human tauopathies. Levels of several soluble phosphorylated tau species were highest at 1 month relative to later time points, suggesting that certain tau hyperphosphorylation events were insufficient to drive tangle formation in young mice. Despite a robust, pre-tangle-like accumulation of phospho-tau in 1-month-old mice, this material was cleared by 3 months, indicating that the young mouse brain either fails to facilitate tau insolubility or possesses an enhanced ability to clear tau relative to the adult. We also found that while heat shock protein expression increased with normal aging, this process was accelerated in rTg4510 mice. Moreover, by exploiting an exon 10 (-) specific antibody, we demonstrated that endogenous mouse tau turnover was slowed in response to human tau over-expression, and that this endogenous tau adopted disease-related properties. These data suggest that a younger brain fails to develop lasting tau pathology despite elevated levels of phosphorylated tau, perhaps because of reduced expression of stress-related proteins. Moreover, we show that the active production of small amounts of abnormal tau protein facilitates dysfunction and accumulation of otherwise normal tau, a significant implication for the pathogenesis of patients with Alzheimer's disease.","['Tauopathy', 'Genetically modified mouse', 'Tangle', 'Tau protein', 'Endogeny', 'Hyperphosphorylation', 'Neurodegeneration', 'Neuroscience', 'Transgene', 'Tau pathology', ""Alzheimer's disease"", 'Pathogenesis', 'Cell biology', 'Phosphorylation', 'Biology', 'Chemistry', 'Pathology', 'Endocrinology', 'Disease', 'Medicine', 'Biochemistry', 'Gene', 'Mathematics', 'Pure mathematics']","tau, forebrain tau, human tau, tangle formation, heat shock"
Paper_01342,Multimodel Inference,"['Kenneth P. Burnham', 'David R. Anderson']",2004,Sociological Methods & Research,Journal,,261-304,33,2,10.1177/0049124104268644,"The model selection literature has been generally poor at reflecting the deep foundations of the Akaike information criterion (AIC) and at making appropriate comparisons to the Bayesian information criterion (BIC). There is a clear philosophy, a sound criterion based in information theory, and a rigorous statistical foundation for AIC. AIC can be justified as Bayesian using a “savvy” prior on models that is a function of sample size and the number of model parameters. Furthermore, BIC can be derived as a non-Bayesian result. Therefore, arguments about using AIC versus BIC for model selection cannot be from a Bayes versus frequentist perspective. The philosophical context of what is assumed about reality, approximating models, and the intent of model-based inference should determine whether AIC or BIC is used. Various facets of such multimodel inference are presented here, particularly methods of model averaging.","['Akaike information criterion', 'Frequentist inference', 'Bayesian information criterion', 'Model selection', 'Deviance information criterion', 'Bayes factor', 'Bayesian inference', 'Information Criteria', 'Inference', 'Bayesian probability', 'Context (archaeology)', 'Mathematics', 'Econometrics', 'Computer science', 'Statistics', 'Artificial intelligence', 'Paleontology', 'Biology']","model selection, akaike information criterion, aic, bayesian information criterion, bic, information theory, statistical, aic, aic, sample size, bic, bic, model selection, aic, bic, multimodel inference, model averaging"
Paper_01344,Mediation in experimental and nonexperimental studies: New procedures and recommendations.,"['Patrick E. Shrout', 'Niall Bolger']",2002,Psychological Methods,Journal,,422-445,7,4,10.1037/1082-989x.7.4.422,"Mediation is said to occur when a causal effect of some variable X on an outcome Y is explained by some intervening variable M. The authors recommend that with small to moderate samples, bootstrap methods (B. Efron & R. Tibshirani, 1993) be used to assess mediation. Bootstrap tests are powerful because they detect that the sampling distribution of the mediated effect is skewed away from 0. They argue that R. M. Baron and D. A. Kenny's (1986) recommendation of first testing the X --> Y association for statistical significance should not be a requirement when there is a priori belief that the effect size is small or suppression is a possibility. Empirical examples and computer setups for bootstrap analyses are provided.","['Mediation', 'Statistics', 'Econometrics', 'Statistical hypothesis testing', 'Psychology', 'A priori and a posteriori', 'Outcome (game theory)', 'Variable (mathematics)', 'Type I and type II errors', 'Statistical significance', 'Mathematics', 'Epistemology', 'Sociology', 'Philosophy', 'Mathematical analysis', 'Social science', 'Mathematical economics']","mediation, causal effect, bootstrap methods, bootstrap tests, sampling distribution, mediated effect, statistical significance, computer setups, bootstrap analyses"
Paper_01345,The Mathematical Theory of Communication,['Claude E. Shannon'],1948,['Encyclopedia of Communication Theory'],Unknown,,,,,10.4135/9781412959384.n229,"Scientific knowledge grows at a phenomenal pace--but few books have had as lasting an impact or played as important a role in our modern world as The Mathematical Theory of Communication, published originally as a paper on communication theory more than fifty years ago. Republished in book form shortly thereafter, it has since gone through four hardcover and sixteen paperback printings. It is a revolutionary work, astounding in its foresight and contemporaneity. The University of Illinois Press is pleased and honored to issue this commemorative reprinting of a classic.","['Futures studies', 'Pace', 'History', 'Media studies', 'Classics', 'Sociology', 'Computer science', 'Geography', 'Artificial intelligence', 'Geodesy']","scientific knowledge, mathematical theory of communication, communication theory"
Paper_01348,Active contours without edges,"['Tony F. Chan', 'Luminita A. Vese']",2001,IEEE Transactions on Image Processing,Journal,,266-277,10,2,10.1109/83.902291,"We propose a new model for active contours to detect objects in a given image, based on techniques of curve evolution, Mumford-Shah (1989) functional for segmentation and level sets. Our model can detect objects whose boundaries are not necessarily defined by the gradient. We minimize an energy which can be seen as a particular case of the minimal partition problem. In the level set formulation, the problem becomes a ""mean-curvature flow""-like evolving the active contour, which will stop on the desired boundary. However, the stopping term does not depend on the gradient of the image, as in the classical active contour models, but is instead related to a particular segmentation of the image. We give a numerical algorithm using finite differences. Finally, we present various experimental results and in particular some examples for which the classical snakes methods based on the gradient are not applicable. Also, the initial curve can be anywhere in the image, and interior contours are automatically detected.","['Active contour model', 'Image segmentation', 'Level set (data structures)', 'Curvature', 'Boundary (topology)', 'Artificial intelligence', 'Image (mathematics)', 'Mathematics', 'Energy functional', 'Partition (number theory)', 'Computer vision', 'Segmentation', 'Balanced flow', 'Level set method', 'Computer science', 'Algorithm', 'Geometry', 'Mathematical analysis', 'Combinatorics']","active contours, curve evolution, segmentation, level sets, minimal partition problem, level set, active contour, numerical algorithm, finite differences, interior contours"
Paper_01350,"The relationship between infrared, optical, and ultraviolet extinction","['Jason A. Cardelli', 'Geoffrey C. Clayton', 'John S. Mathis']",1989,The Astrophysical Journal,Journal,,245-245,345,,10.1086/167900,"view Abstract Citations (9701) References (43) Co-Reads Similar Papers Volume Content Graphics Metrics Export Citation NASA/ADS The Relationship between Infrared, Optical, and Ultraviolet Extinction Cardelli, Jason A. ; Clayton, Geoffrey C. ; Mathis, John S. Abstract The parameterized extinction data of Fitzpatrick and Massa (1986, 1988) for the ultraviolet and various sources for the optical and near-infrared are used to derive a meaningful average extinction law over the 3.5 micron to 0.125 wavelength range which is applicable to both diffuse and dense regions of the interstellar medium. The law depends on only one parameter R(V) = A(V)/E(B-V). An analytic formula is given for the mean extinction law which can be used to calculate color excesses or to deredden observations. The validity of the law over a large wavelength interval suggests that the processes which modify the sizes and compositions of grains are stochastic in nature and very efficient. Publication: The Astrophysical Journal Pub Date: October 1989 DOI: 10.1086/167900 Bibcode: 1989ApJ...345..245C Keywords: Infrared Spectra; Interstellar Extinction; Ultraviolet Spectra; Visible Spectrum; Computational Astrophysics; Interstellar Matter; Iue; Astrophysics; INTERSTELLAR: MATTER; ULTRAVIOLET: SPECTRA full text sources ADS | data products SIMBAD (38) MAST (2)","['Physics', 'Extinction (optical mineralogy)', 'Ultraviolet', 'Astrophysics', 'Interstellar medium', 'Infrared', 'Cosmic dust', 'Astronomy', 'Spectral line', 'Optics', 'Galaxy']","volume content graphics metrics, parameterized extinction data, average extinction law, ##stellar medium, mean extinction law, color excesses, infrared spectra, interstellar extinction, ultraviolet spectra, visible spectrum, computational astrophysics, interstellar matter"
Paper_01351,<scp>micro</scp>‐<scp>checker</scp>: software for identifying and correcting genotyping errors in microsatellite data,"['Cock van Oosterhout', 'William F. Hutchinson', 'D. P. M. Wills', 'Peter Shipley']",2004,Molecular Ecology Notes,Journal,,535-538,4,3,10.1111/j.1471-8286.2004.00684.x,"Abstract DNA degradation, low DNA concentrations and primer‐site mutations may result in the incorrect assignment of microsatellite genotypes, potentially biasing population genetic analyses. micro ‐ checker is windows ®‐based software that tests the genotyping of microsatellites from diploid populations. The program aids identification of genotyping errors due to nonamplified alleles (null alleles), short allele dominance (large allele dropout) and the scoring of stutter peaks, and also detects typographic errors. micro ‐ checker estimates the frequency of null alleles and, importantly, can adjust the allele and genotype frequencies of the amplified alleles, permitting their use in further population genetic analysis. micro ‐ checker can be freely downloaded from http://www.microchecker.hull.ac.uk/ .","['Microsatellite', 'Genotyping', 'Null allele', 'Allele', 'Biology', 'Genotype', 'Genetics', 'Population', 'Gene', 'Demography', 'Sociology']","abstract dna degradation, primer, microsatellite, population genetic analyses, micro ‐ checker, ##otyp, microsatellites, diploid populations, genotyping, nonamplified alleles, null alleles, short allele dominance, large allele dropout, stutter peaks, typographic errors, micro ‐ checker, null all, gen, population genetic analysis, micro ‐ checker, microchecker, [PAD] [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD], [PAD] [PAD] [PAD], [PAD], [PAD], [PAD], [PAD] [PAD] [PAD], [PAD] [PAD] [PAD], [PAD], [PAD], [PAD] [PAD]"
Paper_01352,Use of Ranks in One-Criterion Variance Analysis,"['William Kruskal', 'W. Allen Wallis']",1952,Journal of the American Statistical Association,Journal,,583-621,47,260,10.1080/01621459.1952.10483441,"Abstract Given C samples, with n i observations in the ith sample, a test of the hypothesis that the samples are from the same population may be made by ranking the observations from from 1 to Σn i (giving each observation in a group of ties the mean of the ranks tied for), finding the C sums of ranks, and computing a statistic H. Under the stated hypothesis, H is distributed approximately as χ2(C – 1), unless the samples are too small, in which case special approximations or exact tables are provided. One of the most important applications of the test is in detecting differences among the population means.Footnote* * Based in part on research supported by the Office of Naval Research at the Statistical Research Center, University of Chicago. Notes * Based in part on research supported by the Office of Naval Research at the Statistical Research Center, University of Chicago.","['Haskell', 'Library science', 'Ranking (information retrieval)', 'Population', 'Test (biology)', 'Mathematics', 'Statistics', 'Demography', 'Sociology', 'Computer science', 'Artificial intelligence', 'Geology', 'Functional programming', 'Paleontology', 'Theoretical computer science']","ith, stat, exact tables, statistical, statistical"
Paper_01354,"Individual differences in two emotion regulation processes: Implications for affect, relationships, and well-being.","['James J. Gross', 'Oliver P. John']",2003,Journal of Personality and Social Psychology,Journal,,348-362,85,2,10.1037/0022-3514.85.2.348,"Five studies tested two general hypotheses: Individuals differ in their use of emotion regulation strategies such as reappraisal and suppression, and these individual differences have implications for affect, well-being, and social relationships. Study 1 presents new measures of the habitual use of reappraisal and suppression. Study 2 examines convergent and discriminant validity. Study 3 shows that reappraisers experience and express greater positive emotion and lesser negative emotion, whereas suppressors experience and express lesser positive emotion, yet experience greater negative emotion. Study 4 indicates that using reappraisal is associated with better interpersonal functioning, whereas using suppression is associated with worse interpersonal functioning. Study 5 shows that using reappraisal is related positively to well-being, whereas using suppression is related negatively.","['Psychology', 'Expressive Suppression', 'Interpersonal communication', 'Cognitive reappraisal', 'Affect (linguistics)', 'Interpersonal relationship', 'Developmental psychology', 'Social psychology', 'Cognition', 'Communication', 'Neuroscience']","emotion regulation strategies, reappraisal, suppression, affect, social relationships, habitual use, reappraisal, suppression, reappraiser, reappraisal, interpersonal functioning, suppression, interpersonal functioning, reappraisal, suppression, [PAD]"
Paper_01356,The Economics of Climate Change: The Stern Review,['Nicholas Stern'],2007,['South African Journal of Economics'],Unknown,,369-372,75,2,10.1111/j.1813-6982.2007.00119.x,"There is now clear scientific evidence that emissions from economic activity, particularly the burning of fossil fuels for energy, are causing changes to the Earth´s climate. A sound understanding of the economics of climate change is needed in order to underpin an effective global response to this challenge. The Stern Review is an independent, rigourous and comprehensive analysis of the economic aspects of this crucial issue. It has been conducted by Sir Nicholas Stern, Head of the UK Government Economic Service, and a former Chief Economist of the World Bank. The Economics of Climate Change will be invaluable for all students of the economics and policy implications of climate change, and economists, scientists and policy makers involved in all aspects of climate change.","['Stern', 'Climate change', 'Order (exchange)', 'Economics', 'Government (linguistics)', 'Natural resource economics', 'Political science', 'Engineering', 'Ecology', 'Finance', 'Linguistics', 'Philosophy', 'Marine engineering', 'Biology']","economic activity, climate change, global, uk, climate change, climate"
Paper_01358,High-Resolution Global Maps of 21st-Century Forest Cover Change,"['Matthew C. Hansen', 'Peter Potapov', 'Rebecca Moore', 'M. Hancher', 'Svetlana Turubanova', 'Alexandra Tyukavina', 'David Thau', 'Stephen V. Stehman', 'S. J. Goetz', 'Thomas R. Loveland', 'Anil Kommareddy', 'A. Egorov', 'Louise Chini', 'C. O. Justice', 'J. R. Townshend']",2013,Science,Journal,,850-853,342,6160,10.1126/science.1244693,"Quantification of global forest change has been lacking despite the recognized importance of forest ecosystem services. In this study, Earth observation satellite data were used to map global forest loss (2.3 million square kilometers) and gain (0.8 million square kilometers) from 2000 to 2012 at a spatial resolution of 30 meters. The tropics were the only climate domain to exhibit a trend, with forest loss increasing by 2101 square kilometers per year. Brazil's well-documented reduction in deforestation was offset by increasing forest loss in Indonesia, Malaysia, Paraguay, Bolivia, Zambia, Angola, and elsewhere. Intensive forestry practiced within subtropical forests resulted in the highest rates of forest change globally. Boreal forest loss due largely to fire and forestry was second to that in the tropics in absolute and proportional terms. These results depict a globally consistent and locally relevant record of forest change.","['Deforestation (computer science)', 'Forest cover', 'Tropics', 'Geography', 'Climate change', 'Subtropics', 'Taiga', 'Physical geography', 'Agroforestry', 'Ecosystem services', 'Forest ecology', 'Forestry', 'Environmental science', 'Ecosystem', 'Ecology', 'Geology', 'Oceanography', 'Biology', 'Computer science', 'Programming language']","global forest change, forest ecosystem services, earth observation satellite data, global forest loss, ##ics, paraguay, bolivia, intensive forestry, subtropical forests, boreal forest loss, ##opics"
Paper_01359,VI. The phenomena of rupture and flow in solids,['Alan Arnold Griffith'],1921,Philosophical Transactions of the Royal Society of London Series A Containing Papers of a Mathematical or Physical Character,Journal,,163-198,221,582-593,10.1098/rsta.1921.0006,"In the course of an investigation of the effect of surface scratches on the mechanical strength of solids, some general conclusions were reached which appear to have a direct bearing on the problem of rupture, from an engineering standpoint, and also on the larger question of the nature of intermolecular cohesion. The original object of the work, which was carried out at the Royal Aircraft Estab­lishment, was the discovery of the effect of surface treatment—such as, for instance, filing, grinding or polishing—on the strength of metallic machine parts subjected to alternating or repeated loads. In the case of steel, and some other metals in common use, the results of fatigue tests indicated that the range of alternating stress which could be permanently sustained by the material was smaller than the range within which it was sensibly elastic, after being subjected to a great number of reversals. Hence it was inferred that the safe range of loading of a part, having a scratched or grooved surface of a given type, should be capable of estimation with the help of one of the two hypotheses of rupture commonly used for solids which are elastic to fracture. According to these hypotheses rupture may be expected if (a) the maximum tensile stress, ( b ) the maximum extension, exceeds a certain critical value. Moreover, as the behaviour of the materials under consideration, within the safe range of alternating stress, shows very little departure from Hooke’s law, it was thought that the necessary stress and strain calculations could be performed by means of the mathematical theory of elasticity.","['Cohesion (chemistry)', 'Polishing', 'Grinding', 'Ultimate tensile strength', 'Materials science', 'Plasticity', 'Stress (linguistics)', 'Flow stress', 'Range (aeronautics)', 'Fracture (geology)', 'Mechanics', 'Forensic engineering', 'Composite material', 'Strain rate', 'Physics', 'Engineering', 'Linguistics', 'Philosophy', 'Quantum mechanics']","surface scratches, mechanical strength, solids, rupture, intermolecular cohesion, surface treatment, polishing, metallic machine parts, fatigue tests, alternating stress, maximum tensile stress, alternating, mathematical, elasticity"
Paper_01360,Prospective identification of tumorigenic breast cancer cells,"['Muhammad Al‐Hajj', 'Max S. Wicha', 'Adalberto Benito‐Hernández', 'Sean J. Morrison', 'Michael F. Clarke']",2003,Proceedings of the National Academy of Sciences,Journal,,3983-3988,100,7,10.1073/pnas.0530291100,"Breast cancer is the most common malignancy in United States women, accounting for &gt;40,000 deaths each year. These breast tumors are comprised of phenotypically diverse populations of breast cancer cells. Using a model in which human breast cancer cells were grown in immunocompromised mice, we found that only a minority of breast cancer cells had the ability to form new tumors. We were able to distinguish the tumorigenic (tumor initiating) from the nontumorigenic cancer cells based on cell surface marker expression. We prospectively identified and isolated the tumorigenic cells as CD44 + CD24 −/low Lineage − in eight of nine patients. As few as 100 cells with this phenotype were able to form tumors in mice, whereas tens of thousands of cells with alternate phenotypes failed to form tumors. The tumorigenic subpopulation could be serially passaged: each time cells within this population generated new tumors containing additional CD44 + CD24 −/low Lineage − tumorigenic cells as well as the phenotypically diverse mixed populations of nontumorigenic cells present in the initial tumor. The ability to prospectively identify tumorigenic cancer cells will facilitate the elucidation of pathways that regulate their growth and survival. Furthermore, because these cells drive tumor development, strategies designed to target this population may lead to more effective therapies.","['CD44', 'CD24', 'Breast cancer', 'Cancer research', 'Cancer', 'Cancer stem cell', 'Biology', 'Malignancy', 'Population', 'Cancer cell', 'Carcinogenesis', 'Phenotype', 'Immunology', 'Pathology', 'Cell', 'Medicine', 'Genetics', 'Gene', 'Environmental health']","breast cancer, united, breast tumors, breast cancer, human breast cancer, breast, cell surface marker, nontumorigenic"
Paper_01361,Phenomenology of Perception,['Maurice Merleau-Ponty'],1982,Routledge eBooks,Unknown,,,,,10.4324/9780203981139,"Foreword, Taylor Carman Introduction, Claude Lefort Preface Introduction: Classical Prejudices and the Return to Phenomena I. Sensation II. Association and the Projection of Memories III. Attention and Judgment IV. The Phenomenal Field Part 1: The Body 1. The Body as an Object and Mechanistic Physiology 2. The Experience of the Body and Classical Psychology 3. The Spatiality of the One's Own Body and Motility 4. The Synthesis of One's Own Body 5. The Body as a Sexed Being 6. Speech and the Body as Expression Part 2: The Perceived World 7. Sensing 8. Space 9. The Thing and the Natural World 10. Others and the Human World Part 3: Being-For-Itself and Being-In-The-World 11. The Cogito 12. Temporality 13. Freedom Original Bibliography Bibliography of English Translations cited Additional Work Cited Index","['Phenomenology (philosophy)', 'Perception', 'Psychology', 'Epistemology', 'Philosophy', 'Psychoanalysis', 'Cognitive psychology', 'Cognitive science']","classical prejudices, sensation, association, memories, attention, judgment, phenomenal field, body, mechanistic physiology, classical psychology, spatiality, motility, sexed, speech, perceived world, sensing, space, thing, natural world, others, human world, cogito, temporality, freedom"
Paper_01363,Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling,"['Jun‐Young Chung', 'Çağlar Gülçehre', 'Kyunghyun Cho', 'Yoshua Bengio']",2014,arXiv (Cornell University),Unknown,,,,,10.48550/arxiv.1412.3555,"In this paper we compare different types of recurrent units in recurrent neural networks (RNNs). Especially, we focus on more sophisticated units that implement a gating mechanism, such as a long short-term memory (LSTM) unit and a recently proposed gated recurrent unit (GRU). We evaluate these recurrent units on the tasks of polyphonic music modeling and speech signal modeling. Our experiments revealed that these advanced recurrent units are indeed better than more traditional recurrent units such as tanh units. Also, we found GRU to be comparable to LSTM.","['Recurrent neural network', 'Computer science', 'Focus (optics)', 'Speech recognition', 'Long short term memory', 'Sequence (biology)', 'Artificial intelligence', 'Polyphony', 'Artificial neural network', 'Psychology', 'Pedagogy', 'Physics', 'Biology', 'Optics', 'Genetics']","recurrent units, recurrent neural networks, rnns, gating mechanism, gated recurrent unit, gr, polyphonic music modeling, speech signal modeling, tanh units, ##u, [PAD], [PAD] [PAD] [PAD], [PAD]"
Paper_01366,Fit indices in covariance structure modeling: Sensitivity to underparameterized model misspecification.,"['Li‐tze Hu', 'Peter M. Bentler']",1998,Psychological Methods,Journal,,424-453,3,4,10.1037/1082-989x.3.4.424,"This study evaluated the sensitivity of maximum likelihood (ML)-, generalized least squares (GLS)-, and asymptotic distribution-free (ADF)-based fit indices to model misspecification, under conditions that varied sample size and distribution. The effect of violating assumptions of asymptotic robustness theory also was examined. Standardized root-mean-square residual (SRMR) was the most sensitive index to models with misspecified factor covariance(s), and Tucker-Lewis Index (1973; TLI), Bollen's fit index (1989; BL89), relative noncentrality index (RNI), comparative fit index (CFI), and the MLand GLS-based gamma hat, McDonald's centrality index (1989; Me), and root-mean-square error of approximation (RMSEA) were the most sensitive indices to models with misspecified factor loadings. With ML and GLS methods, we recommend the use of SRMR, supplemented by TLI, BL89, RNI, CFI, gamma hat, Me, or RMSEA (TLI, Me, and RMSEA are less preferable at small sample sizes). With the ADF method, we recommend the use of SRMR, supplemented by TLI, BL89, RNI, or CFI. Finally, most of the ML-based fit indices outperformed those obtained from GLS and ADF and are preferable for evaluating model fit.","['Covariance', 'Sensitivity (control systems)', 'Econometrics', 'Statistics', 'Structural equation modeling', 'Mathematics', 'Engineering', 'Electronic engineering']","maximum likelihood, generalized least squares, asymptotic robustness theory, misspecified factor covariance, relative noncentrality index, comparative fit index, misspecified factor loadings, srmr, adf, srmr, ##f"
Paper_01367,tRNAscan-SE: A Program for Improved Detection of Transfer RNA Genes in Genomic Sequence,"['Todd M. Lowe', 'Sean R. Eddy']",1997,Nucleic Acids Research,Journal,,955-964,25,5,10.1093/nar/25.5.955,"We describe a program, tRNAscan-SE, which identifies 99–100% of transfer RNA genes in DNA sequence while giving less than one false positive per 15 gigabases. Two previously described tRNA detection programs are used as fast, first-pass prefilters to identify candidate tRNAs, which are then analyzed by a highly selective tRNA covariance model. This work represents a practical application of RNA covariance models, which are general, probabilistic secondary structure profiles based on stochastic context-free grammars. tRNAscan-SE searches at ∼30 000 bp/s. Additional extensions to tRNAscan-SE detect unusual tRNA homologues such as selenocysteine tRNAs, tRNA-derived repetitive elements and tRNA pseudo-genes.","['Transfer RNA', 'Biology', 'Genetics', 'Gene', 'RNA', 'Computational biology', 'Sequence (biology)', 'Context (archaeology)', 'Selenocysteine', 'Covariance', 'Biochemistry', 'Mathematics', 'Paleontology', 'Statistics', 'Cysteine', 'Enzyme']","##nas, transfer rna genes, trna detection, highly, rna covariance models, ##bilistic secondary structure profiles, ##na, selenocysteine trnas, [PAD], [PAD], [PAD], [PAD] [PAD]"
Paper_01369,Qualitative research: Methods in the social sciences,['Bruce L. Berg'],2006,PsycEXTRA Dataset,Unknown,,,,,10.1037/e668352010-001,"IN THIS SECTION: 1.) BRIEF 2.) COMPREHENSIVE BRIEF TABLE OF CONTENTS: Chapter 1: Introduction Chapter 2: Designing Qualitative Research Chapter 3: Ethical Issues Chapter 4: A Dramaturgical Look at Interviewing Chapter 5: Focus Group Interviewing Chapter 6: Ethnographic Field Strategies Chapter 7: Action Research Chapter 8: Unobtrusive Measures in Research Chapter 9: Social Historical Research and Oral Traditions Chapter 10: Case Studies Chapter 11: An Introduction to Content Analysis Chapter 12: Writing Research Papers: Sorting the Noodles from the Soup COMPREHENSIVE TABLE OF CONTENTS: Chapter 1: Introduction Quantitative Versus Qualitative Schools of Thought Use of Triangulation in Research Methodology Qualitative Strategies: Defining an Orientation From a Symbolic Interactionist Perspective Why Use Qualitative Methods? A Plan of Presentation Chapter 2: Designing Qualitative Research Theory and Concepts Ideas and Theory Reviewing the Literature Evaluating Web Sites Content versus Use Theory, Reality, and the Social World Framing Research Problems Operationalization and Conceptualization Designing Projects Data Collection and Organization Data Storage, Retrieval, and Analysis Dissemination Trying It Out Chapter 3: Ethical Issues Research Ethics in Historical Perspective From Guidelines to Law: Regulations on the Research Process Institutional Review Boards (IRBs) Ethical Codes Some Common Ethical Concerns in Behavioral Research New Areas for Ethical Concern: Cyberspace Informed Consent and Implied Consent Confidentiality and Anonymity Securing the Data Objectivity and Careful Research Design Trying It Out Chapter 4: A Dramaturgical Look at Interviewing Dramaturgy and Interviewing Types of Interviews The Data Collection Instrument Guideline Development Communicating Effectively A Few Common Problems in Question Formulation Pretesting the Schedule Long Versus Short Interviews Telephone Interviews Computer Assisted Interviewing Conducting an Interview: A Natural or an Unnatural Communication? The Dramaturgical Interview The Interviewer's Repertoire Know Your Audience Analyzing Data Obtained from the Dramaturgical Interview Trying It Out Chapter 5: Focus Group Interviewing What are Focus Groups? Working With a Group The Evolution of Focus Group Interviews Facilitating Focus Group Dynamics: How Focus Groups Work The Moderator's Guide Basic Ingredients in Focus Groups Analyzing Focus Group Data Confidentiality and Focus Group Interviews Recent Trends in Focus Groups: Online Focus Groups Trying It Out Chapter 6: Ethnographic Field Strategies Accessing a Field Setting: Getting In Reflectivity and Ethnography Critical Ethnography Becoming Invisible Other Dangers During Ethnographic Research Watching, Listening, and Learning How to Learn: What to Watch and Listen For Computers and Ethnography OnLine Ethnography Analyzing Ethnographic Data Other Analysis Strategies: Typologies, Sociograms, and Metaphors Disengaging: Getting Out Trying It Out Chapter 7: Action Research The Basics of Action Research Identifying the Research Question(s) Gathering the Information to Answer the Question(s) Analyzing and Interpreting the Information Sharing the Results with the Participants When to Use and When Not to Use Action Research The Action Researcher's Role Types of Action Research Photovoice and Action Research Action Research: A Reiteration Trying It Out Chapter 8: Unobtrusive Measures in Research Archival Strategies Physical Erosion and accretion: Human Traces as Data Sources Trying It Out Chapter 9: Social Historical Research and Oral Traditions What Is Historical Research? Life Histories and Social History What Are the Sources of Data for Historical Researchers? Doing Historiography: Tracing Written History as Data What Are Oral Histories? Trying It Out Chapter 10: Case Studies The Nature of Case Studies Theory and Case Studies The Individual Case Study Intrinsic, Instrumental, and Collective Case Studies Case Study Design Types Designing Case Studies The Scientific Benefit of Case Studies Case Studies of Organizations Case Studies of Communities Trying It Out Chapter 11: An Introduction to Content Analysis What is Content Analysis? Analysis of Qualitative Data Content Analysis as a Technique Content Analysis: Quantitative or Qualitative? Communication Components What to Count: Levels and Units of Analysis Category Development: Building Grounded Theory Discourse Analysis and Content Analysis Open Coding Coding Frames Stages in the Content Analysis Process Strengths and Weaknesses of the Content Analysis Process Computers and Qualitative Analysis Qualitative Research at the Speed of Light Trying It Out Chapter 12: Writing Research Papers: Sorting the Noodles from the Soup Plagiarism: What It Is, Why It's Bad, and How to Avoid It Identifying the Purpose of the Writing: Arranging the Noodles Delineating a Supportive Structure: Visual Signals for the Reader Terms and Conditions Presenting Research Material A Word About the Content of Papers and Articles Write It, Rewrite It, Then Write It Again! A Few Writing Hints A Final Note","['Sociology', 'Qualitative research', 'Social science', 'Pedagogy']","ethical, focus group interviewing, ethnographic field strategies, action research, unobtrusive measures, social historical research, oral traditions, content analysis, symbolic interactionist, implied consent confidentiality, anony, focus, online focus groups, et"
Paper_01370,"Empagliflozin, Cardiovascular Outcomes, and Mortality in Type 2 Diabetes","['Bernard Zinman', 'Christoph Wanner', 'John M. Lachin', 'David Fitchett', 'Erich Bluhmki', 'Stefan Hantel', 'Michaela Mattheus', 'Theresa Devins', 'Odd Erik Johansen', 'Hans J. Woerle', 'Uli C. Broedl', 'Silvio E. Inzucchi']",2015,New England Journal of Medicine,Journal,,2117-2128,373,22,10.1056/nejmoa1504720,"The effects of empagliflozin, an inhibitor of sodium-glucose cotransporter 2, in addition to standard care, on cardiovascular morbidity and mortality in patients with type 2 diabetes at high cardiovascular risk are not known.We randomly assigned patients to receive 10 mg or 25 mg of empagliflozin or placebo once daily. The primary composite outcome was death from cardiovascular causes, nonfatal myocardial infarction, or nonfatal stroke, as analyzed in the pooled empagliflozin group versus the placebo group. The key secondary composite outcome was the primary outcome plus hospitalization for unstable angina.A total of 7020 patients were treated (median observation time, 3.1 years). The primary outcome occurred in 490 of 4687 patients (10.5%) in the pooled empagliflozin group and in 282 of 2333 patients (12.1%) in the placebo group (hazard ratio in the empagliflozin group, 0.86; 95.02% confidence interval, 0.74 to 0.99; P=0.04 for superiority). There were no significant between-group differences in the rates of myocardial infarction or stroke, but in the empagliflozin group there were significantly lower rates of death from cardiovascular causes (3.7%, vs. 5.9% in the placebo group; 38% relative risk reduction), hospitalization for heart failure (2.7% and 4.1%, respectively; 35% relative risk reduction), and death from any cause (5.7% and 8.3%, respectively; 32% relative risk reduction). There was no significant between-group difference in the key secondary outcome (P=0.08 for superiority). Among patients receiving empagliflozin, there was an increased rate of genital infection but no increase in other adverse events.Patients with type 2 diabetes at high risk for cardiovascular events who received empagliflozin, as compared with placebo, had a lower rate of the primary composite cardiovascular outcome and of death from any cause when the study drug was added to standard care. (Funded by Boehringer Ingelheim and Eli Lilly; EMPA-REG OUTCOME ClinicalTrials.gov number, NCT01131676.).","['Empagliflozin', 'Medicine', 'Hazard ratio', 'Myocardial infarction', 'Internal medicine', 'Placebo', 'Confidence interval', 'Relative risk', 'Diabetes mellitus', 'Stroke (engine)', 'Angina', 'Type 2 diabetes', 'Cardiology', 'Endocrinology', 'Mechanical engineering', 'Alternative medicine', 'Pathology', 'Engineering']","empagliflozin, cardiovascular morbidity, nonfatal myocardial infarction, nonfatal"
Paper_01371,Foundations of Statistical Natural Language Processing,"['Christopher D. Manning', 'Hinrich Schütze']",1999,['ACM SIGMOD Record'],Unknown,,37-38,31,3,10.1145/601858.601867,"Statistical approaches to processing natural language text have become dominant in recent years. This foundational text is the first comprehensive introduction to statistical natural language processing (NLP) to appear. The book contains all the theory and algorithms needed for building NLP tools. It provides broad but rigorous coverage of mathematical and linguistic foundations, as well as detailed discussion of statistical methods, allowing students and researchers to construct their own implementations. The book covers collocation finding, word sense disambiguation, probabilistic parsing, information retrieval, and other applications.","['Computer science', 'Natural language processing', 'Artificial intelligence', 'Collocation (remote sensing)', 'Parsing', 'Probabilistic logic', 'Natural language', 'Construct (python library)', 'Word (group theory)', 'Natural (archaeology)', 'Question answering', 'Statistical model', 'Linguistics', 'Programming language', 'Machine learning', 'Philosophy', 'Archaeology', 'History']","statistical, natural language text, statistical natural language processing, nlp, statistical methods, collocation finding, word sense disambiguation, probabilistic parsing, information retrieval"
Paper_01372,Quantum Mechanics and Path Integrals,"['Richard P. Feynman', 'A. R. Hibbs']",1966,Students Quarterly Journal,Journal,,56-56,37,145,10.1049/sqj.1966.0063,Au sommaire : 1.The fundamental concepts of quantum mechanics ; 2.The quantum-mechanical law of motion ; 3.Developing the concepts with special examples ; 4.The schrodinger description of quantum mechanics ; 5.Measurements and operators ; 6.The perturbation method in quantum mechanics ; 7.Transition elements ; 8.Harmonic oscillators ; 9.Quantum electrodynamics ; 10.Statistical mechanics ; 11.The variational method ; 12.Other problems in probability.,"['Path integral formulation', 'Path (computing)', 'Classical mechanics', ""Relation between Schrödinger's equation and the path integral formulation of quantum mechanics"", 'Physics', 'Quantum mechanics', 'Theoretical physics', 'Mathematics', 'Statistical physics', 'Quantum', 'Computer science', 'Programming language']","quantum mechanics, schrodinger description, quantum mechanics, measurements, operators, perturbation method, quantum mechanics, transition elements, harmonic oscillators, quantum electrodynamics, statistical mechanics, variational method, probability"
Paper_01373,Marching cubes: A high resolution 3D surface construction algorithm,"['William E. Lorensen', 'H. E. Cline']",1987,Unknown,Unknown,,163-169,,,10.1145/37401.37422,"We present a new algorithm, called marching cubes, that creates triangle models of constant density surfaces from 3D medical data. Using a divide-and-conquer approach to generate inter-slice connectivity, we create a case table that defines triangle topology. The algorithm processes the 3D medical data in scan-line order and calculates triangle vertices using linear interpolation. We find the gradient of the original data, normalize it, and use it as a basis for shading the models. The detail in images produced from the generated surface models is the result of maintaining the inter-slice connectivity, surface data, and gradient information present in the original 3D data. Results from computed tomography (CT), magnetic resonance (MR), and single-photon emission computed tomography (SPECT) illustrate the quality and functionality of marching cubes. We also discuss improvements that decrease processing time and add solid modeling capabilities.","['Marching cubes', 'Interpolation (computer graphics)', 'Computer science', 'Algorithm', 'Fast marching method', 'Surface (topology)', 'Ground truth', 'Surface reconstruction', 'Single-photon emission computed tomography', 'Computer vision', 'Artificial intelligence', 'Mathematics', 'Visualization', 'Geometry', 'Image (mathematics)', 'Medicine', 'Internal medicine']","marching cubes, triangle models, constant density surfaces, 3d medical data, triangle topology, triangle vertices, linear interpolation, gradient information, computed, magnetic, marching cubes, processing, solid modeling"
Paper_01374,Carbon Nanotubes--the Route Toward Applications,"['Ray H. Baughman', 'Anvar Zakhidov', 'Walt A. de Heer']",2002,Science,Journal,,787-792,297,5582,10.1126/science.1060928,"Many potential applications have been proposed for carbon nanotubes, including conductive and high-strength composites; energy storage and energy conversion devices; sensors; field emission displays and radiation sources; hydrogen storage media; and nanometer-sized semiconductor devices, probes, and interconnects. Some of these applications are now realized in products. Others are demonstrated in early to advanced devices, and one, hydrogen storage, is clouded by controversy. Nanotube cost, polydispersity in nanotube type, and limitations in processing and assembly methods are important barriers for some applications of single-walled nanotubes.","['Carbon nanotube', 'Nanotechnology', 'Materials science', 'Hydrogen storage', 'Energy storage', 'Nanotube', 'Semiconductor', 'Nanometre', 'Dispersity', 'Optoelectronics', 'Composite material', 'Physics', 'Power (physics)', 'Alloy', 'Quantum mechanics', 'Polymer chemistry']","carbon nanotubes, energy storage, energy conversion devices, sensors, field emission displays, radiation sources, hydrogen storage media, probes, interconnects, hydrogen storage, nanotube cost, polydispersity, ##tub, [PAD], [PAD] [PAD], [PAD] [PAD] [PAD], [PAD] [PAD] [PAD]"
Paper_01375,Finding Structure in Time,['Jeffrey L. Elman'],1990,Cognitive Science,Journal,,179-211,14,2,10.1207/s15516709cog1402_1,"Time underlies many interesting human behaviors. Thus, the question of how to represent time in connectionist models is very important. One approach is to represent time implicitly by its effects on processing rather than explicitly (as in a spatial representation). The current report develops a proposal along these lines first described by Jordan (1986) which involves the use of recurrent links in order to provide networks with a dynamic memory. In this approach, hidden unit patterns are fed back to themselves: the internal representations which develop thus reflect task demands in the context of prior internal states. A set of simulations is reported which range from relatively simple problems (temporal version of XOR) to discovering syntactic/semantic features for words. The networks are able to learn interesting internal representations which incorporate task demands with memory demands: indeed, in this approach the notion of memory is inextricably bound up with task processing. These representations reveal a rich structure, which allows them to be highly context‐dependent, while also expressing generalizations across classes of items. These representations suggest a method for representing lexical categories and the type/token distinction.","['Connectionism', 'Computer science', 'Set (abstract data type)', 'Task (project management)', 'Context (archaeology)', 'Representation (politics)', 'Artificial intelligence', 'Natural language processing', 'Semantic memory', 'Security token', 'Cognitive science', 'Cognition', 'Artificial neural network', 'Psychology', 'Law', 'Economics', 'Biology', 'Paleontology', 'Computer security', 'Management', 'Neuroscience', 'Politics', 'Political science', 'Programming language']","human behaviors, connectionist models, spatial representation, ##urrent links, dynamic memory, hidden unit patterns, memory, lexical categories, [PAD], [PAD] [PAD], [PAD]"
Paper_01376,Developing and evaluating complex interventions: the new Medical Research Council guidance,"['Peter Craig', 'Paul Dieppe', 'Sally MacIntyre', 'Susan Michie', 'Irwin Nazareth', 'Mark Petticrew']",2008,BMJ,Journal,,a1655-a1655,,,10.1136/bmj.a1655,"<h3>Abstract</h3> DNA methylation is an important epigenetic regulator of gene expression. Recent studies have revealed widespread associations between genetic variation and methylation levels. However, the mechanistic links between genetic variation and methylation remain unclear. To begin addressing this gap, we collected methylation data at ∼300,000 loci in lymphoblastoid cell lines (LCLs) from 64 HapMap Yoruba individuals, and genome-wide bisulfite sequence data in ten of these individuals. We identified (at an FDR of 10%) 13,915 <i>cis</i> methylation QTLs (meQTLs)—i.e., CpG sites in which changes in DNA methylation are associated with genetic variation at proximal loci. We found that meQTLs are frequently associated with changes in methylation at multiple CpGs across regions of up to 3 kb. Interestingly, meQTLs are also frequently associated with variation in other properties of gene regulation, including histone modifications, DNase I accessibility, chromatin accessibility, and expression levels of nearby genes. These observations suggest that genetic variants may lead to coordinated molecular changes in all of these regulatory phenotypes. One plausible driver of coordinated changes in different regulatory mechanisms is variation in transcription factor (TF) binding. Indeed, we found that SNPs that change predicted TF binding affinities are significantly enriched for associations with DNA methylation at nearby CpGs. <h3>Author Summary</h3> DNA methylation is an important epigenetic mark that contributes to many biological processes including the regulation of gene expression. Genetic variation has been associated with quantitative changes in DNA methylation (meQTLs). We identified thousands of meQTLs using an assay that allowed us to measure methylation levels at around 300 thousand cytosines. We found that meQTLs are enriched with loci that is also associated with quantitative changes in gene expression, DNase I hypersensitivity, PolII occupancy, and a number of histone marks. This suggests that many molecular events are likely regulated in concert. Finally, we found that changes in transcription factor binding as well as transcription factor abundance are associated with changes in DNA methylation near transcription factor binding sites. This work contributes to our understanding of the regulation of DNA methylation in the larger context of gene regulatory landscape.","['DNA methylation', 'Epigenetics', 'Biology', 'Genetics', 'Methylation', 'CpG site', 'Epigenomics', 'Chromatin', 'Regulation of gene expression', 'Epigenetics of physical exercise', 'DNA binding site', 'Gene', 'Gene expression', 'Promoter']","dna methylation, ##igenetic, gene expression, genetic variation, methylation levels, genetic variation, methyl, methylation, ##id cell lines, methylation qtls, cpg, dna, ##mal, meqtl, meqtls, gene regulation, histone modifications, chromatin accessibility, genetic, transcription, ##f, dna, genetic variation, dna methylation, polii occ, ##tone marks, transcription factor binding, transcription, transcription factor, dna"
Paper_01377,The Foucault Effect: Studies in Governmentality,"['Graham Burchell', 'Colin Gordon', 'Peter Miller']",1991,Unknown,Unknown,,,,,10.1515/9780791487112,"Governmental rationality - an introduction, Colin Gordon politics and study of discourse, Michel Foucault questions of method, Michel Foucault governmentality, Michel Foucault theatrum politicum - genealogy of capital (police and state of prosperity), Pasquale Pasquino peculiar interests - civil society and governing the system of natural liberty, Graham Burchell social economy and government of poverty, Giovanna Procaci mobilization of society, Jacques Donzelot how should we do history of statistics?, Ian Hacking insurance and risk, Francois Ewald popular life and insurance technology, Daniel Defert criminology - birth of a special knowledge, Pasqale Pasquino pleasure in work, Jacques Donzelot from dangerousness to risk, Robert Castel.","['Governmentality', 'Michel foucault', 'Sociology', 'Rationality', 'Pleasure', 'Politics', 'Prosperity', 'Government (linguistics)', 'Capital (architecture)', 'Poverty', 'Criminology', 'Humanities', 'Law', 'Political science', 'Art', 'Philosophy', 'Psychology', 'Linguistics', 'Neuroscience', 'Visual arts']","governmental rationality, discourse, governmentality, capital, police, civil society, natural liberty, social economy, risk, insurance"
Paper_01379,R: A Language for Data Analysis and Graphics,"['Ross Ihaka', 'Robert Gentleman']",1996,Journal of Computational and Graphical Statistics,Journal,,299-314,5,3,10.1080/10618600.1996.10474713,"Abstract In this article we discuss our experience designing and implementing a statistical computing language. In developing this new language, we sought to combine what we felt were useful features from two existing computer languages. We feel that the new language provides advantages in the areas of portability, computational efficiency, memory management, and scoping.","['Software portability', 'Computer science', 'Computational statistics', 'Graphics', 'Programming language', 'Data science', 'Artificial intelligence', 'Machine learning', 'Computer graphics (images)']","statistical computing language, portability, computational efficiency, memory management, scoping, [PAD], [PAD] [PAD], [PAD], [PAD], [PAD]"
Paper_01380,The Logic of Collective Action,['Mancur Olson'],1965,Harvard University Press eBooks,Unknown,,,,,10.4159/9780674041660,"Olson develops a theory of group and organizational behavior that cuts across disciplinary lines and illustrates the theory with empirical and historical studies of particular organizations, examining the extent to which individuals who share a common interest find it in their individual interest to bear the costs of the organizational effort.","['Action (physics)', 'Collective action', 'Computer science', 'Epistemology', 'Political science', 'Philosophy', 'Physics', 'Law', 'Quantum mechanics', 'Politics']",organizational behavior
Paper_01381,Principles of Economics,['Alfred Marshall'],1890,['Journal of the Royal Statistical Society'],Unknown,,337,76,3,10.2307/2340059,"BOOK I: PRELIMINARY SURVEY 1. Introduction 2. The Substance of Economics 3. Economic Generalizations or Laws 4. The Order and Aims of Economic Studies BOOK II: SOME FUNDAMENTAL NOTIONS 1. Introductory 2. Wealth 3. Production, Consumption, Labour, Necessaries 4. Income. Capital. BOOK III: ON WANTS AND THEIR SATISFACTION 1. Introductory 2. Wants in Relation to Activities 3. Gradations of consumers' demand 4. The elasticity of wants 5. Choice between different uses of the same thing. Immediate and deferred uses. 6. Value and utility BOOK IV: THE AGENTS OF PRODUCTION. LAND, LABOUR, CAPITAL AND ORGANIZATION T 1. Introductory 2. The Fertility of Land 3. The Fertility of Land, continued. The Tendency to Diminishing Return. 4. The Growth of Population 5. The Health and Strength of the Population 6. Industrial Training. 7. The Growth of Wealth 8. Industrial Organization 9. Industrial Organization, continued. Division of Labour. The Influence of Machinery 10. Industrial Organization, continued. The Concentration of the Specialized Industries in Particular Localities. 11. Industrial Organization, continued. Production on a Large Scale 12. Industrial Organization, continued. Business Management. 13. Conclusion. Correlation of the Tendencies to Increasing and to Diminishing Return BOOK V: GENERAL RELATIONS OF DEMAND, SUPPLY, AND VALUE 1. Introductory. On Markets. 2. Temporary Equilibrium of Demand and Supply 3. Equilibrium of Normal Demand and Supply 4. The Investment and Distribution of Resources 5. Equilibrium of Normal Demand and Supply, continued, with reference to long and short periods 6. Joint and Composite Demand. Joint and Composite Supply 7. Prime and total cost in relation to joint products. Cost of marketing. Insurance against risk. Cost of Reproduction. 8. Marginal costs in relation to values. General Principles. 9. Marginal costs in relation to values. General Principles, continued 10. Marginal costs in relation to agricultural values 11. Marginal costs in relation to urban values 12. Equilibrium of normal demand and supply, continued, with reference to the law of increasing return 13. Theory of changes of normal demand and supply, in relation to the doctrine of maximum satisfaction 14. The theory of monopolies 15. Summary of the general theory of equilibrium of demand and supply BOOK VI: THE DISTRIBUTION OF THE NATIONAL INCOME 1. Preliminary survey of distribution 2. Preliminary survey of distribution, continued 3. Earnings of labour 4. Earnings of labour, continued 5. Earnings of labour, continued 6. Interest of capital 7. Profits of capital and business power 8. Profits of capital and business power, continued 9. Rent of land 10. Land tenure 11. General view of distribution 12. General influences of progress on value 13. Progress in relation to standards of life","['Economics', 'Population', 'Consumption (sociology)', 'Supply and demand', 'Labour supply', 'Agricultural economics', 'Labour economics', 'Microeconomics', 'Social science', 'Demography', 'Sociology']","economic generalizations, nec, ##aries, gr, elasticity, industrial training, industrial organization, industrial organization, industrial organization, industrial organization, business management, temporary equilibrium, normal demand, composite demand, total cost, marginal costs, marginal costs, marginal costs, agricultural values, marginal costs, urban values, increasing return, normal demand, maximum satisfaction, monopolies, earnings, earnings, earnings"
Paper_01382,The weirdest people in the world?,"['Joseph Henrich', 'Steven J. Heine', 'Ara Norenzayan']",2010,Behavioral and Brain Sciences,Journal,,61-83,33,2-3,10.1017/s0140525x0999152x,"Abstract Behavioral scientists routinely publish broad claims about human psychology and behavior in the world's top journals based on samples drawn entirely from Western, Educated, Industrialized, Rich, and Democratic (WEIRD) societies. Researchers – often implicitly – assume that either there is little variation across human populations, or that these “standard subjects” are as representative of the species as any other population. Are these assumptions justified? Here, our review of the comparative database from across the behavioral sciences suggests both that there is substantial variability in experimental results across populations and that WEIRD subjects are particularly unusual compared with the rest of the species – frequent outliers. The domains reviewed include visual perception, fairness, cooperation, spatial reasoning, categorization and inferential induction, moral reasoning, reasoning styles, self-concepts and related motivations, and the heritability of IQ. The findings suggest that members of WEIRD societies, including young children, are among the least representative populations one could find for generalizing about humans. Many of these findings involve domains that are associated with fundamental aspects of psychology, motivation, and behavior – hence, there are no obvious a priori grounds for claiming that a particular behavioral phenomenon is universal based on sampling from a single subpopulation. Overall, these empirical patterns suggests that we need to be less cavalier in addressing questions of human nature on the basis of data drawn from this particularly thin, and rather unusual, slice of humanity. We close by proposing ways to structurally re-organize the behavioral sciences to best tackle these challenges.","['Categorization', 'Psychology', 'Variation (astronomy)', 'Population', 'Phenomenon', 'Behavioural sciences', 'Social psychology', 'Cognitive psychology', 'Epistemology', 'Sociology', 'Philosophy', 'Physics', 'Demography', 'Astrophysics', 'Psychotherapist']","abstract behavioral scientists, human psychology, behavior, comparative database, visual perception, fairness, cooperation, spatial reasoning, categorization, inferential induction, moral reasoning, reasoning styles, her, iq, psychology, motivation, behavior"
Paper_01383,Cd-hit: a fast program for clustering and comparing large sets of protein or nucleotide sequences,"['Weizhong Li', 'Adam Godzik']",2006,Bioinformatics,Journal,,1658-1659,22,13,10.1093/bioinformatics/btl158,"In 2001 and 2002, we published two papers (Bioinformatics, 17, 282-283, Bioinformatics, 18, 77-82) describing an ultrafast protein sequence clustering program called cd-hit. This program can efficiently cluster a huge protein database with millions of sequences. However, the applications of the underlying algorithm are not limited to only protein sequences clustering, here we present several new programs using the same algorithm including cd-hit-2d, cd-hit-est and cd-hit-est-2d. Cd-hit-2d compares two protein datasets and reports similar matches between them; cd-hit-est clusters a DNA/RNA sequence database and cd-hit-est-2d compares two nucleotide datasets. All these programs can handle huge datasets with millions of sequences and can be hundreds of times faster than methods based on the popular sequence comparison and database search tools, such as BLAST.","['Cluster analysis', 'Computer science', 'Sequence (biology)', 'Protein sequencing', 'Sequence database', 'Sequence alignment', 'Data mining', 'Computational biology', 'Database', 'Bioinformatics', 'Peptide sequence', 'Biology', 'Genetics', 'Artificial intelligence', 'Gene']","bioinformatics, bioinformatics, ultrafast protein sequence clustering program, protein database, protein sequences clustering, ##cle, sequence comparison, database search, blast, [PAD]"
Paper_01384,A study of cross-validation and bootstrap for accuracy estimation and model selection,['Ron Kohavi'],1995,['Statistics in Biopharmaceutical Research'],Conference,,168-203,14,2,10.1080/19466315.2020.1828159,"We review accuracy estimation methods and compare the two most common methods crossvalidation and bootstrap. Recent experimental results on artificial data and theoretical re cults in restricted settings have shown that for selecting a good classifier from a set of classifiers (model selection), ten-fold cross-validation may be better than the more expensive leaveone-out cross-validation. We report on a largescale experiment--over half a million runs of C4.5 and a Naive-Bayes algorithm--to estimate the effects of different parameters on these algrithms on real-world datasets. For crossvalidation we vary the number of folds and whether the folds are stratified or not, for bootstrap, we vary the number of bootstrap samples. Our results indicate that for real-word datasets similar to ours, The best method to use for model selection is ten fold stratified cross validation even if computation power allows using more folds.","['Cross-validation', 'Naive Bayes classifier', 'Model selection', 'Computer science', 'Classifier (UML)', 'Selection (genetic algorithm)', 'Feature selection', 'Artificial intelligence', 'Computation', 'Statistics', 'Data mining', 'Machine learning', 'Pattern recognition (psychology)', 'Mathematics', 'Support vector machine', 'Algorithm']","accuracy estimation methods, crossvalidation, bootstrap, artificial data, theoretical re cults, restricted settings, model selection, ##ith, cross, ##idation, bootstrap, bootstrap, model selection"
Paper_01386,On Estimation of a Probability Density Function and Mode,['Emanuel Parzen'],1962,The Annals of Mathematical Statistics,Journal,,1065-1076,33,3,10.1214/aoms/1177704472,"Abstract : Given a sequence of independent identically distributed random variables with a common probability density function, the problem of the estimation of a probability density function and of determining the mode of a probability function are discussed. Only estimates which are consistent and asymptotically normal are constructed. (Author)","['Mathematics', 'Probability density function', 'Estimation', 'Density estimation', 'Statistics', 'Econometrics', 'Mode (computer interface)', 'Applied mathematics', 'Computer science', 'Estimator', 'Economics', 'Operating system', 'Management']","identically distributed random variables, common probability density function, probability density function, probability, asymptotically, [PAD] [PAD] [PAD], [PAD], [PAD], [PAD] [PAD], [PAD] [PAD] [PAD], [PAD] [PAD], [PAD] [PAD], [PAD]"
Paper_01387,A Theory of the Allocation of Time,['Gary S. Becker'],1965,The Economic Journal,Journal,,493-493,75,299,10.2307/2228949,"Journal Article A Theory of the Allocation of Time Get access Gary S. Becker Gary S. Becker Columbia University Search for other works by this author on: Oxford Academic Google Scholar The Economic Journal, Volume 75, Issue 299, 1 September 1965, Pages 493–517, https://doi.org/10.2307/2228949 Published: 01 September 1965","['Mathematical economics', 'Sociology', 'Operations research', 'Economics', 'Mathematics']","allocation, economic"
Paper_01390,The Cityscapes Dataset for Semantic Urban Scene Understanding,"['Marius Cordts', 'Mohamed Omran', 'Sebastian Ramos', 'Timo Rehfeld', 'Markus Enzweiler', 'Rodrigo Benenson', 'Uwe Franke', 'Stefan Roth', 'Bernt Schiele']",2016,Unknown,Unknown,,3213-3223,,,10.1109/cvpr.2016.350,"Visual understanding of complex urban street scenes is an enabling factor for a wide range of applications. Object detection has benefited enormously from large-scale datasets, especially in the context of deep learning. For semantic urban scene understanding, however, no current dataset adequately captures the complexity of real-world urban scenes. To address this, we introduce Cityscapes, a benchmark suite and large-scale dataset to train and test approaches for pixel-level and instance-level semantic labeling. Cityscapes is comprised of a large, diverse set of stereo video sequences recorded in streets from 50 different cities. 5000 of these images have high quality pixel-level annotations, 20 000 additional images have coarse annotations to enable methods that leverage large volumes of weakly-labeled data. Crucially, our effort exceeds previous attempts in terms of dataset size, annotation richness, scene variability, and complexity. Our accompanying empirical study provides an in-depth analysis of the dataset characteristics, as well as a performance evaluation of several state-of-the-art approaches based on our benchmark.","['Computer science', 'Leverage (statistics)', 'Artificial intelligence', 'Suite', 'Benchmark (surveying)', 'Context (archaeology)', 'Scale (ratio)', 'Set (abstract data type)', 'Pixel', 'Semantics (computer science)', 'Machine learning', 'Computer vision', 'Cartography', 'Geography', 'Archaeology', 'Programming language']","visual understanding, complex urban street scenes, object detection, deep learning, semantic urban scene understanding, cityscapes, ##mark suite, cityscapes, stereo video sequences, dataset size, annotation richness, scene variability, performance evaluation"
Paper_01391,Sarcopenia: revised European consensus on definition and diagnosis,"['Alfonso J. Cruz‐Jentoft', 'Gülistan Bahat', 'Jürgen M. Bauer', 'Yves Boirie\u200c', 'Olivier Bruyère', 'Tommy Cederholm', 'Cyrus Cooper', 'Francesco Landi', 'Yves Rolland', 'Avan Aihie Sayer', 'S. Schneider', 'Cornel Sieber', 'Eva Topinková', 'M. Vandewoude', 'Marjolein Visser', 'Mauro Zamboni', 'Ivan Bautmans', 'Jean‐Pierre Baeyens', 'Matteo Cesari', 'Antonio Cherubini', 'John А. Kanis', 'Marcello Maggio', 'Finbarr C. Martin', 'Jean‐Pierre Michel', 'Kaisu Pitkälä', 'Jean‐Yves Reginster', 'René Rizzoli', 'Dolores Sánchez‐Rodríguez', 'Jos M. G. A. Schols']",2018,Age and Ageing,Journal,,16-31,48,1,10.1093/ageing/afy169,"in 2010, the European Working Group on Sarcopenia in Older People (EWGSOP) published a sarcopenia definition that aimed to foster advances in identifying and caring for people with sarcopenia. In early 2018, the Working Group met again (EWGSOP2) to update the original definition in order to reflect scientific and clinical evidence that has built over the last decade. This paper presents our updated findings. to increase consistency of research design, clinical diagnoses and ultimately, care for people with sarcopenia. sarcopenia is a muscle disease (muscle failure) rooted in adverse muscle changes that accrue across a lifetime; sarcopenia is common among adults of older age but can also occur earlier in life. In this updated consensus paper on sarcopenia, EWGSOP2: (1) focuses on low muscle strength as a key characteristic of sarcopenia, uses detection of low muscle quantity and quality to confirm the sarcopenia diagnosis, and identifies poor physical performance as indicative of severe sarcopenia; (2) updates the clinical algorithm that can be used for sarcopenia case-finding, diagnosis and confirmation, and severity determination and (3) provides clear cut-off points for measurements of variables that identify and characterise sarcopenia. EWGSOP2's updated recommendations aim to increase awareness of sarcopenia and its risk. With these new recommendations, EWGSOP2 calls for healthcare professionals who treat patients at risk for sarcopenia to take actions that will promote early detection and treatment. We also encourage more research in the field of sarcopenia in order to prevent or delay adverse health outcomes that incur a heavy burden for patients and healthcare systems.","['Sarcopenia', 'Medicine', 'MEDLINE', 'Intensive care medicine', 'Gerontology', 'Internal medicine', 'Law', 'Political science']","sarcopenia, older people, ewgsop, sarcopenia definition, sarcopenia, ##wgsop, sarcopenia, muscle failure, adverse muscle changes, sarcopenia, sarcopenia, ##sop, low muscle strength, sarcope, severity, sar, ##sop, ##wgsop, healthcare, sarcope"
Paper_01395,Dynamics of Fluids in Porous Media,['Jacob Bear'],1975,Soil Science,Journal,,162-163,120,2,10.1097/00010694-197508000-00022,"Keywords: Ecoulement souterrain ; Milieux poreux Reference Record created on 2004-09-07, modified on 2016-08-08","['Porous medium', 'Porosity', 'Geology', 'Mechanics', 'Geotechnical engineering', 'Materials science', 'Physics']","ecoule, milieu, por, [PAD], [PAD] [PAD], [PAD], [PAD], [PAD], [PAD], [PAD]"
Paper_01396,Efficient Hybrid Solar Cells Based on Meso-Superstructured Organometal Halide Perovskites,"['Michael M. Lee', 'Joël Teuscher', 'Tsutomu Miyasaka', 'Takurou N. Murakami', 'Henry J. Snaith']",2012,Science,Journal,,643-647,338,6107,10.1126/science.1228604,"Perovskite Photovoltaics For many types of low-cost solar cells, including those using dye-sensitized titania, performance is limited by low open-circuit voltages. Lee et al. (p. 643 , published online 4 October; see the Perspective by Norris and Aydil ) have developed a solid-state cell in which structured films of titania or alumina nanoparticles are solution coated with a lead-halide perovskite layer that acts as the absorber and n-type photoactive layer. These particles are coated with a spirobifluorene organic-hole conductor in a solar cell with transparent oxide and metal contacts. For the alumina particles, power conversion efficiencies of up to 10.9% were obtained.","['Halide', 'Perovskite (structure)', 'Photovoltaics', 'Materials science', 'Solar cell', 'Photoactive layer', 'Energy conversion efficiency', 'Layer (electronics)', 'Perovskite solar cell', 'Optoelectronics', 'Nanoparticle', 'Chemical engineering', 'Photovoltaic system', 'Nanotechnology', 'Inorganic chemistry', 'Chemistry', 'Polymer solar cell', 'Ecology', 'Biology', 'Engineering']","perovskite photovoltaics, structured films, titan, alumina nanopar, transparent oxide, power conversion effi"
Paper_01398,Speech Acts,['John R. Searle'],1969,Unknown,Unknown,,,,,10.1017/cbo9781139173438,"Written in an outstandingly clear and lively style, this 1969 book provokes its readers to rethink issues they may have regarded as long since settled.","['Computer science', 'Psychology', 'Communication', 'Speech recognition', 'Linguistics', 'Philosophy']",
Paper_01399,On Happiness and Human Potentials: A Review of Research on Hedonic and Eudaimonic Well-Being,"['Richard M. Ryan', 'Edward L. Deci']",2001,Annual Review of Psychology,Journal,,141-166,52,1,10.1146/annurev.psych.52.1.141,"▪ Abstract Well-being is a complex construct that concerns optimal experience and functioning. Current research on well-being has been derived from two general perspectives: the hedonic approach, which focuses on happiness and defines well-being in terms of pleasure attainment and pain avoidance; and the eudaimonic approach, which focuses on meaning and self-realization and defines well-being in terms of the degree to which a person is fully functioning. These two views have given rise to different research foci and a body of knowledge that is in some areas divergent and in others complementary. New methodological developments concerning multilevel modeling and construct comparisons are also allowing researchers to formulate new questions for the field. This review considers research from both perspectives concerning the nature of well-being, its antecedents, and its stability across time and culture.","['Happiness', 'Psychology', 'Pleasure', 'Construct (python library)', 'Eudaimonia', 'Well-being', 'Meaning (existential)', 'Social psychology', 'Positive psychology', 'Cognitive psychology', 'Epistemology', 'Psychotherapist', 'Philosophy', 'Computer science', 'Programming language']","optimal experience, hedonic approach, happiness, pleasure attainment, pain avoidance, eudaimonic, meaning, multilevel modeling, construct comparisons, [PAD] [PAD] [PAD], [PAD] [PAD] [PAD]"
Paper_01400,The Human Genome Browser at UCSC,"['W. James Kent', 'Charles W. Sugnet', 'Terrence S. Furey', 'Krishna M. Roskin', 'Tom H. Pringle', 'Alan M. Zahler', 'A Haussler']",2002,Genome Research,Journal,,996-1006,12,6,10.1101/gr.229102,"As vertebrate genome sequences near completion and research refocuses to their analysis, the issue of effective genome annotation display becomes critical. A mature web tool for rapid and reliable display of any requested portion of the genome at any scale, together with several dozen aligned annotation tracks, is provided at http://genome.ucsc.edu . This browser displays assembly contigs and gaps, mRNA and expressed sequence tag alignments, multiple gene predictions, cross-species homologies, single nucleotide polymorphisms, sequence-tagged sites, radiation hybrid data, transposon repeats, and more as a stack of coregistered tracks. Text and sequence-based searches provide quick and precise access to any region of specific interest. Secondary links from individual features lead to sequence details and supplementary off-site databases. One-half of the annotation tracks are computed at the University of California, Santa Cruz from publicly available sequence data; collaborators worldwide provide the rest. Users can stably add their own custom tracks to the browser for educational or research purposes. The conceptual and technical framework of the browser, its underlying MYSQL database, and overall use are described. The web site currently serves over 50,000 pages per day to over 3000 different users.","['Genome browser', 'Annotation', 'Biology', 'Genome', 'Contig', 'Genome project', 'Computational biology', 'Sequence (biology)', 'Scrolling', 'Genomics', 'Genetics', 'World Wide Web', 'Computer science', 'Gene', 'Artificial intelligence']","vertebrate genome sequences, genome annotation display, aligned annotation tracks, multiple gene predictions, single nucleotide polymorphisms, radiation hybrid data, transposon repeats, mys, ##l database"
Paper_01401,Raman Spectrum of Graphite,"['F. Tuinstra', 'Jack L. Koenig']",1970,The Journal of Chemical Physics,Journal,,1126-1130,53,3,10.1063/1.1674108,"Raman spectra are reported from single crystals of graphite and other graphite materials. Single crystals of graphite show one single line at 1575 cm−1. For the other materials like stress-annealed pyrolitic graphite, commercial graphites, activated charcoal, lampblack, and vitreous carbon another line is detected at 1355 cm−1. The Raman intensity of this band is inversely proportional to the crystallite size and is caused by a breakdown of the k-selection rule. The intensity of this band allows an estimate of the crystallite size in the surface layer of any carbon sample. Two in-plane force constants are calculated from the frequencies.","['Graphite', 'Raman spectroscopy', 'Crystallite', 'Materials science', 'Polycrystalline diamond', 'Carbon fibers', 'Intensity (physics)', 'Analytical Chemistry (journal)', 'Mineralogy', 'Composite material', 'Chemistry', 'Optics', 'Diamond', 'Physics', 'Metallurgy', 'Chromatography', 'Composite number']","raman spectra, single, graphite, graphite materials, graphite, commercial graphites, activated charcoal, lampblack, vitreous carbon, raman intensity, ##lite, carbon, [PAD], [PAD]"
Paper_01402,Polymer Photovoltaic Cells: Enhanced Efficiencies via a Network of Internal Donor-Acceptor Heterojunctions,"['Gang Yu', 'Jun Gao', 'Jan C. Hummelen', 'Fred Wudl', 'Alan J. Heeger']",1995,Science,Journal,,1789-1791,270,5243,10.1126/science.270.5243.1789,"The carrier collection efficiency (η c ) and energy conversion efficiency (η e ) of polymer photovoltaic cells were improved by blending of the semiconducting polymer with C 60 or its functionalized derivatives. Composite films of poly(2-methoxy-5-(2′-ethyl-hexyloxy)-1,4-phenylene vinylene) (MEH-PPV) and fullerenes exhibit η c of about 29 percent of electrons per photon and η e of about 2.9 percent, efficiencies that are better by more than two orders of magnitude than those that have been achieved with devices made with pure MEH-PPV. The efficient charge separation results from photoinduced electron transfer from the MEH-PPV (as donor) to C 60 (as acceptor); the high collection efficiency results from a bicontinuous network of internal donor-acceptor heterojunctions.","['Acceptor', 'Materials science', 'Heterojunction', 'Fullerene', 'Polymer', 'Photovoltaic system', 'Phenylene', 'Energy conversion efficiency', 'Polymer solar cell', 'Charge carrier', 'Optoelectronics', 'Electron acceptor', 'Photochemistry', 'Chemistry', 'Organic chemistry', 'Composite material', 'Physics', 'Condensed matter physics', 'Ecology', 'Biology']","carrier collection efficiency, energy conversion efficiency, polymer photovoltaic cells, semi, ##du, composite films, charge separation"
Paper_01406,The Production of Space,"['E Swyngedouw', 'Henri Lefebvre']",1992,Economic Geography,Journal,,317-317,68,3,10.2307/144191,Translatora s Acknowledgements. 1. Plan of the Present Work. 2. Social Space. 3. Spatial Architectonics. 4. From Absolute Space to Abstract Space. 5. Contradictory Space. 6. From the Contradictions of Space to Differential Space. 7. Openings and Conclusions. Afterword by David Harvey. Index.,"['Production (economics)', 'Space (punctuation)', 'Economics', 'Computer science', 'Microeconomics', 'Operating system']","social space, spatial architectonics, absolute space, abstract space, contradictory space, contradiction, differential space"
Paper_01408,Intensive Insulin Therapy in Critically Ill Patients,"['Greet Van den Berghe', 'Pieter Wouters', 'Frank Weekers', 'Charles Verwaest', 'Frans Bruyninckx', 'Miet Schetz', 'Dirk Vlasselaers', 'Patrick Ferdinande', 'Peter Lauwers', 'Roger Bouillon']",2001,New England Journal of Medicine,Journal,,1359-1367,345,19,10.1056/nejmoa011300,"Hyperglycemia and insulin resistance are common in critically ill patients, even if they have not previously had diabetes. Whether the normalization of blood glucose levels with insulin therapy improves the prognosis for such patients is not known.","['Medicine', 'Critically ill', 'Insulin', 'Insulin resistance', 'Intensive care medicine', 'Diabetes mellitus', 'Critical illness', 'Internal medicine', 'Endocrinology']","hyperglycemia, insulin resistance, critically, blood glucose levels, [PAD] [PAD]"
Paper_01409,The Large Scale Structure of Space-Time,"['S. W. Hawking', 'George Ellis']",1973,Unknown,Unknown,,,,,10.1017/cbo9780511524646,"Einstein's General Theory of Relativity leads to two remarkable predictions: first, that the ultimate destiny of many massive stars is to undergo gravitational collapse and to disappear from view, leaving behind a 'black hole' in space; and secondly, that there will exist singularities in space-time itself. These singularities are places where space-time begins or ends, and the presently known laws of physics break down. They will occur inside black holes, and in the past are what might be construed as the beginning of the universe. To show how these predictions arise, the authors discuss the General Theory of Relativity in the large. Starting with a precise formulation of the theory and an account of the necessary background of differential geometry, the significance of space-time curvature is discussed and the global properties of a number of exact solutions of Einstein's field equations are examined. The theory of the causal structure of a general space-time is developed, and is used to study black holes and to prove a number of theorems establishing the inevitability of singualarities under certain conditions. A discussion of the Cauchy problem for General Relativity is also included in this 1973 book.","['General relativity', 'Theoretical physics', 'Physics', 'Einstein', 'Theory of relativity', 'Spacetime', 'Gravitational collapse', 'Gravitational singularity', 'Space (punctuation)', 'Destiny (ISS module)', 'Space time', 'Black hole (networking)', 'Gravitation', 'Curvature', 'Classical mechanics', 'Mathematics', 'Geometry', 'Quantum mechanics', 'Philosophy', 'Computer science', 'Astronomy', 'Engineering', 'Link-state routing protocol', 'Computer network', 'Linguistics', 'Routing protocol', 'Routing (electronic design automation)', 'Chemical engineering']","gravitational collapse, singular, differential geometry, causal structure, black holes, singualarities, cauchy problem, general relativity"
Paper_01410,Induced Pluripotent Stem Cell Lines Derived from Human Somatic Cells,"['Junying Yu', 'Maxim A. Vodyanik', 'Kim Smuga-Otto', 'Jessica Antosiewicz‐Bourget', 'Jennifer L. Frane', 'Shulan Tian', 'Jeff Nie', 'Guðrún A. Jónsdóttir', 'Victor Ruotti', 'Ron Stewart', 'Igor I. Slukvin', 'James A. Thomson']",2007,Science,Journal,,1917-1920,318,5858,10.1126/science.1151526,"Somatic cell nuclear transfer allows trans-acting factors present in the mammalian oocyte to reprogram somatic cell nuclei to an undifferentiated state. We show that four factors (OCT4, SOX2, NANOG, and LIN28) are sufficient to reprogram human somatic cells to pluripotent stem cells that exhibit the essential characteristics of embryonic stem (ES) cells. These induced pluripotent human stem cells have normal karyotypes, express telomerase activity, express cell surface markers and genes that characterize human ES cells, and maintain the developmental potential to differentiate into advanced derivatives of all three primary germ layers. Such induced pluripotent human cell lines should be useful in the production of new disease models and in drug development, as well as for applications in transplantation medicine, once technical limitations (for example, mutation through viral integration) are eliminated.","['Induced pluripotent stem cell', 'Homeobox protein NANOG', 'SOX2', 'Somatic cell', 'Biology', 'Stem cell', 'Embryonic stem cell', 'Cell biology', 'KOSR', 'Cell potency', 'Telomerase', 'Induced stem cells', 'Somatic cell nuclear transfer', 'Genetics', 'Gene', 'Embryo', 'Embryogenesis', 'Blastocyst']","somatic cell nuclear transfer, mammalian oocyte, so, oct, sox, lin, ##potent, embryonic, tel, drug, transplantation medicine, viral integration"
Paper_01411,Accuracy of clinical diagnosis of idiopathic Parkinson's disease: a clinico-pathological study of 100 cases.,"['Andrew Hughes', 'S. E. Daniel', 'Linda Kilford', 'Andrew J. Lees']",1992,Journal of Neurology Neurosurgery & Psychiatry,Journal,,181-184,55,3,10.1136/jnnp.55.3.181,"Few detailed clinico-pathological correlations of Parkinson9s disease have been published. The pathological findings in 100 patients diagnosed prospectively by a group of consultant neurologists as having idiopathic Parkinson9s disease are reported. Seventy six had nigral Lewy bodies, and in all of these Lewy bodies were also found in the cerebral cortex. In 24 cases without Lewy bodies, diagnoses included progressive supranuclear palsy, multiple system atrophy, Alzheimer9s disease, Alzheimer-type pathology, and basal ganglia vascular disease. The retrospective application of recommended diagnostic criteria improved the diagnostic accuracy to 82%. These observations call into question current concepts of Parkinson9s disease as a single distinct morbid entity.","['Progressive supranuclear palsy', 'Pathological', 'Disease', ""Parkinson's disease"", 'Medicine', 'Atrophy', 'Dementia with Lewy bodies', 'Pathology', 'Basal ganglia', 'Medical diagnosis', 'Degenerative disease', 'Central nervous system disease', 'Lewy body', 'Dementia', 'Central nervous system', 'Internal medicine']","parkinson9, consultant neurologists, idiopathic, nigral lewy bodies, cerebral, progressive supranuclear palsy, multiple system atrophy, alzheimer, basal ganglia vascular disease, parkinson9, [PAD], [PAD] [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD], [PAD] [PAD], [PAD] [PAD], [PAD] [PAD], [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD], [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"
Paper_01413,"Titanium Dioxide Nanomaterials: Synthesis, Properties, Modifications, and Applications","['Xiaobo Chen', 'Samuel S. Mao']",2007,Chemical Reviews,Journal,,2891-2959,107,7,10.1021/cr0500535,"ADVERTISEMENT RETURN TO ISSUEPREVArticleNEXTTitanium Dioxide Nanomaterials: Synthesis, Properties, Modifications, and ApplicationsXiaobo Chen and Samuel S. MaoView Author Information Lawrence Berkeley National Laboratory, and University of California, Berkeley, California 94720 Cite this: Chem. Rev. 2007, 107, 7, 2891–2959Publication Date (Web):June 23, 2007Publication History Received27 March 2006Published online23 June 2007Published inissue 1 July 2007https://pubs.acs.org/doi/10.1021/cr0500535https://doi.org/10.1021/cr0500535research-articleACS PublicationsCopyright © 2007 American Chemical SocietyRequest reuse permissionsArticle Views122151Altmetric-Citations9105LEARN ABOUT THESE METRICSArticle Views are the COUNTER-compliant sum of full text article downloads since November 2008 (both PDF and HTML) across all institutions and individuals. These metrics are regularly updated to reflect usage leading up to the last few days.Citations are the number of other articles citing this article, calculated by Crossref and updated daily. Find more information about Crossref citation counts.The Altmetric Attention Score is a quantitative measure of the attention that a research article has received online. Clicking on the donut icon will load a page at altmetric.com with additional details about the score and the social media presence for the given article. Find more information on the Altmetric Attention Score and how the score is calculated. Share Add toView InAdd Full Text with ReferenceAdd Description ExportRISCitationCitation and abstractCitation and referencesMore Options Share onFacebookTwitterWechatLinked InRedditEmail Other access optionsGet e-Alertsclose SUBJECTS:Electrodes,Minerals,Nanomaterials,Nanoparticles,Oxides Get e-Alerts","['Citation', 'Computer science', 'World Wide Web', 'Library science', 'Nanotechnology', 'Materials science']","##var, ##lenexttitanium dioxide nanomaterials, american, ##sar, ##le, ##le, altmetric attention score, social, altmetric attention score, exportriscitation, ##ation, abstract, ##ation, references, ##mate, nano, ##les"
Paper_01414,<i>The Physics of Liquid Crystals</i>,"['P. G. de Gennes', 'Jacques Prost', 'Robert A. Pelcovits']",1995,Physics Today,Journal,,70-71,48,5,10.1063/1.2808028,"Part 1 Liquid crystals - main types and properties: introduction - what is a liquid crystal? the building blocks nematics and cholesterics smectics columnar phases more on long-, quasi-long and short-range order remarkable features of liquid crystals. Part 2 Long- and short-range order in nematics: definition of an order parameter statistical theories of the nematic order phenomonological description of the nematic-isotopic mixtures. Part 3 Static distortion in a nematic single crystal: principles of the continuum theory magnetic field effects electric field effects in an insulating nematic fluctuations in the alignment hydrostatics of nematics. Part 4 Defects and textures in nematics: observations disclination lines point disclinations walls under magnetic fields umbilics surface disclinations. Part 5 Dynamical properties of nematics: the equations of nematodynamics experiments measuring the Leslie co-efficients convective instabilities under electric fields molecular motions. Part 6 Cholesterics: optical properties of an ideal helix agents influencing the pitch dynamical properties textures and defects in cholesterics. Part 7 Smectics: symmetry of the main smectic phases continuum description of smectics A and C remarks on phase and precritical phenomena.","['Physics', 'Liquid crystal', 'Engineering physics', 'Optics']","liquid crystals, liquid crystal, nematics, cholesterics smect, columnar phases, liquid crystals, ##s, static distortion, continuum theory magnetic field effects electric field effects, alignment hydrostatics, ##matics, ##s, disclination lines, disclinations, magnetic, ##al properties, convective instabilities, electric, cholesterics, ##ect, precritical phenomena"
Paper_01415,A Treatise on the Theory of Bessel Functions.,"['Matthew Porter', 'G. N. Watson']",1923,American Mathematical Monthly,Journal,,326-326,30,6,10.2307/2300274,1. Bessel functions before 1826 2. The Bessel coefficients 3. Bessel functions 4. Differential equations 5. Miscellaneous properties of Bessel functions 6. Integral representations of Bessel functions 7. Asymptotic expansions of Bessel functions 8. Bessel functions of large order 9. Polynomials associated with Bessel functions 10. Functions associated with Bessel functions 11. Addition theorems 12. Definite integrals 13. Infinitive integrals 14. Multiple integrals 15. The zeros of Bessel functions 16. Neumann series and Lommel's functions of two variables 17. Kapteyn series 18. Series of Fourier-Bessel and Dini 19. Schlomlich series 20. The tabulation of Bessel functions Tables of Bessel functions Bibliography Indices.,"['Bessel function', 'Bessel polynomials', 'Struve function', 'Mathematics', 'Cylindrical harmonics', 'Calculus (dental)', 'Mathematical analysis', 'Medicine', 'Orthogonal polynomials', 'Classical orthogonal polynomials', 'Gegenbauer polynomials', 'Macdonald polynomials', 'Dentistry', 'Difference polynomials']","bessel functions, bessel coefficients, bessel functions, differential equations, miscellaneous properties, bessel functions, integral representations, bessel functions, asymptotic expansions, bessel functions, bessel functions, large order, bessel functions, bessel functions, addition theorems, definite integrals, infinitive integrals, multiple integrals, zeros, bessel functions, neumann series, kapteyn series, ##lich series, tab, bessel functions, bessel functions, [PAD] [PAD], [PAD], [PAD] [PAD], [PAD], [PAD] [PAD], [PAD], [PAD], [PAD] [PAD], [PAD] [PAD], [PAD] [PAD], [PAD] [PAD], [PAD] [PAD], [PAD], [PAD], [PAD], [PAD]"
Paper_01416,Cognitive Therapy for Depression,"['Steven D. Hollon', 'Aaron T. Beck']",2012,PsycEXTRA Dataset,Unknown,,,,,10.1037/e675542012-001,"We provide an overview of cognitive therapy (CT) of depression, including its treatment procedures, therapeutic effects, and mechanisms of change, as well as its effectiveness and dissemination. CT is a well-established treatment with acute effects on par with those of medication. Unlike medication, CT appears to have effects that endure after treatment ends. Although definitively establishing CT’s mechanism of action is difficult, the available evidence is consistent with the possibility that CT achieves its effects partly through cognitive change. Despite potential challenges in generalizing research findings on CT into clinical practice, initial evidence of the effectiveness of CT has been promising. Finally, we discuss efforts to disseminate CT, along with our thoughts on future research directions.","['Depression (economics)', 'Cognition', 'Psychology', 'Psychotherapist', 'Clinical psychology', 'Psychiatry', 'Economics', 'Macroeconomics']","cognitive therapy, ct, depression, therapeutic effects, ct, acute effects, cognitive change"
Paper_01418,Tumor Angiogenesis: Therapeutic Implications,"['Louis M. Sherwood', 'Edith E. Parris', 'Judah Folkman']",1971,New England Journal of Medicine,Journal,,1182-1186,285,21,10.1056/nejm197111182852108,"THE growth of solid neoplasms is always accompanied by neovascularization. This new capillary growth is even more vigorous and continuous than a similar outgrowth of capillary sprouts observed in fresh wounds or in inflammation.1 Many workers have described the association between growing solid malignant tumors and new vessel growth.2 3 4 5 6 However, it has not been appreciated until the past few years that the population of tumor cells and the population of capillary endothelial cells within a neoplasm may constitute a highly integrated ecosystem. In this ecosystem the mitotic index of the two cell populations may depend upon each other. Tumor cells . . .","['Neovascularization', 'Angiogenesis', 'Medicine', 'Population', 'Mitotic index', 'Inflammation', 'Mitosis', 'Cancer research', 'Pathology', 'Immunology', 'Cell biology', 'Biology', 'Environmental health']","solid neoplasms, neovascularization, capillary sprouts, solid malignant tumors, tumor cells, capillary endothelial cells, neo, ##as, mitotic index"
Paper_01419,The Power of Feedback,"['John Hattie', 'Helen Timperley']",2007,Review of Educational Research,Journal,,81-112,77,1,10.3102/003465430298487,"Feedback is one of the most powerful influences on learning and achievement, but this impact can be either positive or negative. Its power is frequently mentioned in articles about learning and teaching, but surprisingly few recent studies have systematically investigated its meaning. This article provides a conceptual analysis of feedback and reviews the evidence related to its impact on learning and achievement. This evidence shows that although feedback is among the major influences, the type of feedback and the way it is given can be differentially effective. A model of feedback is then proposed that identifies the particular properties and circumstances that make it effective, and some typically thorny issues are discussed, including the timing of feedback and the effects of positive and negative feedback. Finally, this analysis is used to suggest ways in which feedback can be used to enhance its effectiveness in classrooms.","['Negative feedback', 'Meaning (existential)', 'Psychology', 'Power (physics)', 'Computer science', 'Positive feedback', 'Cognitive psychology', 'Engineering', 'Physics', 'Quantum mechanics', 'Voltage', 'Electrical engineering', 'Psychotherapist']","feedback, achievement, learning, teaching, feedback, achievement, feedback, feedback, feedback"
Paper_01420,Introduction to Information Retrieval,"['Christopher D. Manning', 'Prabhakar Raghavan', 'Hinrich Schütze']",2008,Unknown,Unknown,,,,,10.1017/cbo9780511809071,"Class-tested and coherent, this textbook teaches classical and web information retrieval, including web search and the related areas of text classification and text clustering from basic concepts. It gives an up-to-date treatment of all aspects of the design and implementation of systems for gathering, indexing, and searching documents; methods for evaluating systems; and an introduction to the use of machine learning methods on text collections. All the important ideas are explained using examples and figures, making it perfect for introductory courses in information retrieval for advanced undergraduates and graduate students in computer science. Based on feedback from extensive classroom experience, the book has been carefully structured in order to make teaching more natural and effective. Slides and additional exercises (with solutions for lecturers) are also available through the book's supporting website to help course instructors prepare their lectures.","['Computer science', 'Search engine indexing', 'Class (philosophy)', 'Information retrieval', 'Cluster analysis', 'World Wide Web', 'Graduate students', 'Multimedia', 'Artificial intelligence', 'Psychology', 'Pedagogy']","web information retrieval, web search, text classification, text clustering, machine learning methods, text collections, information retrieval, graduate students, computer science"
Paper_01421,Fully Convolutional Networks for Semantic Segmentation,"['Evan Shelhamer', 'Jonathan Long', 'Trevor Darrell']",2016,IEEE Transactions on Pattern Analysis and Machine Intelligence,Journal,,640-651,39,4,10.1109/tpami.2016.2572683,"Convolutional networks are powerful visual models that yield hierarchies of features. We show that convolutional networks by themselves, trained end-to-end, pixels-to-pixels, improve on the previous best result in semantic segmentation. Our key insight is to build ""fully convolutional"" networks that take input of arbitrary size and produce correspondingly-sized output with efficient inference and learning. We define and detail the space of fully convolutional networks, explain their application to spatially dense prediction tasks, and draw connections to prior models. We adapt contemporary classification networks (AlexNet, the VGG net, and GoogLeNet) into fully convolutional networks and transfer their learned representations by fine-tuning to the segmentation task. We then define a skip architecture that combines semantic information from a deep, coarse layer with appearance information from a shallow, fine layer to produce accurate and detailed segmentations. Our fully convolutional networks achieve improved segmentation of PASCAL VOC (30% relative improvement to 67.2% mean IU on 2012), NYUDv2, SIFT Flow, and PASCAL-Context, while inference takes one tenth of a second for a typical image.","['Computer science', 'Artificial intelligence', 'Segmentation', 'Convolutional neural network', 'Pascal (unit)', 'Pattern recognition (psychology)', 'Inference', 'Pixel', 'Deep learning', 'Programming language']","convolutional networks, visual models, convolutional networks, semantic segmentation, convolutional networks, spatially dense prediction tasks, classification networks, alexnet, vgg net, googlenet, ##volutional networks, skip architecture, semantic information, appearance, convolution, pascal voc, nyudv2, sift flow"
Paper_01423,The Relational View: Cooperative Strategy and Sources of Interorganizational Competitive Advantage,"['Jeffrey H. Dyer', 'Harbir Singh']",1998,Academy of Management Review,Journal,,660-679,23,4,10.5465/amr.1998.1255632,"In this article we offer a view that suggests that a firm's critical resources may span firm boundaries and may be embedded in interfirm resources and routines. We argue that an increasingly important unit of analysis for understanding competitive advantage is the relationship between firms and identify four potential sources of interorganizational competitive advantage: (1) relation-specific assets, (2) knowledge-sharing routines, (3) complementary resources/capabilities, and (4) effective governance. We examine each of these potential sources of rent in detail, identifying key subprocesses, and also discuss the isolating mechanisms that serve to preserve relational rents. Finally, we discuss how the relational view may offer normative prescriptions for firm-level strategies that contradict the prescriptions offered by those with a resource-based view or industry structure view.","['Competitive advantage', 'Economic rent', 'Resource-based view', 'Business', 'Relational view', 'Industrial organization', 'Relation (database)', 'Resource (disambiguation)', 'Knowledge management', 'Normative', 'Corporate governance', 'Marketing', 'Computer science', 'Microeconomics', 'Economics', 'Computer network', 'Philosophy', 'Epistemology', 'Finance', 'Database']","critical resources, firm boundaries, competitive advantage, inter, ##zational competitive advantage, effective governance, ##lating mechanisms, relational rents, relational view, industry structure"
Paper_01424,The NumPy Array: A Structure for Efficient Numerical Computation,"['Stéfan van der Walt', 'Steven C. Colbert', 'Gaël Varoquaux']",2011,Computing in Science & Engineering,Journal,,22-30,13,2,10.1109/mcse.2011.37,"In the Python world, NumPy arrays are the standard representation for numerical data. Here, we show how these arrays enable efficient implementation of numerical computations in a high-level language. Overall, three techniques are applied to improve performance: vectorizing calculations, avoiding copying data in memory, and minimizing operation counts. We first present the NumPy array structure, then show how to use it for efficient computation, and finally how to share array data with other libraries.","['Python (programming language)', 'Computation', 'Copying', 'Computer science', 'Data structure', 'Computational science', 'Parallel computing', 'Array data structure', 'Algorithm', 'Programming language', 'Political science', 'Law']","numpy arrays, numerical data, numerical computations, vectorizing calculations, operation counts, numpy array structure, [PAD], [PAD], [PAD] [PAD] [PAD] [PAD] [PAD], [PAD] [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD]"
Paper_01426,Qualitative research practice: a guide for social science students and researchers,"['Jane Ritchie', 'Jane Lewis', 'Carol McNaughton Nicholls', 'Rachel Ormston']",2003,Choice Reviews Online,Journal,,41-1319,41,03,10.5860/choice.41-1319,"The Foundations of Qualitative Research - Rachel Ormston, Liz Spencer, Matt Barnard, Dawn Snape The Applications of Qualitative Methods to Social Research - Jane Ritchie and Rachel Ormston Design Issues - Jane Lewis and Carol McNaughton Nicholls Ethics of Qualitative Research - Stephen Webster, Jane Lewis and Ashley Brown Designing and Selecting Samples - Jane Ritchie, Jane Lewis, Gilliam Elam, Rosalind Tennant and Nilufer Rahim Designing Fieldwork - Sue Arthur, Martin Mitchell, Jane Lewis and Carol McNaughton Nicholls In-depth Interviews - Alice Yeo, Robin Legard, Jill Keegan, Kit Ward, Carol McNaughton Nicholls and Jane Lewis Focus Groups - Helen Finch, Jane Lewis, and Caroline Turley Observation - Carol McNaughton Nicholls, Lisa Mills and Mehul Kotecha Analysis: Principles and Processes - Liz Spencer, Jane Ritchie, Rachel Ormston, William O'Connor and Matt Barnard Traditions and approaches Analysis in practice - Liz Spencer, Jane Ritchie, William O'Connor, Gareth Morrell and Rachel Ormston Generalisability Writing up qualitative Research - Clarissa White, Kandy Woodfield, Jane Ritchie and Rachel Ormston","['Qualitative research', 'Sociology', 'Engineering ethics', 'Social science', 'Engineering']","qualitative research, qualitative methods, social research, qualitative research, approaches, general, qualitative research"
Paper_01427,<i>Planck</i>2018 results,"['N. Aghanim', 'Y. Akrami', 'M. Ashdown', 'J. Aumont', 'C. Baccigalupi', 'M. Ballardini', 'A. J. Banday', 'R. B. Barreiro', 'N. Bartolo', 'S. Basak', 'Richard A. Battye', 'K. Benabed', 'J.-P. Bernard', 'M. Bersanelli', 'P. Bielewicz', 'J. J. Bock', 'J. R. Bond', 'J. Borrill', 'F. R. Bouchet', 'F. Boulanger', 'M. Bucher', 'C. Burigana', 'R. C. Butler', 'E. Calabrese', 'J.-F. Cardoso', 'Julien Carron', 'A. Challinor', 'H. C. Chiang', 'Jens Chluba', 'L. P. L. Colombo', 'C. Combet', 'D. Contreras', 'B. P. Crill', 'F. Cuttaia', 'P. de Bernardis', 'G. de Zotti', 'G. de Zotti', 'J.-M. Delouis', 'Eleonora Di Valentino', 'J. M. Diego', 'J. M. Diego', 'M. Douspis', 'A. Ducout', 'X. Dupac', 'S. Dusini', 'G. Efstathiou', 'F. Elsner', 'T. A. Enßlin', 'H. K. Eriksen', 'Y. Fantaye', 'M. Farhang', 'J. Fergusson', 'R. Fernández-Cobos', 'F. Finelli⋆', 'F. Forastieri', 'M. Frailis', 'A. A. Fraisse', 'E. Franceschi', 'A. Frolov', 'S. Galeotta', 'S. Galli', 'K. Ganga', 'R. T. Génova-Santos', 'M. Gerbino', 'T. Ghosh', 'J. González-Nuevo', 'K. M. Górski', 'S. Gratton', 'A. Gruppuso', 'J. E. Gudmundsson', 'J. Hamann', 'Will Handley', 'F. K. Hansen', 'D. Herranz', 'S. R. Hildebrandt', 'E. Hivon', 'Zhiqi Huang', 'A. H. Jaffe', 'W. C. Jones', 'A. Karakci', 'E. Keihänen', 'R. Keskitalo', 'K. Kiiveri', 'J. Kim', 'T. S. Kisner', 'L. Knox', 'N. Krachmalnicoff', 'M. Kunz', 'H. Kurki‐Suonio', 'G. Lagache', 'J.-M. Lamarre', 'A. Lasenby', 'M. Lattanzi', 'C. R. Lawrence', 'M. Le Jeune', 'Pablo Lemos', 'J. Lesgourgues', 'F. Levrier', 'Antony Lewis', 'M. Liguori']",2020,Astronomy and Astrophysics,Journal,,A6-A6,641,,10.1051/0004-6361/201833910,"We present cosmological parameter results from the final full-mission Planck measurements of the CMB anisotropies. We find good consistency with the standard spatially-flat 6-parameter $\Lambda$CDM cosmology having a power-law spectrum of adiabatic scalar perturbations (denoted ""base $\Lambda$CDM"" in this paper), from polarization, temperature, and lensing, separately and in combination. A combined analysis gives dark matter density $\Omega_c h^2 = 0.120\pm 0.001$, baryon density $\Omega_b h^2 = 0.0224\pm 0.0001$, scalar spectral index $n_s = 0.965\pm 0.004$, and optical depth $\tau = 0.054\pm 0.007$ (in this abstract we quote $68\,\%$ confidence regions on measured parameters and $95\,\%$ on upper limits). The angular acoustic scale is measured to $0.03\,\%$ precision, with $100\theta_*=1.0411\pm 0.0003$. These results are only weakly dependent on the cosmological model and remain stable, with somewhat increased errors, in many commonly considered extensions. Assuming the base-$\Lambda$CDM cosmology, the inferred late-Universe parameters are: Hubble constant $H_0 = (67.4\pm 0.5)$km/s/Mpc; matter density parameter $\Omega_m = 0.315\pm 0.007$; and matter fluctuation amplitude $\sigma_8 = 0.811\pm 0.006$. We find no compelling evidence for extensions to the base-$\Lambda$CDM model. Combining with BAO we constrain the effective extra relativistic degrees of freedom to be $N_{\rm eff} = 2.99\pm 0.17$, and the neutrino mass is tightly constrained to $\sum m_\nu< 0.12$eV. The CMB spectra continue to prefer higher lensing amplitudes than predicted in base -$\Lambda$CDM at over $2\,\sigma$, which pulls some parameters that affect the lensing amplitude away from the base-$\Lambda$CDM model; however, this is not supported by the lensing reconstruction or (in models that also change the background geometry) BAO data. (Abridged)","['Physics', 'Cosmic microwave background', 'Spectral index', 'Omega', ""Hubble's law"", 'Planck', 'Spectral density', 'Cosmology', 'Matter power spectrum', 'Astrophysics', 'Lambda', 'Cold dark matter', 'Dark energy', 'Baryon acoustic oscillations', 'Particle physics', 'Anisotropy', 'Quantum mechanics', 'Spectral line', 'Statistics', 'Mathematics']","cosmological parameter, cmb anisotropies, adiabatic scalar perturbations, lens, dark matter density, baryon density, scalar spectral index, optical depth, angular acoustic scale, hubble constant, matter density, matter fluctuation amplitude, ##ivistic degrees of freedom, neutrino mass, cmb, lensing amplitudes, lensing amplitude"
Paper_01428,Toward the next generation of recommender systems: a survey of the state-of-the-art and possible extensions,"['Gediminas Adomavičius', 'Alexander Tuzhilin']",2005,IEEE Transactions on Knowledge and Data Engineering,Journal,,734-749,17,6,10.1109/tkde.2005.99,"This paper presents an overview of the field of recommender systems and describes the current generation of recommendation methods that are usually classified into the following three main categories: content-based, collaborative, and hybrid recommendation approaches. This paper also describes various limitations of current recommendation methods and discusses possible extensions that can improve recommendation capabilities and make recommender systems applicable to an even broader range of applications. These extensions include, among others, an improvement of understanding of users and items, incorporation of the contextual information into the recommendation process, support for multicriteria ratings, and a provision of more flexible and less intrusive types of recommendations.","['Recommender system', 'Computer science', 'Field (mathematics)', 'Process (computing)', 'Collaborative filtering', 'Range (aeronautics)', 'Information retrieval', 'Data science', 'Materials science', 'Mathematics', 'Pure mathematics', 'Composite material', 'Operating system']","recommender systems, recommendation methods, hybrid recommendation approaches, recommendation, recommender systems, contextual information, multicriteria ratings, [PAD] [PAD], [PAD], [PAD] [PAD], [PAD], [PAD] [PAD], [PAD], [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD], [PAD], [PAD], [PAD] [PAD] [PAD] [PAD] [PAD]"
Paper_01432,A modified particle swarm optimizer,"['Yibing Shi', 'R.C. Eberhart']",2002,Unknown,Unknown,,,,,10.1109/icec.1998.699146,"Evolutionary computation techniques, genetic algorithms, evolutionary strategies and genetic programming are motivated by the evolution of nature. A population of individuals, which encode the problem solutions are manipulated according to the rule of survival of the fittest through ""genetic"" operations, such as mutation, crossover and reproduction. A best solution is evolved through the generations. In contrast to evolutionary computation techniques, Eberhart and Kennedy developed a different algorithm through simulating social behavior (R.C. Eberhart et al., 1996; R.C. Eberhart and J. Kennedy, 1996; J. Kennedy and R.C. Eberhart, 1995; J. Kennedy, 1997). As in other algorithms, a population of individuals exists. This algorithm is called particle swarm optimization (PSO) since it resembles a school of flying birds. In a particle swarm optimizer, instead of using genetic operators, these individuals are ""evolved"" by cooperation and competition among the individuals themselves through generations. Each particle adjusts its flying according to its own flying experience and its companions' flying experience. We introduce a new parameter, called inertia weight, into the original particle swarm optimizer. Simulations have been done to illustrate the significant and effective impact of this new parameter on the particle swarm optimizer.","['Particle swarm optimization', 'Evolutionary computation', 'Crossover', 'Mathematical optimization', 'Population', 'Computer science', 'Mutation', 'Evolutionary algorithm', 'Computation', 'Genetic algorithm', 'Survival of the fittest', 'Mathematics', 'Algorithm', 'Artificial intelligence', 'Biology', 'Genetics', 'Demography', 'Sociology', 'Gene']","evolutionary computation techniques, genetic algorithms, evolutionary strategies, genetic programming, mutation, evolutionary computation, social behavior, particle swarm optimization, flying birds, particle swarm optimizer, genetic operators, inertia weight, particle swarm optimizer, particle swarm"
Paper_01433,The vascular plants collection (P) at the Herbarium of the Muséum national d'Histoire Naturelle (MNHN - Paris),['MNHN'],2017,Unknown,Unknown,,,,,10.15468/nc6rxy,"The French National Herbarium, estimated at 8 million
		preserved specimens from around the world,
		but particularly in France, Francophone Africa, New Caledonia,
		Madagascar, Southeast Asia, in French Guiana .
		It also has important collections in light of the history of botany:
		Tournefort, Jussieu, Lamarck, Adanson, and those of famous travelers
		as Bonpland, Michaud, Saint-Hilaire, Richard, D'Orbigny etc.
		The designation at CITES is FR 75A. It publishes Adansonia, a botanical
		periodical, and journals on
		the flora of New Caledonia, Madagascar and Comores, Cambodia, Laos and
		Vietnam, Cameroon, and Gabon.","['Herbarium', 'Flora (microbiology)', 'Geography', 'CITES', 'Archaeology', 'Ethnology', 'Forestry', 'Botany', 'Ecology', 'Biology', 'History', 'Genetics', 'Bacteria']",adanson
Paper_01434,Restoring the Density-Gradient Expansion for Exchange in Solids and Surfaces,"['John P. Perdew', 'Adrienn Ruzsinszky', 'Gábor I. Csonka', 'Oleg A. Vydrov', 'Gustavo E. Scuseria', 'Lucian A. Constantin', 'Xiaolan Zhou', 'Kieron Burke']",2008,Physical Review Letters,Journal,,,100,13,10.1103/physrevlett.100.136406,Popular modern generalized gradient approximations are biased toward the description of free-atom energies. Restoration of the first-principles gradient expansion for exchange over a wide range of density gradients eliminates this bias. We introduce a revised Perdew-Burke-Ernzerhof generalized gradient approximation that improves equilibrium properties of densely packed solids and their surfaces.,"['Range (aeronautics)', 'Density gradient', 'Concentration gradient', 'Atom (system on chip)', 'Physics', 'Statistical physics', 'Materials science', 'Quantum mechanics', 'Chemistry', 'Computer science', 'Environmental chemistry', 'Composite material', 'Embedded system']","generalized gradient approximations, density gradients, generalized gradient approximation, equilibrium properties, densely packed solids"
Paper_01435,"Conceptualizing, Measuring, and Managing Customer-Based Brand Equity",['Kevin Lane Keller'],1993,Journal of Marketing,Journal,,1-1,57,1,10.2307/1252054,"The author presents a conceptual model of brand equity from the perspective of the individual consumer. Customer-based brand equity is defined as the differential effect of brand knowledge on consumer response to the marketing of the brand. A brand is said to have positive (negative) customer-based brand equity when consumers react more (less) favorably to an element of the marketing mix for the brand than they do to the same marketing mix element when it is attributed to a fictitiously named or unnamed version of the product or service. Brand knowledge is conceptualized according to an associative network memory model in terms of two components, brand awareness and brand image (i.e., a set of brand associations). Customer-based brand equity occurs when the consumer is familiar with the brand and holds some favorable, strong, and unique brand associations in memory. Issues in building, measuring, and managing customer-based brand equity are discussed, as well as areas for future research.","['Brand equity', 'Brand management', 'Brand awareness', 'Business', 'Marketing', 'Brand extension', 'Advertising']","brand equity, brand knowledge, brand knowledge, associative network memory model, brand awareness, brand image, brand associations"
Paper_01436,Chord,"['Ion Stoica', 'Robert Morris', 'David R. Karger', 'M. Frans Kaashoek', 'Hari Balakrishnan']",2001,Unknown,Unknown,,149-160,,,10.1145/383059.383071,"A fundamental problem that confronts peer-to-peer applications is to efficiently locate the node that stores a particular data item. This paper presents Chord, a distributed lookup protocol that addresses this problem. Chord provides support for just one operation: given a key, it maps the key onto a node. Data location can be easily implemented on top of Chord by associating a key with each data item, and storing the key/data item pair at the node to which the key maps. Chord adapts efficiently as nodes join and leave the system, and can answer queries even if the system is continuously changing. Results from theoretical analysis, simulations, and experiments show that Chord is scalable, with communication cost and the state maintained by each node scaling logarithmically with the number of Chord nodes.","['Chord (peer-to-peer)', 'Computer science', 'Scalability', 'Pastry', 'Key (lock)', 'Distributed hash table', 'Theoretical computer science', 'Distributed computing', 'Node (physics)', 'Computer network', 'Peer-to-peer', 'Engineering', 'Database', 'Operating system', 'Structural engineering']","chord, distributed lookup protocol, chord, chord, chord, chord, communication"
Paper_01437,"Graphene and Graphene Oxide: Synthesis, Properties, and Applications","['Yanwu Zhu', 'Shanthi Murali', 'Weiwei Cai', 'Xuesong Li', 'Ji Won Suk', 'Jeffrey R. Potts', 'Rodney S. Ruoff']",2010,Advanced Materials,Journal,,3906-3924,22,35,10.1002/adma.201001068,"Abstract There is intense interest in graphene in fields such as physics, chemistry, and materials science, among others. Interest in graphene's exceptional physical properties, chemical tunability, and potential for applications has generated thousands of publications and an accelerating pace of research, making review of such research timely. Here is an overview of the synthesis, properties, and applications of graphene and related materials (primarily, graphite oxide and its colloidal suspensions and materials made from them), from a materials science perspective.","['Graphene', 'Materials science', 'Nanotechnology', 'Oxide', 'Graphite', 'Pace', 'Graphene oxide paper', 'Graphite oxide', 'Engineering physics', 'Physics', 'Composite material', 'Metallurgy', 'Astronomy']","graphene, materials science, graphene, physical properties, chemical tunability, graphene, graphite oxide, colloidal suspensions, materials science, [PAD], [PAD]"
Paper_01441,The control of the false discovery rate in multiple testing under dependency,"['Yoav Benjamini', 'Daniel Yekutieli']",2001,The Annals of Statistics,Journal,,,29,4,10.1214/aos/1013699998,"Benjamini and Hochberg suggest that the false discovery rate may be the appropriate error rate to control in many applied multiple testing problems. A simple procedure was given there as an FDR controlling procedure for independent test statistics and was shown to be much more powerful than comparable procedures which control the traditional familywise error rate. We prove that this same procedure also controls the false discovery rate when the test statistics have positive regression dependency on each of the test statistics corresponding to the true null hypotheses. This condition for positive dependency is general enough to cover many problems of practical interest, including the comparisons of many treatments with a single control, multivariate normal test statistics with positive correlation matrix and multivariate $t$. Furthermore, the test statistics may be discrete, and the tested hypotheses composite without posing special difficulties. For all other forms of dependency, a simple conservative modification of the procedure controls the false discovery rate. Thus the range of problems for which a procedure with proven FDR control can be offered is greatly increased.","['False discovery rate', 'Multiple comparisons problem', 'Statistics', 'Mathematics', 'Dependency (UML)', 'Statistical hypothesis testing', 'Multivariate statistics', 'Null hypothesis', 'Type I and type II errors', 'Simple (philosophy)', 'Computer science', 'Artificial intelligence', 'Biochemistry', 'Chemistry', 'Philosophy', 'Epistemology', 'Gene']","false discovery rate, multiple testing problems, fdr controlling procedure, independent test statistics, familywise error rate, false discovery rate, positive dependency, multivariate normal test statistics, positive correlation matrix, multivariate, false discovery"
Paper_01442,World Map of the Köppen-Geiger climate classification updated,"['M. Kottek', 'Jürgen Grieser', 'Christoph Beck', 'B. Rudolf', 'Franz Rubel']",2006,Meteorologische Zeitschrift,Journal,,259-263,15,3,10.1127/0941-2948/2006/0130,"The most frequently used climate classification map is that of Wladimir Köppen, presented in its latest version 1961 by Rudolf Geiger.A huge number of climate studies and subsequent publications adopted this or a former release of the Köppen-Geiger map.While the climate classification concept has been widely applied to a broad range of topics in climate and climate change research as well as in physical geography, hydrology, agriculture, biology and educational aspects, a well-documented update of the world climate classification map is still missing.Based on recent data sets from the Climatic Research Unit (CRU) of the University of East Anglia and the Global Precipitation Climatology Centre (GPCC) at the German Weather Service, we present here a new digital Köppen-Geiger world map on climate classification, valid for the second half of the 20 th century.","['Geiger counter', 'Climate zones', 'Meteorology', 'Environmental science', 'Remote sensing', 'Climatology', 'Geography', 'Geology', 'Physics', 'Optics']","climate classification, climatic research unit, global precipitation climatology centre, german, climate classification"
Paper_01443,"A program for annotating and predicting the effects of single nucleotide polymorphisms, SnpEff","['Pablo Cingolani', 'Adrian E. Platts', 'Le Lily Wang', 'Melissa Coon', 'Tung Thanh Nguyen', 'Luan Wang', 'Susan Land', 'Xiangyi Lu', 'Douglas M. Ruden']",2012,Fly,Journal,,80-92,6,2,10.4161/fly.19695,"We describe a new computer program, SnpEff, for rapidly categorizing the effects of variants in genome sequences. Once a genome is sequenced, SnpEff annotates variants based on their genomic locations and predicts coding effects. Annotated genomic locations include intronic, untranslated region, upstream, downstream, splice site, or intergenic regions. Coding effects such as synonymous or non-synonymous amino acid replacement, start codon gains or losses, stop codon gains or losses, or frame shifts can be predicted. Here the use of SnpEff is illustrated by annotating ~356,660 candidate SNPs in ~117 Mb unique sequences, representing a substitution rate of ~1/305 nucleotides, between the Drosophila melanogaster w(1118); iso-2; iso-3 strain and the reference y(1); cn(1) bw(1) sp(1) strain. We show that ~15,842 SNPs are synonymous and ~4,467 SNPs are non-synonymous (N/S ~0.28). The remaining SNPs are in other categories, such as stop codon gains (38 SNPs), stop codon losses (8 SNPs), and start codon gains (297 SNPs) in the 5'UTR. We found, as expected, that the SNP frequency is proportional to the recombination frequency (i.e., highest in the middle of chromosome arms). We also found that start-gain or stop-lost SNPs in Drosophila melanogaster often result in additions of N-terminal or C-terminal amino acids that are conserved in other Drosophila species. It appears that the 5' and 3' UTRs are reservoirs for genetic variations that changes the termini of proteins during evolution of the Drosophila genus. As genome sequencing is becoming inexpensive and routine, SnpEff enables rapid analyses of whole-genome sequencing data to be performed by an individual laboratory.","['Single-nucleotide polymorphism', 'Genetics', 'Biology', 'Computational biology', 'Computer science', 'Genotype', 'Gene']","computer program, snpeff, snpef, coding, frame shifts, snpeff, substitution, stop codon gains, stop codon losses, rec, ##bina, snpeff"
Paper_01444,From molecules to solids with the DMol3 approach,['B. Delley'],2000,The Journal of Chemical Physics,Journal,,7756-7764,113,18,10.1063/1.1316015,"Recent extensions of the DMol3 local orbital density functional method for band structure calculations of insulating and metallic solids are described. Furthermore the method for calculating semilocal pseudopotential matrix elements and basis functions are detailed together with other unpublished parts of the methodology pertaining to gradient functionals and local orbital basis sets. The method is applied to calculations of the enthalpy of formation of a set of molecules and solids. We find that the present numerical localized basis sets yield improved results as compared to previous results for the same functionals. Enthalpies for the formation of H, N, O, F, Cl, and C, Si, S atoms from the thermodynamic reference states are calculated at the same level of theory. It is found that the performance in predicting molecular enthalpies of formation is markedly improved for the Perdew–Burke–Ernzerhof [Phys. Rev. Lett. 77, 3865 (1996)] functional.","['Pseudopotential', 'Basis (linear algebra)', 'Basis set', 'Standard enthalpy of formation', 'Molecule', 'Density functional theory', 'Matrix (chemical analysis)', 'Thermodynamics', 'Enthalpy', 'Chemistry', 'Yield (engineering)', 'Standard enthalpy change of formation', 'Physics', 'Computational chemistry', 'Atomic physics', 'Mathematics', 'Quantum mechanics', 'Geometry', 'Chromatography']","band structure calculations, metallic solids, semilocal pseudopotential matrix elements, basis functions, gradient functionals, local orbital basis sets, enthalpy, numerical localized basis sets, thermod, ##mic reference states, [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD] [PAD], [PAD]"
Paper_01447,A Simplest Systematics for the Organization of Turn-Taking for Conversation,"['Harvey Sacks', 'Emanuel A. Schegloff', 'Gail Jefferson']",1974,Language,Journal,,696-696,50,4,10.2307/412243,"The organization of taking turns to talk is fundament as to other speech-exchange systems.A model for the t conversation is proposed, and is examined for its compati observable facts about conversation.The results of the at least, a model for turn-taking in conversation will be c aged, party-administered, interactionally controlled, and Several general consequences of the model are explicated with turn-taking organizations for other speech-exchange 1. INTRODUCTION.Turn-taking is used for the orde allocating political office, for regulating traffic at inte at business establishments, and for talking in intervi monies, conversations etc.-these last being membe refer to as 'speech exchange systems'.It is obvious organization, one whose instances are implicated in a For socially organized activities, the presence of with turns for something being valued-and with mea affect their relative distribution, as in economies.An sociology of a turn-organized activity will want to de the turn-taking organization device, and how it affec for the activities on which it operates.For the investigator of turn-taking systems per se, i taking systems can be workably built in various organize sorts of activities that are quite different fro ular interest to see how operating turn-taking s adapting to properties of the sorts of activities in investigator interested in some sort of activity that system will want to determine how the sort of activit constrained by, the particular form of turn-taking sThe subject of this report is the turn-taking syst foregoing are among the questions to which it will b that the organization of taking turns at talk is one t in conversation, and have located a range of interesti sort of organization.1But no account of the syste","['Conversation', 'Turn-taking', 'Turn (biochemistry)', 'Systematics', 'Psychology', 'Linguistics', 'Sociology', 'Communication', 'Philosophy', 'Chemistry', 'Biology', 'Taxonomy (biology)', 'Zoology', 'Biochemistry']",speech exchange systems
Paper_01448,Object Detection with Discriminatively Trained Part-Based Models,"['Pedro F. Felzenszwalb', 'Ross Girshick', 'David McAllester', 'Deva Ramanan']",2009,IEEE Transactions on Pattern Analysis and Machine Intelligence,Journal,,1627-1645,32,9,10.1109/tpami.2009.167,"We describe an object detection system based on mixtures of multiscale deformable part models. Our system is able to represent highly variable object classes and achieves state-of-the-art results in the PASCAL object detection challenges. While deformable part models have become quite popular, their value had not been demonstrated on difficult benchmarks such as the PASCAL data sets. Our system relies on new methods for discriminative training with partially labeled data. We combine a margin-sensitive approach for data-mining hard negative examples with a formalism we call latent SVM. A latent SVM is a reformulation of MI--SVM in terms of latent variables. A latent SVM is semiconvex, and the training problem becomes convex once latent information is specified for the positive examples. This leads to an iterative training algorithm that alternates between fixing latent values for positive examples and optimizing the latent SVM objective function.","['Pascal (unit)', 'Artificial intelligence', 'Computer science', 'Latent variable', 'Support vector machine', 'Discriminative model', 'Pattern recognition (psychology)', 'Object detection', 'Latent variable model', 'Machine learning', 'Probabilistic latent semantic analysis', 'Training set', 'Margin (machine learning)', 'Programming language']","object detection system, multiscale deformable part models, highly, pascal object detection challenges, deformable part models, pascal data sets, ##tive training, latent svm, latent svm, latent variables, latent sv, ##con, iterative training algorithm, latent sv, [PAD], [PAD] [PAD]"
Paper_01451,The Logic of Practice,['Pierre Bourdieu'],1990,Stanford University Press eBooks,Unknown,,,,,10.1515/9781503621749,"Our usual representations of the opposition between the ""civilized"" and the ""primitive"" derive from willfully ignoring the relationship of distance our social science sets up between the observer and the observed. In fact, the author argues, the relationship between the anthropologist and his object of study is a particular instance of the relationship between knowing and doing, interpreting and using, symbolic mastery and practical mastery—or between logical logic, armed with all the accumulated instruments of objectification, and the universally pre-logical logic of practice. In this, his fullest statement of a theory of practice, Bourdieu both sets out what might be involved in incorporating one's own standpoint into an investigation and develops his understanding of the powers inherent in the second member of many oppositional pairs—that is, he explicates how the practical concerns of daily life condition the transmission and functioning of social or cultural forms. The first part of the book, ""Critique of Theoretical Reason,"" covers more general questions, such as the objectivization of the generic relationship between social scientific observers and their objects of study, the need to overcome the gulf between subjectivism and objectivism, the interplay between structure and practice (a phenomenon Bourdieu describes via his concept of the habitus), the place of the body, the manipulation of time, varieties of symbolic capital, and modes of domination. The second part of the book, ""Practical Logics,"" develops detailed case studies based on Bourdieu's ethnographic fieldwork in Algeria. These examples touch on kinship patterns, the social construction of domestic space, social categories of perception and classification, and ritualized actions and exchanges. This book develops in full detail the theoretical positions sketched in Bourdieu's Outline of a Theory of Practice. It will be especially useful to readers seeking to grasp the subtle concepts central to Bourdieu's theory, to theorists interested in his points of departure from structuralism (especially fom Lévi-Strauss), and to critics eager to understand what role his theory gives to human agency. It also reveals Bourdieu to be an anthropological theorist of considerable originality and power.","['Epistemology', 'Habitus', 'Objectivism', 'Sociology', 'Subjectivism', 'Social practice', 'Doxa', 'Kinship', 'The Symbolic', 'Statement (logic)', 'Ethnography', 'Psychology', 'Philosophy', 'Anthropology', 'Art', 'Performance art', 'Psychoanalysis', 'Art history']","social science, symbolic mastery, practical mastery, logical logic, daily life, theoretical reason, social scientific, objectivism, habitus, symbolic capital, practical logics, kinship patterns, social construction, domestic space, ritual, structural, anthropological"
Paper_01452,Integrated analysis of multimodal single-cell data,"['Yuhan Hao', 'Stephanie Hao', 'Erica Andersen‐Nissen', 'William M. Mauck', 'Shiwei Zheng', 'Andrew Butler', 'Madeline Lee', 'Aaron J. Wilk', 'Charlotte A. Darby', 'Michael Zager', 'Paul Hoffman', 'Marlon Stoeckius', 'Efthymia Papalexi', 'Eleni P. Mimitou', 'Jaison Jain', 'Avi Srivastava', 'Tim Stuart', 'Lamar M. Fleming', 'Bertrand Z. Yeung', 'Angela J. Rogers', 'M. Juliana McElrath', 'Catherine A. Blish', 'Raphaël Gottardo', 'Peter Smibert', 'Rahul Satija']",2021,Cell,Journal,,3573-3587.e29,184,13,10.1016/j.cell.2021.04.048,"The simultaneous measurement of multiple modalities represents an exciting frontier for single-cell genomics and necessitates computational methods that can define cellular states based on multimodal data. Here, we introduce ""weighted-nearest neighbor"" analysis, an unsupervised framework to learn the relative utility of each data type in each cell, enabling an integrative analysis of multiple modalities. We apply our procedure to a CITE-seq dataset of 211,000 human peripheral blood mononuclear cells (PBMCs) with panels extending to 228 antibodies to construct a multimodal reference atlas of the circulating immune system. Multimodal analysis substantially improves our ability to resolve cell states, allowing us to identify and validate previously unreported lymphoid subpopulations. Moreover, we demonstrate how to leverage this reference to rapidly map new datasets and to interpret immune responses to vaccination and coronavirus disease 2019 (COVID-19). Our approach represents a broadly applicable strategy to analyze single-cell multimodal datasets and to look beyond the transcriptome toward a unified and multimodal definition of cellular identity.","['Leverage (statistics)', 'Biology', 'Computational biology', 'Functional genomics', 'Computer science', 'Immune system', 'Genomics', 'Artificial intelligence', 'Bioinformatics', 'Genome', 'Immunology', 'Genetics', 'Gene']","multimodal data, human peripheral blood mononuclear cells, ##bm, multi, ##dal reference atlas, circulating immune system, multimodal analysis, vaccination, coronavirus disease, cellular identity, [PAD]"
Paper_01453,Organizational Culture and Leadership,"['William G. Tierney', 'Edgar H. Schein']",1986,Academy of Management Review,Journal,,677-677,11,3,10.2307/258322,"The article presents a review of the book “Organizational Culture and Leadership,” by Edgar H. Schein.","['Organizational culture', 'Management', 'Sociology', 'Public relations', 'Political science', 'Economics']","organizational culture, leadership"
Paper_01455,XGBoost,"['Tianqi Chen', 'Carlos Guestrin']",2016,Unknown,Unknown,,785-794,,,10.1145/2939672.2939785,"Tree boosting is a highly effective and widely used machine learning method. In this paper, we describe a scalable end-to-end tree boosting system called XGBoost, which is used widely by data scientists to achieve state-of-the-art results on many machine learning challenges. We propose a novel sparsity-aware algorithm for sparse data and weighted quantile sketch for approximate tree learning. More importantly, we provide insights on cache access patterns, data compression and sharding to build a scalable tree boosting system. By combining these insights, XGBoost scales beyond billions of examples using far fewer resources than existing systems.","['Boosting (machine learning)', 'Computer science', 'Scalability', 'Machine learning', 'Sketch', 'Artificial intelligence', 'Tree (set theory)', 'Cache', 'Data mining', 'Database', 'Parallel computing', 'Algorithm', 'Mathematical analysis', 'Mathematics']","tree boosting, machine learning, xgboost, data scientists, machine learning, sparse data, weighted quantile sketch, approximate tree learning, cache access patterns, data compression, sha, ##ng, scalable tree boosting, xgboost"
Paper_01456,Köppen's climate classification map for Brazil,"['Clayton Alcarde Álvares', 'José Luiz Stape', 'Paulo César Sentelhas', 'José Leonardo de Moraes Gonçalves', 'Gerd Sparovek']",2013,Meteorologische Zeitschrift,Journal,,711-728,22,6,10.1127/0941-2948/2013/0507,"Koppen's climate classification remains the most widely used system by geographical and climatological societies across the world, with well recognized simple rules and climate symbol letters. In Brazil, climatology has been studied for more than 140 years, and among the many proposed methods Koppen 0 s system remains as the most utilized. Considering Koppen's climate classification importance for Brazil (geography, biology, ecology, meteorology, hydrology, agronomy, forestry and environmental sciences), we developed a geographical information system to identify Koppen's climate types based on monthly temperature and rainfall data from 2,950 weather stations. Temperature maps were spatially described using multivariate equations that took into account the geographical coordinates and altitude; and the map resolution (100 m) was similar to the digital elevation model derived from Shuttle Radar Topography Mission. Patterns of rainfall were interpolated using kriging, with the same resolution of temperature maps. The final climate map obtained for Brazil (851,487,700 ha) has a high spatial resolution (1 ha) which allows to observe the climatic variations at the landscape level. The results are presented as maps, graphs, diagrams and tables, allowing users to interpret the occurrence of climate types in Brazil. The zones and climate types are referenced to the most important mountains, plateaus and depressions, geographical landmarks, rivers and watersheds and major cities across the country making the information accessible to all levels of users. The climate map not only showed that the A, B and C zones represent approximately 81%, 5% and 14% of the country but also allowed the identification of Koppen's climates types never reported before in Brazil.","['Climatology', 'Environmental science', 'Climate zones', 'Meteorology', 'Geography', 'Cartography', 'Geology']","climate classification, climatological societies, climate symbol letters, climatology, geographical information system, rainfall, multivariate equations, geographical coordinates, digital elevation model, k, ##ging"
Paper_01457,Causality,['Judea Pearl'],2009,Unknown,Unknown,,,,,10.1017/cbo9780511803161,"Written by one of the preeminent researchers in the field, this book provides a comprehensive exposition of modern analysis of causation. It shows how causality has grown from a nebulous concept into a mathematical theory with significant applications in the fields of statistics, artificial intelligence, economics, philosophy, cognitive science, and the health and social sciences. Judea Pearl presents and unifies the probabilistic, manipulative, counterfactual, and structural approaches to causation and devises simple mathematical tools for studying the relationships between causal connections and statistical associations. Cited in more than 2,100 scientific publications, it continues to liberate scientists from the traditional molds of statistical thinking. In this revised edition, Judea Pearl elucidates thorny issues, answers readers' questions, and offers a panoramic view of recent advances in this field of research. Causality will be of interest to students and professionals in a wide variety of fields. Dr Judea Pearl has received the 2011 Rumelhart Prize for his leading research in Artificial Intelligence (AI) and systems from The Cognitive Science Society.","['Causation', 'Counterfactual thinking', 'Pearl', 'Causality (physics)', 'Counterfactual conditional', 'Exposition (narrative)', 'Field (mathematics)', 'Epistemology', 'Variety (cybernetics)', 'Probabilistic logic', 'Causal reasoning', 'Computer science', 'Cognition', 'Management science', 'Psychology', 'Data science', 'Cognitive science', 'Artificial intelligence', 'Philosophy', 'Mathematics', 'Engineering', 'Physics', 'Quantum mechanics', 'Neuroscience', 'Art', 'Theology', 'Literature', 'Pure mathematics']","causation, causality, mathematical theory, statistics, artificial intelligence, economics, philosophy, cognitive science, causation, causal connections, statistical associations, statistical thinking, causality, artificial intelligence, cognitive science, [PAD], [PAD], [PAD], [PAD], [PAD], [PAD]"
Paper_01458,Chemical Reaction Engineering,['Octave Levenspiel'],1999,Industrial & Engineering Chemistry Research,Journal,,4140-4143,38,11,10.1021/ie990488g,"ADVERTISEMENT RETURN TO ISSUEPREVCommentaryNEXTChemical Reaction EngineeringOctave LevenspielView Author Information Chemical Engineering Department Oregon State University Corvallis, Oregon 97331Cite this: Ind. Eng. Chem. Res. 1999, 38, 11, 4140–4143Publication Date (Web):September 11, 1999Publication History Published online11 September 1999Published inissue 1 November 1999https://pubs.acs.org/doi/10.1021/ie990488ghttps://doi.org/10.1021/ie990488gbrief-reportACS PublicationsCopyright © 1999 American Chemical SocietyRequest reuse permissionsArticle Views23019Altmetric-Citations1239LEARN ABOUT THESE METRICSArticle Views are the COUNTER-compliant sum of full text article downloads since November 2008 (both PDF and HTML) across all institutions and individuals. These metrics are regularly updated to reflect usage leading up to the last few days.Citations are the number of other articles citing this article, calculated by Crossref and updated daily. Find more information about Crossref citation counts.The Altmetric Attention Score is a quantitative measure of the attention that a research article has received online. Clicking on the donut icon will load a page at altmetric.com with additional details about the score and the social media presence for the given article. Find more information on the Altmetric Attention Score and how the score is calculated. Share Add toView InAdd Full Text with ReferenceAdd Description ExportRISCitationCitation and abstractCitation and referencesMore Options Share onFacebookTwitterWechatLinked InRedditEmail Other access optionsGet e-Alertsclose SUBJECTS:Kinetic modeling,Kinetics,Order,Reaction engineering,Surface reactions Get e-Alerts","['Citation', 'Computer science', 'Social media', 'Order (exchange)', 'Information retrieval', 'Library science', 'World Wide Web', 'Finance', 'Economics']","altmetric attention score, altmetric attention score, ##citation, abstract, references, kinetic modeling, kinetics, order, reaction engineering, surface reactions"
Paper_01459,Reconsidering Baron and Kenny: Myths and Truths about Mediation Analysis,"['Xinshu Zhao', 'John Lynch', 'Qimei Chen']",2010,Journal of Consumer Research,Journal,,197-206,37,2,10.1086/651257,"Journal Article Reconsidering Baron and Kenny: Myths and Truths about Mediation Analysis Get access Xinshu Zhao, Xinshu Zhao Search for other works by this author on: Oxford Academic PubMed Google Scholar John G. Lynch, Jr., John G. Lynch, Jr. Search for other works by this author on: Oxford Academic PubMed Google Scholar Qimei Chen Qimei Chen Search for other works by this author on: Oxford Academic PubMed Google Scholar Journal of Consumer Research, Volume 37, Issue 2, August 2010, Pages 197–206, https://doi.org/10.1086/651257 Published: 15 February 2010","['Mediation', 'Psychology', 'Epistemology', 'Mythology', 'Variable (mathematics)', 'Relation (database)', 'Sociology', 'Philosophy', 'Computer science', 'Social science', 'Data mining', 'Mathematics', 'Theology', 'Mathematical analysis']","mediation analysis, consumer research, [PAD], [PAD]"
Paper_01461,Amazon's Mechanical Turk,"['Michael D. Buhrmester', 'Tracy Kwang', 'Samuel D. Gosling']",2011,Perspectives on Psychological Science,Journal,,3-5,6,1,10.1177/1745691610393980,"Amazon's Mechanical Turk (MTurk) is a relatively new website that contains the major elements required to conduct research: an integrated participant compensation system; a large participant pool; and a streamlined process of study design, participant recruitment, and data collection. In this article, we describe and evaluate the potential contributions of MTurk to psychology and other social sciences. Findings indicate that (a) MTurk participants are slightly more demographically diverse than are standard Internet samples and are significantly more diverse than typical American college samples; (b) participation is affected by compensation rate and task length, but participants can still be recruited rapidly and inexpensively; (c) realistic compensation rates do not affect data quality; and (d) the data obtained are at least as reliable as those obtained via traditional methods. Overall, MTurk can be used to obtain high-quality data inexpensively and rapidly.","['Amazon rainforest', 'Compensation (psychology)', 'Data collection', 'Task (project management)', 'Affect (linguistics)', 'The Internet', 'Psychology', 'Quality (philosophy)', 'Computer science', 'Data quality', 'Data science', 'Applied psychology', 'World Wide Web', 'Social psychology', 'Statistics', 'Engineering', 'Biology', 'Operations management', 'Ecology', 'Philosophy', 'Metric (unit)', 'Mathematics', 'Systems engineering', 'Communication', 'Epistemology']","mechanical turk, mturk, integrated participant compensation system, participant pool, study design, participant recruitment, data collection, mturk, social, internet, american college samples, compensation rate, task length, compensation rates, mturk"
Paper_01462,Non-local Neural Networks,"['Xiaolong Wang', 'Ross Girshick', 'Abhinav Gupta', 'Kaiming He']",2018,Unknown,Unknown,,,,,10.1109/cvpr.2018.00813,"Both convolutional and recurrent operations are building blocks that process one local neighborhood at a time. In this paper, we present non-local operations as a generic family of building blocks for capturing long-range dependencies. Inspired by the classical non-local means method in computer vision, our non-local operation computes the response at a position as a weighted sum of the features at all positions. This building block can be plugged into many computer vision architectures. On the task of video classification, even without any bells and whistles, our non-local models can compete or outperform current competition winners on both Kinetics and Charades datasets. In static image recognition, our non-local models improve object detection/segmentation and pose estimation on the COCO suite of tasks. Code is available at https://github.com/facebookresearch/video-nonlocal-net .","['Computer science', 'Artificial neural network', 'Artificial intelligence']","convolution, recurrent operations, local neighborhood, computer vision, computer vision architecture, video classification, charades datasets, static image recognition, pose estimation, coco"
Paper_01464,"The Optical Properties of Metal Nanoparticles: The Influence of Size, Shape, and Dielectric Environment","['K. Lance Kelly', 'Eduardo A. Coronado', 'Lin Lin Zhao', 'George C. Schatz']",2002,The Journal of Physical Chemistry B,Journal,,668-677,107,3,10.1021/jp026731y,"The optical properties of metal nanoparticles have long been of interest in physical chemistry, starting with Faraday's investigations of colloidal gold in the middle 1800s. More recently, new lithographic techniques as well as improvements to classical wet chemistry methods have made it possible to synthesize noble metal nanoparticles with a wide range of sizes, shapes, and dielectric environments. In this feature article, we describe recent progress in the theory of nanoparticle optical properties, particularly methods for solving Maxwell's equations for light scattering from particles of arbitrary shape in a complex environment. Included is a description of the qualitative features of dipole and quadrupole plasmon resonances for spherical particles; a discussion of analytical and numerical methods for calculating extinction and scattering cross-sections, local fields, and other optical properties for nonspherical particles; and a survey of applications to problems of recent interest involving triangular silver particles and related shapes.","['Discrete dipole approximation', 'Nanoparticle', 'Dielectric', 'Scattering', 'Light scattering', 'Materials science', 'Extinction (optical mineralogy)', 'Quadrupole', 'Plasmon', 'Nanotechnology', 'Dipole', 'Chemical physics', 'Optics', 'Chemistry', 'Physics', 'Optoelectronics', 'Atomic physics', 'Quantum mechanics']","optical properties, metal nanoparticles, physical chemistry, colloidal gold, wet chemistry, noble metal nanoparticles, nanoparticle optical properties, light scattering, dip, quadrupole plasmon resonances, spherical particles, local fields, nonspherical particles, triangular silver particles"
Paper_01465,Consensus and Cooperation in Networked Multi-Agent Systems,"['R. Olfati-Saber', 'J.A. Fax', 'Richard M. Murray']",2007,Proceedings of the IEEE,Journal,,215-233,95,1,10.1109/jproc.2006.887293,"<para xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink""> This paper provides a theoretical framework for analysis of consensus algorithms for multi-agent networked systems with an emphasis on the role of directed information flow, robustness to changes in network topology due to link/node failures, time-delays, and performance guarantees. An overview of basic concepts of information consensus in networks and methods of convergence and performance analysis for the algorithms are provided. Our analysis framework is based on tools from matrix theory, algebraic graph theory, and control theory. We discuss the connections between consensus problems in networked dynamic systems and diverse applications including synchronization of coupled oscillators, flocking, formation control, fast consensus in small-world networks, Markov processes and gossip-based algorithms, load balancing in networks, rendezvous in space, distributed sensor fusion in sensor networks, and belief propagation. We establish direct connections between spectral and structural properties of complex networks and the speed of information diffusion of consensus algorithms. A brief introduction is provided on networked systems with nonlocal information flow that are considerably faster than distributed systems with lattice-type nearest neighbor interactions. Simulation results are presented that demonstrate the role of small-world effects on the speed of consensus algorithms and cooperative control of multivehicle formations. </para>","['Flocking (texture)', 'Computer science', 'Distributed computing', 'Rendezvous', 'Consensus algorithm', 'Consensus', 'Multi-agent system', 'Markov chain', 'Robustness (evolution)', 'Gossip', 'Network topology', 'Graph theory', 'Algebraic graph theory', 'Complex network', 'Theoretical computer science', 'Topology (electrical circuits)', 'Computer network', 'Algorithm', 'Artificial intelligence', 'Mathematics', 'Machine learning', 'Materials science', 'Aerospace engineering', 'Chemistry', 'World Wide Web', 'Engineering', 'Composite material', 'Psychology', 'Social psychology', 'Biochemistry', 'Combinatorics', 'Spacecraft', 'Gene']","consensus algorithms, directed information flow, network topology, performance, information consensus, performance analysis, matrix theory, algebraic graph theory, control theory, consensus problems, networked dynamic systems, synchronization, coupled oscillators, flocking, formation control, fast consensus, load balancing, rendezvous, distributed sensor fusion, sensor networks, belief propagation, complex, information diffusion, consensus algorithms, non, ##cal information flow, consensus algorithms, cooperative control"
Paper_01467,Positive psychology: An introduction.,"['Martin E. P. Seligman', 'Mihály Csíkszentmihályi']",2000,American Psychologist,Journal,,5-14,55,1,10.1037//0003-066x.55.1.5,"A science of positive subjective experience, positive individual traits, and positive institutions promises to improve quality of life and prevent the pathologies that arise when life is barren and meaningless. The exclusive focus on pathology that has dominated so much of our discipline results in a model of the human being lacking the positive features that make life worth living. Hope, wisdom, creativity, future mindedness, courage, spirituality, responsibility, and perseverance are ignored or explained as transformations of more authentic negative impulses. The 15 articles in this millennial issue of the American Psychologist discuss such issues as what enables happiness, the effects of autonomy and self-regulation, how optimism and hope affect health, what constitutes wisdom, and how talent and creativity come to fruition. The authors outline a framework for a science of positive psychology, point to gaps in our knowledge, and predict that the next century will see a science and profession that will come to understand and build the factors that allow individuals, communities, and societies to flourish.","['Happiness', 'Creativity', 'Optimism', 'Courage', 'Positive psychology', 'Psychology', 'Autonomy', 'Spirituality', 'Social psychology', 'Affect (linguistics)', 'Quality (philosophy)', 'Epistemology', 'Political science', 'Medicine', 'Philosophy', 'Alternative medicine', 'Communication', 'Pathology', 'Law']","positive subjective experience, positive individual traits, positive institutions, pathology, hope, wisdom, creativity, future mindedness, courage, spirituality, responsibility, perseverance, american psychologist, happiness, optimism, hope, health, wisdom, talent, creativity, positive psychology"
Paper_01468,Mussel-Inspired Surface Chemistry for Multifunctional Coatings,"['Haeshin Lee', 'Shara M. Dellatore', 'William M. Miller', 'Phillip B. Messersmith']",2007,Science,Journal,,426-430,318,5849,10.1126/science.1147241,"We report a method to form multifunctional polymer coatings through simple dip-coating of objects in an aqueous solution of dopamine. Inspired by the composition of adhesive proteins in mussels, we used dopamine self-polymerization to form thin, surface-adherent polydopamine films onto a wide range of inorganic and organic materials, including noble metals, oxides, polymers, semiconductors, and ceramics. Secondary reactions can be used to create a variety of ad-layers, including self-assembled monolayers through deposition of long-chain molecular building blocks, metal films by electroless metallization, and bioinert and bioactive surfaces via grafting of macromolecules.","['Polymer', 'Polymerization', 'Monolayer', 'Materials science', 'Aqueous solution', 'Coating', 'Noble metal', 'Adhesive', 'Nanotechnology', 'Chemical engineering', 'Deposition (geology)', 'Metal', 'Chemistry', 'Polymer chemistry', 'Layer (electronics)', 'Organic chemistry', 'Composite material', 'Metallurgy', 'Paleontology', 'Engineering', 'Sediment', 'Biology']","multifunctional polymer coatings, dopamine, adhesive proteins, mussel, noble metals, metal films, electroless metallization, bioactive surfaces, [PAD] [PAD], [PAD], [PAD] [PAD]"
Paper_01469,A simple panel unit root test in the presence of cross‐section dependence,['M. Hashem Pesaran'],2007,Journal of Applied Econometrics,Journal,,265-312,22,2,10.1002/jae.951,"A number of panel unit root tests that allow for cross-section dependence have been proposed in the literature that use orthogonalization type procedures to asymptotically eliminate the cross-dependence of the series before standard panel unit root tests are applied to the transformed series. In this paper we propose a simple alternative where the standard augmented Dickey–Fuller (ADF) regressions are augmented with the cross-section averages of lagged levels and first-differences of the individual series. New asymptotic results are obtained both for the individual cross-sectionally augmented ADF (CADF) statistics and for their simple averages. It is shown that the individual CADF statistics are asymptotically similar and do not depend on the factor loadings. The limit distribution of the average CADF statistic is shown to exist and its critical values are tabulated. Small sample properties of the proposed test are investigated by Monte Carlo experiments. The proposed test is applied to a panel of 17 OECD real exchange rate series as well as to log real earnings of households in the PSID data. Copyright © 2007 John Wiley & Sons, Ltd.","['Unit root', 'Series (stratigraphy)', 'Mathematics', 'Unit root test', 'Econometrics', 'Statistics', 'Monte Carlo method', 'Autocorrelation', 'Simple (philosophy)', 'Orthogonalization', 'Panel data', 'Cointegration', 'Null hypothesis', 'Asymptotic distribution', 'Estimator', 'Paleontology', 'Philosophy', 'Epistemology', 'Algorithm', 'Biology']","panel unit root tests, orthogonalization type procedures, lagged levels, as, factor loadings, limit distribution, monte carlo experiments, oecd real exchange rate series"
Paper_01471,Probing Single Molecules and Single Nanoparticles by Surface-Enhanced Raman Scattering,"['Shuming Nie', 'Steven R. Emory']",1997,Science,Journal,,1102-1106,275,5303,10.1126/science.275.5303.1102,"Optical detection and spectroscopy of single molecules and single nanoparticles have been achieved at room temperature with the use of surface-enhanced Raman scattering. Individual silver colloidal nanoparticles were screened from a large heterogeneous population for special size-dependent properties and were then used to amplify the spectroscopic signatures of adsorbed molecules. For single rhodamine 6G molecules adsorbed on the selected nanoparticles, the intrinsic Raman enhancement factors were on the order of 10 14 to 10 15 , much larger than the ensemble-averaged values derived from conventional measurements. This enormous enhancement leads to vibrational Raman signals that are more intense and more stable than single-molecule fluorescence.","['Raman scattering', 'Rhodamine 6G', 'Raman spectroscopy', 'Nanoparticle', 'Molecule', 'Materials science', 'Adsorption', 'Fluorescence', 'Analytical Chemistry (journal)', 'Chemical physics', 'Nanotechnology', 'Chemistry', 'Optics', 'Physical chemistry', 'Physics', 'Chromatography', 'Organic chemistry']","optical detection, single molecules, single nanoparticles, silver colloidal nanoparticles, spec, ads, ##dam, intrinsic raman enhancement factors, vibrational raman signals"
Paper_01472,Circos: An information aesthetic for comparative genomics,"['Martin Krzywinski', 'Jacqueline E. Schein', 'İnanç Birol', 'Joseph M. Connors', 'Randy D. Gascoyne', 'Doug Horsman', 'Steven J.M. Jones', 'Marco A. Marra']",2009,Genome Research,Journal,,1639-1645,19,9,10.1101/gr.092759.109,"We created a visualization tool called Circos to facilitate the identification and analysis of similarities and differences arising from comparisons of genomes. Our tool is effective in displaying variation in genome structure and, generally, any other kind of positional relationships between genomic intervals. Such data are routinely produced by sequence alignments, hybridization arrays, genome mapping, and genotyping studies. Circos uses a circular ideogram layout to facilitate the display of relationships between pairs of positions by the use of ribbons, which encode the position, size, and orientation of related genomic elements. Circos is capable of displaying data as scatter, line, and histogram plots, heat maps, tiles, connectors, and text. Bitmap or vector images can be created from GFF-style data inputs and hierarchical configuration files, which can be easily generated by automated tools, making Circos suitable for rapid deployment in data analysis and reporting pipelines.","['Biology', 'Genome', 'Visualization', 'Computational biology', 'Comparative genomics', 'Genomics', 'Reference genome', 'ENCODE', 'Silhouette', 'Data visualization', 'Computer science', 'Genetics', 'Data mining', 'Artificial intelligence', 'Gene']","visualization, circos, genome structure, positional relationships, genomic intervals, sequence alignments, hybridization arrays, genome mapping, genotyping studies, circos, circular ideogram layout, ribbons, gen, circos, histogram plots, heat maps, tiles, connectors, bit, vector images, hierarchical configuration files, automated tools, circos, data analysis, reporting, [PAD], [PAD], [PAD], [PAD], [PAD] [PAD], [PAD], [PAD], [PAD] [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD], [PAD] [PAD], [PAD] [PAD] [PAD], [PAD], [PAD] [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD], [PAD] [PAD], [PAD] [PAD] [PAD], [PAD], [PAD], [PAD], [PAD] [PAD]"
Paper_01473,Challenges for Rechargeable Li Batteries,"['John B. Goodenough', 'Youngsik Kim']",2009,Chemistry of Materials,Journal,,587-603,22,3,10.1021/cm901452z,"The challenges for further development of Li rechargeable batteries for electric vehicles are reviewed. Most important is safety, which requires development of a nonflammable electrolyte with either a larger window between its lowest unoccupied molecular orbital (LUMO) and highest occupied molecular orbital (HOMO) or a constituent (or additive) that can develop rapidly a solid/electrolyte-interface (SEI) layer to prevent plating of Li on a carbon anode during a fast charge of the battery. A high Li+-ion conductivity (σLi > 10−4 S/cm) in the electrolyte and across the electrode/electrolyte interface is needed for a power battery. Important also is an increase in the density of the stored energy, which is the product of the voltage and capacity of reversible Li insertion/extraction into/from the electrodes. It will be difficult to design a better anode than carbon, but carbon requires formation of an SEI layer, which involves an irreversible capacity loss. The design of a cathode composed of environmentally benign, low-cost materials that has its electrochemical potential μC well-matched to the HOMO of the electrolyte and allows access to two Li atoms per transition-metal cation would increase the energy density, but it is a daunting challenge. Two redox couples can be accessed where the cation redox couples are ""pinned"" at the top of the O 2p bands, but to take advantage of this possibility, it must be realized in a framework structure that can accept more than one Li atom per transition-metal cation. Moreover, such a situation represents an intrinsic voltage limit of the cathode, and matching this limit to the HOMO of the electrolyte requires the ability to tune the intrinsic voltage limit. Finally, the chemical compatibility in the battery must allow a long service life.","['Electrolyte', 'Anode', 'Battery (electricity)', 'Electrochemistry', 'Cathode', 'HOMO/LUMO', 'Redox', 'Organic radical battery', 'Carbon fibers', 'Transition metal', 'Electrode', 'Materials science', 'Chemistry', 'Chemical engineering', 'Nanotechnology', 'Inorganic chemistry', 'Molecule', 'Physical chemistry', 'Organic chemistry', 'Power (physics)', 'Composite material', 'Catalysis', 'Physics', 'Quantum mechanics', 'Composite number', 'Engineering']","li rechargeable batteries, electric vehicles, nonflammable electrolyte, intrinsic voltage limit, chemical"
Paper_01476,Theory of Dislocations,"['J. P. Hirth', 'J. Lothe']",1968,['Progress in Metal Physics'],Unknown,,77-126,1,,10.1016/0502-8205(49)90004-0,Dislocations in Isotropic Continua. Effects of Crystal Structure on Dislocations. Dislocation-Point-Defect Interactions at Finite Temperatures. Groups of Dislocations. Appendixes. Author and Subject Indexes.,['Materials science'],"dislocations, isotropic continua, crystal structure, disl, finite temperatures, disl, [PAD] [PAD], [PAD] [PAD], [PAD], [PAD] [PAD] [PAD] [PAD] [PAD], [PAD] [PAD], [PAD] [PAD], [PAD], [PAD], [PAD] [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD]"
Paper_01477,Obesity: preventing and managing the global epidemic. Report of a WHO consultation.,[],2000,['Journal of Biosocial Science'],Unknown,,624-625,35,4,10.1017/s0021932003245508,"Overweight and obesity represent a rapidly growing threat to the health of populations in an increasing number of countries. Indeed they are now so common that they are replacing more traditional problems such as undernutrition and infectious diseases as the most significant causes of ill-health. Obesity comorbidities include coronary heart disease, hypertension and stroke, certain types of cancer, non-insulin-dependent diabetes mellitus, gallbladder disease, dyslipidaemia, osteoarthritis and gout, and pulmonary diseases, including sleep apnoea. In addition, the obese suffer from social bias, prejudice and discrimination, on the part not only of the general public but also of health professionals, and this may make them reluctant to seek medical assistance. WHO therefore convened a Consultation on obesity to review current epidemiological information, contributing factors and associated consequences, and this report presents its conclusions and recommendations. In particular, the Consultation considered the system for classifying overweight and obesity based on the body mass index, and concluded that a coherent system is now available and should be adopted internationally. The Consultation also concluded that the fundamental causes of the obesity epidemic are sedentary lifestyles and high-fat energy-dense diets, both resulting from the profound changes taking place in society and the behavioural patterns of communities as a consequence of increased urbanization and industrialization and the disappearance of traditional lifestyles. A reduction in fat intake to around 20-25% of energy is necessary to minimize energy imbalance and weight gain in sedentary individuals. While there is strong evidence that certain genes have an influence on body mass and body fat, most do not qualify as necessary genes, i.e. genes that cause obesity whenever two copies of the defective allele are present; it is likely to be many years before the results of genetic research can be applied to the problem. Methods for the treatment of obesity are described, including dietary management, physical activity and exercise, and antiobesity drugs, with gastrointestinal surgery being reserved for extreme cases.","['Obesity', 'Overweight', 'Medicine', 'Public health', 'Disease', 'Malnutrition', 'Epidemiology', 'Gerontology', 'Environmental health', 'Internal medicine', 'Pathology']","overweight, obesity, undernutrition, infectious diseases, obesity como, coronary heart disease, gallbladder disease, dyslipidae, osteoarth, sleep apnoea, obe, social bias, overweight, obesity, body mass index, obesity, ##dentary lifestyles, energy imbalance, weight gain, ##ary individuals, dietary management, physical activity, antiobesity drugs, gastrointestinal surgery"
Paper_01478,The Coding Manual for Qualitative Researchers,['Maria Lungu'],2022,American Journal of Qualitative Research,Journal,,232-237,6,1,10.29333/ajqr/12085,"The Coding Manual fourth edition is reformatted to 15 chapters and divided into three parts, as opposed to six chapters in the third edition.This provides readers with more straightforward yet more detailed sectional references.The fourth edition also introduces two new first-cycle coding methods, 'metaphor coding' and 'theming the data categorically.'The fourth edition is aptly suited as a guide for teaching contexts for coding processes, given the provision of a companion website with student exercises and digital content.This includes screenshots of relevant academic software for analyzing the material and detailed thematic mapping diagrams.Furthermore, this book can assist novice researchers in determining the appropriate approaches to reinforce their perspectives and provide incremental processes for qualitative coding data.","['Coding (social sciences)', 'Computer science', 'Psychology', 'Sociology', 'Social science']","coding manual, metaphor coding, coding processes, student exercises, digital content, academic software, thematic mapping diagrams, qualitative coding data"
Paper_01480,Fuzzy Nanoassemblies: Toward Layered Polymeric Multicomposites,['Gero Decher'],1997,Science,Journal,,1232-1237,277,5330,10.1126/science.277.5330.1232,"Multilayer films of organic compounds on solid surfaces have been studied for more than 60 years because they allow fabrication of multicomposite molecular assemblies of tailored architecture. However, both the Langmuir-Blodgett technique and chemisorption from solution can be used only with certain classes of molecules. An alternative approach—fabrication of multilayers by consecutive adsorption of polyanions and polycations—is far more general and has been extended to other materials such as proteins or colloids. Because polymers are typically flexible molecules, the resulting superlattice architectures are somewhat fuzzy structures, but the absence of crystallinity in these films is expected to be beneficial for many potential applications.","['Fabrication', 'Chemisorption', 'Superlattice', 'Adsorption', 'Polymer', 'Molecule', 'Materials science', 'Nanotechnology', 'Crystallinity', 'Chemical engineering', 'Chemistry', 'Organic chemistry', 'Optoelectronics', 'Composite material', 'Medicine', 'Alternative medicine', 'Pathology', 'Engineering']","multilayer films, organic compounds, solid surfaces, multicomposite molecular assemblies, tailored architecture, chemisor, multi, consecutive adsorption, polycations, colloids, flexible molecules, superlattice architectures, fuzzy structures, crystallinity"
Paper_01481,z-Tree: Zurich toolbox for ready-made economic experiments,['Urs Fischbacher'],2007,Experimental Economics,Journal,,171-178,10,2,10.1007/s10683-006-9159-4,"z-Tree (Zurich Toolbox for Ready-made Economic Experiments) is a software for developing and conducting economic experiments. The software is stable and allows programming almost any kind of experiments in a short time. In this article, I present the guiding principles behind the software design, its features, and its limitations.","['Toolbox', 'Computer science', 'Software', 'Software engineering', 'Tree (set theory)', 'Mathematical economics', 'Programming language', 'Operations research', 'Industrial engineering', 'Economics', 'Engineering', 'Mathematics', 'Mathematical analysis']",
Paper_01482,Heterogeneous photocatalyst materials for water splitting,"['Akihiko Kudo', 'Yugo Miseki']",2008,Chemical Society Reviews,Journal,,253-278,38,1,10.1039/b800489g,"This critical review shows the basis of photocatalytic water splitting and experimental points, and surveys heterogeneous photocatalyst materials for water splitting into H2 and O2, and H2 or O2 evolution from an aqueous solution containing a sacrificial reagent. Many oxides consisting of metal cations with d0 and d10 configurations, metal (oxy)sulfide and metal (oxy)nitride photocatalysts have been reported, especially during the latest decade. The fruitful photocatalyst library gives important information on factors affecting photocatalytic performances and design of new materials. Photocatalytic water splitting and H2 evolution using abundant compounds as electron donors are expected to contribute to construction of a clean and simple system for solar hydrogen production, and a solution of global energy and environmental issues in the future (361 references).","['Photocatalysis', 'Water splitting', 'Photocatalytic water splitting', 'Aqueous solution', 'Reagent', 'Sulfide', 'Materials science', 'Solar energy conversion', 'Hydrogen sulfide', 'Nitride', 'Metal', 'Hydrogen production', 'Nanotechnology', 'Solar energy', 'Chemistry', 'Hydrogen', 'Chemical engineering', 'Catalysis', 'Physical chemistry', 'Metallurgy', 'Organic chemistry', 'Ecology', 'Sulfur', 'Layer (electronics)', 'Engineering', 'Biology']","photocatalytic water splitting, heterogeneous photocatalyst materials, ##ous solution, sacrificial reagent, metal cations, ##st, photocat, photocatalytic water splitting, h2 evolution, solar hydrogen production"
Paper_01483,First‐Year <i>Wilkinson Microwave Anisotropy Probe</i> ( <i>WMAP</i> ) Observations: Determination of Cosmological Parameters,"['David N. Spergel', 'Licia Verde', 'Hiranya V. Peiris', 'Eiichiro Komatsu', 'M. R. Nolta', 'C. L. Bennett', 'M. Halpern', 'G. Hinshaw', 'N. Jarosik', 'A. Kogut', 'M. Limon', 'S. S. Meyer', 'Lyman A. Page', 'Gregory S. Tucker', 'J. L. Weiland', 'Edward J. Wollack', 'E. L. Wright']",2003,The Astrophysical Journal Supplement Series,Journal,,175-194,148,1,10.1086/377226,"WMAP precision data enables accurate testing of cosmological models. We find that the emerging standard model of cosmology, a flat Lambda-dominated universe seeded by nearly scale-invariant adiabatic Gaussian fluctuations, fits the WMAP data. With parameters fixed only by WMAP data, we can fit finer scale CMB measurements and measurements of large scle structure (galaxy surveys and the Lyman alpha forest). This simple model is also consistent with a host of other astronomical measurements. We then fit the model parameters to a combination of WMAP data with other finer scale CMB experiments (ACBAR and CBI), 2dFGRS measurements and Lyman alpha forest data to find the model's best fit cosmological parameters: h=0.71+0.04-0.03, Omega_b h^2=0.0224+-0.0009, Omega_m h^2=0.135+0.008-0.009, tau=0.17+-0.06, n_s(0.05/Mpc)=0.93+-0.03, and sigma_8=0.84+-0.04. WMAP's best determination of tau=0.17+-0.04 arises directly from the TE data and not from this model fit, but they are consistent. These parameters imply that the age of the universe is 13.7+-0.2 Gyr. The data favors but does not require a slowly varying spectral index. By combining WMAP data with other astronomical data sets, we constrain the geometry of the universe, Omega_tot = 1.02 +- 0.02, the equation of state of the dark energy w &lt; -0.78 (95% confidence limit assuming w &gt;= -1), and the energy density in stable neutrinos, Omega_nu h^2 &lt; 0.0076 (95% confidence limit). For 3 degenerate neutrino species, this limit implies that their mass is less than 0.23 eV (95% confidence limit). The WMAP detection of early reionization rules out warm dark matter.","['CMB cold spot', 'Cosmic microwave background', 'Physics', 'Anisotropy', 'Astrophysics', 'Microwave', 'Cosmology', 'Astronomy', 'Optics', 'Quantum mechanics']","##p, cosmological models, cosmology, ##tic gaussian fluctuations, galaxy surveys, lyman alpha forest, ##i, 2df, ##s, lyman alpha forest, dark energy, energy density, stable neutrinos, degenerate ne, ##p, warm dark matter"
Paper_01484,Combining theory and experiment in electrocatalysis: Insights into materials design,"['Zhi Wei Seh', 'Jakob Kibsgaard', 'Colin F. Dickens', 'Ib Chorkendorff', 'Jens K. Nørskov', 'Thomas F. Jaramillo']",2017,Science,Journal,,,355,6321,10.1126/science.aad4998,"Better living through water-splitting Chemists have known how to use electricity to split water into hydrogen and oxygen for more than 200 years. Nonetheless, because the electrochemical route is inefficient, most of the hydrogen made nowadays comes from natural gas. Seh et al. review recent progress in electrocatalyst development to accelerate water-splitting, the reverse reactions that underlie fuel cells, and related oxygen, nitrogen, and carbon dioxide reductions. A unified theoretical framework highlights the need for catalyst design strategies that selectively stabilize distinct reaction intermediates relative to each other. Science , this issue p. 10.1126/science.aad4998","['Electrocatalyst', 'Water splitting', 'Electrochemistry', 'Hydrogen', 'Catalysis', 'Oxygen evolution', 'Oxygen', 'Carbon dioxide', 'Chemistry', 'Fuel cells', 'Nanotechnology', 'Chemical engineering', 'Materials science', 'Electrode', 'Organic chemistry', 'Engineering', 'Physical chemistry', 'Photocatalysis']","electrocatalyst development, reverse reactions, fuel cells, carbon, catalyst design, [PAD] [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD], [PAD]"
Paper_01485,Aerosol and Surface Stability of SARS-CoV-2 as Compared with SARS-CoV-1,"['Neeltje van Doremalen', 'Trenton Bushmaker', 'Dylan H. Morris', 'Myndi G. Holbrook', 'Amandine Gamble', 'Brandi N. Williamson', 'Azaibi Tamin', 'Jennifer L. Harcourt', 'Natalie J. Thornburg', 'Susan I. Gerber', 'James O. Lloyd‐Smith', 'Emmie de Wit', 'Vincent J. Munster']",2020,New England Journal of Medicine,Journal,,1564-1567,382,16,10.1056/nejmc2004973,"Aerosol and Surface Stability of SARS-CoV-2 In this research letter, investigators report on the stability of SARS-CoV-2 and SARS-CoV-1 under experimental conditions. The viability of the two virus...","['Severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2)', 'Aerosol', 'Coronavirus disease 2019 (COVID-19)', 'Sars virus', '2019-20 coronavirus outbreak', 'Virology', 'Stability (learning theory)', 'Environmental science', 'Medicine', 'Meteorology', 'Physics', 'Computer science', 'Infectious disease (medical specialty)', 'Pathology', 'Disease', 'Machine learning', 'Outbreak']","aerosol, surface stability, [PAD] [PAD], [PAD]"
Paper_01486,"Trends, Rhythms, and Aberrations in Global Climate 65 Ma to Present","['James C. Zachos', 'Mark Pagani', 'Lisa C. Sloan', 'Ellen Thomas', 'Katharina Billups']",2001,Science,Journal,,686-693,292,5517,10.1126/science.1059412,"Since 65 million years ago (Ma), Earth's climate has undergone a significant and complex evolution, the finer details of which are now coming to light through investigations of deep-sea sediment cores. This evolution includes gradual trends of warming and cooling driven by tectonic processes on time scales of 10(5) to 10(7) years, rhythmic or periodic cycles driven by orbital processes with 10(4)- to 10(6)-year cyclicity, and rare rapid aberrant shifts and extreme climate transients with durations of 10(3) to 10(5) years. Here, recent progress in defining the evolution of global climate over the Cenozoic Era is reviewed. We focus primarily on the periodic and anomalous components of variability over the early portion of this era, as constrained by the latest generation of deep-sea isotope records. We also consider how this improved perspective has led to the recognition of previously unforeseen mechanisms for altering climate.","['Global cooling', 'Cenozoic', 'Climatology', 'Climate change', 'Paleoclimatology', 'Climate state', 'Deep sea', 'Climate oscillation', 'Global warming', 'Plate tectonics', 'Global climate', 'Climate model', 'Geology', 'Paleontology', 'Oceanography', 'Tectonics', 'Earth science', 'Effects of global warming', 'Structural basin']","cooling, tectonic processes, periodic cycles, orbital processes, extreme climate transients"
Paper_01487,Practical Statistics for Medical Research,['Douglas G. Altman'],1990,Chapman and Hall/CRC eBooks,Unknown,,,,,10.1201/9780429258589,"Most medical researchers, whether clinical or non-clinical, receive some background in statistics as undergraduates. However, it is most often brief, a long time ago, and largely forgotten by the time it is needed. Furthermore, many introductory texts fall short of adequately explaining the underlying concepts of statistics, and often are divorced from the reality of conducting and assessing medical research.

Practical Statistics for Medical Research is a problem-based text for medical researchers, medical students, and others in the medical arena who need to use statistics but have no specialized mathematics background. 

The author draws on twenty years of experience as a consulting medical statistician to provide clear explanations to key statistical concepts, with a firm emphasis on practical aspects of designing and analyzing medical research. The text gives special attention to the presentation and interpretation of results and the many real problems that arise in medical research","['Medical statistics', 'Statistics', 'Computer science', 'Data science', 'Mathematics']","medical researchers, statistics, statistics, practical statistics, medical research, medical, medical"
Paper_01488,Early Goal-Directed Therapy in the Treatment of Severe Sepsis and Septic Shock,"['Emanuel P. Rivers', 'Bryant Nguyen', 'Suzanne Havstad', 'Julie A. Ressler', 'Alexandria Muzzin', 'Bernhard Knoblich', 'Kevin R. Ward', 'Michael Tomlanovich']",2001,New England Journal of Medicine,Journal,,1368-1377,345,19,10.1056/nejmoa010307,"Goal-directed therapy has been used for severe sepsis and septic shock in the intensive care unit. This approach involves adjustments of cardiac preload, afterload, and contractility to balance oxygen delivery with oxygen demand. The purpose of this study was to evaluate the efficacy of early goal-directed therapy before admission to the intensive care unit.","['Medicine', 'Early goal-directed therapy', 'Septic shock', 'Preload', 'Intensive care medicine', 'Afterload', 'Sepsis', 'Intensive care unit', 'Shock (circulatory)', 'Contractility', 'Anesthesia', 'Hemodynamics', 'Severe sepsis', 'Cardiology', 'Surgery', 'Internal medicine']","severe, septic shock, intensive, cardiac preload, afterload, contractility, oxygen delivery, oxygen demand, [PAD] [PAD], [PAD], [PAD] [PAD], [PAD], [PAD], [PAD] [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"
Paper_01492,Deep Neural Networks for Acoustic Modeling in Speech Recognition: The Shared Views of Four Research Groups,"['Geoffrey E. Hinton', 'Li Deng', 'Dong Yu', 'George E. Dahl', 'Abdelrahman Mohamed', 'Navdeep Jaitly', 'Andrew Senior', 'Vincent Vanhoucke', 'Patrick Nguyen', 'Tara N. Sainath', 'Brian Kingsbury']",2012,IEEE Signal Processing Magazine,Journal,,82-97,29,6,10.1109/msp.2012.2205597,"Most current speech recognition systems use hidden Markov models (HMMs) to deal with the temporal variability of speech and Gaussian mixture models (GMMs) to determine how well each state of each HMM fits a frame or a short window of frames of coefficients that represents the acoustic input. An alternative way to evaluate the fit is to use a feed-forward neural network that takes several frames of coefficients as input and produces posterior probabilities over HMM states as output. Deep neural networks (DNNs) that have many hidden layers and are trained using new methods have been shown to outperform GMMs on a variety of speech recognition benchmarks, sometimes by a large margin. This article provides an overview of this progress and represents the shared views of four research groups that have had recent successes in using DNNs for acoustic modeling in speech recognition.","['Hidden Markov model', 'Speech recognition', 'Computer science', 'Mixture model', 'Artificial neural network', 'Margin (machine learning)', 'Deep neural networks', 'Pattern recognition (psychology)', 'Frame (networking)', 'Artificial intelligence', 'Acoustic model', 'Gaussian', 'Speech processing', 'Machine learning', 'Telecommunications', 'Physics', 'Quantum mechanics']","speech recognition systems, hidden markov models, hmm, temporal variability, gaussian mixture models, gmms, posterior probabilities, deep neural networks, d, ##ms, speech recognition, dnns, acoustic modeling, speech recognition"
Paper_01493,An all-electron numerical method for solving the local density functional for polyatomic molecules,['B. Delley'],1990,The Journal of Chemical Physics,Journal,,508-517,92,1,10.1063/1.458452,"A method for accurate and efficient local density functional calculations (LDF) on molecules is described and presented with results. The method, Dmol for short, uses fast convergent three-dimensional numerical integrations to calculate the matrix elements occurring in the Ritz variation method. The flexibility of the integration technique opens the way to use the most efficient variational basis sets. A practical choice of numerical basis sets is shown with a built-in capability to reach the LDF dissociation limit exactly. Dmol includes also an efficient, exact approach for calculating the electrostatic potential. Results on small molecules illustrate present accuracy and error properties of the method. Computational effort for this method grows to leading order with the cube of the molecule size. Except for the solution of an algebraic eigenvalue problem the method can be refined to quadratic growth for large molecules.","['Eigenvalues and eigenvectors', 'Ritz method', 'Basis (linear algebra)', 'Polyatomic ion', 'Numerical analysis', 'Density functional theory', 'Limit (mathematics)', 'Quadratic equation', 'Algebraic number', 'Molecule', 'Applied mathematics', 'Mathematics', 'Computational chemistry', 'Physics', 'Quantum mechanics', 'Mathematical analysis', 'Chemistry', 'Boundary value problem', 'Geometry']","local density functional calculations, ##f, d, ##l, matrix elements, ritz variation method, variational basis sets, ldf, electrostatic potential, algebraic eigenvalue problem, quadratic growth"
Paper_01494,Interviewing as Qualitative Research: A Guide for Researchers in Education and the Social Sciences,['Irving Seidman'],1991,['Contemporary Psychology: A Journal of Reviews'],Unknown,,717-718,37,7,10.1037/032390,"The third edition of this bestselling resource provides clear, step-by-step guidance for new and experienced interviewers to help them develop, shape, and reflect on interviewing as a qualitative research process. While proposing a phenomenological approach to in-depth interviewing, the author also includes principles and methods that can be adapted to a range of interviewing approaches. Using concrete examples of interviewing techniques to illustrate the issues under discussion, this classic text helps readers to understand the complexities of interviewing and its connections to broader issues of qualitative research. Equally popular for individual and classroom use, the new Third Edition of Interviewing as Qualitative Research features: an introduction to the Institutional Review Board (IRB) process in its historical context, including an expanded discussion of informed consent and its complexities; special attention to the rights of participants in interview research as those rights interact with ethical issues; and, updated references and suggestions for additional reading for a deeper consideration of methodological, ethical, and philosophical issues, including relevant Internet resources.","['Interview', 'Qualitative research', 'Context (archaeology)', 'Resource (disambiguation)', 'Engineering ethics', 'Process (computing)', 'Ethical issues', 'Reading (process)', 'The Internet', 'Psychology', 'Internet research', 'Medical education', 'Sociology', 'Computer science', 'Social science', 'Political science', 'Medicine', 'Engineering', 'World Wide Web', 'Paleontology', 'Computer network', 'Anthropology', 'Law', 'Biology', 'Operating system']","qualitative, interviewing, qualitative research, ##tative, institutional review board, informed consent, interview research, ethical, internet resources"
Paper_01495,Quantum cryptography based on Bell’s theorem,['Artur Ekert'],1991,Physical Review Letters,Journal,,661-663,67,6,10.1103/physrevlett.67.661,Practical application of the generalized Bell's theorem in the so-called key distribution process in cryptography is reported. The proposed scheme is based on the Bohm's version of the Einstein-Podolsky-Rosen gedanken experiment and Bell's theorem is used to test for eavesdropping.,"[""Bell's theorem"", 'Quantum cryptography', 'Eavesdropping', 'Quantum key distribution', 'Bell test experiments', 'Cryptography', 'Kochen–Specker theorem', 'Bell state', 'Local hidden variable theory', 'Computer science', 'Quantum mechanics', 'Physics', 'Theoretical physics', 'Quantum information', 'Quantum', 'Computer security', 'Quantum entanglement']","key distribution process, cryptography, eavesdropping, [PAD] [PAD], [PAD], [PAD] [PAD] [PAD], [PAD]"
Paper_01496,Systematic Evolution of Ligands by Exponential Enrichment: RNA Ligands to Bacteriophage T4 DNA Polymerase,"['Craig Tuerk', 'Larry Gold']",1990,Science,Journal,,505-510,249,4968,10.1126/science.2200121,"High-affinity nucleic acid ligands for a protein were isolated by a procedure that depends on alternate cycles of ligand selection from pools of variant sequences and amplification of the bound species. Multiple rounds exponentially enrich the population for the highest affinity species that can be clonally isolated and characterized. In particular one eight-base region of an RNA that interacts with the T4 DNA polymerase was chosen and randomized. Two different sequences were selected by this procedure from the calculated pool of 65,536 species. One is the wild-type sequence found in the bacteriophage mRNA; one is varied from wild type at four positions. The binding constants of these two RNA's to T4 DNA polymerase are equivalent. These protocols with minimal modification can yield high-affinity ligands for any protein that binds nucleic acids as part of its function; high-affinity ligands could conceivably be developed for any target molecule.","['Nucleic acid', 'Polymerase', 'DNA', 'Bacteriophage', 'Biology', 'RNA', 'Molecular biology', 'RNA polymerase', 'DNA polymerase', 'Population', 'Ligand (biochemistry)', 'Biochemistry', 'Gene', 'Escherichia coli', 'Receptor', 'Demography', 'Sociology']","ligand selection, ##cter"
Paper_01497,Bayesian Phylogenetics with BEAUti and the BEAST 1.7,"['Alexei J. Drummond', 'Marc A. Suchard', 'Dong Xie', 'Andrew Rambaut']",2012,Molecular Biology and Evolution,Journal,,1969-1973,29,8,10.1093/molbev/mss075,"Computational evolutionary biology, statistical phylogenetics and coalescent-based population genetics are becoming increasingly central to the analysis and understanding of molecular sequence data. We present the Bayesian Evolutionary Analysis by Sampling Trees (BEAST) software package version 1.7, which implements a family of Markov chain Monte Carlo (MCMC) algorithms for Bayesian phylogenetic inference, divergence time dating, coalescent analysis, phylogeography and related molecular evolutionary analyses. This package includes an enhanced graphical user interface program called Bayesian Evolutionary Analysis Utility (BEAUti) that enables access to advanced models for molecular sequence and phenotypic trait evolution that were previously available to developers only. The package also provides new tools for visualizing and summarizing multispecies coalescent and phylogeographic analyses. BEAUti and BEAST 1.7 are open source under the GNU lesser general public license and available at http://beast-mcmc.googlecode.com and http://beast.bio.ed.ac.uk","['Coalescent theory', 'Markov chain Monte Carlo', 'Biology', 'Evolutionary biology', 'Phylogenetic tree', 'Bayesian probability', 'Phylogenetics', 'Phylogeography', 'Most recent common ancestor', 'Computer science', 'Artificial intelligence', 'Genetics', 'Gene']","computational evolutionary biology, statistical phylogenetics, population genetics, molecular sequence data, bayesian evolutionary analysis, sampling trees, beast, markov chain monte carlo, bayesian phylogenetic inference, divergence time dating, coalescent analysis, phylogeography, molecular evolutionary analyses, bayesian evolutionary analysis utility, beauti, phenotypic trait evolution, phylogeographic analyses, beauti, beast"
Paper_01498,Genetic Distance between Populations,['Masatoshi Nei'],1972,The American Naturalist,Journal,,283-292,106,949,10.1086/282771,"A measure of genetic distance (D) based on the identity of genes between populations is formulated. It is defined as D = -logeI, where I is the normalized identity of genes between two populations. This genetic distance measures the accumulated allele differences per locus. If the rate of gene substitution per year is constant, it is linearly related to the divergence time between populations under sexual isolation. It is also linearly related to geographical distance or area in some migration models. Since D is a measure of the accumulated number of codon differences per locus, it can also be estimated from data on amino acid sequences in proteins even for a distantly related species. Thus, if enough data are available, genetic distance between any pair of organisms can be measured in terms of D. This measure is applicable to any kind of organism without regard to ploidy or mating scheme.","['Genetic distance', 'Biology', 'Locus (genetics)', 'Genetics', 'Genetic divergence', 'Allele', 'Gene', 'Isolation by distance', 'Evolutionary biology', 'Reproductive isolation', 'Geographical distance', 'Genetic variation', 'Population', 'Genetic diversity', 'Microsatellite', 'Demography', 'Sociology']","genetic distance, normalized identity, genetic distance, accumulated allele differences, gene substitution, divergence time, sexual isolation, geographical distance, migration models, codon differences, amino, genetic distance, ##y, mating scheme"
Paper_01499,Capital: A Critique of Political Economy,['Karl Marx'],2020,Duke University Press eBooks,Unknown,,63-77,,,10.1515/9780822390169-009,"Unfinished at the time of Marx's death in 1883 and first published with a preface by Frederick Engels in 1894, the third volume of Das Kapital strove to combine the theories and concepts of the two previous volumes in order to prove conclusively that capitalism is inherently unworkable as a permanent system for society. Here, Marx asserts controversially that - regardless of the efforts of individual capitalists, public authorities or even generous philanthropists - any market economy is inevitably doomed to endure a series of worsening, explosive crises leading finally to complete collapse. But he also offers an inspirational and compelling prediction: that the end of capitalism will culminate, ultimately, in the birth of a far greater form of society.","['Politics', 'Capital (architecture)', 'Economics', 'Political science', 'Political economy', 'Economic system', 'History', 'Ancient history', 'Law']","##pit, capitalism, public authorities, market economy"
Paper_01500,Symbolic Interactionism: Perspective and Method.,"['Rosabeth Moss Kanter', 'Herbert Blumer']",1971,American Sociological Review,Journal,,333-333,36,2,10.2307/2094060,"This is a collection of articles dealing with the point of view of symbolic interactionism and with the topic of methodology in the discipline of sociology. It is written by the leading figure in the school of symbolic interactionism, and presents what might be regarded as the most authoritative statement of its point of view, outlining its fundamental premises and sketching their implications for sociological study. Blumer states that symbolic interactionism rests on three premises: that human beings act toward things on the basis of the meanings of things have for them; that the meaning of such things derives from the social interaction one has with one's fellows; and that these meanings are handled in, and modified through, an interpretive process.","['Symbolic interactionism', 'Perspective (graphical)', 'Sociology', 'Interactionism', 'Epistemology', 'Symbolic data analysis', 'Criminology', 'Psychology', 'Social science', 'Computer science', 'Mathematics', 'Statistics', 'Artificial intelligence', 'Philosophy']","symbolic interactionism, methodology, sociology, symbolic interactionism, symbolic interactionism, social"
Paper_01501,"STRING v10: protein–protein interaction networks, integrated over the tree of life","['Damian Szklarczyk', 'Andrea Franceschini', 'Stefan Wyder', 'Sofia K. Forslund', 'Davide Heller', 'Jaime Huerta‐Cepas', 'Milan Simonovic', 'Alexander Röth', 'Alberto Santos', 'Kalliopi P. Tsafou', 'Michael Kuhn', 'Peer Bork', 'Lars Juhl Jensen', 'Christian von Mering']",2014,Nucleic Acids Research,Journal,,D447-D452,43,D1,10.1093/nar/gku1003,"The many functional partnerships and interactions that occur between proteins are at the core of cellular processing and their systematic characterization helps to provide context in molecular systems biology. However, known and predicted interactions are scattered over multiple resources, and the available data exhibit notable differences in terms of quality and completeness. The STRING database (http://string-db.org) aims to provide a critical assessment and integration of protein–protein interactions, including direct (physical) as well as indirect (functional) associations. The new version 10.0 of STRING covers more than 2000 organisms, which has necessitated novel, scalable algorithms for transferring interaction information between organisms. For this purpose, we have introduced hierarchical and self-consistent orthology annotations for all interacting proteins, grouping the proteins into families at various levels of phylogenetic resolution. Further improvements in version 10.0 include a completely redesigned prediction pipeline for inferring protein–protein associations from co-expression data, an API interface for the R computing environment and improved statistical analysis for enrichment tests in user-provided networks.","['Biology', 'String (physics)', 'Computational biology', 'Context (archaeology)', 'Pipeline (software)', 'Protein–protein interaction', 'Tree (set theory)', 'Scalability', 'Phylogenetic tree', 'Computer science', 'Theoretical computer science', 'Database', 'Genetics', 'Programming language', 'Gene', 'Physics', 'Paleontology', 'Mathematical analysis', 'Mathematics', 'Quantum mechanics']","functional partnerships, cellular processing, molecular systems biology, string database, phylogenetic resolution, prediction pipeline, api interface, statistical analysis, enrichment tests"
Paper_01503,Practical Research: Planning and Design,"['Edward Brent', 'Paul D. Leedy']",1990,Teaching Sociology,Journal,,248-248,18,2,10.2307/1318509,"Brief Contents PART I THE FUNDAMENTALS Chapter 1 THE NATURE AND TOOLS OF RESEARCH PART II FOCUSING YOUR RESEARCH EFFORTS Chapter 2 THE PROBLEM: THE HEART OF THE RESEARCH PROCESS Chapter 3 REVIEW OF THE RELATED LITERATURE Chapter 4 PLANNING YOUR RESEARCH PROJECT Chapter 5 WRITING THE RESEARCH PROPOSAL PART III QUANTITATIVE RESEARCH Chapter 6 DESCRIPTIVE RESEARCH Chapter 7 EXPERIMENTAL, QUASI-EXPERIMENTAL, AND EX POST FACTO DESIGNS Chapter 8 ANALYZING QUANTITATIVE DATA PART IV QUALITATIVE RESEARCH Chapter 9 QUALITATIVE RESEARCH METHODS Chapter 10 HISTORICAL RESEARCH Chapter 11 ANALYZING QUALITATIVE DATA PART V MIXED-METHODS RESEARCH Chapter 12 MIXED-METHODS DESIGNS PART VI RESEARCH REPORTS Chapter 13 PLANNING AND PREPARING A FINAL RESEARCH REPORT APPENDICES Appendix A USING A SPREADSHEET: MICROSOFT EXCEL Appendix B USING SPSS","['Management science', 'Qualitative research', 'Research design', 'Computer science', 'Process (computing)', 'Research methodology', 'Mathematics education', 'Sociology', 'Engineering ethics', 'Engineering', 'Social science', 'Psychology', 'Population', 'Demography', 'Operating system']","quantitative research, descriptive research, qualitative, qualitative research, quali, spreadsheet, microsoft excel, spss, [PAD]"
Paper_01505,Involvement of the Superoxide Anion Radical in the Autoxidation of Pyrogallol and a Convenient Assay for Superoxide Dismutase,"['Stefan L. Marklund', 'Gudrun MARKLUND']",1974,European Journal of Biochemistry,Journal,,469-474,47,3,10.1111/j.1432-1033.1974.tb03714.x,"The autoxidation of pyrogallol was investigated in the presence of EDTA in the pH range 7.9–10.6. The rate of autoxidation increases with increasing pH. At pH 7.9 the reaction is inhibited to 99% by superoxide dismutase, indicating an almost total dependence on the participation of the superoxide anion radical, O 2 · − , in the reaction. Up to pH 9.1 the reaction is still inhibited to over 90% by superoxide dismutase, but at higher alkalinity, O 2 · − ‐independent mechanisms rapidly become dominant. Catalase has no effect on the autoxidation but decreases the oxygen consumption by half, showing that H 2 O 2 is the stable product of oxygen and that H 2 O 2 is not involved in the autoxidation mechanism. A simple and rapid method for the assay of superoxide dismutase is described, based on the ability of the enzyme to inhibit the autoxidation of pyrogallol. A plausible explanation is given for the non‐competitive part of the inhibition of catechol O ‐methyltransferase brought about by pyrogallol.","['Autoxidation', 'Pyrogallol', 'Chemistry', 'Superoxide dismutase', 'Superoxide', 'Catechol', 'Catalase', 'Homolysis', 'Oxygen', 'Medicinal chemistry', 'Radical', 'Enzyme', 'Photochemistry', 'Nuclear chemistry', 'Biochemistry', 'Organic chemistry']","##xidation, pyrogallol, edta, superoxide dismutase, super, superoxide dismutase, catalase, superoxide dismutase, pyrogallol"
Paper_01506,Prodigal: prokaryotic gene recognition and translation initiation site identification,"['Doug Hyatt', 'Gwo-Liang Chen', 'Philip LoCascio', 'Miriam Land', 'Frank W. Larimer', 'Loren Hauser']",2010,BMC Bioinformatics,Journal,,,11,1,10.1186/1471-2105-11-119,"The quality of automated gene prediction in microbial organisms has improved steadily over the past decade, but there is still room for improvement. Increasing the number of correct identifications, both of genes and of the translation initiation sites for each gene, and reducing the overall number of false positives, are all desirable goals. With our years of experience in manually curating genomes for the Joint Genome Institute, we developed a new gene prediction algorithm called Prodigal (PROkaryotic DYnamic programming Gene-finding ALgorithm). With Prodigal, we focused specifically on the three goals of improved gene structure prediction, improved translation initiation site recognition, and reduced false positives. We compared the results of Prodigal to existing gene-finding methods to demonstrate that it met each of these objectives. We built a fast, lightweight, open source gene prediction program called Prodigal http://compbio.ornl.gov/prodigal/ . Prodigal achieved good results compared to existing methods, and we believe it will be a valuable asset to automated microbial annotation pipelines.","['Gene prediction', 'False positive paradox', 'Gene', 'Annotation', 'Identification (biology)', 'Genome', 'Computer science', 'Gene Annotation', 'Translation (biology)', 'Computational biology', 'DNA microarray', 'Eukaryotic translation', 'Data mining', 'Genetics', 'Biology', 'Artificial intelligence', 'Gene expression', 'Messenger RNA', 'Botany']","automated gene prediction, microbial organisms, translation initiation sites, joint genome institute, gene prediction algorithm, prodigal, prokaryotic dynamic programming, ##gal, gene structure prediction, translation initiation site recognition, ##gal, prodigal, ##gal, pro, ##gal"
Paper_01507,"School Engagement: Potential of the Concept, State of the Evidence","['Jennifer A. Fredricks', 'Phyllis C. Blumenfeld', 'Alison H. Paris']",2004,Review of Educational Research,Journal,,59-109,74,1,10.3102/00346543074001059,"The concept of school engagement has attracted increasing attention as representing a possible antidote to declining academic motivation and achievement. Engagement is presumed to be malleable, responsive to contextual features, and amenable to environmental change. Researchers describe behavioral, emotional, and cognitive engagement and recommend studying engagement as a multifaceted construct. This article reviews definitions, measures, precursors, and outcomes of engagement; discusses limitations in the existing research; and suggests improvements. The authors conclude that, although much has been learned, the potential contribution of the concept of school engagement to research on student experience has yet to be realized. They call for richer characterizations of how students behave, feel, and think—research that could aid in the development of finely tuned interventions","['Student engagement', 'Psychology', 'Construct (python library)', 'Cognition', 'Psychological intervention', 'Academic achievement', 'Social psychology', 'Pedagogy', 'Neuroscience', 'Psychiatry', 'Computer science', 'Programming language']","school engagement, academic motivation, contextual features, environmental change, cognitive engagement, engagement, school engagement, student experience"
Paper_01510,A Colorimetric Method for the Determination of Serum Glutamic Oxalacetic and Glutamic Pyruvic Transaminases,"['Stanley Reitman', 'Sam Frankel']",1957,American Journal of Clinical Pathology,Journal,,56-63,28,1,10.1093/ajcp/28.1.56,"Journal Article A Colorimetric Method for the Determination of Serum Glutamic Oxalacetic and Glutamic Pyruvic Transaminases Get access Stanley Reitman, M.D., Stanley Reitman, M.D. Medical and Laboratory Sections, Research Institute, The Jewish Hospital of St. Louis, St. Louis, Missouri Search for other works by this author on: Oxford Academic Google Scholar Sam Frankel, Ph.D. Sam Frankel, Ph.D. Medical and Laboratory Sections, Research Institute, The Jewish Hospital of St. Louis, St. Louis, Missouri Search for other works by this author on: Oxford Academic Google Scholar American Journal of Clinical Pathology, Volume 28, Issue 1, 1 July 1957, Pages 56–63, https://doi.org/10.1093/ajcp/28.1.56 Published: 01 July 1957 Article history Received: 31 December 1956 Revision received: 11 March 1957 Accepted: 01 April 1957 Published: 01 July 1957","['St louis', 'Medicine', 'Library science', 'History', 'Art history', 'Computer science']","colorimetric method, g, ##tamic pyruvic transaminases, clinical pathology"
Paper_01511,"Digital Natives, Digital Immigrants Part 1",['Marc Prensky'],2001,On the Horizon The International Journal of Learning Futures,Journal,,1-6,9,5,10.1108/10748120110424816,"Abstract Part one of this paper highlights how students today think and process information fundamentally differently from their predecessors, as a result of being surrounded by new technology. The author compares these ""digital natives"" with the older generation who are learning and adopting new technology naming them ""digital immigrants"".","['Digital native', 'Immigration', 'Process (computing)', 'Information technology', 'Sociology', 'Computer science', 'Political science', 'World Wide Web', 'Law', 'Operating system']","digital natives, digital immigrants"
Paper_01512,Self-Consistent Molecular-Orbital Methods. IX. An Extended Gaussian-Type Basis for Molecular-Orbital Studies of Organic Molecules,"['R. Ditchfield', 'Warren J. Hehre', 'John A. Pople']",1971,The Journal of Chemical Physics,Journal,,724-728,54,2,10.1063/1.1674902,"An extended basis set of atomic functions expressed as fixed linear combinations of Gaussian functions is presented for hydrogen and the first-row atoms carbon to fluorine. In this set, described as 4–31 G, each inner shell is represented by a single basis function taken as a sum of four Gaussians and each valence orbital is split into inner and outer parts described by three and one Gaussian function, respectively. The expansion coefficients and Gaussian exponents are determined by minimizing the total calculated energy of the atomic ground state. This basis set is then used in single-determinant molecular-orbital studies of a group of small polyatomic molecules. Optimization of valence-shell scaling factors shows that considerable rescaling of atomic functions occurs in molecules, the largest effects being observed for hydrogen and carbon. However, the range of optimum scale factors for each atom is small enough to allow the selection of a standard molecular set. The use of this standard basis gives theoretical equilibrium geometries in reasonable agreement with experiment.","['STO-nG basis sets', 'Basis set', 'Gaussian', 'Chemistry', 'Molecular orbital', 'Valence (chemistry)', 'Atomic physics', 'Fragment molecular orbital', 'Scaling', 'Hydrogen atom', 'Polyatomic ion', 'Basis function', 'Molecular orbital theory', 'Molecule', 'Non-bonding orbital', 'Molecular physics', 'Computational chemistry', 'Physics', 'Quantum mechanics', 'Density functional theory', 'Mathematics', 'Group (periodic table)', 'Geometry', 'Organic chemistry']","atomic functions, fixed linear combinations, gaussian functions, valence orbital, ##ussian function, expansion coefficients, gaussian exponents, ##atomic molecules"
Paper_01513,Response Surface Methodology: Process and Product Optimization Using Designed Experiments,"['Richard F. Gunst', 'Raymond H. Myers', 'Douglas C. Montgomery']",1996,Technometrics,Journal,,285-285,38,3,10.2307/1270613,"From the Publisher:
Using a practical approach, it discusses two-level factorial and fractional factorial designs, several aspects of empirical modeling with regression techniques, focusing on response surface methodology, mixture experiments and robust design techniques. Features numerous authentic application examples and problems. Illustrates how computers can be a useful aid in problem solving. Includes a disk containing computer programs for a response surface methodology simulation exercise and concerning mixtures.","['Response surface methodology', 'Process (computing)', 'Computer science', 'Product (mathematics)', 'Process engineering', 'Mathematics', 'Engineering', 'Machine learning', 'Programming language', 'Geometry']","fractional factorial designs, empirical modeling, regression techniques, response surface methodology, mixture experiments, robust design techniques, computer programs, response surface methodology, mixture, [PAD] [PAD] [PAD], [PAD] [PAD], [PAD], [PAD], [PAD], [PAD] [PAD] [PAD] [PAD] [PAD], [PAD], [PAD], [PAD] [PAD], [PAD] [PAD] [PAD], [PAD], [PAD] [PAD] [PAD], [PAD] [PAD], [PAD]"
Paper_01515,Supramolecular Chemistry,['J.-M. Lehn'],1995,Unknown,Unknown,,,,,10.1002/3527607439,"Part 1 From molecular to supramolecular chemistry: concepts and language of supramolecular chemistry. Part 2 Molecular recognition: recognition, information, complementarity molecular receptors - design principles spherical recognition - cryptates of metal cations tetrahedral recognition by macrotricyclic cryptands recognition of ammonium ions and related substrates binding and recognition of neutral moelcules. Part 3 Anion co-ordination chemistry and the recognition of anionic substrates. Part 4 Coreceptor molecules and multiple recognition: dinuclear and polynuclear metal ion cryptates linear recognition of molecular length by ditopic coreceptors heterotopic coreceptors - cyclophane receptors, amphiphilic receptors, large molecular cage multiple recognition in metalloreceptors supramolecular dynamics. Part 5 Supramolecular reactivity and catalysis: catalysis by reactive macrocyclic cation receptor molecules catalysis by reactive anion receptor molecules catalysis with cyclophane type receptors supramolecular metallo-catalysis cocatalysis - catalysis of synthetic reactions biomolecular and abiotic catalysis. Part 6 Transport processes and carrier design: carrier-mediated transport cation-transport processes - cation carriers anion transport processes - anion carriers coupled transport processes electron-coupled transpoort in a redox gradient proton-coupled transport in a pH gradient light-coupled transport processes transfer via transmembrane channels. Part 7 From supermolecules to polymolecular assemblies: heterogeneous molecular recognition - supramolecular solid materials from endoreceptors to exoreceptors - molecular recognition at surfaces molecular and supramolecular morphogenesis supramolecular heterogeneous catalysis. Part 8 Molecular and supramolecular devices: molecular recognition, information and signals - semiochemistry supramolecular photochemistry - molecular and supramolecular photonic devices light conversion and energy transfer devices photosensitive molecular receptors photoinduced electron transfer in photoactive devices photoinduced reactions in supramolecular species non-linear optical properties of supramolecular species supramolecular effects in photochemical hole burning molecular and supramolecular electronic devices supramolecular electrochemistry electron conducting devices - molecular wires polarized molecular wires - rectifying devices modified and switchable molecular wires molecular magnetic devices molecular and supramolecular ionic devices tubular mesophases. (Part contents).","['Supramolecular chemistry', 'Chemistry', 'Polymer science', 'Organic chemistry', 'Molecule']","supramolecular chemistry, molecular recognition, ##or molecules, multiple recognition, ##hane, ##ce, ##rane, light conversion, energy transfer, ##d"
Paper_01516,trimAl: a tool for automated alignment trimming in large-scale phylogenetic analyses,"['Salvador Capella-Gutiérrez', 'José M. Silla-Martínez', 'Toni Gabaldón']",2009,Bioinformatics,Journal,,1972-1973,25,15,10.1093/bioinformatics/btp348,"Abstract Summary: Multiple sequence alignments are central to many areas of bioinformatics. It has been shown that the removal of poorly aligned regions from an alignment increases the quality of subsequent analyses. Such an alignment trimming phase is complicated in large-scale phylogenetic analyses that deal with thousands of alignments. Here, we present trimAl, a tool for automated alignment trimming, which is especially suited for large-scale phylogenetic analyses. trimAl can consider several parameters, alone or in multiple combinations, for selecting the most reliable positions in the alignment. These include the proportion of sequences with a gap, the level of amino acid similarity and, if several alignments for the same set of sequences are provided, the level of consistency across different alignments. Moreover, trimAl can automatically select the parameters to be used in each specific alignment so that the signal-to-noise ratio is optimized. Availability: trimAl has been written in C++, it is portable to all platforms. trimAl is freely available for download (http://trimal.cgenomics.org) and can be used online through the Phylemon web server (http://phylemon2.bioinfo.cipf.es/). Supplementary Material is available at http://trimal.cgenomics.org/publications. Contact: tgabaldon@crg.es","['Multiple sequence alignment', 'Phylogenetic tree', 'Trimming', 'Computer science', 'Sequence alignment', 'Set (abstract data type)', 'Similarity (geometry)', 'Scale (ratio)', 'Consistency (knowledge bases)', 'Data mining', 'Computational biology', 'Artificial intelligence', 'Biology', 'Peptide sequence', 'Genetics', 'Physics', 'Quantum mechanics', 'Gene', 'Image (mathematics)', 'Programming language', 'Operating system']","multiple sequence alignments, bioinformatics, alignment trimming, trimal, automated alignment trimming, trimal, amino acid similarity, trimal, trimal, trimal, ##gen, phylemon web server, ##don"
Paper_01517,Phylogenies and the Comparative Method,['Joseph Felsenstein'],1985,The American Naturalist,Journal,,1-15,125,1,10.1086/284325,"Comparative studies of the relationship between two phenotypes, or between a phenotype and an environment, are frequently carried out by invalid statistical methods. Most regression, correlation, and contingency table methods, including nonparametric methods, assume that the points are drawn independently from a common distribution. When species are taken from a branching phylogeny, they are manifestly nonindependent. Use of a statistical method that assumes independence will cause overstatement of the significance in hypothesis tests. Some illustrative examples of these phenomena have been given, and limitations of previous proposals of ways to correct for the nonindependence have been discussed. A method of correcting for the phylogeny has been proposed. It requires that we know both the tree topology and the branch lengths, and that we be willing to allow the characters to be modeled by Brownian motion on a linear scale. Given these conditions, the phylogeny specifies a set of contrasts among species, contrasts that are statistically independent and can be used in regression or correlation studies. The considerable barriers to making practical use of this technique have been discussed.","['Contingency table', 'Phylogenetics', 'Phylogenetic comparative methods', 'Statistical hypothesis testing', 'Nonparametric statistics', 'Regression', 'Independence (probability theory)', 'Econometrics', 'Biology', 'Statistics', 'Evolutionary biology', 'Mathematics', 'Biochemistry', 'Gene']","comparative, invalid statistical methods, correlation, contingency table methods, nonparametric methods, branching phylogeny, statistical method, hypothesis tests, ##endence, ##ogen, tree topology, branch lengths, brownian motion, linear scale, correlation studies, [PAD], [PAD], [PAD], [PAD], [PAD]"
Paper_01518,Immediate Psychological Responses and Associated Factors during the Initial Stage of the 2019 Coronavirus Disease (COVID-19) Epidemic among the General Population in China,"['Cuiyan Wang', 'Riyu Pan', 'Xiaoyang Wan', 'Yilin Tan', 'Linkang Xu', 'Cyrus S. H. Ho', 'Roger Ho']",2020,International Journal of Environmental Research and Public Health,Journal,,1729-1729,17,5,10.3390/ijerph17051729,"Background: The 2019 coronavirus disease (COVID-19) epidemic is a public health emergency of international concern and poses a challenge to psychological resilience. Research data are needed to develop evidence-driven strategies to reduce adverse psychological impacts and psychiatric symptoms during the epidemic. The aim of this study was to survey the general public in China to better understand their levels of psychological impact, anxiety, depression, and stress during the initial stage of the COVID-19 outbreak. The data will be used for future reference. Methods: From 31 January to 2 February 2020, we conducted an online survey using snowball sampling techniques. The online survey collected information on demographic data, physical symptoms in the past 14 days, contact history with COVID-19, knowledge and concerns about COVID-19, precautionary measures against COVID-19, and additional information required with respect to COVID-19. Psychological impact was assessed by the Impact of Event Scale-Revised (IES-R), and mental health status was assessed by the Depression, Anxiety and Stress Scale (DASS-21). Results: This study included 1210 respondents from 194 cities in China. In total, 53.8% of respondents rated the psychological impact of the outbreak as moderate or severe; 16.5% reported moderate to severe depressive symptoms; 28.8% reported moderate to severe anxiety symptoms; and 8.1% reported moderate to severe stress levels. Most respondents spent 20–24 h per day at home (84.7%); were worried about their family members contracting COVID-19 (75.2%); and were satisfied with the amount of health information available (75.1%). Female gender, student status, specific physical symptoms (e.g., myalgia, dizziness, coryza), and poor self-rated health status were significantly associated with a greater psychological impact of the outbreak and higher levels of stress, anxiety, and depression (p &lt; 0.05). Specific up-to-date and accurate health information (e.g., treatment, local outbreak situation) and particular precautionary measures (e.g., hand hygiene, wearing a mask) were associated with a lower psychological impact of the outbreak and lower levels of stress, anxiety, and depression (p &lt; 0.05). Conclusions: During the initial phase of the COVID-19 outbreak in China, more than half of the respondents rated the psychological impact as moderate-to-severe, and about one-third reported moderate-to-severe anxiety. Our findings identify factors associated with a lower level of psychological impact and better mental health status that can be used to formulate psychological interventions to improve the mental health of vulnerable groups during the COVID-19 epidemic.","['Anxiety', 'Snowball sampling', 'Mental health', 'Public health', 'Medicine', 'Population', 'Depression (economics)', 'Outbreak', 'Pandemic', 'Psychological resilience', 'Disease', 'Psychiatry', 'Environmental health', 'Coronavirus disease 2019 (COVID-19)', 'Psychology', 'Infectious disease (medical specialty)', 'Nursing', 'Social psychology', 'Pathology', 'Virology', 'Economics', 'Macroeconomics']","2019 coronavirus disease, public health, psychological resilience, adverse psychological impacts, psychiatric symptoms, snowball sampling techniques, ##ary, mental health, female gender, student status, myal, dizziness, coryza, hand hygiene"
Paper_01520,The River Continuum Concept,"['Robin L. Vannote', 'G. Wayne Minshall', 'Kenneth W. Cummins', 'James R. Sedell', 'Colbert E. Cushing']",1980,Canadian Journal of Fisheries and Aquatic Sciences,Journal,,130-137,37,1,10.1139/f80-017,"From headwaters to mouth, the physical variables within a river system present a continuous gradient of physical conditions. This gradient should elicit a series of responses within the constituent populations resulting in a continuum of biotic adjustments and consistent patterns of loading, transport, utilization, and storage of organic matter along the length of a river. Based on the energy equilibrium theory of fluvial geomorphologists, we hypothesize that the structural and functional characteristics of stream communities are adapted to conform to the most probable position or mean state of the physical system. We reason that producer and consumer communities characteristic of a given river reach become established in harmony with the dynamic physical conditions of the channel. In natural stream systems, biological communities can be characterized as forming a temporal continuum of synchronized species replacements. This continuous replacement functions to distribute the utilization of energy inputs over time. Thus, the biological system moves towards a balance between a tendency for efficient use of energy inputs through resource partitioning (food, substrate, etc.) and an opposing tendency for a uniform rate of energy processing throughout the year. We theorize that biological communities developed in natural streams assume processing strategies involving minimum energy loss. Downstream communities are fashioned to capitalize on upstream processing inefficiencies. Both the upstream inefficiency (leakage) and the downstream adjustments seem predictable. We propose that this River Continuum Concept provides a framework for integrating predictable and observable biological features of lotic systems. Implications of the concept in the areas of structure, function, and stability of riverine ecosystems are discussed.Key words: river continuum; stream ecosystems; ecosystem structure, function; resource partitioning; ecosystem stability; community succession; river zonation; stream geomorphology","['River ecosystem', 'Environmental science', 'Ecology', 'Fluvial', 'Ecosystem', 'Energy balance', 'Hydrology (agriculture)', 'Structural basin', 'Geology', 'Biology', 'Geomorphology', 'Geotechnical engineering']","biotic adjustments, energy equilibrium theory, fluvial geomorphologist, natural stream systems, biological communities, temporal continuum, synchronized species replacements, resource partitioning, biological communities, natural streams, downstream communities, lot, river continuum, stream ecosystems, ecosystem structure, resource partitioning, ecosystem stability, community succession, river zonation, stream geomorphology"
Paper_01521,Standard methods for the examination of water and waste water.,['F. W. Gilcreas'],1966,American Journal of Public Health and the Nations Health,Journal,,387-388,56,3,10.2105/ajph.56.3.387,"Standard methods for the examination of water and waste water. F W GilcreasCopyRight https://doi.org/10.2105/AJPH.56.3.387 Published Online: August 29, 2011","['Environmental science', 'Waste management', 'Engineering']","waste water, gilcreascopy, [PAD]"
Paper_01522,Convex Analysis,['R. T. Rockafellar'],1970,Princeton University Press eBooks,Unknown,,,,,10.1515/9781400873173,"Available for the first time in paperback, R. Tyrrell Rockafellar's classic study presents readers with a coherent branch of nonlinear mathematical analysis that is especially suited to the study of optimization problems. Rockafellar's theory differs from classical analysis in that differentiability assumptions are replaced by convexity assumptions. The topics treated in this volume include: systems of inequalities, the minimum or maximum of a convex function over a convex set, Lagrange multipliers, minimax theorems and duality, as well as basic results about the structure of convex sets and the continuity and differentiability of convex functions and saddle- functions. This book has firmly established a new and vital area not only for pure mathematics but also for applications to economics and engineering. A sound knowledge of linear algebra and introductory real analysis should provide readers with sufficient background for this book. There is also a guide for the reader who may be using the book as an introduction, indicating which parts are essential and which may be skipped on a first reading.","['Convexity', 'Convex analysis', 'Mathematics', 'Differentiable function', 'Convex function', 'Duality (order theory)', 'Convex optimization', 'Nonlinear programming', 'Proper convex function', 'Convex set', 'Minimax', 'Saddle point', 'Function (biology)', 'Linear algebra', 'Saddle', 'Algebra over a field', 'Regular polygon', 'Applied mathematics', 'Mathematical optimization', 'Pure mathematics', 'Nonlinear system', 'Physics', 'Geometry', 'Quantum mechanics', 'Evolutionary biology', 'Financial economics', 'Economics', 'Biology']","nonlinear mathematical analysis, optimization problems, classical analysis, differentiability assumptions, convexity assumptions, inequalities, convex function, convex, lagrange multipliers, minimax theorems, duality, convex sets, ##bility, linear algebra, introductory real analysis, [PAD], [PAD], [PAD] [PAD], [PAD] [PAD], [PAD] [PAD], [PAD], [PAD], [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD], [PAD] [PAD], [PAD] [PAD], [PAD] [PAD] [PAD], [PAD] [PAD], [PAD], [PAD], [PAD] [PAD], [PAD] [PAD], [PAD] [PAD] [PAD] [PAD], [PAD] [PAD], [PAD], [PAD] [PAD], [PAD] [PAD], [PAD] [PAD] [PAD]"
Paper_01524,TCS: a computer program to estimate gene genealogies,"['Mark Clement', 'David Posada', 'Keith A. Crandall']",2000,Molecular Ecology,Journal,,1657-1659,9,10,10.1046/j.1365-294x.2000.01020.x,"Phylogenies are extremely useful tools, not only for establishing genealogical relationships among a group of organisms or their parts (e.g. genes), but also for a variety of research once the phylogenies are estimated. In a recent review, Pagel (1999) eloquently outline a number of uses for phylogenetic information from discovery of drug resistance to reconstructing the common ancestor to all of life. Phylogenies have been used to predict future trends in infectious disease ( Bush et al. 1999 ) and have even been offered as evidence in a court of law ( Vogel 1997). Yet phylogenies are only as useful as they are accurate. Estimating genealogical relationships among genes at the population level presents a number of difficulties to traditional methods of phylogeny reconstruction. These traditional methods such as parsimony, neighbour-joining, and maximum-likelihood make assumptions that are invalid at the population level. For example, these methods assume ancestral haplotypes are no longer in the population, yet coalescent theory predicts that ancestral haplotypes will be the most frequent sequences sampled in a population level study ( Watterson & Guess 1977; Donnelly & Tavaré 1986; Crandall & Templeton 1993). Traditional methods require reasonably large numbers of variable characters to accurately reconstruct relationships ( Huelsenbeck & Hillis 1993) and population level studies typically lack such variation. Also, recombination is a real possibility among sequences at the population level and traditional methods assume recombination does not occur. The failure to incorporate the possibility of recombination in phylogeny reconstruction can lead to grave errors in the resulting estimated phylogeny. The combination of these effects can lead parsimony methods to infer a cumbersome amount of most parsimonious trees at the population level with no resolution among the set (e.g. over one billion trees for a set of human mitochondrial DNA (mtDNA), Excoffier & Smouse 1994). These effects can also lead neighbour-joining and traditional maximum-likelihood methods to be over confident in the resulting relationships ( Bandelt et al. 1995 ). Therefore, an alternative approach is needed to provide accurate estimates of gene genealogies at the population level that take into account these population level phenomena not addressed by traditional methods. Multiple groups have looked to network representations for population level genealogical information ( Bandelt & Dress 1992; Templeton et al. 1992 ; Excoffier & Smouse 1994; Fitch 1997). Networks allow one to naturally incorporate the often-times nonbifurcating genealogical information associated with population level divergences. The method of Templeton et al. (1992) (TCS) has been used extensively with restriction site and nucleotide sequence data to infer population level genealogies when divergences are low ( Georgiadis et al. 1994 ; Routman et al. 1994 ; Gerber & Templeton 1996; Hedin 1997; Schaal et al. 1998 ; Viláet al. 1999 , Gómez-Zurita et al. 2000). TCS has been used with traditional methods to estimate relationships among organisms that span a wide range of divergence ( Crandall & Fitzpatrick 1996; Benabib et al. 1997 ). The approach has also been used extensively with a nested analysis procedure to partition population structure from population history ( Templeton et al. 1995 ; Templeton 1998) and explore the phylogeographic history of a diversity of organisms (e.g. Johnson & Jordon 2000; Turner et al. 2000 ). In this note, we announce the availability of a new software package, TCS, to estimate genealogical relationships among sequences using the method of Templeton et al. (1992) . The TCS software opens nucleotide sequence files in either nexus ( Maddison et al. 1997 ) or phylip ( Felsenstein 1991) sequential format. Sequences should not be collapsed into haplotypes as frequency data can be incorporated into the output. The program collapses sequences into haplotypes and calculates the frequencies of the haplotypes in the sample. These frequencies are used to estimate haplotype outgroup probabilities, which correlate with haplotype age ( Donnelly & Tavaré 1986; Castelloe & Templeton 1994). An absolute distance matrix is then calculated for all pairwise comparisons of haplotypes. The probability of parsimony [as defined in Templeton et al. (1992) , equations 6, 7, and 8] is calculated for pairwise differences until the probability exceeds 0.95. The number of mutational differences associated with the probability just before this 95% cut-off is then the maximum number of mutational connections between pairs of sequences justified by the 'parsimony' criterion. These justified connections are then made resulting in a 95% set of plausible solutions. The program outputs the sequences, the pairwise absolute distance matrix, probabilities of parsimony for mutational steps just beyond the 95% cut-off, a test listing of connections made and missing intermediates generated, and a graph output file containing the resulting network ( Fig. 1). This graph output file can be opened in the freeware VGJ 1.0.3 ( http://www.eng.auburn.edu/department/cse/research/graphdrawing/graphdrawing.html; distributed under the terms of the GNU General Public License, Version 2), which is packaged with the TCS algorithm. The program can handle a reasonable number of sequences. For example, an HTLV data set with 69 haplotypes of length 725 bp took over one hour to run in a Macintosh G3. Memory requirements are low, and the program will run with less than 1 MB RAM. The TCS software package, including executables for Mac and PC, documentation, and Java source code, is distributed freely and is available at our website, along with a host of other programs for population genetic and phylogenetic analyses: http://bioag.byu.edu/zoology/crandalllab/programs.htm. TCS Java interface. The maximum number of steps connecting parsimoniously two haplotypes is indicated. Gaps can be treated as a 5th state or as missing data. The graph can be edited and arranged using different algorithms. By double-clicking over a haplotype, some information is displayed, such as sequences included in the haplotype and outgroup weights. The haplotype with the highest outgroup probability is displayed as a square, while other haplotypes are displayed as ovals. The size of the square or oval corresponds to the haplotype frequency. This work was supported by the Alfred P. Sloan Foundation, a Shannon Award from the National Institutes of Health, and NIH R01-HD34350.","['Coalescent theory', 'Biology', 'Phylogenetic tree', 'Phylogenetics', 'Population', 'Evolutionary biology', 'Genealogy', 'Maximum parsimony', 'Genetics', 'Gene', 'Demography', 'Clade', 'History', 'Sociology']","phylogenies, genealogical relationships, phylogenetic information, drug resistance, infectious disease, phylogeny reconstruction, parsimony, ancestral haplotypes, coal, ##cent, ancestral haplotypes, recombination, recombination, ##bination, phylogeny reconstruction, parsimony, human mitochondrial dna, network representations, ex"
Paper_01528,Selection of Conserved Blocks from Multiple Alignments for Their Use in Phylogenetic Analysis,['José Castresana'],2000,Molecular Biology and Evolution,Journal,,540-552,17,4,10.1093/oxfordjournals.molbev.a026334,"The use of some multiple-sequence alignments in phylogenetic analysis, particularly those that are not very well conserved, requires the elimination of poorly aligned positions and divergent regions, since they may not be homologous or may have been saturated by multiple substitutions. A computerized method that eliminates such positions and at the same time tries to minimize the loss of informative sites is presented here. The method is based on the selection of blocks of positions that fulfill a simple set of requirements with respect to the number of contiguous conserved positions, lack of gaps, and high conservation of flanking positions, making the final alignment more suitable for phylogenetic analysis. To illustrate the efficiency of this method, alignments of 10 mitochondrial proteins from several completely sequenced mitochondrial genomes belonging to diverse eukaryotes were used as examples. The percentages of removed positions were higher in the most divergent alignments. After removing divergent segments, the amino acid composition of the different sequences was more uniform, and pairwise distances became much smaller. Phylogenetic trees show that topologies can be different after removing conserved blocks, particularly when there are several poorly resolved nodes. Strong support was found for the grouping of animals and fungi but not for the position of more basal eukaryotes. The use of a computerized method such as the one presented here reduces to a certain extent the necessity of manually editing multiple alignments, makes the automation of phylogenetic analysis of large data sets feasible, and facilitates the reproduction of the final alignment by other researchers.","['Phylogenetic tree', 'Biology', 'Pairwise comparison', 'Multiple sequence alignment', 'Conserved sequence', 'Selection (genetic algorithm)', 'Phylogenetic network', 'Computational biology', 'Sequence alignment', 'Set (abstract data type)', 'Genome', 'Phylogenetics', 'Genetics', 'Evolutionary biology', 'Alignment-free sequence analysis', 'Gene', 'Computer science', 'Peptide sequence', 'Artificial intelligence', 'Programming language']","phylogenetic analysis, divergent regions, flanking positions, phylogenetic analysis, mitochondrial proteins, mitochondrial genomes, amino, pairwise distances, phylogenetic trees, fungi, phylogenetic analysis"
Paper_01530,"Cancer Statistics, 2009","['Ahmedin Jemal', 'Rebecca L. Siegel', 'Elizabeth Ward', 'Yongping Hao', 'Jianfeng Xu', 'M. J. Thun']",2009,CA A Cancer Journal for Clinicians,Journal,,225-249,59,4,10.3322/caac.20006,"Each year, the American Cancer Society estimates the number of new cancer cases and deaths expected in the United States in the current year and compiles the most recent data on cancer incidence, mortality, and survival based on incidence data from the National Cancer Institute, Centers for Disease Control and Prevention, and the North American Association of Central Cancer Registries and mortality data from the National Center for Health Statistics. Incidence and death rates are standardized by age to the 2000 United States standard million population. A total of 1,479,350 new cancer cases and 562,340 deaths from cancer are projected to occur in the United States in 2009. Overall cancer incidence rates decreased in the most recent time period in both men (1.8% per year from 2001 to 2005) and women (0.6% per year from 1998 to 2005), largely because of decreases in the three major cancer sites in men (lung, prostate, and colon and rectum [colorectum]) and in two major cancer sites in women (breast and colorectum). Overall cancer death rates decreased in men by 19.2% between 1990 and 2005, with decreases in lung (37%), prostate (24%), and colorectal (17%) cancer rates accounting for nearly 80% of the total decrease. Among women, overall cancer death rates between 1991 and 2005 decreased by 11.4%, with decreases in breast (37%) and colorectal (24%) cancer rates accounting for 60% of the total decrease. The reduction in the overall cancer death rates has resulted in the avoidance of about 650,000 deaths from cancer over the 15-year period. This report also examines cancer incidence, mortality, and survival by site, sex, race/ethnicity, education, geographic area, and calendar year. Although progress has been made in reducing incidence and mortality rates and improving survival, cancer still accounts for more deaths than heart disease in persons younger than 85 years of age. Further progress can be accelerated by applying existing cancer control knowledge across all segments of the population and by supporting new discoveries in cancer prevention, early detection, and treatment.","['Medicine', 'Cancer', 'Colorectal cancer', 'Prostate cancer', 'Lung cancer', 'Breast cancer', 'Incidence (geometry)', 'Population', 'Mortality rate', 'Cancer registry', 'Demography', 'Cause of death', 'Disease', 'Internal medicine', 'Environmental health', 'Physics', 'Sociology', 'Optics']","american cancer society, central cancer registries, women, women, cancer control, early detection"
Paper_01470,Anomaly detection,"['Varun Chandola', 'Arindam Banerjee', 'Vipin Kumar']",2009,ACM Computing Surveys,Journal,,1-58,41,3,10.1145/1541880.1541882,"Anomaly detection is an important problem that has been researched within diverse research areas and application domains. Many anomaly detection techniques have been specifically developed for certain application domains, while others are more generic. This survey tries to provide a structured and comprehensive overview of the research on anomaly detection. We have grouped existing techniques into different categories based on the underlying approach adopted by each technique. For each category we have identified key assumptions, which are used by the techniques to differentiate between normal and anomalous behavior. When applying a given technique to a particular domain, these assumptions can be used as guidelines to assess the effectiveness of the technique in that domain. For each category, we provide a basic anomaly detection technique, and then show how the different existing techniques in that category are variants of the basic technique. This template provides an easier and more succinct understanding of the techniques belonging to each category. Further, for each category, we identify the advantages and disadvantages of the techniques in that category. We also provide a discussion on the computational complexity of the techniques since it is an important issue in real application domains. We hope that this survey will provide a better understanding of the different directions in which research has been done on this topic, and how techniques developed in one area can be applied in domains for which they were not intended to begin with.","['Computer science', 'Anomaly detection', 'Domain (mathematical analysis)', 'Key (lock)', 'Anomaly (physics)', 'Data mining', 'Data science', 'Artificial intelligence', 'Machine learning', 'Mathematics', 'Mathematical analysis', 'Physics', 'Computer security', 'Condensed matter physics']","anomaly detection, anomaly detection techniques, anomaly detection, anomalous behavior, anomaly detection technique, computational complexity"
Paper_01471,The Design and Analysis of Computer Algorithms,"['Alfred V. Aho', 'John E. Hopcroft']",1974,['Choice Reviews Online'],Unknown,,50-1513-50-1513,50,03,10.5860/choice.50-1513,"From the Publisher:
With this text, you gain an understanding of the fundamental concepts of algorithms, the very heart of computer science. It introduces the basic data structures and programming techniques often used in efficient algorithms. Covers use of lists, push-down stacks, queues, trees, and graphs. Later chapters go into sorting, searching and graphing algorithms, the string-matching algorithms, and the Schonhage-Strassen integer-multiplication algorithm. Provides numerous graded exercises at the end of each chapter.


0201000296B04062001","['Computer science', 'Strassen algorithm', 'Sorting', 'String (physics)', 'Sorting algorithm', 'Theoretical computer science', 'Algorithm', 'String searching algorithm', 'Matching (statistics)', 'Data structure', 'Programming language', 'Mathematics', 'Matrix multiplication', 'Statistics', 'Physics', 'Quantum mechanics', 'Mathematical physics', 'Quantum']","algorithms, computer science, data structures, programming techniques, efficient algorithms, queues, trees, graphs, graphing algorithms, graded exercises, [PAD] [PAD], [PAD] [PAD], [PAD], [PAD] [PAD], [PAD], [PAD]"
Paper_01472,Reflecting on reflexive thematic analysis,"['Virginia Braun', 'Victoria Clarke']",2019,Qualitative Research in Sport Exercise and Health,Journal,,589-597,11,4,10.1080/2159676x.2019.1628806,"Since initially writing on thematic analysis in 2006, the popularity of the method we outlined has exploded, the variety of TA approaches have expanded, and, not least, our thinking has developed and shifted. In this reflexive commentary, we look back at some of the unspoken assumptions that informed how we wrote our 2006 paper. We connect some of these un-identified assumptions, and developments in the method over the years, with some conceptual mismatches and confusions we see in published TA studies. In order to facilitate better TA practice, we reflect on how our thinking has evolved – and in some cases sedimented – since the publication of our 2006 paper, and clarify and revise some of the ways we phrased or conceptualised TA, and the elements of, and processes around, a method we now prefer to call reflexive TA.","['Reflexivity', 'Popularity', 'Variety (cybernetics)', 'Epistemology', 'Thematic analysis', 'Thematic map', 'Order (exchange)', 'Sociology', 'Computer science', 'Data science', 'Psychology', 'Qualitative research', 'Philosophy', 'Social science', 'Social psychology', 'Cartography', 'Artificial intelligence', 'Geography', 'Business', 'Finance']","thematic analysis, ta, reflexive commentary, ta, reflexive ta, [PAD], [PAD] [PAD] [PAD]"
Paper_01473,"Analysis of protein-coding genetic variation in 60,706 humans","['Monkol Lek', 'Konrad J. Karczewski', 'Eric Vallabh Minikel', 'Kaitlin E. Samocha', 'Eric Banks', 'Timothy R. Fennell', 'Anne O’Donnell‐Luria', 'James S. Ware', 'Andrew Hill', 'Beryl B. Cummings', 'Taru Tukiainen', 'Daniel P. Birnbaum', 'Jack A. Kosmicki', 'Laramie E. Duncan', 'Karol Estrada', 'Fengmei Zhao', 'James Zou', 'Emma Pierce‐Hoffman', 'Joanne Berghout', 'D.N. Cooper', 'Nicole Deflaux', 'Mark A. DePristo', 'Ron Do', 'Jason Flannick', 'Menachem Fromer', 'Laura D. Gauthier', 'Jackie Goldstein', 'Namrata Gupta', 'Daniel P. Howrigan', 'Adam Kieżun', 'Mitja Kurki', 'Ami Levy Moonshine', 'Pradeep Natarajan', 'Lorena Orozco', 'Gina M. Peloso', 'Ryan Poplin', 'Manuel A. Rivas', 'Valentín Ruano-Rubio', 'Samuel A. Rose', 'Douglas M. Ruderfer', 'Khalid Shakir', 'Peter D. Stenson', 'Christine Stevens', 'Brett Thomas', 'Grace Tiao', 'Maria T. Tusie-Luna', 'Ben Weisburd', 'Hong‐Hee Won', 'Dongmei Yu', 'David Altshuler', 'Diego Ardissino', 'Michael Boehnke', 'John Danesh', 'Stacey Donnelly', 'Roberto Elosúa', 'José C. Florez', 'Stacey Gabriel', 'Gad Getz', 'Stephen J. Glatt', 'Christina M. Hultman', 'Sekar Kathiresan', 'Markku Laakso', 'Steven A. McCarroll', 'Mark I. McCarthy', 'Dermot McGovern', 'Ruth McPherson', 'Benjamin M. Neale', 'Aarno Palotie', 'Shaun Purcell', 'Danish Saleheen', 'Jeremiah M. Scharf', 'Pamela Sklar', 'Patrick F. Sullivan', 'Jaakko Tuomilehto', 'Ming T. Tsuang', 'Hugh Watkins', 'James G. Wilson', 'Mark J. Daly', 'Daniel G. MacArthur']",2016,Nature,Journal,,285-291,536,7616,10.1038/nature19057,"Large-scale reference data sets of human genetic variation are critical for the medical and functional interpretation of DNA sequence changes. Here we describe the aggregation and analysis of high-quality exome (protein-coding region) DNA sequence data for 60,706 individuals of diverse ancestries generated as part of the Exome Aggregation Consortium (ExAC). This catalogue of human genetic diversity contains an average of one variant every eight bases of the exome, and provides direct evidence for the presence of widespread mutational recurrence. We have used this catalogue to calculate objective metrics of pathogenicity for sequence variants, and to identify genes subject to strong selection against various classes of mutation; identifying 3,230 genes with near-complete depletion of predicted protein-truncating variants, with 72% of these genes having no currently established human disease phenotype. Finally, we demonstrate that these data can be used for the efficient filtering of candidate disease-causing variants, and for the discovery of human 'knockout' variants in protein-coding genes. Exome sequencing data from 60,706 people of diverse geographic ancestry is presented, providing insight into genetic variation across populations, and illuminating the relationship between DNA variants and human disease. As part of the Exome Aggregation Consortium (ExAC) project, Daniel MacArthur and colleagues report on the generation and analysis of high-quality exome sequencing data from 60,706 individuals of diverse ancestry. This provides the most comprehensive catalogue of human protein-coding genetic variation to date, yielding unprecedented resolution for the analysis of very rare variants across multiple human populations. The catalogue is freely accessible and provides a critical reference panel for the clinical interpretation of genetic variants and the discovery of disease-related genes.","['Variation (astronomy)', 'Genetic variation', 'Coding (social sciences)', 'Evolutionary biology', 'Computational biology', 'Biology', 'Genetics', 'Statistics', 'Gene', 'Mathematics', 'Physics', 'Astrophysics']","human genetic variation, dna, diverse ancestries, exome aggregation consortium, ##ac, human genetic diversity, pathogen, human, exome aggregation consortium"
Paper_01475,The Elastic Behaviour of a Crystalline Aggregate,['R. Hill'],1952,Proceedings of the Physical Society Section A,Journal,,349-354,65,5,10.1088/0370-1298/65/5/307,"The connection between the elastic behaviour of an aggregate and a single crystal is considered, with special reference to the theories of Voigt, Reuss, and Huber and Schmid. The elastic limit under various stress systems is also considered, in particular, it is shown that the tensile elastic limit of a face-centred aggregate cannot exceed two-thirds of the stress at which pronounced plastic distortion occurs.","['Aggregate (composite)', 'Limit (mathematics)', 'Distortion (music)', 'Connection (principal bundle)', 'Stress (linguistics)', 'Elasticity (physics)', 'Ultimate tensile strength', 'Materials science', 'Classical mechanics', 'Mechanics', 'Mathematics', 'Physics', 'Composite material', 'Mathematical analysis', 'Geometry', 'Philosophy', 'Amplifier', 'Linguistics', 'Optoelectronics', 'CMOS']","elastic behaviour, elastic limit, stress systems, tensile elastic limit, plastic distortion"
Paper_01477,Usability Engineering,['Jakob Nielsen'],1993,['it - Information Technology'],Unknown,,3-4,44,1,10.1524/itit.2002.44.1.003,"From the Publisher:
Written by the author of the best-selling HyperText & HyperMedia, this book provides an excellent guide to the methods of usability engineering. Special features: emphasizes cost-effective methods that will help developers improve their user interfaces immediately, shows you how to avoid the four most frequently listed reasons for delay in software projects, provides step-by-step information about which methods to use at various stages during the development life cycle, and offers information on the unique issues relating to informational usability. You do not need to have previous knowledge of usability to implement the methods provided, yet all of the latest research is covered.","['Usability', 'Computer science', 'Hypermedia', 'Hypertext', 'Usability engineering', 'Usability inspection', 'World Wide Web', 'Software engineering', 'Web usability', 'Human–computer interaction']","hypertext, hypermedia, usability engineering, user interfaces, informational usability"
Paper_01480,Review: Knowledge Management and Knowledge Management Systems: Conceptual Foundations and Research Issues,"['Maryam Alavi', 'Dorothy E. Leidner']",2001,MIS Quarterly,Journal,,107-107,25,1,10.2307/3250961,"Knowledge is a broad and abstract notion that has defined epistemological debate in western philosophy since the classical Greek era. In the past few years, however, there has been a growing interest in treating knowledge as a significant organizational resource. Consistent with the interest in organizational knowledge and knowledge management (KM), IS researchers have begun promoting a class of information systems, referred to as knowledge management systems (KMS). The objective of KMS is to support creation, transfer, and application of knowledge in organizations. Knowledge and knowledge management are complex and multi-faceted concepts. Thus, effective development and implementation of KMS requires a foundation in several rich literatures.","['Knowledge management', 'Personal knowledge management', 'Business', 'Management science', 'Computer science', 'Process management', 'Organizational learning', 'Engineering']","knowledge, epistemological, knowledge, organizational resource, organizational knowledge, knowledge management, information systems, knowledge management systems, knowledge management"
Paper_01483,Computer Architecture: A Quantitative Approach,"['John L. Hennessy', 'David A. Patterson']",1989,['Microelectronics Journal'],Unknown,,157-158,24,1-2,10.1016/0026-2692(93)90111-q,"This best-selling title, considered for over a decade to be essential reading for every serious student and practitioner of computer design, has been updated throughout to address the most important trends facing computer designers today. In this edition, the authors bring their trademark method of quantitative analysis not only to high-performance desktop machine design, but also to the design of embedded and server systems. They have illustrated their principles with designs from all three of these domains, including examples from consumer electronics, multimedia and Web technologies, and high-performance computing.","['Computer science', 'Trademark', 'Reading (process)', 'Architecture', 'Multimedia', 'Electronics', 'World Wide Web', 'Software engineering', 'Engineering', 'Operating system', 'Art', 'Electrical engineering', 'Political science', 'Law', 'Visual arts']","computer design, computer designers, quantitative analysis, embedded, server systems, consumer electronics, multimedia, web technologies"
Paper_01485,"Total Carbon, Organic Carbon, and Organic Matter","['D. W. Nelson', 'L. E. Sommers']",2013,Soil Science Society of America book series,Unknown,,961-1010,,,10.2136/sssabookser5.3.c34,"Total carbon (C) in soils is the sum of both organic and inorganic C. Organic C is present in the soil organic matter fraction, whereas inorganic C is largely found in carbonate minerals. The wet combustion analysis of soils by chromic acid digestion has long been a standard method for determining total C, giving results in good agreement with dry combustion. Methods for total C are basic for many of the procedures used to determine organic C in soils. In contrast to noncalcareous soils, inorganic C must be removed from calcareous or limed soils before the analysis if wet or dry combustion techniques are used to directly measure the organic C present. The organic matter content of soil may be indirectly estimated through multiplication of the organic C concentration by the ratio of organic matter to organic C commonly found in soils.","['Total organic carbon', 'Organic matter', 'Soil water', 'Environmental chemistry', 'Chemistry', 'Soil organic matter', 'Carbon fibers', 'Soil carbon', 'Combustion', 'Carbonate', 'Environmental science', 'Soil science', 'Materials science', 'Organic chemistry', 'Composite number', 'Composite material']","total carbon, soils, organic, soil organic matter fraction, inorganic, carbonate minerals, wet combustion analysis, soils, chromic acid digestion, dry combustion, noncalcareous soils, inorganic, lime, dry combustion, organic matter content, soils"
Paper_01486,"Descartes' Error: Emotion, Reason, and the Human Brain",['António R. Damásio'],1994,['JAMA: The Journal of the American Medical Association'],Unknown,,1463,273,18,10.1001/jama.1995.03520420079045,"Descartes' Error offers the scientific basis for ending the division between mind and body. Antonio Damasio contends that rational decisions are not the product of logic alone - they require the support of emotion and feeling. Drawing on his experience with neurological patients affected with brain damage, Dr Damasio shows how absence of emotions and feelings can break down rationality. He also offers a new perspective on what emotions and feelings actually are: a direct view of our own body states; a link between the body and its survival-oriented regulation on the one hand, and consciousness on the other. Written as a conversation between the author and an imaginary listener, Descartes' Error leads us to conclude that human organisms are endowed from their very beginning with a spirited passion for making choices, which the social mind can then use to build rational behaviour.","['Feeling', 'Rationality', 'Psychology', 'Consciousness', 'Perspective (graphical)', 'Passion', 'Conversation', 'Expression (computer science)', 'Epistemology', 'Cognitive psychology', 'Social psychology', 'Cognitive science', 'Philosophy', 'Communication', 'Neuroscience', 'Computer science', 'Artificial intelligence', 'Programming language']","rational decisions, neurological patients, brain damage, rational, social mind, rational"
Paper_01487,Gephi: An Open Source Software for Exploring and Manipulating Networks,"['Mathieu Bastian', 'Sébastien Heymann', 'Mathieu Jacomy']",2009,Proceedings of the International AAAI Conference on Web and Social Media,Journal,,361-362,3,1,10.1609/icwsm.v3i1.13937,"Gephi is an open source software for graph and network analysis. It uses a 3D render engine to display large networks in real-time and to speed up the exploration. A flexible and multi-task architecture brings new possibilities to work with complex data sets and produce valuable visual results. We present several key features of Gephi in the context of interactive exploration and interpretation of networks. It provides easy and broad access to network data and allows for spatializing, filtering, navigating, manipulating and clustering. Finally, by presenting dynamic features of Gephi, we highlight key aspects of dynamic network visualization.","['Computer science', 'Visualization', 'Key (lock)', 'Software', 'Software visualization', 'Context (archaeology)', 'Open source', 'Open source software', 'Graph', 'Software system', 'Component-based software engineering', 'Data mining', 'Theoretical computer science', 'Operating system', 'Paleontology', 'Biology']","gephi, network analysis, 3d render engine, gephi, interactive exploration, spatial, na, clustering, gephi, dynamic network visualization, [PAD], [PAD], [PAD] [PAD] [PAD], [PAD], [PAD]"
Paper_01488,Statistical parametric maps in functional imaging: A general linear approach,"['Karl Friston', 'Andrew P. Holmes', 'Keith J. Worsley', 'J.‐P. Poline', 'Chris Frith', 'R. S. J. Frackowiak']",1994,Human Brain Mapping,Journal,,189-210,2,4,10.1002/hbm.460020402,"Abstract Statistical parametric maps are spatially extended statistical processes that are used to test hypotheses about regionally specific effects in neuroimaging data. The most established sorts of statistical parametric maps (e.g., Friston et al. [1991]: J Cereb Blood Flow Metab 11:690–699; Worsley et al. [1992]: J Cereb Blood Flow Metab 12:900–918) are based on linear models, for example ANCOVA, correlation coefficients and t tests. In the sense that these examples are all special cases of the general linear model it should be possible to implement them (and many others) within a unified framework. We present here a general approach that accomodates most forms of experimental layout and ensuing analysis (designed experiments with fixed effects for factors, covariates and interaction of factors). This approach brings together two well established bodies of theory (the general linear model and the theory of Gaussian fields) to provide a complete and simple framework for the analysis of imaging data. The importance of this framework is twofold: (i) Conceptual and mathematical simplicity, in that the same small number of operational equations is used irrespective of the complexity of the experiment or nature of the statistical model and (ii) the generality of the framework provides for great latitude in experimental design and analysis. © 1995 Wiley‐Liss, Inc.","['Generality', 'Parametric statistics', 'General linear model', 'Computer science', 'Linear model', 'Statistical parametric mapping', 'Statistical hypothesis testing', 'Gaussian', 'Simple (philosophy)', 'Statistical model', 'Generalized linear model', 'Applied mathematics', 'Algorithm', 'Mathematics', 'Artificial intelligence', 'Statistics', 'Machine learning', 'Psychology', 'Medicine', 'Philosophy', 'Physics', 'Radiology', 'Epistemology', 'Quantum mechanics', 'Magnetic resonance imaging', 'Psychotherapist']","abstract statistical parametric maps, spatially extended statistical processes, neuroimaging data, statistical parametric maps, linear models, ancova, correlation coefficients, t tests, fixed effects, covariates, general linear model, gaussian fields, operational equations"
Paper_01491,Observation of a new boson at a mass of 125 GeV with the CMS experiment at the LHC,"['S. Chatrchyan', 'V. Khachatryan', 'A. M. Sirunyan', 'A. Tumasyan', 'W. Adam', 'E. Aguiló', 'T. Bergauer', 'M. Dragicevic', 'J. Erö', 'C. Fabjan', 'M. Friedl', 'R. Frühwirth', 'V. M. Ghete', 'J. Hammer', 'M. Hoch', 'N. Hörmann', 'J. Hrubec', 'M. Jeitler', 'W. Kiesenhofer', 'V. Knünz', 'M. Krammer', 'I. Krätschmer', 'D. Liko', 'W. Majerotto', 'I. Mikulec', 'M. Pernicka', 'B. Rahbaran', 'C. Rohringer', 'H. Rohringer', 'R. Schöfbeck', 'J. Strauss', 'F. Szoncsó', 'A. Taurok', 'W. Waltenberger', 'G. Walzel', 'E. Widl', 'C.-E. Wulz', 'V. Chekhovsky', 'I. Emeliantchik', 'A. Litomin', 'В. Макаренко', 'V. Mossolov', 'N. Shumeiko', 'A. Solin', 'R. Stefanovitch', 'J. Suarez Gonzalez', 'A. Fedorov', 'M. Korzhik', 'O. Missevitch', 'R. Zuyeuski', 'M. Bansal', 'S. Bansal', 'W. Worby Beaumont', 'T. Cornelis', 'E. A. De Wolf', 'D. Druzhkin', 'X. Janssen', 'S. Luyckx', 'L. Mucibello', 'S. Ochesanu', 'B. Roland', 'R. Rougny', 'M. Selvaggi', 'Z. Staykova', 'H. Van Haevermaet', 'P. Van Mechelen', 'N. Van Remortel', 'A. Van Spilbeeck', 'F. Blekman', 'S. Blyweert', 'J. D’Hondt', 'O. Devroede', 'R. Gonzalez Suarez', 'R. Goorens', 'A. Kalogeropoulos', 'M. Maes', 'A. Olbrechts', 'S. Tavernier', 'W. Van Doninck', 'L. Van Lancker', 'P. Van Mulders', 'G. P. Van Onsem', 'I. Villella', 'B. Clerbaux', 'G. De Lentdecker', 'V. Dero', 'J.‐P. Dewulf', 'A. P. R. Gay', 'T. Hreus', 'A. Léonard', 'P. Marage', 'A. Mohammadi', 'T. Reis', 'S. Rugovac', 'Laurent Thomas', 'C. Vander Velde', 'P. Vanlaer', 'J. Wang', 'J.H. Wickens', 'V. Adler']",2012,Physics Letters B,Journal,,30-61,716,1,10.1016/j.physletb.2012.08.021,"Results are presented from searches for the standard model Higgs boson in proton-proton collisions at sqrt(s) = 7 and 8 TeV in the Compact Muon Solenoid experiment at the LHC, using data samples corresponding to integrated luminosities of up to 5.1 inverse femtobarns at 7 TeV and 5.3 inverse femtobarns at 8 TeV. The search is performed in five decay modes: gamma gamma, ZZ, WW, tau tau, and b b-bar. An excess of events is observed above the expected background, with a local significance of 5.0 standard deviations, at a mass near 125 GeV, signalling the production of a new particle. The expected significance for a standard model Higgs boson of that mass is 5.8 standard deviations. The excess is most significant in the two decay modes with the best mass resolution, gamma gamma and ZZ; a fit to these signals gives a mass of 125.3 +/- 0.4 (stat.) +/- 0.5 (syst.) GeV. The decay to two photons indicates that the new particle is a boson with spin different from one.","['Physics', 'Particle physics', 'Compact Muon Solenoid', 'Higgs boson', 'Large Hadron Collider', 'Standard Model (mathematical formulation)', 'Nuclear physics', 'Inverse', 'Boson', 'Muon', 'Luminosity', 'Physics beyond the Standard Model', 'Photon', 'Bar (unit)', 'Astrophysics', 'Geometry', 'Mathematics', 'Archaeology', 'Gauge (firearms)', 'History', 'Quantum mechanics', 'Galaxy', 'Meteorology']","compact muon solenoid experiment, integrated luminosities, gamma gamma, tau tau, gamma gamma"
Paper_01492,Automatic Recording Apparatus for Use in Chromatography of Amino Acids,"['D. Spackman', 'William H. Stein', 'Stanford Moore']",1958,Analytical Chemistry,Journal,,1190-1206,30,7,10.1021/ac60139a006,"ADVERTISEMENT RETURN TO ISSUEPREVArticleNEXTAutomatic Recording Apparatus for Use in Chromatography of Amino AcidsD. H. Spackman, W. H. Stein, and Stanford. MooreCite this: Anal. Chem. 1958, 30, 7, 1190–1206Publication Date (Print):July 1, 1958Publication History Published online1 May 2002Published inissue 1 July 1958https://pubs.acs.org/doi/10.1021/ac60139a006https://doi.org/10.1021/ac60139a006research-articleACS PublicationsRequest reuse permissionsArticle Views3221Altmetric-Citations7629LEARN ABOUT THESE METRICSArticle Views are the COUNTER-compliant sum of full text article downloads since November 2008 (both PDF and HTML) across all institutions and individuals. These metrics are regularly updated to reflect usage leading up to the last few days.Citations are the number of other articles citing this article, calculated by Crossref and updated daily. Find more information about Crossref citation counts.The Altmetric Attention Score is a quantitative measure of the attention that a research article has received online. Clicking on the donut icon will load a page at altmetric.com with additional details about the score and the social media presence for the given article. Find more information on the Altmetric Attention Score and how the score is calculated. Share Add toView InAdd Full Text with ReferenceAdd Description ExportRISCitationCitation and abstractCitation and referencesMore Options Share onFacebookTwitterWechatLinked InRedditEmail Other access optionsGet e-Alertsclose Get e-Alerts","['Altmetrics', 'Citation', 'Icon', 'Social media', 'Computer science', 'Information retrieval', 'Reuse', 'World Wide Web', 'Library science', 'Engineering', 'Programming language', 'Waste management']","##varticlenextautomatic recording apparatus, chromatography, amino, permissionsarticle, ##le, altmetric attention score, social, altmetric attention score, ##riscitation, abstract, ##ation, references"
Paper_01493,Design and validation of a histological scoring system for nonalcoholic fatty liver disease†,"['David E. Kleiner', 'Elizabeth M. Brunt', 'Mark L. Van Natta', 'Cynthia Behling', 'Melissa J. Contos', 'Oscar W. Cummings', 'Linda D. Ferrell', 'Yao‐Chang Liu', 'Michael Torbenson', 'Aynur Ünalp–Arida', 'Matthew M. Yeh', 'Arthur J. McCullough', 'Arun J. Sanyal']",2005,Hepatology,Journal,,1313-1321,41,6,10.1002/hep.20701,"Nonalcoholic fatty liver disease (NAFLD) is characterized by hepatic steatosis in the absence of a history of significant alcohol use or other known liver disease. Nonalcoholic steatohepatitis (NASH) is the progressive form of NAFLD. The Pathology Committee of the NASH Clinical Research Network designed and validated a histological feature scoring system that addresses the full spectrum of lesions of NAFLD and proposed a NAFLD activity score (NAS) for use in clinical trials. The scoring system comprised 14 histological features, 4 of which were evaluated semi-quantitatively: steatosis (0-3), lobular inflammation (0-2), hepatocellular ballooning (0-2), and fibrosis (0-4). Another nine features were recorded as present or absent. An anonymized study set of 50 cases (32 from adult hepatology services, 18 from pediatric hepatology services) was assembled, coded, and circulated. For the validation study, agreement on scoring and a diagnostic categorization (""NASH,"" ""borderline,"" or ""not NASH"") were evaluated by using weighted kappa statistics. Inter-rater agreement on adult cases was: 0.84 for fibrosis, 0.79 for steatosis, 0.56 for injury, and 0.45 for lobular inflammation. Agreement on diagnostic category was 0.61. Using multiple logistic regression, five features were independently associated with the diagnosis of NASH in adult biopsies: steatosis (P = .009), hepatocellular ballooning (P = .0001), lobular inflammation (P = .0001), fibrosis (P = .0001), and the absence of lipogranulomas (P = .001). The proposed NAS is the unweighted sum of steatosis, lobular inflammation, and hepatocellular ballooning scores. In conclusion, we present a strong scoring system and NAS for NAFLD and NASH with reasonable inter-rater reproducibility that should be useful for studies of both adults and children with any degree of NAFLD. NAS of > or =5 correlated with a diagnosis of NASH, and biopsies with scores of less than 3 were diagnosed as ""not NASH.""","['Nonalcoholic fatty liver disease', 'Internal medicine', 'Medicine', 'Disease', 'Fatty liver', 'Gastroenterology', 'Pathology']","nonalcoholic fatty liver disease, na, hepatic steatosis, nonalcoholic steato, nash clinical research network, histological feature scoring system, na, ##d, steatosis, lobular inflammation, hepatocellular ballooning, fibrosis, adult hepatology services, pediatric hepatology services, diagnostic, weighted kappa statistics, lobular inflammation, multiple logistic regression, adult bio, steatosis, hepatocellular ballooning, lobular inflammation, fibrosis, lipogran, ##weighted, steato, lobular inflammation, ##tocellular ballooning scores, na, nash"
Paper_01494,An Introduction To Compressive Sampling,"['Emmanuel J. Candès', 'Michael B. Wakin']",2008,IEEE Signal Processing Magazine,Journal,,21-30,25,2,10.1109/msp.2007.914731,"Conventional approaches to sampling signals or images follow Shannon's theorem: the sampling rate must be at least twice the maximum frequency present in the signal (Nyquist rate). In the field of data conversion, standard analog-to-digital converter (ADC) technology implements the usual quantized Shannon representation - the signal is uniformly sampled at or above the Nyquist rate. This article surveys the theory of compressive sampling, also known as compressed sensing or CS, a novel sensing/sampling paradigm that goes against the common wisdom in data acquisition. CS theory asserts that one can recover certain signals and images from far fewer samples or measurements than traditional methods use.","['Nyquist–Shannon sampling theorem', 'Compressed sensing', 'Nyquist rate', 'Sampling (signal processing)', 'Computer science', 'SIGNAL (programming language)', 'Oversampling', 'Sampling theory', 'Algorithm', 'Representation (politics)', 'Mathematics', 'Statistics', 'Telecommunications', 'Bandwidth (computing)', 'Computer vision', 'Sample size determination', 'Politics', 'Political science', 'Law', 'Programming language', 'Detector']","sampling, nyquist rate, data conversion, quantized shannon representation, nyquist rate, compressive sampling, compressed sensing, data acquisition, [PAD], [PAD], [PAD] [PAD], [PAD] [PAD], [PAD], [PAD], [PAD], [PAD] [PAD], [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD], [PAD], [PAD] [PAD] [PAD], [PAD], [PAD] [PAD], [PAD] [PAD] [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD]"
Paper_01495,Free Radicals in the Physiological Control of Cell Function,['Wulf Dröge'],2002,Physiological Reviews,Journal,,47-95,82,1,10.1152/physrev.00018.2001,"At high concentrations, free radicals and radical-derived, nonradical reactive species are hazardous for living organisms and damage all major cellular constituents. At moderate concentrations, however, nitric oxide (NO), superoxide anion, and related reactive oxygen species (ROS) play an important role as regulatory mediators in signaling processes. Many of the ROS-mediated responses actually protect the cells against oxidative stress and reestablish “redox homeostasis.” Higher organisms, however, have evolved the use of NO and ROS also as signaling molecules for other physiological functions. These include regulation of vascular tone, monitoring of oxygen tension in the control of ventilation and erythropoietin production, and signal transduction from membrane receptors in various physiological processes. NO and ROS are typically generated in these cases by tightly regulated enzymes such as NO synthase (NOS) and NAD(P)H oxidase isoforms, respectively. In a given signaling protein, oxidative attack induces either a loss of function, a gain of function, or a switch to a different function. Excessive amounts of ROS may arise either from excessive stimulation of NAD(P)H oxidases or from less well-regulated sources such as the mitochondrial electron-transport chain. In mitochondria, ROS are generated as undesirable side products of the oxidative energy metabolism. An excessive and/or sustained increase in ROS production has been implicated in the pathogenesis of cancer, diabetes mellitus, atherosclerosis, neurodegenerative diseases, rheumatoid arthritis, ischemia/reperfusion injury, obstructive sleep apnea, and other diseases. In addition, free radicals have been implicated in the mechanism of senescence. That the process of aging may result, at least in part, from radical-mediated oxidative damage was proposed more than 40 years ago by Harman ( J Gerontol 11: 298–300, 1956). There is growing evidence that aging involves, in addition, progressive changes in free radical-mediated regulatory processes that result in altered gene expression.","['Reactive oxygen species', 'Oxidative stress', 'Superoxide', 'Cell biology', 'Mitochondrion', 'Signal transduction', 'Chemistry', 'NADPH oxidase', 'Oxidative phosphorylation', 'Nitric oxide', 'Mitochondrial ROS', 'Biochemistry', 'Biology', 'Endocrinology', 'Enzyme']","free, nitric, reactive oxygen species, ##tive stress, red, vascular tone, oxygen tension, erythropoietin production, signal transduction, membrane receptors, no, cancer, diabetes, atheros, ##rosis, ##urodegenerative diseases, rheuma, ##id arthritis, ob, ##ctive sleep, free radicals, sen"
Paper_01496,Mixed-Effects Models in S and S-PLUS,"['Josae C. Pinheiro', 'Douglas M. Bates']",2001,Technometrics,Journal,,113-114,43,1,10.1198/tech.2001.s574,"Mixed-effects models provide a flexible and powerful tool for the analysis of grouped data, which arise in many areas as diverse as agriculture, biology, economics, manufacturing, and geophysics.Examples of grouped data include longitudinal data, repeated measures, blocked designs, and multilevel data.The increasing popularity of mixed-effects models is explained by the flexibility they offer in modeling the within-group correlation often present in grouped data, by the handling of balanced and unbalanced data in a unified framework, and by the availability of reliable and efficient software for fitting them.This book provides an overview of the theory and application of linear and nonlinear mixed-effects models in the analysis of grouped data.A unified model-building strategy for both linear and nonlinear models is presented and applied to the analysis of over 20 real datasets from a wide variety of areas, including pharmacokinetics, agriculture, and manufacturing.A strong emphasis is placed on the use of graphical displays at the various phases of the model-building process, starting with exploratory plots of the data and concluding with diagnostic plots to assess the adequacy of a fitted model.Over 170 figures are included in the book.The class of mixed-effects models considered in this book assumes that both the random effects and the errors follow Gaussian distributions.These models are intended for grouped data in which the response variable is (at least approximately) continuous.This covers a large number of practical applications of mixed-effects models, but does not include, for example, generalized linear mixed-effects models (Diggle, Liang and Zeger, 1994).","['Mathematics', 'Statistics', 'Econometrics', 'Chemistry']","grouped data, biology, economics, geo, longitudinal data, repeated measures, blocked designs, multilevel data, grouped, pharmacokinetics, agriculture, manufacturing, graphical displays, ##tory plots, diagnostic plots, random effects, gaussian distributions, [PAD]"
Paper_01497,Quantitative Monitoring of Gene Expression Patterns with a Complementary DNA Microarray,"['Mark Schena', 'Dari Shalon', 'Ronald W. Davis', 'Patrick O. Brown']",1995,Science,Journal,,467-470,270,5235,10.1126/science.270.5235.467,"A high-capacity system was developed to monitor the expression of many genes in parallel. Microarrays prepared by high-speed robotic printing of complementary DNAs on glass were used for quantitative expression measurements of the corresponding genes. Because of the small format and high density of the arrays, hybridization volumes of 2 microliters could be used that enabled detection of rare transcripts in probe mixtures derived from 2 micrograms of total cellular messenger RNA. Differential expression measurements of 45 Arabidopsis genes were made by means of simultaneous, two-color fluorescence hybridization.","['DNA microarray', 'Gene', 'Gene expression', 'Microarray', 'DNA', 'Biology', 'Messenger RNA', 'Molecular biology', 'Arabidopsis', 'Nucleic acid thermodynamics', 'RNA', 'Computational biology', 'Genetics', 'Mutant']","microar, quantitative expression, hybridization volumes, rare transcripts, differential expression measurements, arabidopsis genes, [PAD], [PAD], [PAD]"
Paper_01500,Schedule for Affective Disorders and Schizophrenia for School-Age Children-Present and Lifetime Version (K-SADS-PL): Initial Reliability and Validity Data,"['Joan Kaufman', 'Boris Birmaher', 'David A. Brent', 'Uma Rao', 'Cynthia Flynn', 'Paula Moreci', 'Douglas E. Williamson', 'Neal D. Ryan']",1997,Journal of the American Academy of Child & Adolescent Psychiatry,Journal,,980-988,36,7,10.1097/00004583-199707000-00021,"ObJective: To describe the psychometric properties of the Schedule for Affective Disorders and Schizophrenia for School-Age Children-Present and Lifetime version (K-SADS-PL) interview, which surveys additional disorders not assessed in prior K-SADS, contains improved probes and anchor points, includes diagnosis-specific impairment ratings, generates DSM-IfI-R and DSM-IV diagnoses, and divides symptoms surveyed into a screening interview and five diagnostic supplements.Method: Subjects were 55 psychiatric outpatients and 11 normal controls (aged 7 through 17 years).Both parents and children were used as informants.Concurrent validity of the screen criteria and the K-SADS-PL diagnoses was assessed against standard self-report scales.Interrater (n = 15) and test-retest (n = 20) reliability data were also collected (mean retest interval: 18 days: range: 2 to 38 days).Results: Rating scale data support the concurrent validity of screens and K-SADS-PL diagnoses.Interrater agreement in scoring screens and diagnoses was high (range: 93% to 100%).Test-retest reliability l( coefficients were in the excellent range for present and/or lifetime diagnoses of major depression, any bipolar, generalized anxiety, conduct, and oppositional defiant disorder (.77 to 1.00) and in the good range for present diagnoses of posttraumatic stress disorder and attention-deficit hyperactivity disorder (.63 to .67).Conclusion: Results suggest the K-SADS•PL generates reliable and valid child psychiatric diagnoses.J.","['Schedule for Affective Disorders and Schizophrenia', 'Inter-rater reliability', 'Medical diagnosis', 'Psychology', 'Psychiatry', 'Clinical psychology', 'Schizophrenia (object-oriented programming)', 'Anxiety', 'Rating scale', 'Test validity', 'Anxiety disorder', 'Psychometrics', 'Medicine', 'Developmental psychology', 'Pathology']","psychometric, affective disorders, schizophrenia, psychiatric, reliability data, rating, interrater, major, oppositional defiant disorder"
Paper_01501,Parental Investment and Sexual Selection,['Robert Trivers'],2017,Routledge eBooks,Unknown,,136-179,,,10.4324/9781315129266-7,"There is a tendency among biologists studying social behavior to regard the adult sex ratio as an independent variable to which the species reacts with appropriate adaptations. D. Lack often interprets social behavior as an adaptation in part to an unbalanced (or balanced) sex ratio, and J. Verner has summarized other instances of this tendency. The only mechanism that will generate differential mortality independent of sexual differences clearly related to parental investment and sexual selection is the chromosomal mechanism, applied especially to humans and other mammals: the unguarded X chromosome of the male is presumed to predispose him to higher mortality. Each offspring can be viewed as an investment independent of other offspring, increasing investment in one offspring tending to decrease investment in others. Species can be classified according to the relative parental investment of the sexes in their young. In the vast majority of species, the male's only contribution to the survival of his offspring is his sex cells.","['Sexual selection', 'Investment (military)', 'Selection (genetic algorithm)', 'Biology', 'Computer science', 'Zoology', 'Political science', 'Artificial intelligence', 'Law', 'Politics']","social behavior, adult sex ratio, social behavior, sexual selection, chromosomal mechanism, unguarded, parental investment"
Paper_01502,COVID-19: consider cytokine storm syndromes and immunosuppression,"['Puja Mehta', 'Daniel F. McAuley', 'Michael Brown', 'Emilie Sanchez', 'Rachel Tattersall', 'Jessica Manson']",2020,The Lancet,Journal,,1033-1034,395,10229,10.1016/s0140-6736(20)30628-0,"As of March 12, 2020, coronavirus disease 2019 (COVID-19) has been confirmed in 125 048 people worldwide, carrying a mortality of approximately 3·7%,1 compared with a mortality rate of less than 1% from influenza. There is an urgent need for effective treatment. Current focus has been on the development of novel therapeutics, including antivirals and vaccines. Accumulating evidence suggests that a subgroup of patients with severe COVID-19 might have a cytokine storm syndrome. We recommend identification and treatment of hyperinflammation using existing, approved therapies with proven safety profiles to address the immediate need to reduce the rising mortality.","['Cytokine storm', 'Coronavirus disease 2019 (COVID-19)', 'Immunosuppression', '2019-20 coronavirus outbreak', 'Severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2)', 'Medicine', 'Storm', 'Cytokine', 'Betacoronavirus', 'Virology', 'Coronavirus Infections', 'Immunology', 'Geography', 'Meteorology', 'Internal medicine', 'Infectious disease (medical specialty)', 'Disease', 'Outbreak']","coronavirus disease, co, antivirals, vaccines, cytokine storm syndrome, hyperinflammation, [PAD] [PAD] [PAD] [PAD]"
Paper_01503,Surviving Sepsis Campaign,"['R. Phillip Dellinger', 'Mitchell M. Levy', 'Andrew Rhodes', 'Djillali Annane', 'Herwig Gerlach', 'Steven M. Opal', 'Jonathan Sevransky', 'Charles L. Sprung', 'Ivor S. Douglas', 'Roman Jaeschke', 'Tiffany M. Osborn', 'Mark Nunnally', 'Sean R. Townsend', 'Konrad Reinhart', 'Ruth Kleinpell', 'Derek C. Angus', 'Clifford S. Deutschman', 'Flávia Ribeiro Machado', 'Gordon D. Rubenfeld', 'S. A. R. Webb', 'Richard Beale', 'Jean‐Louis Vincent', 'Rui P. Moreno']",2013,Critical Care Medicine,Journal,,580-637,41,2,10.1097/ccm.0b013e31827e83af,"To provide an update to the ""Surviving Sepsis Campaign Guidelines for Management of Severe Sepsis and Septic Shock,"" last published in 2008. A consensus committee of 68 international experts representing 30 international organizations was convened. Nominal groups were assembled at key international meetings (for those committee members attending the conference). A formal conflict of interest policy was developed at the onset of the process and enforced throughout. The entire guidelines process was conducted independent of any industry funding. A stand-alone meeting was held for all subgroup heads, co- and vice-chairs, and selected individuals. Teleconferences and electronic-based discussion among subgroups and among the entire committee served as an integral part of the development. The authors were advised to follow the principles of the Grading of Recommendations Assessment, Development and Evaluation (GRADE) system to guide assessment of quality of evidence from high (A) to very low (D) and to determine the strength of recommendations as strong (1) or weak (2). The potential drawbacks of making strong recommendations in the presence of low-quality evidence were emphasized. Some recommendations were ungraded (UG). Recommendations were classified into three groups: 1) those directly targeting severe sepsis; 2) those targeting general care of the critically ill patient and considered high priority in severe sepsis; and 3) pediatric considerations. Key recommendations and suggestions, listed by category, include: early quantitative resuscitation of the septic patient during the first 6 hrs after recognition (1C); blood cultures before antibiotic therapy (1C); imaging studies performed promptly to confirm a potential source of infection (UG); administration of broad-spectrum antimicrobials therapy within 1 hr of recognition of septic shock (1B) and severe sepsis without septic shock (1C) as the goal of therapy; reassessment of antimicrobial therapy daily for de-escalation, when appropriate (1B); infection source control with attention to the balance of risks and benefits of the chosen method within 12 hrs of diagnosis (1C); initial fluid resuscitation with crystalloid (1B) and consideration of the addition of albumin in patients who continue to require substantial amounts of crystalloid to maintain adequate mean arterial pressure (2C) and the avoidance of hetastarch formulations (1C); initial fluid challenge in patients with sepsis-induced tissue hypoperfusion and suspicion of hypovolemia to achieve a minimum of 30 mL/kg of crystalloids (more rapid administration and greater amounts of fluid may be needed in some patients) (1C); fluid challenge technique continued as long as hemodynamic improvement, as based on either dynamic or static variables (UG); norepinephrine as the first-choice vasopressor to maintain mean arterial pressure ≥ 65 mm Hg (1B); epinephrine when an additional agent is needed to maintain adequate blood pressure (2B); vasopressin (0.03 U/min) can be added to norepinephrine to either raise mean arterial pressure to target or to decrease norepinephrine dose but should not be used as the initial vasopressor (UG); dopamine is not recommended except in highly selected circumstances (2C); dobutamine infusion administered or added to vasopressor in the presence of a) myocardial dysfunction as suggested by elevated cardiac filling pressures and low cardiac output, or b) ongoing signs of hypoperfusion despite achieving adequate intravascular volume and adequate mean arterial pressure (1C); avoiding use of intravenous hydrocortisone in adult septic shock patients if adequate fluid resuscitation and vasopressor therapy are able to restore hemodynamic stability (2C); hemoglobin target of 7-9 g/dL in the absence of tissue hypoperfusion, ischemic coronary artery disease, or acute hemorrhage (1B); low tidal volume (1A) and limitation of inspiratory plateau pressure (1B) for acute respiratory distress syndrome (ARDS); application of at least a minimal amount of positive end-expiratory pressure (PEEP) in ARDS (1B); higher rather than lower level of PEEP for patients with sepsis-induced moderate or severe ARDS (2C); recruitment maneuvers in sepsis patients with severe refractory hypoxemia due to ARDS (2C); prone positioning in sepsis-induced ARDS patients with a PaO2/FIO2 ratio of ≤ 100 mm Hg in facilities that have experience with such practices (2C); head-of-bed elevation in mechanically ventilated patients unless contraindicated (1B); a conservative fluid strategy for patients with established ARDS who do not have evidence of tissue hypoperfusion (1C); protocols for weaning and sedation (1A); minimizing use of either intermittent bolus sedation or continuous infusion sedation targeting specific titration endpoints (1B); avoidance of neuromuscular blockers if possible in the septic patient without ARDS (1C); a short course of neuromuscular blocker (no longer than 48 hrs) for patients with early ARDS and a Pao2/Fio2 < 150 mm Hg (2C); a protocolized approach to blood glucose management commencing insulin dosing when two consecutive blood glucose levels are > 180 mg/dL, targeting an upper blood glucose ≤ 180 mg/dL (1A); equivalency of continuous veno-venous hemofiltration or intermittent hemodialysis (2B); prophylaxis for deep vein thrombosis (1B); use of stress ulcer prophylaxis to prevent upper gastrointestinal bleeding in patients with bleeding risk factors (1B); oral or enteral (if necessary) feedings, as tolerated, rather than either complete fasting or provision of only intravenous glucose within the first 48 hrs after a diagnosis of severe sepsis/septic shock (2C); and addressing goals of care, including treatment plans and end-of-life planning (as appropriate) (1B), as early as feasible, but within 72 hrs of intensive care unit admission (2C). Recommendations specific to pediatric severe sepsis include: therapy with face mask oxygen, high flow nasal cannula oxygen, or nasopharyngeal continuous PEEP in the presence of respiratory distress and hypoxemia (2C), use of physical examination therapeutic endpoints such as capillary refill (2C); for septic shock associated with hypovolemia, the use of crystalloids or albumin to deliver a bolus of 20 mL/kg of crystalloids (or albumin equivalent) over 5 to 10 mins (2C); more common use of inotropes and vasodilators for low cardiac output septic shock associated with elevated systemic vascular resistance (2C); and use of hydrocortisone only in children with suspected or proven ""absolute""' adrenal insufficiency (2C). Strong agreement existed among a large cohort of international experts regarding many level 1 recommendations for the best care of patients with severe sepsis. Although a significant number of aspects of care have relatively weak support, evidence-based recommendations regarding the acute management of sepsis and septic shock are the foundation of improved outcomes for this important group of critically ill patients.","['Medicine', 'Sepsis', 'Intensive care medicine', 'Internal medicine']","surviving sepsis, severe sepsis, septic shock, blood cultures"
Paper_01504,The Job Demands‐Resources model: state of the art,"['Arnold B. Bakker', 'Evangelia Demerouti']",2007,Journal of Managerial Psychology,Journal,,309-328,22,3,10.1108/02683940710733115,"Purpose The purpose of this paper is to give a state‐of‐the art overview of the Job Demands‐Resources (JD‐R) model Design/methodology/approach The strengths and weaknesses of the demand‐control model and the effort‐reward imbalance model regarding their predictive value for employee well being are discussed. The paper then introduces the more flexible JD‐R model and discusses its basic premises. Findings The paper provides an overview of the studies that have been conducted with the JD‐R model. It discusses evidence for each of the model's main propositions. The JD‐R model can be used as a tool for human resource management. A two‐stage approach can highlight the strengths and weaknesses of individuals, work groups, departments, and organizations at large. Originality/value This paper challenges existing stress models, and focuses on both negative and positive indicators of employee well being. In addition, it outlines how the JD‐R model can be applied to a wide range of occupations, and be used to improve employee well being and performance.","['Strengths and weaknesses', 'Human resource management', 'Originality', 'Human resources', 'Value (mathematics)', 'Control (management)', 'Work (physics)', 'Knowledge management', 'Computer science', 'Process management', 'Management science', 'Psychology', 'Business', 'Management', 'Social psychology', 'Engineering', 'Economics', 'Mechanical engineering', 'Machine learning', 'Artificial intelligence', 'Creativity']","job demands, jd, demand ‐, reward imbalance, predictive, employee well being, jd, human resource management, work groups, stress models, employee well being, employee well being, [PAD]"
Paper_01505,How Much Should We Trust Differences-In-Differences Estimates?,"['Bertrand Moine', 'Esther Duflo', 'Sendhil Mullainathan']",2004,The Quarterly Journal of Economics,Journal,,249-275,119,1,10.1162/003355304772839588,"Most papers that employ Differences-in-Differences estimation (DD) use many years of data and focus on serially correlated outcomes but ignore that the resulting standard errors are inconsistent. To illustrate the severity of this issue, we randomly generate placebo laws in state-level data on female wages from the Current Population Survey. For each law, we use OLS to compute the DD estimate of its ""effect"" as well as the standard error of this estimate. These conventional DD standard errors severely understate the standard deviation of the estimators: we find an ""effect"" significant at the 5 percent level for up to 45 percent of the placebo interventions. We use Monte Carlo simulations to investigate how well existing methods help solve this problem. Econometric corrections that place a specific parametric form on the time-series process do not perform well. Bootstrap (taking into account the autocorrelation of the data) works well when the number of states is large enough. Two corrections based on asymptotic approximation of the variance-covariance matrix work well for moderate numbers of states and one correction that collapses the time series information into a ""pre""- and ""post""-period and explicitly takes into account the effective sample size works well even for small numbers of states.","['Estimator', 'Econometrics', 'Autocorrelation', 'Standard error', 'Series (stratigraphy)', 'Standard deviation', 'Variance (accounting)', 'Statistics', 'Monte Carlo method', 'Parametric statistics', 'Sample size determination', 'Population', 'Mathematics', 'Covariance', 'Economics', 'Paleontology', 'Demography', 'Accounting', 'Sociology', 'Biology']","serially correlated outcomes, placebo laws, female wages, population survey, ols, monte carlo simulations, econometric corrections, parametric, bootstrap, autocorrel, ##otic approximation, time series"
Paper_01507,"Evaluation, Treatment, and Prevention of Vitamin D Deficiency: an Endocrine Society Clinical Practice Guideline","['Michael F. Holick', 'Neil Binkley', 'Heike A. Bischoff‐Ferrari', 'Catherine M. Gordon', 'David A. Hanley', 'Robert P. Heaney', 'M. Hassan Murad', 'Connie M. Weaver']",2011,The Journal of Clinical Endocrinology & Metabolism,Journal,,1911-1930,96,7,10.1210/jc.2011-0385,"The objective was to provide guidelines to clinicians for the evaluation, treatment, and prevention of vitamin D deficiency with an emphasis on the care of patients who are at risk for deficiency. The Task Force was composed of a Chair, six additional experts, and a methodologist. The Task Force received no corporate funding or remuneration. Consensus was guided by systematic reviews of evidence and discussions during several conference calls and e-mail communications. The draft prepared by the Task Force was reviewed successively by The Endocrine Society's Clinical Guidelines Subcommittee, Clinical Affairs Core Committee, and cosponsoring associations, and it was posted on The Endocrine Society web site for member review. At each stage of review, the Task Force received written comments and incorporated needed changes. Considering that vitamin D deficiency is very common in all age groups and that few foods contain vitamin D, the Task Force recommended supplementation at suggested daily intake and tolerable upper limit levels, depending on age and clinical circumstances. The Task Force also suggested the measurement of serum 25-hydroxyvitamin D level by a reliable assay as the initial diagnostic test in patients at risk for deficiency. Treatment with either vitamin D2 or vitamin D3 was recommended for deficient patients. At the present time, there is not sufficient evidence to recommend screening individuals who are not at risk for deficiency or to prescribe vitamin D to attain the noncalcemic benefit for cardiovascular protection.","['vitamin D deficiency', 'Guideline', 'Medicine', 'Vitamin D and neurology', 'Task force', 'Remuneration', 'Clinical Practice', 'Endocrine system', 'Family medicine', 'Internal medicine', 'Hormone', 'Political science', 'Pathology', 'Public administration', 'Law']","clinic, vitamin d deficiency, endocrine society, clinical guidelines, clinical affairs, endocrine society, vitamin, non, ##ce, cardiovascular"
Paper_01508,<i>Ab initio</i> effective core potentials for molecular calculations. Potentials for main group elements Na to Bi,"['Willard R. Wadt', 'P. Jeffrey Hay']",1985,The Journal of Chemical Physics,Journal,,284-298,82,1,10.1063/1.448800,"A consistent set of ab initio effective core potentials (ECP) has been generated for the main group elements from Na to Bi using the procedure originally developed by Kahn. The ECP's are derived from all‐electron numerical Hartree–Fock atomic wave functions and fit to analytical representations for use in molecular calculations. For Rb to Bi the ECP's are generated from the relativistic Hartree–Fock atomic wave functions of Cowan which incorporate the Darwin and mass–velocity terms. Energy‐optimized valence basis sets of (3s3p) primitive Gaussians are presented for use with the ECP's. Comparisons between all‐electron and valence‐electron ECP calculations are presented for NaF, NaCl, Cl2, Cl2−, Br2, Br2−, and Xe2+. The results show that the average errors introduced by the ECP's are generally only a few percent.","['Ab initio', 'Atomic physics', 'Valence (chemistry)', 'Wave function', 'Hartree–Fock method', 'Basis set', 'Valence electron', 'Ab initio quantum chemistry methods', 'Chemistry', 'Core electron', 'Physics', 'Electron', 'Computational chemistry', 'Quantum mechanics', 'Molecule', 'Density functional theory']","ab, ##ock atomic wave functions, analytical representations, molecular calculations, relativistic hartree, ##ock atomic wave functions, mass – velocity terms, ##nce basis sets, primitive gaussians, vale"
Paper_01510,Two‐Dimensional Nanocrystals Produced by Exfoliation of Ti<sub>3</sub>AlC<sub>2</sub>,"['Michael Naguib', 'Murat Kurtoglu', 'Volker Presser', 'Jun Lu', 'Junjie Niu', 'Min Heon', 'Lars Hultman', 'Yury Gogotsi', 'Michel W. Barsoum']",2011,Advanced Materials,Journal,,4248-4253,23,37,10.1002/adma.201102306,"2D Ti3C2 nanosheets, multilayer structures, and conical scrolls produced by room temperature exfoliation of Ti3AlC2 in HF are reported. Since Ti3AlC2 is a member of a 60+ group of layered ternary carbides and nitrides, this discovery opens a door to the synthesis of a large number of other 2D crystals.","['Materials science', 'Exfoliation joint', 'Carbide', 'Ternary operation', 'Nitride', 'Nanocrystal', 'MAX phases', 'Nanotechnology', 'Crystallography', 'Metallurgy', 'Graphene', 'Layer (electronics)', 'Chemistry', 'Computer science', 'Programming language']","ti3c, multilayer structures, conical scrolls, room temperature exfoliation, ti, ##al, ti, ##al, layered ternary carbides, nitrides, 2d, [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD], [PAD], [PAD], [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD], [PAD], [PAD]"
Paper_01511,Strong localization of photons in certain disordered dielectric superlattices,['Sajeev John'],1987,Physical Review Letters,Journal,,2486-2489,58,23,10.1103/physrevlett.58.2486,"A new mechanism for strong Anderson localization of photons in carefully prepared disordered dielectric superlattices with an everywhere real positive dielectric constant is described. In three dimensions, two photon mobility edges separate high- and low-frequency extended states from an intermediate-frequency pseudogap of localized states arising from remnant geometric Bragg resonances. Experimentally observable consequences are discussed.","['Dielectric', 'Superlattice', 'Condensed matter physics', 'Photon', 'Physics', 'Anderson localization', 'Observable', 'Pseudogap', 'Weak localization', 'Quantum mechanics', 'Cuprate', 'Magnetoresistance', 'Superconductivity', 'Magnetic field']","strong anderson localization, photon, disordered dielectric superlattices, photon mobility edges, localized states, remnant geometric bragg resonances, [PAD] [PAD] [PAD] [PAD] [PAD] [PAD], [PAD]"
Paper_01513,Philosophy in the flesh: the embodied mind and its challenge to Western thought,"['George Lakoff', 'Mark Johnson']",1999,Choice Reviews Online,Journal,,37-0239,37,01,10.5860/choice.37-0239,* Introduction: Who Are We? How The Embodied Mind Challenges The Western Philosophical Tradition * The Cognitive Unconscious * The Embodied Mind * Primary Metaphor and Subjective Experience * The Anatomy of Complex Metaphor * Embodied Realism: Cognitive Science Versus A Priori Philosophy * Realism and Truth * Metaphor and Truth The Cognitive Science Of Basic Philosophical Ideas * The Cognitive Science of Philosophical Ideas * Time * Events and Causes * The Mind * The Self * Morality The Cognitive Science Of Philosophy * The Cognitive Science of Philosophy * The Pre-Socratics: The Cognitive Science of Early Greek Metaphysics * Plato * Aristotle * Descartes and the Enlightenment Mind * Kantian Morality * Analytic Philosophy * Chomskys Philosophy and Cognitive Linguistics * The Theory of Rational Action * How Philosophical Theories Work Embodied Philosophy * Philosophy in the Flesh,"['Flesh', 'Embodied cognition', 'Western thought', 'Philosophy', 'Aesthetics', 'Literature', 'Epistemology', 'Art', 'Chemistry', 'Food science']","embodied mind, western philosophical tradition, cognitive unconscious, embodied mind, primary metaphor, subjective experience, complex metaphor, embodied realism, cognitive science, realism, truth, metaphor, cognitive science, cognitive science, philosophical ideas, cognitive science, cognitive science, cognitive science, ##tes, enlightenment mind, kantian morality, analytic philosophy, ##ky, cognitive linguistics, rational action, philosophical, embodied philosophy"
Paper_01514,The behaviour change wheel: A new method for characterising and designing behaviour change interventions,"['Susan Michie', 'Maartje M. van Stralen', 'Robert West']",2011,Implementation Science,Journal,,,6,1,10.1186/1748-5908-6-42,"Improving the design and implementation of evidence-based practice depends on successful behaviour change interventions. This requires an appropriate method for characterising interventions and linking them to an analysis of the targeted behaviour. There exists a plethora of frameworks of behaviour change interventions, but it is not clear how well they serve this purpose. This paper evaluates these frameworks, and develops and evaluates a new framework aimed at overcoming their limitations. A systematic search of electronic databases and consultation with behaviour change experts were used to identify frameworks of behaviour change interventions. These were evaluated according to three criteria: comprehensiveness, coherence, and a clear link to an overarching model of behaviour. A new framework was developed to meet these criteria. The reliability with which it could be applied was examined in two domains of behaviour change: tobacco control and obesity. Nineteen frameworks were identified covering nine intervention functions and seven policy categories that could enable those interventions. None of the frameworks reviewed covered the full range of intervention functions or policies, and only a minority met the criteria of coherence or linkage to a model of behaviour. At the centre of a proposed new framework is a 'behaviour system' involving three essential conditions: capability, opportunity, and motivation (what we term the 'COM-B system'). This forms the hub of a 'behaviour change wheel' (BCW) around which are positioned the nine intervention functions aimed at addressing deficits in one or more of these conditions; around this are placed seven categories of policy that could enable those interventions to occur. The BCW was used reliably to characterise interventions within the English Department of Health's 2010 tobacco control strategy and the National Institute of Health and Clinical Excellence's guidance on reducing obesity. Interventions and policies to change behaviour can be usefully characterised by means of a BCW comprising: a 'behaviour system' at the hub, encircled by intervention functions and then by policy categories. Research is needed to establish how far the BCW can lead to more efficient design of effective interventions.","['Psychological intervention', 'Behaviour change', 'Intervention (counseling)', 'Behavior change methods', 'Behavior change', 'Health psychology', 'Process management', 'Medicine', 'Management science', 'Applied psychology', 'Risk analysis (engineering)', 'Psychology', 'Public health', 'Social psychology', 'Nursing', 'Engineering']","behaviour change, behaviour change interventions, electronic databases, behaviour, behaviour, tobacco control, obesity, behaviour, tobacco control, national, clinical"
Paper_01515,"Feature selection based on mutual information criteria of max-dependency, max-relevance, and min-redundancy","['Hanchuan Peng', 'Fuhui Long', 'Chen Ding']",2005,IEEE Transactions on Pattern Analysis and Machine Intelligence,Journal,,1226-1238,27,8,10.1109/tpami.2005.159,"Feature selection is an important problem for pattern classification systems. We study how to select good features according to the maximal statistical dependency criterion based on mutual information. Because of the difficulty in directly implementing the maximal dependency condition, we first derive an equivalent form, called minimal-redundancy-maximal-relevance criterion (mRMR), for first-order incremental feature selection. Then, we present a two-stage feature selection algorithm by combining mRMR and other more sophisticated feature selectors (e.g., wrappers). This allows us to select a compact set of superior features at very low cost. We perform extensive experimental comparison of our algorithm and other methods using three different classifiers (naive Bayes, support vector machine, and linear discriminate analysis) and four different data sets (handwritten digits, arrhythmia, NCI cancer cell lines, and lymphoma tissues). The results confirm that mRMR leads to promising improvement on feature selection and classification accuracy.","['Feature selection', 'Mutual information', 'Pattern recognition (psychology)', 'Redundancy (engineering)', 'Minimum redundancy feature selection', 'Artificial intelligence', 'Computer science', 'Support vector machine', 'Dependency (UML)', 'Naive Bayes classifier', 'Feature (linguistics)', 'Data mining', 'Machine learning', 'Linguistics', 'Philosophy', 'Operating system']","feature selection, pattern classification systems, maximal statistical dependency criterion, mutual information, maximal dependency condition, feature selection, wrappers, naive bayes, support vector machine, linear discriminate analysis, handwritten digits, arrhythmia, nci cancer cell lines, lymphoma tissues, feature selection, classification accuracy, [PAD] [PAD] [PAD] [PAD], [PAD], [PAD] [PAD], [PAD], [PAD], [PAD], [PAD], [PAD] [PAD]"
Paper_01516,Executive Functions,['Adele Diamond'],2012,Annual Review of Psychology,Journal,,135-168,64,1,10.1146/annurev-psych-113011-143750,"Executive functions (EFs) make possible mentally playing with ideas; taking the time to think before acting; meeting novel, unanticipated challenges; resisting temptations; and staying focused. Core EFs are inhibition [response inhibition (self-control--resisting temptations and resisting acting impulsively) and interference control (selective attention and cognitive inhibition)], working memory, and cognitive flexibility (including creatively thinking ""outside the box,"" seeing anything from different perspectives, and quickly and flexibly adapting to changed circumstances). The developmental progression and representative measures of each are discussed. Controversies are addressed (e.g., the relation between EFs and fluid intelligence, self-regulation, executive attention, and effortful control, and the relation between working memory and inhibition and attention). The importance of social, emotional, and physical health for cognitive health is discussed because stress, lack of sleep, loneliness, or lack of exercise each impair EFs. That EFs are trainable and can be improved with practice is addressed, including diverse methods tried thus far.","['Psychology', 'Executive functions', 'Cognition', 'Working memory', 'Cognitive flexibility', 'Flexibility (engineering)', 'Cognitive psychology', 'Loneliness', 'Attentional control', 'Control (management)', 'Developmental psychology', 'Social psychology', 'Neuroscience', 'Statistics', 'Mathematics', 'Management', 'Economics']","executive functions, efs, response inhibition, interference control, selective attention, cognitive inhibition, working memory, cognitive flexibility, developmental progression, e, fluid intelligence, executive attention, effortful control, working memory, physical health, cognitive health"
Paper_01518,Legal Determinants of External Finance,"['Rafael La Porta', 'Florencio López‐de‐Silanes', 'Andrei Shleifer', 'Robert W. Vishny']",1997,The Journal of Finance,Journal,,1131-1150,52,3,10.1111/j.1540-6261.1997.tb02727.x,"ABSTRACT Using a sample of 49 countries, we show that countries with poorer investor protections, measured by both the character of legal rules and the quality of law enforcement, have smaller and narrower capital markets. These findings apply to both equity and debt markets. In particular, French civil law countries have both the weakest investor protections and the least developed capital markets, especially as compared to common law countries.","['Capital market', 'Equity (law)', 'Debt', 'Enforcement', 'Business', 'Sample (material)', 'Investor protection', 'Emerging markets', 'Quality (philosophy)', 'Financial system', 'Economics', 'Finance', 'Law', 'Corporate governance', 'Political science', 'Philosophy', 'Chemistry', 'Chromatography', 'Epistemology']","investor protections, legal rules, law, capital markets, equity, debt markets, french civil law countries, investor protections, common law"
Paper_01521,Identification of programmed cell death in situ via specific labeling of nuclear DNA fragmentation.,"['Yael Gavrieli', 'Yoav Sherman', 'Shmuel A. Ben‐Sasson']",1992,The Journal of Cell Biology,Journal,,493-501,119,3,10.1083/jcb.119.3.493,"Programmed cell death (PCD) plays a key role in developmental biology and in maintenance of the steady state in continuously renewing tissues. Currently, its existence is inferred mainly from gel electrophoresis of a pooled DNA extract as PCD was shown to be associated with DNA fragmentation. Based on this observation, we describe here the development of a method for the in situ visualization of PCD at the single-cell level, while preserving tissue architecture. Conventional histological sections, pretreated with protease, were nick end labeled with biotinylated poly dU, introduced by terminal deoxy-transferase, and then stained using avidin-conjugated peroxidase. The reaction is specific, only nuclei located at positions where PCD is expected are stained. The initial screening includes: small and large intestine, epidermis, lymphoid tissues, ovary, and other organs. A detailed analysis revealed that the process is initiated at the nuclear periphery, it is relatively short (1-3 h from initiation to cell elimination) and that PCD appears in tissues in clusters. The extent of tissue-PCD revealed by this method is considerably greater than apoptosis detected by nuclear morphology, and thus opens the way for a variety of studies.","['Biology', 'DNA fragmentation', 'Programmed cell death', 'Apoptosis', 'Molecular biology', 'Cell biology', 'Fragmentation (computing)', 'Nuclear DNA', 'Cell nucleus', 'Biotinylation', 'DNA', 'Cell', 'Cytoplasm', 'Biochemistry', 'Mitochondrial DNA', 'Ecology', 'Gene']","programmed cell death, pc, developmental biology, gel electrophoresis, pooled dna extract, dna fragmentation, protea, epidermis, lymphoid tissues, o, nuclear, ##optosis, nuclear morphology"
Paper_01523,An Introduction to Propensity Score Methods for Reducing the Effects of Confounding in Observational Studies,['Peter C. Austin'],2011,Multivariate Behavioral Research,Journal,,399-424,46,3,10.1080/00273171.2011.568786,"The propensity score is the probability of treatment assignment conditional on observed baseline characteristics. The propensity score allows one to design and analyze an observational (nonrandomized) study so that it mimics some of the particular characteristics of a randomized controlled trial. In particular, the propensity score is a balancing score: conditional on the propensity score, the distribution of observed baseline covariates will be similar between treated and untreated subjects. I describe 4 different propensity score methods: matching on the propensity score, stratification on the propensity score, inverse probability of treatment weighting using the propensity score, and covariate adjustment using the propensity score. I describe balance diagnostics for examining whether the propensity score model has been adequately specified. Furthermore, I discuss differences between regression-based methods and propensity score-based methods for the analysis of observational data. I describe different causal average treatment effects and their relationship with propensity score analyses.","['Propensity score matching', 'Observational study', 'Covariate', 'Confounding', 'Statistics', 'Inverse probability weighting', 'Econometrics', 'Mathematics']","propensity score, treatment assignment, observed baseline characteristics, propensity score, randomized controlled trial, propensity score, balancing score, propensity, propensity score, propensity score, propensity score, inverse probability of treatment weighting, propensity score, covariate adjustment, propensity score, balance diagnostics, propensity score, causal average treatment effects, propensity score analyses, [PAD] [PAD], [PAD] [PAD], [PAD], [PAD]"
Paper_01525,The job demands-resources model of burnout.,"['Evangelia Demerouti', 'Arnold B. Bakker', 'Friedhelm Nachreiner', 'Wilmar B. Schaufeli']",2001,Journal of Applied Psychology,Journal,,499-512,86,3,10.1037/0021-9010.86.3.499,"The job demands-resources (JD-R) model proposes that working conditions can be categorized into 2 broad categories, job demands and job resources. that are differentially related to specific outcomes. A series of LISREL analyses using self-reports as well as observer ratings of the working conditions provided strong evidence for the JD-R model: Job demands are primarily related to the exhaustion component of burnout, whereas (lack of) job resources are primarily related to disengagement. Highly similar patterns were observed in each of 3 occupational groups: human services, industry, and transport (total N = 374). In addition, results confirmed the 2-factor structure (exhaustion and disengagement) of a new burnout instrument--the Oldenburg Burnout Inventory--and suggested that this structure is essentially invariant across occupational groups.","['LISREL', 'Disengagement theory', 'Burnout', 'Psychology', 'Occupational burnout', 'Job satisfaction', 'Occupational stress', 'Emotional exhaustion', 'Job performance', 'Social psychology', 'Applied psychology', 'Structural equation modeling', 'Clinical psychology', 'Statistics', 'Mathematics', 'Gerontology', 'Medicine']","working conditions, job demands, job resources, observer ratings, exhaustion, burn, human services, industry, transport, exhaustion, disengagement, oldenburg burnout inventory"
Paper_01526,Functional connectivity in the motor cortex of resting human brain using echo‐planar mri,"['Bharat B. Biswal', 'F. Zerrin Yetkin', 'Victor M. Haughton', 'James S. Hyde']",1995,Magnetic Resonance in Medicine,Journal,,537-541,34,4,10.1002/mrm.1910340409,"Abstract An MRI time course of 512 echo‐planar images (EPI) in resting human brain obtained every 250 ms reveals fluctuations in signal intensity in each pixel that have a physiologic origin. Regions of the sensorimotor cortex that were activated secondary to hand movement were identified using functional MRI methodology (FMRI). Time courses of low frequency (&lt;0.1 Hz) fluctuations in resting brain were observed to have a high degree of temporal correlation ( P &lt; 10 −3 ) within these regions and also with time courses in several other regions that can be associated with motor function. It is concluded that correlation of low frequency fluctuations, which may arise from fluctuations in blood oxygenation or flow, is a manifestation of functional connectivity of the brain.","['Human brain', 'Resting state fMRI', 'Neuroscience', 'Correlation', 'Cortex (anatomy)', 'Nuclear magnetic resonance', 'Motor cortex', 'Echo (communications protocol)', 'Blood oxygenation', 'Intensity (physics)', 'Echo-planar imaging', 'Functional magnetic resonance imaging', 'Physics', 'Magnetic resonance imaging', 'Psychology', 'Medicine', 'Computer science', 'Mathematics', 'Computer network', 'Geometry', 'Stimulation', 'Radiology', 'Quantum mechanics']","mri time course, 512, planar images, ep, resting human brain, signal intensity, sensorimotor cortex, hand movement, functional mri methodology, fm, resting brain, temporal correlation, motor function, low frequency fluctuations, functional connectivity"
Paper_01527,Electron-Hole Diffusion Lengths Exceeding 1 Micrometer in an Organometal Trihalide Perovskite Absorber,"['Samuel D. Stranks', 'Giles E. Eperon', 'Giulia Grancini', 'Christopher Menelaou', 'Marcelo J. P. Alcocer', 'Tomas Leijtens', 'Laura M. Herz', 'Annamaria Petrozza', 'Henry J. Snaith']",2013,Science,Journal,,341-344,342,6156,10.1126/science.1243982,"Organic-inorganic perovskites have shown promise as high-performance absorbers in solar cells, first as a coating on a mesoporous metal oxide scaffold and more recently as a solid layer in planar heterojunction architectures. Here, we report transient absorption and photoluminescence-quenching measurements to determine the electron-hole diffusion lengths, diffusion constants, and lifetimes in mixed halide (CH3NH3PbI(3-x)Cl(x)) and triiodide (CH3NH3PbI3) perovskite absorbers. We found that the diffusion lengths are greater than 1 micrometer in the mixed halide perovskite, which is an order of magnitude greater than the absorption depth. In contrast, the triiodide absorber has electron-hole diffusion lengths of ~100 nanometers. These results justify the high efficiency of planar heterojunction perovskite solar cells and identify a critical parameter to optimize for future perovskite absorber development.","['Triiodide', 'Perovskite (structure)', 'Materials science', 'Trihalide', 'Heterojunction', 'Micrometer', 'Absorption (acoustics)', 'Diffusion', 'Photoluminescence', 'Oxide', 'Halide', 'Optoelectronics', 'Chemistry', 'Optics', 'Inorganic chemistry', 'Crystallography', 'Physical chemistry', 'Dye-sensitized solar cell', 'Electrolyte', 'Composite material', 'Physics', 'Thermodynamics', 'Electrode', 'Metallurgy']","solar cells, mesoporous metal oxide scaffold, solid layer, planar heterojunction architectures, transient absorption, diffusion constants, mixed hal, planar heterojunction perovskite solar cells"
Paper_01529,An Introduction to Multivariate Statistical Analysis,"['Robb J. Muirhead', 'T. W. Anderson']",1986,Journal of Business and Economic Statistics,Journal,,135-135,4,1,10.2307/1391399,Preface to the Third Edition.Preface to the Second Edition.Preface to the First Edition.1. Introduction.2. The Multivariate Normal Distribution.3. Estimation of the Mean Vector and the Covariance Matrix.4. The Distributions and Uses of Sample Correlation Coefficients.5. The Generalized T2-Statistic.6. Classification of Observations.7. The Distribution of the Sample Covariance Matrix and the Sample Generalized Variance.8. Testing the General Linear Hypothesis: Multivariate Analysis of Variance9. Testing Independence of Sets of Variates.10. Testing Hypotheses of Equality of Covariance Matrices and Equality of Mean Vectors and Covariance Matrices.11. Principal Components.12. Cononical Correlations and Cononical Variables.13. The Distributions of Characteristic Roots and Vectors.14. Factor Analysis.15. Pattern of Dependence Graphical Models.Appendix A: Matrix Theory.Appendix B: Tables.References.Index.,"['Mathematics', 'Covariance matrix', 'Estimation of covariance matrices', 'Statistics', 'Multivariate normal distribution', 'Scatter matrix', 'Covariance', 'Statistic', 'Multivariate statistics', 'Law of total covariance', 'Test statistic', 'Principal component analysis', 'Applied mathematics', 'Statistical hypothesis testing', 'Covariance intersection']","multivariate normal distribution, mean vector, covariance matrix, sample correlation coefficients, sample covariance matrix, sample generalized variance, general linear hypothesis, multivariate analysis, hypoth, covariance matrices, mean vectors, covariance matrices, principal components, cononical correlations, cononical variables, characteristic roots, factor analysis, pattern of dependence graphical models, matrix theory, [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD], [PAD] [PAD], [PAD]"
Paper_01530,Mail and internet surveys : the tailored design method,['Don A. Dillman'],2007,['Journal of Advertising Research'],Unknown,,207,47,2,10.2501/s0021849907070237,"Preface to the 2007 Update.Preface to the Second Edition.Acknowledgments.Part One: ELEMENTS OF THE TAILORED DESIGN METHOD.1 Introduction to Tailored Design.2 Writing Questions.3 Constructing the Questionnaire.4 Survey Implementation.5 Reduction of Coverage and Sampling Errors.Part Two: TAILORING TO THE SURVEY SITUATION.6 Mixed-Mode Surveys.7 Alternative Questionnaire Delivery: In Person, to Groups, and through Publications.8 When Timing Is Critical: Diary, Customer Satisfaction, and Election Forecast Surveys.9 Household and Individual Person Surveys by Government.10 Surveys of Businesses and Other Organizations.11 Internet and Interactive Voice Response Surveys.12 Optical Scanning and Imaging, and the Future of Self-Administered Surveys.References.2007 Appendix: Recent Developments in the Design of Web, Mail, and Mixed-Mode Surveys.Appendix References.Index.","['The Internet', 'Index (typography)', 'Computer science', 'Survey research', 'Government (linguistics)', 'Mode (computer interface)', 'World Wide Web', 'Data science', 'Psychology', 'Applied psychology', 'Human–computer interaction', 'Linguistics', 'Philosophy']","tailored design method, tailored design, survey implementation, sampling errors, diary, customer satisfaction, election forecast surveys, individual person surveys, internet, interactive voice response surveys, optical"
Paper_01531,"FieldTrip: Open Source Software for Advanced Analysis of MEG, EEG, and Invasive Electrophysiological Data","['Robert Oostenveld', 'Pascal Fries', 'Eric Maris', 'Jan‐Mathijs Schoffelen']",2010,Computational Intelligence and Neuroscience,Journal,,1-9,2011,,10.1155/2011/156869,"This paper describes FieldTrip, an open source software package that we developed for the analysis of MEG, EEG, and other electrophysiological data. The software is implemented as a MATLAB toolbox and includes a complete set of consistent and user-friendly high-level functions that allow experimental neuroscientists to analyze experimental data. It includes algorithms for simple and advanced analysis, such as time-frequency analysis using multitapers, source reconstruction using dipoles, distributed sources and beamformers, connectivity analysis, and nonparametric statistical permutation tests at the channel and source level. The implementation as toolbox allows the user to perform elaborate and structured analyses of large data sets using the MATLAB command line and batch scripting. Furthermore, users and developers can easily extend the functionality and implement new algorithms. The modular design facilitates the reuse in other software packages.","['Computer science', 'Toolbox', 'Software', 'MATLAB', 'Scripting language', 'Modular design', 'Data mining', 'Permutation (music)', 'Computer engineering', 'Programming language', 'Physics', 'Acoustics']","fieldtrip, meg, eeg, electrophysiological data, matlab toolbox, experimental neuroscient, multitapers, source reconstruction, dipoles, distributed sources, beamform, connectivity analysis, nonparametric statistical permutation tests, matlab command line, batch scripting, modular design"
Paper_01532,Matrix Analysis,"['Roger A. Horn', 'Charles R. Johnson']",1985,Unknown,Unknown,,,,,10.1017/cbo9780511810817,"In this book the authors present classical and recent results for matrix analysis that have proved to be important to applied mathematics. Facts about matrices, beyond those found in an elementary linear algebra course, are needed to understand virtually any area of mathematics, and the necessary material has only occurred sporadically in the literature and university curricula. As the interest in applied mathematics has grown, the need for a text and a reference work offering a broad selection of topics has become apparent, and this book aims to meet that need. This book will be welcomed as an undergraduate or graduate textbook for students studying matrix analysis. The authors assume a background in elementary linear algebra and knowledge of rudimentary analytical concepts. They begin with a review and discussion of eigenvalues and eigenvectors. The following chapters each treat a major topic in depth. This volume should be useful not only as a text, but also as a self-contained reference work to a variety of audiences in other scientific fields.","['Linear algebra', 'Variety (cybernetics)', 'Matrix (chemical analysis)', 'Curriculum', 'Mathematics education', 'Algebra over a field', 'Selection (genetic algorithm)', 'Eigenvalues and eigenvectors', 'Elementary mathematics', 'Work (physics)', 'Computer science', 'Mathematics', 'Pure mathematics', 'Pedagogy', 'Engineering', 'Artificial intelligence', 'Sociology', 'Physics', 'Geometry', 'Mechanical engineering', 'Materials science', 'Quantum mechanics', 'Composite material']","matrix analysis, applied mathematics, matrices, elementary linear algebra, university, applied mathematics, matrix analysis, elementary linear algebra, eigenvalues, eigenvectors"
Paper_01533,Targeted gene expression as a means of altering cell fates and generating dominant phenotypes,"['Andrea H. Brand', 'Norbert Perrimon']",1993,Development,Journal,,401-415,118,2,10.1242/dev.118.2.401,"ABSTRACT We have designed a system for targeted gene expression that allows the selective activation of any cloned gene in a wide variety of tissueand cell-specific patterns. The gene encoding the yeast transcriptional activator GAL4 is inserted randomly into the Drosophila genome to drive GAL4 expression from one of a diverse array of genomic enhancers. It is then possible to introduce a gene containing GAL4 binding sites within its promoter, to activate it in those cells where GAL4 is expressed, and to observe the effect of this directed misexpression on development. We have used GAL4-directed transcription to expand the domain of embryonic expression of the homeobox protein even-skipped. We show that even-skipped represses wingless and transforms cells that would normally secrete naked cuticle into denticle secreting cells. The GAL4 system can thus be used to study regulatory interactions during embryonic development. In adults, targeted expression can be used to generate dominant phenotypes for use in genetic screens. We have directed expression of an activated form of the Dras2 protein, resulting in dominant eye and wing defects that can be used in screens to identify other members of the Dras2 signal transduction pathway.","['Biology', 'Enhancer', 'Phenotype', 'Gene', 'Transcription factor', 'Genetics', 'Embryonic stem cell', 'Gene expression', 'Cell biology', 'Regulation of gene expression', 'Homeobox', 'POU domain', 'Activator (genetics)']","targeted gene expression, yeast transcriptional activator gal, gal, gen, gal, dent, gal, dominant ph, genetic screens, ##as, wing defects"
Paper_01534,The Structure of Scientific Revolutions,"['Thomas Kühn', 'David Hawkins']",1963,American Journal of Physics,Journal,,554-555,31,7,10.1119/1.1969660,First Page,"['Physics', 'Theoretical physics', 'Engineering physics', 'Statistical physics']",
Paper_01535,The Resource-Based Theory of Competitive Advantage: Implications for Strategy Formulation,['Robert M. Grant'],1991,California Management Review,Journal,,114-135,33,3,10.2307/41166664,"Recent contributions to strategic management and the theory of the collectively known as the view of the firm provide illuminating insights into the sources of profitability and the nature of competitive strategy. This article argues that internal resources rather than the market environment should provide the foundation for a firm's strategy. On the basis of an analysis of the relationships among resources, capabilities, conpetitive advantage, and profitability, this article advances a framework for a resource-based approach to strategy formulation.","['Profitability index', 'Competitive advantage', 'Resource-based view', 'Resource (disambiguation)', 'Strategic management', 'Industrial organization', 'Business', 'Dynamic capabilities', 'Foundation (evidence)', 'Computer science', 'Marketing', 'Archaeology', 'History', 'Computer network', 'Finance']","strategic management, profitability, competitive strategy, internal resources, market environment, capabilities, conpetitive advantage, profitability, strategy formulation"
Paper_01536,Deep Learning,"['Ian Goodfellow', 'Yoshua Bengio', 'Aaron Courville']",2016,['South African Journal of Higher Education'],Unknown,,,17,1,10.4314/sajhe.v17i1.25201,"Deep learning is a form of machine learning that enables computers to learn from experience and understand the world in terms of a hierarchy of concepts. Because the computer gathers knowledge from experience, there is no need for a human computer operator to formally specify all the knowledge that the computer needs. The hierarchy of concepts allows the computer to learn complicated concepts by building them out of simpler ones; a graph of these hierarchies would be many layers deep. This book introduces a broad range of topics in deep learning. The text offers mathematical and conceptual background, covering relevant concepts in linear algebra, probability theory and information theory, numerical computation, and machine learning. It describes deep learning techniques used by practitioners in industry, including deep feedforward networks, regularization, optimization algorithms, convolutional networks, sequence modeling, and practical methodology; and it surveys such applications as natural language processing, speech recognition, computer vision, online recommendation systems, bioinformatics, and videogames. Finally, the book offers research perspectives, covering such theoretical topics as linear factor models, autoencoders, representation learning, structured probabilistic models, Monte Carlo methods, the partition function, approximate inference, and deep generative models. Deep Learning can be used by undergraduate or graduate students planning careers in either industry or research, and by software engineers who want to begin using deep learning in their products or platforms. A website offers supplementary material for both readers and instructors.","['Deep learning', 'Computer science', 'Artificial intelligence', 'Algorithmic learning theory', 'Machine learning', 'Computational learning theory', 'Active learning (machine learning)']","deep learning, machine learning, human computer operator, deep learning, linear algebra, probability theory, information theory, numerical computation, machine learning, deep learning, deep feedforward networks, regularization, optimization algorithms, convolutional networks, sequence modeling, practical methodology, natural language processing, speech recognition, computer vision, online recommendation systems, bioinformatics, videogames, linear factor models, autoencoders, representation learning, structured probabilistic models, monte carlo methods, partition function, approximate inference, deep generative models, deep learning"
Paper_01537,Optical Properties and Electronic Structure of Amorphous Germanium,"['J. Tauc', 'R. Grigorovici', 'A. Vancu']",1966,physica status solidi (b),Journal,,627-637,15,2,10.1002/pssb.19660150224,"Abstract The optical constants of amorphous Ge are determined for the photon energies from 0.08 to 1.6 eV. From 0.08 to 0.5 eV, the absorption is due to k ‐conserving transitions of holes between the valence bands as in p‐type crystals; the spin‐orbit splitting is found to be 0.20 and 0.21 eV in non‐annealed, and annealed samples respectively. The effective masses of the holes in the three bands are 0.49 m (respectively 0.43 m ); 0.04 m , and 0.08 m . An absorption band is observed below the main absorption edge (at 300 °K the maximum of this band is at 0.86 eV); the absorption in this band increases with increasing temperature. This band is considered to be due to excitons bound to neutral acceptors, and these are presumably the same ones that play a decisive role in the transport properties and which are considered to be associated with vacancies. The absorption edge has the form: ω 2 ϵ 2 ∼(hω− E g ) 2 ( E g = 0.88 eV at 300 °K). This suggests that the optical transitions conserve energy but not k vector, and that the densities of states near the band extrema have the same energy‐dependence as in crystalline Ge. A simple theory describing this situation is proposed, and comparison of it with the experimental results leads to an estimate of the localization of the conduction‐band wavefunctions.","['Absorption edge', 'Photon energy', 'Exciton', 'Germanium', 'Absorption (acoustics)', 'Materials science', 'Atomic physics', 'Valence (chemistry)', 'Amorphous solid', 'Electronic band structure', 'Molecular physics', 'Condensed matter physics', 'Chemistry', 'Band gap', 'Photon', 'Physics', 'Optics', 'Crystallography', 'Optoelectronics', 'Silicon', 'Organic chemistry', 'Composite material']","optical constants, photon energies, valence bands, spin ‐ orbit splitting, absorption band, neutral acceptors, absorption, optical"
Paper_01538,Translating the Histone Code,"['Thomas Jenuwein', 'C. David Allis']",2001,Science,Journal,,1074-1080,293,5532,10.1126/science.1063127,"Chromatin, the physiological template of all eukaryotic genetic information, is subject to a diverse array of posttranslational modifications that largely impinge on histone amino termini, thereby regulating access to the underlying DNA. Distinct histone amino-terminal modifications can generate synergistic or antagonistic interaction affinities for chromatin-associated proteins, which in turn dictate dynamic transitions between transcriptionally active or transcriptionally silent chromatin states. The combinatorial nature of histone amino-terminal modifications thus reveals a “histone code” that considerably extends the information potential of the genetic code. We propose that this epigenetic marking system represents a fundamental regulatory mechanism that has an impact on most, if not all, chromatin-templated processes, with far-reaching consequences for cell fate decisions and both normal and pathological development.","['Histone code', 'Chromatin', 'Histone', 'Genetic code', 'Epigenetics', 'Biology', 'Computational biology', 'Histone H2A', 'Epigenomics', 'Chromatin remodeling', 'Histone H1', 'Genetics', 'Histone methyltransferase', 'Cell biology', 'Histone methylation', 'DNA', 'Nucleosome', 'DNA methylation', 'Gene', 'Gene expression']","chromatin, physiological template, eukar, ##tic, ##translational, histone code, epigenetic marking, cell fate"
Paper_01539,Free Energy of a Nonuniform System. I. Interfacial Free Energy,"['John W. Cahn', 'J. E. Hilliard']",1958,The Journal of Chemical Physics,Journal,,258-267,28,2,10.1063/1.1744102,"It is shown that the free energy of a volume V of an isotropic system of nonuniform composition or density is given by : NV∫V [f0(c)+κ(▿c)2]dV, where NV is the number of molecules per unit volume, ▿c the composition or density gradient, f0 the free energy per molecule of a homogeneous system, and κ a parameter which, in general, may be dependent on c and temperature, but for a regular solution is a constant which can be evaluated. This expression is used to determine the properties of a flat interface between two coexisting phases. In particular, we find that the thickness of the interface increases with increasing temperature and becomes infinite at the critical temperature Tc, and that at a temperature T just below Tc the interfacial free energy σ is proportional to (Tc−T)32. The predicted interfacial free energy and its temperature dependence are found to be in agreement with existing experimental data. The possibility of using optical measurements of the interface thickness to provide an additional check of our treatment is briefly discussed.","['Isotropy', 'Volume (thermodynamics)', 'Constant (computer programming)', 'Energy (signal processing)', 'Molecule', 'Thermodynamics', 'Homogeneous', 'Chemistry', 'Free surface', 'Surface energy', 'Materials science', 'Molecular physics', 'Condensed matter physics', 'Physics', 'Optics', 'Organic chemistry', 'Quantum mechanics', 'Computer science', 'Programming language']","free energy, isotropic system, nonuniform composition, density gradient, free energy, homogeneous system, interfacial free energy, interfacial free energy, temperature dependence, optical measurements, interface thickness"
Paper_01541,node2vec,"['Aditya Grover', 'Jure Leskovec']",2016,Unknown,Unknown,,855-864,,,10.1145/2939672.2939754,"Prediction tasks over nodes and edges in networks require careful effort in engineering features used by learning algorithms. Recent research in the broader field of representation learning has led to significant progress in automating prediction by learning the features themselves. However, present feature learning approaches are not expressive enough to capture the diversity of connectivity patterns observed in networks. Here we propose node2vec, an algorithmic framework for learning continuous feature representations for nodes in networks. In node2vec, we learn a mapping of nodes to a low-dimensional space of features that maximizes the likelihood of preserving network neighborhoods of nodes. We define a flexible notion of a node's network neighborhood and design a biased random walk procedure, which efficiently explores diverse neighborhoods. Our algorithm generalizes prior work which is based on rigid notions of network neighborhoods, and we argue that the added flexibility in exploring neighborhoods is the key to learning richer representations.",['Computer science'],"prediction, learning algorithms, representation learning, feature learning, connectivity patterns, node2vec, continuous feature representations, node2vec, biased random walk procedure"
Paper_01542,Topics in Matrix Analysis,"['Roger A. Horn', 'Charles R. Johnson']",1991,Unknown,Unknown,,,,,10.1017/cbo9780511840371,"Building on the foundations of its predecessor volume, Matrix Analysis, this book treats in detail several topics in matrix theory not included in the previous volume, but with important applications and of special mathematical interest. As with the previous volume, the authors assume a background knowledge of elementary linear algebra and rudimentary analytical concepts. Many examples and exercises of varying difficulty are included.","['Matrix (chemical analysis)', 'Algebra over a field', 'Volume (thermodynamics)', 'Linear algebra', 'Computer science', 'Matrix analysis', 'Calculus (dental)', 'Mathematics', 'Applied mathematics', 'Pure mathematics', 'Geometry', 'Physics', 'Eigenvalues and eigenvectors', 'Medicine', 'Materials science', 'Dentistry', 'Quantum mechanics', 'Composite material']","matrix analysis, matrix theory, elementary linear algebra, [PAD] [PAD], [PAD]"
Paper_01543,ITS primers with enhanced specificity for basidiomycetes ‐ application to the identification of mycorrhizae and rusts,"['Monique Gardes', 'Thomas D. Bruns']",1993,Molecular Ecology,Journal,,113-118,2,2,10.1111/j.1365-294x.1993.tb00005.x,"Abstract We have designed two taxon‐selective primers for the internal transcribed spacer (ITS) region in the nuclear ribosomal repeat unit. These primers, ITS1‐F and ITS4‐B, were intended to be specific to fungi and basidiomycetes, respectively. We have tested the specificity of these primers against 13 species of ascomycetes, 14 of basidiomycetes, and 15 of plants. Our results showed that ITS4‐B, when paired with either a ‘universal’ primer ITS1 or the fungal‐specific primer ITS1‐F, efficiently amplified DNA from all basidiomycetes and discriminated against ascomycete DNAs. The results with plants were not as clearcut. The ITS1‐F/ITS4‐B primer pair produced a small amount of PCR product for certain plant species, but the quantity was in most cases less than that produced by the ‘universal’ ITS primers. However, under conditions where both plant and fungal DNAs were present, the fungal DNA was amplified to the apparent exclusion of plant DNA. ITS1‐F/ITS4‐B preferential amplification was shown to be particularly useful for detection and analysis of the basidiomycete component in ectomycorrhizae and in rust‐infected tissues. These primers can be used to study the structure of ectomycorrhizal communities or the distribution of rusts on alternate hosts.","['Biology', 'Primer (cosmetics)', 'Ribosomal DNA', 'Internal transcribed spacer', 'Ectomycorrhizae', 'Botany', 'Polymerase chain reaction', 'Ribosomal RNA', 'Genetics', 'Phylogenetics', 'Gene', 'Symbiosis', 'Mycorrhiza', 'Bacteria', 'Chemistry', 'Organic chemistry']","taxon, internal transcribed spacer, nuclear ribosomal repeat unit, basidiomy, ##omy, ##yce, preferential amplification, ectomycorrhiza"
Paper_01544,Not So Different After All: A Cross-Discipline View Of Trust,"['Denise M. Rousseau', 'Sim B. Sitkin', 'Ronald S. Burt', 'Colin F. Camerer']",1998,Academy of Management Review,Journal,,393-404,23,3,10.5465/amr.1998.926617,"The article discusses trust theory, multidisciplinary research, and trust between organizations. The analysis of trust is based on four questions: whether scholars can agree on the meaning of trust; if researchers are viewing trust statistically; if the status of trust--cause, effect, or interaction--changes across disciplines; and whether the levels of analysis also change. The ""bandwidth"" of trust--where trust and distrust are differentiated--can vary over time in the same relationship or coexist at the same time. Bandwidth types are deterrence-based trust, calculus-based trust, relational trust, and institution-based trust. Two conditions of trust are risk and interdependence. Three phases are building, stability, and dissolution. Several studies are mentioned.","['Organizational behavior', 'Sociology', 'Management', 'Psychology', 'Political science', 'Social psychology', 'Economics']","trust theory, multidisciplinary research, trust, organizations, trust, trust, trust, trust, distrust, relational trust, risk, interde, ##dence, stability, dissolution"
Paper_01545,Continuous Univariate Distributions.,"['Yasuhiro Omori', 'Norman L. Johnson', 'S. Kotz', 'N. Balakrishnan']",1995,Journal of the American Statistical Association,Journal,,1490-1490,90,432,10.2307/2291547,Continuous Distributions (General). Normal Distributions. Lognormal Distributions. Inverse Gaussian (Wald) Distributions. Cauchy Distribution. Gamma Distributions. Chi-Square Distributions Including Chi and Rayleigh. Exponential Distributions. Pareto Distributions. Weibull Distributions. Abbreviations. Indexes.,"['Univariate', 'Mathematics', 'Statistics', 'Econometrics', 'Multivariate statistics']","continuous distributions, normal distributions, lognormal distributions, inverse gaussian, wal, cauchy distribution, gamma distributions, ray, exponential distributions, pareto distributions, weibull distributions, indexes, [PAD], [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD], [PAD], [PAD], [PAD] [PAD], [PAD], [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD], [PAD], [PAD], [PAD] [PAD], [PAD] [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD], [PAD], [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD], [PAD], [PAD] [PAD], [PAD] [PAD] [PAD] [PAD], [PAD] [PAD], [PAD] [PAD], [PAD], [PAD] [PAD] [PAD] [PAD], [PAD]"
Paper_01548,Tensor Decompositions and Applications,"['Tamara G. Kolda', 'Brett W. Bader']",2009,SIAM Review,Journal,,455-500,51,3,10.1137/07070111x,"This survey provides an overview of higher-order tensor decompositions, their applications, and available software. A tensor is a multidimensional or N-way array. Decompositions of higher-order tensors (i.e., N-way arrays with $N \geq 3$) have applications in psycho-metrics, chemometrics, signal processing, numerical linear algebra, computer vision, numerical analysis, data mining, neuroscience, graph analysis, and elsewhere. Two particular tensor decompositions can be considered to be higher-order extensions of the matrix singular value decomposition: CANDECOMP/PARAFAC (CP) decomposes a tensor as a sum of rank-one tensors, and the Tucker decomposition is a higher-order form of principal component analysis. There are many other tensor decompositions, including INDSCAL, PARAFAC2, CANDELINC, DEDICOM, and PARATUCK2 as well as nonnegative variants of all of the above. The N-way Toolbox, Tensor Toolbox, and Multilinear Engine are examples of software packages for working with tensors.","['Multilinear algebra', 'Tensor (intrinsic definition)', 'Singular value decomposition', 'Tensor algebra', 'Multilinear map', 'Toolbox', 'Principal component analysis', 'Rank (graph theory)', 'Mathematics', 'Algebra over a field', 'Cartesian tensor', 'Linear algebra', 'Software', 'Matrix (chemical analysis)', 'Tucker decomposition', 'Tensor decomposition', 'Computer science', 'Pure mathematics', 'Tensor density', 'Algorithm', 'Combinatorics', 'Mathematical analysis', 'Geometry', 'Exact solutions in general relativity', 'Tensor field', 'Statistics', 'Materials science', 'Current algebra', 'Jordan algebra', 'Composite material', 'Filtered algebra', 'Programming language', 'Division algebra']","tensor, chemometrics, signal processing, numerical linear algebra, computer vision, numerical analysis, data mining, neuroscience, graph analysis, tensor decomposition, matrix singular value decomposition, tucker decomposition, principal component analysis, tensor decompositions, indscal, parafac2, candelinc, dedicom, paratuck2, ##ne, tensor toolbox, multilinear engine"
Paper_01549,Commentary: The Materials Project: A materials genome approach to accelerating materials innovation,"['Anubhav Jain', 'Shyue Ping Ong', 'Geoffroy Hautier', 'Wei Chen', 'William D. Richards', 'Stephen Dacek', 'Shreyas Cholia', 'Dan Gunter', 'David Skinner', 'Gerbrand Ceder', 'Kristin A. Persson']",2013,APL Materials,Journal,,,1,1,10.1063/1.4812323,"Accelerating the discovery of advanced materials is essential for human welfare and sustainable, clean energy. In this paper, we introduce the Materials Project (www.materialsproject.org), a core program of the Materials Genome Initiative that uses high-throughput computing to uncover the properties of all known inorganic materials. This open dataset can be accessed through multiple channels for both interactive exploration and data mining. The Materials Project also seeks to create open-source platforms for developing robust, sophisticated materials analyses. Future efforts will enable users to perform ''rapid-prototyping'' of new materials in silico, and provide researchers with new avenues for cost-effective, data-driven materials design.","['Materials processing', 'Systems engineering', 'Nanotechnology', 'Computer science', 'Materials science', 'Data science', 'Engineering', 'Manufacturing engineering']","human, materials project, materials, materials genome, inorganic, interactive exploration, data mining, [PAD]"
Paper_01550,Wireless Communications,['Andrea Goldsmith'],2005,Unknown,Unknown,,,,,10.1017/cbo9780511841224,"Wireless technology is a truly revolutionary paradigm shift, enabling multimedia communications between people and devices from any location. It also underpins exciting applications such as sensor networks, smart homes, telemedicine, and automated highways. This book provides a comprehensive introduction to the underlying theory, design techniques and analytical tools of wireless communications, focusing primarily on the core principles of wireless system design. The book begins with an overview of wireless systems and standards. The characteristics of the wireless channel are then described, including their fundamental capacity limits. Various modulation, coding, and signal processing schemes are then discussed in detail, including state-of-the-art adaptive modulation, multicarrier, spread spectrum, and multiple antenna techniques. The concluding chapters deal with multiuser communications, cellular system design, and ad-hoc network design. Design insights and tradeoffs are emphasized throughout the book. It contains many worked examples, over 200 figures, almost 300 homework exercises, over 700 references, and is an ideal textbook for students.","['Wireless', 'Computer science', 'Wireless network', 'Telecommunications', 'Wireless ad hoc network', 'Engineering']","wireless technology, multimedia communications, sensor networks, smart homes, telemedicine, automated highways, wireless communications, wireless system design, coding, signal processing schemes, adaptive modulation, multicarrier, spread spectrum, multiple antenna techniques, multiuser communications, cellular system design"
Paper_01551,Business Dynamics: Systems Thinking and Modeling for a Complex World,['John D. Sterman'],2000,['Journal of the Operational Research Society'],Unknown,,472-473,53,4,10.1057/palgrave.jors.2601336,"Introduction Part I. Perspective and Process 1. Learning In and About Complex Systems 2. System Dynamics In Action 3. The Modeling Process 4. Structure and Behavior of Dynamic Systems Part II. Tools for Systems Thinking 5. Causal Loop Diagrams 6. Stocks and Flows 7. Dynamics of Stocks and Flows 8. Closing the Loop: Dynamics of Simple Structures Part III. The Dynamics of Growth 9. S-Shaped Growth: Epidemics, Innovation Diffusion, and the Growth of New Products 10. Path Dependence and Positive Feedback Part IV. Tools for Modeling Dynamic Systems 11. Delays 12. Coflows and Aging Chains 13. Modeling Decision Making 14. Forming Non-linear Relationships Part V. Instability and Oscillation 15. Modeling Human Behavior: Bounded Rationality or Rational Expectations? 16. Forecasts and Fudge Factors: Modeling Expectation Formation 17. Supply Chains and the Origin of Oscillations 18. Managing Supply Chains in Manufacturing 19. The Labor Supply Chain and the Origin of Business Cycles 20. The Invisible Hand Sometimes Shakes: Commodity Cycles Part VI. Validation and Model Testing 21. Truth and Beauty Part VII. Commencement 22. Challenges for the Future Appendix A: Numerical Integration Appendix B: Noise References Index","['Supply chain', 'System dynamics', 'Causal loop diagram', 'Rationality', 'Bounded rationality', 'Economics', 'Computer science', 'Industrial engineering', 'Engineering', 'Microeconomics', 'Marketing', 'Business', 'Artificial intelligence', 'Law', 'Political science']","complex systems, system dynamics, modeling, dynamic systems, systems thinking, causal loop diagrams, innovation diffusion, path dependence, positive feedback, delays, coflows, aging chains, - linear relationships, instability, oscillation, human behavior, bounded rationality, rational expectations, forecasts, fudge factors, expectation formation, supply chains, osci, supply chains, manufacturing, labor supply chain, business cycles, commodity cycles, validation, model testing, truth, numerical integration, noise references index"
Paper_01553,Adolescence-limited and life-course-persistent antisocial behavior: A developmental taxonomy.,['Terrie E. Moffitt'],1993,Psychological Review,Journal,,674-701,100,4,10.1037/0033-295x.100.4.674,"A dual taxonomy is presented to reconcile 2 incongruous facts about antisocial behavior: (a) It shows impressive continuity over age, but (b) its prevalence changes dramatically over age, increasing almost 10-fold temporarily during adolescence. This article suggests that delinquency conceals 2 distinct categories of individuals, each with a unique natural history and etiology: A small group engages in antisocial behavior of 1 sort or another at every life stage, whereas a larger group is antisocial only during adolescence. According to the theory of life-course-persistent antisocial behavior, children's neuropsychological problems interact cumulatively with their criminogenic environments across development, culminating in a pathological personality. According to the theory of adolescence-limited antisocial behavior, a contemporary maturity gap encourages teens to mimic antisocial behavior in ways that are normative and adjustive.","['Psychology', 'Normative', 'Antisocial personality disorder', 'Developmental psychology', 'Psychopathy', 'Life course approach', 'Juvenile delinquency', 'Neuropsychology', 'Personality', 'Poison control', 'Injury prevention', 'Social psychology', 'Cognition', 'Psychiatry', 'Medicine', 'Philosophy', 'Environmental health', 'Epistemology']","antisocial behavior, delinquency, ##social behavior, neuropsychological problems, criminogenic, pathological personality, maturity gap, antisocial behavior"
Paper_01554,Health Measurement Scales: A Practical Guide to Their Development and Use,"['David L. Streiner', 'Geoffrey R. Norman', 'John Cairney']",1989,['Journal of Psychosomatic Research'],Unknown,,294,36,3,10.1016/0022-3999(92)90105-b,1. Introduction 2. Basic concepts 3. Devising the items 4. Scaling responses 5. Selecting the items 6. Biases in responding 7. From items to scales 8. Reliability 9. Generalizability theory 10. Validity 11. Measuring change 12. Item response theory 13. Methods of administration 14. Ethical considerations 15. Reporting test results Appendices,"['Generalizability theory', 'Reliability (semiconductor)', 'Item response theory', 'Psychology', 'Test (biology)', 'Classical test theory', 'Scale (ratio)', 'Test theory', 'Theory of change', 'Applied psychology', 'Psychometrics', 'Computer science', 'Management science', 'Clinical psychology', 'Developmental psychology', 'Engineering', 'Sociology', 'Geography', 'Power (physics)', 'Paleontology', 'Physics', 'Cartography', 'Quantum mechanics', 'Anthropology', 'Biology']","scaling responses, ##es, reliability, generalizability theory, validity, measuring, item response theory, administration, ethical considerations, reporting, [PAD], [PAD], [PAD] [PAD], [PAD] [PAD], [PAD] [PAD], [PAD], [PAD] [PAD], [PAD] [PAD], [PAD] [PAD], [PAD] [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD] [PAD], [PAD], [PAD] [PAD], [PAD] [PAD], [PAD], [PAD] [PAD], [PAD], [PAD] [PAD], [PAD] [PAD] [PAD], [PAD] [PAD], [PAD] [PAD], [PAD], [PAD], [PAD], [PAD] [PAD] [PAD] [PAD], [PAD], [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD], [PAD] [PAD], [PAD] [PAD], [PAD] [PAD], [PAD], [PAD], [PAD], [PAD], [PAD] [PAD], [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD]"
Paper_01555,New Colorimetric Cytotoxicity Assay for Anticancer-Drug Screening,"['Philip Skehan', 'Ritsa Storeng', 'Dominic A. Scudiero', 'Anne Monks', 'jeannette mcmahon', 'David T. Vistica', 'James T. Warren', 'Heidi R. Bokesch', 'Susan Kenney', 'M. R. Boyd']",1990,JNCI Journal of the National Cancer Institute,Journal,,1107-1112,82,13,10.1093/jnci/82.13.1107,"Journal Article New Colorimetric Cytotoxicity Assay for Anticancer-Drug Screening Get access Philip Skehan, Philip Skehan * Developmental Therapeutics Program, Division of Cancer Treatment * Correspondence to: Philip Skehan, M.D., Developmental Therapeutics Program, Division of Cancer Treatment, Bldg. 560, Rm. 3260, National Cancer Institute, Frederick Cancer Research Facility, Frederick, MD 21701 Search for other works by this author on: Oxford Academic PubMed Google Scholar Ritsa Storeng, Ritsa Storeng Developmental Therapeutics Program, Division of Cancer Treatment Search for other works by this author on: Oxford Academic PubMed Google Scholar Dominic Scudiero, Dominic Scudiero Program Resources, Inc., National Cancer Institute, Frederick Cancer Research FacilityFrederick, MD. Search for other works by this author on: Oxford Academic PubMed Google Scholar Anne Monks, Anne Monks Program Resources, Inc., National Cancer Institute, Frederick Cancer Research FacilityFrederick, MD. Search for other works by this author on: Oxford Academic PubMed Google Scholar James McMahon, James McMahon Developmental Therapeutics Program, Division of Cancer Treatment Search for other works by this author on: Oxford Academic PubMed Google Scholar David Vistica, David Vistica Developmental Therapeutics Program, Division of Cancer Treatment Search for other works by this author on: Oxford Academic PubMed Google Scholar Jonathan T. Warren, Jonathan T. Warren Developmental Therapeutics Program, Division of Cancer Treatment Search for other works by this author on: Oxford Academic PubMed Google Scholar Heidi Bokesch, Heidi Bokesch Program Resources, Inc., National Cancer Institute, Frederick Cancer Research FacilityFrederick, MD. Search for other works by this author on: Oxford Academic PubMed Google Scholar Susan Kenney, Susan Kenney Developmental Therapeutics Program, Division of Cancer Treatment Search for other works by this author on: Oxford Academic PubMed Google Scholar Michael R. Boyd Michael R. Boyd Developmental Therapeutics Program, Division of Cancer Treatment, National Cancer InstituteBethesda, MD. Search for other works by this author on: Oxford Academic PubMed Google Scholar JNCI: Journal of the National Cancer Institute, Volume 82, Issue 13, 4 July 1990, Pages 1107–1112, https://doi.org/10.1093/jnci/82.13.1107 Published: 04 July 1990 Article history Received: 05 September 1980 Revision received: 11 December 1989 Accepted: 15 March 1990 Published: 04 July 1990","['Chromatography', 'Sulforhodamine B', 'Microtiter plate', 'Cytotoxicity', 'Resazurin', 'Trichloroacetic acid', 'Bradford protein assay', 'Plate reader', 'Acetic acid', 'Chemistry', 'Tris', 'Fluorescence', 'Lowry protein assay', 'Molecular biology', 'Biochemistry', 'In vitro', 'Biology', 'Quantum mechanics', 'Casein', 'Physics']","color, developmental therapeutic, developmental therapeutic"
Paper_01556,The use of partial least squares path modeling in international marketing,"['Jörg Henseler', 'Christian M. Ringle', 'Rudolf R. Sinkovics']",2009,Advances in international marketing,Unknown,,277-319,,,10.1108/s1474-7979(2009)0000020014,"In order to determine the status quo of PLS path modeling in international marketing research, we conducted an exhaustive literature review. An evaluation of double-blind reviewed journals through important academic publishing databases (e.g., ABI/Inform, Elsevier ScienceDirect, Emerald Insight, Google Scholar, PsycINFO, Swetswise) revealed that more than 30 academic articles in the domain of international marketing (in a broad sense) used PLS path modeling as means of statistical analysis. We assessed what the main motivation for the use of PLS was in respect of each article. Moreover, we checked for applications of PLS in combination with one or more additional methods, and whether the main reason for conducting any additional method(s) was mentioned.","['Partial least squares regression', 'Path analysis (statistics)', 'Status quo', 'PsycINFO', 'International marketing', 'Marketing research', 'Path (computing)', 'Psychology', 'Computer science', 'Marketing', 'Statistics', 'Mathematics', 'Political science', 'MEDLINE', 'Business', 'Law', 'Programming language']","pls path modeling, international marketing research, academic publishing databases, else, emerald insight, google scholar, psycinfo, ##etswise, international marketing, pls path modeling, statistical analysis, ##s, pls"
Paper_01558,Work and motivation,['Victor H. Vroom'],1964,"['The SAGE Encyclopedia of Industrial and Organizational Psychology,\n                    2nd edition']",Unknown,,,,,10.4135/9781483386874.n601,"Why do people choose the careers they do? What factors cause people to be satisfied with their work? No single work did more to make concepts like motive, goal incentive, and attitude part of the workplace vocabulary. This landmark work, originally published in 1964, integrates the work of hundreds of researchers in individual workplace behavior to explain choice of work, job satisfaction, and job performance. Includes an extensive new introduction that highlights and updates his model for current organization behavior educators and students, as well as professionals who must extract the highest levels of productivity from today's downsized workforces.","['Work (physics)', 'Incentive', 'Productivity', 'Job satisfaction', 'Psychology', 'Vocabulary', 'Work motivation', 'Public relations', 'Social psychology', 'Applied psychology', 'Political science', 'Engineering', 'Economics', 'Microeconomics', 'Economic growth', 'Mechanical engineering', 'Linguistics', 'Philosophy']","motive, goal incentive, attitude, individual workplace behavior, job satisfaction, job performance, organization behavior educators"
Paper_01561,Diagnostic criteria for multiple sclerosis: 2010 Revisions to the McDonald criteria,"['Chris H. Polman', 'Stephen C. Reingold', 'Brenda Banwell', 'M. Clanet', 'Jeffrey A. Cohen', 'Massimo Filippi', 'Kazuo Fujihara', 'Eva Havrdová', 'Michael Hutchinson', 'Ludwig Kappos', 'Fred Lublin', 'Xavier Montalbán', 'Paul O’Connor', 'Magnhild Sandberg‐Wollheim', 'Alan J. Thompson', 'Emmanuelle Waubant', 'Brian G. Weinshenker', 'Jerry S. Wolinsky']",2011,Annals of Neurology,Journal,,292-302,69,2,10.1002/ana.22366,"New evidence and consensus has led to further revision of the McDonald Criteria for diagnosis of multiple sclerosis. The use of imaging for demonstration of dissemination of central nervous system lesions in space and time has been simplified, and in some circumstances dissemination in space and time can be established by a single scan. These revisions simplify the Criteria, preserve their diagnostic sensitivity and specificity, address their applicability across populations, and may allow earlier diagnosis and more uniform and widespread use.","['Multiple sclerosis', 'McDonald criteria', 'Medicine', 'Space (punctuation)', 'Diagnostic test', 'Medical physics', 'Computer science', 'Intensive care medicine', 'Pediatrics', 'Psychiatry', 'Operating system']","mcdonald criteria, multiple sclerosis, imaging, central nervous system lesions, diagnostic sensitivity, [PAD] [PAD]"
Paper_01563,The Commitment-Trust Theory of Relationship Marketing,"['Robert M. Morgan', 'Shelby D. Hunt']",1994,Journal of Marketing,Journal,,20-38,58,3,10.1177/002224299405800302,"Relationship marketing—establishing, developing, and maintaining successful relational exchanges—constitutes a major shift in marketing theory and practice. After conceptualizing relationship marketing and discussing its ten forms, the authors (1) theorize that successful relationship marketing requires relationship commitment and trust, (2) model relationship commitment and trust as key mediating variables, (3) test this key mediating variable model using data from automobile tire retailers, and (4) compare their model with a rival that does not allow relationship commitment and trust to function as mediating variables. Given the favorable test results for the key mediating variable model, suggestions for further explicating and testing it are offered.","['Relationship marketing', 'Key (lock)', 'Marketing', 'Business', 'Structural equation modeling', 'Test (biology)', 'Variable (mathematics)', 'Function (biology)', 'Marketing management', 'Computer science', 'Mathematics', 'Paleontology', 'Mathematical analysis', 'Computer security', 'Machine learning', 'Evolutionary biology', 'Biology']","relationship marketing, relational exchanges, marketing, relationship marketing, relationship marketing, relationship commitment, trust, relationship commitment, trust, automobile tire retailers, relationship commitment"
Paper_01564,Agency Theory: An Assessment and Review,['Kathleen M. Eisenhardt'],1989,Academy of Management Review,Journal,,57-74,14,1,10.5465/amr.1989.4279003,"Agency theory is an important, yet controversial, theory. This paper reviews agency theory, its contributions to organization theory, and the extant empirical work and develops testable propositions. The conclusions are that agency theory (a) offers unique insight into information systems, outcome uncertainty, incentives, and risk and (b) is an empirically valid perspective, particularly when coupled with complementary perspectives. The principal recommendation is to incorporate an agency perspective in studies of the many problems having a cooperative structure.","['Agency (philosophy)', 'Organizational behavior', 'Organizational theory', 'Principal–agent problem', 'Business', 'Sociology', 'Psychology', 'Public relations', 'Political science', 'Management', 'Social psychology', 'Economics', 'Social science', 'Corporate governance']","agency theory, agency theory, organization theory, agency theory, information systems, outcome uncertainty, incentives, risk, agency perspective, cooperative structure"
Paper_01565,Antenna Theory: Analysis and Design,['Constantine A. Balanis'],1982,['Proceedings of the IEEE'],Unknown,,989-990,72,7,10.1109/proc.1984.12959,"The most-up-to-date resource available on antenna theory and design. Expanded coverage of design procedures and equations makes meeting ABET design requirements easy and prepares readers for authentic situations in industry. New coverage of microstrip antennas exposes readers to information vital to a wide variety of practical applications.Computer programs at end of each chapter and the accompanying disk assist in problem solving, design projects and data plotting.-- Includes updated material on moment methods, radar cross section, mutual impedances, aperture and horn antennas, and antenna measurements.-- Outstanding 3-dimensional illustrations help readers visualize the entire antenna radiation pattern.","['Variety (cybernetics)', 'Antenna (radio)', 'Computer science', 'Engineering', 'Electronic engineering', 'Electrical engineering', 'Systems engineering', 'Artificial intelligence']","antenna theory, microstrip antennas, computer programs, design, data plotting, moment methods, radar cross section, mutual impedances, horn antennas, antenna measurements, antenna radiation pattern"
Paper_01567,IOP Conference Series: Earth and Environmental Science,"['Inez Slamet', 'Rauza Sukma', 'Zuldadan Naspendra', 'Aprisal Aprisal', 'N Hijri', 'Mimien Harianti']",2020,IOP Conference Series Earth and Environmental Science,Conference,IOP Publishing,,,,10.1088/issn.1755-1315,s si s t a n t 678,"['Series (stratigraphy)', 'Earth (classical element)', 'Astrobiology', 'Geology', 'Physics', 'Astronomy', 'Paleontology']",
Paper_01569,Statistical significance for genomewide studies,"['John D. Storey', 'Robert Tibshirani']",2003,Proceedings of the National Academy of Sciences,Journal,,9440-9445,100,16,10.1073/pnas.1530509100,"With the increase in genomewide experiments and the sequencing of multiple genomes, the analysis of large data sets has become commonplace in biology. It is often the case that thousands of features in a genomewide data set are tested against some null hypothesis, where a number of features are expected to be significant. Here we propose an approach to measuring statistical significance in these genomewide studies based on the concept of the false discovery rate. This approach offers a sensible balance between the number of true and false positives that is automatically calibrated and easily interpreted. In doing so, a measure of statistical significance called the q value is associated with each tested feature. The q value is similar to the well known p value, except it is a measure of significance in terms of the false discovery rate rather than the false positive rate. Our approach avoids a flood of false positive results, while offering a more liberal criterion than what has been used in genome scans for linkage.","['False positive paradox', 'False discovery rate', 'False positives and false negatives', 'False positive rate', 'Statistical hypothesis testing', 'Multiple comparisons problem', 'Genome', 'Computer science', 'Null hypothesis', 'Set (abstract data type)', 'Linkage (software)', 'Feature (linguistics)', 'Computational biology', 'Measure (data warehouse)', 'Data mining', 'Statistics', 'Biology', 'Genetics', 'Artificial intelligence', 'Mathematics', 'Gene', 'Linguistics', 'Philosophy', 'Programming language']","genomewide experiments, multiple genomes, statistical significance, false discovery rate, statistical significance, q value, q, p, false discovery, genome scans, linkage"
Paper_01571,Cluster Analysis,"['Barry J. Everitt', 'Sabine Landau', 'Morven Leese']",1974,['British Journal of Psychiatry'],Unknown,,474-474,120,557,10.1192/bjp.120.557.474,"Cluster analysis comprises a range of methods for classifying multivariate data into subgroups. By organising multivariate data into such subgroups, clustering can help reveal the characteristics of any structure or patterns present. These techniques are applicable in a wide range of areas such as medicine, psychology and market research. This fourth edition of the highly successful Cluster Analysis represents a thorough revision of the third edition and covers new and developing areas such as classification likelihood and neural networks for clustering. Real life examples are used throughout to demonstrate the application of the theory, and figures are used extensively to illustrate graphical techniques. The book is comprehensive yet relatively non-mathematical, focusing on the practical aspects of cluster analysis.","['Cluster analysis', 'Cluster (spacecraft)', 'Multivariate statistics', 'Computer science', 'Range (aeronautics)', 'Data mining', 'Multivariate analysis', 'Data science', 'Artificial intelligence', 'Machine learning', 'Engineering', 'Programming language', 'Aerospace engineering']","cluster analysis, multivariate data, subgroup, multivariate data, clustering, medicine, psychology, market research, cluster analysis, classification likelihood, neural networks, clustering, graphical techniques, cluster analysis, [PAD] [PAD], [PAD] [PAD], [PAD], [PAD] [PAD] [PAD], [PAD], [PAD] [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD], [PAD]"
Paper_01573,The american college of rheumatology 1990 criteria for the classification of fibromyalgia,"['Frederick Wolfe', 'H A Smythe', 'Muhammad B. Yunus', 'Robert M. Bennett', 'Claire Bombardier', 'Don L. Goldenberg', 'Peter Tugwell', 'Stephen Campbell', 'Micha Abeles', 'Patricia Clark', 'Adel G. Fam', 'Stephen J. Farber', 'Justus J. Fiechtner', 'Cindy Franklin', 'Robert Gatter', 'Daniel Hamaty', 'James Lessard', 'Alan S. Lichtbroun', 'Alfonse T. Masi', 'Glenn A. McCain', 'W. J. Reynolds', 'Thomas J. Romano', 'I. Jon Russell', 'Robert P. Sheon']",1990,Arthritis & Rheumatism,Journal,,160-172,33,2,10.1002/art.1780330203,"Abstract To develop criteria for the classification of fibromyalgia, we studied 558 consecutive patients: 293 patients with fibromyalgia and 265 control patients. Interviews and examinations were performed by trained, blinded assessors. Control patients for the group with primary fibromyalgia were matched for age and sex, and limited to patients with disorders that could be confused with primary fibromyalgia. Control patients for the group with secondary‐concomitant fibromyalgia were matched for age, sex, and concomitant rheumatic disorders. Widespread pain (axial plus upper and lower segment plus left‐ and right‐sided pain) was found in 97.6% of all patients with fibromyalgia and in 69.1% of all control patients. The combination of widespread pain and mild or greater tenderness in ⩾ 11 of 18 tender point sites yielded a sensitivity of 88.4% and a specificity of 81.1%. Primary fibromyalgia patients and secondary‐concomitant fibromyalgia patients did not differ statistically in any major study variable, and the criteria performed equally well in patients with and those without concomitant rheumatic conditions. The newly proposed criteria for the classification of fibromyalgia are 1) widespread pain in combination with 2) tenderness at 11 or more of the 18 specific tender point sites. No exclusions are made for the presence of concomitant radiographic or laboratory abnormalities. At the diagnostic or classification level, the distinction between primary fibromyalgia and secondary‐concomitant fibromyalgia (as defined in the text) is abandoned.","['Fibromyalgia', 'Concomitant', 'Medicine', 'Rheumatology', 'Internal medicine', 'Physical therapy', 'Tenderness', 'Surgery']","blinded, primary fibromy, widespread pain, left, right, widespread, primary fibromy, con, widespread pain, primary fibromy"
Paper_01574,Velvet: Algorithms for de novo short read assembly using de Bruijn graphs,"['Daniel R. Zerbino', 'Ewan Birney']",2008,Genome Research,Journal,,821-829,18,5,10.1101/gr.074492.107,"We have developed a new set of algorithms, collectively called “Velvet,” to manipulate de Bruijn graphs for genomic sequence assembly. A de Bruijn graph is a compact representation based on short words ( k -mers) that is ideal for high coverage, very short read (25–50 bp) data sets. Applying Velvet to very short reads and paired-ends information only, one can produce contigs of significant length, up to 50-kb N50 length in simulations of prokaryotic data and 3-kb N50 on simulated mammalian BACs. When applied to real Solexa data sets without read pairs, Velvet generated contigs of ∼8 kb in a prokaryote and 2 kb in a mammalian BAC, in close agreement with our simulated results without read-pair information. Velvet represents a new approach to assembly that can leverage very short reads in combination with read pairs to produce useful assemblies.","['Contig', 'De Bruijn sequence', 'Velvet', 'De Bruijn graph', 'Biology', 'k-mer', 'Sequence assembly', 'Algorithm', 'Computer science', 'Computational biology', 'Genetics', 'Combinatorics', 'DNA sequencing', 'Genome', 'Mathematics', 'Gene', 'Gene expression', 'Transcriptome', 'Organic chemistry', 'Chemistry']","velvet, genomic sequence assembly, compact representation, prokar, mammalian bacs, ##kar, velvet"
Paper_01577,The Benefits of Facebook “Friends:” Social Capital and College Students’ Use of Online Social Network Sites,"['Nicole B. Ellison', 'Charles Steinfield', 'Cliff Lampe']",2007,Journal of Computer-Mediated Communication,Journal,,1143-1168,12,4,10.1111/j.1083-6101.2007.00367.x,"This study examines the relationship between use of Facebook, a popular online social network site, and the formation and maintenance of social capital. In addition to assessing bonding and bridging social capital, we explore a dimension of social capital that assesses one's ability to stay connected with members of a previously inhabited community, which we call maintained social capital. Regression analyses conducted on results from a survey of undergraduate students (N = 286) suggest a strong association between use of Facebook and the three types of social capital, with the strongest relationship being to bridging social capital. In addition, Facebook usage was found to interact with measures of psychological well-being, suggesting that it might provide greater benefits for users experiencing low self-esteem and low life satisfaction.","['Social capital', 'Social network (sociolinguistics)', 'Bridging (networking)', 'Psychology', 'Social psychology', 'Social engagement', 'Social mobility', 'Association (psychology)', 'Sociology', 'Business', 'Demographic economics', 'Social media', 'Economics', 'World Wide Web', 'Social science', 'Computer science', 'Computer network', 'Psychotherapist']","facebook, online social network site, social capital, ##ging, social capital, maintained social capital, undergraduate, facebook, social, facebook usage, psychological well - being"
Paper_01579,Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition,"['Kaiming He', 'Xiangyu Zhang', 'Shaoqing Ren', 'Jian Sun']",2015,IEEE Transactions on Pattern Analysis and Machine Intelligence,Journal,,1904-1916,37,9,10.1109/tpami.2015.2389824,"Existing deep convolutional neural networks (CNNs) require a fixed-size (e.g., 224 × 224) input image. This requirement is ""artificial"" and may reduce the recognition accuracy for the images or sub-images of an arbitrary size/scale. In this work, we equip the networks with another pooling strategy, ""spatial pyramid pooling"", to eliminate the above requirement. The new network structure, called SPP-net, can generate a fixed-length representation regardless of image size/scale. Pyramid pooling is also robust to object deformations. With these advantages, SPP-net should in general improve all CNN-based image classification methods. On the ImageNet 2012 dataset, we demonstrate that SPP-net boosts the accuracy of a variety of CNN architectures despite their different designs. On the Pascal VOC 2007 and Caltech101 datasets, SPP-net achieves state-of-the-art classification results using a single full-image representation and no fine-tuning. The power of SPP-net is also significant in object detection. Using SPP-net, we compute the feature maps from the entire image only once, and then pool features in arbitrary regions (sub-images) to generate fixed-length representations for training the detectors. This method avoids repeatedly computing the convolutional features. In processing test images, our method is 24-102 × faster than the R-CNN method, while achieving better or comparable accuracy on Pascal VOC 2007. In ImageNet Large Scale Visual Recognition Challenge (ILSVRC) 2014, our methods rank #2 in object detection and #3 in image classification among all 38 teams. This manuscript also introduces the improvement made for this competition.","['Pooling', 'Pascal (unit)', 'Artificial intelligence', 'Computer science', 'Convolutional neural network', 'Pattern recognition (psychology)', 'Pyramid (geometry)', 'Contextual image classification', 'Object detection', 'Deep learning', 'Feature extraction', 'Computer vision', 'Image (mathematics)', 'Mathematics', 'Geometry', 'Programming language']","deep convolutional neural networks, cnn, recognition accuracy, ##ing, spatial pyramid pooling, pyramid pooling, object deformations, imagenet, cnn, pascal voc, caltech10, object detection, feature maps, pascal vo, imagenet large scale visual recognition challenge, ##s, object detection, image classification"
Paper_01580,The Costs and Benefits of Ownership: A Theory of Vertical and Lateral Integration,"['Sanford J. Grossman', 'Oliver Hart']",1986,Journal of Political Economy,Journal,,691-719,94,4,10.1086/261404,"Our theory of costly contracts emphasizes the contractual rights can by of two types: specific rights and residual rights. When it is costly to list all specific rights over assets in the contract, it may be optimal to let one party purchase all residual rights. Ownership is the purchase of these residual rights. When residual rights are purchased by one party, they are lost by a second party, and this inevitably creates distortions. Firm 1 purchases firm 2 when firm 1's control increases the productivity of its management more than the loss of control decreases the productivity of firm 2's management.","['Residual', 'Productivity', 'Property rights', 'Business', 'Theory of the firm', 'Control (management)', 'Industrial organization', 'Microeconomics', 'Law and economics', 'Economics', 'Management', 'Algorithm', 'Computer science', 'Macroeconomics']","costly contracts, contractual rights, specific rights, residual rights, residual rights, residual rights, residual rights, [PAD], [PAD], [PAD] [PAD] [PAD], [PAD] [PAD] [PAD], [PAD] [PAD] [PAD]"
Paper_01581,Prediction of Coronary Heart Disease Using Risk Factor Categories,"['Peter W.F. Wilson', 'Ralph B. DʼAgostino', 'Daniel Levy', 'Albert M. Belanger', 'Halit Silbershatz', 'William B. Kannel']",1998,Circulation,Journal,,1837-1847,97,18,10.1161/01.cir.97.18.1837,"Background —The objective of this study was to examine the association of Joint National Committee (JNC-V) blood pressure and National Cholesterol Education Program (NCEP) cholesterol categories with coronary heart disease (CHD) risk, to incorporate them into coronary prediction algorithms, and to compare the discrimination properties of this approach with other noncategorical prediction functions. Methods and Results —This work was designed as a prospective, single-center study in the setting of a community-based cohort. The patients were 2489 men and 2856 women 30 to 74 years old at baseline with 12 years of follow-up. During the 12 years of follow-up, a total of 383 men and 227 women developed CHD, which was significantly associated with categories of blood pressure, total cholesterol, LDL cholesterol, and HDL cholesterol (all P &lt;.001). Sex-specific prediction equations were formulated to predict CHD risk according to age, diabetes, smoking, JNC-V blood pressure categories, and NCEP total cholesterol and LDL cholesterol categories. The accuracy of this categorical approach was found to be comparable to CHD prediction when the continuous variables themselves were used. After adjustment for other factors, ≈28% of CHD events in men and 29% in women were attributable to blood pressure levels that exceeded high normal (≥130/85). The corresponding multivariable-adjusted attributable risk percent associated with elevated total cholesterol (≥200 mg/dL) was 27% in men and 34% in women. Conclusions —Recommended guidelines of blood pressure, total cholesterol, and LDL cholesterol effectively predict CHD risk in a middle-aged white population sample. A simple coronary disease prediction algorithm was developed using categorical variables, which allows physicians to predict multivariate CHD risk in patients without overt CHD.","['Medicine', 'Blood pressure', 'Cholesterol', 'Internal medicine', 'Diabetes mellitus', 'Risk factor', 'Cohort', 'Population', 'Cardiology', 'Coronary heart disease', 'Cohort study', 'Endocrinology', 'Environmental health']","blood, national cho, coronary heart disease, coronary prediction algorithms, ##categorical, blood, total, ##l, ##l cho, ##d, blood, total, ##l, coronary disease prediction algorithm, categorical variables, multivariate"
Paper_01583,UK Biobank: An Open Access Resource for Identifying the Causes of a Wide Range of Complex Diseases of Middle and Old Age,"['Cathie Sudlow', 'John Gallacher', 'Naomi E. Allen', 'Valerie Beral', 'Paul R. Burton', 'John Danesh', 'Paul Downey', 'Paul Elliott', 'Jane Green', 'Martin Landray', 'Bette Liu', 'Paul M. Matthews', 'Giok Ong', 'Jill P. Pell', 'Alan J. Silman', 'A. P. Young', 'Tim Sprosen', 'Tim Peakman', 'Rory Collins']",2015,PLoS Medicine,Journal,,e1001779-e1001779,12,3,10.1371/journal.pmed.1001779,"Cathie Sudlow and colleagues describe the UK Biobank, a large population-based prospective study, established to allow investigation of the genetic and non-genetic determinants of the diseases of middle and old age.","['Biobank', 'Biorepository', 'Medicine', 'Population', 'Gerontology', 'Demography', 'Environmental health', 'Bioinformatics', 'Biology', 'Sociology']","uk biobank, old age, [PAD], [PAD]"
Paper_01586,An Invitation to Reflexive Sociology.,"['Charles Camic', 'Pierre Bourdieu', 'Loïc Wacquant']",1993,Contemporary Sociology A Journal of Reviews,Journal,,450-450,22,3,10.2307/2074573,"Over the last three decades, the French sociologist Pierre Bourdieu has produced one of the most imaginative and subtle bodies of social theory and research of the post war era. Yet, despite the influence of his work, no single introduction to his wide-ranging oeuvre is available. This book, intended for an English-speaking audience, offers a systematic and accessible overview, providing interpretive keys to the internal logic of Bourdieu's work by explicating thematic and methodological principles underlying his work. The structure of Bourdieu's theory of knowledge, practice, and society is first dissected by Loi c Wacquant; he then collaborates with Bourdieu in a dialogue in which they discuss central concepts of Bourdieu's work, confront the main objections and criticisms his work has met, and outline Bourdieu's views of the relation of sociology to philosophy, economics, history, and politics. The final section captures Bourdieu in action in the seminar room as he addresses the topic of how to practice the craft of reflexive sociology. Throughout, they stress Bourdieu's emphasis on reflexivity--his inclusion of a theory of intellectual practice as an integral component of a theory of society--and on method--particularly his manner of posing problems that permits a transfer of knowledge from one area of inquiry into another. Amplified by notes and an extensive bibliography, this synthetic view is essential reading for both students and advanced scholars. Pierre Bourdieu is Professor of Sociology at the Colle ge de France. Loi c J. D. Wacquant is a Junior Fellow, Society of Fellows, Harvard University.","['Reflexivity', 'Sociology', 'Epistemology', 'Social science', 'Philosophy']","social theory, philosophy, economics, politics, reflexive sociology, reflexivity, intellectual practice"
Paper_01587,Robust Face Recognition via Sparse Representation,"['John Wright', 'A. Yang', 'Arvind Ganesh', 'Shankar Sastry', 'Yi Ma']",2009,IEEE Transactions on Pattern Analysis and Machine Intelligence,Journal,,210-227,31,2,10.1109/tpami.2008.79,"We consider the problem of automatically recognizing human faces from frontal views with varying expression and illumination, as well as occlusion and disguise. We cast the recognition problem as one of classifying among multiple linear regression models and argue that new theory from sparse signal representation offers the key to addressing this problem. Based on a sparse representation computed by l{1}-minimization, we propose a general classification algorithm for (image-based) object recognition. This new framework provides new insights into two crucial issues in face recognition: feature extraction and robustness to occlusion. For feature extraction, we show that if sparsity in the recognition problem is properly harnessed, the choice of features is no longer critical. What is critical, however, is whether the number of features is sufficiently large and whether the sparse representation is correctly computed. Unconventional features such as downsampled images and random projections perform just as well as conventional features such as Eigenfaces and Laplacianfaces, as long as the dimension of the feature space surpasses certain threshold, predicted by the theory of sparse representation. This framework can handle errors due to occlusion and corruption uniformly by exploiting the fact that these errors are often sparse with respect to the standard (pixel) basis. The theory of sparse representation helps predict how much occlusion the recognition algorithm can handle and how to choose the training images to maximize robustness to occlusion. We conduct extensive experiments on publicly available databases to verify the efficacy of the proposed algorithm and corroborate the above claims.","['Sparse approximation', 'Robustness (evolution)', 'Artificial intelligence', 'Pattern recognition (psychology)', 'Facial recognition system', 'Computer science', 'Feature extraction', 'Biochemistry', 'Chemistry', 'Gene']","frontal views, illumination, occlusion, disguise, recognition, multiple linear regression models, sparse signal representation, sparse representation, object, face recognition, feature extraction, robustness, o, ##lusion, feature extraction, ##rsity, sparse representation, downsampled images, random projections, eigenfaces, laplacianfaces, sparse representation, o, sparse representation"
Paper_01589,A New Approach to the Economic Analysis of Nonstationary Time Series and the Business Cycle,['James D. Hamilton'],1989,Econometrica,Journal,,357-357,57,2,10.2307/1912559,"This paper proposes a very tractable approach to modeling changes in regime. The parameters of an autoregression are viewed as the outcome of a discrete-state Markov process. For example, the mean growth rate of a nonstationary series may be subject to occasional, discrete shifts. The econometrician is presumed not to observe these shifts directly, but instead must draw probabilistic inference about whether and when they may have occurred based on the observed behavior of the series. The paper presents an algorithm for drawing such probabilistic inference in the form of a nonlinear iterative filter","['Business cycle', 'Series (stratigraphy)', 'Economics', 'Time series', 'Econometrics', 'Macroeconomics', 'Mathematical economics', 'Mathematics', 'Statistics', 'Geology', 'Paleontology']","auto, ##gre, mean growth rate, nonstationary series, eco, nonlinear iterative filter, [PAD] [PAD], [PAD], [PAD] [PAD], [PAD] [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD] [PAD], [PAD], [PAD] [PAD], [PAD], [PAD] [PAD], [PAD], [PAD] [PAD], [PAD] [PAD], [PAD] [PAD] [PAD] [PAD] [PAD]"
Paper_01590,The Clavien-Dindo Classification of Surgical Complications,"['Pierre A. Clavien', 'Jeffrey Barkun', 'Michelle Oliveira', 'Jean‐Nicolas Vauthey', 'Daniel Dindo', 'Richard D. Schulick', 'Eduardo de Santibañés', 'Juan Pekolj', 'Ksenija Slankamenac', 'Claudio Bassi', 'Rolf Graf', 'René Vonlanthen', 'Robert Padbury', 'John L. Cameron', 'Masatoshi Makuuchi']",2009,Annals of Surgery,Journal,,187-196,250,2,10.1097/sla.0b013e3181b13ca2,"The lack of consensus on how to define and grade adverse postoperative events has greatly hampered the evaluation of surgical procedures. A new classification of complications, initiated in 1992, was updated 5 years ago. It is based on the type of therapy needed to correct the complication. The principle of the classification was to be simple, reproducible, flexible, and applicable irrespective of the cultural background. The aim of the current study was to critically evaluate this classification from the perspective of its use in the literature, by assessing interobserver variability in grading complex complication scenarios and to correlate the classification grades with patients', nurses', and doctors' perception.Reports from the literature using the classification system were systematically analyzed. Next, 11 scenarios illustrating difficult cases were prepared to develop a consensus on how to rank the various complications. Third, 7 centers from different continents, having routinely used the classification, independently assessed the 11 scenarios. An agreement analysis was performed to test the accuracy and reliability of the classification. Finally, the perception of the severity was tested in patients, nurses, and physicians by presenting 30 scenarios, each illustrating a specific grade of complication.We noted a dramatic increase in the use of the classification in many fields of surgery. About half of the studies used the contracted form, whereas the rest used the full range of grading. Two-thirds of the publications avoided subjective terms such as minor or major complications. The study of 11 difficult cases among various centers revealed a high degree of agreement in identifying and ranking complications (89% agreement), and enabled a better definition of unclear situations. Each grade of complications significantly correlated with the perception by patients, nurses, and physicians (P < 0.05, Kruskal-Wallis test).This 5-year evaluation provides strong evidence that the classification is valid and applicable worldwide in many fields of surgery. No modification in the general principle of classification is warranted in view of the use in ongoing publications and trials. Subjective, inaccurate, or confusing terms such as ""minor or major"" should be removed from the surgical literature.","['Medicine', 'Grading (engineering)', 'Complication', 'MEDLINE', 'Surgery', 'Civil engineering', 'Political science', 'Law', 'Engineering']","##operative events, surgical procedures, interobserver variability, complex complication scenarios, agreement analysis, major"
Paper_01593,SExtractor: Software for source extraction,"['E. Bertin', 'S. Arnouts']",1996,Astronomy and Astrophysics Supplement Series,Journal,,393-404,117,2,10.1051/aas:1996164,"We present the automated techniques we have developed for new software that optimally detects, deblends, measures and classifies sources from astronomical images: SExtractor (Source Extractor ). We show that a very reliable star/galaxy separation can be achieved on most images using a neural network trained with simulated images. Salient features of SExtractor include its ability to work on very large images, with minimal human intervention, and to deal with a wide variety of object shapes and magnitudes. It is therefore particularly suited to the analysis of large extragalactic surveys.","['Computer science', 'Software', 'Extractor', 'Salient', 'Artificial intelligence', 'Artificial neural network', 'Pattern recognition (psychology)', 'Computer vision', 'Engineering', 'Programming language', 'Process engineering']","automated techniques, deblends, astronomical images, sextractor, source extractor, neural network, simulated images, sextractor, large extragalactic surveys, [PAD], [PAD] [PAD], [PAD], [PAD] [PAD] [PAD] [PAD] [PAD], [PAD], [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD], [PAD], [PAD] [PAD], [PAD]"
Paper_01595,Chemistry with ADF,"['G. te Velde', 'F. Matthias Bickelhaupt', 'Evert Jan Baerends', 'Célia Fonseca Guerra', 'S. J. A. van Gisbergen', 'J. G. Snijders', 'Tom Ziegler']",2001,Journal of Computational Chemistry,Journal,,931-967,22,9,10.1002/jcc.1056,"Abstract We present the theoretical and technical foundations of the Amsterdam Density Functional (ADF) program with a survey of the characteristics of the code (numerical integration, density fitting for the Coulomb potential, and STO basis functions). Recent developments enhance the efficiency of ADF (e.g., parallelization, near order‐N scaling, QM/MM) and its functionality (e.g., NMR chemical shifts, COSMO solvent effects, ZORA relativistic method, excitation energies, frequency‐dependent (hyper)polarizabilities, atomic VDD charges). In the Applications section we discuss the physical model of the electronic structure and the chemical bond, i.e., the Kohn–Sham molecular orbital (MO) theory, and illustrate the power of the Kohn–Sham MO model in conjunction with the ADF‐typical fragment approach to quantitatively understand and predict chemical phenomena. We review the “Activation‐strain TS interaction” (ATS) model of chemical reactivity as a conceptual framework for understanding how activation barriers of various types of (competing) reaction mechanisms arise and how they may be controlled, for example, in organic chemistry or homogeneous catalysis. Finally, we include a brief discussion of exemplary applications in the field of biochemistry (structure and bonding of DNA) and of time‐dependent density functional theory (TDDFT) to indicate how this development further reinforces the ADF tools for the analysis of chemical phenomena. © 2001 John Wiley &amp; Sons, Inc. J Comput Chem 22: 931–967, 2001","['Chemistry', 'Density functional theory', 'Time-dependent density functional theory', 'Scaling', 'Computational chemistry', 'Reactivity (psychology)', 'Chemical shift', 'Coulomb', 'Solvent effects', 'Chemical bond', 'Hybrid functional', 'Quantum mechanics', 'Physical chemistry', 'Physics', 'Solvent', 'Organic chemistry', 'Medicine', 'Geometry', 'Mathematics', 'Alternative medicine', 'Pathology', 'Electron']","amsterdam density functional, numerical integration, density fitting, coulomb potential, sto basis functions, parallel, nmr chemical shifts, cosmo solvent effects, zora relativistic method, excitation energies, frequency ‐ dependent, atomic vdd charges, electronic structure, chemical bond, chemical reactivity, activation, organic chemistry, homogeneous catalysis, time ‐ dependent density functional theory"
Paper_01596,Declining Morbidity and Mortality among Patients with Advanced Human Immunodeficiency Virus Infection,"['Frank J. Palella', 'Kathleen M. Delaney', 'Anne C. Moorman', 'Mark O. Loveless', 'Jack Fuhrer', 'Glen A. Satten', 'Diane Aschman', 'Scott D. Holmberg']",1998,New England Journal of Medicine,Journal,,853-860,338,13,10.1056/nejm199803263381301,"National surveillance data show recent, marked reductions in morbidity and mortality associated with the acquired immunodeficiency syndrome (AIDS). To evaluate these declines, we analyzed data on 1255 patients, each of whom had at least one CD4+ count below 100 cells per cubic millimeter, who were seen at nine clinics specializing in the treatment of human immunodeficiency virus (HIV) infection in eight U.S. cities from January 1994 through June 1997.Mortality among the patients declined from 29.4 per 100 person-years in the first quarter of 1995 to 8.8 per 100 in the second quarter of 1997. There were reductions in mortality regardless of sex, race, age, and risk factors for transmission of HIV. The incidence of any of three major opportunistic infections (Pneumocystis carinii pneumonia, Mycobacterium avium complex disease, and cytomegalovirus retinitis) declined from 21.9 per 100 person-years in 1994 to 3.7 per 100 person-years by mid-1997. In a failure-rate model, increases in the intensity of antiretroviral therapy (classified as none, monotherapy, combination therapy without a protease inhibitor, and combination therapy with a protease inhibitor) were associated with stepwise reductions in morbidity and mortality. Combination antiretroviral therapy was associated with the most benefit; the inclusion of protease inhibitors in such regimens conferred additional benefit. Patients with private insurance were more often prescribed protease inhibitors and had lower mortality rates than those insured by Medicare or Medicaid.The recent declines in morbidity and mortality due to AIDS are attributable to the use of more intensive antiretroviral therapies.","['Medicine', 'Mortality rate', 'Pneumonia', 'Internal medicine', 'Incidence (geometry)', 'Esophageal candidiasis', 'Opportunistic infection', 'Pediatrics', 'Immunology', 'Viral disease', 'Human immunodeficiency virus (HIV)', 'Physics', 'Optics']","national surveillance, acquired immunodeficiency syndrome, human im, ##stic infections, pneumocyst, my, ##bacter, cytom, ##lov, antiretrov, ##l therapy, mono, combination antiretrov, private insurance, ##id"
Paper_01597,<b>Hard and Soft Acids and Bases</b>,['Ralph G. Pearson'],1963,Journal of the American Chemical Society,Journal,,3533-3539,85,22,10.1021/ja00905a001,"ADVERTISEMENT RETURN TO ISSUEPREVArticleNEXTHard and Soft Acids and BasesRalph G. PearsonCite this: J. Am. Chem. Soc. 1963, 85, 22, 3533–3539Publication Date (Print):November 1, 1963Publication History Published online1 May 2002Published inissue 1 November 1963https://pubs.acs.org/doi/10.1021/ja00905a001https://doi.org/10.1021/ja00905a001research-articleACS PublicationsRequest reuse permissionsArticle Views28682Altmetric-Citations7890LEARN ABOUT THESE METRICSArticle Views are the COUNTER-compliant sum of full text article downloads since November 2008 (both PDF and HTML) across all institutions and individuals. These metrics are regularly updated to reflect usage leading up to the last few days.Citations are the number of other articles citing this article, calculated by Crossref and updated daily. Find more information about Crossref citation counts.The Altmetric Attention Score is a quantitative measure of the attention that a research article has received online. Clicking on the donut icon will load a page at altmetric.com with additional details about the score and the social media presence for the given article. Find more information on the Altmetric Attention Score and how the score is calculated. Share Add toView InAdd Full Text with ReferenceAdd Description ExportRISCitationCitation and abstractCitation and referencesMore Options Share onFacebookTwitterWechatLinked InRedditEmail Other access optionsGet e-Alertsclose Get e-Alerts","['Citation', 'Icon', 'Social media', 'Computer science', 'Altmetrics', 'Information retrieval', 'World Wide Web', 'Library science', 'Programming language']","##var, soft acids, basesralph, permissionsarticle views, ##le, cross, ##f, ##f, altmetric attention score, social, altmetric attention score, ##riscitation, abstract, ##ation"
Paper_01600,A Set of Measures of Centrality Based on Betweenness,['Linton C. Freeman'],1977,Sociometry,Journal,,35-35,40,1,10.2307/3033543,"A family of new measures of point and graph centrality based on early intuitions of Bavelas (1948) is introduced. These measures define centrality in terms of the degree to which a point falls on the shortest path between others and there fore has a potential for control of communication. They may be used to index centrality in any large or small network of symmetrical relations, whether connected or unconnected.","['Betweenness centrality', 'Centrality', 'Set (abstract data type)', 'Computer science', 'Mathematics', 'Statistics', 'Programming language']","point, graph centrality, centrality, centrality, symmetrical relations, [PAD]"
Paper_01601,Dispersion and Absorption in Dielectrics I. Alternating Current Characteristics,"['Kenneth S. Cole', 'Robert H. Cole']",1941,The Journal of Chemical Physics,Journal,,341-351,9,4,10.1063/1.1750906,"The dispersion and absorption of a considerable number of liquid and dielectrics are represented by the empirical formula ε*−ε∞=(ε0−ε∞)/[1+(iωτ0)1−α]. In this equation, ε* is the complex dielectric constant, ε0 and ε∞ are the ``static'' and ``infinite frequency'' dielectric constants, ω=2π times the frequency, and τ0 is a generalized relaxation time. The parameter α can assume values between 0 and 1, the former value giving the result of Debye for polar dielectrics. The expression (1) requires that the locus of the dielectric constant in the complex plane be a circular arc with end points on the axis of reals and center below this axis. If a distribution of relaxation times is assumed to account for Eq. (1), it is possible to calculate the necessary distribution function by the method of Fuoss and Kirkwood. It is, however, difficult to understand the physical significance of this formal result. If a dielectric satisfying Eq. (1) is represented by a three-element electrical circuit, the mechanism responsible for the dispersion is equivalent to a complex impedance with a phase angle which is independent of the frequency. On this basis, the mechanism of interaction has the striking property that energy is conserved or ``stored'' in addition to being dissipated and that the ratio of the average energy stored to the energy dissipated per cycle is independent of the frequency.","['Dielectric', 'Debye', 'Relaxation (psychology)', 'Electrical impedance', 'Dispersion (optics)', 'Absorption (acoustics)', 'Dielectric absorption', 'Condensed matter physics', 'Mathematical analysis', 'Materials science', 'Physics', 'Computational physics', 'Chemistry', 'Optics', 'Mathematics', 'Quantum mechanics', 'Voltage', 'Capacitor', 'Psychology', 'Social psychology']","dispersion, complex dielectric constant, generalized relaxation time, ##by, polar dielectrics, circular arc, complex impedance, phase angle"
Paper_01602,Reduced Lung-Cancer Mortality with Low-Dose Computed Tomographic Screening,[],2011,New England Journal of Medicine,Journal,,395-409,365,5,10.1056/nejmoa1102873,"The aggressive and heterogeneous nature of lung cancer has thwarted efforts to reduce mortality from this cancer through the use of screening. The advent of low-dose helical computed tomography (CT) altered the landscape of lung-cancer screening, with studies indicating that low-dose CT detects many tumors at early stages. The National Lung Screening Trial (NLST) was conducted to determine whether screening with low-dose CT could reduce mortality from lung cancer.","['National Lung Screening Trial', 'Lung cancer screening', 'Lung cancer', 'Medicine', 'Computed tomographic', 'Computed tomography', 'Cancer', 'Radiology', 'Lung', 'Nuclear medicine', 'Oncology', 'Internal medicine']","lung cancer, national lung screening trial, nl"
Paper_01603,The Strengthening the Reporting of Observational Studies in Epidemiology (STROBE) Statement: Guidelines for Reporting Observational Studies,"['Erik von Elm', 'Douglas G. Altman', 'Matthias Egger', 'Stuart J. Pocock', 'Peter C Gøtzsche', 'Jan P. Vandenbroucke']",2007,Annals of Internal Medicine,Journal,,573-573,147,8,10.7326/0003-4819-147-8-200710160-00010,"Much biomedical research is observational. The reporting of such research is often inadequate, which hampers the assessment of its strengths and weaknesses and of a study's generalizability. The Strengthening the Reporting of Observational Studies in Epidemiology (STROBE) Initiative developed recommendations on what should be included in an accurate and complete report of an observational study. We defined the scope of the recommendations to cover 3 main study designs: cohort, case–control, and cross-sectional studies. We convened a 2-day workshop in September 2004, with methodologists, researchers, and journal editors, to draft a checklist of items. This list was subsequently revised during several meetings of the coordinating group and in e-mail discussions with the larger group of STROBE contributors, taking into account empirical evidence and methodological considerations. The workshop and the subsequent iterative process of consultation and revision resulted in a checklist of 22 items (the STROBE Statement) that relate to the title, abstract, introduction, methods, results, and discussion sections of articles. Eighteen items are common to all 3 study designs and 4 are specific for cohort, case–control, or cross-sectional studies. A detailed Explanation and Elaboration document is published separately and is freely available at http://www.annals.org and on the Web sites of PLoS Medicine and Epidemiology. We hope that the STROBE Statement will contribute to improving the quality of reporting of observational studies.","['Strengthening the reporting of observational studies in epidemiology', 'Observational study', 'Checklist', 'Medicine', 'Generalizability theory', 'Consolidated Standards of Reporting Trials', 'Family medicine', 'MEDLINE', 'Epidemiology', 'Cohort study', 'Scope (computer science)', 'Guideline', 'Medical education', 'Evidence-based medicine', 'Alternative medicine', 'Psychology', 'Pathology', 'Computer science', 'Developmental psychology', 'Political science', 'Law', 'Cognitive psychology', 'Programming language']","biomedical, observational studies, epidemiology, ##be, co, case, method, strobe, co, plos medicine, epidemiology"
Paper_01604,IQ-TREE 2: New Models and Efficient Methods for Phylogenetic Inference in the Genomic Era,"['Bùi Quang Minh', 'Heiko A. Schmidt', 'Olga Chernomor', 'Dominik Schrempf', 'Michael D. Woodhams', 'Arndt von Haeseler', 'Robert Lanfear']",2020,Molecular Biology and Evolution,Journal,,1530-1534,37,5,10.1093/molbev/msaa015,"Abstract IQ-TREE (http://www.iqtree.org, last accessed February 6, 2020) is a user-friendly and widely used software package for phylogenetic inference using maximum likelihood. Since the release of version 1 in 2014, we have continuously expanded IQ-TREE to integrate a plethora of new models of sequence evolution and efficient computational approaches of phylogenetic inference to deal with genomic data. Here, we describe notable features of IQ-TREE version 2 and highlight the key advantages over other software.","['Phylogenetic tree', 'Inference', 'Biology', 'Tree (set theory)', 'Tree rearrangement', 'Software', 'Evolutionary biology', 'Computational biology', 'Phylogenetic network', 'Computer science', 'Machine learning', 'Artificial intelligence', 'Genetics', 'Gene', 'Mathematics', 'Programming language', 'Mathematical analysis']","iq, phylogenetic inference, maximum likelihood, sequence evolution, phylogenetic inference, genomic data"
Paper_01607,Categorical Data Analysis,['David E. Hapeman'],1991,Technometrics,Journal,,241-241,33,2,10.1080/00401706.1991.10484817,"categorical data analysis , categorical data analysis , کتابخانه مرکزی دانشگاه علوم پزشکی تهران","['Categorical variable', 'Statistics', 'Computer science', 'Econometrics', 'Data mining', 'Mathematics']","categorical data analysis, categorical data analysis"
Paper_01608,Sol-Gel Science: The Physics and Chemistry of Sol-Gel Processing,"['C. Jeffrey Brinker', 'George W. Scherer']",1990,['Journal of Controlled Release'],Unknown,,186,15,2,10.1016/0168-3659(91)90078-r,Preface. Acknowledgments. Introduction. Hydrolysis and Condensation I: Nonsilicates. Hydrolysis and Condensation II: Silicates. Particulate Sols and Gels. Gelation. Aging of Gels. Theory of Deformation and Flow in Gels. Drying. Structural Evolution during Consolidation. Surface Chemistry and Chemical Modification. Sintering. Comparison of Gel-Derived and Conventional Ceramics. Film Formation. Applications. Index.,"['Hydrolysis', 'Sol-gel', 'Consolidation (business)', 'Condensation', 'Chemical engineering', 'Chemistry', 'Ceramic', 'Materials science', 'Polymer science', 'Nanotechnology', 'Organic chemistry', 'Thermodynamics', 'Engineering', 'Physics', 'Accounting', 'Business']","##ents, hydrolysis, condensation, nonsilicates, hydro, condens, silicates, particulate sols, gel, gelation, drying, structural evolution, consolidation, surface chemistry, chemical modification, sintering, film formation"
Paper_01610,A familial cluster of pneumonia associated with the 2019 novel coronavirus indicating person-to-person transmission: a study of a family cluster,"['Jasper Fuk‐Woo Chan', 'Shuofeng Yuan', 'Kin‐Hang Kok', 'Kelvin Kai‐Wang To', 'Hin Chu', 'Yang Jin', 'Fanfan Xing', 'Jieling Liu', 'Cyril Chik‐Yan Yip', 'Rosana Wing‐Shan Poon', 'Hoi-Wah Tsoi', 'Simon Kam-Fai Lo', 'Kwok‐Hung Chan', 'Vincent Kwok‐Man Poon', 'Wan-Mui Chan', 'Jonathan Daniel Ip', 'Jian‐Piao Cai', 'Vincent Chi‐Chung Cheng', 'Honglin Chen', 'Christopher Kim-Ming Hui', 'Kwok-Yung Yuen']",2020,The Lancet,Journal,,514-523,395,10223,10.1016/s0140-6736(20)30154-9,"An ongoing outbreak of pneumonia associated with a novel coronavirus was reported in Wuhan city, Hubei province, China. Affected patients were geographically linked with a local wet market as a potential source. No data on person-to-person or nosocomial transmission have been published to date.","['Outbreak', 'China', 'Family member', 'Cluster (spacecraft)', 'Transmission (telecommunications)', 'Medicine', 'Pneumonia', 'Asymptomatic', 'Pediatrics', 'Family history', 'Epidemiology', 'Demography', 'Geography', 'Internal medicine', 'Virology', 'Family medicine', 'Computer science', 'Archaeology', 'Engineering', 'Sociology', 'Electrical engineering', 'Programming language']","corona, nosoco, [PAD]"
Paper_01611,Nonlinear Fiber Optics,['Govind P. Agrawal'],1989,Unknown,Unknown,,,,,10.1016/c2011-0-00045-5,"Nonlinear fiber optics concerns with the nonlinear optical phenomena occurring inside optical fibers. Although the field ofnonlinear optics traces its beginning to 1961, when a ruby laser was first used to generate the second-harmonic radiation inside a crystal [1], the use ofoptical fibers as a nonlinear medium became feasible only after 1970 when fiber losses were reduced to below 20 dB/km [2]. Stimulated Raman and Brillouin scatterings in single-mode fibers were studied as early as 1972 [3] and were soon followed by the study of other nonlinear effects such as self- and crossphase modulation and four-wave mixing [4]. By 1989, the field ofnonlinear fiber optics has advanced enough that a whole book was devoted to it [5]. This book or its second edition has been translated into Chinese, Japanese, and Russian languages, attesting to the worldwide activity in the field of nonlinear fiber optics.","['Nonlinear optics', 'Optics', 'Optical fiber', 'Brillouin scattering', 'Nonlinear system', 'Fiber', 'Fiber laser', 'Photonic-crystal fiber', 'Physics', 'Laser', 'Materials science', 'Quantum mechanics', 'Composite material']","nonlinear fiber optics, nonlinear optical phenomena, optical fibers, ##nonlinear optics, ruby laser, ##optical fibers, nonlinear medium, stimulated raman, brillouin scatterings, cross, ##se modulation, ##nonlinear fiber optics, nonlinear fiber optics, [PAD], [PAD], [PAD], [PAD] [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"
Paper_01612,Least angle regression,"['Bradley Efron', 'Trevor Hastie', 'Iain M. Johnstone', 'Robert Tibshirani']",2004,The Annals of Statistics,Journal,,,32,2,10.1214/009053604000000067,"The purpose of model selection algorithms such as All Subsets, Forward Selection and Backward Elimination is to choose a linear model on the basis of the same set of data to which the model will be applied. Typically we have available a large collection of possible covariates from which we hope to select a parsimonious set for the efficient prediction of a response variable. Least Angle Regression (LARS), a new model selection algorithm, is a useful and less greedy version of traditional forward selection methods. Three main properties are derived: (1) A simple modification of the LARS algorithm implements the Lasso, an attractive version of ordinary least squares that constrains the sum of the absolute regression coefficients; the LARS modification calculates all possible Lasso estimates for a given problem, using an order of magnitude less computer time than previous methods. (2) A different LARS modification efficiently implements Forward Stagewise linear regression, another promising new model selection method; this connection explains the similar numerical results previously observed for the Lasso and Stagewise, and helps us understand the properties of both methods, which are seen as constrained versions of the simpler LARS algorithm. (3) A simple approximation for the degrees of freedom of a LARS estimate is available, from which we derive a Cp estimate of prediction error; this allows a principled choice among the range of possible LARS estimates. LARS and its variants are computationally efficient: the paper describes a publicly available algorithm that requires only the same order of magnitude of computational effort as ordinary least squares applied to the full set of covariates.","['Lasso (programming language)', 'Ordinary least squares', 'Mathematics', 'Algorithm', 'Selection (genetic algorithm)', 'Set (abstract data type)', 'Model selection', 'Elastic net regularization', 'Linear regression', 'Regression', 'Feature selection', 'Mathematical optimization', 'Contrast (vision)', 'Least-squares function approximation', 'Computer science', 'Artificial intelligence', 'Statistics', 'Estimator', 'World Wide Web', 'Programming language']","model selection algorithms, ##s, forward selection, backward elimination, linear model, covar, least angle regression, model selection, forward selection, lars algorithm, lasso, ordinary least squares, absolute regression coefficients, lars, lasso estimates, degrees of freedom, lars, prediction error"
Paper_01613,Clathrate Hydrates of Natural Gases,"['E. Dendy Sloan', 'Carolyn A. Koh', 'Carolyn A. Koh']",2007,CRC Press eBooks,Unknown,,,,,10.1201/9781420008494,"Hydrate research has expanded substantially over the past decade, resulting in more than 4,000 hydrate-related publications. Collating this vast amount of information into one source, Clathrate Hydrates of Natural Gases, Third Edition presents a thoroughly updated, authoritative, and comprehensive description of all major aspects of natural gas cla","['Clathrate hydrate', 'Natural gas', 'Natural (archaeology)', 'Petroleum engineering', 'Geology', 'Chemistry', 'Hydrate', 'Paleontology', 'Organic chemistry']","hydrate, clathrate hydrates, natural gases, natural gas, [PAD] [PAD], [PAD], [PAD], [PAD], [PAD], [PAD] [PAD]"
Paper_01614,"Presenting Characteristics, Comorbidities, and Outcomes Among 5700 Patients Hospitalized With COVID-19 in the New York City Area","['Safiya Richardson', 'Jamie S. Hirsch', 'Mangala Narasimhan', 'James M. Crawford', 'Thomas McGinn', 'Karina W. Davidson', 'Douglas P. Barnaby', 'Lance B. Becker', 'John Chelico', 'Stuart L. Cohen', 'Jennifer Cookingham', 'Kevin Coppa', 'Michael A. Diefenbach', 'Andrew J. Dominello', 'Joan Duer-Hefele', 'Louise Falzon', 'Jordan Gitlin', 'Negin Hajizadeh', 'Tiffany G. Harvin', 'David Hirschwerk', 'Eun Ji Kim', 'Zachary Kozel', 'Lyndonna Marrast', 'Jazmin N. Mogavero', 'Gabrielle A. Osorio', 'Michael Qiu', 'Theodoros P. Zanos']",2020,JAMA,Journal,,2052-2052,323,20,10.1001/jama.2020.6775,"There is limited information describing the presenting characteristics and outcomes of US patients requiring hospitalization for coronavirus disease 2019 (COVID-19).To describe the clinical characteristics and outcomes of patients with COVID-19 hospitalized in a US health care system.Case series of patients with COVID-19 admitted to 12 hospitals in New York City, Long Island, and Westchester County, New York, within the Northwell Health system. The study included all sequentially hospitalized patients between March 1, 2020, and April 4, 2020, inclusive of these dates.Confirmed severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) infection by positive result on polymerase chain reaction testing of a nasopharyngeal sample among patients requiring admission.Clinical outcomes during hospitalization, such as invasive mechanical ventilation, kidney replacement therapy, and death. Demographics, baseline comorbidities, presenting vital signs, and test results were also collected.A total of 5700 patients were included (median age, 63 years [interquartile range {IQR}, 52-75; range, 0-107 years]; 39.7% female). The most common comorbidities were hypertension (3026; 56.6%), obesity (1737; 41.7%), and diabetes (1808; 33.8%). At triage, 30.7% of patients were febrile, 17.3% had a respiratory rate greater than 24 breaths/min, and 27.8% received supplemental oxygen. The rate of respiratory virus co-infection was 2.1%. Outcomes were assessed for 2634 patients who were discharged or had died at the study end point. During hospitalization, 373 patients (14.2%) (median age, 68 years [IQR, 56-78]; 33.5% female) were treated in the intensive care unit care, 320 (12.2%) received invasive mechanical ventilation, 81 (3.2%) were treated with kidney replacement therapy, and 553 (21%) died. As of April 4, 2020, for patients requiring mechanical ventilation (n = 1151, 20.2%), 38 (3.3%) were discharged alive, 282 (24.5%) died, and 831 (72.2%) remained in hospital. The median postdischarge follow-up time was 4.4 days (IQR, 2.2-9.3). A total of 45 patients (2.2%) were readmitted during the study period. The median time to readmission was 3 days (IQR, 1.0-4.5) for readmitted patients. Among the 3066 patients who remained hospitalized at the final study follow-up date (median age, 65 years [IQR, 54-75]), the median follow-up at time of censoring was 4.5 days (IQR, 2.4-8.1).This case series provides characteristics and early outcomes of sequentially hospitalized patients with confirmed COVID-19 in the New York City area.","['Medicine', 'Interquartile range', 'Comorbidity', 'Intensive care unit', 'Mechanical ventilation', 'Emergency medicine', 'Pediatrics', 'Diabetes mellitus', 'Mortality rate', 'Internal medicine', 'Endocrinology']","coronavirus, north, severe acute respiratory syndrome, polymerase chain reaction, nas, invasive mechanical ventilation, kidney replacement therapy, baseline comorb, ##le, hypertension, invasive mechanical ventilation, kidney replacement therapy, mechanical ventilation"
Paper_01615,Global burden of bacterial antimicrobial resistance in 2019: a systematic analysis,"['Christopher J L Murray', 'Kevin S Ikuta', 'Fablina Sharara', 'Lucien R Swetschinski', 'Gisela Robles Aguilar', 'Authia P Gray', 'Chieh Han', 'Catherine Bisignano', 'Puja C Rao', 'Eve E Wool', 'Sarah Charlotte Johnson', 'Annie J. Browne', 'Michael G. Chipeta', 'Frederick Fell', 'Sean Hackett', 'Georgina Haines–Woodhouse', 'Bahar H. Kashef Hamadani', 'Emmanuelle A. P. Kumaran', 'Barney McManigal', 'Sureeruk Achalapong', 'Ramesh Agarwal', 'Samuel Akech', 'Samuel B Albertson', 'John Amuasi', 'Jason R. Andrews', 'Aleskandr Aravkin', 'Elizabeth A. Ashley', 'François-Xavier Babin', 'Freddie Bailey', 'Stephen Baker', 'Buddha Basnyat', 'Adrie Bekker', 'Rose G Bender', 'James A. Berkley', 'B. Adhisivam', 'Julia Bielicki', 'Suppawat Boonkasidecha', 'James Bukosia', 'Cristina Gardonyi Carvalheiro', 'Carlos A Castañeda-Orjuela', 'Vilada Chansamouth', 'Suman Chaurasia', 'Sara Chiurchiù', 'Fazle Rabbi Chowdhury', 'Rafai Clotaire Donatien', 'Aislinn Cook', 'Ben S. Cooper', 'Tim R. Cressey', 'Elia Criollo-Mora', 'Matthew Cunningham', 'Saffiatou Darboe', 'Nicholas Day', 'Maia De Luca', 'Клара Докова', 'Angela Dramowski', 'Susanna Dunachie', 'Thuy Duong Bich', 'Tim Eckmanns', 'Daniel Eibach', 'Amir Emami', 'Nicholas Feasey', 'Natasha Fisher-Pearson', 'Karen Forrest', 'Coralith Garcia', 'Denise O Garrett', 'Petra Gastmeier', 'Ababi Zergaw Giref', 'Rachel Greer', 'Vikas Gupta', 'Sebastian Haller', 'Andrea Haselbeck', 'Simon I Hay', 'Marianne Holm', 'Susan Hopkins', 'Yingfen Hsia', 'Kenneth Iregbu', 'Jan Jacobs', 'Daniel Jarovsky', 'Fatemeh Javanmardi', 'Adam Jenney', 'Meera Khorana', 'Suwimon Khusuwan', 'Niranjan Kissoon', 'Elsa Kobeissi', 'Tomislav Kostyanev', 'Fiorella Krapp', 'Ralf Krumkamp', 'Ajay Kumar', 'Hmwe Hmwe Kyu', 'Cherry Lim', 'Kruy Lim', 'Direk Limmathurotsakul', 'Michael J. Loftus', 'Miles Lunn', 'Jianing Ma', 'Anand Manoharan', 'Florian Marks', 'Jürgen May', 'Mayfong Mayxay', 'Neema Mturi']",2022,The Lancet,Journal,,629-655,399,10325,10.1016/s0140-6736(21)02724-0,"<h2>Summary</h2><h3>Background</h3> Antimicrobial resistance (AMR) poses a major threat to human health around the world. Previous publications have estimated the effect of AMR on incidence, deaths, hospital length of stay, and health-care costs for specific pathogen–drug combinations in select locations. To our knowledge, this study presents the most comprehensive estimates of AMR burden to date. <h3>Methods</h3> We estimated deaths and disability-adjusted life-years (DALYs) attributable to and associated with bacterial AMR for 23 pathogens and 88 pathogen–drug combinations in 204 countries and territories in 2019. We obtained data from systematic literature reviews, hospital systems, surveillance systems, and other sources, covering 471 million individual records or isolates and 7585 study-location-years. We used predictive statistical modelling to produce estimates of AMR burden for all locations, including for locations with no data. Our approach can be divided into five broad components: number of deaths where infection played a role, proportion of infectious deaths attributable to a given infectious syndrome, proportion of infectious syndrome deaths attributable to a given pathogen, the percentage of a given pathogen resistant to an antibiotic of interest, and the excess risk of death or duration of an infection associated with this resistance. Using these components, we estimated disease burden based on two counterfactuals: deaths attributable to AMR (based on an alternative scenario in which all drug-resistant infections were replaced by drug-susceptible infections), and deaths associated with AMR (based on an alternative scenario in which all drug-resistant infections were replaced by no infection). We generated 95% uncertainty intervals (UIs) for final estimates as the 25th and 975th ordered values across 1000 posterior draws, and models were cross-validated for out-of-sample predictive validity. We present final estimates aggregated to the global and regional level. <h3>Findings</h3> On the basis of our predictive statistical models, there were an estimated 4·95 million (3·62–6·57) deaths associated with bacterial AMR in 2019, including 1·27 million (95% UI 0·911–1·71) deaths attributable to bacterial AMR. At the regional level, we estimated the all-age death rate attributable to resistance to be highest in western sub-Saharan Africa, at 27·3 deaths per 100 000 (20·9–35·3), and lowest in Australasia, at 6·5 deaths (4·3–9·4) per 100 000. Lower respiratory infections accounted for more than 1·5 million deaths associated with resistance in 2019, making it the most burdensome infectious syndrome. The six leading pathogens for deaths associated with resistance (<i>Escherichia coli</i>, followed by <i>Staphylococcus aureus, Klebsiella pneumoniae, Streptococcus pneumoniae, Acinetobacter baumannii</i>, and <i>Pseudomonas aeruginosa</i>) were responsible for 929 000 (660 000–1 270 000) deaths attributable to AMR and 3·57 million (2·62–4·78) deaths associated with AMR in 2019. One pathogen–drug combination, meticillin-resistant <i>S aureus</i>, caused more than 100 000 deaths attributable to AMR in 2019, while six more each caused 50 000–100 000 deaths: multidrug-resistant excluding extensively drug-resistant tuberculosis, third-generation cephalosporin-resistant <i>E coli, carbapenem-resistant</i> A baumannii, <i>fluoroquinolone-resistant E coli</i>, carbapenem-resistant <i>K pneumoniae</i>, and third-generation cephalosporin-resistant <i>K pneumoniae</i>. <h3>Interpretation</h3> To our knowledge, this study provides the first comprehensive assessment of the global burden of AMR, as well as an evaluation of the availability of data. AMR is a leading cause of death around the world, with the highest burdens in low-resource settings. Understanding the burden of AMR and the leading pathogen–drug combinations contributing to it is crucial to making informed and location-specific policy decisions, particularly about infection prevention and control programmes, access to essential antibiotics, and research and development of new vaccines and antibiotics. There are serious data gaps in many low-income settings, emphasising the need to expand microbiology laboratory capacity and data collection systems to improve our understanding of this important human health threat. <h3>Funding</h3> Bill & Melinda Gates Foundation, Wellcome Trust, and Department of Health and Social Care using UK aid funding managed by the Fleming Fund.","['Medicine', 'Antibiotic resistance', 'Infectious disease (medical specialty)', 'Drug resistance', 'Incidence (geometry)', 'Disease burden', 'Disease', 'Intensive care medicine', 'Antibiotics', 'Internal medicine', 'Biology', 'Microbiology', 'Physics', 'Optics']","antimicrobial resistance, hospital systems, surveillance systems, predictive, predictive statistical models"
Paper_01616,MEME SUITE: tools for motif discovery and searching,"['Timothy L. Bailey', 'Mikael Bodén', 'Fabian A. Buske', 'Martin C. Frith', 'Charles E. Grant', 'Luca Clementi', 'Junxiao Ren', 'Wen‐Wu Li', 'William Stafford Noble']",2009,Nucleic Acids Research,Journal,,W202-W208,37,Web Server,10.1093/nar/gkp335,"The MEME Suite web server provides a unified portal for online discovery and analysis of sequence motifs representing features such as DNA binding sites and protein interaction domains. The popular MEME motif discovery algorithm is now complemented by the GLAM2 algorithm which allows discovery of motifs containing gaps. Three sequence scanning algorithms—MAST, FIMO and GLAM2SCAN—allow scanning numerous DNA and protein sequence databases for motifs discovered by MEME and GLAM2. Transcription factor motifs (including those discovered using MEME) can be compared with motifs in many popular motif databases using the motif database scanning algorithm Tomtom. Transcription factor motifs can be further analyzed for putative function by association with Gene Ontology (GO) terms using the motif-GO term association tool GOMO. MEME output now contains sequence LOGOS for each discovered motif, as well as buttons to allow motifs to be conveniently submitted to the sequence and motif database scanning algorithms (MAST, FIMO and Tomtom), or to GOMO, for further analysis. GLAM2 output similarly contains buttons for further analysis using GLAM2SCAN and for rerunning GLAM2 with different parameters. All of the motif-based tools are now implemented as web services via Opal. Source code, binaries and a web server are freely available for noncommercial use at http://meme.nbcr.net.","['Motif (music)', 'Sequence motif', 'Biology', 'Computational biology', 'Web server', 'Suite', 'Structural motif', 'Sequence analysis', 'Computer science', 'Genetics', 'Gene', 'The Internet', 'World Wide Web', 'History', 'Biochemistry', 'Physics', 'Archaeology', 'Acoustics']","meme suite, online discovery, sequence motifs, dna binding sites, protein interaction domains, meme, glam, sequence scanning algorithms, mast, fimo, glam2scan, transcription factor motifs, motif database scanning algorithm, transcription factor motifs, gene ontology, sequence, motif database scanning, mast, fimo, tomtom, gomo, glam, ##lam, ##al, binaries, [PAD] [PAD], [PAD], [PAD] [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"
Paper_01618,A Brief History of Neoliberalism,['David Harvey'],2020,Unknown,Unknown,,14-21,,,10.2307/j.ctv17ppcd0.8,"Neoliberalism--the doctrine that market exchange is an ethic in itself, capable of acting as a guide for all human action--has become dominant in both thought and practice throughout much of the world since 1970 or so. Writing for a wide audience, David Harvey, author of The New Imperialism and The Condition of Postmodernity, here tells the political-economic story of where neoliberalization came from and how it proliferated on the world stage. Through critical engagement with this history, he constructs a framework, not only for analyzing the political and economic dangers that now surround us, but also for assessing the prospects for the more socially just alternatives being advocated by many oppositional movements.","['Neoliberalism (international relations)', 'History', 'Sociology', 'Social science']","neoliberalism, market exchange, ##modern, neoliberal"
Paper_01619,Qualitative Inquiry and Research Design : Choosing Among Five Approaches,"['John W. Creswell', 'Cheryl Poth']",2017,['Health Promotion Practice'],Unknown,,473-475,16,4,10.1177/1524839915580941,"Dalam edisi revisi keempat dari buku terlaris, John W. Creswell dan rekan penulis baru Cheryl N.Poth mengeksplorasi dasar filosofis, sejarah, dan elemen kunci dari lima pendekatan penelitian kualitatif: penelitian naratif, fenomenologi, teori dasar, etnografi, dan studi kasus. Mempertahankan gaya penulisannya, penulis membandingkan pendekatan dan menghubungkan desain penelitian dengan masing-masing tradisi penyelidikan dengan cara yang sangat mudah diakses. Menampilkan konten baru, artikel, pedagogi, referensi, dan cakupan etika yang diperluas. Edisi Keempat adalah pengantar yang ideal untuk teori, strategi, dan praktik penelitian kualitatif.","['Art', 'Humanities']","##ah, fenomeno, ##ikel, pe, ##gi"
Paper_01621,Risk Society: Towards a New Modernity,"['William Boyd', 'Ulrich Beck', 'Kristin Shrader‐Frechette']",1993,Economic Geography,Journal,,432-432,69,4,10.2307/143601,"(1993). Risk Society: Towards a New Modernity. Economic Geography: Vol. 69, Theme Issue: Environment and Development, Part 2, pp. 432-436.","['Modernity', 'Risk society', 'Environmental ethics', 'Sociology', 'Political science', 'Social science', 'Philosophy', 'Law']","risk society, economic geography, [PAD] [PAD], [PAD] [PAD]"
Paper_01623,Social Structure and Competition in Interfirm Networks: The Paradox of Embeddedness,['Brian Uzzi'],1997,Administrative Science Quarterly,Journal,,35-35,42,1,10.2307/2393808,"This chapter aims to develop one of perhaps multiple specifications of embeddedness, a concept that has been used to refer broadly to the contingent nature of economic action with respect to cognition, social structure, institutions, and culture. Research on embeddedness is an exciting area in sociology and economics because it advances understanding of how social structure affects economic life. The chapter addresses propositions about the operation and outcomes of interfirm networks that are guided implicitly by ceteris paribus assumptions. While economies of time due to embeddedness have obvious benefits for the individual firm, they also have important implications for allocative efficiency and the determination of prices. Under the conditions, social processes that increase integration combine with resource dependency problems to increase the vulnerability of networked organizations. The level of investment in an economy promotes positive changes in productivity, standards of living, mobility, and wealth generation.","['Embeddedness', 'Competition (biology)', 'Economic geography', 'Business', 'Industrial organization', 'Sociology', 'Economic system', 'Economics', 'Social science', 'Ecology', 'Biology']","embeddedness, contingent, economic action, cognition, social structure, institutions, culture, embeddedness, sociology, economics, social structure, economic life, interfirm networks, ceter, embeddedness, allocative efficiency, prices, social processes, integration, resource dependency problems, networked organizations, productivity, standards of living, mobility, wealth generation"
Paper_01624,Upper Echelons: The Organization as a Reflection of Its Top Managers,"['Donald C. Hambrick', 'Phyllis A. Mason']",1984,Academy of Management Review,Journal,,193-206,9,2,10.5465/amr.1984.4277628,Theorists in various fields have discussed characteristics of top managers. This paper attempts to synthesize these previously fragmented literatures around a more general “upper echelons perspective.” The theory states that organizational outcomes—strategic choices and performance levels—are partially predicted by managerial background characteristics. Propositions and methodological suggestions are included.,"['Upper echelons', 'Perspective (graphical)', 'Reflection (computer programming)', 'Organizational theory', 'Business', 'Knowledge management', 'Process management', 'Industrial organization', 'Management', 'Strategic management', 'Marketing', 'Computer science', 'Economics', 'Programming language', 'Artificial intelligence']","top managers, organizational outcomes, strategic choices, performance levels, managerial background characteristics, [PAD], [PAD], [PAD]"
Paper_01625,Machine Learning : A Probabilistic Perspective,['Kevin P. Murphy'],2012,['CHANCE'],Unknown,,62-63,27,2,10.1080/09332480.2014.914768,"Today's Web-enabled deluge of electronic data calls for automated methods of data analysis. Machine learning provides these, developing methods that can automatically detect patterns in data and then use the uncovered patterns to predict future data. This textbook offers a comprehensive and self-contained introduction to the field of machine learning, based on a unified, probabilistic approach. The coverage combines breadth and depth, offering necessary background material on such topics as probability, optimization, and linear algebra as well as discussion of recent developments in the field, including conditional random fields, L1 regularization, and deep learning. The book is written in an informal, accessible style, complete with pseudo-code for the most important algorithms. All topics are copiously illustrated with color images and worked examples drawn from such application domains as biology, text processing, computer vision, and robotics. Rather than providing a cookbook of different heuristic methods, the book stresses a principled model-based approach, often using the language of graphical models to specify models in a concise and intuitive way. Almost all the models described have been implemented in a MATLAB software package--PMTK (probabilistic modeling toolkit)--that is freely available online. The book is suitable for upper-level undergraduates with an introductory-level college math background and beginning graduate students.","['Computer science', 'Probabilistic logic', 'Artificial intelligence', 'Field (mathematics)', 'Conditional random field', 'Heuristic', 'Machine learning', 'Graphical model', 'Regularization (linguistics)', 'Software', 'Programming language', 'Mathematics', 'Pure mathematics']","automated methods, data analysis, machine learning, machine learning, probability, optimization, linear algebra, conditional random fields, l1 regularization, deep learning, color images, biology, text processing, computer vision, robotics, ##uristic, graphical models, mat, probabilistic modeling toolkit"
Paper_01626,Electronic Processes in Non-Crystalline Materials,"['N. F. Mott', 'E. A. Davis', 'A. Lösche']",1972,De Gruyter eBooks,Unknown,,507-508,,,10.1515/9783112653326-018,"1. Introduction 2. Theory of Electrons in a Non-Crystalline Medium 3. Phonons and Polarons 4. The Fermi Glass and the Anderson Transition 5. Liquid Metals and Semimetals 6. Non-Crystalline Semiconductors 7. Tetrahedrally-Bonded Semiconductors - Amorphous Germanium and Silicon 8. Aresnic and Other Three-Fold Co-ordinated Materials 9. Chalcogenide and Other Glasses 10. Selenium, Tellurium, and their Alloys",['Materials science'],"non, crystalline medium, phonons, polarons, fermi glass, anderson transition, liquid metals, semimetals, non - crystalline semiconductors, ares, chalcogenide, selen, telluri"
Paper_01627,Case Studies and Theory Development in the Social Sciences,"['Alexander L. George', 'Andrew Bennett']",2005,['Perspectives on Politics'],Unknown,,187-188,5,1,10.1017/s1537592707070491,A text that emphasizes the importance of case studies in social science scholarship and shows how to make case study practices more rigorous.,"['Development (topology)', 'Sociology', 'Psychology', 'Cognitive science', 'Mathematics', 'Mathematical analysis']","case studies, social science scholarship, case study practices, [PAD] [PAD], [PAD]"
Paper_01631,‘Small Changes' to Diet and Physical Activity Behaviors for Weight Management,"['Andrew P. Hills', 'Nuala M. Byrne', 'Rachel C. Lindstrom', 'James O. Hill']",2013,Obesity Facts,Journal,,228-238,6,3,10.1159/000345030,"Although general parenting styles and restrictive parental feeding practices have been associated with children's weight status, few studies have examined the association between feeding styles and proximal outcomes such as children's food intake, especially in multi-ethnic families with limited incomes. The purpose of this study was to evaluate the association of parental feeding styles and young children's evening food intake in a multiethnic sample of families in Head Start.Participants were 715 Head Start children and their parents from Texas and Alabama representing three ethnic groups: African-American (43%), Hispanic (29%), and White (28%). The Caregivers Feeding Styles Questionnaire (Hughes) was used to characterize authoritative, authoritarian (referent), indulgent or uninvolved feeding styles. Food intake in several food groups was calculated from 3 days of dietary recalls for the child for evening food intakes from 3 PM until bedtime.Compared to children of authoritarian parents, intakes of fruits, juice and vegetables were lowest among children of indulgent or uninvolved parents (1.77 +/- 0.09 vs 1.45 +/- 0.09 and 1.42 +/- 0.11 cups) as were intakes of dairy foods (0.84 +/- 0.05 vs 0.67 +/- 0.05 and 0.63+0.06 cups), respectively.Findings suggest that permissive parent feeding styles like indulgent or uninvolved relate negatively to children's intake of nutrient-rich foods fruit, 100% fruit juice, vegetables and dairy foods from 3 PM until bedtime.","['Bedtime', 'Medicine', 'Ethnic group', 'Evening', 'Neophobia', 'Parenting styles', 'Environmental health', 'Head start', 'Permissive', 'Demography', 'Developmental psychology', 'Psychology', 'Clinical psychology', 'Physics', 'Virology', 'Astronomy', 'Psychiatry', 'Sociology', 'Anthropology', 'Internal medicine']","general parenting styles, restrictive parental feeding practices, parental feeding styles, caregivers feeding styles questionnaire, dietary recalls, authoritarian parents, dairy foods, permissive parent feeding styles, dairy foods"
Paper_01632,Why Most Published Research Findings Are False,['John P. A. Ioannidis'],2005,PLoS Medicine,Journal,,e124-e124,2,8,10.1371/journal.pmed.0020124,"There is increasing concern that most current published research findings are false. The probability that a research claim is true may depend on study power and bias, the number of other studies on the same question, and, importantly, the ratio of true to no relationships among the relationships probed in each scientific field. In this framework, a research finding is less likely to be true when the studies conducted in a field are smaller; when effect sizes are smaller; when there is a greater number and lesser preselection of tested relationships; where there is greater flexibility in designs, definitions, outcomes, and analytical modes; when there is greater financial and other interest and prejudice; and when more teams are involved in a scientific field in chase of statistical significance. Simulations show that for most study designs and settings, it is more likely for a research claim to be false than true. Moreover, for many current scientific fields, claimed research findings may often be simply accurate measures of the prevailing bias. In this essay, I discuss the implications of these problems for the conduct and interpretation of research.","['Medicine', 'MEDLINE', 'Biology', 'Biochemistry']",
Paper_01633,De-noising by soft-thresholding,['David L. Donoho'],1995,IEEE Transactions on Information Theory,Journal,,613-627,41,3,10.1109/18.382009,"Donoho and Johnstone (1994) proposed a method for reconstructing an unknown function f on [0,1] from noisy data d/sub i/=f(t/sub i/)+/spl sigma/z/sub i/, i=0, ..., n-1,t/sub i/=i/n, where the z/sub i/ are independent and identically distributed standard Gaussian random variables. The reconstruction f/spl circ/*/sub n/ is defined in the wavelet domain by translating all the empirical wavelet coefficients of d toward 0 by an amount /spl sigma//spl middot//spl radic/(2log (n)/n). The authors prove two results about this type of estimator. [Smooth]: with high probability f/spl circ/*/sub n/ is at least as smooth as f, in any of a wide variety of smoothness measures. [Adapt]: the estimator comes nearly as close in mean square to f as any measurable estimator can come, uniformly over balls in each of two broad scales of smoothness classes. These two properties are unprecedented in several ways. The present proof of these results develops new facts about abstract statistical inference and its connection with an optimal recovery model.< <ETX xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">&gt;</ETX>","['Smoothness', 'Estimator', 'Independent and identically distributed random variables', 'Mathematics', 'Random variable', 'Combinatorics', 'Gaussian', 'Sigma', 'Type (biology)', 'Wavelet', 'Connection (principal bundle)', 'Statistical inference', 'Algorithm', 'Discrete mathematics', 'Computer science', 'Statistics', 'Artificial intelligence', 'Mathematical analysis', 'Physics', 'Geometry', 'Ecology', 'Quantum mechanics', 'Biology']","unknown function, noisy data, wavelet domain, empirical wavelet coefficients, smoothness measures, mean, me, smoothness classes, abstract statistical inference, optimal recovery model"
Paper_01634,Learning Deep Features for Discriminative Localization,"['Bolei Zhou', 'Aditya Khosla', 'Àgata Lapedriza', 'Aude Oliva', 'Antonio Torralba']",2016,Unknown,Unknown,,,,,10.1109/cvpr.2016.319,"In this work, we revisit the global average pooling layer proposed in [13], and shed light on how it explicitly enables the convolutional neural network (CNN) to have remarkable localization ability despite being trained on imagelevel labels. While this technique was previously proposed as a means for regularizing training, we find that it actually builds a generic localizable deep representation that exposes the implicit attention of CNNs on an image. Despite the apparent simplicity of global average pooling, we are able to achieve 37.1% top-5 error for object localization on ILSVRC 2014 without training on any bounding box annotation. We demonstrate in a variety of experiments that our network is able to localize the discriminative image regions despite just being trained for solving classification task1.","['Discriminative model', 'Pooling', 'Artificial intelligence', 'Computer science', 'Convolutional neural network', 'Pattern recognition (psychology)', 'Bounding overwatch', 'Minimum bounding box', 'Deep learning', 'Contextual image classification', 'Representation (politics)', 'Image (mathematics)', 'Simplicity', 'Object (grammar)', 'Layer (electronics)', 'Annotation', 'Philosophy', 'Chemistry', 'Organic chemistry', 'Epistemology', 'Politics', 'Political science', 'Law']","global average pooling layer, convolutional neural network, cnn, localization, imagelevel labels, generic localizable deep representation, implicit attention, global average pooling, object localization, ilsvrc, bounding box annotation, ##inative image regions, [PAD], [PAD], [PAD] [PAD], [PAD] [PAD] [PAD] [PAD] [PAD], [PAD], [PAD], [PAD]"
Paper_01635,The External Control of Organizations: A Resource Dependence Perspective,"['H. Joseph Reitz', 'Jeffrey Pfeffer', 'Gerald R. Salancik']",1979,Academy of Management Review,Journal,,309-309,4,2,10.2307/257794,"Examines how external constraints affect organizations and how to design and manage organizations under such constraints. Taking a resource dependence perspective on organizations, the book discusses basic components of control, including the concentration and availability of resources, the role of managers, interdependence among organizations, the environment, and organizational structure. Two case studies, one on Israeli managers and one on American defense contractors, exemplify how governmental external control affects organizational choice. In the case of the Israeli managers, the managers' responses regarding the size of the return they would be willing to give up to invest in a government-created development area were positively correlated with the proportion of the firm's government sales. Similarly, the study of American defense contractors examined how willing they were to comply with affirmative action laws for employment of women, finding a strong correlation between positive replies to women seeking employment and government dependence. Dependence is not restricted to the government, however, as firms are heavily reliant upon resources made available to them from other organizations. Despite external control, the organization is able to achieve internal control to a certain extent, stabilizing activities by institutionalizing roles and patterns of behavior. The question of power within organizations requires further study, as organizations are coalitions of interest and only some interests and goals are accomplished at the expense of others. Organizations also serve to create and transact ideas and the influence these ideas create, so that influence and control are multidirectional. Conclusions show that organizations are not autonomous entities, but are reliant upon the larger network of organizations within the environment - through which they must strive to manipulate resources to survive. (CJC)","['Perspective (graphical)', 'Control (management)', 'Resource dependence theory', 'Human resource management', 'Resource (disambiguation)', 'Organizational behavior', 'Management control system', 'Business', 'Management', 'Knowledge management', 'Sociology', 'Operations management', 'Process management', 'Computer science', 'Economics', 'Computer network', 'Artificial intelligence']","external constraints, resource dependence, organizations, managers, ##den, organizational structure, israeli managers, american defense contractors, governmental external control, organizational, israeli, american defense contractors, affirmative action laws, women, women, government dependence"
Paper_01636,Hydrogen Peroxide is Scavenged by Ascorbate-specific Peroxidase in Spinach Chloroplasts,"['Yoshiyuki Nakano', 'Kozi Asada']",1981,Plant and Cell Physiology,Journal,,,,,10.1093/oxfordjournals.pcp.a076232,"Intact spinach chloroplasts scavenge hydrogen peroxide with a peroxidase that uses a photoreductant as the electron donor, but the activity of ruptured chloroplasts is very low [Nakano and Asada (1980) Plant & Cell Physiol. 21 : 1295]. Ruptured spinach chloroplasts recovered their ability to photoreduce hydrogen peroxide with the concomitant evolution of oxygen after the addition of glutathione and dehydroascorbate (DHA). In ruptured chloroplasts, DHA was photoreduced to ascorbate and oxygen was evolved in the process in the presence of glutathione. DHA reductase (EC 1.8.5.1) and a peroxidase whose electron donor is specific to L-ascorbate are localized in chloroplast stroma. These observations confirm that the electron donor for the scavenging of hydrogen peroxide in chloroplasts is L-ascorbate and that the L-ascorbate is regenerated from DHA by the system: photosystem I→ferredoxin→NADP→glutathione. A preliminary characterization of the chloroplast peroxidase is given.","['Chloroplast', 'Hydrogen peroxide', 'Peroxidase', 'Chemistry', 'Spinach', 'Dehydroascorbic acid', 'Glutathione reductase', 'Biochemistry', 'Photosystem I', 'Peroxide', 'Ascorbic acid', 'Glutathione peroxidase', 'Antioxidant', 'Superoxide dismutase', 'Vitamin C', 'Enzyme', 'Organic chemistry', 'Food science', 'Gene']","##ach chloroplasts, per, ##ida, photoreductant, ##ured spin, ##rba, ##ida, ##las"
Paper_01637,A Cognitive Model of the Antecedents and Consequences of Satisfaction Decisions,['Richard L. Oliver'],1980,Journal of Marketing Research,Journal,,460-460,17,4,10.2307/3150499,"A model is proposed which expresses consumer satisfaction as a function of expectation and expectancy disconfirmation. Satisfaction, in turn, is believed to influence attitude change and purchase i...","['Expectancy theory', 'Psychology', 'Cognition', 'Consumer satisfaction', 'Function (biology)', 'Social psychology', 'Marketing', 'Business', 'Neuroscience', 'Evolutionary biology', 'Biology']","consumer satisfaction, expectation, expectancy disconfirmation, attitude change, purchase, [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD]"
Paper_01642,A General Inductive Approach for Analyzing Qualitative Evaluation Data,['David R. Thomas'],2006,American Journal of Evaluation,Journal,,237-246,27,2,10.1177/1098214005283748,"A general inductive approach for analysis of qualitative evaluation data is described. The purposes for using an inductive approach are to (a) condense raw textual data into a brief, summary format; (b) establish clear links between the evaluation or research objectives and the summary findings derived from the raw data; and (c) develop a framework of the underlying structure of experiences or processes that are evident in the raw data. The general inductive approach provides an easily used and systematic set of procedures for analyzing qualitative data that can produce reliable and valid findings. Although the general inductive approach is not as strong as some other analytic strategies for theory or model development, it does provide a simple, straightforward approach for deriving findings in the context of focused evaluation questions. Many evaluators are likely to find using a general inductive approach less complicated than using other approaches to qualitative data analysis.","['Raw data', 'Computer science', 'Set (abstract data type)', 'Inductive reasoning', 'Qualitative research', 'Context (archaeology)', 'Qualitative property', 'Inductive method', 'Data science', 'Management science', 'Data mining', 'Artificial intelligence', 'Machine learning', 'Mathematics', 'Engineering', 'Mathematics education', 'Teaching method', 'Paleontology', 'Social science', 'Sociology', 'Biology', 'Programming language']","qualitative evaluation data, induc, ##tative data analysis"
Paper_01643,The basics of epithelial-mesenchymal transition,"['Raghu Kalluri', 'Robert A. Weinberg']",2009,Journal of Clinical Investigation,Journal,,1420-1428,119,6,10.1172/jci39104,"The origins of the mesenchymal cells participating in tissue repair and pathological processes, notably tissue fibrosis, tumor invasiveness, and metastasis, are poorly understood. However, emerging evidence suggests that epithelial-mesenchymal transitions (EMTs) represent one important source of these cells. As we discuss here, processes similar to the EMTs associated with embryo implantation, embryogenesis, and organ development are appropriated and subverted by chronically inflamed tissues and neoplasias. The identification of the signaling pathways that lead to activation of EMT programs during these disease processes is providing new insights into the plasticity of cellular phenotypes and possible therapeutic interventions.","['Epithelial–mesenchymal transition', 'Mesenchymal stem cell', 'Metastasis', 'Fibrosis', 'Phenotype', 'Biology', 'Cancer research', 'Pathological', 'Cell biology', 'Pathology', 'Medicine', 'Cancer', 'Genetics', 'Gene']","mesenchymal cells, tissue repair, pathological processes, tissue fibrosis, tumor invasiveness, metastasis, embryo implantation, embryo, organ development, ##pl, em, therapeutic"
Paper_01645,The Foundations of Social Research: Meaning and Perspective in the Research Process,['Michael Crotty'],1998,['Field Methods'],Unknown,,72-79,12,1,10.1177/1525822x0001200106,Introduction Positivism The March of Science Constructionism The Making of Meaning Interpretivism For and against Culture Interpretivism The Way of Hermeneutics Critical Inquiry The Marxist Heritage Critical Inquiry Contemporary Critics and Contemporary Critique Feminism Re-Visioning the Man-Made World Postmodernism Crisis of Confidence or Moment of Truth? Conclusion,"['Postmodernism', 'Hermeneutics', 'Positivism', 'Epistemology', 'Meaning (existential)', 'Sociology', 'Marxist philosophy', 'Feminism', 'Perspective (graphical)', 'Social constructionism', 'Social science', 'Philosophy', 'Politics', 'Political science', 'Gender studies', 'Art', 'Law', 'Visual arts']","positivism, constructionism, meaning, culture interpretivism, hermeneutics critical inquiry, marxist heritage, contemporary critique feminism, postmodernism, [PAD] [PAD], [PAD], [PAD] [PAD]"
Paper_01646,TensorFlow: A system for large-scale machine learning,"['Martı́n Abadi', 'Paul Barham', 'Jianmin Chen', 'Zhifeng Chen', 'Andy Davis', 'Jay B. Dean', 'Matthieu Devin', 'Sanjay Ghemawat', 'Geoffrey Irving', 'Michael Isard', 'Manjunath Kudlur', 'Josh Levenberg', 'Rajat Monga', 'Sherry Moore', 'Derek G. Murray', 'Benoit Steiner', 'Paul A. Tucker', 'Vijay Vasudevan', 'Pete Warden', 'Martin Wicke', 'Yuan Yu', 'Xiaoqiang Zheng']",2016,arXiv (Cornell University),Unknown,,,,,10.48550/arxiv.1605.08695,"TensorFlow is a machine learning system that operates at large scale and in heterogeneous environments. TensorFlow uses dataflow graphs to represent computation, shared state, and the operations that mutate that state. It maps the nodes of a dataflow graph across many machines in a cluster, and within a machine across multiple computational devices, including multicore CPUs, general-purpose GPUs, and custom designed ASICs known as Tensor Processing Units (TPUs). This architecture gives flexibility to the application developer: whereas in previous ""parameter server"" designs the management of shared state is built into the system, TensorFlow enables developers to experiment with novel optimizations and training algorithms. TensorFlow supports a variety of applications, with particularly strong support for training and inference on deep neural networks. Several Google services use TensorFlow in production, we have released it as an open-source project, and it has become widely used for machine learning research. In this paper, we describe the TensorFlow dataflow model in contrast to existing systems, and demonstrate the compelling performance that TensorFlow achieves for several real-world applications.","['Scale (ratio)', 'Computer science', 'Artificial intelligence', 'Machine learning', 'Cartography', 'Geography']","tensorflow, machine learning system, ##gen, tensorflow, dataflow graphs, shared state, dataflow, tensor processing units, parameter server, tensorflow, training algorithms, tensorflow, deep neural networks, tensorflow, machine learning, tensorflow dataflow, tensorflow"
Paper_01649,Jalview Version 2—a multiple sequence alignment editor and analysis workbench,"['Andrew Waterhouse', 'James B Procter', 'David Martin', 'Michèle Clamp', 'Geoffrey J. Barton']",2009,Bioinformatics,Journal,,1189-1191,25,9,10.1093/bioinformatics/btp033,"Abstract Summary: Jalview Version 2 is a system for interactive WYSIWYG editing, analysis and annotation of multiple sequence alignments. Core features include keyboard and mouse-based editing, multiple views and alignment overviews, and linked structure display with Jmol. Jalview 2 is available in two forms: a lightweight Java applet for use in web applications, and a powerful desktop application that employs web services for sequence alignment, secondary structure prediction and the retrieval of alignments, sequences, annotation and structures from public databases and any DAS 1.53 compliant sequence or annotation server. Availability: The Jalview 2 Desktop application and JalviewLite applet are made freely available under the GPL, and can be downloaded from www.jalview.org Contact: g.j.barton@dundee.ac.uk","['Java applet', 'Workbench', 'Annotation', 'Computer science', 'Java', 'Multiple sequence alignment', 'Sequence alignment', 'Sequence (biology)', 'World Wide Web', 'Visualization', 'Information retrieval', 'Programming language', 'Artificial intelligence', 'Biology', 'Peptide sequence', 'Biochemistry', 'Genetics', 'Gene']","abstract summary, jalview, interactive wysiwyg editing, multiple sequence alignments, alignment overviews, linked structure display, j, ##l, jalview, java, web, sequence alignment, secondary structure prediction, jalview, jalviewlite, ##lview"
Paper_01650,<i>Planck</i>2015 results,"['P. A. R. Ade', 'N. Aghanim', 'M. Arnaud', 'M. Ashdown', 'J. Aumont', 'C. Baccigalupi', 'A. J. Banday', 'R. B. Barreiro', 'J. G. Bartlett', 'N. Bartolo', 'E. Battaner', 'Richard A. Battye', 'K. Benabed', 'A. Benoît', 'A. Benoit-Lévy', 'J.-P. Bernard', 'M. Bersanelli', 'P. Bielewicz', 'J. J. Bock', 'A. Bonaldi', 'L. Bonavera', 'J. R. Bond', 'J. Borrill', 'F. R. Bouchet', 'F. Boulanger', 'M. Bucher', 'C. Burigana', 'R. C. Butler', 'E. Calabrese', 'J.-F. Cardoso', 'A. Catalano', 'A. Challinor', 'A. Chamballu', 'Ranga‐Ram Chary', 'H. C. Chiang', 'Jens Chluba', 'P. R. Christensen', 'Sarah E. Church', 'D. L. Clements', 'S. Colombi', 'L. P. L. Colombo', 'C. Combet', 'A. Coulais', 'B. P. Crill', 'A. Curto', 'F. Cuttaia', 'L. Danese', 'R. D. Davies', 'R. J. Davis', 'P. de Bernardis', 'A. de Rosa', 'G. de Zotti', 'J. Delabrouille', 'F.–X. Désert', 'Eleonora Di Valentino', 'C. Dickinson', 'J. M. Diego', 'K. Dolag', 'H. Dole', 'S. Donzelli', 'O. Doré', 'M. Douspis', 'A. Ducout', 'Jo Dunkley', 'X. Dupac', 'G. Efstathiou', 'F. Elsner', 'T. A. Enßlin', 'H. K. Eriksen', 'M. Farhang', 'J. Fergusson', 'F. Finelli⋆', 'O. Forni', 'M. Frailis', 'A. A. Fraisse', 'E. Franceschi', 'A. Frejsel', 'S. Galeotta', 'S. Galli', 'K. Ganga', 'C. Gauthier', 'M. Gerbino', 'T. Ghosh', 'M. Giard', 'Y. Giraud–Héraud', 'Elena Giusarma', 'E. Gjerløw', 'J. González-Nuevo', 'K. M. Górski', 'S. Gratton', 'A. Gregorio', 'A. Gruppuso', 'J. E. Gudmundsson', 'J. Hamann', 'F. K. Hansen', 'D. Hanson', 'D. L. Harrison', 'G. Hélou', 'S. Henrot–Versillé', 'C. Hernández-Monteagudo']",2016,Astronomy and Astrophysics,Journal,,A13-A13,594,,10.1051/0004-6361/201525830,"We present results based on full-mission Planck observations of temperature and polarization anisotropies of the CMB. These data are consistent with the six-parameter inflationary LCDM cosmology. From the Planck temperature and lensing data, for this cosmology we find a Hubble constant, H0= (67.8 +/- 0.9) km/s/Mpc, a matter density parameter Omega_m = 0.308 +/- 0.012 and a scalar spectral index with n_s = 0.968 +/- 0.006. (We quote 68% errors on measured parameters and 95% limits on other parameters.) Combined with Planck temperature and lensing data, Planck LFI polarization measurements lead to a reionization optical depth of tau = 0.066 +/- 0.016. Combining Planck with other astrophysical data we find N_ eff = 3.15 +/- 0.23 for the effective number of relativistic degrees of freedom and the sum of neutrino masses is constrained to < 0.23 eV. Spatial curvature is found to be |Omega_K| < 0.005. For LCDM we find a limit on the tensor-to-scalar ratio of r <0.11 consistent with the B-mode constraints from an analysis of BICEP2, Keck Array, and Planck (BKP) data. Adding the BKP data leads to a tighter constraint of r < 0.09. We find no evidence for isocurvature perturbations or cosmic defects. The equation of state of dark energy is constrained to w = -1.006 +/- 0.045. Standard big bang nucleosynthesis predictions for the Planck LCDM cosmology are in excellent agreement with observations. We investigate annihilating dark matter and deviations from standard recombination, finding no evidence for new physics. The Planck results for base LCDM are in agreement with BAO data and with the JLA SNe sample. However the amplitude of the fluctuations is found to be higher than inferred from rich cluster counts and weak gravitational lensing. Apart from these tensions, the base LCDM cosmology provides an excellent description of the Planck CMB observations and many other astrophysical data sets.","['Planck', 'Physics', 'Astronomy']","polarization anisotropies, lensing, hubble constant, matter density parameter, scalar spectral index, ##ing, reionization optical depth, relativistic degrees of freedom, neutrino masses, iso, ##ture perturbations, cosmic defects, dark energy, big bang nucleosynthesis, planck, ann, ##la, rich cluster counts, weak gravitational lensing"
Paper_01651,Research Methodology: Methods and Techniques,['C.R. Kothari'],2004,Unknown,Unknown,,,,,10.59646/rmmt/171,"The book is primarily intended to serve as a textbook for graduate and M.Phil. students ofResearch Methodology in all disciplines of various universities. It is hoped that the book shall provideguidelines to all interested in research studies of one sort or the other. The book is, in fact, anoutgrowth of my experience of teaching the subject to M.Phil. students for the last several years","['Subject (documents)', 'sort', 'Mathematics education', 'Engineering ethics', 'Graduate students', 'Computer science', 'Sociology', 'Library science', 'Pedagogy', 'Engineering', 'Psychology', 'Information retrieval']",research studies
Paper_01653,"Institutional Ecology, `Translations' and Boundary Objects: Amateurs and Professionals in Berkeley's Museum of Vertebrate Zoology, 1907-39","['Susan Leigh Star', 'James Griesemer']",1989,Social Studies of Science,Journal,,387-420,19,3,10.1177/030631289019003001,"Scientific work is heterogeneous, requiring many different actors and viewpoints. It also requires cooperation. The two create tension between divergent viewpoints and the need for generalizable findings. We present a model of how one group of actors managed this tension. It draws on the work of amateurs, professionals, administrators and others connected to the Museum of Vertebrate Zoology at the University of California, Berkeley, during its early years. Extending the Latour-Callon model of interessement, two major activities are central for translating between viewpoints: standardization of methods, and the development of `boundary objects'. Boundary objects are both adaptable to different viewpoints and robust enough to maintain identity across them. We distinguish four types of boundary objects: repositories, ideal types, coincident boundaries and standardized forms.","['Viewpoints', 'Standardization', 'Boundary (topology)', 'Boundary-work', 'Identity (music)', 'Sociology', 'Work (physics)', 'Boundary object', 'Ideal (ethics)', 'Ecology', 'Epistemology', 'Political science', 'Biology', 'Engineering', 'Social science', 'Mathematics', 'Aesthetics', 'Visual arts', 'Philosophy', 'Art', 'Law', 'Mechanical engineering', 'Mathematical analysis', 'Negotiation']","vertebrate zoology, boundary objects, boundary objects, boundary objects, repositories, ideal types, coincident boundaries, standardized"
Paper_01656,ACSM's guidelines for exercise testing and prescription,"['Linda S. Pescatello', 'Ross Arena', 'Deborah Riebe', 'Paul M. Thompson']",2014,['Encyclopedia of Lifestyle Medicine &amp; Health'],Unknown,,,,,10.4135/9781412994149.n165,SECTION I: HEALTH APPRAISAL AND RISK ASSESSMENT 1 Benefits and Risks Associated with Physical Activity 2 Preparticipation Health Screening SECTION II: EXERCISE TESTING 3 Preexercise Evaluation 4 Health-Related Physical Fitness Testing and Interpretation 5 Clinical Exercise Testing 6 Interpretation of Clinical Exercise Test Results SECTION III: EXERCISE PRESCRIPTION 7 General Principles of Exercise Prescription 8 Exercise Prescription for Healthy Populations With Special Considerations and Environmental Considerations 9 Exercise Prescription For Patients With Cardiovascular and Cerebrovascular Disease 10 Exercise Prescription for Populations With Other Chronic Diseases and Health Conditions 11 Behavioral Theories and Strategies for Promoting Exercise SECTION IV: APPENDICES Appendix A Common Medications Appendix B Medical Emergency Management Appendix C Electrocardiogram Interpretation Appendix D American College of Sports Medicine Certifications Appendix E Contributing Authors to the Previous Two Editions,"['Medical prescription', 'Exercise prescription', 'Medicine', 'Sports medicine', 'Physical therapy', 'Test (biology)', 'Certification', 'Physical fitness', 'Family medicine', 'Nursing', 'Paleontology', 'Political science', 'Law', 'Biology']","health appraisal, risk assessment, preparticipation health screening, exercise testing, ##exercise, clinical exercise testing, clinical exercise test, exercise prescription, exercise prescription, common medications, medical emergency management, electrocardio, american college"
Paper_01657,Science and Human Behavior,"['Ernest Kilzer', 'B. F. Skinner']",1953,The American Catholic Sociological Review,Journal,,121-121,14,2,10.2307/3707860,"The psychology classic-a detailed study of scientific theories of human nature and the possible ways in which human behavior can be predicted and controlled-from one of the most influential behaviorists of the twentieth century and the author of Walden Two. This is an important book, exceptionally well written, and logically consistent with the basic premise of the unitary nature of science. Many students of society and culture would take violent issue with most of the things that Skinner has to say, but even those who disagree most will find this a stimulating book. -Samuel M. Strong, The American Journal of Sociology This is a remarkable book-remarkable in that it presents a strong, consistent, and all but exhaustive case for a natural science of human behavior...It ought to be...valuable for those whose preferences lie with, as well as those whose preferences stand against, a behavioristic approach to human activity. -Harry Prosch, Ethics",['Psychology'],"psychology, scientific, human nature, behaviorists, american journal, behavioristic, human activity, ethics"
Paper_01658,"Production, Information Costs and Economic Organization","['Armen A. Alchian', 'Harold Demsetz']",1996,Oxford University Press eBooks,Unknown,,75-102,,,10.1093/oso/9780198774358.003.0005,"Abstract The mark of a capitalistic society is that resources are owned and allocated by such nongovernmental organizations as firms, households, and markets. Resource owners increase productivity through cooperative specialization and this leads to the demand for economic organizations which facilitate co-operation. When a lumber mill employs a cabinetmaker, co-operation between specialists is achieved within a firm, and when a cabinetmaker purchases wood from a lumberman, the co-operation takes place across markets (or between firms). Two important problems face a theory of economic organization-to explain the conditions that determine whether the gains from specialization and cooperative production can better be obtained within an organization like the firm, or across markets, and to explain the structure of the organization.","['Productivity', 'Production (economics)', 'Industrial organization', 'Business', 'Mill', 'Organizational structure', 'Resource (disambiguation)', 'Economics', 'Market economy', 'Microeconomics', 'Management', 'Economic growth', 'Engineering', 'Computer network', 'Computer science', 'Mechanical engineering']","capitalistic society, ##governmental organizations, households, resource owners, cooperative specialization, economic organizations, lumber mill, cabinet, economic organization, cooperative production, [PAD]"
Paper_01659,Wastewater engineering : treatment and reuse,"['Metcalf', 'Eddy']",2004,['Advances in Water Resources'],Unknown,,146,3,3,10.1016/0309-1708(80)90067-6,"1. Wastewater Engineering: An Overview 2. Constituents in Wastewater 3. Analysis and Selection of Wastewater Flowrates and Constituent Loadings 4. Introduction to Process Analysis and Selection 5. Physical Unit Operations 6. Chemical Unit Processes 7. Fundamentals of Biological Treatment 8. Suspended Growth Biological Treatment Processes 9. Attached Growth and Combined Biological Treatment Processes 10. Anaerobic Suspended and Attached Growth Biological Treatment Processes 11. Advanced Wastewater Treatment 12. Disinfection Processes 13. Water Reuse 14. Treatment, Reuse, and Disposal of Solids and Biosolids 15. Issues Related to Treatment-Plant Performance Appendixes A Conversion Factors B Physical Properties of Selected Gases and the Composition of Air C Physical Properties of Water D Solubility of Dissolved Oxygen in Water as a Function of Salinity and Barometric Pressure E MPN Tables and Their Use F Carbonate Equilibrium G Moody Diagrams for the Analysis of Flow in Pipes","['Wastewater', 'Biosolids', 'Reuse', 'Sewage treatment', 'Waste management', 'Environmental science', 'Environmental engineering', 'Engineering']","wastewater engineering, constituents, wastewater flowrates, constituent loadings, physical unit operations, chemical unit processes, biological treatment, suspended growth biological treatment, attached growth, combined biological treatment, attached growth, advanced wastewater treatment, disinfection processes, water reuse, ##sol, conversion factors, sal, ##ty, barometric pressure, mpn tables, carbonate equilibrium, moody diagrams"
Paper_01661,Nucleic acid techniques in bacterial systematics,"['Erko Stackebrandt', 'Michael Goodfellow']",1991,['International Journal of Food Microbiology'],Unknown,,225-236,120,3,10.1016/j.ijfoodmicro.2007.06.023,Isolation and purification of nucleic acids DNA reassociation experiments DNA-rRNA hybridization and methods DNA sequencing in bacterial systematics direct sequence analysis of small RNAs 16S/23S rRNA sequencing the polymerase chain reaction development and application of nucleic acid probes DNA fingerprinting from macromolecules to trees.,"['Nucleic acid', 'Biology', 'DNA', 'Nucleic acid thermodynamics', 'Sequencing by ligation', 'DNA sequencing', 'Polymerase chain reaction', 'Computational biology', 'Molecular biology', 'Biochemistry', 'Gene', 'Base sequence', 'Genomic library']","nucleic, dna reassociation, dna sequencing, bacterial systematics, polymerase chain reaction, nucleic, dna fingerprinting"
Paper_01664,<i>EGFR</i> Mutations in Lung Cancer: Correlation with Clinical Response to Gefitinib Therapy,"['J. Guillermo Paez', 'Pasi A. Jänne', 'Jeffrey C. Lee', 'Sean Tracy', 'Heidi Greulich', 'Stacey Gabriel', 'Paula Herman', 'Frederic J. Kaye', 'Neal I. Lindeman', 'Titus J. Boggon', 'Katsuhiko Naoki', 'Hidefumi Sasaki', 'Yoshitaka Fujii', 'Michael J. Eck', 'William R. Sellers', 'Bruce E. Johnson', 'Matthew Meyerson']",2004,Science,Journal,,1497-1500,304,5676,10.1126/science.1099314,"Receptor tyrosine kinase genes were sequenced in non–small cell lung cancer (NSCLC) and matched normal tissue. Somatic mutations of the epidermal growth factor receptor gene EGFR were found in 15of 58 unselected tumors from Japan and 1 of 61 from the United States. Treatment with the EGFR kinase inhibitor gefitinib (Iressa) causes tumor regression in some patients with NSCLC, more frequently in Japan. EGFR mutations were found in additional lung cancer samples from U.S. patients who responded to gefitinib therapy and in a lung adenocarcinoma cell line that was hypersensitive to growth inhibition by gefitinib, but not in gefitinib-insensitive tumors or cell lines. These results suggest that EGFR mutations may predict sensitivity to gefitinib.","['Gefitinib', 'Lung cancer', 'Epidermal growth factor receptor', 'Adenocarcinoma', 'Cancer research', 'Somatic cell', 'Medicine', 'Oncology', 'Tyrosine kinase', 'Internal medicine', 'Tyrosine-kinase inhibitor', 'Cancer', 'Biology', 'Gene', 'Receptor', 'Genetics']","receptor tyrosine kinase, non – small cell lung cancer, somatic, epidermal growth factor receptor gene egf, egfr kinase, ##tin, tumor regression, egfr, lung cancer, ge, ##ib, lung adenocarcinoma, egf, [PAD] [PAD]"
Paper_01667,Measuring the Accuracy of Diagnostic Systems,['John A. Swets'],1988,Science,Journal,,1285-1293,240,4857,10.1126/science.3287615,"Diagnostic systems of several kinds are used to distinguish between two classes of events, essentially ""signals"" and ""noise."" For them, analysis in terms of the ""relative operating characteristic"" of signal detection theory provides a precise and valid measure of diagnostic accuracy. It is the only measure available that is uninfluenced by decision biases and prior probabilities, and it places the performances of diverse systems on a common, easily interpreted scale. Representative values of this measure are reported here for systems in medical imaging, materials testing, weather forecasting, information retrieval, polygraph lie detection, and aptitude testing. Though the measure itself is sound, the values obtained from tests of diagnostic systems often require qualification because the test data on which they are based are of unsure quality. A common set of problems in testing is faced in all fields. How well these problems are handled, or can be handled in a given field, determines the degree of confidence that can be placed in a measured value of accuracy. Some fields fare much better than others.","['Measure (data warehouse)', 'Computer science', 'Field (mathematics)', 'Noise (video)', 'Quality (philosophy)', 'Set (abstract data type)', 'Lie detection', 'Scale (ratio)', 'Polygraph', 'SIGNAL (programming language)', 'Data mining', 'Detection theory', 'Artificial intelligence', 'Machine learning', 'Statistics', 'Mathematics', 'Psychology', 'Social psychology', 'Telecommunications', 'Philosophy', 'Physics', 'Epistemology', 'Quantum mechanics', 'Detector', 'Pure mathematics', 'Image (mathematics)', 'Programming language', 'Deception']","diagnostic systems, noise, relative operating characteristic, signal detection theory, diagnostic accuracy, decision biases, medical imaging, materials testing, weather forecasting, information retrieval, polygraph lie detection, aptitude testing"
Paper_01668,The Structure of Scientific Revolutions.,"['David Böhm', 'Thomas Kühn']",1964,The Philosophical Quarterly,Journal,,377-377,14,57,10.2307/2217783,"Journal Article Book Reviews Get access The Structure of Scientific Revolutions. By Thomas S. Kuhn. International Encyclopaedia of Unified Science, Vol. II , No. 2. (Chicago and London : University of Chicago Press. 1962. Pp. xvi + 172. Price 22s 6d or $3.00). David Bohm David Bohm Search for other works by this author on: Oxford Academic Google Scholar The Philosophical Quarterly, Volume 14, Issue 57, October 1964, Pages 377–379, https://doi.org/10.2307/2217783 Published: 01 October 1964","['Encyclopedia', 'Classics', 'Philosophy', 'Library science', 'Sociology', 'History', 'Computer science']","scientific revolutions, international encyclopaedia, unified science, philosophical quarterly, [PAD]"
Paper_01600,Click Chemistry: Diverse Chemical Function from a Few Good Reactions,"['Hartmuth C. Kolb', 'M. G. Finn', 'K. Barry Sharpless']",2001,Angewandte Chemie International Edition,Journal,,2004-2021,40,11,10.1002/1521-3773(20010601)40:11<2004::aid-anie2004>3.3.co;2-x,"Examination of nature's favorite molecules reveals a striking preference for making carbon–heteroatom bonds over carbon–carbon bonds—surely no surprise given that carbon dioxide is nature's starting material and that most reactions are performed in water. Nucleic acids, proteins, and polysaccharides are condensation polymers of small subunits stitched together by carbon–heteroatom bonds. Even the 35 or so building blocks from which these crucial molecules are made each contain, at most, six contiguous C−C bonds, except for the three aromatic amino acids. Taking our cue from nature's approach, we address here the development of a set of powerful, highly reliable, and selective reactions for the rapid synthesis of useful new compounds and combinatorial libraries through heteroatom links (C−X−C), an approach we call “click chemistry”. Click chemistry is at once defined, enabled, and constrained by a handful of nearly perfect “spring-loaded” reactions. The stringent criteria for a process to earn click chemistry status are described along with examples of the molecular frameworks that are easily made using this spartan, but powerful, synthetic strategy.","['Heteroatom', 'Click chemistry', 'Chemistry', 'Molecule', 'Polymer science', 'Combinatorial chemistry', 'Surprise', 'Polymer', 'Condensation reaction', 'Organic chemistry', 'Nanotechnology', 'Materials science', 'Catalysis', 'Ring (chemistry)', 'Social psychology', 'Psychology']","##ato, nucleic, polysaccharides, condensation polymers, aromatic amino acids, ##inatorial libraries, heteroatom links, click chemistry, click chemistry, click"
Paper_01601,Enriching Word Vectors with Subword Information,"['Piotr Bojanowski', 'Édouard Grave', 'Armand Joulin', 'Tomáš Mikolov']",2017,Transactions of the Association for Computational Linguistics,Journal,,135-146,5,,10.1162/tacl_a_00051,"Continuous word representations, trained on large unlabeled corpora are useful for many natural language processing tasks. Popular models that learn such representations ignore the morphology of words, by assigning a distinct vector to each word. This is a limitation, especially for languages with large vocabularies and many rare words. In this paper, we propose a new approach based on the skipgram model, where each word is represented as a bag of character n-grams. A vector representation is associated to each character n-gram; words being represented as the sum of these representations. Our method is fast, allowing to train models on large corpora quickly and allows us to compute word representations for words that did not appear in the training data. We evaluate our word representations on nine different languages, both on word similarity and analogy tasks. By comparing to recently proposed morphological word representations, we show that our vectors achieve state-of-the-art performance on these tasks.","['Computer science', 'Word (group theory)', 'Natural language processing', 'Artificial intelligence', 'Character (mathematics)', 'Similarity (geometry)', 'Analogy', 'Representation (politics)', 'Language model', 'Speech recognition', 'Linguistics', 'Mathematics', 'Philosophy', 'Geometry', 'Politics', 'Political science', 'Law', 'Image (mathematics)']","continuous word representations, natural language processing tasks, morphology, skipgram model, vector representation, word similarity, analogy tasks, morphological word representations"
Paper_01603,Advances in Neural Information Processing Systems 14,[],2002,The MIT Press eBooks,Unknown,,,,,10.7551/mitpress/1120.001.0001,"The proceedings of the 2001 Neural Information Processing Systems (NIPS) Conference. The annual conference on Neural Information Processing Systems (NIPS) is the flagship conference on neural computation. The conference is interdisciplinary, with contributions in algorithms, learning theory, cognitive science, neuroscience, vision, speech and signal processing, reinforcement learning and control, implementations, and diverse applications. Only about 30 percent of the papers submitted are accepted for presentation at NIPS, so the quality is exceptionally high. These proceedings contain all of the papers that were presented at the 2001 conference. Bradford Books imprint","['Presentation (obstetrics)', 'Computer science', 'Information processing', 'Implementation', 'Artificial neural network', 'Reinforcement learning', 'Artificial intelligence', 'Signal processing', 'Neural system', 'Cognitive science', 'Psychology', 'Telecommunications', 'Neuroscience', 'Software engineering', 'Medicine', 'Radar', 'Radiology']","neural information processing systems, neural information processing systems, neural computation, algorithms, learning theory, cognitive science, neuroscience, vision, signal processing, reinforcement learning, control, [PAD], [PAD] [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD]"
Paper_01604,"UFF, a full periodic table force field for molecular mechanics and molecular dynamics simulations","['Anthony K. Rappé', 'C. J. Casewit', 'K. S. Colwell', 'William A. Goddard', 'W. M. Skiff']",1992,Journal of the American Chemical Society,Journal,,10024-10035,114,25,10.1021/ja00051a040,"ADVERTISEMENT RETURN TO ISSUEPREVArticleNEXTUFF, a full periodic table force field for molecular mechanics and molecular dynamics simulationsA. K. Rappe, C. J. Casewit, K. S. Colwell, W. A. Goddard III, and W. M. SkiffCite this: J. Am. Chem. Soc. 1992, 114, 25, 10024–10035Publication Date (Print):December 1, 1992Publication History Published online1 May 2002Published inissue 1 December 1992https://pubs.acs.org/doi/10.1021/ja00051a040https://doi.org/10.1021/ja00051a040research-articleACS PublicationsRequest reuse permissionsArticle Views36939Altmetric-Citations7980LEARN ABOUT THESE METRICSArticle Views are the COUNTER-compliant sum of full text article downloads since November 2008 (both PDF and HTML) across all institutions and individuals. These metrics are regularly updated to reflect usage leading up to the last few days.Citations are the number of other articles citing this article, calculated by Crossref and updated daily. Find more information about Crossref citation counts.The Altmetric Attention Score is a quantitative measure of the attention that a research article has received online. Clicking on the donut icon will load a page at altmetric.com with additional details about the score and the social media presence for the given article. Find more information on the Altmetric Attention Score and how the score is calculated. Share Add toView InAdd Full Text with ReferenceAdd Description ExportRISCitationCitation and abstractCitation and referencesMore Options Share onFacebookTwitterWechatLinked InRedditEmail Other access optionsGet e-AlertscloseSupporting Info (1)»Supporting Information Supporting Information Get e-Alerts","['Citation', 'Computer science', 'Social media', 'Field (mathematics)', 'Icon', 'Dynamics (music)', 'Information retrieval', 'Physics', 'World Wide Web', 'Mathematics', 'Pure mathematics', 'Programming language', 'Acoustics']","##f, full periodic table force field, molecular mechanics, molecular dynamics simulations, permissionsar, ##le, ##le, altmetric attention score, social, altmetric attention score, ##riscitation, abstract, ##ation, references"
Paper_01605,A molecular dynamics method for simulations in the canonical ensemble,['Shūichi Nosé'],1984,Molecular Physics,Journal,,255-268,52,2,10.1080/00268978400101201,"A molecular dynamics simulation method which can generate configurations belonging to the canonical (T, V, N) ensemble or the constant temperature constant pressure (T, P, N) ensemble, is proposed. The physical system of interest consists of N particles (f degrees of freedom), to which an external, macroscopic variable and its conjugate momentum are added. This device allows the total energy of the physical system to fluctuate. The equilibrium distribution of the energy coincides with the canonical distribution both in momentum and in coordinate space. The method is tested for an atomic fluid (Ar) and works well.","['Canonical ensemble', 'Molecular dynamics', 'Microcanonical ensemble', 'Degrees of freedom (physics and chemistry)', 'Momentum (technical analysis)', 'Constant (computer programming)', 'Physics', 'Statistical ensemble', 'Grand canonical ensemble', 'Distribution (mathematics)', 'Total energy', 'Canonical coordinates', 'Space (punctuation)', 'Statistical physics', 'Coordinate space', 'Potential energy', 'Dynamics (music)', 'Kinetic energy', 'Classical mechanics', 'Thermodynamics', 'Quantum mechanics', 'Mathematics', 'Phase space', 'Mathematical analysis', 'Computer science', 'Acoustics', 'Monte Carlo method', 'Statistics', 'Psychotherapist', 'Operating system', 'Psychology', 'Geometry', 'Economics', 'Programming language', 'Finance', 'Displacement (psychology)']","molecular dynamics simulation method, constant temperature constant pressure, conjugate momentum, equilibrium distribution, canonical distribution, coordinate space, atomic fluid, [PAD], [PAD], [PAD], [PAD], [PAD], [PAD] [PAD], [PAD], [PAD] [PAD], [PAD], [PAD], [PAD] [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"
Paper_01606,Cryo-EM structure of the 2019-nCoV spike in the prefusion conformation,"['Daniel Wrapp', 'Nianshuang Wang', 'Kizzmekia S. Corbett', 'Jory A. Goldsmith', 'Ching‐Lin Hsieh', 'Olubukola M. Abiona', 'Barney S. Graham', 'Jason S. McLellan']",2020,Science,Journal,,1260-1263,367,6483,10.1126/science.abb2507,"The outbreak of a novel coronavirus (2019-nCoV) represents a pandemic threat that has been declared a public health emergency of international concern. The CoV spike (S) glycoprotein is a key target for vaccines, therapeutic antibodies, and diagnostics. To facilitate medical countermeasure development, we determined a 3.5-angstrom-resolution cryo–electron microscopy structure of the 2019-nCoV S trimer in the prefusion conformation. The predominant state of the trimer has one of the three receptor-binding domains (RBDs) rotated up in a receptor-accessible conformation. We also provide biophysical and structural evidence that the 2019-nCoV S protein binds angiotensin-converting enzyme 2 (ACE2) with higher affinity than does severe acute respiratory syndrome (SARS)-CoV S. Additionally, we tested several published SARS-CoV RBD-specific monoclonal antibodies and found that they do not have appreciable binding to 2019-nCoV S, suggesting that antibody cross-reactivity may be limited between the two RBDs. The structure of 2019-nCoV S should enable the rapid development and evaluation of medical countermeasures to address the ongoing public health crisis.","['Severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2)', 'Coronavirus disease 2019 (COVID-19)', 'Trimer', 'Monoclonal antibody', 'Coronavirus', 'Antibody', '2019-20 coronavirus outbreak', 'Chemistry', 'Cryo-electron microscopy', 'Betacoronavirus', 'Binding site', 'Receptor', 'Pandemic', 'Outbreak', 'Virology', 'Computational biology', 'Biology', 'Medicine', 'Immunology', 'Biochemistry', 'Dimer', 'Pathology', 'Disease', 'Organic chemistry', 'Infectious disease (medical specialty)']","##demic, cov, therapeutic antibodies, ##s, medical countermeasure development, severe acute respiratory syndrome, medical counter"
Paper_01607,Natural population analysis,"['Alan E. Reed', 'Robert B. Weinstock', 'Frank Weinhold']",1985,The Journal of Chemical Physics,Journal,,735-746,83,2,10.1063/1.449486,"Views Icon Views Article contents Figures & tables Video Audio Supplementary Data Peer Review Share Icon Share Twitter Facebook Reddit LinkedIn Tools Icon Tools Reprints and Permissions Cite Icon Cite Search Site Citation Alan E. Reed, Robert B. Weinstock, Frank Weinhold; Natural population analysis. J. Chem. Phys. 15 July 1985; 83 (2): 735–746. https://doi.org/10.1063/1.449486 Download citation file: Ris (Zotero) Reference Manager EasyBib Bookends Mendeley Papers EndNote RefWorks BibTex toolbar search Search Dropdown Menu toolbar search search input Search input auto suggest filter your search All ContentAIP Publishing PortfolioThe Journal of Chemical Physics Search Advanced Search |Citation Search","['Ionic bonding', 'Mulliken population analysis', 'Generality', 'Population', 'Computational chemistry', 'Wave function', 'Molecular orbital', 'Ionic potential', 'Covalent bond', 'Ab initio', 'Basis (linear algebra)', 'Atomic orbital', 'Chemistry', 'Chemical physics', 'Statistical physics', 'Molecule', 'Atomic physics', 'Physics', 'Density functional theory', 'Electron', 'Mathematics', 'Quantum mechanics', 'Ion', 'Geometry', 'Organic chemistry', 'Psychology', 'Demography', 'Sociology', 'Psychotherapist']","linked, natural population analysis, ##s, zotero, easybib, mendeley papers, bibtex, chemical physics, citation search"
Paper_01609,Enzymatic Determination of Total Serum Cholesterol,"['Charles C. Allain', 'Lucy S Poon', 'Cicely S G Chan', 'W. Richmond', 'Paul Fu']",1974,Clinical Chemistry,Journal,,470-475,20,4,10.1093/clinchem/20.4.470,"Abstract An enzymatic method is described for determination of total serum cholesterol by use of a single aqueous reagent. The method requires no prior treatment of sample and the calibration curve is linear to 600 mg/dl. Cholesterol esters are hydrolyzed to free cholesterol by cholesterol ester hydrolase (EC 3.1.1.13). The free cholesterol produced is oxidized by cholesterol oxidase to cholest-4-en-3-one with the simultaneous production of hydrogen peroxide, which oxidatively couples with 4-aminoantipyrine and phenol in the presence of peroxidase to yield a chromogen with maximum absorption at 500 nm. The method is reproducible, and the results correlate well with those obtained by automated Liebermann—Burchard procedures (AA-2 and SMA 12/60) and the method of Abell et al. The present method affords better specificity than those previously reported and has excellent precision.","['Cholesterol oxidase', 'Chemistry', 'Cholesterol', 'Hydrogen peroxide', 'Chromatography', 'Reagent', 'Hydrolysis', 'Calibration curve', 'Phenol', 'Enzyme', 'Peroxidase', 'Biochemistry', 'Detection limit', 'Organic chemistry']","enzymatic, cholesterol ester hydrolase, ##terol oxidase, hydrogen per"
Paper_01611,THE CONSTITUTION AND FUNDAMENTAL PROPERTIES OF SOLIDS AND LIQUIDS. PART I. SOLIDS.,['Irving Langmuir'],1916,Journal of the American Chemical Society,Journal,,2221-2295,38,11,10.1021/ja02268a002,"ADVERTISEMENT RETURN TO ISSUEPREVArticleNEXTTHE CONSTITUTION AND FUNDAMENTAL PROPERTIES OF SOLIDS AND LIQUIDS. PART I. SOLIDS.Irving LangmuirCite this: J. Am. Chem. Soc. 1916, 38, 11, 2221–2295Publication Date (Print):November 1, 1916Publication History Published online1 May 2002Published inissue 1 November 1916https://pubs.acs.org/doi/10.1021/ja02268a002https://doi.org/10.1021/ja02268a002research-articleACS PublicationsRequest reuse permissionsArticle Views12962Altmetric-Citations7584LEARN ABOUT THESE METRICSArticle Views are the COUNTER-compliant sum of full text article downloads since November 2008 (both PDF and HTML) across all institutions and individuals. These metrics are regularly updated to reflect usage leading up to the last few days.Citations are the number of other articles citing this article, calculated by Crossref and updated daily. Find more information about Crossref citation counts.The Altmetric Attention Score is a quantitative measure of the attention that a research article has received online. Clicking on the donut icon will load a page at altmetric.com with additional details about the score and the social media presence for the given article. Find more information on the Altmetric Attention Score and how the score is calculated. Share Add toView InAdd Full Text with ReferenceAdd Description ExportRISCitationCitation and abstractCitation and referencesMore Options Share onFacebookTwitterWechatLinked InRedditEmail Other access optionsGet e-Alertsclose Get e-Alerts","['Altmetrics', 'Citation', 'Constitution', 'Icon', 'Computer science', 'Social media', 'Reuse', 'World Wide Web', 'Information retrieval', 'Engineering', 'Political science', 'Law', 'Programming language', 'Waste management']","liquids, permissionsar, ##le views, ##le, ##f, altmetric attention score, social, altmetric attention score, ##d, ##riscitation, abstract, ##ation, references"
Paper_01612,Simulation Modeling and Analysis.,"['Mark J. Schervish', 'Averill M. Law', 'W. David Kelton']",1983,Journal of the American Statistical Association,Journal,,743-743,78,383,10.2307/2288169,"From the Publisher:
This second edition of Modeling and Analysis includes a chapter on Simulation in Manufacturing Systems and examples. The text is designed for a one-term or two-quarter course in simulation offered in departments of industrial engineering,business,computer science and operations research.",['Computer science'],"modeling, simulation, manufacturing systems, industrial engineering, business, computer science, operations research, [PAD]"
Paper_01614,A Conceptual Model of Service Quality and Its Implications for Future Research,"['A. Parasuraman', 'Valarie A. Zeithaml', 'Leonard L. Berry']",1985,Journal of Marketing,Journal,,41-50,49,4,10.1177/002224298504900403,"The attainment of quality in products and services has become a pivotal concern of the 1980s. While quality in tangible goods has been described and measured by marketers, quality in services is largely undefined and unresearched. The authors attempt to rectify this situation by reporting the insights obtained in an extensive exploratory investigation of quality in four service businesses and by developing a model of service quality. Propositions and recommendations to stimulate future research about service quality are offered.","['Quality (philosophy)', 'Business', 'Service quality', 'Conceptual model', 'Marketing', 'Service (business)', 'Exploratory research', 'Computer science', 'Sociology', 'Philosophy', 'Epistemology', 'Database', 'Anthropology']","quality, services, quality, tangible goods, quality, services, quality, service businesses, service quality, service quality"
Paper_01615,Signal Recovery From Random Measurements Via Orthogonal Matching Pursuit,"['Joel A. Tropp', 'Anna C. Gilbert']",2007,IEEE Transactions on Information Theory,Journal,,4655-4666,53,12,10.1109/tit.2007.909108,"<para xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink""> This paper demonstrates theoretically and empirically that a greedy algorithm called Orthogonal Matching Pursuit (OMP) can reliably recover a signal with <emphasis><formula formulatype=""inline""><tex>$m$</tex></formula></emphasis> nonzero entries in dimension <emphasis><formula formulatype=""inline""><tex>$d$</tex> </formula></emphasis> given <emphasis><formula formulatype=""inline""><tex>$ {\rm O}(m \ln d)$</tex></formula></emphasis> random linear measurements of that signal. This is a massive improvement over previous results, which require <emphasis><formula formulatype=""inline""><tex>${\rm O}(m^{2})$</tex></formula></emphasis> measurements. The new results for OMP are comparable with recent results for another approach called Basis Pursuit (BP). In some settings, the OMP algorithm is faster and easier to implement, so it is an attractive alternative to BP for signal recovery problems. </para>","['Emphasis (telecommunications)', 'Matching pursuit', 'Dimension (graph theory)', 'SIGNAL (programming language)', 'Basis pursuit', 'Signal processing', 'Signal reconstruction', 'Computer science', 'Matching (statistics)', 'Algorithm', 'Greedy algorithm', 'Mathematics', 'Combinatorics', 'Statistics', 'Compressed sensing', 'Telecommunications', 'Radar', 'Programming language']","greedy algorithm, orthogonal matching pursuit, ##zero, random linear measurements, basis pursuit, signal recovery problems, [PAD]"
Paper_01618,$rm K$-SVD: An Algorithm for Designing Overcomplete Dictionaries for Sparse Representation,"['Michal Aharon', 'Michael Elad', 'Alfred M. Bruckstein⋆']",2006,IEEE Transactions on Signal Processing,Journal,,4311-4322,54,11,10.1109/tsp.2006.881199,"In recent years there has been a growing interest in the study of sparse representation of signals. Using an overcomplete dictionary that contains prototype signal-atoms, signals are described by sparse linear combinations of these atoms. Applications that use sparse representation are many and include compression, regularization in inverse problems, feature extraction, and more. Recent activity in this field has concentrated mainly on the study of pursuit algorithms that decompose signals with respect to a given dictionary. Designing dictionaries to better fit the above model can be done by either selecting one from a prespecified set of linear transforms or adapting the dictionary to a set of training signals. Both of these techniques have been considered, but this topic is largely still open. In this paper we propose a novel algorithm for adapting dictionaries in order to achieve sparse signal representations. Given a set of training signals, we seek the dictionary that leads to the best representation for each member in this set, under strict sparsity constraints. We present a new method-the K-SVD algorithm-generalizing the K-means clustering process. K-SVD is an iterative method that alternates between sparse coding of the examples based on the current dictionary and a process of updating the dictionary atoms to better fit the data. The update of the dictionary columns is combined with an update of the sparse representations, thereby accelerating convergence. The K-SVD algorithm is flexible and can work with any pursuit method (e.g., basis pursuit, FOCUSS, or matching pursuit). We analyze this algorithm and demonstrate its results both on synthetic tests and in applications on real image data","['Matching pursuit', 'K-SVD', 'Sparse approximation', 'Computer science', 'Basis pursuit', 'Algorithm', 'Neural coding', 'Singular value decomposition', 'Cluster analysis', 'Pattern recognition (psychology)', 'Set (abstract data type)', 'Representation (politics)', 'Artificial intelligence', 'Compressed sensing', 'Politics', 'Political science', 'Law', 'Programming language']","sparse representation, overcomplete dictionary, sparse linear combinations, sparse representation, compression, regularization, inverse problems, feature extraction, pursuit algorithms, dictionaries, linear transforms, training signals, dictionaries, sparse signal representations, training, sparsity constraints, sparse coding, dictionary, sparse representations, basis pursuit, focuss, matching pursuit, synthetic tests, real image data"
Paper_01619,Momentum Contrast for Unsupervised Visual Representation Learning,"['Kaiming He', 'Haoqi Fan', 'Yuxin Wu', 'Saining Xie', 'Ross Girshick']",2020,2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),Conference,"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), Seattle, WA, USA",,,,10.1109/cvpr42600.2020.00975,"We present Momentum Contrast (MoCo) for unsupervised visual representation learning. From a perspective on contrastive learning as dictionary look-up, we build a dynamic dictionary with a queue and a moving-averaged encoder. This enables building a large and consistent dictionary on-the-fly that facilitates contrastive unsupervised learning. MoCo provides competitive results under the common linear protocol on ImageNet classification. More importantly, the representations learned by MoCo transfer well to downstream tasks. MoCo can outperform its supervised pre-training counterpart in 7 detection/segmentation tasks on PASCAL VOC, COCO, and other datasets, sometimes surpassing it by large margins. This suggests that the gap between unsupervised and supervised representation learning has been largely closed in many vision tasks.","['Artificial intelligence', 'Pascal (unit)', 'Computer science', 'Contrast (vision)', 'Unsupervised learning', 'Segmentation', 'Feature learning', 'Machine learning', 'Representation (politics)', 'Pattern recognition (psychology)', 'Transfer of learning', 'Encoder', 'Natural language processing', 'Politics', 'Political science', 'Law', 'Programming language', 'Operating system']","momentum contrast, moco, unsupervised visual representation learning, contrastive learning, dynamic dictionary, contrast, ##pervised learning, moco, linear protocol, imagenet classification, moco, moco, pascal voc, coco, supervised representation learning"
Paper_01620,Hegemony and Socialist Strategy: Towards a Radical Democratic Politics,"['Chantal Mouffe', 'Ernesto Laclau']",1985,['Thesis Eleven'],Unknown,,148-150,16,1,10.1177/072551368701600118,"This book traces the genealogy of the present crisis in left-wing thought, from stifling of democracy under Marxist-Lenninism and Stalinism to the contemporary emergence of new forms of struggle; and reexamines the idea of hegemony, from the formation of the idea in the writings of Lenin and Gramsci, to the expanded and discursive ideas of Foucault to posit a claim for the new possibilities of a radical democracy. This is a text for both the understanding of hegemony and for focusing on present social struggles and their significance for democratic theory.","['Hegemony', 'Democracy', 'Marxist philosophy', 'Politics', 'Political science', 'Sociology', 'Political economy', 'Epistemology', 'Social science', 'Law', 'Philosophy']","stalin, hegemony, radical democracy, hegemony, social, democratic theory"
Paper_01621,The Content Analysis Guidebook,['Kimberly A. Neuendorf'],2017,Unknown,Unknown,,,,,10.4135/9781071802878,"List of Boxes List of Tables and Figures Foreword Acknowledgments 1. Defining Content Analysis Is Content Analysis Easy? Is It Something That Anyone Can Do? A Six-Part Definition of Content Analysis 2. Milestones in the History of Content Analysis The Growing Popularity of Content Analysis Milestones of Content Analysis Research 3. Beyond Description: An Integrative Model of Content Analysis The Language of the Scientific Method How Content Analysis Is Done: Flowchart for the Typical Process of Content-Analysis Research Approaches to Content Analysis The Integrative Model of Content Analysis Evaluation With the Integrative Model of Content Analysis 4. Message Units and Sampling Units Defining the Population Archives Medium Management Sampling Sample Size 5. Variables and Predictions Identifying Critical Variables Hypotheses, Predictions, and Research Questions 6. Measurement Techniques Defining Measurement Validity, Reliability, Accuracy, and Precision Types of Validity Assessment Operationalization Computer Coding Selection of a Computer Text Content Analysis Program Human Coding Index Construction in Content Analysis 7. Reliability Intercoder Reliability Standards and Practices Issues in the Assessment of Reliability Pilot and Final Reliabilities Intercoder Reliability Coefficients: Issues and Comparisons Calculating Intercoder Reliability Coefficients Treatment of Variables That Do Not Achieve an Acceptable Level of Reliability The Use of Multiple Coders Advanced and Specialty Issues in Reliatbility Coefficient Selection 8. Results and Reporting Data Handling and Transformations Hypothesis Tesing Selecting the Appropriate Statistical Tests Frequencies Co-Occurences and In-Context Occurrences Time Lines Bivariate Relationships Multivariate Relationships 9. Contexts Psychometric Applications of Content Analysis Open-Ended Written and Pictorial Responses Linguistics and Semantic Networks Stylometrics and Computer Literary Analysis Interaction Analysis Other Interpersonal Behaviors Violence in the Media Gender Roles Minority Portrayals Advertising News Political Communication Web Analyses Other Applied Contexts Commercial and Other Client-Based Applications of Content Analysis Future Directions Resource 1: Message Archives - P.D. Skalski General Collections Film, Television and Radio Archives Literary and General Corpora Other Archives Resource 2: Using NEXIS for Text Acquisition for Content Analysis Resource 3: Computer Content Analysis Software - P.D. Skalski Part I. Quantitative Computer Text Analysis Programs Part II. VBPro How-To Guide and Executional Flowchart Resource 4: An Introduction to PRAM--A Program for Reliability Assessment With Multiple Coders Resource 5: The Content Analysis Guidebook Online Content Analysis Resources Bibliographies Message Archives and Corpora Reliability Human Coding Sample Materials Computer Content Analysis References Author Index Subject Index About the Authors","['Content (measure theory)', 'Environmental science', 'Computer science', 'Mathematics', 'Mathematical analysis']","content analysis, content analysis, content analysis, content analysis, content analysis, content analysis, content analysis, flow, ##rt, content, content, message units, sampling units, population archives, measurement techniques, measurement validity, reliability, validity, human coding index, content analysis, reliability intercoder reliability, final, semantic networks, computer literary analysis, ##s, content, computer content analysis, reliability, content analysis, corpora reliability"
Paper_01624,Coding Algorithms for Defining Comorbidities in ICD-9-CM and ICD-10 Administrative Data,"['Hude Quan', 'Vijaya Sundararajan', 'Patricia Halfon', 'Andrew Fong', 'Bernard Burnand', 'Jean‐Christophe Luthi', 'L. Duncan Saunders', 'Cynthia A Beck', 'Thomas E. Feasby', 'William A. Ghali']",2005,Medical Care,Journal,,1130-1139,43,11,10.1097/01.mlr.0000182534.19832.83,"Implementation of the International Statistical Classification of Disease and Related Health Problems, 10th Revision (ICD-10) coding system presents challenges for using administrative data. Recognizing this, we conducted a multistep process to develop ICD-10 coding algorithms to define Charlson and Elixhauser comorbidities in administrative data and assess the performance of the resulting algorithms.ICD-10 coding algorithms were developed by ""translation"" of the ICD-9-CM codes constituting Deyo's (for Charlson comorbidities) and Elixhauser's coding algorithms and by physicians' assessment of the face-validity of selected ICD-10 codes. The process of carefully developing ICD-10 algorithms also produced modified and enhanced ICD-9-CM coding algorithms for the Charlson and Elixhauser comorbidities. We then used data on in-patients aged 18 years and older in ICD-9-CM and ICD-10 administrative hospital discharge data from a Canadian health region to assess the comorbidity frequencies and mortality prediction achieved by the original ICD-9-CM algorithms, the enhanced ICD-9-CM algorithms, and the new ICD-10 coding algorithms.Among 56,585 patients in the ICD-9-CM data and 58,805 patients in the ICD-10 data, frequencies of the 17 Charlson comorbidities and the 30 Elixhauser comorbidities remained generally similar across algorithms. The new ICD-10 and enhanced ICD-9-CM coding algorithms either matched or outperformed the original Deyo and Elixhauser ICD-9-CM coding algorithms in predicting in-hospital mortality. The C-statistic was 0.842 for Deyo's ICD-9-CM coding algorithm, 0.860 for the ICD-10 coding algorithm, and 0.859 for the enhanced ICD-9-CM coding algorithm, 0.868 for the original Elixhauser ICD-9-CM coding algorithm, 0.870 for the ICD-10 coding algorithm and 0.878 for the enhanced ICD-9-CM coding algorithm.These newly developed ICD-10 and ICD-9-CM comorbidity coding algorithms produce similar estimates of comorbidity prevalence in administrative data, and may outperform existing ICD-9-CM coding algorithms.","['ICD-10', 'Algorithm', 'Medicine', 'Coding (social sciences)', 'Diagnosis code', 'Comorbidity', 'Current Procedural Terminology', 'Data mining', 'Computer science', 'Statistics', 'Population', 'Internal medicine', 'Mathematics', 'Surgery', 'Environmental health', 'Psychiatry']","international statistical classification of disease, administrative data, ##step, elixhauser comorbidities, ##lson comorbidities, elixhauser comorbidities, canadian health region, ##rbidity frequencies, mortality prediction, eli, comorbidity prevalence"
Paper_01627,Tissue Engineering,"['Róbert Langer', 'Joseph P. Vacanti']",1993,Science,Journal,,920-926,260,5110,10.1126/science.8493529,"The loss or failure of an organ or tissue is one of the most frequent, devastating, and costly problems in human health care. A new field, tissue engineering, applies the principles of biology and engineering to the development of functional substitutes for damaged tissue. This article discusses the foundations and challenges of this interdisciplinary field and its attempts to provide solutions to tissue creation and repair.","['Tissue engineering', 'Engineering ethics', 'Tissue repair', 'Hard tissue', 'Medicine', 'Engineering', 'Biomedical engineering', 'Surgery']","human health care, tissue engineering, biology, engineering, functional substitutes"
Paper_01628,The Interpretation of Cultures: Selected Essays.,"['Elizabeth Colson', 'Clifford Geertz']",1975,Contemporary Sociology A Journal of Reviews,Journal,,637-637,4,6,10.2307/2064031,"Part I * Thick Description: Toward an Interpretive Theory of Culture Part II * The Impact of the Concept of Culture on the Concept of Man * The Growth of Culture and the Evolution of Mind Part III * Religion As a Cultural System * Ethos, World View, and the Analysis of Sacred Symbols * Ritual and Social Change: A Javanese Example * Internal Conversion in Contemporary Bali Part IV * Ideology As a Cultural System * After the Revolution: The Fate of Nationalism in the New States * The Integrative Revolution: Primordial Sentiments and Civil Politics in the New States * The Politics of Meaning * Politics Past, Politics Present: Some Notes on the Uses of Anthropology in Understanding the New States PART V * The Cerebral Savage: On the Work of Claude Lvi-Strauss * Person, Time, and Conduct in Bali * Deep Play: Notes on the Balinese Cockfight","['Interpretation (philosophy)', 'Epistemology', 'Sociology', 'Philosophy', 'Linguistics']","thick description, interpretive theory, religion, ##hos, world view, sacred symbols, social change, javanese, internal conversion, ideology, integrative revolution, primordial sentiments, civil politics, meaning, anthropology, cerebral savage, deep play"
Paper_01629,Two-Photon Laser Scanning Fluorescence Microscopy,"['Winfried Denk', 'James H. Strickler', 'Watt W. Webb']",1990,Science,Journal,,73-76,248,4951,10.1126/science.2321027,"Molecular excitation by the simultaneous absorption of two photons provides intrinsic three-dimensional resolution in laser scanning fluorescence microscopy. The excitation of fluorophores having single-photon absorption in the ultraviolet with a stream of strongly focused subpicosecond pulses of red laser light has made possible fluorescence images of living cells and other microscopic objects. The fluorescence emission increased quadratically with the excitation intensity so that fluorescence and photobleaching were confined to the vicinity of the focal plane as expected for cooperative two-photon excitation. This technique also provides unprecedented capabilities for three-dimensional, spatially resolved photochemistry, particularly photolytic release of caged effector molecules.","['Photobleaching', 'Two-photon excitation microscopy', 'Fluorescence', 'Microscopy', 'Excitation', 'Absorption (acoustics)', 'Fluorescence microscope', 'Laser', 'Optics', 'Fluorescence in the life sciences', 'Resonance fluorescence', 'Materials science', 'Chemistry', 'Fluorescence recovery after photobleaching', 'Ultraviolet', 'Optoelectronics', 'Physics', 'Quantum mechanics']","molecular excitation, simultaneous absorption, laser scanning fluorescence microscopy, ##picose, ##d pulses, red laser light, fluorescence, living cells, flu, flu, ##ble, ##tic release, cage"
Paper_01631,Enzymatic Amplification of β-Globin Genomic Sequences and Restriction Site Analysis for Diagnosis of Sickle Cell Anemia,"['Randall K. Saiki', 'Stephen J. Scharf', 'Fred Faloona', 'Kary B. Mullis', 'Glenn T. Horn', 'M Kellis', 'Norman Arnheim']",1985,Science,Journal,,1350-1354,230,4732,10.1126/science.2999980,"Two new methods were used to establish a rapid and highly sensitive prenatal diagnostic test for sickle cell anemia. The first involves the primer-mediated enzymatic amplification of specific beta-globin target sequences in genomic DNA, resulting in the exponential increase (220,000 times) of target DNA copies. In the second technique, the presence of the beta A and beta S alleles is determined by restriction endonuclease digestion of an end-labeled oligonucleotide probe hybridized in solution to the amplified beta-globin sequences. The beta-globin genotype can be determined in less than 1 day on samples containing significantly less than 1 microgram of genomic DNA.","['Restriction enzyme', 'Molecular biology', 'genomic DNA', 'Endonuclease', 'Biology', 'Globin', 'Genotype', 'Primer (cosmetics)', 'DNA', 'Multiple displacement amplification', 'Oligonucleotide', 'Gene duplication', 'Polymerase chain reaction', 'Genetics', 'Sickle cell anemia', 'Restriction site', 'Gene', 'Chemistry', 'Cell', 'DNA extraction', 'Organic chemistry']","prenatal diagnostic test, sickle cell anemia, genomic dna, restriction endonuclease digestion"
Paper_01634,Provincializing Europe: Postcolonial Thought and Historical Difference,"['R. Bin Wong', 'Dipesh Chakrabarty']",2001,The American Historical Review,Journal,,1322-1322,106,4,10.2307/2692957,"Acknowlegments ix Introduction: The Idea of Provincializing Europe 3 Part One: Historicism and the Narration of Modernity Chapter 1. Postcoloniality and the Artifice of History 27 Chapter 2. The Two Histories of Capital 47 Chapter 3. Translating Life-Worlds into Labor and History 72 Chapter 4. Minority Histories, Subaltern Pasts 97 Part Two: Histories of Belonging Chapter 5. Domestic Cruelty and the Birth of the Subject 117 Chapter 6. Nation and Imagination 149 Chapter 7. Adda: A History of Sociality 180 Chapter 8. Family, Fraternity, and Salaried labor 214 Epilogue. Reason and the Critique of Historicism 237 Notes 257 Index 299","['Historicism', 'Narrative', 'Cruelty', 'Subject (documents)', 'Modernity', 'History', 'Subaltern', 'Fraternity', 'Capital (architecture)', 'Narrative history', 'Sociality', 'Gender studies', 'Sociology', 'Anthropology', 'Literature', 'Philosophy', 'Art', 'Epistemology', 'Political science', 'Law', 'Criminology', 'Ancient history', 'Theology', 'Politics', 'Library science', 'Computer science', 'Ecology', 'Biology']","##know, historicism, modernity, postcoloniality, capital, minority histories, subaltern pasts, belonging, domestic cruelty, nation, imagination, adda, sociality, salaried labor, reason, historicism, [PAD], [PAD], [PAD], [PAD] [PAD], [PAD]"
Paper_01636,Cognitive radio: making software radios more personal,"['Joseph Mitola', 'Gerald Q. Maguire']",1999,IEEE Personal Communications,Journal,,13-18,6,4,10.1109/98.788210,"Software radios are emerging as platforms for multiband multimode personal communications systems. Radio etiquette is the set of RF bands, air interfaces, protocols, and spatial and temporal patterns that moderate the use of the radio spectrum. Cognitive radio extends the software radio with radio-domain model-based reasoning about such etiquettes. Cognitive radio enhances the flexibility of personal services through a radio knowledge representation language. This language represents knowledge of radio etiquette, devices, software modules, propagation, networks, user needs, and application scenarios in a way that supports automated reasoning about the needs of the user. This empowers software radios to conduct expressive negotiations among peers about the use of radio spectrum across fluents of space, time, and user context. With RKRL, cognitive radio agents may actively manipulate the protocol stack to adapt known etiquettes to better satisfy the user's needs. This transforms radio nodes from blind executors of predefined protocols to radio-domain-aware intelligent agents that search out ways to deliver the services the user wants even if that user does not know how to obtain them. Software radio provides an ideal platform for the realization of cognitive radio.","['Cognitive radio', 'Computer science', 'Software-defined radio', 'Radio-frequency engineering', 'Protocol stack', 'Computer network', 'Remote radio head', 'Telecommunications', 'Wireless', 'Wireless sensor network']","software radios, multi, radio etiquette, rf bands, air interfaces, protocols, temporal patterns, cognitive radio, software radio, cognitive radio, personal services, radio knowledge representation language, software modules, application, software radios, cognitive radio, protocol, blind executors, ##d, software radio, cognitive radio"
Paper_01637,Iterative minimization techniques for<i>ab initio</i>total-energy calculations: molecular dynamics and conjugate gradients,"['M. C. Payne', 'M. P. Teter', 'D. C. Allan', 'T. A. Arias', 'J. D. Joannopoulos']",1992,Reviews of Modern Physics,Journal,,1045-1097,64,4,10.1103/revmodphys.64.1045,"This article describes recent technical developments that have made the total-energy pseudopotential the most powerful ab initio quantum-mechanical modeling method presently available. In addition to presenting technical details of the pseudopotential method, the article aims to heighten awareness of the capabilities of the method in order to stimulate its application to as wide a range of problems in as many scientific disciplines as possible.","['Pseudopotential', 'Physics', 'Ab initio', 'Total energy', 'Statistical physics', 'Range (aeronautics)', 'Conjugate gradient method', 'Quantum', 'Ab initio quantum chemistry methods', 'Energy minimization', 'Minification', 'Theoretical physics', 'Quantum mechanics', 'Computer science', 'Mathematical optimization', 'Algorithm', 'Molecule', 'Aerospace engineering', 'Mathematics', 'Psychology', 'Displacement (psychology)', 'Psychotherapist', 'Engineering']",pseudopotential method
Paper_01638,Orbital angular momentum of light and the transformation of Laguerre-Gaussian laser modes,"['L. Allen', 'Marco W. Beijersbergen', 'R. J. C. Spreeuw', 'J. P. Woerdman']",1992,Physical Review A,Journal,,8185-8189,45,11,10.1103/physreva.45.8185,Laser light with a Laguerre-Gaussian amplitude distribution is found to have a well-defined orbital angular momentum. An astigmatic optical system may be used to transform a high-order Laguerre-Gaussian mode into a high-order Hermite-Gaussian mode reversibly. An experiment is proposed to measure the mechanical torque induced by the transfer of orbital angular momentum associated with such a transformation.,"['Physics', 'Angular momentum', 'Orbital angular momentum of light', 'Angular momentum of light', 'Orbital angular momentum multiplexing', 'Total angular momentum quantum number', 'Laguerre polynomials', 'Angular momentum coupling', 'Gaussian', 'Azimuthal quantum number', 'Hermite polynomials', 'Optics', 'Classical mechanics', 'Quantum mechanics']","laser light, orbital angular momentum, astigmatic optical system, mechanical torque, orbital angular momentum"
Paper_01639,Development of a new resilience scale: The Connor-Davidson Resilience Scale (CD-RISC),"['Kathryn M. Connor', 'Jonathan Davidson']",2003,Depression and Anxiety,Journal,,76-82,18,2,10.1002/da.10113,"Resilience may be viewed as a measure of stress coping ability and, as such, could be an important target of treatment in anxiety, depression, and stress reactions. We describe a new rating scale to assess resilience. The Connor-Davidson Resilience scale (CD-RISC) comprises of 25 items, each rated on a 5-point scale (0–4), with higher scores reflecting greater resilience. The scale was administered to subjects in the following groups: community sample, primary care outpatients, general psychiatric outpatients, clinical trial of generalized anxiety disorder, and two clinical trials of PTSD. The reliability, validity, and factor analytic structure of the scale were evaluated, and reference scores for study samples were calculated. Sensitivity to treatment effects was examined in subjects from the PTSD clinical trials. The scale demonstrated good psychometric properties and factor analysis yielded five factors. A repeated measures ANOVA showed that an increase in CD-RISC score was associated with greater improvement during treatment. Improvement in CD-RISC score was noted in proportion to overall clinical global improvement, with greatest increase noted in subjects with the highest global improvement and deterioration in CD-RISC score in those with minimal or no global improvement. The CD-RISC has sound psychometric properties and distinguishes between those with greater and lesser resilience. The scale demonstrates that resilience is modifiable and can improve with treatment, with greater improvement corresponding to higher levels of global improvement. Depression and Anxiety 18:76–82, 2003. © 2003 Wiley-Liss, Inc.","['Resilience (materials science)', 'Scale (ratio)', 'Psychology', 'Geography', 'Cartography', 'Physics', 'Thermodynamics']","resilience, stress coping ability, stress reactions, rating scale, resilience, community sample, primary care outpatients, general psychiatric outpatients, generalized anxiety disorder, ptsd, factor analytic structure, ptsd, psychometric, factor analysis, resilience, depression"
Paper_01640,<i>The Brain's Default Network</i>,"['Randy L. Buckner', 'Jessica R. Andrews‐Hanna', 'Daniel L. Schacter']",2008,Annals of the New York Academy of Sciences,Journal,,1-38,1124,1,10.1196/annals.1440.011,"Thirty years of brain imaging research has converged to define the brain's default network—a novel and only recently appreciated brain system that participates in internal modes of cognition. Here we synthesize past observations to provide strong evidence that the default network is a specific, anatomically defined brain system preferentially active when individuals are not focused on the external environment. Analysis of connectional anatomy in the monkey supports the presence of an interconnected brain system. Providing insight into function, the default network is active when individuals are engaged in internally focused tasks including autobiographical memory retrieval, envisioning the future, and conceiving the perspectives of others. Probing the functional anatomy of the network in detail reveals that it is best understood as multiple interacting subsystems. The medial temporal lobe subsystem provides information from prior experiences in the form of memories and associations that are the building blocks of mental simulation. The medial prefrontal subsystem facilitates the flexible use of this information during the construction of self‐relevant mental simulations. These two subsystems converge on important nodes of integration including the posterior cingulate cortex. The implications of these functional and anatomical observations are discussed in relation to possible adaptive roles of the default network for using past experiences to plan for the future, navigate social interactions, and maximize the utility of moments when we are not otherwise engaged by the external world. We conclude by discussing the relevance of the default network for understanding mental disorders including autism, schizophrenia, and Alzheimer's disease.","['Default mode network', 'Posterior cingulate', 'Neuroscience', 'Psychology', 'Cognition', 'Cognitive psychology', 'Mentalization', 'Schizophrenia (object-oriented programming)', 'Computer science', 'Prefrontal cortex', 'Functional integration', 'Cognitive science', 'Mathematical analysis', 'Mathematics', 'Psychiatry', 'Integral equation']","brain imaging, default network, connection, autobiographical memory retrieval, functional anatomy, medial temporal lobe sub, mental simulation, medial prefrontal subsystem, posterior cingulate cortex, [PAD]"
Paper_01643,"Development of a DTPA Soil Test for Zinc, Iron, Manganese, and Copper","['W. L. Lindsay', 'W. A. Norvell']",1978,Soil Science Society of America Journal,Journal,,421-428,42,3,10.2136/sssaj1978.03615995004200030009x,"Abstract A DTPA soil test was developed to identify near‐neutral and calcareous soils with insufficient available Zn, Fe, Mn, or Cu for maximum yields of crops. The extractant consists of 0.005 M DTPA (diethylenetriaminepentaacetic acid), 0.1 M triethanolamine, and 0.01 M CaCl 2 , with a pH of 7.3. The soil test consists of shaking 10 g of air‐dry soil with 20 ml of extractant for 2 hours. The leachate is filtered, and Zn, Fe, Mn, and Cu are measured in the filtrate by atomic absorption spectrophotometry. The soil test successfully separated 77 Colorado soils on the basis of crop response to Zn, Fe, and Mn fertilizers. Critical nutrient levels must be determined separately for each crop using standardized procedures for soil preparation, grinding, and extraction. The critical levels for corn using the procedures reported herein were: 0.8 ppm for Zn, 4.5 ppm for Fe, and tentatively 1.0 ppm for Mn, and 0.2 ppm for Cu. Development of the soil test was based, in part, on theoretical considerations. The extractant is buffered at pH 7.30 and contains CaCl 2 so that equilibrium with CaCO 3 is established at a CO 2 level about 10 times that of the atmosphere. Thus, the extractant precludes dissolution of CaCO 3 and the release of occluded nutrients which are normally not available to plants. DTPA was selected as the chelating agent because it can effectively extract all four micronutrient metals. Factors such as pH, concentration of chelating agent, time of shaking, and temperature of extraction affect the amount of micronutrients extracted and were adjusted for maximum overall effectiveness.","['Chemistry', 'Manganese', 'Triethanolamine', 'Zinc', 'Soil water', 'Calcareous', 'Copper', 'Extraction (chemistry)', 'Nutrient', 'Chelation', 'Dissolution', 'Environmental chemistry', 'Soil test', 'Atomic absorption spectroscopy', 'Leachate', 'Nuclear chemistry', 'Inorganic chemistry', 'Chromatography', 'Soil science', 'Environmental science', 'Analytical Chemistry (journal)', 'Geology', 'Paleontology', 'Physics', 'Organic chemistry', 'Physical chemistry', 'Quantum mechanics']","dtpa, calcareous, atomic absorption spectrophotometry, colorado soils, critical nutrient levels, o, ##luded, ##pa, micronutrient metals, micro, ##rien"
Paper_01644,Efficacy of the Theory of Planned Behaviour: A meta‐analytic review,"['Christopher J. Armitage', 'Mark Conner']",2001,British Journal of Social Psychology,Journal,,471-499,40,4,10.1348/014466601164939,"The Theory of Planned Behaviour (TPB) has received considerable attention in the literature. The present study is a quantitative integration and review of that research. From a database of 185 independent studies published up to the end of 1997, the TPB accounted for 27% and 39% of the variance in behaviour and intention, respectively. The perceived behavioural control (PBC) construct accounted for significant amounts of variance in intention and behaviour, independent of theory of reasoned action variables. When behaviour measures were self‐reports, the TPB accounted for 11% more of the variance in behaviour than when behaviour measures were objective or observed ( R 2 s = .31 and .21, respectively). Attitude, subjective norm and PBC account for significantly more of the variance in individuals' desires than intentions or self‐predictions, but intentions and self‐predictions were better predictors of behaviour. The subjective norm construct is generally found to be a weak predictor of intentions. This is partly attributable to a combination of poor measurement and the need for expansion of the normative component. The discussion focuses on ways in which current TPB research can be taken forward in the light of the present review.","['Theory of planned behavior', 'Psychology', 'Normative', 'Theory of reasoned action', 'Variance (accounting)', 'Construct (python library)', 'Social psychology', 'Explained variation', 'Normative social influence', 'Norm (philosophy)', 'Control (management)', 'Statistics', 'Mathematics', 'Philosophy', 'Business', 'Management', 'Law', 'Economics', 'Programming language', 'Accounting', 'Epistemology', 'Computer science', 'Political science']","planned behaviour, ##p, quantitative integration, perceived behavioural control, p, reasoned action variables, attitude, subjective norm, pbc, self ‐, intentions, self ‐ predictions, subjective norm construct, norma, [PAD]"
Paper_01645,"Risk, Uncertainty and Profit",['Frank H. Knight'],1921,['The Quarterly Journal of Economics'],Unknown,,682,36,4,10.2307/1884757,"In Risk, Uncertainty and Profit, Frank Knight explored the riddle of profitability in a competitive market profit should not be possible under competitive conditions, as the entry of new entrepreneurs would drive prices down and nullify margins, however evidence abounds of competitive yet profitable markets. To explain this seeming paradox, Knight uncovers the distinction between calculable risk and essentially unknowable uncertainty. Knight argued that risk stems from repeated events, which therefore allow probabilities to be calculated and factored into decisions, as for instance insurers do. Uncertainty however, stems from events that are unpredictable and as such cannot be prepared against. According to Knight, it is the interplay between risk and uncertainty on the one hand and competition between incumbent and new entrepreneurs that accounts for the enormous variation in profitability across firms and, for the same firms, over time. His insights on the sources of profit have been instrumental in shaping modern economic theory and to the development of a useful understanding of probability. This New Edition has been typeset with modern techniques and contains a newly compiled Index of important topics. It has been painstakingly proofread to ensure that it is free from errors and that the content is faithful to the original.","['Knight', 'Profitability index', 'Profit (economics)', 'Economics', 'Risk–return spectrum', 'Competition (biology)', 'Perfect competition', 'Financial economics', 'Microeconomics', 'Actuarial science', 'Industrial organization', 'Finance', 'Portfolio', 'Ecology', 'Physics', 'Astronomy', 'Biology']","risk, uncertainty, profit, profitability, competitive market, competitive conditions, calculable risk, ##able uncertainty, ##babilities, insurer, uncertainty, profit, economic, probability"
Paper_01646,TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems,"['Martı́n Abadi', 'Ashish Agarwal', 'Paul Barham', 'Eugene Brevdo', 'Zhifeng Chen', 'Craig Citro', 'Gregory S. Corrado', 'Andy Davis', 'Jay B. Dean', 'Matthieu Devin', 'Sanjay Ghemawat', 'Ian Goodfellow', 'Andrew Harp', 'Geoffrey Irving', 'Michael Isard', 'Yangqing Jia', 'Rafał Józefowicz', 'Łukasz Kaiser', 'Manjunath Kudlur', 'Josh Levenberg', 'Dan Mané', 'Rajat Monga', 'Sherry Moore', 'Derek G. Murray', 'Chris Olah', 'Mike Schuster', 'Jonathon Shlens', 'Benoit Steiner', 'Ilya Sutskever', 'Kunal Talwar', 'Paul A. Tucker', 'Vincent Vanhoucke', 'Vijay Vasudevan', 'Fernanda Viégas', 'Oriol Vinyals', 'Pete Warden', 'Martin Wattenberg', 'Martin Wicke', 'Yuan Yu', 'Xiaoqiang Zheng']",2016,arXiv (Cornell University),Unknown,,,,,10.48550/arxiv.1603.04467,"TensorFlow is an interface for expressing machine learning algorithms, and an implementation for executing such algorithms. A computation expressed using TensorFlow can be executed with little or no change on a wide variety of heterogeneous systems, ranging from mobile devices such as phones and tablets up to large-scale distributed systems of hundreds of machines and thousands of computational devices such as GPU cards. The system is flexible and can be used to express a wide variety of algorithms, including training and inference algorithms for deep neural network models, and it has been used for conducting research and for deploying machine learning systems into production across more than a dozen areas of computer science and other fields, including speech recognition, computer vision, robotics, information retrieval, natural language processing, geographic information extraction, and computational drug discovery. This paper describes the TensorFlow interface and an implementation of that interface that we have built at Google. The TensorFlow API and a reference implementation were released as an open-source package under the Apache 2.0 license in November, 2015 and are available at www.tensorflow.org.","['Scale (ratio)', 'Computer science', 'Artificial intelligence', 'Machine learning', 'Distributed computing', 'Geography', 'Cartography']","tensorflow, machine learning algorithms, tensorflow, tablets, gpu cards, training, inference algorithms, deep neural network models, machine, speech recognition, computer vision, robotics, information retrieval, natural language processing, geographic information extraction, computational drug discovery, tensorflow, tensorflow, tensorflow"
Paper_01647,The theory of polymer dynamics,"['Masao Doi', 'S. F. Edwards']",1986,['Current Opinion in Solid State and Materials Science'],Unknown,,812-816,1,6,10.1016/s1359-0286(96)80106-9,Introduction Static properties of polymers Brownian motion Dynamics of flexible polymers in dilute solution Many chain systems Dynamics of a polymer in a fixed network Molecular theory for the viscoelasticity of polymeric liquids Dilute solutions of rigid rodlike polymers Semidilute solutions of rigid rodlike polymers Concentrated solutions of rigid rodlike polymers Index.,"['Polymer', 'Viscoelasticity', 'Brownian dynamics', 'Dynamics (music)', 'Brownian motion', 'Materials science', 'Polymer solution', 'Molecular dynamics', 'Polymer science', 'Chemical physics', 'Polymer chemistry', 'Statistical physics', 'Computational chemistry', 'Chemistry', 'Physics', 'Composite material', 'Quantum mechanics', 'Acoustics']","static properties, polymers brownian motion dynamics, flexible polymers, dilute solution many chain systems dynamics, fixed network, viscoelasticity, polymeric liquids dilute solutions, rigid rodlike polymers semidilute solutions, rigid rodlike polymers, rigid rodlike polymers, [PAD] [PAD] [PAD] [PAD], [PAD], [PAD], [PAD], [PAD]"
Paper_01648,ORB: An efficient alternative to SIFT or SURF,"['Ethan Rublee', 'Vincent Rabaud', 'Kurt Konolige', 'Gary Bradski']",2011,International Conference on Computer Vision,Conference,"2011 IEEE International Conference on Computer Vision (ICCV), Barcelona, Spain",2564-2571,,,10.1109/iccv.2011.6126544,"Feature matching is at the base of many computer vision problems, such as object recognition or structure from motion. Current methods rely on costly descriptors for detection and matching. In this paper, we propose a very fast binary descriptor based on BRIEF, called ORB, which is rotation invariant and resistant to noise. We demonstrate through experiments how ORB is at two orders of magnitude faster than SIFT, while performing as well in many situations. The efficiency is tested on several real-world applications, including object detection and patch-tracking on a smart phone.","['Orb (optics)', 'Scale-invariant feature transform', 'Computer science', 'Artificial intelligence', 'Computer vision', 'Object detection', 'Cognitive neuroscience of visual object recognition', 'Matching (statistics)', 'Feature extraction', 'Rotation (mathematics)', 'Feature (linguistics)', 'Invariant (physics)', 'Feature matching', 'Object (grammar)', 'Pattern recognition (psychology)', 'Image (mathematics)', 'Mathematics', 'Linguistics', 'Statistics', 'Philosophy', 'Mathematical physics']","feature matching, computer vision, object recognition, structure, ##cript, binary descriptor, orb, rotation invariant, orb, ##ft, object detection, smart phone"
Paper_01650,IOP Conference Series: Materials Science and Engineering,['Vikass Monebhurrun'],2022,IOP Conference Series Materials Science and Engineering,Conference,IOP Publishing,011001-011001,1231,1,10.1088/1757-899x/1231/1/011001,"International Nuclear Science, Technology and Engineering Conference 2021 (iNuSTEC2021) “Nuclear Science and Technology for Socio-economic Development” Universiti Teknologi Malaysia (UTM) Skudai, Johor, Malaysia 10-12 October 2021 Editors Nahrul Khair Alang Md Rashid, Universiti Teknologi Malaysia Khaidzir Hamzah, Universiti Teknologi Malaysia Mohsin Mohd Sies, Universiti Teknologi Malaysia Jasman Zainal, Universiti Teknologi Malaysia Muhammad Arif Sazali, Universiti Teknologi Malaysia Muhammad Syahir Sarkawi, Universiti Teknologi Malaysia Nur Syazwani Mohd Ali, Universiti Teknologi Malaysia Khairulnadzmi Jamaluddin, Universiti Teknologi Malaysia Abdul Aziz Mohamed, Malaysian Nuclear Society Faridah Mohamad Idris, Malaysian Nuclear Agency Julie Andrianny Murshidi, Malaysian Nuclear Agency Faizal K P Kunchi Mohamed, Universiti Kebangsaan Malaysia Hassan Mohamed, Universiti Tenaga Nasional Abu Hassan Husin, Universiti Teknologi MARA All papers have been peer-reviewed List of Supporting/Sponsoring Organisations, Preface, Contents, iNuSTEC2021 Organising Committee, Inustec 2021 Awards And Recognition, Acknowledgement and Images are available in this pdf","['Agency (philosophy)', 'Engineering', 'Acknowledgement', 'Library science', 'Political science', 'Management', 'Sociology', 'Social science', 'Computer science', 'Computer security', 'Economics']","inustec20, ##ec"
Paper_01653,Toward a Theory of Stakeholder Identification and Salience: Defining the Principle of who and What Really Counts,"['Ronald K. Mitchell', 'Bradley R. Agle', 'Donna J. Wood']",1997,Academy of Management Review,Journal,,853-886,22,4,10.5465/amr.1997.9711022105,"Stakeholder theory has been a popular heuristic for describing the management environment for years, but it has not attained full theoretical status. Our aim in this article is to contribute to a theory of stakeholder identification and salience based on stakeholders possessing one or more of three relationship attributes: power, legitimacy, and urgency. By combining these attributes, we generate a typology of stakeholders, propositions concerning their salience to managers of the firm, and research and management implications.","['Salience (neuroscience)', 'Identification (biology)', 'Stakeholder', 'Organizational identification', 'Stakeholder theory', 'Organizational behavior', 'Organizational theory', 'Psychology', 'Positive economics', 'Sociology', 'Social psychology', 'Political science', 'Economics', 'Public relations', 'Management', 'Cognitive psychology', 'Organizational commitment', 'Botany', 'Biology']","stakeholder theory, management environment, stakeholder identification, salience, relationship attributes, power, legitimacy, urgency, [PAD], [PAD], [PAD], [PAD]"
Paper_01654,Cellular Solids: Structure and Properties,"['Lorna J. Gibson', 'Michael F. Ashby']",1988,['Materials Science and Engineering: A'],Unknown,,282-283,123,2,10.1016/0921-5093(90)90295-e,"1. Introduction 2. The structure of cellular solids 3. Material properties 4. The mechanics of honeycombs 5. The mechanics of foams: basic results 6. The mechanics of foams refinements 7. Thermal, electrical and acoustic properties of foams 8. Energy absorption in cellular materials 9. The design of sandwich panels with foam cores 10. Wood 11. Cancellous bone 12. Cork 13. Sources, suppliers and property data Appendix: the linear-elasticity of anisotropic cellular solids.","['Cork', 'Materials science', 'Anisotropy', 'Continuum mechanics', 'Composite material', 'Elasticity (physics)', 'Linear elasticity', 'Mechanics', 'Structural engineering', 'Engineering', 'Finite element method', 'Physics', 'Quantum mechanics']","cellular solids, material properties, honeycombs, foams, foam, acoustic properties, foam, energy absorption, cellular materials, sandwich panels, foam cores, cancellous bone, cork, property data, anisotropic cellular solids"
Paper_01656,A Treatise on the Family,['Gary S. Becker'],1981,['Journal of Marriage and the Family'],Unknown,,231,45,1,10.2307/351313,"Preface to the Enlarged Edition Introduction 1. Single-Person Households 2. Division of Labor in Households and Families Supplement: Human Capital, Effort, and the Sexual Division of Labor 3. Polygamy and Monogamy in Marriage Markets 4. Assortative Mating in Marriage Markets 5. The Demand for Children Supplement: A Reformulation of the Economic Theory of Fertility 6. Family Background and the Opportunities of Children 7. Inequality and Intergenerational Mobility Supplement: Human Capital and the Rise and Fall of Families 8. Altruism in the Family 9. Families in Nonhuman Species 10. Imperfect Information, Marriage, and Divorce 11. The Evolution of the Family Supplement: The Family and the State Bibliography Index","['Assortative mating', 'Altruism (biology)', 'Division of labour', 'Human capital', 'Fertility', 'Economics', 'Imperfect', 'Inequality', 'Sociology', 'Labour economics', 'Capital (architecture)', 'Economic growth', 'Population', 'Psychology', 'Demography', 'Social psychology', 'Geography', 'Market economy', 'Linguistics', 'Philosophy', 'Mathematical analysis', 'Mathematics', 'Archaeology']","human capital, effort, sexual division of labor, polygamy, monogamy, marriage markets, assortative mating, marriage markets, economic theory, family background, inequality, intergenerational mobility, human capital, altruism, families, nonhuman species, imperfect information, state bibliography index"
Paper_01657,"Global epidemiology of nonalcoholic fatty liver disease—Meta‐analytic assessment of prevalence, incidence, and outcomes","['Zobair M. Younossi', 'Aaron B. Koenig', 'Dinan Abdelatif', 'Yousef Fazel', 'Linda Henry', 'Mark Wymer']",2015,Hepatology,Journal,,73-84,64,1,10.1002/hep.28431,"Nonalcoholic fatty liver disease (NAFLD) is a major cause of liver disease worldwide. We estimated the global prevalence, incidence, progression, and outcomes of NAFLD and nonalcoholic steatohepatitis (NASH). PubMed/MEDLINE were searched from 1989 to 2015 for terms involving epidemiology and progression of NAFLD. Exclusions included selected groups (studies that exclusively enrolled morbidly obese or diabetics or pediatric) and no data on alcohol consumption or other liver diseases. Incidence of hepatocellular carcinoma (HCC), cirrhosis, overall mortality, and liver-related mortality were determined. NASH required histological diagnosis. All studies were reviewed by three independent investigators. Analysis was stratified by region, diagnostic technique, biopsy indication, and study population. We used random-effects models to provide point estimates (95% confidence interval [CI]) of prevalence, incidence, mortality and incidence rate ratios, and metaregression with subgroup analysis to account for heterogeneity. Of 729 studies, 86 were included with a sample size of 8,515,431 from 22 countries. Global prevalence of NAFLD is 25.24% (95% CI: 22.10-28.65) with highest prevalence in the Middle East and South America and lowest in Africa. Metabolic comorbidities associated with NAFLD included obesity (51.34%; 95% CI: 41.38-61.20), type 2 diabetes (22.51%; 95% CI: 17.92-27.89), hyperlipidemia (69.16%; 95% CI: 49.91-83.46%), hypertension (39.34%; 95% CI: 33.15-45.88), and metabolic syndrome (42.54%; 95% CI: 30.06-56.05). Fibrosis progression proportion, and mean annual rate of progression in NASH were 40.76% (95% CI: 34.69-47.13) and 0.09 (95% CI: 0.06-0.12). HCC incidence among NAFLD patients was 0.44 per 1,000 person-years (range, 0.29-0.66). Liver-specific mortality and overall mortality among NAFLD and NASH were 0.77 per 1,000 (range, 0.33-1.77) and 11.77 per 1,000 person-years (range, 7.10-19.53) and 15.44 per 1,000 (range, 11.72-20.34) and 25.56 per 1,000 person-years (range, 6.29-103.80). Incidence risk ratios for liver-specific and overall mortality for NAFLD were 1.94 (range, 1.28-2.92) and 1.05 (range, 0.70-1.56).As the global epidemic of obesity fuels metabolic conditions, the clinical and economic burden of NAFLD will become enormous. (Hepatology 2016;64:73-84).","['Medicine', 'Internal medicine', 'Nonalcoholic fatty liver disease', 'Metabolic syndrome', 'Epidemiology', 'Gastroenterology', 'Incidence (geometry)', 'Fatty liver', 'Population', 'Cirrhosis', 'Type 2 diabetes', 'Diabetes mellitus', 'Obesity', 'Disease', 'Endocrinology', 'Environmental health', 'Physics', 'Optics']","nonalcoholic fatty liver disease, nafl, liver disease, nafl, nonalcoholic steato, ##pati, alcohol, hepatocellular carcinoma, ci, overall, bio, incidence, subgroup analysis, metabolic comorbidities, na, obesity, hyperlipidemia, hypertension, metabolic syndrome, fibrosis progression proportion, ##c, na"
Paper_01660,"MULTIVARIABLE PROGNOSTIC MODELS: ISSUES IN DEVELOPING MODELS, EVALUATING ASSUMPTIONS AND ADEQUACY, AND MEASURING AND REDUCING ERRORS","['Frank E. Harrell', 'Kerry L. Lee', 'Daniel B. Mark']",1996,Statistics in Medicine,Journal,,361-387,15,4,10.1002/(sici)1097-0258(19960229)15:4<361::aid-sim168>3.0.co;2-4,"Multivariable regression models are powerful tools that are used frequently in studies of clinical outcomes. These models can use a mixture of categorical and continuous variables and can handle partially observed (censored) responses. However, uncritical application of modelling techniques can result in models that poorly fit the dataset at hand, or, even more likely, inaccurately predict outcomes on new subjects. One must know how to measure qualities of a model's fit in order to avoid poorly fitted or overfitted models. Measurement of predictive accuracy can be difficult for survival time data in the presence of censoring. We discuss an easily interpretable index of predictive discrimination as well as methods for assessing calibration of predicted survival probabilities. Both types of predictive accuracy should be unbiasedly validated using bootstrapping or cross-validation, before using predictions in a new data series. We discuss some of the hazards of poorly fitted and overfitted regression models and present one modelling strategy that avoids many of the problems discussed. The methods described are applicable to all regression models, but are particularly needed for binary, ordinal, and time-to-event outcomes. Methods are illustrated with a survival analysis in prostate cancer using Cox regression.","['Computer science', 'Censoring (clinical trials)', 'Categorical variable', 'Predictive modelling', 'Bootstrapping (finance)', 'Regression', 'Proportional hazards model', 'Regression analysis', 'Multivariable calculus', 'Statistics', 'Data mining', 'Machine learning', 'Econometrics', 'Artificial intelligence', 'Mathematics', 'Control engineering', 'Engineering']","multivariable regression models, clinical outcomes, continuous variables, predictive accuracy, survival time data, predictive discrimination, predictive accuracy, survival analysis, prostate cancer, cox regression, [PAD], [PAD] [PAD] [PAD] [PAD] [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD] [PAD], [PAD], [PAD], [PAD] [PAD] [PAD], [PAD]"
Paper_01661,Cross-Validatory Choice and Assessment of Statistical Predictions,['M. Stone'],1974,Journal of the Royal Statistical Society Series B (Statistical Methodology),Journal,,111-133,36,2,10.1111/j.2517-6161.1974.tb00994.x,"Summary A generalized form of the cross-validation criterion is applied to the choice and assessment of prediction using the data-analytic concept of a prescription. The examples used to illustrate the application are drawn from the problem areas of univariate estimation, linear regression and analysis of variance.","['Computer science', 'Econometrics', 'Statistics', 'Mathematics']","univariate estimation, linear regression, analysis of variance, [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD], [PAD], [PAD] [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD], [PAD] [PAD], [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"
Paper_01662,"Climate change 2007 : impacts, adaptation and vulnerability","['Martin L. Parry', 'Osvaldo Canziani', 'J. P. Palutikof', 'Paul van der Linden', 'Clair Hanson']",2007,"['Advances in Global Change Research', 'Climate Change and Developing Countries']",Unknown,,63-95,,,10.1007/0-306-47980-x_4,"Foreword Preface Introduction Summary for policymakers Technical summary 1. Assessment of observed changes and responses in natural and managed systems 2. New assessment methodologies and the characterisation of future conditions 3. Fresh water resources and their management 4. Ecosystems, their properties, goods and services 5. Food, fibre and forest products 6. Coastal systems and low-lying areas 7. Industry, settlement and society 8. Human health 9. Africa 10. Asia 11. Australia and New Zealand 12. Europe 13. Latin America 14. North America 15. Polar regions (Arctic and Antarctic) 16. Small islands 17. Assessment of adaptation practices, options, constraints and capacity 18. Inter-relationships between adaptation and mitigation 19. Assessing key vulnerabilities and the risk from climate change 20. Perspectives on climate change and sustainability - 811 Cross-chapter case studies Appendix I. Glossary Appendix II. Contributors to the IPCC WGII Fourth Assessment Report Appendix III. Reviewers of the IPCC WGII Fourth Assessment Report Appendix IV. Acronyms and abbreviations Appendix V. Index and database of regional content Index CD-ROM.","['Climate change', 'Glossary', 'Geography', 'Sustainability', 'Vulnerability (computing)', 'Environmental resource management', 'Index (typography)', 'Vulnerability assessment', 'Natural resource', 'Environmental planning', 'Adaptation (eye)', 'Climate change adaptation', 'Environmental protection', 'Political science', 'Environmental science', 'Psychological resilience', 'Ecology', 'Psychology', 'Philosophy', 'Linguistics', 'Physics', 'Computer security', 'Optics', 'World Wide Web', 'Computer science', 'Law', 'Psychotherapist', 'Biology']","policy, fresh water resources, human health, europe, latin america, north america, polar regions, small islands, ##tion, climate change, sustainability, acronym, regional content index"
Paper_01665,Inflationary universe: A possible solution to the horizon and flatness problems,['Alan H. Guth'],1981,"Physical review. D. Particles, fields, gravitation, and cosmology/Physical review. D. Particles and fields",Journal,,347-356,23,2,10.1103/physrevd.23.347,"The standard model of hot big-bang cosmology requires initial conditions which are problematic in two ways: (1) The early universe is assumed to be highly homogeneous, in spite of the fact that separated regions were causally disconnected (horizon problem); and (2) the initial value of the Hubble constant must be fine tuned to extraordinary accuracy to produce a universe as flat (i.e., near critical mass density) as the one we see today (flatness problem). These problems would disappear if, in its early history, the universe supercooled to temperatures 28 or more orders of magnitude below the critical temperature for some phase transition. A huge expansion factor would then result from a period of exponential growth, and the entropy of the universe would be multiplied by a huge factor when the latent heat is released. Such a scenario is completely natural in the context of grand unified models of elementary-particle interactions. In such models, the supercooling is also relevant to the problem of monopole suppression. Unfortunately, the scenario seems to lead to some unacceptable consequences, so modifications must be sought.","['Flatness problem', 'Physics', 'Flatness (cosmology)', 'Particle horizon', 'Theoretical physics', 'Metric expansion of space', 'Big Rip', 'Apparent horizon', 'Universe', 'Cosmology', 'Phantom energy', 'Horizon', 'Astrophysics', 'Dark energy', 'Event horizon', 'Astronomy']","horizon, hubble constant, critical mass density, flatness problem, phase, exponential, latent heat, super, ##oling, monopole suppression"
Paper_01666,"Bank Runs, Deposit Insurance, and Liquidity","['Douglas W. Diamond', 'Philip H. Dybvig']",1983,Journal of Political Economy,Journal,,401-419,91,3,10.1086/261155,"This paper shows that bank deposit contracts can provide allocations superior to those of exchange markets, offering an explanation of how banks subject to runs can attract deposits. Investors face privately observed risks which lead to a demand for liquidity. Traditional demand deposit contracts which provide liquidity have multiple equilibria, one of which is a bank run. Bank runs in the model cause real economic damage, rather than simply reflecting other problems. Contracts which can prevent runs are studied, and the analysis shows that there are circumstances when government provision of deposit insurance can produce superior contracts.","['Deposit insurance', 'Market liquidity', 'Bank run', 'Business', 'Demand deposit', 'Monetary economics', 'Government (linguistics)', 'Fixed deposit', 'Financial system', 'Economics', 'Finance', 'Monetary policy', 'Linguistics', 'Philosophy']","bank deposit contracts, exchange markets, ##ity, demand deposit contracts, liquid, bank, government provision, deposit insurance, [PAD] [PAD]"
Paper_01669,Fully optimized contracted Gaussian basis sets for atoms Li to Kr,"['Ansgar Schäfer', 'Hans W. Horn', 'Reinhart Ahlrichs']",1992,The Journal of Chemical Physics,Journal,,2571-2577,97,4,10.1063/1.463096,"Various contracted Gaussian basis sets for atoms up to Kr are presented which have been determined by optimizing atomic self-consistent field ground state energies with respect to all basis set parameters, i.e., orbital exponents and contraction coefficients.","['STO-nG basis sets', 'Basis (linear algebra)', 'Gaussian', 'Basis set', 'Ground state', 'Atomic physics', 'State (computer science)', 'Physics', 'Mathematics', 'Statistical physics', 'Quantum mechanics', 'Geometry', 'Algorithm', 'Molecule', 'Linear combination of atomic orbitals']","contracted gaussian basis sets, basis set parameters, orbital exponents, contraction coefficients, [PAD], [PAD], [PAD], [PAD] [PAD], [PAD], [PAD] [PAD] [PAD] [PAD], [PAD], [PAD]"
Paper_01670,A Neural Substrate of Prediction and Reward,"['Wolfram Schultz', 'Peter Dayan', 'P. Read Montague']",1997,Science,Journal,,1593-1599,275,5306,10.1126/science.275.5306.1593,"The capacity to predict future events permits a creature to detect, model, and manipulate the causal structure of its interactions with its environment. Behavioral experiments suggest that learning is driven by changes in the expectations about future salient events such as rewards and punishments. Physiological work has recently complemented these studies by identifying dopaminergic neurons in the primate whose fluctuating output apparently signals changes or errors in the predictions of future salient and rewarding events. Taken together, these findings can be understood through quantitative theories of adaptive optimizing control.","['Salient', 'Neuroscience', 'Neural substrate', 'Dopaminergic', 'Cognitive psychology', 'Psychology', 'Computer science', 'Artificial intelligence', 'Cognitive science', 'Cognition', 'Dopamine']","causal structure, behavioral experiments, learning, dopamine, ##ic neurons, adaptive optimizing control"
Paper_01671,The Sloan Digital Sky Survey: Technical Summary,"['Donald G. York', 'Jennifer Adelman', 'John E. Anderson', 'Scott F. Anderson', 'James Annis', 'Neta A. Bahcall', 'Jon Arne Bakken', 'Robert H. Barkhouser', 'Steven Bastian', 'Eileen Berman', 'William N. Boroski', 'S. Bracker', 'Charlie Briegel', 'John W. Briggs', 'J. Brinkmann', 'Róbert Brunner', 'Scott Burles', 'Larry Carey', 'Michael A. Carr', 'F. J. Castander', 'Bing Chen', 'P. Colestock', 'Andrew J. Connolly', 'James H. Crocker', 'István Csabai', 'Paul C. Czarapata', 'John E. Davis', 'Mamoru Doi', 'T. Dombeck', 'Daniel J. Eisenstein', 'N. Ellman', 'Brian Elms', 'Michael L. Evans', 'Xiaohui Fan', 'Glenn R. Federwitz', 'Larry Fiscelli', 'S. D. Friedman', 'Joshua A. Frieman', 'M. Fukugita', 'Bruce Gillespie', 'James E. Gunn', 'Vijay K. Gurbani', 'E. de Haas', 'M. Haldeman', 'Frederick H. Harris', 'J. J. E. Hayes', 'Timothy M. Heckman', 'G. S. Hennessy', 'Robert B. Hindsley', 'S. Holm', 'D. Holmgren', 'Chi-hao Huang', 'Charles L. H. Hull', 'D. Husby', 'Shin-ichi Ichikawa', 'Takashi Ichikawa', 'Željko Ivezić', 'S. Kent', 'Rita S. J. Kim', 'E. Kinney', 'Mark A. Klaene', 'A. Nitta Kleinman', 'S. J. Kleinman', 'G. R. Knapp', 'J. Korienek', 'Richard G. Kron', 'Peter Kunszt', 'D. Q. Lamb', 'B. Lee', 'R. French Leger', 'Siriluk Limmongkol', 'C. Lindenmeyer', 'Daniel C. Long', 'Craig Loomis', 'J. Loveday', 'Rich Lucinio', 'Robert H. Lupton', 'B. MacKinnon', 'Edward J. Mannery', 'P. Mantsch', 'B. Margon', 'P. McGehee', 'Timothy A. McKay', 'Avery Meiksin', 'Aronne Merelli', 'D. G. Monet', 'Jeffrey A. Munn', 'Vijay K. Narayanan', 'Thomas Nash', 'Eric H. Neilsen', 'R. Neswold', 'Heidi Jo Newberg', 'R. C. Nichol', 'Tom Nicinski', 'M. Nonino', 'Norio Okada', 'Sadanori Okamura', 'Jeremiah P. Ostriker', 'Russell Owen', 'A. George Pauls']",2000,The Astronomical Journal,Journal,,1579-1587,120,3,10.1086/301513,"The Sloan Digital Sky Survey (SDSS) will provide the data to support detailed investigations of the distribution of luminous and nonluminous matter in the universe: a photometrically and astrometrically calibrated digital imaging survey of π sr above about Galactic latitude 30° in five broad optical bands to a depth of g' ∼ 23 mag, and a spectroscopic survey of the approximately 106 brightest galaxies and 105 brightest quasars found in the photometric object catalog produced by the imaging survey. This paper summarizes the observational parameters and data products of the SDSS and serves as an introduction to extensive technical on-line documentation.","['Sky', 'Galaxy', 'Astronomy', 'Quasar', 'Physics', 'Astrophysics', 'Active galactic nucleus', 'Documentation', 'Remote sensing', 'Geography', 'Computer science', 'Programming language']","sloan digital sky survey, sd, nonluminous matter, digital imaging survey, galactic latitude, spectro, brightest quasars, photometric object catalog"
Paper_01673,<i>Atmospheric Chemistry and Physics: From Air Pollution to Climate Change</i>,"['John H. Seinfeld', 'Spyros Ν. Pandis', 'K. Noone']",1998,Physics Today,Journal,,88-90,51,10,10.1063/1.882420,1 The Atmosphere. 2 Atmospheric Trace Constituents. 3 Chemical Kinetics. 4 Atmospheric Radiation and Photochemistry. 5 Chemistry of the Stratosphere. 6 Chemistry of the Troposphere. 7 Chemistry of the Atmospheric Aqueous Phase. 8 Properties of the Atmospheric Aerosol. 9 Dynamics of Single Aerosol Particles. 10 Thermodynamics of Aerosols. 11 Nucleation. 12 Mass Transfer Aspects of Atmospheric Chemistry. 13 Dynamics of Aerosol Populations. 14 Organic Atmospheric Aerosols. 15 Interaction of Aerosols with Radiation. 16 Meteorology of the Local Scale. 17 Cloud Physics. 18 Atmospheric Diffusion. 19 Dry Deposition. 20 Wet Deposition. 21 General Circulation of the Atmosphere. 22 Global Cycles: Sulfur and Carbon. 23 Climate and Chemical Composition of the Atmosphere. 24 Aerosols and Climate. 25 Atmospheric Chemical Transport Models. 26 Statistical Models.,"['Atmospheric chemistry', 'Atmospheric sciences', 'Environmental science', 'Climate change', 'Air pollution', 'Atmospheric pollution', 'Atmospheric physics', 'Pollution', 'Meteorology', 'Environmental chemistry', 'Physics', 'Astrobiology', 'Chemistry', 'Atmosphere (unit)', 'Oceanography', 'Ozone', 'Geology', 'Ecology', 'Organic chemistry', 'Biology']","atmosphere, atmospheric trace constituents, chemical kinetics, atmospheric radiation, photochemistry, stratosphere, troposphere, atmospheric aqueous phase, atmospheric aerosol, thermodyna, nucleation, mass transfer aspects, atmospheric chemistry, aerosol populations, organic atmospheric aerosols, meteor, cloud physics, atmospheric diffusion, dry deposition, wet deposition, general circulation, global cycles, sulfur, carbon, chemical composition, aerosol, atmospheric chemical transport models, statistical models"
Paper_01675,Deciding on the Number of Classes in Latent Class Analysis and Growth Mixture Modeling: A Monte Carlo Simulation Study,"['Karen Nylund‐Gibson', 'Tihomir Asparouhov', 'Bengt Muthén']",2007,Structural Equation Modeling A Multidisciplinary Journal,Journal,,535-569,14,4,10.1080/10705510701575396,"Abstract Mixture modeling is a widely applied data analysis technique used to identify unobserved heterogeneity in a population. Despite mixture models' usefulness in practice, one unresolved issue in the application of mixture models is that there is not one commonly accepted statistical indicator for deciding on the number of classes in a study population. This article presents the results of a simulation study that examines the performance of likelihood-based tests and the traditionally used Information Criterion (ICs) used for determining the number of classes in mixture modeling. We look at the performance of these tests and indexes for 3 types of mixture models: latent class analysis (LCA), a factor mixture model (FMA), and a growth mixture models (GMM). We evaluate the ability of the tests and indexes to correctly identify the number of classes at three different sample sizes (n = 200, 500, 1,000). Whereas the Bayesian Information Criterion performed the best of the ICs, the bootstrap likelihood ratio test proved to be a very consistent indicator of classes across all of the models considered. ACKNOWLEDGMENTS Karen L. Nylund's research was supported by Grant R01 DA11796 from the National Institute on Drug Abuse (NIDA) and Bengt O. Muthén's research was supported by Grant K02 AA 00230 from the National Institute on Alcohol Abuse and Alcoholism (NIAAA). We thank Mplus for software support, Jacob Cheadle for programming expertise, and Katherine Masyn for helpful comments. Notes 1In general, the within-class covariance structure can be freed to allow within-class item covariance. a Item probabilities for categorical LCA models are specified by the probability in each cell, and the class means for the continuous LCA are specified by the value in parentheses. 2The number random starts for LCA models with categorical outcomes was specified to be ""starts = 70 7;"" in Mplus. The models with continuous outcomes had differing numbers of random starts. 3It is important to note that when coverage is studied, the random starts option of Mplus should not be used. If it is used, label switching may occur, in that a class for one replication might be represented by another class for another replication, therefore distorting the estimate. 4The models that presented convergence problems were those that were badly misspecified. For example, for the GMM (true k = 3 class model) for n = 500, the convergence rates for the three-, four-, and five-class models were 100%, 87%, and 68%, respectively.","['Mixture model', 'Latent class model', 'Statistics', 'Covariance', 'Econometrics', 'Class (philosophy)', 'Bayesian probability', 'Sample size determination', 'Information Criteria', 'Population', 'Bayesian information criterion', 'Statistical model', 'Structural equation modeling', 'Mathematics', 'Computer science', 'Psychology', 'Artificial intelligence', 'Model selection', 'Demography', 'Sociology']","abstract mixture modeling, data analysis, unobserved heterogeneity, mixture modeling, latent class analysis, factor mixture model, growth mixture models, gm, bayesian information criterion, bootstrap likelihood ratio test, alcohol abuse, ##lus, item probabilities, categorical lca, categorical, mplus, random, random starts, label switching, convergence"
Paper_01676,First principles phonon calculations in materials science,"['Atsushi Togo', 'Isao Tanaka']",2015,Scripta Materialia,Journal,,1-5,108,,10.1016/j.scriptamat.2015.07.021,"Phonon plays essential roles in dynamical behaviors and thermal properties, which are central topics in fundamental issues of materials science. The importance of first principles phonon calculations cannot be overly emphasized. Phonopy is an open source code for such calculations launched by the present authors, which has been world-widely used. Here we demonstrate phonon properties with fundamental equations and show examples how the phonon calculations are applied in materials science.","['Phonon', 'Materials science', 'Thermal', 'Condensed matter physics', 'Statistical physics', 'Engineering physics', 'Physics', 'Thermodynamics']","phonon, dynamical behaviors, thermal properties, materials science, phonon calculations, phonopy, phonon properties, fundamental equations, phonon calculations, materials science, [PAD], [PAD] [PAD], [PAD] [PAD], [PAD], [PAD] [PAD] [PAD] [PAD], [PAD] [PAD], [PAD], [PAD] [PAD], [PAD] [PAD], [PAD], [PAD], [PAD] [PAD] [PAD] [PAD], [PAD], [PAD] [PAD], [PAD], [PAD], [PAD], [PAD], [PAD] [PAD] [PAD] [PAD], [PAD] [PAD], [PAD] [PAD], [PAD] [PAD], [PAD], [PAD] [PAD] [PAD], [PAD] [PAD] [PAD]"
Paper_01679,Measuring Economic Policy Uncertainty*,"['Scott Baker', 'Nicholas Bloom', 'Steven J. Davis']",2016,The Quarterly Journal of Economics,Journal,,1593-1636,131,4,10.1093/qje/qjw024,"Abstract We develop a new index of economic policy uncertainty (EPU) based on newspaper coverage frequency. Several types of evidence—including human readings of 12,000 newspaper articles—indicate that our index proxies for movements in policy-related economic uncertainty. Our U.S. index spikes near tight presidential elections, Gulf Wars I and II, the 9/11 attacks, the failure of Lehman Brothers, the 2011 debt ceiling dispute, and other major battles over fiscal policy. Using firm-level data, we find that policy uncertainty is associated with greater stock price volatility and reduced investment and employment in policy-sensitive sectors like defense, health care, finance, and infrastructure construction. At the macro level, innovations in policy uncertainty foreshadow declines in investment, output, and employment in the United States and, in a panel vector autoregressive setting, for 12 major economies. Extending our U.S. index back to 1900, EPU rose dramatically in the 1930s (from late 1931) and has drifted upward since the 1960s.","['Economics', 'Newspaper', 'Volatility (finance)', 'Index (typography)', 'Fiscal policy', 'Presidential system', 'Monetary policy', 'Debt', 'Macroeconomics', 'Economic policy', 'Monetary economics', 'Finance', 'Business', 'Political science', 'Politics', 'World Wide Web', 'Advertising', 'Computer science', 'Law']","economic policy uncertainty, epu, newspaper coverage frequency, lehman, debt ceiling dispute, policy uncertainty, stock price volatility, health, finance, infrastructure construction, policy uncertainty"
Paper_01681,A PUBLIC MANAGEMENT FOR ALL SEASONS?,['Christopher Hood'],1991,Public Administration,Journal,,3-19,69,1,10.1111/j.1467-9299.1991.tb00779.x,"This article discusses: the doctrinal content of the group of ideas known as ‘new public management’(NPM); the intellectual provenance of those ideas; explanations for their apparent persuasiveness in the 1980 s; and criticisms which have been made of the new doctrines. Particular attention is paid to the claim that NPM offers an all‐purpose key to better provision of public services. This article argues that NFM has been most commonly criticized in terms of a claimed contradiction between ‘equity’ and ‘efficiency’ values, but that any critique which is to survive NPM's claim to ‘infinite reprogrammability’ must be couched in terms of possible conflicts between administrative values. The conclusion is that the ESRC'S Management in Government’ research initiative has been more valuable in helping to identify rather than to definitively answer, the key conceptual questions raised by NPM.","['Contradiction', 'Equity (law)', 'New public management', 'Key (lock)', 'Government (linguistics)', 'Sociology', 'Positive economics', 'Public management', 'Political science', 'Public administration', 'Law and economics', 'Epistemology', 'Economics', 'Law', 'Public sector', 'Philosophy', 'Linguistics', 'Ecology', 'Biology']","doctrinal content, public management ’, np, intellectual proven, npm, public services, nfm, ‘, efficiency, infinite reprogrammability ’, administrative values, es"
Paper_01682,A Survey of Augmented Reality,['Ronald Azuma'],1997,PRESENCE Virtual and Augmented Reality,Journal,,355-385,6,4,10.1162/pres.1997.6.4.355,"This paper surveys the field of augmented reality (AR), in which 3D virtual objects are integrated into a 3D real environment in real time. It describes the medical, manufacturing, visualization, path planning, entertainment, and military applications that have been explored. This paper describes the characteristics of augmented reality systems, including a detailed discussion of the tradeoffs between optical and video blending approaches. Registration and sensing errors are two of the biggest problems in building effective augmented reality systems, so this paper summarizes current efforts to overcome these problems. Future directions and areas requiring further research are discussed. This survey provides a starting point for anyone interested in researching or using augmented reality.","['Augmented reality', 'Entertainment', 'Virtual reality', 'Computer science', 'Human–computer interaction', 'Computer-mediated reality', 'Visualization', 'Point (geometry)', 'Mixed reality', 'Field (mathematics)', 'Data science', 'Artificial intelligence', 'Art', 'Geometry', 'Mathematics', 'Pure mathematics', 'Visual arts']","augmented reality, ar, 3d virtual objects, 3d real environment, visualization, path planning, entertainment, military, augmented, video blending, registration, sensing errors, augmented reality, augmented reality"
Paper_01683,The Social System,['Talcott Parsons'],1951,"['Law, State and Telecommunications Review']",Unknown,,99-116,15,2,10.26512/lstr.v15i2.44770,"In the history of sociological theory, Talcott Parsons holds a very special place. His The Structure of Social Action (1937), was a pioneer work that has influenced many social scientists. The present work, The Social System, presents a major scientific and intellectual advance towards the theory of action first outlined in his earlier work.","['Action theory (sociology)', 'Action (physics)', 'Sociology', 'Epistemology', 'Social system', 'Work (physics)', 'Sociological theory', 'Social theory', 'Social science', 'Engineering', 'Philosophy', 'Mechanical engineering', 'Physics', 'Quantum mechanics']","sociological theory, social action, social, social system"
Paper_01686,Mass Spectrometric Sequencing of Proteins from Silver-Stained Polyacrylamide Gels,"['Andrej Shevchenko', 'Matthias Wilm', 'Ole Vorm', 'Matthias Mann']",1996,Analytical Chemistry,Journal,,850-858,68,5,10.1021/ac950914h,"Proteins from silver-stained gels can be digested enzymatically and the resulting peptides analyzed and sequenced by mass spectrometry. Standard proteins yield the same peptide maps when extracted from Coomassie- and silver-stained gels, as judged by electrospray and MALDI mass spectrometry. The low nanogram range can be reached by the protocols described here, and the method is robust. A silver-stained one-dimensional gel of a fraction from yeast proteins was analyzed by nanoelectrospray tandem mass spectrometry. In the sequencing, more than 1000 amino acids were covered, resulting in no evidence of chemical modifications due to the silver staining procedure. Silver staining allows a substantial shortening of sample preparation time and may, therefore, be preferable over Coomassie staining. This work removes a major obstacle to the low-level sequence analysis of proteins separated on polyacrylamide gels.","['Chemistry', 'Chromatography', 'Silver stain', 'Mass spectrometry', 'Coomassie Brilliant Blue', 'Staining', 'Protein mass spectrometry', 'Tandem mass spectrometry', 'Polyacrylamide', 'Polyacrylamide gel electrophoresis', 'Peptide', 'Proteomics', 'Biochemistry', 'Molecular biology', 'Enzyme', 'Medicine', 'Pathology', 'Gene', 'Polymer chemistry', 'Biology']","mass spectrometry, ##di mass spectrometry, yeast proteins, silver, silver, coomassie staining"
Paper_01687,Economic Growth in a Cross Section of Countries,['Robert J. Barro'],1989,Unknown,Unknown,,,,,10.3386/w3120,"In neoclassical growth models with diminishing returns to capital, a country's per capita growth rate tends to be inversely related to its initial level of income per person.This convergence hypothesis seems to be inconsistent with the cross-country evidence, which indicates that per capita growth rates for about 100 countries in the post-World War II period are uncorrelated with the starting level of per capita product.However, if one holds constant measures of initial human capital-measured by primary and secondary school-enrollment rates-there is evidence that countries with lower per capita product tend to grow faster.Countries with higher human capital also have lower fertility rates and higher ratios of physical investment to GDP.These results on growth, fertility, and investment are consistent with some recent theories of endogenous economic growth.With regard to government, the cross-country data indicate that government consumption is inversely related to growth, whereas public investment has little relation with growth.Average growth rates are positively related to political stability, which may capture the benefits of secure property rights.There is also some indication that distortions of investment-goods prices are adverse for growth.Finally, the analysis leaves unexplained a good deal of the relatively weak growth performances of countries in sub-Saharan Africa and Latin America.","['Economics', 'Section (typography)', 'Cross section (physics)', 'Macroeconomics', 'Classical economics', 'Keynesian economics', 'Business', 'Physics', 'Advertising', 'Quantum mechanics']","neoclassical growth models, capita growth rate, initial human capital, endogenous economic growth, government, government consumption, public investment, political stability, secure property rights, latin america"
Paper_01688,We have never been modern,['Bruno Latour'],1994,Choice Reviews Online,Journal,,31-4888,31,09,10.5860/choice.31-4888,"What makes us modern? This is a classic question in philosophy as well as in political science. However it is often raised without including science and technology in its definition. The argument of this book is that we are modern as long as we split our political process in two - between politics proper, and science and technology. This division allows the formidable expansion of the Western empires. However it has become more and more difficult to maintain this distance between science and politics. Hence the postmodern predicament - the feeling that the modern stance is no longer acceptable but that there is no alternative. The solution, advances one of France's leading sociologists of science, is to realize that we have never been modern to begin with. The comparative anthropology this text provides reintroduces science to the fabric of daily life and aims to make us compatible both with our past and with other cultures wrongly called pre-modern.",['History'],"philosophy, political science, ##modern, comparative anthropology, daily life"
Paper_01689,<i>SIR</i>97: a new tool for crystal structure determination and refinement,"['Angela Altomare', 'M. C. Burla', 'Mercedes Camalli', 'G. Cascarano', 'Carmelo Giacovazzo', 'Antonietta Guagliardi', 'Anna Moliterni', 'G. Polidori', 'R. Spagna']",1999,Journal of Applied Crystallography,Journal,,115-119,32,1,10.1107/s0021889898007717,"SIR 97 is the integration of two programs, SIR 92 and CAOS , the first devoted to the solution of crystal structures by direct methods, the second to refinement via least-squares–Fourier procedures. Several new features have been introduced in SIR 97 with respect to the previous version, SIR 92: greater automatization, increased efficiency of the direct methods section, and a powerful graphics interface. The program also provides publication tables and CIF files.","['Section (typography)', 'Computer science', 'Graphics', 'Direct methods', 'Interface (matter)', 'Computational science', 'Fourier transform', 'Crystal (programming language)', 'Algorithm', 'Crystallography', 'Computer graphics (images)', 'Chemistry', 'Mathematics', 'Programming language', 'Parallel computing', 'Mathematical analysis', 'Operating system', 'Bubble', 'Maximum bubble pressure method']","sir 97, sir 92, caos, crystal structures, direct methods, sir 97, automatization, direct methods, graphics interface, publication tables, cif files, [PAD], [PAD], [PAD]"
Paper_01692,A Stochastic Approximation Method,"['Herbert Robbins', 'Sutton Monro']",1951,The Annals of Mathematical Statistics,Journal,,400-407,22,3,10.1214/aoms/1177729586,"Let $M(x)$ denote the expected value at level $x$ of the response to a certain experiment. $M(x)$ is assumed to be a monotone function of $x$ but is unknown to the experimenter, and it is desired to find the solution $x = \theta$ of the equation $M(x) = \alpha$, where $\alpha$ is a given constant. We give a method for making successive experiments at levels $x_1,x_2,\cdots$ in such a way that $x_n$ will tend to $\theta$ in probability.","['Mathematics', 'Monotone polygon', 'Constant (computer programming)', 'Alpha (finance)', 'Function (biology)', 'Expected value', 'Value (mathematics)', 'Combinatorics', 'Applied mathematics', 'Statistics', 'Geometry', 'Computer science', 'Construct validity', 'Evolutionary biology', 'Biology', 'Programming language', 'Psychometrics']","monotone function, [PAD] [PAD], [PAD]"
Paper_01694,Stellar population synthesis at the resolution of 2003,"['Gustavo Bruzual', 'S. Charlot']",2003,Monthly Notices of the Royal Astronomical Society,Journal,,1000-1028,344,4,10.1046/j.1365-8711.2003.06897.x,"We present a new model for computing the spectral evolution of stellar populations at ages between 100,000 yr and 20 Gyr at a resolution of 3 A across the whole wavelength range from 3200 to 9500 A for a wide range of metallicities. These predictions are based on a newly available library of observed stellar spectra. We also compute the spectral evolution across a larger wavelength range, from 91 A to 160 micron, at lower resolution. The model incorporates recent progress in stellar evolution theory and an observationally motivated prescription for thermally-pulsing stars on the asymptotic giant branch. The latter is supported by observations of surface brightness fluctuations in nearby stellar populations. We show that this model reproduces well the observed optical and near-infrared colour-magnitude diagrams of Galactic star clusters of various ages and metallicities. Stochastic fluctuations in the numbers of stars in different evolutionary phases can account for the full range of observed integrated colours of star clusters in the Magellanic Clouds. The model reproduces in detail typical galaxy spectra from the Early Data Release (EDR) of the Sloan Digital Sky Survey (SDSS). We exemplify how this type of spectral fit can constrain physical parameters such as the star formation history, metallicity and dust content of galaxies. Our model is the first to enable accurate studies of absorption-line strengths in galaxies containing stars over the full range of ages. Using the highest-quality spectra of the SDSS EDR, we show that this model can reproduce simultaneously the observed strengths of those Lick indices that do not depend strongly on element abundance ratios [abridged].","['Physics', 'Astrophysics', 'Galaxy', 'Star formation', 'Stellar population', 'Metallicity', 'Stars', 'Astronomy', 'Asymptotic giant branch', 'Surface brightness fluctuation', 'Spectral line', 'Star cluster', 'Stellar evolution', 'Galaxy merger']","spectral evolution, stellar populations, stellar spectra, spectral evolution, stellar evolution theory, asymptotic giant, surface brightness fluctuations, stochastic fluctuations, ##llan, sloan digital sky survey, star formation history, metallic, dust content, element abundance ratios"
Paper_01695,Inference and missing data,['Donald B. Rubin'],1976,Biometrika,Journal,,581-592,63,3,10.1093/biomet/63.3.581,"When making sampling distribution inferences about the parameter of the data, θ, it is appropriate to ignore the process that causes missing data if the missing data are 'missing at random' and the observed data are 'observed at random', but these inferences are generally conditional on the observed pattern of missing data. When making direct-likelihood or Bayesian inferences about θ, it is appropriate to ignore the process that causes missing data if the missing data are missing at random and the parameter of the missing data process is 'distinct' from θ. These conditions are the weakest general conditions under which ignoring the process that causes missing data always leads to correct inferences.","['Missing data', 'Imputation (statistics)', 'Inference', 'Mathematics', 'Statistics', 'Conditional probability distribution', 'Process (computing)', 'Data mining', 'Bayesian probability', 'Econometrics', 'Computer science', 'Artificial intelligence', 'Operating system']","sampling distribution inferences, bay"
Paper_01697,Graph-Based Algorithms for Boolean Function Manipulation,['Bryant'],1986,IEEE Transactions on Computers,Journal,,677-691,C-35,8,10.1109/tc.1986.1676819,"In this paper we present a new data structure for representing Boolean functions and an associated set of manipulation algorithms. Functions are represented by directed, acyclic graphs in a manner similar to the representations introduced by Lee [1] and Akers [2], but with further restrictions on the ordering of decision variables in the graph. Although a function requires, in the worst case, a graph of size exponential in the number of arguments, many of the functions encountered in typical applications have a more reasonable representation. Our algorithms have time complexity proportional to the sizes of the graphs being operated on, and hence are quite efficient as long as the graphs do not grow too large. We present experimental results from applying these algorithms to problems in logic design verification that demonstrate the practicality of our approach.","['Boolean function', 'Computer science', 'And-inverter graph', 'Algorithm', 'Exponential function', 'Graph', 'Theoretical computer science', 'Boolean circuit', 'Mathematics', 'Mathematical analysis']","data structure, boolean functions, manipulation algorithms, ##yclic, decision variables, time complexity, logic design verification"
Paper_01699,"Organizational Information Requirements, Media Richness and Structural Design","['Richard L. Daft', 'Robert H. Lengel']",1986,Management Science,Journal,,554-571,32,5,10.1287/mnsc.32.5.554,"This paper answers the question, “Why do organizations process information?” Uncertainty and equivocality are defined as two forces that influence information processing in organizations. Organization structure and internal systems determine both the amount and richness of information provided to managers. Models are proposed that show how organizations can be designed to meet the information needs of technology, interdepartmental relations, and the environment. One implication for managers is that a major problem is lack of clarity, not lack of data. The models indicate how organizations can be designed to provide information mechanisms to both reduce uncertainty and resolve equivocality.","['CLARITY', 'Knowledge management', 'Process (computing)', 'Computer science', 'Organizational structure', 'Information system', 'Information technology', 'Information structure', 'Information processing', 'Business', 'Process management', 'Management', 'Engineering', 'Psychology', 'Economics', 'Biochemistry', 'Chemistry', 'Linguistics', 'Philosophy', 'Neuroscience', 'Electrical engineering', 'Operating system']","organizations, uncertainty, equivocality, information processing, organization structure, internal systems, information, interdepartmental relations, information, equivocality, [PAD] [PAD] [PAD] [PAD] [PAD]"
Paper_01700,Authoritative sources in a hyperlinked environment,['Jon Kleinberg'],1999,Journal of the ACM,Journal,,604-632,46,5,10.1145/324133.324140,"The network structure of a hyperlinked environment can be a rich source of information about the content of the environment, provided we have effective means for understanding it. We develop a set of algorithmic tools for extracting information from the link structures of such environments, and report on experiments that demonstrate their effectiveness in a variety of context on the World Wide Web. The central issue we address within our framework is the distillation of broad search topics, through the discovery of “authorative” information sources on such topics. We propose and test an algorithmic formulation of the notion of authority, based on the relationship between a set of relevant authoritative pages and the set of “hub pages” that join them together in the link structure. Our formulation has connections to the eigenvectors of certain matrices associated with the link graph; these connections in turn motivate additional heuristrics for link-based analysis.","['Computer science', 'Set (abstract data type)', 'Variety (cybernetics)', 'Link (geometry)', 'Information retrieval', 'Link analysis', 'Context (archaeology)', 'Theoretical computer science', 'Graph', 'World Wide Web', 'Computer network', 'Artificial intelligence', 'Programming language', 'Paleontology', 'Biology']","network structure, hyperlinked environment, algorithmic, link structures, world, algorithm, authority, authoritative pages, hub pages, link, eigenve, link graph"
Paper_01702,ff14SB: Improving the Accuracy of Protein Side Chain and Backbone Parameters from ff99SB,"['James Maier', 'Carmenza Martinez', 'Koushik Kasavajhala', 'Lauren Wickstrom', 'Kevin Hauser', 'Carlos Simmerling']",2015,Journal of Chemical Theory and Computation,Journal,,3696-3713,11,8,10.1021/acs.jctc.5b00255,"Molecular mechanics is powerful for its speed in atomistic simulations, but an accurate force field is required. The Amber ff99SB force field improved protein secondary structure balance and dynamics from earlier force fields like ff99, but weaknesses in side chain rotamer and backbone secondary structure preferences have been identified. Here, we performed a complete refit of all amino acid side chain dihedral parameters, which had been carried over from ff94. The training set of conformations included multidimensional dihedral scans designed to improve transferability of the parameters. Improvement in all amino acids was obtained as compared to ff99SB. Parameters were also generated for alternate protonation states of ionizable side chains. Average errors in relative energies of pairs of conformations were under 1.0 kcal/mol as compared to QM, reduced 35% from ff99SB. We also took the opportunity to make empirical adjustments to the protein backbone dihedral parameters as compared to ff99SB. Multiple small adjustments of φ and ψ parameters were tested against NMR scalar coupling data and secondary structure content for short peptides. The best results were obtained from a physically motivated adjustment to the φ rotational profile that compensates for lack of ff99SB QM training data in the β-ppII transition region. Together, these backbone and side chain modifications (hereafter called ff14SB) not only better reproduced their benchmarks, but also improved secondary structure content in small peptides and reproduction of NMR χ1 scalar coupling measurements for proteins in solution. We also discuss the Amber ff12SB parameter set, a preliminary version of ff14SB that includes most of its improvements.","['Dihedral angle', 'Side chain', 'Force field (fiction)', 'Protonation', 'Chemistry', 'Molecular dynamics', 'Conformational isomerism', 'Protein secondary structure', 'Scalar (mathematics)', 'Computational chemistry', 'Transferability', 'Chemical physics', 'Crystallography', 'Biological system', 'Molecule', 'Computer science', 'Mathematics', 'Hydrogen bond', 'Artificial intelligence', 'Machine learning', 'Organic chemistry', 'Logit', 'Biology', 'Polymer', 'Ion', 'Biochemistry', 'Geometry']","molecular mechanics, atomistic simulations, force field, protein secondary structure balance, side chain rotamer, backbone secondary structure preferences, amino, multidimensional dihedral scans, ##ation states, protein backbone dihedral parameters, secondary structure, φ"
Paper_01703,Gaussian basis sets for use in correlated molecular calculations. III. The atoms aluminum through argon,"['David E. Woon', 'Thom H. Dunning']",1993,The Journal of Chemical Physics,Journal,,1358-1371,98,2,10.1063/1.464303,"Correlation consistent and augmented correlation consistent basis sets have been determined for the second row atoms aluminum through argon. The methodology, originally developed for the first row atoms [T. H. Dunning, Jr., J. Chem. Phys. 90, (1989)] is first applied to sulfur. The exponents for the polarization functions (dfgh) are systematically optimized for a correlated wave function (HF+1+2). The (sp) correlation functions are taken from the appropriate HF primitive sets; it is shown that these functions differ little from the optimum functions. Basis sets of double zeta [4s3p1d], triple zeta [5s4p2d1f], and quadruple zeta [6s5p3d2f1g] quality are defined. Each of these sets is then augmented with diffuse functions to better describe electron affinities and other molecular properties: s and p functions were obtained by optimization for the anion HF energy, while an additional polarization function for each symmetry present in the standard set was optimized for the anion HF+1+2 energy. The results for sulfur are then used to assist in determining double zeta, triple zeta, and quadruple zeta basis sets for the remainder of the second row of the p block.","['Chemistry', 'Gaussian', 'Basis set', 'Argon', 'Ion', 'Electronic correlation', 'Atomic physics', 'Wave function', 'Basis (linear algebra)', 'Polarization (electrochemistry)', 'Molecular physics', 'Computational chemistry', 'Molecule', 'Physics', 'Mathematics', 'Physical chemistry', 'Density functional theory', 'Geometry', 'Organic chemistry']","correlation consistent, augmented correlation consistent basis sets, polarization functions, correlated wave function, correlation functions, double zeta, triple zeta, quadruple zeta, diffuse functions, electron affinities, an, polarization function, double, triple zeta, quadruple zeta basis sets, [PAD], [PAD], [PAD]"
Paper_01705,Graph Theory with Applications,"['J. A. Bondy', 'U. S. R. Murty']",1976,Unknown,Unknown,,,,,10.1007/978-1-349-03521-2,"(1977). Graph Theory with Applications. Journal of the Operational Research Society: Vol. 28, Volume 28, issue 1, pp. 237-238.","['Computer science', 'Graph', 'Mathematics', 'Theoretical computer science']","graph theory, operational research society, [PAD], [PAD] [PAD], [PAD] [PAD], [PAD], [PAD], [PAD], [PAD] [PAD] [PAD], [PAD] [PAD], [PAD] [PAD]"
Paper_01706,The Theory of Industrial Organization,['Jean Tirole'],1988,Unknown,Unknown,,,,,10.4135/9781071924099,"The Theory of Industrial Organization is the first primary text to treat the new industrial organization at the advanced-undergraduate and graduate level. Rigorously analytical and filled with exercises coded to indicate level of difficulty, it provides a unified and modern treatment of the field with accessible models that are simplified to highlight robust economic ideas while working at an intuitive level. To aid students at different levels, each chapter is divided into a main text and supplementary section containing more advanced material. Each chapter opens with elementary models and builds on this base to incorporate current research in a coherent synthesis. Tirole begins with a background discussion of the theory of the firm. In part I he develops the modern theory of monopoly, addressing single product and multi product pricing, static and intertemporal price discrimination, quality choice, reputation, and vertical restraints. In part II, Tirole takes up strategic interaction between firms, starting with a novel treatment of the Bertrand-Cournot interdependent pricing problem. He studies how capacity constraints, repeated interaction, product positioning, advertising, and asymmetric information affect competition or tacit collusion. He then develops topics having to do with long term competition, including barriers to entry, contestability, exit, and research and development. He concludes with a game theory user's manual and a section of review exercises.","['Tacit collusion', 'Cournot competition', 'Interdependence', 'Monopoly', 'Collusion', 'Reputation', 'Product (mathematics)', 'Competition (biology)', 'Industrial organization', 'Game theory', 'Quality (philosophy)', 'Economics', 'Microeconomics', 'New product development', 'Computer science', 'Management', 'Sociology', 'Ecology', 'Social science', 'Philosophy', 'Geometry', 'Mathematics', 'Epistemology', 'Biology']","industrial organization, industrial organization, monopoly, single product, multi product pricing, ##temporal price discrimination, quality choice, reputation, vertical restraints, strategic interaction, capacity constraints, repeated interaction, product positioning, advertising, asymmetric information, competition, tacit collusion, long, barriers to, contestability, exit, game theory"
Paper_01707,Demonstrating Rigor Using Thematic Analysis: A Hybrid Approach of Inductive and Deductive Coding and Theme Development,"['Jennifer Fereday', 'Eimear Muir‐Cochrane']",2006,International Journal of Qualitative Methods,Journal,,80-92,5,1,10.1177/160940690600500107,"In this article, the authors describe how they used a hybrid process of inductive and deductive thematic analysis to interpret raw data in a doctoral study on the role of performance feedback in the self-assessment of nursing practice. The methodological approach integrated data-driven codes with theory-driven ones based on the tenets of social phenomenology. The authors present a detailed exemplar of the staged process of data coding and identification of themes. This process demonstrates how analysis of the raw data from interview transcripts and organizational documents progressed toward the identification of overarching themes that captured the phenomenon of performance feedback as described by participants in the study.","['Raw data', 'Coding (social sciences)', 'Thematic analysis', 'Phenomenon', 'Computer science', 'Identification (biology)', 'Process (computing)', 'Epistemology', 'Data science', 'Psychology', 'Qualitative research', 'Sociology', 'Social science', 'Philosophy', 'Botany', 'Biology', 'Programming language', 'Operating system']","##ductive thematic analysis, performance feedback, nursing practice, social phenomenology, data coding, interview transcripts, organizational documents, performance feedback"
Paper_01708,Qualitative Data Analysis: A Sourcebook of New Methods,['Linda S. Lotto'],1986,Educational Evaluation and Policy Analysis,Journal,,329-331,8,3,10.3102/01623737008003329,Part One: Introduction Part Two: Focusing and Bounding the Collection of Data Part Three: Analysis During Data Collection Part Four: Within-Site Analysis Part Five: Cross-Site Analysis Part Six: Matrix Displays: Some General Suggestions Part Seven: Drawing and Verifying Conclusions Part Eight: Concluding Remarks,"['Data collection', 'Qualitative analysis', 'Qualitative property', 'Computer science', 'Mathematics education', 'Qualitative research', 'Sociology', 'Statistics', 'Psychology', 'Mathematics', 'Social science']","data collection, matrix displays"
Paper_01712,Handbook of Positive Psychology,"['C. R. Snyder', 'Shane J. Lopez']",2001,Unknown,Unknown,,,,,10.1093/oso/9780195135336.001.0001,"Abstract Psychology after World War II became a science largely devoted to healing. It concentrated on repairing damage using a disease model of human functioning. This almost exclusive attention to pathology neglected the idea of a fulfilled individual and a thriving community, and it neglected the possibility that building strength is the most potent weapon in the arsenal of therapy. The aim of positive psychology is to catalyze a change in psychology from a preoccupation only with repairing the worst things in life to also building the best qualities in life. To redress the previous imbalance, we must bring the building of strength to the forefront in the treatment and prevention of mental illness.","['Thriving', 'Redress', 'Positive psychology', 'Psychology', 'Community psychology', 'Psychotherapist', 'Social psychology', 'Political science', 'Law']","abstract psychology, healing, disease model, human functioning, pathology, strength, positive psychology, mental illness"
Paper_01713,Comorbidity Measures for Use with Administrative Data,"['Anne Elixhauser', 'Claudia Steiner', 'D.R. Harris', 'Rosanna M. Coffey']",1998,Medical Care,Journal,,8-27,36,1,10.1097/00005650-199801000-00004,"This study attempts to develop a comprehensive set of comorbidity measures for use with large administrative inpatient datasets.The study involved clinical and empirical review of comorbidity measures, development of a framework that attempts to segregate comorbidities from other aspects of the patient's condition, development of a comorbidity algorithm, and testing on heterogeneous and homogeneous patient groups. Data were drawn from all adult, nonmaternal inpatients from 438 acute care hospitals in California in 1992 (n = 1,779,167). Outcome measures were those commonly available in administrative data: length of stay, hospital charges, and in-hospital death.A comprehensive set of 30 comorbidity measures was developed. The comorbidities were associated with substantial increases in length of stay, hospital charges, and mortality both for heterogeneous and homogeneous disease groups. Several comorbidities are described that are important predictors of outcomes, yet commonly are not measured. These include mental disorders, drug and alcohol abuse, obesity, coagulopathy, weight loss, and fluid and electrolyte disorders.The comorbidities had independent effects on outcomes and probably should not be simplified as an index because they affect outcomes differently among different patient groups. The present method addresses some of the limitations of previous measures. It is based on a comprehensive approach to identifying comorbidities and separates them from the primary reason for hospitalization, resulting in an expanded set of comorbidities that easily is applied without further refinement to administrative data for a wide range of diseases.","['Comorbidity', 'Medicine', 'Homogeneous', 'MEDLINE', 'Intensive care medicine', 'Psychiatry', 'Physics', 'Political science', 'Law', 'Thermodynamics']","comorbidity measures, administrative inpatient datasets, comorbidity measures, como, ##idi, comorbidity algorithm, acute care hospitals, hospital, comorbidity measures, hospital charges, mortality, mental disorders, obesity, coagulopathy, weight loss, como, como, ##ties"
Paper_01715,Framing Processes and Social Movements: An Overview and Assessment,"['Robert D. Benford', 'David A. Snow']",2000,Annual Review of Sociology,Journal,,611-639,26,1,10.1146/annurev.soc.26.1.611,"The recent proliferation of scholarship on collective action frames and framing processes in relation to social movements indicates that framing processes have come to be regarded, alongside resource mobilization and political opportunity processes, as a central dynamic in understanding the character and course of social movements. This review examines the analytic utility of the framing literature for understanding social movement dynamics. We first review how collective action frames have been conceptualized, including their characteristic and variable features. We then examine the literature related to framing dynamics and processes. Next we review the literature regarding various contextual factors that constrain and facilitate framing processes. We conclude with an elaboration of the consequences of framing processes for other movement processes and outcomes. We seek throughout to provide clarification of the linkages between framing concepts/processes and other conceptual and theoretical formulations relevant to social movements, such as schemas and ideology.","['Framing (construction)', 'Social movement', 'Resource mobilization', 'Political opportunity', 'Scholarship', 'Sociology', 'Politics', 'Salient', 'Epistemology', 'Social psychology', 'Political science', 'Psychology', 'Geography', 'Philosophy', 'Archaeology', 'Law']","collective action frames, framing processes, social movements, framing processes, resource mobilization, political opportunity processes, social, social movement dynamics, collective action frames, framing dynamics, ##ual, framing, social movements, schemas, ideology, [PAD] [PAD] [PAD] [PAD]"
Paper_01717,Matching pursuits with time-frequency dictionaries,"['Stéphane Mallat', 'Zhifeng Zhang']",1993,IEEE Transactions on Signal Processing,Journal,,3397-3415,41,12,10.1109/78.258082,"The authors introduce an algorithm, called matching pursuit, that decomposes any signal into a linear expansion of waveforms that are selected from a redundant dictionary of functions. These waveforms are chosen in order to best match the signal structures. Matching pursuits are general procedures to compute adaptive signal representations. With a dictionary of Gabor functions a matching pursuit defines an adaptive time-frequency transform. They derive a signal energy distribution in the time-frequency plane, which does not include interference terms, unlike Wigner and Cohen class distributions. A matching pursuit isolates the signal structures that are coherent with respect to a given dictionary. An application to pattern extraction from noisy signals is described. They compare a matching pursuit decomposition with a signal expansion over an optimized wavepacket orthonormal basis, selected with the algorithm of Coifman and Wickerhauser see (IEEE Trans. Informat. Theory, vol. 38, Mar. 1992).< <ETX xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">&gt;</ETX>","['Matching pursuit', 'Orthonormal basis', 'Time–frequency analysis', 'Matching (statistics)', 'SIGNAL (programming language)', 'Computer science', 'Basis pursuit', 'Algorithm', 'Waveform', 'Signal processing', 'Pattern recognition (psychology)', 'Basis (linear algebra)', 'Artificial intelligence', 'Mathematics', 'Speech recognition', 'Compressed sensing', 'Digital signal processing', 'Computer vision', 'Telecommunications', 'Radar', 'Physics', 'Geometry', 'Filter (signal processing)', 'Quantum mechanics', 'Computer hardware', 'Programming language', 'Statistics']","matching pursuit, linear expansion, redundant dictionary, matching, adaptive signal representations, gabor functions, matching pursuit, signal energy distribution, matching pursuit, pattern extraction, noisy signals, matching pursuit decomposition, signal expansion"
Paper_01719,NCBI GEO: archive for functional genomics data sets—update,"['Tanya Barrett', 'Stephen E. Wilhite', 'Pierre Ledoux', 'Carlos Evangelista', 'Irene F. Kim', 'Maxim Tomashevsky', 'Kimberly A. Marshall', 'Katherine Phillippy', 'Patti M. Sherman', 'Michelle Holko', 'Andrey Yefanov', 'Hyeseung Lee', 'Naigong Zhang', 'C. Robertson', 'Nadezhda Serova', 'Sean Davis', 'Alexandra Soboleva']",2012,Nucleic Acids Research,Journal,,D991-D995,41,D1,10.1093/nar/gks1193,"The Gene Expression Omnibus (GEO, http://www.ncbi.nlm.nih.gov/geo/) is an international public repository for high-throughput microarray and next-generation sequence functional genomic data sets submitted by the research community. The resource supports archiving of raw data, processed data and metadata which are indexed, cross-linked and searchable. All data are freely available for download in a variety of formats. GEO also provides several web-based tools and strategies to assist users to query, analyse and visualize data. This article reports current status and recent database developments, including the release of GEO2R, an R-based web application that helps users analyse GEO data.","['Metadata', 'Download', 'Biology', 'Raw data', 'Genomics', 'The Internet', 'Resource (disambiguation)', 'Variety (cybernetics)', 'Functional genomics', 'World Wide Web', 'Data science', 'Information retrieval', 'Bioinformatics', 'Computational biology', 'Computer science', 'Genome', 'Gene', 'Genetics', 'Computer network', 'Artificial intelligence', 'Programming language']","gene expression omnibus, geo, geo2r"
Paper_01720,"Contracted Gaussian basis sets for molecular calculations. I. Second row atoms, <i>Z</i>=11–18","['A. D. McLean', 'G. S. Chandler']",1980,The Journal of Chemical Physics,Journal,,5639-5648,72,10,10.1063/1.438980,"Contracted Gaussian basis sets for molecular calculations are derived from uncontracted (12,8) and (12,9) sets for the neutral second row atoms, Z=11–18, and for the negative ions P−, S−, and Cl−. Calculations on Na...2p63p, 2P and Mg...2p63s3p, 3P are used to derive contracted Gaussian functions to describe the 3p orbital in these atoms, necessary in molecular applications. The derived basis sets range from minimal, through double-zeta, to the largest set which has a triple-zeta basis for the 3p orbital, double-zeta for the remaining. Where necessary to avoid unacceptable energy losses in atomic wave functions expanded in the contracted Gaussians, a given uncontracted Gaussian function is used in two contracted functions. These tabulations provide a hierarchy of basis sets to be used in designing a convergent sequence of molecular computations, and to establish the reliability of the molecular properties under study.","['Gaussian', 'Basis (linear algebra)', 'STO-nG basis sets', 'Basis set', 'Range (aeronautics)', 'Wave function', 'Molecular orbital', 'Atomic physics', 'Physics', 'Mathematics', 'Computational chemistry', 'Quantum mechanics', 'Chemistry', 'Molecule', 'Materials science', 'Geometry', 'Linear combination of atomic orbitals', 'Composite material']","contracted gaussian basis sets, molecular calculations, neutral second row atoms, contracted gaussian functions, energy losses, atomic wave functions, uncontracted gaussian function, contracted functions, molecular computations"
Paper_01721,General Theory of Three-Dimensional Consolidation,['Maurice A. Biot'],1941,Journal of Applied Physics,Journal,,155-164,12,2,10.1063/1.1712886,"The settlement of soils under load is caused by a phenomenon called consolidation, whose mechanism is known to be in many cases identical with the process of squeezing water out of an elastic porous medium. The mathematical physical consequences of this viewpoint are established in the present paper. The number of physical constants necessary to determine the properties of the soil is derived along with the general equations for the prediction of settlements and stresses in three-dimensional problems. Simple applications are treated as examples. The operational calculus is shown to be a powerful method of solution of consolidation problems.","['Consolidation (business)', 'Porous medium', 'Calculus (dental)', 'Geotechnical engineering', 'Human settlement', 'Soil water', 'Mathematical model', 'Applied mathematics', 'Computer science', 'Mathematics', 'Porosity', 'Geology', 'Engineering', 'Soil science', 'Economics', 'Medicine', 'Accounting', 'Dentistry', 'Statistics', 'Waste management']","consolidation, elastic porous medium, mathematical physical consequences, operational calculus, consolidation problems"
Paper_01722,Gene Dose of Apolipoprotein E Type 4 Allele and the Risk of Alzheimer's Disease in Late Onset Families,"['Elizabeth H. Corder', 'Ann M. Saunders', 'Warren J. Strittmatter', 'D. E. Schmechel', 'P. C. Gaskell', 'Gary W. Small', 'Allen D. Roses', 'J. L. Haines', 'Jeffery M. Vance']",1993,Science,Journal,,921-923,261,5123,10.1126/science.8346443,"The apolipoprotein E type 4 allele ( APOE -ε4) is genetically associated with the common late onset familial and sporadic forms of Alzheimer's disease (AD). Risk for AD increased from 20% to 90% and mean age at onset decreased from 84 to 68 years with increasing number of APOE -ε4 alleles in 42 families with late onset AD. Thus APOE -ε4 gene dose is a major risk factor for late onset AD and, in these families, homozygosity for APOE -ε4 was virtually sufficient to cause AD by age 80.","['Apolipoprotein E', 'Allele', 'Age of onset', 'Risk factor', 'Disease', ""Alzheimer's disease"", 'Genetics', 'Degenerative disease', 'Biology', 'Medicine', 'Internal medicine', 'Gene']","apoli, ##rot, alzheimer"
Paper_01723,Mitochondria and Apoptosis,"['Douglas R. Green', 'John C. Reed']",1998,Science,Journal,,1309-1312,281,5381,10.1126/science.281.5381.1309,"A variety of key events in apoptosis focus on mitochondria, including the release of caspase activators (such as cytochrome c), changes in electron transport, loss of mitochondrial transmembrane potential, altered cellular oxidation-reduction, and participation of pro- and antiapoptotic Bcl-2 family proteins. The different signals that converge on mitochondria to trigger or inhibit these events and their downstream effects delineate several major pathways in physiological cell death.","['Mitochondrion', 'Apoptosis', 'Cell biology', 'Cytochrome c', 'Bcl-2 family', 'Electron transport chain', 'Programmed cell death', 'Caspase', 'Biology', 'Chemistry', 'Biochemistry']","apoptosis, mit, ##ria, cas, ##tochrome, electron transport, mitochondrial transmembrane potential, physiological cell death"
Paper_01726,Giant Magnetoresistance of (001)Fe/(001)Cr Magnetic Superlattices,"['M. N. Baibich', 'J.M. Broto', 'A. Fert', 'F. Nguyen Van Dau', 'F. Pétroff', 'P. Étienne', 'G. Creuzet', 'A. Friederich', 'J. Chazelas']",1988,Physical Review Letters,Journal,,2472-2475,61,21,10.1103/physrevlett.61.2472,"We have studied the magnetoresistance of (001)Fe/(001)Cr superlattices prepared by molecularbeam epitaxy. A huge magnetoresistance is found in superlattices with thin Cr layers: For example, with ${t}_{\mathrm{Cr}}=9$ \AA{}, at $T=4.2$ K, the resistivity is lowered by almost a factor of 2 in a magnetic field of 2 T. We ascribe this giant magnetoresistance to spin-dependent transmission of the conduction electrons between Fe layers through Cr layers.","['Magnetoresistance', 'Superlattice', 'Condensed matter physics', 'Giant magnetoresistance', 'Materials science', 'Electrical resistivity and conductivity', 'Epitaxy', 'Electron', 'Colossal magnetoresistance', 'Magnetic field', 'Physics', 'Nanotechnology', 'Layer (electronics)', 'Quantum mechanics']","magnetoresistance, ##lattices, molecularbeam epitaxy, magnetoresistance, superlattic, thin cr layers, resist, magnetic field, giant magnetoresistance, ##ion electrons"
Paper_01727,An Information-Maximization Approach to Blind Separation and Blind Deconvolution,"['Anthony J. Bell', 'Terrence J. Sejnowski']",1995,Neural Computation,Journal,,1129-1159,7,6,10.1162/neco.1995.7.6.1129,"We derive a new self-organizing learning algorithm that maximizes the information transferred in a network of nonlinear units. The algorithm does not assume any knowledge of the input distributions, and is defined here for the zero-noise limit. Under these conditions, information maximization has extra properties not found in the linear case (Linsker 1989). The nonlinearities in the transfer function are able to pick up higher-order moments of the input distributions and perform something akin to true redundancy reduction between units in the output representation. This enables the network to separate statistically independent components in the inputs: a higher-order generalization of principal components analysis. We apply the network to the source separation (or cocktail party) problem, successfully separating unknown mixtures of up to 10 speakers. We also show that a variant on the network architecture is able to perform blind deconvolution (cancellation of unknown echoes and reverberation in a speech signal). Finally, we derive dependencies of information transfer on time delays. We suggest that information maximization provides a unifying framework for problems in ""blind"" signal processing.","['Blind signal separation', 'Maximization', 'Blind deconvolution', 'Deconvolution', 'Computer science', 'Algorithm', 'Redundancy (engineering)', 'Nonlinear system', 'Generalization', 'Artificial neural network', 'Mathematics', 'Artificial intelligence', 'Mathematical optimization', 'Channel (broadcasting)', 'Computer network', 'Mathematical analysis', 'Physics', 'Quantum mechanics', 'Operating system']","nonlinear units, information maximization, redundancy reduction, principal components analysis, source separation, cocktail party, network architecture, blind deconvolution, ##ation, speech signal, information transfer, time delays, information maximization, [PAD], [PAD] [PAD] [PAD], [PAD], [PAD], [PAD] [PAD], [PAD] [PAD] [PAD] [PAD]"
Paper_01729,Overview of the Coupled Model Intercomparison Project Phase 6 (CMIP6) experimental design and organization,"['Veronika Eyring', 'Sandrine Bony', 'Gerald A. Meehl', 'C. A. Senior', 'Björn Stevens', 'Ronald J. Stouffer', 'Karl E. Taylor']",2016,Geoscientific model development,Journal,,1937-1958,9,5,10.5194/gmd-9-1937-2016,"Abstract. By coordinating the design and distribution of global climate model simulations of the past, current, and future climate, the Coupled Model Intercomparison Project (CMIP) has become one of the foundational elements of climate science. However, the need to address an ever-expanding range of scientific questions arising from more and more research communities has made it necessary to revise the organization of CMIP. After a long and wide community consultation, a new and more federated structure has been put in place. It consists of three major elements: (1) a handful of common experiments, the DECK (Diagnostic, Evaluation and Characterization of Klima) and CMIP historical simulations (1850–near present) that will maintain continuity and help document basic characteristics of models across different phases of CMIP; (2) common standards, coordination, infrastructure, and documentation that will facilitate the distribution of model outputs and the characterization of the model ensemble; and (3) an ensemble of CMIP-Endorsed Model Intercomparison Projects (MIPs) that will be specific to a particular phase of CMIP (now CMIP6) and that will build on the DECK and CMIP historical simulations to address a large range of specific questions and fill the scientific gaps of the previous CMIP phases. The DECK and CMIP historical simulations, together with the use of CMIP data standards, will be the entry cards for models participating in CMIP. Participation in CMIP6-Endorsed MIPs by individual modelling groups will be at their own discretion and will depend on their scientific interests and priorities. With the Grand Science Challenges of the World Climate Research Programme (WCRP) as its scientific backdrop, CMIP6 will address three broad questions: – How does the Earth system respond to forcing? – What are the origins and consequences of systematic model biases? – How can we assess future climate changes given internal climate variability, predictability, and uncertainties in scenarios? This CMIP6 overview paper presents the background and rationale for the new structure of CMIP, provides a detailed description of the DECK and CMIP6 historical simulations, and includes a brief introduction to the 21 CMIP6-Endorsed MIPs.","['Coupled model intercomparison project', 'Documentation', 'Computer science', 'Range (aeronautics)', 'Consistency (knowledge bases)', 'Systems engineering', 'Environmental science', 'Climate model', 'Operations research', 'Climate change', 'Geology', 'Engineering', 'Programming language', 'Aerospace engineering', 'Artificial intelligence', 'Oceanography']","global climate model simulations, coupled model intercomparison project, cm, climate science, klima, cmip, cmip, cmip, cmip, cm, world climate research programme, wc, ##ip, internal climate variability, predictability, uncertain, cmip"
Paper_01731,Diversity in Tropical Rain Forests and Coral Reefs,['Joseph H. Connell'],1978,Science,Journal,,1302-1310,199,4335,10.1126/science.199.4335.1302,"The commonly observed high diversity of trees in tropical rain forests and corals on tropical reefs is a nonequilibrium state which, if not disturbed further, will progress toward a low-diversity equilibrium community. This may not happen if gradual changes in climate favor different species. If equilibrium is reached, a lesser degree of diversity may be sustained by niche diversification or by a compensatory mortality that favors inferior competitors. However, tropical forests and reefs are subject to severe disturbances often enough that equilibrium may never be attained.","['Coral reef', 'Reef', 'Ecology', 'Diversification (marketing strategy)', 'Tropics', 'Niche', 'Biodiversity', 'Geography', 'Rainforest', 'Tropical climate', 'Biology', 'Business', 'Marketing']","tropical rain forests, corals, tropical reefs, nonequilibrium state, niche diversification, ##ory mortality"
Paper_01732,Coherent Measures of Risk,"['Philippe Artzner', 'Freddy Delbaen', 'Jean‐Marc Eber', 'David Heath']",1999,Mathematical Finance,Journal,,203-228,9,3,10.1111/1467-9965.00068,"In this paper we study both market risks and nonmarket risks, without complete markets assumption, and discuss methods of measurement of these risks. We present and justify a set of four desirable properties for measures of risk, and call the measures satisfying these properties “coherent.” We examine the measures of risk provided and the related actions required by SPAN, by the SEC/NASD rules, and by quantile‐based methods. We demonstrate the universality of scenario‐based methods for providing coherent measures. We offer suggestions concerning the SEC method. We also suggest a method to repair the failure of subadditivity of quantile‐based methods.","['Coherent risk measure', 'Quantile', 'Subadditivity', 'Risk measure', 'Econometrics', 'Universality (dynamical systems)', 'Actuarial science', 'Dynamic risk measure', 'Expected shortfall', 'Market risk', 'Risk analysis (engineering)', 'Value at risk', 'Spectral risk measure', 'Computer science', 'Economics', 'Risk management', 'Mathematics', 'Financial economics', 'Business', 'Finance', 'Portfolio', 'Physics', 'Discrete mathematics', 'Quantum mechanics']","market risks, nonmarket risks, quantile ‐ based, scenario ‐, sec, subadditivity, quantile ‐"
Paper_01733,Communication Theory of Secrecy Systems*,['Claude E. Shannon'],1949,Bell System Technical Journal,Journal,,656-715,28,4,10.1002/j.1538-7305.1949.tb00928.x,"THE problems of cryptography and secrecy systems furnish an interesting application of communication theory. <sup xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">1</sup> In this paper a theory of secrecy systems is developed. The approach is on a theoretical level and is intended to complement the treatment found in standard works on cryptography. <sup xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">2</sup> There, a detailed study is made of the many standard types of codes and ciphers, and of the ways of breaking them. We will be more concerned with the general mathematical structure and properties of secrecy systems.","['Secrecy', 'Cryptography', 'Complement (music)', 'Computer science', 'Theoretical computer science', 'Information-theoretic security', 'Algorithm', 'Computer security', 'Biology', 'Biochemistry', 'Complementation', 'Gene', 'Phenotype']","cryptography, secrecy systems, communication theory, secrecy systems, crypt, ##ink, ##ink, ##s, secrecy systems"
Paper_01735,Decision making with the analytic hierarchy process,['Thomas L. Saaty'],2008,International Journal of Services Sciences,Journal,,83-83,1,1,10.1504/ijssci.2008.017590,"Decisions involve many intangibles that need to be traded off. To do that, they have to be measured along side tangibles whose measurements must also be evaluated as to, how well, they serve the objectives of the decision maker. The Analytic Hierarchy Process (AHP) is a theory of measurement through pairwise comparisons and relies on the judgements of experts to derive priority scales. It is these scales that measure intangibles in relative terms. The comparisons are made using a scale of absolute judgements that represents, how much more, one element dominates another with respect to a given attribute. The judgements may be inconsistent, and how to measure inconsistency and improve the judgements, when possible to obtain better consistency is a concern of the AHP. The derived priority scales are synthesised by multiplying them by the priority of their parent nodes and adding for all such nodes. An illustration is included.","['Analytic hierarchy process', 'Analytic network process', 'Process (computing)', 'Process management', 'Management science', 'Computer science', 'Mathematics', 'Engineering', 'Operations research', 'Operating system']","intangibles, analytic hierarchy process, ah, pairwise comparisons, priority scales, intang, ##s, absolute judgements, ##iste, derived priority scales"
Paper_01736,Quantum Calculation of Molecular Energies and Energy Gradients in Solution by a Conductor Solvent Model,"['Vincenzo Barone', 'Maurizio Cossi']",1998,The Journal of Physical Chemistry A,Journal,,1995-2001,102,11,10.1021/jp9716997,"A new implementation of the conductor-like screening solvation model (COSMO) in the GAUSSIAN94 package is presented. It allows Hartree−Fock (HF), density functional (DF) and post-HF energy, and HF and DF gradient calculations: the cavities are modeled on the molecular shape, using recently optimized parameters, and both electrostatic and nonelectrostatic contributions to energies and gradients are considered. The calculated solvation energies for 19 neutral molecules in water are found in very good agreement with experimental data; the solvent-induced geometry relaxation is studied for some closed and open shell molecules, at HF and DF levels. The computational times are very satisfying: the self-consistent energy evaluation needs a time 15−30% longer than the corresponding procedure in vacuo, whereas the calculation of energy gradients is only 25% longer than in vacuo for medium size molecules.","['Solvation', 'Conductor', 'Molecule', 'Relaxation (psychology)', 'Chemistry', 'Solvation shell', 'Quantum', 'Implicit solvation', 'Molecular physics', 'Atomic physics', 'Materials science', 'Computational chemistry', 'Chemical physics', 'Physics', 'Quantum mechanics', 'Psychology', 'Social psychology', 'Organic chemistry', 'Composite material']","co, gaussian9, density functional, cavities, molecular, solvation energies, energy gradients, medium size, [PAD], [PAD], [PAD], [PAD]"
Paper_01737,The Theory of Matrices,['Felix R. Gantmacher'],1984,['Mathematics of Computation'],Unknown,,886,23,108,10.2307/2004986,"Volume 2: XI. Complex symmetric, skew-symmetric, and orthogonal matrices: 1. Some formulas for complex orthogonal and unitary matrices 2. Polar decomposition of a complex matrix 3. The normal form of a complex symmetric matrix 4. The normal form of a complex skew-symmetric matrix 5. The normal form of a complex orthogonal matrix XII. Singular pencils of matrices: 1. Introduction 2. Regular pencils of matrices 3. Singular pencils. The reduction theorem 4. The canonical form of a singular pencil of matrices 5. The minimal indices of a pencil. Criterion for strong equivalence of pencils 6. Singular pencils of quadratic forms 7. Application to differential equations XIII. Matrices with non-negative elements: 1. General properties 2. Spectral properties of irreducible non-negative matrices 3. Reducible matrices 4. The normal form of a reducible matrix 5. Primitive and imprimitive matrices 6. Stochastic matrices 7. Limiting probabilities for a homogeneous Markov chain with a finite number of states 8. Totally non-negative matrices 9. Oscillatory matrices XIV. Applications of the theory of matrices to the investigation of systems of linear differential equations: 1. Systems of linear differential equations with variable coefficients. General concepts 2. Lyapunov transformations 3. Reducible systems 4. The canonical form of a reducible system. Erugin's theorem 5. The matricant 6. The multiplicative integral. The infinitesimal calculus of Volterra 7. Differential systems in a complex domain. General properties 8. The multiplicative integral in a complex domain 9. Isolated singular points 10. Regular singularities 11. Reducible analytic systems 12. Analytic functions of several matrices and their application to the investigation of differential systems. The papers of Lappo-Danilevskii XV. The problem of Routh-Hurwitz and related questions: 1. Introduction 2. Cauchy indices 3. Routh's algorithm 4. The singular case. Examples 5. Lyapunov's theorem 6. The theorem of Routh-Hurwitz 7. Orlando's formula 8. Singular cases in the Routh-Hurwitz theorem 9. The method of quadratic forms. Determination of the number of distinct real roots of a polynomial 10. Infinite Hankel matrices of finite rank 11. Determination of the index of an arbitrary rational fraction by the coefficients of numerator and denominator 12. Another proof of the Routh-Hurwitz theorem 13. Some supplements to the Routh-Hurwitz theorem. Stability criterion of Lienard and Chipart 14. Some properties of Hurwitz polynomials. Stieltjes' theorem. Representation of Hurwitz polynomials by continued fractions 15. Domain of stability. Markov parameters 16. Connection with the problem of moments 17. Theorems of Markov and Chebyshev 18. The generalized Routh-Hurwitz problem Bibliography Index.","['Mathematics', 'Pure mathematics', 'Matrix (chemical analysis)', 'Multiplicative function', 'Matrix analysis', 'Unitary matrix', 'Normal matrix', 'Mathematical analysis', 'Eigenvalues and eigenvectors', 'Unitary state', 'Materials science', 'Physics', 'Quantum mechanics', 'Political science', 'Law', 'Composite material']","orthogonal matrices, unitary matrices, polar decomposition, complex matrix, normal form, complex symmetric matrix, normal form, normal form, complex orthogonal matrix, singular pencils, regular pencils, singular pencils, reduction theorem, canonical form, singular pencil, minimal indices, singular pencils, quadratic, differential, spectral properties, reducible matrices, normal form, reducible matrix, imprimitive matrices, stochastic matrices, limiting, oscillatory matrices, linear differential equations, linear differential equations, variable, lyapunov transformations, reducible systems, canonical, matrica, multiplicative integral, infinitesimal calculus, differential systems, complex domain, multiplicative integral, complex domain, isolated singular points, regular singularities, reducible analytic systems, analytic functions, differential systems, cauchy indices, singular case, singular cases, quadratic forms, distinct real roots, infinite hankel matrices, denomi"
Paper_01738,Principal Component Analysis,"['Colin Goodall', 'Ian T. Jolliffe']",1988,Technometrics,Journal,,351-351,30,3,10.2307/1270093,"Introduction * Properties of Population Principal Components * Properties of Sample Principal Components * Interpreting Principal Components: Examples * Graphical Representation of Data Using Principal Components * Choosing a Subset of Principal Components or Variables * Principal Component Analysis and Factor Analysis * Principal Components in Regression Analysis * Principal Components Used with Other Multivariate Techniques * Outlier Detection, Influential Observations and Robust Estimation * Rotation and Interpretation of Principal Components * Principal Component Analysis for Time Series and Other Non-Independent Data * Principal Component Analysis for Special Types of Data * Generalizations and Adaptations of Principal Component Analysis","['Principal component analysis', 'Outlier', 'Kernel principal component analysis', 'Multiple correspondence analysis', 'Multivariate statistics', 'Statistics', 'Principal component regression', 'Mathematics', 'Population', 'Correspondence analysis', 'Pattern recognition (psychology)', 'Computer science', 'Artificial intelligence', 'Kernel method', 'Demography', 'Sociology', 'Support vector machine']","graphical representation, principal components, principal component analysis, factor analysis, principal components, regression analysis, principal components, multivariate techniques, outlier detection, influential observations, robust estimation, principal components, principal component analysis, time series, principal component analysis, principal component analysis"
Paper_01739,A Self-Rating Depression Scale,['William W.K. Zung'],1965,Archives of General Psychiatry,Journal,,63-63,12,1,10.1001/archpsyc.1965.01720310065008,"The fact that there is a need for assessing depression, whether as an affect, a symptom, or a disorder is obvious by the numerous scales and inventories available and in use today. The need to assess depression simply and specifically as a psychiatric disorder has not been met by most scales available today. We became acutely aware of this situation in a research project where we needed to correlate both the presence and severity of a depressive disorder in patients with other parameters such as arousal response during sleep and changes with treatment of the depressive disorder. It was felt that the general depression scales used were insufficient for our purpose and that the more specific scales were also inadequate. These inadequacies related to factors such as the length of a scale or inventory being too long and too time consuming, especially for a patient","['Depression (economics)', 'Rating scale', 'Psychology', 'Affect (linguistics)', 'Major depressive disorder', 'Psychiatry', 'Scale (ratio)', 'Clinical psychology', 'Arousal', 'Mood', 'Developmental psychology', 'Social psychology', 'Physics', 'Quantum mechanics', 'Economics', 'Macroeconomics', 'Communication']","psychiatric disorder, depressive disorder, arousal response, ##pressive"
Paper_01740,The Measurement of Meaning,"['Charles E. Osgood', 'George J. Suci', 'Percy H. Tannenbaum']",1957,['World Bank Technical Papers'],Unknown,,,,,10.1596/0-8213-5054-4,"In this pioneering study, the authors deal with the nature and theory of meaning and present a new, objective method for its measurement which they call the semantic differential. This instrument is not a specific test, but rather a general technique of measurement that can be adapted to a wide variety of problems in such areas as clinical psychology, social psychology, linguistics, mass communications, esthetics, and political science. The core of the book is the authors' description, application, and evaluation of this important tool and its far-reaching implications for empirical research.","['Meaning (existential)', 'Variety (cybernetics)', 'Test (biology)', 'Epistemology', 'Semantic differential', 'Empirical research', 'Psychology', 'Politics', 'Social science', 'Computer science', 'Data science', 'Sociology', 'Linguistics', 'Social psychology', 'Political science', 'Artificial intelligence', 'Philosophy', 'Ecology', 'Law', 'Biology']","meaning, semantic differential, clinical psychology, social psychology, linguistics, mass communications, esthetics, political science, empirical"
Paper_01741,"Ordering, metastability and phase transitions in two-dimensional systems","['J. M. Kosterlitz', 'D. J. Thouless']",1973,Journal of Physics C Solid State Physics,Journal,,1181-1203,6,7,10.1088/0022-3719/6/7/010,"A new definition of order called topological order is proposed for two-dimensional systems in which no long-range order of the conventional type exists. The possibility of a phase transition characterized by a change in the response of the system to an external perturbation is discussed in the context of a mean field type of approximation. The critical behaviour found in this model displays very weak singularities. The application of these ideas to the xy model of magnetism, the solid-liquid transition, and the neutral superfluid are discussed. This type of phase transition cannot occur in a superconductor nor in a Heisenberg ferromagnet.","['Phase transition', 'Metastability', 'Condensed matter physics', 'Gravitational singularity', 'Physics', 'Magnetism', 'Ferromagnetism', 'Superconductivity', 'Type (biology)', 'Perturbation (astronomy)', 'Context (archaeology)', 'Quantum phase transition', 'Quantum mechanics', 'Ecology', 'Paleontology', 'Biology']","topological order, phase transition, mean field, critical behaviour, xy model, magnetism, neutral superfluid, phase transition, supercondu, ##berg ferromagnet"
Paper_01742,Experimental Verification of a Negative Index of Refraction,"['R. A. Shelby', 'David R. Smith', 'S. Schultz']",2001,Science,Journal,,77-79,292,5514,10.1126/science.1058847,"We present experimental scattering data at microwave frequencies on a structured metamaterial that exhibits a frequency band where the effective index of refraction (n) is negative. The material consists of a two-dimensional array of repeated unit cells of copper strips and split ring resonators on interlocking strips of standard circuit board material. By measuring the scattering angle of the transmitted beam through a prism fabricated from this material, we determine the effective n, appropriate to Snell's law. These experiments directly confirm the predictions of Maxwell's equations that n is given by the negative square root of epsilon.mu for the frequencies where both the permittivity (epsilon) and the permeability (mu) are negative. Configurations of geometrical optical designs are now possible that could not be realized by positive index materials.","['STRIPS', 'Optics', 'Refractive index', 'Metamaterial', 'Scattering', 'Permittivity', 'Prism', 'Resonator', 'Microwave', 'Physics', 'Scattering parameters', 'Copper', 'Materials science', 'Split-ring resonator', 'Negative refraction', 'Dielectric', 'Optoelectronics', 'Composite material', 'Quantum mechanics', 'Metallurgy']","scattering data, microwave frequencies, structured metamaterial, frequency band, effective index of refraction, repeated unit cells, copper strips, split ring resonators, scattering angle, permittivity, permeability, geometrical optical designs, positive index materials"
Paper_01746,Analysis of Gene Diversity in Subdivided Populations,['Masatoshi Nei'],1973,Proceedings of the National Academy of Sciences,Journal,,3321-3323,70,12,10.1073/pnas.70.12.3321,"A method is presented by which the gene diversity (heterozygosity) of a subdivided population can be analyzed into its components, i.e., the gene diversities within and between subpopulations. This method is applicable to any population without regard to the number of alleles per locus, the pattern of evolutionary forces such as mutation, selection, and migration, and the reproductive method of the organism used. Measures of the absolute and relative magnitudes of gene differentiation among subpopulations are also proposed.","['Loss of heterozygosity', 'Biology', 'Locus (genetics)', 'Genetics', 'Allele', 'Gene', 'Evolutionary biology', 'Population', 'Gene pool', 'Genetic diversity', 'Population genetics', 'Selection (genetic algorithm)', 'Allele frequency', 'Demography', 'Artificial intelligence', 'Sociology', 'Computer science']","gene diversity, heterozygosity, subdivided population, gene diversities, ##pop, evolutionary forces, migration, reproductive method, gene differentiation, [PAD], [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]"
Paper_01747,Copper-Zinc Superoxide Dismutase (SOD1) Is Released by Microglial Cells and Confers Neuroprotection against 6-OHDA Neurotoxicity,"['Elisabetta Polazzi', 'Ilaria Mengoni', 'Marco Caprini', 'Emiliano Peña‐Altamira', 'Ewelina Kurtys', 'Barbara Monti']",2012,Neurosignals,Journal,,112-128,21,1-2,10.1159/000337115,"The role so far ascribed to intracellular CuZn superoxide dismutase is that of an intracellular scavenger of oxygen radicals. However, other functions of cytosolic CuZn superoxide dismutase have been hypothesized. For example, CuZn superoxide dismutase incubated with rat hepatocyte cells in culture inhibits 3-hydroxy-3methylglutaryl CoA reductase, thereby reducing cholesterol synthesis. We recently demonstrated the presence of surface membrane receptors for CuZn superoxide dismutase, suggesting possible autocrine or paracrine activities. The aim of the present study was to investigate whether cytosolic CuZn superoxide dismutase can be secreted by human hepatocarcinoma and fibroblast cells lines. Proteins in human hepatocellular carcinoma (Hep G2) cells and human fibroblasts were biosynthetically labelled with [35S]-cysteine; then cell lysates and media were immunoprecipitated with rabbit polyclonal anti-human CuZn superoxide dismutase antibodies and separated by 12% polyacrylamide gel electrophoresis. Both Hep G2 cells and human fibroblasts produce and secrete CuZn superoxide dismutase which was detectable in cells and medium as a single protein band with the same electrophoretic mobility as human erythrocyte CuZn superoxide dismutase. These data suggest that CuZn superoxide dismutase, an enzyme thus far considered to be located exclusively intracellularly is secreted by at least two cell lines. This is consistent with autocrine or paracrine roles for CuZn superoxide dismutase.","['Superoxide dismutase', 'Chemistry', 'Autocrine signalling', 'Biochemistry', 'Cytosol', 'Molecular biology', 'Dismutase', 'SOD1', 'Paracrine signalling', 'Superoxide', 'Reactive oxygen species', 'Hepatocyte', 'Biology', 'Antioxidant', 'Enzyme', 'Receptor', 'In vitro']","##cellular, ##cellular, oxygen radicals, ##olic, surface membrane receptors, fibroblast"
Paper_01748,"Prevalence of Overweight and Obesity in the United States, 1999-2004","['Cynthia L. Ogden', 'Margaret D. Carroll', 'Lester R. Curtin', 'Margaret McDowell', 'Carolyn J. Tabak', 'Katherine M. Flegal']",2006,JAMA,Journal,,1549-1549,295,13,10.1001/jama.295.13.1549,"The prevalence of overweight in children and adolescents and obesity in adults in the United States has increased over several decades.To provide current estimates of the prevalence and trends of overweight in children and adolescents and obesity in adults.Analysis of height and weight measurements from 3958 children and adolescents aged 2 to 19 years and 4431 adults aged 20 years or older obtained in 2003-2004 as part of the National Health and Nutrition Examination Survey (NHANES), a nationally representative sample of the US population. Data from the NHANES obtained in 1999-2000 and in 2001-2002 were compared with data from 2003-2004.Estimates of the prevalence of overweight in children and adolescents and obesity in adults. Overweight among children and adolescents was defined as at or above the 95th percentile of the sex-specific body mass index (BMI) for age growth charts. Obesity among adults was defined as a BMI of 30 or higher; extreme obesity was defined as a BMI of 40 or higher.In 2003-2004, 17.1% of US children and adolescents were overweight and 32.2% of adults were obese. Tests for trend were significant for male and female children and adolescents, indicating an increase in the prevalence of overweight in female children and adolescents from 13.8% in 1999-2000 to 16.0% in 2003-2004 and an increase in the prevalence of overweight in male children and adolescents from 14.0% to 18.2%. Among men, the prevalence of obesity increased significantly between 1999-2000 (27.5%) and 2003-2004 (31.1%). Among women, no significant increase in obesity was observed between 1999-2000 (33.4%) and 2003-2004 (33.2%). The prevalence of extreme obesity (body mass index > or =40) in 2003-2004 was 2.8% in men and 6.9% in women. In 2003-2004, significant differences in obesity prevalence remained by race/ethnicity and by age. Approximately 30% of non-Hispanic white adults were obese as were 45.0% of non-Hispanic black adults and 36.8% of Mexican Americans. Among adults aged 20 to 39 years, 28.5% were obese while 36.8% of adults aged 40 to 59 years and 31.0% of those aged 60 years or older were obese in 2003-2004.The prevalence of overweight among children and adolescents and obesity among men increased significantly during the 6-year period from 1999 to 2004; among women, no overall increases in the prevalence of obesity were observed. These estimates were based on a 6-year period and suggest that the increases in body weight are continuing in men and in children and adolescents while they may be leveling off in women.","['Overweight', 'Medicine', 'Obesity', 'National Health and Nutrition Examination Survey', 'Body mass index', 'Percentile', 'Demography', 'Population', 'Pediatrics', 'Gerontology', 'Environmental health', 'Internal medicine', 'Statistics', 'Mathematics', 'Sociology']","overweight, obesity, ##weight, obesity, adults, national, us, ##weight, ##weight, obesity, adults, extreme obesity, ##weight, ##weight, obesity, women, obesity, extreme obesity, obesity, hispanic, mexican, ##weight"
Paper_01749,Validation and Utility of a Self-report Version of PRIME-MD&lt;SUBTITLE&gt;The PHQ Primary Care Study&lt;/SUBTITLE&gt;,['Robert L. Spitzer'],1999,JAMA,Journal,,1737-1737,282,18,10.1001/jama.282.18.1737,"The Primary Care Evaluation of Mental Disorders (PRIME-MD) was developed as a screening instrument but its administration time has limited its clinical usefulness.To determine if the self-administered PRIME-MD Patient Health Questionnaire (PHQ) has validity and utility for diagnosing mental disorders in primary care comparable to the original clinician-administered PRIME-MD.Criterion standard study undertaken between May 1997 and November 1998.Eight primary care clinics in the United States.Of a total of 3000 adult patients (selected by site-specific methods to avoid sampling bias) assessed by 62 primary care physicians (21 general internal medicine, 41 family practice), 585 patients had an interview with a mental health professional within 48 hours of completing the PHQ.Patient Health Questionnaire diagnoses compared with independent diagnoses made by mental health professionals; functional status measures; disability days; health care use; and treatment/referral decisions.A total of 825 (28%) of the 3000 individuals and 170 (29%) of the 585 had a PHQ diagnosis. There was good agreement between PHQ diagnoses and those of independent mental health professionals (for the diagnosis of any 1 or more PHQ disorder, kappa = 0.65; overall accuracy, 85%; sensitivity, 75%; specificity, 90%), similar to the original PRIME-MD. Patients with PHQ diagnoses had more functional impairment, disability days, and health care use than did patients without PHQ diagnoses (for all group main effects, P<.001). The average time required of the physician to review the PHQ was far less than to administer the original PRIME-MD (<3 minutes for 85% vs 16% of the cases). Although 80% of the physicians reported that routine use of the PHQ would be useful, new management actions were initiated or planned for only 117 (32%) of the 363 patients with 1 or more PHQ diagnoses not previously recognized.Our study suggests that the PHQ has diagnostic validity comparable to the original clinician-administered PRIME-MD, and is more efficient to use.","['Medicine', 'Medical diagnosis', 'Mental health', 'Referral', 'Patient Health Questionnaire', 'Primary care', 'Health care', 'Family medicine', 'Psychiatry', 'Cognition', 'Depressive symptoms', 'Pathology', 'Economics', 'Economic growth']","primary care evaluation of mental disorders, screening, sampling, mental health, mental health, functional status measures, disability days, health, functional impairment, disability days"
Paper_01751,A Closed-Form Solution for Options with Stochastic Volatility with Applications to Bond and Currency Options,['Steven L. Heston'],1993,Review of Financial Studies,Journal,,327-343,6,2,10.1093/rfs/6.2.327,"Journal Article A Closed-Form Solution for Options with Stochastic Volatility with Applications to Bond and Currency Options Get access Steven L. Heston Steven L. Heston Yale University Address correspondence to Steven L. Heston, Yale School of Organization and Management, 135 Prospect Street, New Haven, CT06511. Search for other works by this author on: Oxford Academic Google Scholar The Review of Financial Studies, Volume 6, Issue 2, April 1993, Pages 327–343, https://doi.org/10.1093/rfs/6.2.327 Published: 02 April 2015","['Stochastic volatility', 'Currency', 'Heston model', 'Bond', 'Volatility (finance)', 'Economics', 'Financial economics', 'SABR volatility model', 'Finance', 'Monetary economics']","options, stochastic volatility, bond, currency options, organization, financial studies, [PAD], [PAD], [PAD] [PAD]"
Paper_01752,A survey on Image Data Augmentation for Deep Learning,"['Connor Shorten', 'Taghi M. Khoshgoftaar']",2019,Journal Of Big Data,Journal,,,6,1,10.1186/s40537-019-0197-0,"Deep convolutional neural networks have performed remarkably well on many Computer Vision tasks. However, these networks are heavily reliant on big data to avoid overfitting. Overfitting refers to the phenomenon when a network learns a function with very high variance such as to perfectly model the training data. Unfortunately, many application domains do not have access to big data, such as medical image analysis. This survey focuses on Data Augmentation, a data-space solution to the problem of limited data. Data Augmentation encompasses a suite of techniques that enhance the size and quality of training datasets such that better Deep Learning models can be built using them. The image augmentation algorithms discussed in this survey include geometric transformations, color space augmentations, kernel filters, mixing images, random erasing, feature space augmentation, adversarial training, generative adversarial networks, neural style transfer, and meta-learning. The application of augmentation methods based on GANs are heavily covered in this survey. In addition to augmentation techniques, this paper will briefly discuss other characteristics of Data Augmentation such as test-time augmentation, resolution impact, final dataset size, and curriculum learning. This survey will present existing methods for Data Augmentation, promising developments, and meta-level decisions for implementing Data Augmentation. Readers will understand how Data Augmentation can improve the performance of their models and expand limited datasets to take advantage of the capabilities of big data.","['Computer science', 'Overfitting', 'Deep learning', 'Artificial intelligence', 'Machine learning', 'Big data', 'Artificial neural network', 'Transfer of learning', 'Convolutional neural network', 'Benchmark (surveying)', 'Data science', 'Data mining', 'Geodesy', 'Geography']","deep convolutional neural networks, computer vision tasks, ##fi, medical image analysis, data augmentation, data augmentation, deep learning, image augmentation algorithms, geometric transformations, color space augmentations, kernel filters, mixing images, random erasing, feature space augmentation, adversarial training, generative adversarial networks, neural style transfer, augmentation methods, ##s, resolution impact, final dataset size, curriculum learning, data, data"
Paper_01754,"Addressing Moderated Mediation Hypotheses: Theory, Methods, and Prescriptions","['Kristopher J. Preacher', 'Derek D. Rucker', 'Andrew F. Hayes']",2007,Multivariate Behavioral Research,Journal,,185-227,42,1,10.1080/00273170701341316,"This article provides researchers with a guide to properly construe and conduct analyses of conditional indirect effects, commonly known as moderated mediation effects. We disentangle conflicting definitions of moderated mediation and describe approaches for estimating and testing a variety of hypotheses involving conditional indirect effects. We introduce standard errors for hypothesis testing and construction of confidence intervals in large samples but advocate that researchers use bootstrapping whenever possible. We also describe methods for probing significant conditional indirect effects by employing direct extensions of the simple slopes method and Johnson-Neyman technique for probing significant interactions. Finally, we provide an SPSS macro to facilitate the implementation of the recommended asymptotic and bootstrapping methods. We illustrate the application of these methods with an example drawn from the Michigan Study of Adolescent Life Transitions, showing that the indirect effect of intrinsic student interest on mathematics performance through teacher perceptions of talent is moderated by student math self-concept.","['Bootstrapping (finance)', 'Moderated mediation', 'Mediation', 'Psychology', 'Statistical hypothesis testing', 'Computer science', 'Variety (cybernetics)', 'Econometrics', 'Macro', 'Statistics', 'Social psychology', 'Mathematics', 'Artificial intelligence', 'Political science', 'Law', 'Programming language']","conditional indirect effects, moderated mediation effects, moderated mediation, conditional indirect effects, hypothesis testing, confidence intervals, bootstrapping, significant conditional indirect effects, simple slopes method, significant, spss macro, boots, ##pping, adolescent life transitions, intrinsic student interest, mathematics performance, teacher perceptions of, [PAD], [PAD], [PAD] [PAD], [PAD], [PAD] [PAD]"
Paper_01757,A technique for the measurement of attitudes,['Rensis Likert'],1932,['The SAGE Encyclopedia of Research Design'],Unknown,,,,,10.4135/9781071812082.n626,"THIS paper describes a technique which has been developed for the measurement of race prejudice. technique differs from most prejudice inventories in that it avoids the following assumptions: (a) that the individual can say, to his own or the investigator's satisfaction, This is how prejudiced I am, and (b) that, to the extent that the individual can accurately assess his degree of antipathy, he will report honestly the findings of such introspection. Most sociologists would perhaps agree that race attitudes rarely reside on a completely articulate level. Even where the individual holds to intellectual or ideological convictions which would seem to leave no room for out-group antipathies, such do persevere. Thus, we may expect the number of Americans who honestly think themselves to be considerably larger than effective research would reveal. Moreover, the number who present themselves as unprejudiced probably exceeds considerably the number who honestly, though often inaccurately, see themselves in this light. Most indirect techniques for the measurement of attitudes have their rationale in observations such as these. The instrument to be described here is not, however, indirect in the usual sense of the word; it does not seek responses to items apparently unrelated to the attitudes investigated. We do, however, seek to measure prejudice in a manner less direct than is true of the usual prejudice scale. In our instrument we seek to measure anti-Negro prejudice. Persons are called upon to respond on social distance scales to whites and Negroes who occupy a variety of occupational positions. The measure of prejudice is derived through the summation of the differences in distance responses to Negroes as opposed to whites in the same occupations. Thus, for lack of a better label,","['Antipathy', 'Prejudice (legal term)', 'Social psychology', 'Introspection', 'Race (biology)', 'Ideology', 'Scale (ratio)', 'Psychology', 'Sociology', 'Political science', 'Cognitive psychology', 'Gender studies', 'Geography', 'Law', 'Politics', 'Cartography']","race prejudice, prejudice inventories, race attitudes, attitudes, prejudice, social distance scales"
Paper_01758,The Fluid Mosaic Model of the Structure of Cell Membranes,"['Sherwin J. Singer', 'Garth L. Nicolson']",1972,Science,Journal,,720-731,175,4023,10.1126/science.175.4023.720,"A fluid mosaic model is presented for the gross organization and structure of the proteins and lipids of biological membranes. The model is consistent with the restrictions imposed by thermodynamics. In this model, the proteins that are integral to the membrane are a heterogeneous set of globular molecules, each arranged in an amphipathic structure, that is, with the ionic and highly polar groups protruding from the membrane into the aqueous phase, and the nonpolar groups largely buried in the hydrophobic interior of the membrane. These globular molecules are partially embedded in a matrix of phospholipid. The bulk of the phospholipid is organized as a discontinuous, fluid bilayer, although a small fraction of the lipid may interact specifically with the membrane proteins. The fluid mosaic structure is therefore formally analogous to a two-dimensional oriented solution of integral proteins (or lipoproteins) in the viscous phospholipid bilayer solvent. Recent experiments with a wide variety of techniques and several different membrane systems are described, all of which are consistent with, and add much detail to, the fluid mosaic model. It therefore seems appropriate to suggest possible mechanisms for various membrane functions and membrane-mediated phenomena in the light of the model. As examples, experimentally testable mechanisms are suggested for cell surface changes in malignant transformation, and for cooperative effects exhibited in the interactions of membranes with some specific ligands.","['Membrane', 'Phospholipid', 'Biophysics', 'Elasticity of cell membranes', 'Chemistry', 'Lipid bilayer', 'Biological membrane', 'Bilayer', 'Globular protein', 'Amphiphile', 'Membrane structure', 'Integral membrane protein', 'Molecule', 'Ionic bonding', 'Cell membrane', 'Membrane protein', 'Chemical physics', 'Crystallography', 'Biochemistry', 'Organic chemistry', 'Biology', 'Polymer', 'Ion', 'Copolymer']","fluid mosaic model, lipids, biological membranes, thermodynamics, ##bular molecules, membrane, fluid mosaic structure, lipoproteins, viscous ph, fluid mosaic model, cell surface changes, malignant transformation"
Paper_01759,Global Biodiversity Scenarios for the Year 2100,"['Osvaldo E. Sala', 'F. Stuart Chapin', 'Iii.', 'Juan J. Armestó', 'Eric L. Berlow', 'Janine Bloomfield', 'Rodolfo Dirzo', 'Elisabeth Huber-Sanwald', 'Laura Huenneke', 'Robert B. Jackson', 'Ann P. Kinzig', 'Rik Leemans', 'David M. Lodge', 'Harold A. Mooney', 'Martı́n Oesterheld', 'N. LeRoy Poff', 'Martin T. Sykes', 'Brian Walker', 'Marilyn D. Walker', 'Diana H. Wall']",2000,Science,Journal,,1770-1774,287,5459,10.1126/science.287.5459.1770,"Scenarios of changes in biodiversity for the year 2100 can now be developed based on scenarios of changes in atmospheric carbon dioxide, climate, vegetation, and land use and the known sensitivity of biodiversity to these changes. This study identified a ranking of the importance of drivers of change, a ranking of the biomes with respect to expected changes, and the major sources of uncertainties. For terrestrial ecosystems, land-use change probably will have the largest effect, followed by climate change, nitrogen deposition, biotic exchange, and elevated carbon dioxide concentration. For freshwater ecosystems, biotic exchange is much more important. Mediterranean climate and grassland ecosystems likely will experience the greatest proportional change in biodiversity because of the substantial influence of all drivers of biodiversity change. Northern temperate ecosystems are estimated to experience the least biodiversity change because major land-use change has already occurred. Plausible changes in biodiversity in other biomes depend on interactions among the causes of biodiversity change. These interactions represent one of the largest uncertainties in projections of future biodiversity change.","['Biodiversity', 'Biome', 'Climate change', 'Ecosystem', 'Environmental science', 'Land use, land-use change and forestry', 'Environmental change', 'Land use', 'Temperate climate', 'Ecology', 'Vegetation (pathology)', 'Geography', 'Biology', 'Medicine', 'Pathology']","atmospheric carbon dioxide, land use, terrestrial ecosystems, climate change, nitrogen deposition, biotic exchange, carbon dioxide concentration, freshwater ecosystems, ##tic, mediterranean climate, grassland ecosystems, northern temperate ecosystems"
Paper_01760,"CheckM: assessing the quality of microbial genomes recovered from isolates, single cells, and metagenomes","['Donovan H. Parks', 'Michael Imelfort', 'Connor T. Skennerton', 'Philip Hugenholtz', 'Gene W. Tyson']",2015,Genome Research,Journal,,1043-1055,25,7,10.1101/gr.186072.114,"Donovan H. Parks1, Michael Imelfort1, Connor T. Skennerton1, Philip Hugenholtz1,2 and Gene W. Tyson1,3 1Australian Centre for Ecogenomics, School of Chemistry and Molecular Biosciences, The University of Queensland, St. Lucia, QLD 4072, Queensland, Australia; 2Institute for Molecular Bioscience, The University of Queensland, St. Lucia, QLD 4072, Queensland, Australia; 3Advanced Water Management Centre, The University of Queensland, St. Lucia, QLD 4072, Queensland, Australia Corresponding authors: d.parks{at}uq.edu.au, g.tyson{at}uq.edu.au","['Biology', 'Genome', 'Metagenomics', 'Computational biology', 'Genetics', 'Gene']","##ustralian centre, ecogenomics, molecular biosciences, ##tute, molecular bioscience, ##vanced water management centre, [PAD]"
Paper_01761,Microwave Mobile Communications,"['William C. Jakes', 'D.C. Cox']",1975,Unknown,Unknown,,,,,10.1109/9780470545287,"From the Publisher:
IEEE Press is pleased to bring back into print this definitive text and reference covering all aspects of microwave mobile systems design. Encompassing ten years of advanced research in the field, this invaluable resource reviews basic microwave theory, explains how cellular systems work, and presents useful techniques for effective systems development. The return of this classic volume should be welcomed by all those seeking the original authoritative and complete source of information on this emerging technology. An in-depth and practical guide, Microwave Mobile Communications will provide you with a solid understanding of the microwave propagation techniques essential to the design of effective cellular systems.","['Microwave', 'Computer science', 'Telecommunications', 'Field (mathematics)', 'Resource (disambiguation)', 'Mobile telephony', 'Engineering', 'Systems engineering', 'Multimedia', 'Mobile radio', 'Computer network', 'Mathematics', 'Pure mathematics']","ieee press, microwave mobile systems design, cellular systems, microwave mobile communications, microwave propagation techniques, [PAD], [PAD] [PAD]"
Paper_01762,Markov Decision Processes: Discrete Stochastic Dynamic Programming.,"['Kasra Hazeghi', 'Martin L. Puterman']",1995,Journal of the American Statistical Association,Journal,,392-392,90,429,10.2307/2291177,"From the Publisher:
The past decade has seen considerable theoretical and applied research on Markov decision processes, as well as the growing use of these models in ecology, economics, communications engineering, and other fields where outcomes are uncertain and sequential decision-making processes are needed. A timely response to this increased activity, Martin L. Puterman's new work provides a uniquely up-to-date, unified, and rigorous treatment of the theoretical, computational, and applied research on Markov decision process models. It discusses all major research directions in the field, highlights many significant applications of Markov decision processes models, and explores numerous important topics that have previously been neglected or given cursory coverage in the literature. Markov Decision Processes focuses primarily on infinite horizon discrete time models and models with discrete time spaces while also examining models with arbitrary state spaces, finite horizon models, and continuous-time discrete state models. The book is organized around optimality criteria, using a common framework centered on the optimality (Bellman) equation for presenting results. The results are presented in a theorem-proof format and elaborated on through both discussion and examples, including results that are not available in any other book. A two-state Markov decision process model, presented in Chapter 3, is analyzed repeatedly throughout the book and demonstrates many results and algorithms. Markov Decision Processes covers recent research advances in such areas as countable state space models with average reward criterion, constrained models, and models with risk sensitive optimality criteria. It also explores several topics that have received little or no attention in other books, including modified policy iteration, multichain models with average reward criterion, and sensitive optimality. In addition, a Bibliographic Remarks section in each chapter comments on relevant historic","['Dynamic programming', 'Markov decision process', 'Computer science', 'Markov chain', 'Mathematical optimization', 'Mathematics', 'Markov process', 'Machine learning', 'Statistics']","markov decision processes, communications engineering, markov decision process models, markov decision processes, markov decision processes, infinite horizon discrete time models, discrete time spaces, arbitrary state spaces, finite horizon models, optimality criteria, markov decision processes, countable state space models, average reward criterion, constrained models, risk sensitive optimality criteria, modified policy iteration, multichain models, average reward criterion, sensitive optimality"
Paper_01763,Toxic Potential of Materials at the Nanolevel,"['André E. Nel', 'Tian Xia', 'Lutz Mädler', 'Ning Li']",2006,Science,Journal,,622-627,311,5761,10.1126/science.1114397,"Nanomaterials are engineered structures with at least one dimension of 100 nanometers or less. These materials are increasingly being used for commercial purposes such as fillers, opacifiers, catalysts, semiconductors, cosmetics, microelectronics, and drug carriers. Materials in this size range may approach the length scale at which some specific physical or chemical interactions with their environment can occur. As a result, their properties differ substantially from those bulk materials of the same composition, allowing them to perform exceptional feats of conductivity, reactivity, and optical sensitivity. Possible undesirable results of these capabilities are harmful interactions with biological systems and the environment, with the potential to generate toxicity. The establishment of principles and test procedures to ensure safe manufacture and use of nanomaterials in the marketplace is urgently required and achievable.","['Microelectronics', 'Nanotechnology', 'Nanomaterials', 'Nanometre', 'Materials science', 'Biochemical engineering', 'Engineering', 'Composite material']","nanomaterials, engineered structures, fillers, opacifiers, catalysts, semiconductors, cosmetics, microelectronics, drug carriers, conductivity, reactivity, optical sensitivity, nanomate, ##s, [PAD] [PAD], [PAD] [PAD] [PAD] [PAD] [PAD], [PAD], [PAD] [PAD], [PAD] [PAD] [PAD], [PAD], [PAD] [PAD], [PAD] [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD] [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD], [PAD], [PAD], [PAD] [PAD], [PAD] [PAD], [PAD], [PAD]"
Paper_01764,Short screening scales to monitor population prevalences and trends in non-specific psychological distress,"['Ronald C. Kessler', 'Gavin Andrews', 'Lisa J. Colpe', 'Eva Hiripi', 'Daniel K. Mroczek', 'Sharon‐Lise T. Normand', 'Ellen E. Walters', 'A. M. Zaslavsky']",2002,Psychological Medicine,Journal,,959-976,32,6,10.1017/s0033291702006074,"Background. A 10-question screening scale of psychological distress and a six-question short-form scale embedded within the 10-question scale were developed for the redesigned US National Health Interview Survey (NHIS). Methods. Initial pilot questions were administered in a US national mail survey ( N = 1401). A reduced set of questions was subsequently administered in a US national telephone survey ( N = 1574). The 10-question and six-question scales, which we refer to as the K10 and K6, were constructed from the reduced set of questions based on Item Response Theory models. The scales were subsequently validated in a two-stage clinical reappraisal survey ( N = 1000 telephone screening interviews in the first stage followed by N = 153 face-to-face clinical interviews in the second stage that oversampled first-stage respondents who screened positive for emotional problems) in a local convenience sample. The second-stage sample was administered the screening scales along with the Structured Clinical Interview for DSM-IV (SCID). The K6 was subsequently included in the 1997 ( N = 36116) and 1998 ( N = 32440) US National Health Interview Survey, while the K10 was included in the 1997 ( N = 10641) Australian National Survey of Mental Health and Well-Being. Results. Both the K10 and K6 have good precision in the 90th–99th percentile range of the population distribution (standard errors of standardized scores in the range 0·20–0·25) as well as consistent psychometric properties across major sociodemographic subsamples. The scales strongly discriminate between community cases and non-cases of DSM-IV/SCID disorders, with areas under the Receiver Operating Characteristic (ROC) curve of 0·87–0·88 for disorders having Global Assessment of Functioning (GAF) scores of 0–70 and 0·95–0·96 for disorders having GAF scores of 0–50. Conclusions. The brevity, strong psychometric properties, and ability to discriminate DSM-IV cases from non-cases make the K10 and K6 attractive for use in general-purpose health surveys. The scales are already being used in annual government health surveys in the US and Canada as well as in the WHO World Mental Health Surveys. Routine inclusion of either the K10 or K6 in clinical studies would create an important, and heretofore missing, crosswalk between community and clinical epidemiology.","['National Health Interview Survey', 'Distress', 'Percentile', 'Population', 'Psychology', 'Telephone interview', 'Scale (ratio)', 'Mental health', 'Clinical psychology', 'Medicine', 'Family medicine', 'Psychiatry', 'Demography', 'Statistics', 'Environmental health', 'Geography', 'Social science', 'Mathematics', 'Cartography', 'Sociology']","psychological distress, us national health interview survey, item response theory, emotional problems, psychometric properties, receiver operating characteristic, global assessment of functioning, psychometric properties, government health surveys"
Paper_01765,Practical Meta-Analysis,"['Mark W. Lipsey', 'David B. Wilson']",2000,['JAMA Surgery'],Unknown,,430,155,5,10.1001/jamasurg.2019.4523,"Introduction Problem Specification and Study Retrieval Selecting, Computing and Coding the Effect Size Statistic Developing a Coding Scheme and Coding Study Reports Data Management Analysis Issues and Strategies Computational Techniques for Meta-Analysis Data Interpreting and Using Meta-Analysis Results","['Statistic', 'Computer science', 'Coding (social sciences)', 'Meta-analysis', 'Statistics', 'Mathematics', 'Medicine', 'Internal medicine']","problem specification, study retrieval, effect size statistic, coding scheme, coding, data management analysis"
Paper_01766,Standards of Medical Care in Diabetes,['David V. Power'],2006,Diabetes Care,Journal,,476-476,29,2,10.2337/diacare.29.02.06.dc05-1593,"I write in reference to the recently updated and circulated “Standards of Medical Care in Diabetes,” in particular part II, “Screening for Diabetes,” which were recently updated and published in the American Diabetes Association (ADA) 2006 Clinical Practice Recommendations (1). I would like to take issue with the use of the phrase “standards of medical care in diabetes,” which is used to …","['Medicine', 'Diabetes mellitus', 'Family medicine', 'Medical care', 'Phrase', 'MEDLINE', 'Endocrinology', 'Political science', 'Law', 'Artificial intelligence', 'Computer science']","medical care, american diabetes association, clinical practice, medical care"
Paper_01767,THE DISTRIBUTION AND CHEMICAL COMPOSITION OF ULTRACENTRIFUGALLY SEPARATED LIPOPROTEINS IN HUMAN SERUM,"['Richard J. Havel', 'Howard A. Eder', 'Joseph H. Bragdon']",1955,Journal of Clinical Investigation,Journal,,1345-1353,34,9,10.1172/jci103182,"In the past few years several methods have been developed for the analysis of serum lipoproteins.Lindgren, Elliott, and Gofman (1) have utilized the relatively low density of the lipoproteins to separate them from the other serum proteins by ultracentrifugal flotation.Quantitation was sub- sequently performed by refractometric methods in the analytical ultracentrifuge.Separations of lipoproteins have also been made by Cohn frac- tionation in cold ethanol, and the quantities of lipoprotein have been estimated from the lipid.content of the fractions (2, 3).Widely used at the present time is the method of zone electrophoresis with quantitation either by staining (4) or by chemical analysis of eluates from the support- ing medium (5, 6).Each of these methods has serious limitations.Analytical ultracentrifugal techniques (7, 8) require the possession of expensive equipment.The quantitation of data is subject to considerable error and gives no information regarding the chemi- cal composition of the lipoproteins.Cohn frac- tionation requires facilities for operation at -5°C.It permits accurate determination of the lipid com- ponents of the alpha and beta lipoproteins, but with this technique it is impossible to subfractionate these groups.With certain abnormal sera the method is unreliable (9).Determination of electrophoretically separated fractions by stain- ing techniques or by chemical analysis of eluates is subject to appreciable error.Both Cohn frac- tionation and electrophoretic techniques fail to separate lipoproteins from other serum pro- teins, thus making impossible the study of the protein moiety.The combination of preparative ultracentrifu- gation with chemical analysis of the separated fractions would seem to be a procedure by which both the distribution and composition of lipo- proteins could be determined simply and accu- rately.","['Ultracentrifuge', 'Chemistry', 'Chromatography', 'Electrophoresis', 'Lipoprotein', 'Centrifugation', 'Analytical Ultracentrifugation', 'Biochemistry', 'Cholesterol']","serum lipoproteins, ultracentri, ##rac, analytical ultracentrifuge, cold ethanol, zone electrophoresis, quantitation, staining, chemical analysis, analytical ultracentrifugal techniques"
Paper_01768,COSMO: a new approach to dielectric screening in solvents with explicit expressions for the screening energy and its gradient,"['Andreas Klamt', 'Gerrit Schüürmann']",1993,Journal of the Chemical Society. Perkin transactions II,Journal,,799-805,,5,10.1039/p29930000799,"Starting from the screening in conductors, an algorithm for the accurate calculation of dielectric screening effects in solvents is presented, which leads to rather simple explicit expressions for the screening energy and its analytic gradient with respect to the solute coordinates. Thus geometry optimization of a solute within a realistic dielectric continuum model becomes practicable for the first time. The algorithm is suited for molecular mechanics as well as for any molecular orbital algorithm. The implementation into MOPAC and some example applications are reported.","['Dielectric', 'Simple (philosophy)', 'Molecular orbital', 'Energy (signal processing)', 'Computational chemistry', 'Chemistry', 'Statistical physics', 'Classical mechanics', 'Physics', 'Quantum mechanics', 'Molecule', 'Philosophy', 'Epistemology']","conductors, dielectric screening effects, solvents, screening energy, analytic gradient, solute coordinates, geometry optimization, dielectric continuum model, molecular mechanics, molecular orbital algorithm, mopac, [PAD] [PAD], [PAD] [PAD], [PAD] [PAD], [PAD], [PAD], [PAD] [PAD], [PAD], [PAD] [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD]"
Paper_01769,Rivaroxaban versus Warfarin in Nonvalvular Atrial Fibrillation,"['Manesh R. Patel', 'Kenneth W. Mahaffey', 'Jyotsna Garg', 'Guohua Pan', 'Daniel E. Singer', 'Werner Hacke', 'Günter Breithardt', 'Jonathan L. Halperin', 'Graeme J. Hankey', 'Jonathan P. Piccini', 'Richard C. Becker', 'Christopher C. Nessel', 'John F. Paolini', 'Scott D. Berkowitz', 'Keith A.A. Fox', 'Robert M. Califf']",2011,New England Journal of Medicine,Journal,,883-891,365,10,10.1056/nejmoa1009638,"The use of warfarin reduces the rate of ischemic stroke in patients with atrial fibrillation but requires frequent monitoring and dose adjustment. Rivaroxaban, an oral factor Xa inhibitor, may provide more consistent and predictable anticoagulation than warfarin.","['Rivaroxaban', 'Medicine', 'Warfarin', 'Atrial fibrillation', 'Hazard ratio', 'Stroke (engine)', 'Clinical endpoint', 'Internal medicine', 'Confidence interval', 'Embolism', 'Anesthesia', 'Cardiology', 'Randomized controlled trial', 'Surgery', 'Mechanical engineering', 'Engineering']","warfarin, ischemic stroke, atrial fibrillation, dose adjustment, rivaroxaban, oral factor x, warfarin, [PAD] [PAD], [PAD], [PAD], [PAD], [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD], [PAD], [PAD] [PAD] [PAD] [PAD], [PAD] [PAD], [PAD]"
Paper_01770,Plant Products as Antimicrobial Agents,['M. M. Cowan'],1999,Clinical Microbiology Reviews,Journal,,564-582,12,4,10.1128/cmr.12.4.564,"SUMMARY The use of and search for drugs and dietary supplements derived from plants have accelerated in recent years. Ethnopharmacologists, botanists, microbiologists, and natural-products chemists are combing the Earth for phytochemicals and “leads” which could be developed for treatment of infectious diseases. While 25 to 50% of current pharmaceuticals are derived from plants, none are used as antimicrobials. Traditional healers have long used plants to prevent or cure infectious conditions; Western medicine is trying to duplicate their successes. Plants are rich in a wide variety of secondary metabolites, such as tannins, terpenoids, alkaloids, and flavonoids, which have been found in vitro to have antimicrobial properties. This review attempts to summarize the current status of botanical screening efforts, as well as in vivo studies of their effectiveness and toxicity. The structure and antimicrobial properties of phytochemicals are also addressed. Since many of these compounds are currently available as unregulated botanical preparations and their use by the public is increasing rapidly, clinicians need to consider the consequences of patients self-medicating with these preparations.","['Antimicrobial', 'Traditional medicine', 'Terpenoid', 'Anti-Infective Agents', 'Medicine', 'Biology', 'Biotechnology', 'Toxicology', 'Microbiology', 'Botany']","dietary supplements, ##har, microbio, phytochemicals, infectious diseases, western medicine, tannins, terpenoids, alkaloids, flavonoids, botanical screening, phytochemicals"
Paper_01771,Kinetics of Adsorption on Carbon from Solution,"['Walter J. Weber', 'John C. Morris']",1963,Journal of the Sanitary Engineering Division,Journal,,31-59,89,2,10.1061/jsedai.0000430,"Laboratory investigations show that rates of adsorption of persistent organic compounds on granular carbon are quite low. Intraparticle diffusion of solute appears to control the rate of uptake, thus the rate is partially a function of the pore size distribution of the adsorbent, of the molecular size and configuration of the solute, and of the relative electrokinetic properties of adsorbate and adsorbent. Systemic factors such as temperature and pH will influence the rates of adsorption; rates increase with increasing temperature and decrease with increasing pH. The effect of initial concentration of solute is of considerable significance, the rate of uptake being a linear function of the square-root of concentration within the range of experimentation. Relative reaction rates also vary reciprocally with the square of the diameter of individual carbon particle for a given weight of carbon. Based on the findings of the research, fluidized-bed operation is suggested as an efficient means of using adsorption for treatment of waters and waste waters.","['Adsorption', 'Chemistry', 'Diffusion', 'Carbon fibers', 'Electrokinetic phenomena', 'Particle size', 'Particle (ecology)', 'Fluidized bed', 'Activated carbon', 'Kinetics', 'Chemical engineering', 'Chromatography', 'Thermodynamics', 'Organic chemistry', 'Materials science', 'Physical chemistry', 'Geology', 'Physics', 'Quantum mechanics', 'Composite number', 'Engineering', 'Composite material', 'Oceanography']","adsor, persistent organic compounds, granular carbon, intraparticle diffusion, sol, pore size distribution, ##kinetic properties, adsorbent, adsorption, waste waters"
Paper_01772,Neutrophil Extracellular Traps Kill Bacteria,"['Volker Brinkmann', 'Ulrike Reichard', 'Christian Goosmann', 'Beatrix Fauler', 'Yvonne Uhlemann', 'David S. Weiss', 'Yvette Weinrauch', 'Arturo Zychlinsky']",2004,Science,Journal,,1532-1535,303,5663,10.1126/science.1092385,"Neutrophils engulf and kill bacteria when their antimicrobial granules fuse with the phagosome. Here, we describe that, upon activation, neutrophils release granule proteins and chromatin that together form extracellular fibers that bind Gram-positive and -negative bacteria. These neutrophil extracellular traps (NETs) degrade virulence factors and kill bacteria. NETs are abundant in vivo in experimental dysentery and spontaneous human appendicitis, two examples of acute inflammation. NETs appear to be a form of innate response that binds microorganisms, prevents them from spreading, and ensures a high local concentration of antimicrobial agents to degrade virulence factors and kill bacteria.","['Neutrophil extracellular traps', 'Bacteria', 'Microbiology', 'Extracellular', 'Innate immune system', 'Virulence', 'Biology', 'Antimicrobial', 'Phagosome', 'Inflammation', 'Phagocytosis', 'Cell biology', 'Immune system', 'Immunology', 'Biochemistry', 'Genetics', 'Gene']","neutrophil, ##micro, granule proteins, ch, ##cellular fibers, ne, ##rophil extracellular traps, nets, experimental dysentery, spontaneous human appendicitis, acute inflammation, nets, innate response, [PAD]"
Paper_01777,THE PSYCHOLOGY OF PERSONAL CONSTRUCTS,['George Alexander Kelly'],2010,Taylor & Francis eBooks,Unknown,,1-28,,,10.4324/9780203405321_chapter_1,First published in 1992. Unavailable for many years this is a reissue of George Kelly's classic work. It is the bible of personal construct psychology written by its founder. The second volume presents the implications for clinical practice.,"['Psychology', 'Psychoanalysis']","personal construct psychology, clinical practice, [PAD], [PAD], [PAD], [PAD] [PAD], [PAD], [PAD], [PAD], [PAD]"
Paper_01778,"Synthesis, structure, and spectroscopic properties of copper(<scp>II</scp>) compounds containing nitrogen–sulphur donor ligands; the crystal and molecular structure of aqua[1,7-bis(N-methylbenzimidazol-2′-yl)-2,6-dithiaheptane]copper(<scp>II</scp>) perchlorate","['Anthony W. Addison', 'T. Nageswara Rao', 'J. Reedijk', 'Jacobus Van Rijn', 'G. C. Verschoor']",1984,Journal of the Chemical Society. Dalton transactions,Journal,,1349-1356,,7,10.1039/dt9840001349,"The linear quadridentate N2S2 donor ligand 1,7-bis(N-methylbenzimidazol-2′-yl)-2,6-dithiaheptane (bmdhp) forms mono- and di-hydrate 1 : 1 copper(II) complexes which are significantly more stable toward autoreduction than those of the non-methylated analogue. The deep green monohydrate of the perchlorate salt crystallises as the mononuclear aqua-complex, [Cu(bmdhp)(OH2)][ClO4]2, in the monoclinic space group P21/n, with Z= 4, a= 18.459(3), b= 10.362(2), c= 16.365(3)Å, and β= 117.14(1)°. The structure was solved and refined by standard Patterson, Fourier, and least-squares techniques to R= 0.047 and R′= 0.075 for 3 343 independent reflections with l > 2σ(l). The compound consists of [Cu(bmdhp)(OH2)]2+ ions and ClO4– counter ions. The co-ordination around copper is intermediate between trigonal bipyramidal and square pyramidal, with Cu–N distances of 1.950(4) and 1.997(4)Å, Cu–O(water) 2.225(4)Å, and Cu–S 2.328(1) and 2.337(1)Å. In the solid state, the perchlorate dihydrate's co-ordination sphere may be a topoisomer of the monohydrate's. A new angular structural parameter, τ, is defined and proposed as an index of trigonality, as a general descriptor of five-co-ordinate centric molecules. By this criterion, the irregular co-ordination geometry of [Cu(bmdhp)(OH2)]2+ in the solid state is described as being 48% along the pathway of distortion from square pyramidal toward trigonal bipyramidal. In the electronic spectrum of the complex, assignment is made of the S(thioether)→ Cu charge-transfer bands by comparison with those of the colourless complex Zn(bmdhp)(OH)(ClO4). E.s.r. and ligand-field spectra show that the copper(II) compounds adopt a tetragonal structure in donor solvents.","['Chemistry', 'Trigonal bipyramidal molecular geometry', 'Monoclinic crystal system', 'Perchlorate', 'Crystallography', 'Copper', 'Square pyramidal molecular geometry', 'Crystal structure', 'Ligand (biochemistry)', 'Trigonal pyramidal molecular geometry', 'Hydrate', 'Ion', 'Tetragonal crystal system', 'Coordination sphere', 'Stereochemistry', 'Organic chemistry', 'Biochemistry', 'Receptor']","linear quadridenta, ##inic, colourless complex"
Paper_01779,Room-Temperature Ultraviolet Nanowire Nanolasers,"['Michael H. Huang', 'Samuel S. Mao', 'H. Feick', 'Haoquan Yan', 'Yiying Wu', 'Hannes Kind', 'Eicke R. Weber', 'Richard E. Russo', 'Peidong Yang']",2001,Science,Journal,,1897-1899,292,5523,10.1126/science.1060367,"Room-temperature ultraviolet lasing in semiconductor nanowire arrays has been demonstrated. The self-organized, &lt;0001&gt; oriented zinc oxide nanowires grown on sapphire substrates were synthesized with a simple vapor transport and condensation process. These wide band-gap semiconductor nanowires form natural laser cavities with diameters varying from 20 to 150 nanometers and lengths up to 10 micrometers. Under optical excitation, surface-emitting lasing action was observed at 385 nanometers, with an emission linewidth less than 0.3 nanometer. The chemical flexibility and the one-dimensionality of the nanowires make them ideal miniaturized laser light sources. These short-wavelength nanolasers could have myriad applications, including optical computing, information storage, and microanalysis.","['Nanowire', 'Lasing threshold', 'Materials science', 'Optoelectronics', 'Ultraviolet', 'Sapphire', 'Laser', 'Nanolaser', 'Laser linewidth', 'Semiconductor', 'Nanometre', 'Whispering-gallery wave', 'Photonics', 'Nanotechnology', 'Optics', 'Wavelength', 'Resonator', 'Physics', 'Composite material']","semiconductor nanowire arrays, zinc oxide nanowires, sapphire substrates, vapor transport, condensation process, natural laser cavities, optical, ##aturized laser light sources, optical computing, information storage, microanalysis"
Paper_01783,The Condition of Postmodernity,"['Cole Harris', 'David Harvey']",1991,Economic Geography,Journal,,154-154,67,2,10.2307/143544,"Postmodernism has been particularly important in acknowledging 'the multiple forms of otherness as they emerge from differences in subjectivity, gender and sexuality, race and class, temporal and spatial geographic locations and dislocations'. Postmodernism also ought to be looked at as mimetic of the social, economic, and political practices in society. The meta-narratives that the postmodernists decry were much more open, nuanced, and sophisticated than the critics admit. The rhetoric of postmodernism is dangerous for it avoids confronting the realities of political economy and the circumstances of global power. The sharp categorical distinction between modernism and postmodernism disappears, to be replaced by an examination of the flux of internal relations within capitalism as a whole. The reproduction of the social and symbolic order through the exploration of difference and 'otherness' is all too evident in the climate of postmodernism.","['Postmodernity', 'Geography', 'History', 'Philosophy', 'Epistemology', 'Postmodernism']","postmodernism, otherness, subjectivity, gender, sexuality, class, postmodernism, political, postmodernism, political economy, global power, modernism, postmodernism, internal relations, capitalism, difference, otherness, postmodernism"
Paper_01784,"Self-Determination Theory: Basic Psychological Needs in Motivation, Development, and Wellness",[],2017,Guilford Press eBooks,Unknown,,,,,10.1521/978.14625/28806,"I. Introduction 1. Self-Determination Theory: An Introduction and Overview II. Philosophical and Historical Considerations 2. Organismic Principles: Historical Perspectives on Development and Integration in Living Entities 3. Human Autonomy: Philosophical Perspectives and the Phenomenology of Self 4. Psychological Needs: Varied Concepts and a Preliminary Description of Self-Determination Theory's Approach 5. A Brief History of Intrinsic Motivation III. The Six Mini-Theories of Self-Determination Theory 6. Cognitive Evaluation Theory, Part I: The Effects of Rewards, Feedback, and Other External Events on Intrinsic Motivation 7. Cognitive Evaluation Theory, Part II: Interpersonal and Intrapersonal Processes Affecting Intrinsic Motivation 8. Organismic Integration Theory: Internalization and the Differentiation of Extrinsic Motivation 9. Causality Orientations Theory: Individual Differences in, and Priming of, Motivational Orientations 10. Basic Psychological Needs Theory: Satisfaction and Frustration of Autonomy, Competence, and Relatedness in Relation to Psychological Wellness and Illness 11. Goal Contents Theory: Aspirations, Life Goals, and Their Varied Consequences 12. Relationships Motivation Theory: The Self in Close Relationships IV. Motivation and Human Development in Families, Schools, and Societies 13. Parenting and the Facilitation of Autonomy and Well-Being in Development 14. Schools as Contexts for Learning and Social Development 15. Identity Development, Self-Esteem, and Authenticity 16. Development, Psychological Needs, and Psychopathology V. The Application and Practice of Self-Determination Theory in Multiple Domains 17. Psychotherapy and Behavior Change: Creating Facilitating Environments 18. Health Care and Patient Need Satisfaction: Supporting Maintained Health Behavior Change 19. Sport, Physical Activity, and Physical Education 20. Motivation and Need Satisfaction in Video Games and Virtual Environments 21. Work and Organizations: Promoting Wellness and Productivity VI. Basic Psychological Needs in Pervasive Social Contexts 22. Pervasive Social Influences, Part I: Cultural Contexts 23. Pervasive Social Influences, Part II: Economic and Political Systems 24. On Basic Needs and Human Natures: Altruism, Aggression, and the Bright and Dark Sides of Human Motivation A Very Brief Epilogue References Author Index Subject Index","['Self-determination theory', 'Psychology', 'Intrapersonal communication', 'Cognitive evaluation theory', 'Need theory', 'Competence (human resources)', 'Autonomy', 'Social psychology', ""Maslow's hierarchy of needs"", 'Interpersonal communication', 'Feature integration theory', 'Personal development', 'Developmental stage theories', 'Integrated information theory', 'Goal theory', 'Developmental psychology', 'Cognitive psychology', 'Psychotherapist', 'Neuroscience', 'Political science', 'Law']","organismic principles, human autonomy, psychological needs, intrinsic motivation, cognitive evaluation theory, intrinsic motivation, cognitive evaluation theory, intrinsic motivation, organismic integration, ##ization, extrinsic motivation, causality orientations, individual differences, basic psychological needs, frustration, ##ness, psychological wellness, goal contents, relationships motivation, close relationships, motivation, human development, parenting, social development, identity development, psychotherapy, behavior change, facilitating environments, patient need satisfaction, maintained health behavior change, physical education, need satisfaction, video games, virtual environments, per, ##ive social influences, cultural contexts, pervasive social influences, ##ism, aggression, human motivation, [PAD]"
Paper_01785,Solar Water Splitting Cells,"['Michael G. Walter', 'Emily L. Warren', 'James R. McKone', 'Shannon W. Boettcher', 'Qixi Mi', 'Elizabeth A. Santori', 'Nathan S. Lewis']",2010,Chemical Reviews,Journal,,6446-6473,110,11,10.1021/cr1002326,"ADVERTISEMENT RETURN TO ISSUEPREVReviewNEXTADDITION / CORRECTIONThis article has been corrected. View the notice.Solar Water Splitting CellsMichael G. Walter, Emily L. Warren, James R. McKone, Shannon W. Boettcher†, Qixi Mi, Elizabeth A. Santori, and Nathan S. Lewis*View Author Information Division of Chemistry and Chemical Engineering, 210 Noyes Laboratory, 127-72 California Institute of Technology, Pasadena, California 91125* Corresponding author. E-mail: [email protected]†Current address: Department of Chemistry, University of Oregon, Eugene OR 97403.Cite this: Chem. Rev. 2010, 110, 11, 6446–6473Publication Date (Web):November 10, 2010Publication History Received23 July 2010Published online10 November 2010Published inissue 10 November 2010https://doi.org/10.1021/cr1002326Copyright © 2010 American Chemical SocietyRIGHTS & PERMISSIONSACS AuthorChoiceArticle Views108224Altmetric-Citations7461LEARN ABOUT THESE METRICSArticle Views are the COUNTER-compliant sum of full text article downloads since November 2008 (both PDF and HTML) across all institutions and individuals. These metrics are regularly updated to reflect usage leading up to the last few days.Citations are the number of other articles citing this article, calculated by Crossref and updated daily. Find more information about Crossref citation counts.The Altmetric Attention Score is a quantitative measure of the attention that a research article has received online. Clicking on the donut icon will load a page at altmetric.com with additional details about the score and the social media presence for the given article. Find more information on the Altmetric Attention Score and how the score is calculated. Share Add toView InAdd Full Text with ReferenceAdd Description ExportRISCitationCitation and abstractCitation and referencesMore Options Share onFacebookTwitterWechatLinked InReddit PDF (2 MB) Get e-AlertsSUBJECTS:Catalysts,Electrical conductivity,Electrodes,Photonics,Semiconductors Get e-Alerts","['Notice', 'Citation', 'Social media', 'Library science', 'Altmetrics', 'Computer science', 'World Wide Web', 'Political science', 'Law']","solar water splitting cells, chemical engineering, ##ication, ##sa, metric, ##le, ##f, ##f, altmetric attention score, social, altmetric attention score, ##citation, abstract, ##ation, catalysts, electrical conductivity, electrodes, photonics, semiconductors"
Paper_01786,Memristor-The missing circuit element,['Leon O. Chua'],1971,IEEE Transactions on Circuit Theory,Journal,,507-519,18,5,10.1109/tct.1971.1083337,"A new two-terminal circuit element-called the memristorcharacterized by a relationship between the charge <tex xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">q(t)\equiv \int_{-\infty}^{t} i(\tau) d \tau</tex> and the flux-linkage <tex xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">\varphi(t)\equiv \int_{- \infty}^{t} v(\tau) d \tau</tex> is introduced as the fourth basic circuit element. An electromagnetic field interpretation of this relationship in terms of a quasi-static expansion of Maxwell's equations is presented. Many circuit-theoretic properties of memistors are derived. It is shown that this element exhibits some peculiar behavior different from that exhibited by resistors, inductors, or capacitors. These properties lead to a number of unique applications which cannot be realized with <tex xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">RLC</tex> networks alone. Although a physical memristor device without internal power supply has not yet been discovered, operational laboratory models have been built with the help of active circuits. Experimental results are presented to demonstrate the properties and potential applications of memristors.","['Capacitor', 'Resistor', 'Element (criminal law)', 'Inductor', 'Linearization', 'Electrical element', 'Topology (electrical circuits)', 'RLC circuit', 'Memristor', 'Physics', 'Computer science', 'Electrical engineering', 'Voltage', 'Engineering', 'Quantum mechanics', 'Nonlinear system', 'Political science', 'Law']","memristor, ##ink, electromagnetic field, me, internal power supply, operational laboratory, active circuits, memrist"
Paper_01787,Enrichr: a comprehensive gene set enrichment analysis web server 2016 update,"['Maxim V. Kuleshov', 'Matthew R. Jones', 'Andrew D. Rouillard', 'Nicolas Fernandez', 'Qiaonan Duan', 'Zichen Wang', 'Simon Koplev', 'Sherry L. Jenkins', 'Kathleen M. Jagodnik', 'Alexander Lachmann', 'Michael G. McDermott', 'Caroline D. Monteiro', 'Gregory W. Gundersen', 'Avi Ma’ayan']",2016,Nucleic Acids Research,Journal,,W90-W97,44,W1,10.1093/nar/gkw377,"Enrichment analysis is a popular method for analyzing gene sets generated by genome-wide experiments. Here we present a significant update to one of the tools in this domain called Enrichr. Enrichr currently contains a large collection of diverse gene set libraries available for analysis and download. In total, Enrichr currently contains 180 184 annotated gene sets from 102 gene set libraries. New features have been added to Enrichr including the ability to submit fuzzy sets, upload BED files, improved application programming interface and visualization of the results as clustergrams. Overall, Enrichr is a comprehensive resource for curated gene sets and a search engine that accumulates biological knowledge for further biological discoveries. Enrichr is freely available at: http://amp.pharm.mssm.edu/Enrichr.","['Upload', 'Biology', 'Set (abstract data type)', 'Web server', 'Interface (matter)', 'Visualization', 'Computational biology', 'Gene', 'Application programming interface', 'Genome', 'Gene nomenclature', 'The Internet', 'Computer science', 'Information retrieval', 'World Wide Web', 'Data mining', 'Genetics', 'Programming language', 'Taxonomy (biology)', 'Pulmonary surfactant', 'Biochemistry', 'Gibbs isotherm', 'Botany', 'Nomenclature']","enrichment analysis, gene sets, enrichr, enrichr, enrichr, ##otated, enrichr, fuzzy sets, ##load bed files, application programming interface, cluster, ##s, enrichr, curated gene sets, enrichr, [PAD], [PAD], [PAD], [PAD] [PAD], [PAD] [PAD], [PAD] [PAD] [PAD], [PAD] [PAD], [PAD], [PAD], [PAD], [PAD]"
Paper_01789,Pembrolizumab versus Chemotherapy for PD-L1–Positive Non–Small-Cell Lung Cancer,"['Martin Reck', 'Delvys Rodríguez‐Abreu', 'Andrew Robinson', 'Rina Hui', 'Tibor Csöszi', 'Andrea Fülöp', 'Maya Gottfried', 'Nir Peled', 'Ali Tafreshi', 'Sinéad Cuffe', 'Mary O’Brien', 'Suman Rao', 'Katsuyuki Hotta', 'Melanie A. Leiby', 'Gregory M. Lubiniecki', 'Yue Shentu', 'Reshma Rangwala', 'Julie R. Brahmer']",2016,New England Journal of Medicine,Journal,,1823-1833,375,19,10.1056/nejmoa1606774,"Pembrolizumab is a humanized monoclonal antibody against programmed death 1 (PD-1) that has antitumor activity in advanced non-small-cell lung cancer (NSCLC), with increased activity in tumors that express programmed death ligand 1 (PD-L1).In this open-label, phase 3 trial, we randomly assigned 305 patients who had previously untreated advanced NSCLC with PD-L1 expression on at least 50% of tumor cells and no sensitizing mutation of the epidermal growth factor receptor gene or translocation of the anaplastic lymphoma kinase gene to receive either pembrolizumab (at a fixed dose of 200 mg every 3 weeks) or the investigator's choice of platinum-based chemotherapy. Crossover from the chemotherapy group to the pembrolizumab group was permitted in the event of disease progression. The primary end point, progression-free survival, was assessed by means of blinded, independent, central radiologic review. Secondary end points were overall survival, objective response rate, and safety.Median progression-free survival was 10.3 months (95% confidence interval [CI], 6.7 to not reached) in the pembrolizumab group versus 6.0 months (95% CI, 4.2 to 6.2) in the chemotherapy group (hazard ratio for disease progression or death, 0.50; 95% CI, 0.37 to 0.68; P<0.001). The estimated rate of overall survival at 6 months was 80.2% in the pembrolizumab group versus 72.4% in the chemotherapy group (hazard ratio for death, 0.60; 95% CI, 0.41 to 0.89; P=0.005). The response rate was higher in the pembrolizumab group than in the chemotherapy group (44.8% vs. 27.8%), the median duration of response was longer (not reached [range, 1.9+ to 14.5+ months] vs. 6.3 months [range, 2.1+ to 12.6+]), and treatment-related adverse events of any grade were less frequent (occurring in 73.4% vs. 90.0% of patients), as were grade 3, 4, or 5 treatment-related adverse events (26.6% vs. 53.3%).In patients with advanced NSCLC and PD-L1 expression on at least 50% of tumor cells, pembrolizumab was associated with significantly longer progression-free and overall survival and with fewer adverse events than was platinum-based chemotherapy. (Funded by Merck; KEYNOTE-024 ClinicalTrials.gov number, NCT02142738 .).","['Pembrolizumab', 'Medicine', 'Lung cancer', 'Internal medicine', 'Hazard ratio', 'Oncology', 'Chemotherapy', 'Cancer', 'Gastroenterology', 'Confidence interval', 'Immunotherapy']","pembrolizuma, programmed death, programmed death, ##mal growth factor receptor, objective response rate"
Paper_01791,Development of an Instrument to Measure the Perceptions of Adopting an Information Technology Innovation,"['Gary C. Moore', 'Izak Benbasat']",1991,Information Systems Research,Journal,,192-222,2,3,10.1287/isre.2.3.192,"This paper reports on the development of an instrument designed to measure the various perceptions that an individual may have of adopting an information technology (IT) innovation. This instrument is intended to be a tool for the study of the initial adoption and eventual diffusion of IT innovations within organizations. While the adoption of information technologies by individuals and organizations has been an area of substantial research interest since the early days of computerization, research efforts to date have led to mixed and inconclusive outcomes. The lack of a theoretical foundation for such research and inadequate definition and measurement of constructs have been identified as major causes for such outcomes. In a recent study examining the diffusion of new end-user IT, we decided to focus on measuring the potential adopters' perceptions of the technology. Measuring such perceptions has been termed a “classic issue” in the innovation diffusion literature, and a key to integrating the various findings of diffusion research. The perceptions of adopting were initially based on the five characteristics of innovations derived by Rogers (1983) from the diffusion of innovations literature, plus two developed specifically within this study. Of the existing scales for measuring these characteristics, very few had the requisite levels of validity and reliability. For this study, both newly created and existing items were placed in a common pool and subjected to four rounds of sorting by judges to establish which items should be in the various scales. The objective was to verify the convergent and discriminant validity of the scales by examining how the items were sorted into various construct categories. Analysis of inter-judge agreement about item placement identified both bad items as well as weaknesses in some of the constructs' original definitions. These were subsequently redefined. Scales for the resulting constructs were subjected to three separate field tests. Following the final test, the scales all demonstrated acceptable levels of reliability. Their validity was further checked using factor analysis, as well as conducting discriminant analysis comparing responses between adopters and nonadopters of the innovation. The result is a parsimonious, 38-item instrument comprising eight scales which provides a useful tool for the study of the initial adoption and diffusion of innovations. A short, 25 item, version of the instrument is also suggested.","['Perception', 'Diffusion of innovations', 'Knowledge management', 'Discriminant validity', 'Measure (data warehouse)', 'Reliability (semiconductor)', 'Marketing', 'Information technology', 'Early adopter', 'Computer science', 'Psychology', 'Data science', 'Business', 'Data mining', 'Power (physics)', 'Physics', 'Internal consistency', 'Quantum mechanics', 'Neuroscience', 'Patient satisfaction', 'Operating system']","information technology, it, innovation diffusion, diffusion, reliability, item, factor analysis, ##inant"
Paper_01792,A general and simple method for obtaining <i>R</i><sup>2</sup> from generalized linear mixed‐effects models,"['Shinichi Nakagawa', 'Holger Schielzeth']",2012,Methods in Ecology and Evolution,Journal,,133-142,4,2,10.1111/j.2041-210x.2012.00261.x,"Summary The use of both linear and generalized linear mixed‐effects models ( LMM s and GLMM s) has become popular not only in social and medical sciences, but also in biological sciences, especially in the field of ecology and evolution. Information criteria, such as Akaike Information Criterion ( AIC ), are usually presented as model comparison tools for mixed‐effects models. The presentation of ‘variance explained’ ( R 2 ) as a relevant summarizing statistic of mixed‐effects models, however, is rare, even though R 2 is routinely reported for linear models ( LM s) and also generalized linear models ( GLM s). R 2 has the extremely useful property of providing an absolute value for the goodness‐of‐fit of a model, which cannot be given by the information criteria. As a summary statistic that describes the amount of variance explained, R 2 can also be a quantity of biological interest. One reason for the under‐appreciation of R 2 for mixed‐effects models lies in the fact that R 2 can be defined in a number of ways. Furthermore, most definitions of R 2 for mixed‐effects have theoretical problems (e.g. decreased or negative R 2 values in larger models) and/or their use is hindered by practical difficulties (e.g. implementation). Here, we make a case for the importance of reporting R 2 for mixed‐effects models. We first provide the common definitions of R 2 for LM s and GLM s and discuss the key problems associated with calculating R 2 for mixed‐effects models. We then recommend a general and simple method for calculating two types of R 2 (marginal and conditional R 2 ) for both LMM s and GLMM s, which are less susceptible to common problems. This method is illustrated by examples and can be widely employed by researchers in any fields of research, regardless of software packages used for fitting mixed‐effects models. The proposed method has the potential to facilitate the presentation of R 2 for a wide range of circumstances.","['Generalized linear mixed model', 'Akaike information criterion', 'Mixed model', 'Generalized linear model', 'Linear model', 'Variance (accounting)', 'Mathematics', 'Statistic', 'Statistics', 'Goodness of fit', 'Applied mathematics', 'Econometrics', 'Simple (philosophy)', 'Philosophy', 'Accounting', 'Epistemology', 'Business']","generalized linear mixed ‐ effects models, ##mm, glmm, ecology, evolution, information criteria, ##ike information criterion, mixed ‐ effects models, mixed ‐ effects, mixed ‐ effects models, mixed ‐ effects, mixed ‐ effects, mixed ‐ effects, mixed ‐ effects"
Paper_01794,Human papillomavirus is a necessary cause of invasive cervical cancer worldwide,"['Jan M.M. Walboomers', 'Marcel V. Jacobs', 'M. Michele Manos', 'F. Xavier Bosch', 'J. Alain Kummer', 'Keerti V. Shah', 'Peter J.F. Snijders', 'Julian Peto', 'Chris J.L.M. Meijer', 'Nubia Mu�oz']",1999,The Journal of Pathology,Journal,,12-19,189,1,10.1002/(sici)1096-9896(199909)189:1<12::aid-path431>3.0.co;2-f,"A recent report that 93 per cent of invasive cervical cancers worldwide contain human papillomavirus (HPV) may be an underestimate, due to sample inadequacy or integration events affecting the HPV L1 gene, which is the target of the polymerase chain reaction (PCR)-based test which was used. The formerly HPV-negative cases from this study have therefore been reanalysed for HPV serum antibodies and HPV DNA. Serology for HPV 16 VLPs, E6, and E7 antibodies was performed on 49 of the 66 cases which were HPV-negative and a sample of 48 of the 866 cases which were HPV-positive in the original study. Moreover, 55 of the 66 formerly HPV-negative biopsies were also reanalysed by a sandwich procedure in which the outer sections in a series of sections are used for histological review, while the inner sections are assayed by three different HPV PCR assays targeting different open reading frames (ORFs). No significant difference was found in serology for HPV 16 proteins between the cases that were originally HPV PCR-negative and -positive. Type-specific E7 PCR for 14 high-risk HPV types detected HPV DNA in 38 (69 per cent) of the 55 originally HPV-negative and amplifiable specimens. The HPV types detected were 16, 18, 31, 33, 39, 45, 52, and 58. Two (4 per cent) additional cases were only HPV DNA-positive by E1 and/or L1 consensus PCR. Histological analysis of the 55 specimens revealed that 21 were qualitatively inadequate. Only two of the 34 adequate samples were HPV-negative on all PCR tests, as against 13 of the 21 that were inadequate ( p< 0·001). Combining the data from this and the previous study and excluding inadequate specimens, the worldwide HPV prevalence in cervical carcinomas is 99·7 per cent. The presence of HPV in virtually all cervical cancers implies the highest worldwide attributable fraction so far reported for a specific cause of any major human cancer. The extreme rarity of HPV-negative cancers reinforces the rationale for HPV testing in addition to, or even instead of, cervical cytology in routine cervical screening. Copyright © 1999 John Wiley & Sons, Ltd.","['Serology', 'ORFS', 'Polymerase chain reaction', 'Cervical cancer', 'HPV infection', 'Virology', 'Human papillomavirus', 'Biology', 'Cancer', 'Medicine', 'Antibody', 'Pathology', 'Internal medicine', 'Gene', 'Immunology', 'Open reading frame', 'Genetics', 'Peptide sequence']","invasive cervical cancers, human papillomavirus, hp, sandwich procedure, hpv, open reading frames, cervical carcinomas, hp, cervical cancers, cervical screening"
Paper_01795,Beyond Baron and Kenny: Statistical Mediation Analysis in the New Millennium,['Andrew F. Hayes'],2009,Communication Monographs,Journal,,408-420,76,4,10.1080/03637750903310360,"Click to increase image sizeClick to decrease image size Notes 1. Although the partitioning of a total effect into direct and indirect components in the manner described here does not require the assumption that the errors in estimation are uncorrelated, such intercorrelation can bias parameter estimates and standard errors. Correlated errors can result from, among other things, the exclusion of variables from the model that are correlated with two or more included variables. 2. Otherwise, I agree wholeheartedly with the position Holbert and Stephenson (2003) take in their statement that communication researchers should place much more emphasis on the estimation and testing of indirect effects than they have in the past. 3. Bootstrapping requires the raw data rather than just a covariance matrix. Readers interested in the raw data used in this example can contact me at hayes.338@osu.edu and I will gladly send it. 4. Contrary to conventional wisdom, it is possible (although rare in practice) for a standardized coefficient to be larger than 1 in absolute value (Deegan, 1978 Deegan, J. R. 1978. On the occurrence of standardized regression coefficients greater than 1. Educational and Psychological Measurement, 38: 873–888. [Crossref], [Web of Science ®] , [Google Scholar]). This means that even the standardized indirect effect has no real upper or lower bound.","['Statistics', 'Bootstrapping (finance)', 'Standard error', 'Econometrics', 'Raw data', 'Uncorrelated', 'Value (mathematics)', 'Mediation', 'Computer science', 'Mathematics', 'Psychology', 'Sociology', 'Social science']","image sizeclick, image size, total effect, parameter estimates, correlated errors, communication researchers, covariance matrix, standardized coefficient, standardized regression coefficients, educational, psychological measurement, standardized indirect effect"
Paper_01796,Epigenetic Regulations of GABAergic Neurotransmission: Relevance for Neurological Disorders and Epigenetic Therapy,"['Shikshya Shrestha', 'Steven M. Offer']",2016,Medical Epigenetics,Journal,,1-19,4,1,10.1159/000444713,"Reelin, a large glycoprotein secreted by telencephalic GABAergic neurons, plays an important role in neuronal guidance embryonically and in synaptic plasticity postnatally. The reeler heterozygous mouse (+/rl) appears superficially normal but has been of interest as an animal model for psychosis since the discovery that reelin is 50% down-regulated in postmortem psychotic brain. Brain abnormalities in +/rl are similar to psychotic brain and include a reduction in glutamic acid de carboxylase 67 (GAD67), dendritic arbors and spine density in cortex and hippocampus, and abnormalities in synaptic function including long-term potentiation (LTP). In spite of these abnormalities, behavioral abnormalities in +/rl are subtle and controversial. Recent findings indicate that the reelin (RELN) and GAD67 promoters are hypermethylated in GABAergic neurons of psychotic postmortem brain and that DNA methyltransferase 1 (DNMT1) is up-regulated. Hypermethlyation of RELN and GAD67 promoters can be induced by treating mice with methionine, and these mice display brain and behavioral abnormalities similar to +/rl. Thus, an animal model that combines genetic heterozygocity with epigenesis holds promise for understanding the role of Reelin down-regulation in psychosis.","['Reelin', 'DAB1', 'GABAergic', 'Neuroscience', 'Glutamate decarboxylase', 'Reeler', 'Synaptic plasticity', 'Hippocampus', 'Epigenetics', 'Dendritic spine', 'Psychosis', 'Long-term potentiation', 'Biology', 'Psychology', 'Hippocampal formation', 'Psychiatry', 'Cell biology', 'Genetics', 'Receptor', 'Gene', 'Inhibitory postsynaptic potential', 'Biochemistry', 'Extracellular matrix', 'Enzyme']","reelin, tel, ##lic, synaptic plasticity, reel, psychosis, reel, dendritic arbors, spine density, synaptic function, dna, psycho"
Paper_01797,"Synthesis and characterization of nearly monodisperse CdE (E = sulfur, selenium, tellurium) semiconductor nanocrystallites","['C. B. Murray', 'David J. Norris', 'Moungi G. Bawendi']",1993,Journal of the American Chemical Society,Journal,,8706-8715,115,19,10.1021/ja00072a025,"ADVERTISEMENT RETURN TO ISSUEPREVArticleNEXTSynthesis and characterization of nearly monodisperse CdE (E = sulfur, selenium, tellurium) semiconductor nanocrystallitesC. B. Murray, D. J. Norris, and M. G. BawendiCite this: J. Am. Chem. Soc. 1993, 115, 19, 8706–8715Publication Date (Print):September 1, 1993Publication History Published online1 May 2002Published inissue 1 September 1993https://pubs.acs.org/doi/10.1021/ja00072a025https://doi.org/10.1021/ja00072a025research-articleACS PublicationsRequest reuse permissionsArticle Views65449Altmetric-Citations7838LEARN ABOUT THESE METRICSArticle Views are the COUNTER-compliant sum of full text article downloads since November 2008 (both PDF and HTML) across all institutions and individuals. These metrics are regularly updated to reflect usage leading up to the last few days.Citations are the number of other articles citing this article, calculated by Crossref and updated daily. Find more information about Crossref citation counts.The Altmetric Attention Score is a quantitative measure of the attention that a research article has received online. Clicking on the donut icon will load a page at altmetric.com with additional details about the score and the social media presence for the given article. Find more information on the Altmetric Attention Score and how the score is calculated. Share Add toView InAdd Full Text with ReferenceAdd Description ExportRISCitationCitation and abstractCitation and referencesMore Options Share onFacebookTwitterWechatLinked InRedditEmail Other access optionsGet e-Alertsclose Get e-Alerts","['Citation', 'Tellurium', 'Dispersity', 'Computer science', 'Selenium', 'Library science', 'Information retrieval', 'Chemistry', 'Organic chemistry']","##varticlene, ##pers, semiconductor nanocryst, ##sar, ##le, metric, ##le, altmetric attention score, social, altmetric attention score, ##d, ##riscitation, ##ation, abstract, ##ation, references"
Paper_01731,Open Babel: An open chemical toolbox,"[""N.M. O'Boyle"", 'Michael Banck', 'Craig A. James', 'Chris Morley', 'Tim Vandermeersch', 'Geoffrey Hutchison']",2011,Journal of Cheminformatics,Journal,,,3,1,10.1186/1758-2946-3-33,"A frequent problem in computational modeling is the interconversion of chemical structures between different formats. While standard interchange formats exist (for example, Chemical Markup Language) and de facto standards have arisen (for example, SMILES format), the need to interconvert formats is a continuing problem due to the multitude of different application areas for chemistry data, differences in the data stored by different formats (0D versus 3D, for example), and competition between software along with a lack of vendor-neutral formats.We discuss, for the first time, Open Babel, an open-source chemical toolbox that speaks the many languages of chemical data. Open Babel version 2.3 interconverts over 110 formats. The need to represent such a wide variety of chemical and molecular data requires a library that implements a wide range of cheminformatics algorithms, from partial charge assignment and aromaticity detection, to bond order perception and canonicalization. We detail the implementation of Open Babel, describe key advances in the 2.3 release, and outline a variety of uses both in terms of software products and scientific research, including applications far beyond simple format interconversion.Open Babel presents a solution to the proliferation of multiple chemical file formats. In addition, it provides a variety of useful utilities from conformer searching and 2D depiction, to filtering, batch conversion, and substructure and similarity searching. For developers, it can be used as a programming library to handle chemical data in areas such as organic chemistry, drug design, materials science, and computational chemistry. It is freely available under an open-source license from http://openbabel.org.","['Cheminformatics', 'Computer science', 'Toolbox', 'Chemical database', 'Variety (cybernetics)', 'World Wide Web', 'Software', 'File format', 'Chemical similarity', 'Data science', 'Information retrieval', 'Chemistry', 'Database', 'Programming language', 'Artificial intelligence', 'Computational chemistry', 'Organic chemistry', 'Cluster analysis']","computational modeling, chemical structures, interchange formats, chemical markup language, smiles, chemistry data, open, ##l, open, cheminformatics algorithms, partial charge assignment, aromaticity detection, bond order perception, canonicalization, open babel, open babel, conformer searching, 2d depiction, filtering, batch conversion, similarity searching, organic chemistry, drug design, materials science, computational chemistry, ##ba, [PAD], [PAD] [PAD], [PAD], [PAD] [PAD]"
Paper_01732,PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation,"['Raffaelli Charles', 'Hao Su', 'Kaichun Mo', 'Leonidas Guibas']",2017,Unknown,Unknown,,77-85,,,10.1109/cvpr.2017.16,"Point cloud is an important type of geometric data structure. Due to its irregular format, most researchers transform such data to regular 3D voxel grids or collections of images. This, however, renders data unnecessarily voluminous and causes issues. In this paper, we design a novel type of neural network that directly consumes point clouds, which well respects the permutation invariance of points in the input. Our network, named PointNet, provides a unified architecture for applications ranging from object classification, part segmentation, to scene semantic parsing. Though simple, PointNet is highly efficient and effective. Empirically, it shows strong performance on par or even better than state of the art. Theoretically, we provide analysis towards understanding of what the network has learnt and why the network is robust with respect to input perturbation and corruption.","['Point cloud', 'Computer science', 'Segmentation', 'Artificial intelligence', 'Parsing', 'Deep learning', 'Convolutional neural network', 'Point (geometry)', 'Architecture', 'Artificial neural network', 'Pattern recognition (psychology)', 'Geometry', 'Mathematics', 'Art', 'Visual arts']","point cloud, geometric data structure, 3d voxel grids, neural network, point clouds, permutation invariance, pointnet, unified architecture, object classification, part segmentation, scene semantic parsing, pointnet"
Paper_01734,The Amber biomolecular simulation programs,"['David A. Case', 'Thomas E. Cheatham', 'Tom Darden', 'Holger Gohlke', 'Ray Luo', 'Kenneth M. Merz', 'Alexey V. Onufriev', 'Carlos Simmerling', 'Bing Wang', 'Robert J. Woods']",2005,Journal of Computational Chemistry,Journal,,1668-1688,26,16,10.1002/jcc.20290,"We describe the development, current features, and some directions for future development of the Amber package of computer programs. This package evolved from a program that was constructed in the late 1970s to do Assisted Model Building with Energy Refinement, and now contains a group of programs embodying a number of powerful tools of modern computational chemistry, focused on molecular dynamics and free energy calculations of proteins, nucleic acids, and carbohydrates. © 2005 Wiley Periodicals, Inc. J Comput Chem 26: 1668–1688, 2005","['Salt lake', 'Library science', 'Marie curie', 'Chemistry', 'Engineering', 'Computer science', 'Biology', 'Paleontology', 'European union', 'Structural basin', 'Business', 'Economic policy']","amber, computer programs, assisted model building, energy refinement, computational chemistry, molecular dynamics, free energy calculations, proteins, nucleic, ##hydra, wiley"
Paper_01735,Assessing coping strategies: A theoretically based approach.,"['Charles S. Carver', 'M F Scheier', 'Jagdish K. Weintraub']",1989,Journal of Personality and Social Psychology,Journal,,267-283,56,2,10.1037//0022-3514.56.2.267,"We developed a multidimensional coping inventory to assess the different ways in which people respond to stress. Five scales (of four items each) measure conceptually distinct aspects of problem-focused coping (active coping, planning, suppression of competing activities, restraint coping, seeking of instrumental social support); five scales measure aspects of what might be viewed as emotional-focused coping (seeking of emotional social support, positive reinterpretation, acceptance, denial, turning to religion); and three scales measure coping responses that arguably are less useful (focus on and venting of emotions, behavioral disengagement, mental disengagement). Study 1 reports the development of scale items. Study 2 reports correlations between the various coping scales and several theoretically relevant personality measures in an effort to provide preliminary information about the inventory's convergent and discriminant validity. Study 3 uses the inventory to assess coping responses among a group of undergraduates who were attempting to cope with a specific stressful episode. This study also allowed an initial examination of associations between dispositional and situational coping tendencies.","['Psychology', 'Coping (psychology)', 'Disengagement theory', 'Situational ethics', 'Denial', 'Social psychology', 'Personality', 'Discriminant validity', 'Developmental psychology', 'Clinical psychology', 'Psychometrics', 'Psychotherapist', 'Gerontology', 'Medicine', 'Internal consistency']","multidimensional coping inventory, active coping, restraint coping, instrumental social support, coping, behavioral disengagement, mental disengagement, ##al coping"
Paper_01736,RNA-Guided Human Genome Engineering via Cas9,"['Prashant Mali', 'Luhan Yang', 'Kevin M. Esvelt', 'John Aach', 'Marc Güell', 'James J. DiCarlo', 'Julie E. Norville', 'George M. Church']",2013,Science,Journal,,823-826,339,6121,10.1126/science.1232033,"Bacteria and archaea have evolved adaptive immune defenses, termed clustered regularly interspaced short palindromic repeats (CRISPR)/CRISPR-associated (Cas) systems, that use short RNA to direct degradation of foreign nucleic acids. Here, we engineer the type II bacterial CRISPR system to function with custom guide RNA (gRNA) in human cells. For the endogenous AAVS1 locus, we obtained targeting rates of 10 to 25% in 293T cells, 13 to 8% in K562 cells, and 2 to 4% in induced pluripotent stem cells. We show that this process relies on CRISPR components; is sequence-specific; and, upon simultaneous introduction of multiple gRNAs, can effect multiplex editing of target loci. We also compute a genome-wide resource of ~190 K unique gRNAs targeting ~40.5% of human exons. Our results establish an RNA-guided editing tool for facile, robust, and multiplexable human genome engineering.","['CRISPR', 'Guide RNA', 'Biology', 'Genome editing', 'Cas9', 'RNA', 'Computational biology', 'Genome', 'Genetics', 'Genome engineering', 'Human genome', 'Gene']","adaptive immune defenses, short, foreign nucleic acids, custom guide rna, 293, induced pluripotent stem cells, multiplex editing, multiple, ##ble human genome engineering"
Paper_01737,EVOLUTION IN MENDELIAN POPULATIONS,['Sewall Wright'],1931,Genetics,Journal,,97-159,16,2,10.1093/genetics/16.2.97,"Page 108, last line of text, for P/P″ read P′/P″.

Page 120, last line, for δ v  read δ y .

Page 123, line 10, for 4Nn read 4Nu.

Page 125, line 1, for q read q.

Page 126, line 12, for q read q.

Page 135, line 5 from bottom, for y4Nsq read e4Nsq.

Page 141, lines 8","['Biology', 'Mendelian inheritance', 'Genetics', 'Evolutionary biology', 'Gene']",
Paper_01738,Reading images: the grammar of visual design,"['Gunther R. Kress', 'Theo van Leeuwen']",1996,Choice Reviews Online,Journal,,34-1950,34,04,10.5860/choice.34-1950,Introduction 1. The Semiotic Landscape 2. Narrative Representations: Designing Social Action 3. Conceptual Representations: Designing Social Constructs 4. Representation and Interaction: Designing the Position of the Viewer 5. Morality: Designing Models of Reality 6. The Meaning of Composition 7. The Materiality of Meaning - Surface and Inscription 8. The Third Dimension,"['Materiality (auditing)', 'Semiotics', 'Narrative', 'Meaning (existential)', 'Linguistics', 'Grammar', 'Representation (politics)', 'Reading (process)', 'Aesthetics', 'Action (physics)', 'Computer science', 'Cognitive science', 'Communication', 'Sociology', 'Psychology', 'Art', 'Epistemology', 'Philosophy', 'Politics', 'Physics', 'Quantum mechanics', 'Political science', 'Law']","semiotic landscape, narrative representations, social action, conceptual representations, social constructs, morality, ##ity, [PAD], [PAD]"
Paper_01739,Dynamic Source Routing in Ad Hoc Wireless Networks,"['David B. Johnson', 'David A. Maltz']",2007,Mobile computing,Journal,,153-181,,,10.1007/978-0-585-29603-6_5,"An ad hoc network is a collection of wireless mobile hosts forming a temporary network without the aid of any established infrastructure or centralized administration. In such an environment, it may be necessary for one mobile host to enlist the aid of other hosts in forwarding a packet to its destination, due to the limited range of each mobile host’s wireless transmissions. This paper presents a protocol for routing in ad hoc networks that uses dynamic source routing. The protocol adapts quickly to routing changes when host movement is frequent, yet requires little or no overhead during periods in which hosts move less frequently. Based on results from a packet-level simulation of mobile hosts operating in an ad hoc network, the protocol performs well over a variety of environmental conditions such as host density and movement rates. For all but the highest rates of host movement simulated, the overhead of the protocol is quite low, falling to just 1% of total data packets transmitted for moderate movement rates in a network of 24 mobile hosts. In all cases, the difference in length between the routes used and the optimal route lengths is negligible, and in most cases, route lengths are on average within a factor of 1.01 of optimal.","['Computer network', 'Computer science', 'Optimized Link State Routing Protocol', 'Wireless Routing Protocol', 'Mobile ad hoc network', 'Wireless ad hoc network', 'Adaptive quality of service multi-hop routing', 'Host (biology)', 'Ad hoc wireless distribution service', 'Routing protocol', 'Dynamic Source Routing', 'Network packet', 'Destination-Sequenced Distance Vector routing', 'Overhead (engineering)', 'Distributed computing', 'Wireless', 'Telecommunications', 'Biology', 'Operating system', 'Ecology']","ad hoc network, wireless mobile hosts, ad hoc networks, dynamic source routing, ad hoc network, host density, movement rates"
Paper_01742,Human Domination of Earth's Ecosystems,"['Peter M. Vitousek', 'Harold A. Mooney', 'Jane Lubchenco', 'Jerry M. Melillo']",1997,Science,Journal,,494-499,277,5325,10.1126/science.277.5325.494,"Human alteration of Earth is substantial and growing. Between one-third and one-half of the land surface has been transformed by human action; the carbon dioxide concentration in the atmosphere has increased by nearly 30 percent since the beginning of the Industrial Revolution; more atmospheric nitrogen is fixed by humanity than by all natural terrestrial sources combined; more than half of all accessible surface fresh water is put to use by humanity; and about one-quarter of the bird species on Earth have been driven to extinction. By these and other standards, it is clear that we live on a human-dominated planet.","['Earth (classical element)', 'Humanity', 'Atmosphere (unit)', 'Astrobiology', 'Natural (archaeology)', 'Ecosystem', 'Planet', 'Environmental science', ""Carbon dioxide in Earth's atmosphere"", 'Terrestrial ecosystem', 'Earth science', 'Carbon dioxide', 'Ecology', 'Geography', 'Biology', 'Geology', 'Meteorology', 'Law', 'Archaeology', 'Political science', 'Physics', 'Astronomy']","carbon, atmospheric nitrogen"
Paper_01745,The Behavioral Consequences of Service Quality,"['Valarie A. Zeithaml', 'Leonard L. Berry', 'A. Parasuraman']",1996,Journal of Marketing,Journal,,31-31,60,2,10.2307/1251929,"If service quality relates to retention of customers at the aggregate level, as other research has indicated, then evidence of its impact on customers' behavioral responses should be detectable. The authors offer a conceptual model of the impact of service quality on particular behaviors that signal whether customers remain with or defect from a company. Results from a multicompany empirical study examining relationships from the model concerning customers' behavioral intentions show strong evidence of their being influenced by service quality. The findings also reveal differences in the nature of the quality-intentions link across different dimensions of behavioral intentions. The authors' discussion centers on ways the results and research approach of their study can be helpful to researchers and managers.","['Service quality', 'Quality (philosophy)', 'Service (business)', 'Conceptual model', 'Marketing', 'Empirical research', 'Psychology', 'Business', 'Behavioral modeling', 'Empirical evidence', 'Computer science', 'Philosophy', 'Epistemology', 'Database', 'Artificial intelligence']","service quality, behavioral responses, service quality, multicompany, behavioral intentions, service, behavioral intentions"
Paper_01746,Statistical-Mechanical Theory of Irreversible Processes. I. General Theory and Simple Applications to Magnetic and Conduction Problems,['Ryogo Kubo'],1957,Journal of the Physical Society of Japan,Journal,,570-586,12,6,10.1143/jpsj.12.570,"A general type of fluctuation-dissipation theorem is discussed to show that the physical quantities such as complex susceptibility of magnetic or electric polarization and complex conductivity for electric conduction are rigorously expressed in terms of time-fluctuation of dynamical variables associated with such irreversible processes. This is a generalization of statistical mechanics which affords exact formulation as the basis of calculation of such irreversible quantities from atomistic theory. The general formalism of this statistical-mechanical theory is examined in detail. The response, relaxation, and correlation functions are defined in quantummechanical way and their relations are investigated. The formalism is illustrated by simple examples of magnetic and conduction problems. Certain sum rules are discussed for these examples. Finally it is pointed out that this theory may be looked as a generalization of the Einstein relation.","['Formalism (music)', 'Thermal conduction', 'Einstein relation', 'Statistical physics', 'Generalization', 'Statistical mechanics', 'Physics', 'General theory', 'Simple (philosophy)', 'Microscopic theory', 'Classical mechanics', 'Theoretical physics', 'Quantum mechanics', 'Mathematics', 'Mathematical analysis', 'Philosophy', 'Epistemology', 'Art', 'Musical', 'Metric (unit)', 'Operations management', 'Economics', 'Visual arts']","complex susceptibility, electric polarization, complex conductivity, electric conduction, ##al variables, ir, ##versible processes, statistical mechanics, ##versible, atomistic theory, correlation functions, ##ion, sum rules, einstein relation"
Paper_01747,Bayesian Data Analysis,"['Andrew Gelman', 'John B. Carlin', 'Hal S. Stern', 'David B. Dunson', 'Aki Vehtari', 'Donald B. Rubin']",2013,Chapman and Hall/CRC eBooks,Unknown,,,,,10.1201/b16018,"Winner of the 2016 De Groot Prize from the International Society for Bayesian AnalysisNow in its third edition, this classic book is widely considered the leading text on Bayesian methods, lauded for its accessible, practical approach to analyzing data and solving research problems. Bayesian Data Analysis, Third Edition continues to take an applied","['Bayesian probability', 'Computer science', 'Econometrics', 'Artificial intelligence', 'Mathematics']","bayesian analysis, bayesian methods, bayesian data analysis"
Paper_01748,"Computer ""Experiments"" on Classical Fluids. I. Thermodynamical Properties of Lennard-Jones Molecules",['Loup Verlet'],1967,Physical Review,Journal,,98-103,159,1,10.1103/physrev.159.98,"The equation of motion of a system of 864 particles interacting through a Lennard-Jones potential has been integrated for various values of the temperature and density, relative, generally, to a fluid state. The equilibrium properties have been calculated and are shown to agree very well with the corresponding properties of argon. It is concluded that, to a good approximation, the equilibrium state of argon can be described through a two-body potential.","['Lennard-Jones potential', 'Equation of state', 'Argon', 'Physics', 'Thermodynamics', 'Molecular dynamics', 'Statistical physics', 'Classical mechanics', 'Atomic physics', 'Quantum mechanics']","fluid state, equilibrium properties, argon"
Paper_01749,Minimal information for studies of extracellular vesicles 2018 (MISEV2018): a position statement of the International Society for Extracellular Vesicles and update of the MISEV2014 guidelines,"['Clotilde Théry', 'Kenneth W. Witwer', 'Elena Aïkawa', 'María José Alcaraz', 'Johnathon D. Anderson', 'Ramaroson Andriantsitohaina', 'Anna Antoniou', 'Tanina Arab', 'Fabienne Archer', 'Georgia K. Atkin‐Smith', 'D. Craig Ayre', 'Jean‐Marie Bach', 'Daniel Bachurski', 'Hossein Baharvand', 'Leonora Balaj', 'Shawn Baldacchino', 'Natalie Bauer', 'Amy A. Baxter', 'Mary Bebawy', 'Carla Beckham', 'Apolonija Bedina Zavec', 'Abderrahim Benmoussa', 'Anna C. Berardi', 'Paolo Bergese', 'Ewa Bielska', 'Cherie Blenkiron', 'Sylwia Bobis‐Wozowicz', 'Éric Boilard', 'Wilfrid Boireau', 'Antonella Bongiovanni', 'Francesc E. Borràs', 'Steffi Bösch', 'Chantal M. Boulanger', 'Xandra O. Breakefield', 'Andrew Breglio', 'Meadhbh Á. Brennan', 'David R. Brigstock', 'Alain Brisson', 'Marike L. D. Broekman', 'Jacqueline Bromberg', 'Paulina Bryl‐Górecka', 'Shilpa Buch', 'Amy H. Buck', 'Dylan Burger', 'Sara Busatto', 'Dominik Buschmann', 'Benedetta Bussolati', 'Edit I. Buzás', 'James Brian Byrd', 'Giovanni Camussi', 'David R. F. Carter', 'Sarah Caruso', 'Lawrence W. Chamley', 'Yu‐Ting Chang', 'Chihchen Chen', 'Daiwen Chen', 'Lesley Cheng', 'Andrew R. Chin', 'Aled Clayton', 'Stefano Piatto Clerici', 'Alex Cocks', 'Emanuele Cocucci', 'Robert J. Coffey', 'Anabela Cordeiro‐da‐Silva', 'Yvonne Couch', 'Frank A. W. Coumans', 'Beth Coyle', 'Rossella Crescitelli', 'Miriã Ferreira Criado', 'Crislyn D’Souza‐Schorey', 'Saumya Das', 'Amrita Datta Chaudhuri', 'Paola de Candia', 'Eliezer F De Santana', 'Olivier De Wever', 'Hernando A. del Portillo', 'Tanguy Demaret', 'Sarah Deville', 'Andrew Devitt', 'Bert Dhondt', 'Dolores Di Vizio', 'Lothar C. Dieterich', 'Vincenza Dolo', 'Ana Paula Domínguez Rubio', 'Massimo Dominici', 'Maurício Rocha Dourado', 'Tom A. P. Driedonks', 'Filipe V. Duarte', 'Heather M. Duncan', 'Ramon M. Eichenberger', 'Karin M. Ekström', 'Samir EL Andaloussi', 'Céline Élie-Caille', 'Uta Erdbrügger', 'Juan Manuel Falcón‐Pérez', 'Farah Fatima', 'Jason E. Fish', 'Miguel Flores‐Bellver', 'András Försönits', 'Annie Frelet‐Barrand']",2018,Journal of Extracellular Vesicles,Journal,,,7,1,10.1080/20013078.2018.1535750,"ABSTRACT The last decade has seen a sharp increase in the number of scientific publications describing physiological and pathological functions of extracellular vesicles (EVs), a collective term covering various subtypes of cell‐released, membranous structures, called exosomes, microvesicles, microparticles, ectosomes, oncosomes, apoptotic bodies, and many other names. However, specific issues arise when working with these entities, whose size and amount often make them difficult to obtain as relatively pure preparations, and to characterize properly. The International Society for Extracellular Vesicles (ISEV) proposed Minimal Information for Studies of Extracellular Vesicles (“MISEV”) guidelines for the field in 2014. We now update these “MISEV2014” guidelines based on evolution of the collective knowledge in the last four years. An important point to consider is that ascribing a specific function to EVs in general, or to subtypes of EVs, requires reporting of specific information beyond mere description of function in a crude, potentially contaminated, and heterogeneous preparation. For example, claims that exosomes are endowed with exquisite and specific activities remain difficult to support experimentally, given our still limited knowledge of their specific molecular machineries of biogenesis and release, as compared with other biophysically similar EVs. The MISEV2018 guidelines include tables and outlines of suggested protocols and steps to follow to document specific EV‐associated functional activities. Finally, a checklist is provided with summaries of key points.","['Microvesicles', 'Extracellular vesicles', 'Function (biology)', 'Biogenesis', 'Extracellular vesicle', 'Vesicle', 'Microvesicle', 'Exosome', 'Biology', 'Computational biology', 'Computer science', 'Cell biology', 'Biochemistry', 'microRNA', 'Membrane', 'Gene']","pathological functions, extracellular vesicles, membranous structures, exosomes, microvesicles, microparticles, ectosomes, oncosomes, apoptotic bodies, international, extracellular vesicles, extracellular vesicles, misev20, ex, ##20"
Paper_01750,Seeking Qualitative Rigor in Inductive Research,"['Dennis A. Gioia', 'Kevin G. Corley', 'Aimee L. Hamilton']",2012,Organizational Research Methods,Journal,,15-31,16,1,10.1177/1094428112452151,"For all its richness and potential for discovery, qualitative research has been critiqued as too often lacking in scholarly rigor. The authors summarize a systematic approach to new concept development and grounded theory articulation that is designed to bring “qualitative rigor” to the conduct and presentation of inductive research.","['Qualitative research', 'Rigour', 'Grounded theory', 'Articulation (sociology)', 'Presentation (obstetrics)', 'Epistemology', 'Psychology', 'Engineering ethics', 'Sociology', 'Social science', 'Political science', 'Medicine', 'Philosophy', 'Politics', 'Law', 'Radiology', 'Engineering']","qualitative research, concept development, grounded theory articulation, qualitative rigor, inductive research, [PAD], [PAD] [PAD], [PAD], [PAD]"
Paper_01751,YALMIP : a toolbox for modeling and optimization in MATLAB,['Johan Löfberg'],2005,Unknown,Unknown,,284-289,,,10.1109/cacsd.2004.1393890,"The MATLAB toolbox YALMIP is introduced. It is described how YALMIP can be used to model and solve optimization problems typically occurring in systems and control theory. In this paper, free MATLAB toolbox YALMIP, developed initially to model SDPs and solve these by interfacing eternal solvers. The toolbox makes development of optimization problems in general, and control oriented SDP problems in particular, extremely simple. In fact, learning 3 YALMIP commands is enough for most users to model and solve the optimization problems","['Toolbox', 'MATLAB', 'Interfacing', 'Computer science', 'Simple (philosophy)', 'Optimization problem', 'Mathematical optimization', 'Algorithm', 'Programming language', 'Mathematics', 'Computer hardware', 'Philosophy', 'Epistemology']","matlab toolbox yalmip, yalmip, optimization problems, control theory, matlab toolbox ya, sdps, eternal solvers, optimization, control oriented sdp problems, yalmip, [PAD], [PAD] [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD], [PAD]"
Paper_01753,Estimating causal effects of treatments in randomized and nonrandomized studies.,['Donald B. Rubin'],1974,Journal of Educational Psychology,Journal,,688-701,66,5,10.1037/h0037350,"A discussion of matching, randomization, random sampling, and other methods of controlling extraneous variation is presented. The objective is to specify the benefits of randomization in estimating causal effects of treatments. The basic conclusion is that randomization should be employed whenever possible but that the use of carefully controlled nonrandomized data to estimate causal effects is a reasonable and necessary procedure in many cases. Recent psychological and educational literature has included extensive criticism of the use of nonrandomized studies to estimate causal effects of treatments (e.g., Campbell & Erlebacher, 1970). The implication in much of this literature is that only properly randomized experiments can lead to useful estimates of causal effects. If taken as applying to all fields of study, this position is untenable. Since the extensive use of randomized experiments is limited to the last half century,8 and in fact is not used in much scientific investigation today,4 one is led to the conclusion that most scientific truths have been established without using randomized experiments. In addition, most of us successfully determine the causal effects of many of our everyday actions, even interpersonal behaviors, without the benefit of randomization. Even if the position that causal effects of treatments can only be well established from randomized experiments is taken as applying only to the social sciences in which","['Psychology', 'Randomized controlled trial', 'Developmental psychology', 'Cognitive psychology', 'Clinical psychology', 'Medicine', 'Surgery']","matching, randomization, random sampling, extraneous variation, randomization, causal effects, randomization, ##randomized data, causal effects, nonrandomized studies, causal effects, random, causal effects, randomized experiments, randomized experiments, causal effects, interpersonal behaviors, causal effects, randomized experiments, social"
Paper_01755,Cannibals with forks: the triple bottom line of 21st century business,['John Elkington'],1999,Choice Reviews Online,Journal,,36-3997,36,07,10.5860/choice.36-3997,"Introduction - is capitalism sustainable? seven revolutions for sustainable capitalism revolution 1 - competition - going for the triple win revolution 2 - values - from me to we revolution 3 - information and transparency - no hiding place revolution 4 - lifecylces - from conception to resurrection revolution 5 - partnerships - after the honeymoon revolution 6 - time - three scenarios revolution 7 - corporate governance - stake in the future the sustainability transition - value shifts, value migrations the worlds of money and power the sustainability audit - how are you placed?","['Triple bottom line', 'Line (geometry)', 'Business', 'Political science', 'Geometry', 'Law', 'Mathematics', 'Sustainable development']","sustainable capitalism, transparency, lifecylces, corporate governance, sustainability transition, value shifts, value migrations, sustainability audit"
Paper_01756,"DAVID: Database for Annotation, Visualization, and Integrated Discovery","['Glynn Dennis', 'Brad T. Sherman', 'Douglas A Hosack', 'Jun Yang', 'Wei Gao', 'H. Clifford Lane', 'Richard A. Lempicki']",2003,Genome biology,Journal,,,4,5,10.1186/gb-2003-4-5-p3,"Functional annotation of differentially expressed genes is a necessary and critical step in the analysis of microarray data. The distributed nature of biological knowledge frequently requires researchers to navigate through numerous web-accessible databases gathering information one gene at a time. A more judicious approach is to provide query-based access to an integrated database that disseminates biologically rich information across large datasets and displays graphic summaries of functional information.Database for Annotation, Visualization, and Integrated Discovery (DAVID; http://www.david.niaid.nih.gov) addresses this need via four web-based analysis modules: 1) Annotation Tool - rapidly appends descriptive data from several public databases to lists of genes; 2) GoCharts - assigns genes to Gene Ontology functional categories based on user selected classifications and term specificity level; 3) KeggCharts - assigns genes to KEGG metabolic processes and enables users to view genes in the context of biochemical pathway maps; and 4) DomainCharts - groups genes according to PFAM conserved protein domains.Analysis results and graphical displays remain dynamically linked to primary data and external data repositories, thereby furnishing in-depth as well as broad-based data coverage. The functionality provided by DAVID accelerates the analysis of genome-scale datasets by facilitating the transition from data collection to biological meaning.","['Annotation', 'Visualization', 'KEGG', 'Computer science', 'Ontology', 'Biological database', 'Microarray databases', 'Gene Annotation', 'Context (archaeology)', 'Information retrieval', 'Gene ontology', 'Database', 'Genome', 'Computational biology', 'Biology', 'Microarray analysis techniques', 'Gene', 'Data mining', 'Bioinformatics', 'Genetics', 'Paleontology', 'Philosophy', 'Gene expression', 'Epistemology']","functional annotation, differentially expressed genes, microarray data, biological knowledge, integrated database, integrated discovery, annota, gocharts, user, term specificity level, keggcharts, biochemical pathway maps, domain, ##rts"
Paper_01757,Conditional Generative Adversarial Nets,"['Mehdi Mirza', 'Simon Osindero']",2014,arXiv (Cornell University),Unknown,,,,,10.48550/arxiv.1411.1784,"Generative Adversarial Nets [8] were recently introduced as a novel way to train generative models. In this work we introduce the conditional version of generative adversarial nets, which can be constructed by simply feeding the data, y, we wish to condition on to both the generator and discriminator. We show that this model can generate MNIST digits conditioned on class labels. We also illustrate how this model could be used to learn a multi-modal model, and provide preliminary examples of an application to image tagging in which we demonstrate how this approach can generate descriptive tags which are not part of training labels.","['MNIST database', 'Generative grammar', 'Generator (circuit theory)', 'Computer science', 'Discriminator', 'Adversarial system', 'Class (philosophy)', 'Artificial intelligence', 'Modal', 'Generative model', 'Machine learning', 'Image (mathematics)', 'Artificial neural network', 'Power (physics)', 'Telecommunications', 'Chemistry', 'Physics', 'Quantum mechanics', 'Detector', 'Polymer chemistry']","generative adversarial nets, generative models, conditional version, generative adversarial nets, mnist digits, class labels, image tagging, descriptive tags, training, [PAD]"
Paper_01758,The Cambridge Structural Database,"['Colin R. Groom', 'Ian Bruno', 'Matthew P. Lightfoot', 'Suzanna C. Ward']",2016,Acta Crystallographica Section B Structural Science Crystal Engineering and Materials,Journal,,171-179,72,2,10.1107/s2052520616003954,"The Cambridge Structural Database (CSD) contains a complete record of all published organic and metal–organic small-molecule crystal structures. The database has been in operation for over 50 years and continues to be the primary means of sharing structural chemistry data and knowledge across disciplines. As well as structures that are made public to support scientific articles, it includes many structures published directly as CSD Communications. All structures are processed both computationally and by expert structural chemistry editors prior to entering the database. A key component of this processing is the reliable association of the chemical identity of the structure studied with the experimental data. This important step helps ensure that data is widely discoverable and readily reusable. Content is further enriched through selective inclusion of additional experimental data. Entries are available to anyone through free CSD community web services. Linking services developed and maintained by the CCDC, combined with the use of standard identifiers, facilitate discovery from other resources. Data can also be accessed through CCDC and third party software applications and through an application programming interface.","['Identifier', 'Computer science', 'Database', 'Interface (matter)', 'Data sharing', 'Application programming interface', 'Key (lock)', 'Software', 'Data structure', 'World Wide Web', 'Information retrieval', 'Medicine', 'Alternative medicine', 'Computer security', 'Bubble', 'Pathology', 'Maximum bubble pressure method', 'Parallel computing', 'Programming language']","cambridge structural database, structural chemistry, expert structural chemistry editors, chemical identity, csd community web services, linking services, ##dc, application programming interface"
Paper_01759,Revisiting the Behavioral Model and Access to Medical Care: Does it Matter?,['Ronald Andersen'],1995,Journal of Health and Social Behavior,Journal,,1-1,36,1,10.2307/2137284,"The Behavioral Model of Health Services Use was initially developed over 25 years ago. In the interim it has been subject to considerable application, reprobation, and alteration. I review its development and assess its continued relevance.","['Interim', 'Relevance (law)', 'Subject matter', 'Psychology', 'Political science', 'Pedagogy', 'Law', 'Curriculum']","behavioral model, health services use"
Paper_01760,National Council of Teachers of Mathematics,[],1979,Mathematics Teacher Learning and Teaching PK-12,Journal,,637-638,72,8,10.5951/mt.72.8.0637,"Organized groups of teachers of mathematics or of individuals preparing to become teachers of mathematics may petition the NCTM Board of Directors to become affiliated with the Council. Affiliated Groups are entitled to send a delegate to the delegate Assembly, which is held each year in conjunction with the NCTM Annual Meeting. The Assembly is a highly respected and influential recommending body of the Council that discusses and votes on resolutions concerning matters pertinent to mathematics education.","['Delegate', 'Mathematics education', 'Research council', 'Political science', 'Mathematics', 'Computer science', 'Linguistics', 'Philosophy', 'Government (linguistics)', 'Programming language']","teachers, mathematics, teachers, mathematics, nctm, nctm, mathematics education"
Paper_01762,A view of cloud computing,"['Michael Armbrust', 'Armando Fox', 'Rean Griffith', 'Anthony D. Joseph', 'Randy H. Katz', 'Andy Konwinski', 'Gunho Lee', 'David A. Patterson', 'Ariel Rabkin', 'Ion Stoica', 'Matei Zaharia']",2010,Communications of the ACM,Journal,,50-58,53,4,10.1145/1721654.1721672,Clearing the clouds away from the true potential and obstacles posed by this computing capability.,"['Cloud computing', 'Computer science', 'Operating system']",
Paper_01763,Partial least squares structural equation modeling (PLS-SEM),"['Joe F. Hair', 'Marko Sarstedt', 'Lucas Hopkins', 'Volker G. Kuppelwieser']",2014,European Business Review,Journal,,106-121,26,2,10.1108/ebr-10-2013-0128,"Abstract Purpose The authors aim to present partial least squares (PLS) as an evolving approach to structural equation modeling (SEM), highlight its advantages and limitations and provide an overview of recent research on the method across various fields. Design/methodology/approach In this review article, the authors merge literatures from the marketing, management, and management information systems fields to present the state-of-the art of PLS-SEM research. Furthermore, the authors meta-analyze recent review studies to shed light on popular reasons for PLS-SEM usage. Findings PLS-SEM has experienced increasing dissemination in a variety of fields in recent years with nonnormal data, small sample sizes and the use of formative indicators being the most prominent reasons for its application. Recent methodological research has extended PLS-SEM's methodological toolbox to accommodate more complex model structures or handle data inadequacies such as heterogeneity. Research limitations/implications While research on the PLS-SEM method has gained momentum during the last decade, there are ample research opportunities on subjects such as mediation or multigroup analysis, which warrant further attention. Originality/value This article provides an introduction to PLS-SEM for researchers that have not yet been exposed to the method. The article is the first to meta-analyze reasons for PLS-SEM usage across the marketing, management, and management information systems fields. The cross-disciplinary review of recent research on the PLS-SEM method also makes this article useful for researchers interested in advanced concepts.","['Structural equation modeling', 'Partial least squares regression', 'Mathematics', 'Econometrics', 'Statistics']","partial least squares, pl, structural equation modeling, management information systems, nonnormal data, formative indicators, heterogeneity, mediation, multigroup analysis, management information systems"
Paper_01764,A system of shuttle vectors and yeast host strains designed for efficient manipulation of DNA in Saccharomyces cerevisiae.,"['R Sikorski', 'P. Hieter']",1989,Genetics,Journal,,19-27,122,1,10.1093/genetics/122.1.19,"Abstract A series of yeast shuttle vectors and host strains has been created to allow more efficient manipulation of DNA in Saccharomyces cerevisiae. Transplacement vectors were constructed and used to derive yeast strains containing nonreverting his3, trp1, leu2 and ura3 mutations. A set of YCp and YIp vectors (pRS series) was then made based on the backbone of the multipurpose plasmid pBLUESCRIPT. These pRS vectors are all uniform in structure and differ only in the yeast selectable marker gene used (HIS3, TRP1, LEU2 and URA3). They possess all of the attributes of pBLUESCRIPT and several yeast-specific features as well. Using a pRS vector, one can perform most standard DNA manipulations in the same plasmid that is introduced into yeast.","['URA3', 'Shuttle vector', 'Biology', 'Saccharomyces cerevisiae', 'Selectable marker', 'Plasmid', 'Yeast', 'Genetics', 'Multiple cloning site', 'DNA', 'Computational biology', 'Gene', 'Vector (molecular biology)', 'Recombinant DNA']","yeast shuttle vectors, host strains, transplacement vectors, yeast strains, ##u, ##a, ##p, multipurpose plasmid p, ##s, yeast selectable marker gene, ##cript, ##s, dna, [PAD], [PAD] [PAD] [PAD] [PAD] [PAD]"
Paper_01770,Hybridization of denatured RNA and small DNA fragments transferred to nitrocellulose.,['Patricia S. Thomas'],1980,Proceedings of the National Academy of Sciences,Journal,,5201-5205,77,9,10.1073/pnas.77.9.5201,"A simple and rapid method for transferring RNA from agarose gels to nitrocellulose paper for blot hybridization has been developed. Poly(A)+ and ribosomal RNAs transfer efficiently to nitrocellulose paper in high salt (3 M NaCl/0.3 M trisodium citrate) after denaturation with glyoxal and 50% (vol/vol) dimethyl sulfoxide. RNA also binds to nitrocellulose after treatment with methylmercuric hydroxide. The method is sensitive: about 50 pg of specific mRNA per band is readily detectable after hybridization with high specific activity probes (10(8) cpm/microgram). The RNA is stably bound to the nitrocellulose paper by this procedure, allowing removal of the hybridized probes and rehybridization of the RNA blots without loss of sensitivity. The use of nitrocellulose paper for the analysis of RNA by blot hybridization has several advantages over the use of activated paper (diazobenzyloxymethyl-paper). The method is simple, inexpensive, reproducible, and sensitive. In addition, denaturation of DNA with glyoxal and dimethyl sulfoxide promotes transfer and retention of small DNAs (100 nucleotides and larger) to nitrocellulose paper. A related method is also described for dotting RNA and DNA directly onto nitrocellulose paper treated with a high concentration of salt; under these conditions denatured DNA of less than 200 nucleotides is retained and hybridizes efficiently.","['Nitrocellulose', 'RNA', 'Molecular biology', 'DNA', 'Chemistry', 'Nucleic acid', 'Nucleic acid thermodynamics', 'Agarose', 'Biochemistry', 'Dimethyl sulfate', 'Chromatography', 'Biology', 'Membrane', 'Gene', 'Organic chemistry']","agarose gels, ##los, blot hybridization, ribosomal rna, ##ric"
Paper_01771,"PyTorch: An Imperative Style, High-Performance Deep Learning Library","['Adam Paszke', 'Sam Gross', 'Francisco Massa', 'Adam Lerer', 'James Bradbury', 'Gregory Chanan', 'Trevor Killeen', 'Zeming Lin', 'Natalia Gimelshein', 'Luca Antiga', 'Alban Desmaison', 'Andreas Köpf', 'Edward Z. Yang', 'Zachary DeVito', 'Martin Raison', 'Alykhan Tejani', 'Sasank Chilamkurthy', 'Benoit Steiner', 'Lu Fang', 'Junjie Bai', 'Soumith Chintala']",2019,"['AIP Conference Proceedings', 'PROCEEDINGS OF THE 24TH INTERNATIONAL SCIENTIFIC CONFERENCE OF YOUNG SCIENTISTS AND SPECIALISTS (AYSS-2020)']",Unknown,,040004,2377,,10.1063/5.0063300,"Deep learning frameworks have often focused on either usability or speed, but not both. PyTorch is a machine learning library that shows that these two goals are in fact compatible: it was designed from first principles to support an imperative and Pythonic programming style that supports code as a model, makes debugging easy and is consistent with other popular scientific computing libraries, while remaining efficient and supporting hardware accelerators such as GPUs. In this paper, we detail the principles that drove the implementation of PyTorch and how they are reflected in its architecture. We emphasize that every aspect of PyTorch is a regular Python program under the full control of its user. We also explain how the careful and pragmatic implementation of the key components of its runtime enables them to work together to achieve compelling performance. We demonstrate the efficiency of individual subsystems, as well as the overall speed of PyTorch on several commonly used benchmarks.","['Computer science', 'Debugging', 'Python (programming language)', 'Programming style', 'Deep learning', 'Usability', 'Key (lock)', 'Architecture', 'Artificial intelligence', 'Programming language', 'Computer architecture', 'Software engineering', 'Human–computer interaction', 'Operating system', 'Art', 'Visual arts']","deep learning frameworks, pytorch, machine learning library, pythonic programming, debu, scientific computing libraries, hardware, gpus, pytorch, pytorch, python program, p, ##ch, [PAD]"
Paper_01772,Outline of a New Approach to the Analysis of Complex Systems and Decision Processes,['Lotfi A. Zadeh'],1973,IEEE Transactions on Systems Man and Cybernetics,Journal,,28-44,SMC-3,1,10.1109/tsmc.1973.5408575,"The approach described in this paper represents a substantive departure from the conventional quantitative techniques of system analysis. It has three main distinguishing features: 1) use of so-called ``linguistic'' variables in place of or in addition to numerical variables; 2) characterization of simple relations between variables by fuzzy conditional statements; and 3) characterization of complex relations by fuzzy algorithms. A linguistic variable is defined as a variable whose values are sentences in a natural or artificial language. Thus, if tall, not tall, very tall, very very tall, etc. are values of height, then height is a linguistic variable. Fuzzy conditional statements are expressions of the form IF A THEN B, where A and B have fuzzy meaning, e.g., IF x is small THEN y is large, where small and large are viewed as labels of fuzzy sets. A fuzzy algorithm is an ordered sequence of instructions which may contain fuzzy assignment and conditional statements, e.g., x = very small, IF x is small THEN Y is large. The execution of such instructions is governed by the compositional rule of inference and the rule of the preponderant alternative. By relying on the use of linguistic variables and fuzzy algorithms, the approach provides an approximate and yet effective means of describing the behavior of systems which are too complex or too ill-defined to admit of precise mathematical analysis.","['Fuzzy logic', 'Variable (mathematics)', 'Mathematics', 'Fuzzy number', 'Characterization (materials science)', 'Defuzzification', 'Type-2 fuzzy sets and systems', 'Fuzzy classification', 'Sequence (biology)', 'Computer science', 'Simple (philosophy)', 'Fuzzy set operations', 'Fuzzy set', 'Relation (database)', 'Linguistics', 'Artificial intelligence', 'Data mining', 'Epistemology', 'Mathematical analysis', 'Philosophy', 'Materials science', 'Biology', 'Nanotechnology', 'Genetics']","system analysis, numerical, fuzzy conditional statements, fuzzy algorithms, linguistic variable, fuzzy conditional statements, fuzzy sets, fuzzy algorithm, fuzzy assignment, conditional statements, compositional rule of inference, linguistic variables, fuzzy algorithms, mathematical analysis"
Paper_01777,DeepWalk,"['Bryan Perozzi', 'Rami Al‐Rfou', 'Steven Skiena']",2014,Unknown,Unknown,,701-710,,,10.1145/2623330.2623732,"We present DeepWalk, a novel approach for learning latent representations of vertices in a network. These latent representations encode social relations in a continuous vector space, which is easily exploited by statistical models. DeepWalk generalizes recent advancements in language modeling and unsupervised feature learning (or deep learning) from sequences of words to graphs.","['Computer science', 'Artificial intelligence', 'Feature learning', 'Feature vector', 'Feature (linguistics)', 'Latent variable', 'Unsupervised learning', 'Deep learning', 'Vector space', 'ENCODE', 'Natural language processing', 'Machine learning', 'Mathematics', 'Linguistics', 'Philosophy', 'Biochemistry', 'Geometry', 'Chemistry', 'Gene']","deepwalk, latent representations, late, social relations, continuous vector space, statistical models, deepwalk, language modeling, unsupervised feature learning, deep learning, [PAD] [PAD] [PAD], [PAD] [PAD]"
Paper_01778,Isolation of Putative Progenitor Endothelial Cells for Angiogenesis,"['Takayuki Asahara', 'Toyoaki Murohara', 'Alison Sullivan', 'Marcy Silver', 'Rien van der Zee', 'Tong Li', 'Bernhard Witzenbichler', 'Gina C. Schatteman', 'Jeffrey M. Isner']",1997,Science,Journal,,964-966,275,5302,10.1126/science.275.5302.964,"Putative endothelial cell (EC) progenitors or angioblasts were isolated from human peripheral blood by magnetic bead selection on the basis of cell surface antigen expression. In vitro, these cells differentiated into ECs. In animal models of ischemia, heterologous, homologous, and autologous EC progenitors incorporated into sites of active angiogenesis. These findings suggest that EC progenitors may be useful for augmenting collateral vessel growth to ischemic tissues (therapeutic angiogenesis) and for delivering anti- or pro-angiogenic agents, respectively, to sites of pathologic or utilitarian angiogenesis.","['Angiogenesis', 'Progenitor cell', 'Heterologous', 'Cell biology', 'Endothelial stem cell', 'Biology', 'Endothelial progenitor cell', 'Therapeutic angiogenesis', 'In vitro', 'Immunology', 'Neovascularization', 'Stem cell', 'Cancer research', 'Biochemistry', 'Gene']","putative endothelial cell, angioblasts, human peripheral blood, magnetic bead selection, cell surface antigen expression, ischemia, active angiogenesis, collateral vessel growth, is, therapeutic angiogenesis, ##tarian"
Paper_01779,"Total Carbon, Organic Carbon, and Organic Matter","['D. W. Nelson', 'L. E. Sommers']",1982,Agronomy monograph/Agronomy,Unknown,,539-579,,,10.2134/agronmonogr9.2.2ed.c29,"Total carbon (C) in soils is the sum of both organic and inorganic C. Most organic C is present in the soil organic matter fraction, whereas inorganic C is largely found in carbonate minerals. This chapter describes two dry combustion and one wet combustion procedures for total C analysis. Not all soils contain inorganic C because of dissolution during soil formation of carbonate minerals originally present in parent material. However, organic C is present in all agricultural soils. Total C determinations for soil involve conversion of all forms of C in soils to CO2 by wet or dry combustion and subsequent quantitation of evolved CO2 by gravimetric, titrimetric, volumetric, spectrophotometric, or gas chromatographic techniques. Because of the problem associated with determining the organic matter content of a soil, it is strongly suggested that investigators determine and report the organic C concentration as a measure of the organic matter in a soil.","['Carbon fibers', 'Total organic carbon', 'Organic matter', 'Environmental chemistry', 'Environmental science', 'Chemistry', 'Materials science', 'Organic chemistry', 'Composite number', 'Composite material']","total carbon, soils, soil organic matter fraction, carbonate minerals, dry combustion, wet combustion, total, carbonate minerals, organic, agricultural soils, total, dry combustion, gravi, titri, volume, spectrophoto, gas chromatographic, organic c"
Paper_01780,A Film Detection Method for Tritium‐Labelled Proteins and Nucleic Acids in Polyacrylamide Gels,"['William M. Bonner', 'Ronald A. Laskey']",1974,European Journal of Biochemistry,Journal,,83-88,46,1,10.1111/j.1432-1033.1974.tb03599.x,"A simple method is described for detecting 3 H in polyacrylamide gels by scintillation autography (fluorography) using X‐ray film. The gel is dehydrated in dimethyl sulphoxide, soaked in a solution of 2,5‐diphenyloxazole (PPO) in dimethylsulphoxide, dried and exposed to RP Royal “X‐Omat” film at ‐70 °C. Optimal conditions for each step are described. β‐particles from 3 H interact with the 2,5‐diphenyloxazole emitting light which causes local blackening of an X‐ray film. The image produced resembles that obtained by conventional autoradiography of isotopes with higher emission energies such as 14 C. 3000 dis. 3 H/min in a band in a gel can be detected in a 24‐h exposure. Similarly 500 dis./min can be detected in one week. When applied to the detection of 35 S and 14 C in polyacrylamide gels, this method is ten times more sensitive than conventional autoradiography. 130 dis. 35 S or 14 C/min in a band in a gel can be detected in 24 h.","['Polyacrylamide', 'Polyacrylamide gel electrophoresis', 'Scintillation', 'Nucleic acid', 'Tritium', 'Chemistry', 'Chromatography', 'Materials science', 'Optics', 'Polymer chemistry', 'Physics', 'Biochemistry', 'Detector', 'Nuclear physics', 'Enzyme']","polyac, ##amide gels, scintillation autography, fluorography, x, β, polyac, ##amide"
Paper_01781,Nivolumab versus Docetaxel in Advanced Nonsquamous Non–Small-Cell Lung Cancer,"['H. Borghaei', 'L. Paz-Ares', 'Leora Horn', 'David R. Spigel', 'Martin Steins', 'Neal Ready', 'Laura Q.M. Chow', 'Everett E. Vokes', 'Enriqueta Felip', 'Esther Holgado', 'Fabrice Barlési', 'M. Kohlhufl', 'Óscar Arrieta', 'M. Burgio', 'Jérôme Fayette', 'H. Lena', 'Elena Poddubskaya', 'David E. Gerber', 'Scott Gettinger', 'Charles M. Rudin', 'Naiyer A. Rizvi', 'L. Crina', 'George R. Blumenschein', 'Scott Antonia', 'Cécile Dorange', 'Christopher Harbison', 'F. Graf Finckenstein', 'Julie R. Brahmer']",2015,New England Journal of Medicine,Journal,,1627-1639,373,17,10.1056/nejmoa1507643,"Nivolumab, a fully human IgG4 programmed death 1 (PD-1) immune-checkpoint-inhibitor antibody, disrupts PD-1-mediated signaling and may restore antitumor immunity.","['Medicine', 'Docetaxel', 'Nivolumab', 'Lung cancer', 'Oncology', 'Internal medicine', 'Cancer', 'Immunotherapy']","nivolumab, antitumor immunity, [PAD] [PAD] [PAD], [PAD] [PAD], [PAD], [PAD] [PAD], [PAD], [PAD] [PAD]"
Paper_01786,Sensitivity of Goodness of Fit Indexes to Lack of Measurement Invariance,['Fangfang Chen'],2007,Structural Equation Modeling A Multidisciplinary Journal,Journal,,464-504,14,3,10.1080/10705510701301834,"Two Monte Carlo studies were conducted to examine the sensitivity of goodness of fit indexes to lack of measurement invariance at 3 commonly tested levels: factor loadings, intercepts, and residual variances. Standardized root mean square residual (SRMR) appears to be more sensitive to lack of invariance in factor loadings than in intercepts or residual variances. Comparative fit index (CFI) and root mean square error of approximation (RMSEA) appear to be equally sensitive to all 3 types of lack of invariance. The most intriguing finding is that changes in fit statistics are affected by the interaction between the pattern of invariance and the proportion of invariant items: when the pattern of lack of invariance is uniform, the relation is nonmonotonic, whereas when the pattern of lack of invariance is mixed, the relation is monotonic. Unequal sample sizes affect changes across all 3 levels of invariance: Changes are bigger when sample sizes are equal rather than when they are unequal. Cutoff points for testing invariance at different levels are recommended.","['Measurement invariance', 'Goodness of fit', 'Mathematics', 'Statistics', 'Residual', 'Invariant (physics)', 'Monte Carlo method', 'Factor analysis', 'Sample size determination', 'Sensitivity (control systems)', 'Econometrics', 'Structural equation modeling', 'Confirmatory factor analysis', 'Algorithm', 'Electronic engineering', 'Engineering', 'Mathematical physics']","monte carlo studies, goodness of fit indexes, measurement invariance, factor loadings, intercepts, residual variances, standardized root mean square residual, factor loading, residual variances, comparative fit index, root mean square error of approximation, fit statistics, ##mon, unequal sample sizes, cut, invariance"
Paper_01787,A comparison of methods to test mediation and other intervening variable effects.,"['David P. MacKinnon', 'Chondra M. Lockwood', 'Jeanne M. Hoffman', 'Stephen G. West', 'Virgil L. Sheets']",2002,Psychological Methods,Journal,,83-104,7,1,10.1037/1082-989x.7.1.83,A Monte Carlo study compared 14 methods to test the statistical significance of the intervening variable effect. An intervening variable (mediator) transmits the effect of an independent variable to a dependent variable. The commonly used R. M. Baron and D. A. Kenny (1986) approach has low statistical power. Two methods based on the distribution of the product and 2 difference-in-coefficients methods have the most accurate Type I error rates and greatest statistical power except in 1 important case in which Type I error rates are too high. The best balance of Type I error and statistical power across all cases is the test of the joint significance of the two effects comprising the intervening variable effect.,"['Type I and type II errors', 'Statistics', 'Statistical significance', 'Statistical hypothesis testing', 'Variable (mathematics)', 'Statistical power', 'Variables', 'Mediation', 'Monte Carlo method', 'Mathematics', 'Econometrics', 'Mathematical analysis', 'Political science', 'Law']","monte carlo, statistical significance, intervening variable effect, media, statistical, type i error rates, statistical, intervening variable"
Paper_01789,IARC Monographs on the Evaluation of Carcinogenic Risks to Humans,['A. J. Zuckerman'],1995,Journal of Clinical Pathology,Journal,,691-691,48,7,10.1136/jcp.48.7.691-a,"Viral hepatitis in all its forms is a major public health problem throughout the world, affecting several hundreds of millions of people.Viral hepatitis is a cause of con- siderable morbidity and mortality both from acute infection and chronic sequelae which include, in the case of hepatitis B, C and D, chronic active hepatitis and cirrhosis.Hep- atocellular carcinoma, which is one of the 10 commonest cancers worldwide, is closely associated with hepatitis B and, at least in some regions of the world, with hepatitis C","['Carcinogen', 'Computational biology', 'Bioinformatics', 'Medicine', 'Biology', 'Genetics']","viral hepatitis, public health, viral hepatitis, chronic active hepatitis, cirrhosis"
Paper_01791,Document Analysis as a Qualitative Research Method,['Glenn A. Bowen'],2009,Qualitative Research Journal,Journal,,27-40,9,2,10.3316/qrj0902027,"This article examines the function of documents as a data source in qualitative research and discusses document analysis procedure in the context of actual research experiences. Targeted to research novices, the article takes a nuts‐and‐bolts approach to document analysis. It describes the nature and forms of documents, outlines the advantages and limitations of document analysis, and offers specific examples of the use of documents in the research process. The application of document analysis to a grounded theory study is illustrated.","['Function (biology)', 'Grounded theory', 'Context (archaeology)', 'Qualitative analysis', 'Qualitative research', 'Process (computing)', 'Content analysis', 'Data science', 'Computer science', 'Sociology', 'Management science', 'Engineering ethics', 'Social science', 'Engineering', 'History', 'Archaeology', 'Evolutionary biology', 'Biology', 'Operating system']","documents, data source, qualitative research, document analysis, document analysis, document analysis, documents, document analysis, grounded theory, [PAD], [PAD] [PAD], [PAD] [PAD] [PAD], [PAD] [PAD], [PAD] [PAD], [PAD], [PAD], [PAD], [PAD], [PAD] [PAD] [PAD], [PAD], [PAD]"
Paper_01795,The Effect of Spironolactone on Morbidity and Mortality in Patients with Severe Heart Failure,"['Bertram Pitt', 'Faı̈ez Zannad', 'Willem J. Remme', 'Robert Cody', 'A Castaigne', 'A.J. Pérez Pérez', 'Jolie Palensky', 'Janet Wittes']",1999,New England Journal of Medicine,Journal,,709-717,341,10,10.1056/nejm199909023411001,"Aldosterone is important in the pathophysiology of heart failure. In a doubleblind study, we enrolled 1663 patients who had severe heart failure and a left ventricular ejection fraction of no more than 35 percent and who were being treated with an angiotensin-converting-enzyme inhibitor, a loop diuretic, and in most cases digoxin. A total of 822 patients were randomly assigned to receive 25 mg of spironolactone daily, and 841 to receive placebo. The primary end point was death from all causes.The trial was discontinued early, after a mean follow-up period of 24 months, because an interim analysis determined that spironolactone was efficacious. There were 386 deaths in the placebo group (46 percent) and 284 in the spironolactone group (35 percent; relative risk of death, 0.70; 95 percent confidence interval, 0.60 to 0.82; P<0.001). This 30 percent reduction in the risk of death among patients in the spironolactone group was attributed to a lower risk of both death from progressive heart failure and sudden death from cardiac causes. The frequency of hospitalization for worsening heart failure was 35 percent lower in the spironolactone group than in the placebo group (relative risk of hospitalization, 0.65; 95 percent confidence interval, 0.54 to 0.77; P<0.001). In addition, patients who received spironolactone had a significant improvement in the symptoms of heart failure, as assessed on the basis of the New York Heart Association functional class (P<0.001). Gynecomastia or breast pain was reported in 10 percent of men who were treated with spironolactone, as compared with 1 percent of men in the placebo group (P<0.001). The incidence of serious hyperkalemia was minimal in both groups of patients.Blockade of aldosterone receptors by spironolactone, in addition to standard therapy, substantially reduces the risk of both morbidity and death among patients with severe heart failure.","['Spironolactone', 'Medicine', 'Heart failure', 'Digoxin', 'Internal medicine', 'Relative risk', 'Placebo', 'Ejection fraction', 'Cardiology', 'Confidence interval', 'Sudden death', 'Alternative medicine', 'Pathology']","aldosterone, heart failure, double, left ventricular ejection fraction, loop diuretic, ##la, spironola, ##e, spiro, ##la, spiro, ##la, gyne, ##ast, breast pain, ##iro, ##la, ##kal, aldosterone, spiro, ##la"
Paper_01796,"Effects of an Angiotensin-Converting–Enzyme Inhibitor, Ramipril, on Cardiovascular Events in High-Risk Patients","['Salim Yusuf', 'Peter Sleight', 'Janice Pogue', 'Jackie Bosch', 'Richard Davies', 'Gilles R. Dagenais']",2000,New England Journal of Medicine,Journal,,145-153,342,3,10.1056/nejm200001203420301,"Angiotensin-converting–enzyme inhibitors improve the outcome among patients with left ventricular dysfunction, whether or not they have heart failure. We assessed the role of an angiotensin-converting–enzyme inhibitor, ramipril, in patients who were at high risk for cardiovascular events but who did not have left ventricular dysfunction or heart failure.","['Ramipril', 'Medicine', 'Internal medicine', 'Placebo', 'Myocardial infarction', 'Heart failure', 'Ejection fraction', 'ACE inhibitor', 'Relative risk', 'Stroke (engine)', 'Angiotensin-converting enzyme', 'Cardiology', 'Diabetes mellitus', 'Confidence interval', 'Endocrinology', 'Blood pressure', 'Mechanical engineering', 'Alternative medicine', 'Pathology', 'Engineering']","left ventricular dysfunction, heart, ramipril, left ventricular dysfunction, [PAD], [PAD] [PAD] [PAD] [PAD] [PAD], [PAD], [PAD] [PAD], [PAD], [PAD], [PAD] [PAD], [PAD], [PAD], [PAD] [PAD], [PAD] [PAD] [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD] [PAD]"
Paper_01797,Association of glycaemia with macrovascular and microvascular complications of type 2 diabetes (UKPDS 35): prospective observational study,['Irene Stratton'],2000,BMJ,Journal,,405-412,321,7258,10.1136/bmj.321.7258.405,"<h3>Abstract</h3> <b>Objective:</b> To determine the relation between exposure to glycaemia over time and the risk of macrovascular or microvascular complications in patients with type 2 diabetes. <b>Design:</b> Prospective observational study. <b>Setting:</b> 23 hospital based clinics in England, Scotland, and Northern Ireland. <b>Participants:</b> 4585 white, Asian Indian, and Afro-Caribbean UKPDS patients, whether randomised or not to treatment, were included in analyses of incidence; of these, 3642 were included in analyses of relative risk. <b>Outcome measures:</b> Primary predefined aggregate clinical outcomes: any end point or deaths related to diabetes and all cause mortality. Secondary aggregate outcomes: myocardial infarction, stroke, amputation (including death from peripheral vascular disease), and microvascular disease (predominantly retinal photo-coagulation). Single end points: non-fatal heart failure and cataract extraction. Risk reduction associated with a 1% reduction in updated mean HbA<sub>1c</sub> adjusted for possible confounders at diagnosis of diabetes. <b>Results:</b> The incidence of clinical complications was significantly associated with glycaemia. Each 1% reduction in updated mean HbA<sub>1c</sub> was associated with reductions in risk of 21% for any end point related to diabetes (95% confidence interval 17% to 24%, P&lt;0.0001), 21% for deaths related to diabetes (15% to 27%, P&lt;0.0001), 14% for myocardial infarction (8% to 21%, P&lt;0.0001), and 37% for microvascular complications (33% to 41%, P&lt;0.0001). No threshold of risk was observed for any end point. <b>Conclusions:</b> In patients with type 2 diabetes the risk of diabetic complications was strongly associated with previous hyperglycaemia. Any reduction in HbA<sub>1c</sub> is likely to reduce the risk of complications, with the lowest risk being in those with HbA<sub>1c</sub> values in the normal range (&lt;6.0%).","['Medicine', 'Diabetes mellitus', 'Internal medicine', 'Type 2 diabetes', 'United Kingdom Prospective Diabetes Study', 'Macrovascular disease', 'Relative risk', 'Myocardial infarction', 'Incidence (geometry)', 'Retinopathy', 'Stroke (engine)', 'Prospective cohort study', 'Confounding', 'Surgery', 'Cardiology', 'Confidence interval', 'Endocrinology', 'Mechanical engineering', 'Physics', 'Engineering', 'Optics']","all, myocardial in, amputation, peripheral vascular disease, micro, cataract extraction, my"
Paper_01799,Estimating Nonresponse Bias in Mail Surveys,"['J. Scott Armstrong', 'Terry Overton']",1977,Journal of Marketing Research,Journal,,396-402,14,3,10.1177/002224377701400320,"Valid predictions for the direction of nonresponse bias were obtained from subjective estimates and extrapolations in an analysis of mail survey data from published studies. For estimates of the magnitude of bias, the use of extrapolations led to substantial improvements over a strategy of not using extrapolations.","['Non-response bias', 'Econometrics', 'Statistics', 'Computer science', 'Mathematics']","nonresponse bias, subjective estimates, extra, ##ations, mail survey data, extra, ##ations, ##ations, [PAD], [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD], [PAD], [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD]"
Paper_01800,Bidirectional recurrent neural networks,"['Mike Schuster', 'Kuldip K. Paliwal']",1997,IEEE Transactions on Signal Processing,Journal,,2673-2681,45,11,10.1109/78.650093,"In the first part of this paper, a regular recurrent neural network (RNN) is extended to a bidirectional recurrent neural network (BRNN). The BRNN can be trained without the limitation of using input information just up to a preset future frame. This is accomplished by training it simultaneously in positive and negative time direction. Structure and training procedure of the proposed network are explained. In regression and classification experiments on artificial data, the proposed structure gives better results than other approaches. For real data, classification experiments for phonemes from the TIMIT database show the same tendency. In the second part of this paper, it is shown how the proposed bidirectional structure can be easily modified to allow efficient estimation of the conditional posterior probability of complete symbol sequences without making any explicit assumption about the shape of the distribution. For this part, experiments on real data are reported.","['TIMIT', 'Recurrent neural network', 'Computer science', 'Artificial neural network', 'Frame (networking)', 'Artificial intelligence', 'Pattern recognition (psychology)', 'Symbol (formal)', 'Algorithm', 'Machine learning', 'Hidden Markov model', 'Telecommunications', 'Programming language']","regular recurrent neural network, rn, bidirectional recurrent neural network, br, training, classification, artificial data, classification, phone, timit database, bidirectional structure, conditional posterior probability"
Paper_01801,2018 ESC/ESH Guidelines for the management of arterial hypertension,"['Bryan Williams', 'Giuseppe Mancia', 'Wilko Spiering', 'Enrico Agabiti Rosei', 'Michel Azizi', 'Michel Burnier', 'Denis L Clement', 'António Coca', 'Giovanni de Simone', 'Anna F. Dominiczak', 'Thomas Kahan', 'Felix Mahfoud', 'Josep Redón', 'Luís M. Ruilope', 'Alberto Zanchetti', 'Mary Kerins', 'Sverre E. Kjeldsen', 'Reinhold Kreutz', 'Stéphane Laurent', 'Gregory Y H Lip', 'Richard J. McManus', 'Krzysztof Narkiewicz', 'Frank Ruschitzka', 'Roland E. Schmieder', 'Е. V. Shlyakhto', 'Costas Tsioufis', 'Victor Aboyans', 'Iléana Desormais', 'Guy De Backer', 'Anthony M. Heagerty', 'Stefan Agewall', 'Murielle Bochud', 'Claudio Borghi', 'Pierre Boutouyrie', 'Jana Brguljan', 'Héctor Bueno', 'Enrico G. Caiani', 'Bo Carlberg', 'Neil Chapman', 'Renata Cífková', 'John G.F. Cleland', 'Jean-Philippe Collet', 'Ioan Mircea Coman', 'Peter W. de Leeuw', 'Victoria Delgado', 'Paul Dendale', 'Hans‐Christoph Diener', 'Maria Dorobanţu', 'Robert Fagard', 'Csaba Farsang', 'Marc Ferrini', 'Ian M Graham', 'Guıdo Grassı', 'Hermann Haller', 'F D Richard Hobbs', 'Bojan Jelakovic', 'Catriona Jennings', 'Hugo A Katus', 'Abraham A Kroon', 'Christophe Leclercq', 'Dragan Lovic', 'Empar Lurbe', 'Athanasios Manolis', 'Theresa A McDonagh', 'Franz H. Messerli', 'Maria Lorenza Muiesan', 'Uwe Nixdorff', 'Michael Hecht Olsen', 'Gianfranco Parati', 'Joep Perk', 'Massimo Piepoli', 'Jorge Polonia', 'Piotr Ponikowski', 'Dimitrios J Richter', 'Stefano F. Rimoldi', 'Marco Roffi', 'Naveed Sattar', 'Petar Seferovic', 'Iain A Simpson', 'Georges Saadé', 'Alice Stanton', 'Philippe van de Borne', 'Panos E. Vardas', 'Massimo Volpe', 'Sven Waßmann', 'Stephan Windecker', 'Jose Luis Zamorano', 'Stephan Windecker', 'Victor Aboyans', 'Stefan Agewall', 'Emanuele Barbato', 'Héctor Bueno', 'Antonio Coca', 'Jean-Philippe Collet', 'Ioan Mircea Coman', 'Verónica Dean', 'Victoria Delgado', 'Donna Fitzsimons', 'O. Gaemperli', 'Gerhard Hindricks']",2018,European Heart Journal,Journal,,3021-3104,39,33,10.1093/eurheartj/ehy339,"The ESC/ESH Guidelines represent the views of the ESC and ESH and were produced after careful consideration of the scientific and medical knowledge and the evidence available at the time of their dating.The ESC and ESH are not responsible in the event of any contradiction, discrepancy, and/or ambiguity between the ESC/ESH Guidelines and any other official","['Medicine', 'Ambiguity', 'Contradiction', 'Intensive care medicine', 'Family medicine', 'Medical emergency', 'Epistemology', 'Philosophy', 'Linguistics']",medical
Paper_01802,phytools: an R package for phylogenetic comparative biology (and other things),['Liam J. Revell'],2011,Methods in Ecology and Evolution,Journal,,217-223,3,2,10.1111/j.2041-210x.2011.00169.x,"Summary 1. Here, I present a new, multifunctional phylogenetics package, phytools, for the R statistical computing environment. 2. The focus of the package is on methods for phylogenetic comparative biology; however, it also includes tools for tree inference, phylogeny input/output, plotting, manipulation and several other tasks. 3. I describe and tabulate the major methods implemented in phytools, and in addition provide some demonstration of its use in the form of two illustrative examples. 4. Finally, I conclude by briefly describing an active web‐log that I use to document present and future developments for phytools. I also note other web resources for phylogenetics in the R computational environment.","['Phylogenetics', 'Phylogenetic tree', 'R package', 'Computer science', 'Inference', 'Comparative biology', 'Focus (optics)', 'Statistical inference', 'Data science', 'Tree (set theory)', 'Evolutionary biology', 'Biology', 'Computational biology', 'Theoretical computer science', 'Artificial intelligence', 'Mathematics', 'Statistics', 'Programming language', 'Genetics', 'Mathematical analysis', 'Physics', 'Gene', 'Optics']","multifunctional phylogenetics package, phytools, r statistical computing environment, phylogenetic comparative biology, tree inference, phylogen, plotting, manipulation, phytools, active web ‐ log, ##ytools, ##s"
Paper_01804,Adaptive Subgradient Methods for Online Learning and Stochastic Optimization,"['John C. Duchi', 'Elad Hazan', 'Yoram Singer']",2011,['SpringerReference'],Journal,,2121-2159,12,61,10.1007/springerreference_72529,"We present a new family of subgradient methods that dynamically incorporate knowledge of the geometry of the data observed in earlier iterations to perform more informative gradient-based learning. Metaphorically, the adaptation allows us to find needles in haystacks in the form of very predictive but rarely seen features. Our paradigm stems from recent advances in stochastic optimization and online learning which employ proximal functions to control the gradient steps of the algorithm. We describe and analyze an apparatus for adaptively modifying the proximal function, which significantly simplifies setting a learning rate and results in regret guarantees that are provably as good as the best proximal function that can be chosen in hindsight. We give several efficient algorithms for empirical risk minimization problems with common and important regularization functions and domain constraints. We experimentally study our theoretical analysis and show that adaptive subgradient methods outperform state-of-the-art, yet non-adaptive, subgradient algorithms.","['Subgradient method', 'Regret', 'Computer science', 'Regularization (linguistics)', 'Mathematical optimization', 'Empirical risk minimization', 'Artificial intelligence', 'Hindsight bias', 'Stochastic optimization', 'Machine learning', 'Algorithm', 'Mathematics', 'Psychology', 'Cognitive psychology']","subgradient methods, stochastic optimization, online learning, proximal functions, proximal function, learning, regret guarantees, ##mal function, regularization functions, domain constraints"
Paper_01805,Performance analysis of the IEEE 802.11 distributed coordination function,['Giuseppe Bianchi'],2000,IEEE Journal on Selected Areas in Communications,Journal,,535-547,18,3,10.1109/49.840210,"The IEEE has standardized the 802.11 protocol for wireless local area networks. The primary medium access control (MAC) technique of 802.11 is called the distributed coordination function (DCF). The DCF is a carrier sense multiple access with collision avoidance (CSMA/CA) scheme with binary slotted exponential backoff. This paper provides a simple, but nevertheless extremely accurate, analytical model to compute the 802.11 DCF throughput, in the assumption of finite number of terminals and ideal channel conditions. The proposed analysis applies to both the packet transmission schemes employed by DCF, namely, the basic access and the RTS/CTS access mechanisms. In addition, it also applies to a combination of the two schemes, in which packets longer than a given threshold are transmitted according to the RTS/CTS mechanism. By means of the proposed model, we provide an extensive throughput performance evaluation of both access mechanisms of the 802.11 protocol.","['Distributed coordination function', 'Computer science', 'Exponential backoff', 'Carrier sense multiple access with collision avoidance', 'Computer network', 'Multiple Access with Collision Avoidance for Wireless', 'Throughput', 'Network packet', 'Network allocation vector', 'Media access control', 'Inter-Access Point Protocol', 'IEEE 802.11', 'Access control', 'Transmission (telecommunications)', 'Channel (broadcasting)', 'Protocol (science)', 'IEEE 802.11e-2005', 'Wireless network', 'Wireless', 'Wi-Fi', 'Telecommunications', 'Wi-Fi array', 'Medicine', 'Routing protocol', 'Alternative medicine', 'Pathology', 'Optimized Link State Routing Protocol']","wireless local area networks, primary medium access control, distributed coordination function, carrier sense multiple access with collision avoidance, binary slotted exponential backoff, packet transmission schemes, throughput performance evaluation, [PAD] [PAD] [PAD] [PAD] [PAD]"
Paper_01808,Learning with Kernels,"['Bernhard Schölkopf', 'Alexander J. Smola']",2001,Unknown,Unknown,,,,,10.7551/mitpress/4175.001.0001,"A comprehensive introduction to Support Vector Machines and related kernel methods. In the 1990s, a new type of learning algorithm was developed, based on results from statistical learning theory: the Support Vector Machine (SVM). This gave rise to a new class of theoretically elegant learning machines that use a central concept of SVMs—-kernels—for a number of learning tasks. Kernel machines provide a modular framework that can be adapted to different tasks and domains by the choice of the kernel function and the base algorithm. They are replacing neural networks in a variety of fields, including engineering, information retrieval, and bioinformatics. Learning with Kernels provides an introduction to SVMs and related kernel methods. Although the book begins with the basics, it also includes the latest research. It provides all of the concepts necessary to enable a reader equipped with some basic mathematical knowledge to enter the world of machine learning using theoretically well-founded yet easy-to-use kernel algorithms and to understand and apply the powerful algorithms that have been developed over the last few years.",['Computer science'],"support vector machines, kernel methods, learning algorithm, statistical learning theory, support vector machine, svm, sv, kernels, kernel machines, kernel function, base algorithm, neural networks, engineering, information retrieval, bioinformatics, svms, kernel methods, machine learning"
Paper_01810,Economic Welfare and the Allocation of Resources for Invention,['Kenneth J. Arrow'],1962,Princeton University Press eBooks,Unknown,,609-626,,,10.1515/9781400879762-024,"Invention is here interpreted broadly as the production of knowledge. From the viewpoint of welfare economics, the determination of optimal resource allocation for invention will depend on the technological characteristics of the invention process and the nature of the market for knowledge.","['Welfare', 'Economics', 'Economic welfare', 'Natural resource economics', 'Business', 'Market economy']","invention, welfare economics, optimal resource allocation, [PAD] [PAD]"
Paper_01811,Open Innovation: The New Imperative for Creating and Profiting from Technology,['Henry Chesbrough'],2003,['Innovation'],Unknown,,474-474,6,3,10.5172/impp.2004.6.3.474,"The article reviews the book “Open Innovation: The New Imperative for Creating and Profiting From Technology,” by Henry Chesbrough.","['Open innovation', 'Business', 'Knowledge management', 'Marketing', 'Computer science']",open innovation
Paper_01812,Learning Spatiotemporal Features with 3D Convolutional Networks,"['Du Tran', 'Lubomir Bourdev', 'Rob Fergus', 'Lorenzo Torresani', 'Manohar Paluri']",2015,Unknown,Unknown,,4489-4497,,,10.1109/iccv.2015.510,"We propose a simple, yet effective approach for spatiotemporal feature learning using deep 3-dimensional convolutional networks (3D ConvNets) trained on a large scale supervised video dataset. Our findings are three-fold: 1) 3D ConvNets are more suitable for spatiotemporal feature learning compared to 2D ConvNets, 2) A homogeneous architecture with small 3x3x3 convolution kernels in all layers is among the best performing architectures for 3D ConvNets, and 3) Our learned features, namely C3D (Convolutional 3D), with a simple linear classifier outperform state-of-the-art methods on 4 different benchmarks and are comparable with current best methods on the other 2 benchmarks. In addition, the features are compact: achieving 52.8% accuracy on UCF101 dataset with only 10 dimensions and also very efficient to compute due to the fast inference of ConvNets. Finally, they are conceptually very simple and easy to train and use.","['Computer science', 'Artificial intelligence', 'Convolutional neural network', 'Classifier (UML)', 'Pattern recognition (psychology)', 'Convolution (computer science)', 'Inference', 'Deep learning', 'Feature (linguistics)', 'Feature extraction', 'Homogeneous', 'Machine learning', 'Artificial neural network', 'Mathematics', 'Combinatorics', 'Philosophy', 'Linguistics']","spatiotemporal feature learning, 3d con, 3d con, spatiot, ##poral feature learning, homogeneous architecture, c, convolutional 3d, linear classifier"
Paper_01813,<i>Linear and Nonlinear Waves</i>,"['G. B. Whitham', 'Richard Fowler']",1975,Physics Today,Journal,,55-56,28,6,10.1063/1.3069011,"Introduction and General Outline. HYPERBOLIC WAVES. Waves and First Order Equations. Specific Problems. Burger's Equation. Hyperbolic Systems. Gas Dynamics. The Wave Equation. Shock Dynamics. The Propagation of Weak Shocks. Wave Hierarchies. DISPERSIVE WAVES. Linear Dispersive Waves. Wave Patterns. Water Waves. Nonlinear Dispersion and the Variational Method. Group Velocities, Instability, and Higher Order Dispersion. Applications of the Nonlinear Theory. Exact Solutions: Interacting Solitary Waves. References. Index.","['Nonlinear system', 'Physics', 'Mechanics', 'Quantum mechanics']","hyperbolic waves, first, hyperbolic systems, gas dynamics, wave equation, shock dynamics, weak shocks, wave hierarchies, dispersive waves, linear dispersive waves, wave patterns, water waves, nonlinear dispersion, variational method, group velocities, instability, higher order dispersion, interacting solitary waves, [PAD]"
Paper_01814,The New Meaning of Educational Change,['Michael Fullan'],2013,Routledge eBooks,Unknown,,,,,10.4324/9780203609071,Part I Understanding Educational Change 1. A Brief History of Educational Change 2. Sources of Educational Change 3. The Meaning of Educational Change 4. The Causes and Problems of Initiation 5. The Causes and Problems of Implementation and Continuation 6. Planning Doing and Coping with Change Part II Educational Change at the Local Level 7. The Teacher 8. The Principal 9. The Student 10. The District Administrator 11. The Consultant 12. The Parent and the Community Part III Educational Change at Regional and National Levels 13. Governments 14. Professional Preparation of Teachers 15. Professional Development of Educators 16. The Future of Educational Change,"['Meaning (existential)', 'Sociology', 'Mathematics education', 'Pedagogy', 'Psychology', 'Epistemology', 'Philosophy']","educational change, educational change, educational change, educational change, district administrator, governments, professional preparation, teachers, professional development, educators, educational change"
Paper_01816,Down-Regulation of Na<sup>+</sup>/K<sup>+</sup>ATPase Activity by Human Parvovirus B19 Capsid Protein VP1,"['Ahmad Almilaji', 'Kalina Szteyn', 'Evelyn Fein', 'Tatsiana Pakladok', 'Carlos Muñoz', 'Bernat Elvira', 'Syeda Tasneem Towhid', 'Ioana Alesutan', 'Ekaterina Shumilina', 'C.‐Thomas Bock', 'Reinhard Kandolf', 'Florian Läng']",2013,Cellular Physiology and Biochemistry,Journal,,638-648,31,4-5,10.1159/000350083,"Background/Aims: Human parvovirus B19 (B19V) may cause inflammatory cardiomyopathy (iCMP) which is accompanied by endothelial dysfunction. The B19V capsid protein VP1 contains a lysophosphatidylcholine producing phospholipase A2 (PLA) sequence. Lysophosphatidylcholine has in turn been shown to inhibit Na+/K+ ATPase. The present study explored whether VP1 modifies Na+/K+ ATPase activity. Methods:Xenopus oocytes were injected with cRNA encoding VP1 isolated from a patient suffering from fatal B19V-iCMP or cRNA encoding PLA2-negative VP1 mutant (H153A) and K+ induced pump current (Ipump) as well as ouabain-inhibited current (Iouabain) both reflecting Na+/K+-ATPase activity were determined by dual electrode voltage clamp. Results: Injection of cRNA encoding VP1, but not of VP1(H153A) or water, was followed by a significant decrease of both, Ipump and Iouabain in Xenopus oocytes. The effect was not modified by inhibition of transcription with actinomycin (10 µM for 36 hours) but was abrogated in the presence of PLA2 specific blocker 4-bromophenacylbromide (50 µM) and was mimicked by lysophosphatidylcholine (0.5 - 1 µg/ml). According to whole cell patch clamp, lysophosphatidylcholine (1 µg /ml) similarly decreased Ipump in human microvascular endothelial cells (HMEC). Conclusion: The B19V capsid protein VP1 is a powerful inhibitor of host cell Na+/K+ ATPase, an effect at least partially due to phospholipase A2 (PLA2) dependent formation of lysophosphatidylcholine.","['Lysophosphatidylcholine', 'Capsid', 'Molecular biology', 'Biology', 'Chemistry', 'Biochemistry', 'Phosphatidylcholine', 'Virus', 'Immunology', 'Phospholipid', 'Membrane']","human parvovirus b1, inflammatory cardiomyopathy, endothelial dysfunction, dual electrode voltage clamp, whole cell patch clamp, human microvascular endothelial cells"
Paper_01817,Quantum entanglement,"['Ryszard Horodecki', 'Paweł Horodecki', 'Michał Horodecki', 'Karol Horodecki']",2009,Reviews of Modern Physics,Journal,,865-942,81,2,10.1103/revmodphys.81.865,"All our former experience with application of quantum theory seems to say: {\it what is predicted by quantum formalism must occur in laboratory}. But the essence of quantum formalism - entanglement, recognized by Einstein, Podolsky, Rosen and Schr\""odinger - waited over 70 years to enter to laboratories as a new resource as real as energy. This holistic property of compound quantum systems, which involves nonclassical correlations between subsystems, is a potential for many quantum processes, including ``canonical'' ones: quantum cryptography, quantum teleportation and dense coding. However, it appeared that this new resource is very complex and difficult to detect. Being usually fragile to environment, it is robust against conceptual and mathematical tools, the task of which is to decipher its rich structure. This article reviews basic aspects of entanglement including its characterization, detection, distillation and quantifying. In particular, the authors discuss various manifestations of entanglement via Bell inequalities, entropic inequalities, entanglement witnesses, quantum cryptography and point out some interrelations. They also discuss a basic role of entanglement in quantum communication within distant labs paradigm and stress some peculiarities such as irreversibility of entanglement manipulations including its extremal form - bound entanglement phenomenon. A basic role of entanglement witnesses in detection of entanglement is emphasized.","['Quantum entanglement', 'Quantum discord', 'Physics', 'Quantum teleportation', 'Quantum cryptography', 'Squashed entanglement', 'Quantum mechanics', 'Multipartite entanglement', 'Theoretical physics', 'Quantum', 'Quantum capacity', 'Entanglement witness', 'Quantum information science', 'Quantum network', 'Quantum information']","quantum theory, quantum formalism, quantum formalism, entanglement, compound quantum systems, nonclassical correlations, quantum cryptography, quantum teleportation, dense coding, entanglement, distillation, quantifying, entanglement, bell inequalities, entropic inequalities, entanglement witnesses, quantum cryptography, entanglement, quantum communication, distant labs, ##ibility, entanglement, entanglement witnesses, entanglement, [PAD], [PAD], [PAD], [PAD], [PAD], [PAD] [PAD] [PAD], [PAD] [PAD], [PAD] [PAD], [PAD] [PAD] [PAD] [PAD], [PAD] [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD]"
Paper_01819,A Theory of the Term Structure of Interest Rates,"['John C. Cox', 'Jonathan E. Ingersoll', 'Stephen A. Ross']",1985,Econometrica,Journal,,385-385,53,2,10.2307/1911242,"This paper uses an intertemporal general equilibrium asset pricing model to study the term structure of interest rates. In this model, anticipations, risk aversion, investment alternatives, and preferences about the timing of consumption all play a role in determining bond prices. Many of the factors traditionally mentioned as influencing the term structure are thus included in a way which is fully consistent with maximizing behavior and rational expectations. The model leads to specific formulas for bond prices which are well suited for empirical testing. 1. INTRODUCTION THE TERM STRUCTURE of interest rates measures the relationship among the yields on default-free securities that differ only in their term to maturity. The determinants of this relationship have long been a topic of concern for economists. By offering a complete schedule of interest rates across time, the term structure embodies the market's anticipations of future events. An explanation of the term structure gives us a way to extract this information and to predict how changes in the underlying variables will affect the yield curve. In a world of certainty, equilibrium forward rates must coincide with future spot rates, but when uncertainty about future rates is introduced the analysis becomes much more complex. By and large, previous theories of the term structure have taken the certainty model as their starting point and have proceeded by examining stochastic generalizations of the certainty equilibrium relationships. The literature in the area is voluminous, and a comprehensive survey would warrant a paper in itself. It is common, however, to identify much of the previous work in the area as belonging to one of four strands of thought. First, there are various versions of the expectations hypothesis. These place predominant emphasis on the expected values of future spot rates or holdingperiod returns. In its simplest form, the expectations hypothesis postulates that bonds are priced so that the implied forward rates are equal to the expected spot rates. Generally, this approach is characterized by the following propositions: (a) the return on holding a long-term bond to maturity is equal to the expected return on repeated investment in a series of the short-term bonds, or (b) the expected rate of return over the next holding period is the same for bonds of all maturities. The liquidity preference hypothesis, advanced by Hicks [16], concurs with the importance of expected future spot rates, but places more weight on the effects of the risk preferences of market participants. It asserts that risk aversion will cause forward rates to be systematically greater than expected spot rates, usually","['Term (time)', 'Yield curve', 'Economics', 'Interest rate', 'Mathematical economics', 'Econometrics', 'Mathematics', 'Monetary economics', 'Physics', 'Quantum mechanics']","intertemporal general equilibrium asset pricing model, term structure, interest rates, anticipations, risk aversion, investment alternatives, bond prices, rational expectations, bond prices, interest rates, interest, equilibrium forward rates, certainty model, certainty equilibrium relationships, expectations hypothesis, holdingperiod returns, expectations hypothesis, liquidity preference hypothesis, risk preferences, risk aversion"
Paper_01822,Electrophoretic analysis of the major polypeptides of the human erythrocyte membrane,"['Grant Fairbanks', 'Theodore L. Steck', 'Donald F. H. Wallach']",1971,Biochemistry,Journal,,2606-2617,10,13,10.1021/bi00789a030,"ADVERTISEMENT RETURN TO ISSUEPREVArticleNEXTElectrophoretic analysis of the major polypeptides of the human erythrocyte membraneG. Fairbanks, Theodore L. Steck, and D. F. H. WallachCite this: Biochemistry 1971, 10, 13, 2606–2617Publication Date (Print):June 1, 1971Publication History Published online1 May 2002Published inissue 1 June 1971https://pubs.acs.org/doi/10.1021/bi00789a030https://doi.org/10.1021/bi00789a030research-articleACS PublicationsRequest reuse permissionsArticle Views4517Altmetric-Citations6745LEARN ABOUT THESE METRICSArticle Views are the COUNTER-compliant sum of full text article downloads since November 2008 (both PDF and HTML) across all institutions and individuals. These metrics are regularly updated to reflect usage leading up to the last few days.Citations are the number of other articles citing this article, calculated by Crossref and updated daily. Find more information about Crossref citation counts.The Altmetric Attention Score is a quantitative measure of the attention that a research article has received online. Clicking on the donut icon will load a page at altmetric.com with additional details about the score and the social media presence for the given article. Find more information on the Altmetric Attention Score and how the score is calculated. Share Add toView InAdd Full Text with ReferenceAdd Description ExportRISCitationCitation and abstractCitation and referencesMore Options Share onFacebookTwitterWechatLinked InRedditEmail Other access optionsGet e-Alertsclose Get e-Alerts","['Icon', 'Citation', 'Computer science', 'Social media', 'Altmetrics', 'Information retrieval', 'Library science', 'World Wide Web', 'Programming language']","##varticlenextelect, ##horetic analysis, polypeptides, human erythrocyte membrane, permissionsar, ##le views, ##f, ##f, altmetric attention score, social, altmetric attention score, ##citation, abstract, ##ation, references"
Paper_01824,"<i>EXPGUI</i>, a graphical user interface for<i>GSAS</i>",['Brian H. Toby'],2001,Journal of Applied Crystallography,Journal,,210-213,34,2,10.1107/s0021889801002242,A description and justification of the EXPGUI program is presented. This program implements a graphical user interface and shell for the GSAS single-crystal and Rietveld package. Use of the Tcl/Tk scripting language allows EXPGUI to be platform independent. Also included is a synopsis of how the program is implemented.,"['Scripting language', 'Graphical user interface', 'Computer science', 'Shell (structure)', 'Programming language', 'Interface (matter)', 'Graphical user interface testing', 'User interface', 'Computer graphics (images)', 'Operating system', 'User interface design', 'Materials science', 'Bubble', 'Maximum bubble pressure method', 'Composite material']","expgui, graphical user interface, rietveld, expgui, [PAD], [PAD] [PAD], [PAD] [PAD], [PAD] [PAD], [PAD], [PAD] [PAD], [PAD], [PAD] [PAD], [PAD] [PAD], [PAD], [PAD], [PAD], [PAD], [PAD] [PAD], [PAD], [PAD] [PAD], [PAD], [PAD], [PAD] [PAD], [PAD], [PAD] [PAD], [PAD], [PAD] [PAD], [PAD] [PAD], [PAD], [PAD], [PAD] [PAD]"
Paper_01825,Biomechanics and motor control of human movement,['David A. Winter'],1990,Choice Reviews Online,Journal,,28-2135,28,04,10.5860/choice.28-2135,"Preface to the Fourth Edition. 1 Biomechanics as an Interdiscipline. 1.0 Introduction. 1.1 Measurement, Description, Analysis, and Assessment. 1.2 Biomechanics and its Relationship with Physiology and Anatomy. 1.3 Scope of the Textbook. 1.4 References. 2 Signal Processing. 2.0 Introduction. 2.1 Auto- and Cross-Correlation Analyses. 2.2 Frequency Analysis. 2.3 Ensemble Averaging of Repetitive Waveforms. 2.4 References. 3 Kinematics. 3.0 Historical Development and Complexity of Problem. 3.1 Kinematic Conventions. 3.2 Direct Measurement Techniques. 3.3 Imaging Measurement Techniques. 3.4 Processing of Raw Kinematic Data. 3.5 Calculation of Other Kinematic Variables. 3.6 Problems Based on Kinematic Data. 3.7 References. 4 Anthropometry. 4.0 Scope of Anthropometry in Movement Biomechanics. 4.1 Density, Mass, and Inertial Properties. 4.2 Direct Experimental Measures. 4.3 Muscle Anthropometry. 4.4 Problems Based on Anthropometric Data. 4.5 References. 5 Kinetics: Forces and Moments of Force. 5.0 Biomechanical Models. 5.1 Basic Link-Segment Equations-the Free-Body Diagram. 5.2 Force Transducers and Force Plates. 5.3 Bone-on-Bone Forces During Dynamic Conditions. 5.4 Problems Based on Kinetic and Kinematic Data. 5.5 References. 6 Mechanical Work, Energy, and Power. 6.0 Introduction. 6.1 Efficiency. 6.2 Forms of Energy Storage. 6.3 Calculation of Internal and External Work. 6.4 Power Balances at Joints and Within Segments. 6.5 Problems Based on Kinetic and Kinematic Data. 6.6 References. 7 Three-Dimensional Kinematics and Kinetics. 7.0 Introduction. 7.1 Axes Systems. 7.2 Marker and Anatomical Axes Systems. 7.3 Determination of Segment Angular Velocities and Accelerations. 7.4 Kinetic Analysis of Reaction Forces and Moments. 7.5 Suggested Further Reading. 7.6 References. 8 Synthesis of Human Movement-Forward Solutions. 8.0 Introduction. 8.1 Review of Forward Solution Models. 8.2 Mathematical Formulation. 8.3 System Energy. 8.4 External Forces and Torques. 8.5 Designation of Joints. 8.6 Illustrative Example. 8.7 Conclusions. 8.8 References. 9 Muscle Mechanics. 9.0 Introduction. 9.1 Force-Length Characteristics of Muscles. 9.2 Force-Velocity Characteristics. 9.3 Muscle Modeling. 9.4 References. 10 Kinesiological Electromyography. 10.0 Introduction. 10.1 Electrophysiology of Muscle Contraction. 10.2 Recording of the Electromyogram. 10.3 Processing of the Electromyogram,. 10.4 Relationship between Electromyogram and Biomechanical Variables. 10.5 References. 11 Biomechanical Movement Synergies. 11.0 Introduction. 11.1 The Support Moment Synergy. 11.2 Medial/Lateral and Anterior/Posterior Balance in Standing. 11.3 Dynamic Balance during Walking. 11.4 References. APPENDICES. A. Kinematic, Kinetic, and Energy Data. Figure A.1 Walking Trial-Marker Locations and Mass and Frame Rate Information. Table A.1 Raw Coordinate Data (cm). Table A.2( a ) Filtered Marker Kinematics-Rib Cage and Greater Trochanter (Hip). Table A.2( b ) Filtered Marker Kinematics-Femoral Lateral Epicondyle (Knee) and Head of Fibula. Table A.2( c ) Filtered Marker Kinematics-Lateral Malleolus (Ankle) and Heel. Table A.2( d ) Filtered Marker Kinematics-Fifth Metatarsal and Toe. Table A.3( a ) Linear and Angular Kinematics-Foot. Table A.3( b ) Linear and Angular Kinematics-Leg. Table A.3( c ) Linear and Angular Kinematics-Thigh. Table A.3( d ) Linear and Angular Kinematics-1/2 HAT. Table A.4 Relative Joint Angular Kinematics-Ankle, Knee, and Hip. Table A.5( a ) Reaction Forces and Moments of Force-Ankle and Knee. Table A.5( b ) Reaction Forces and Moments of Force-Hip. Table A.6 Segment Potential, Kinetic, and Total Energies-Foot, Leg, Thigh, and1/2 HAT. Table A.7 Power Generation/Absorption and Transfer-Ankle, Knee, and Hip. B. Units and Definitions Related to Biomechanical and Electromyographical Measurements. Table B.1 Base SI Units. Table B.2 Derived SI Units. Index.","['Kinematics', 'Biomechanics', 'Computer science', 'Work (physics)', 'Mechanical energy', 'Simulation', 'Engineering', 'Power (physics)', 'Physics', 'Mechanical engineering', 'Classical mechanics', 'Anatomy', 'Medicine', 'Quantum mechanics']","biomechanics, ##ics, anatomy, signal processing, frequency analysis, ensemble averaging, repetitive waveforms, kinematics, kinematic conventions, direct measurement techniques, imaging measurement techniques, kin, ##op, movement, density, inertial properties, moments, force transducers, force plates, dynamic, energy storage, power balances, axes systems, anatomical axes systems, segment angular velocities, accelerations, kinetic analysis, reaction forces, forward solution models, mathematical formulation, external forces, torques"
Paper_01826,The diagnosis of mild cognitive impairment due to Alzheimer's disease: Recommendations from the National Institute on Aging‐Alzheimer's Association workgroups on diagnostic guidelines for Alzheimer's disease,"['Marilyn S. Albert', 'Steven T. DeKosky', 'Dennis W. Dickson', 'Bruno Dubois', 'Howard Feldman', 'Nick C. Fox', 'Anthony Gamst', 'David M. Holtzman', 'William J. Jagust', 'Ronald C. Petersen', 'Peter J. Snyder', 'María C. Carrillo', 'Bill Thies', 'Creighton H. Phelps']",2011,Alzheimer s & Dementia,Journal,,270-279,7,3,10.1016/j.jalz.2011.03.008,"The National Institute on Aging and the Alzheimer's Association charged a workgroup with the task of developing criteria for the symptomatic predementia phase of Alzheimer's disease (AD), referred to in this article as mild cognitive impairment due to AD. The workgroup developed the following two sets of criteria: (1) core clinical criteria that could be used by healthcare providers without access to advanced imaging techniques or cerebrospinal fluid analysis, and (2) research criteria that could be used in clinical research settings, including clinical trials. The second set of criteria incorporate the use of biomarkers based on imaging and cerebrospinal fluid measures. The final set of criteria for mild cognitive impairment due to AD has four levels of certainty, depending on the presence and nature of the biomarker findings. Considerable work is needed to validate the criteria that use biomarkers and to standardize biomarker analysis for use in community settings.","['Workgroup', 'Disease', 'Biomarker', ""Alzheimer's disease"", 'Cognitive impairment', 'Medicine', 'Dementia', 'Psychology', 'Cognition', 'Psychiatry', 'Pathology', 'Computer science', 'Computer network', 'Biochemistry', 'Chemistry']","alzheimer, symptomatic predementia phase, alzheimer, mild cognitive impairment, healthcare providers, advanced imaging techniques, cerebrospinal fluid analysis, clinical, cerebrospinal fluid measures, mild cognitive impairment, ##ers, biomarker analysis, community settings, [PAD]"
Paper_01828,The New Institutionalism in Organizational Analysis.,"['Alice O. Andrews', 'Walter W. Powell', 'Paul DiMaggio']",1993,Administrative Science Quarterly,Journal,,691-691,38,4,10.2307/2393344,"Long a fruitful area of scrutiny for students of organizations, the study of institutions is undergoing a renaissance in contemporary social science. This volume offers, for the first time, both often-cited foundation works and the latest writings of scholars associated with the approach to organization analysis. In their introduction, the editors discuss points of convergence and disagreement with institutionally oriented research in economics and political science, and locate the approach in relation to major developments in contemporary sociological theory. Several chapters consolidate the theoretical advances of the past decade, identify and clarify the paradigm's key ambiguities, and push the theoretical agenda in novel ways by developing sophisticated arguments about the linkage between institutional patterns and forms of social structure. The empirical studies that follow—involving such diverse topics as mental health clinics, art museums, large corporations, civil-service systems, and national polities—illustrate the explanatory power of institutional theory in the analysis of organizational change. Required reading for anyone interested in the sociology of organizations, the volume should appeal to scholars concerned with culture, political institutions, and social change.","['Sociology', 'Scrutiny', 'New institutionalism', 'Institutionalism', 'Politics', 'Organizational theory', 'Appeal', 'Social science', 'Explanatory power', 'Power (physics)', 'Epistemology', 'Institutional analysis', 'Political science', 'Law', 'Management', 'Economics', 'Philosophy', 'Physics', 'Quantum mechanics']","organizations, institutions, social science, organization analysis, institutional, economics, political science, sociological, institutional patterns, social structure, mental health clinics, art museums, large corporations, national polities, institutional theory, organizational change, organizations, culture, political institutions, social change"
Paper_01829,CD-HIT: accelerated for clustering the next-generation sequencing data,"['LiMin Fu', 'Beifang Niu', 'Zhengwei Zhu', 'Sitao Wu', 'Weizhong Li']",2012,Bioinformatics,Journal,,3150-3152,28,23,10.1093/bioinformatics/bts565,"CD-HIT is a widely used program for clustering biological sequences to reduce sequence redundancy and improve the performance of other sequence analyses. In response to the rapid increase in the amount of sequencing data produced by the next-generation sequencing technologies, we have developed a new CD-HIT program accelerated with a novel parallelization strategy and some other techniques to allow efficient clustering of such datasets. Our tests demonstrated very good speedup derived from the parallelization for up to ∼24 cores and a quasi-linear speedup for up to ∼8 cores. The enhanced CD-HIT is capable of handling very large datasets in much shorter time than previous versions.http://cd-hit.org.liwz@sdsc.eduSupplementary data are available at Bioinformatics online.","['Speedup', 'Computer science', 'Cluster analysis', 'Redundancy (engineering)', 'Data mining', 'Sequence (biology)', 'Parallel computing', 'Machine learning', 'Biology', 'Operating system', 'Genetics']","cluster, biological sequences, sequence redundancy, parallelization strategy, ##ment, bioinformatics"
Paper_01832,Fully optimized contracted Gaussian basis sets of triple zeta valence quality for atoms Li to Kr,"['Ansgar Schäfer', 'Christian Huber', 'Reinhart Ahlrichs']",1994,The Journal of Chemical Physics,Journal,,5829-5835,100,8,10.1063/1.467146,Contracted Gaussian basis sets of triple zeta valence (TZV) quality are presented for Li to Kr. The TZV bases are characterized by typically including a single contraction to describe inner shells and three basis functions for valence shells. All parameters—orbital exponents and contraction coefficients—have been determined by minimization of atomic self-consistent field ground state energies. Advantages and necessary modifications of TZV basis sets are discussed for simple test calculations of molecular energies and nuclear magnetic resonance (NMR) chemical shieldings in treatments with and without inclusion of electron correlation.,"['Gaussian', 'Valence (chemistry)', 'Chemistry', 'Atomic physics', 'Chemical shift', 'Atomic orbital', 'Ground state', 'Computational chemistry', 'Physics', 'Electron', 'Quantum mechanics', 'Physical chemistry', 'Organic chemistry']","contracted gaussian basis sets, triple zeta valence, t, ##v, single contraction, inner shells, basis functions, valence shells, orbital exponents, contraction coefficients, ##v, molecular energies, nuclear magnetic resonance, chemical shieldings, electron correlation, [PAD] [PAD] [PAD] [PAD]"
Paper_01834,On the Quantum Correction For Thermodynamic Equilibrium,['E. P. Wigner'],1932,Physical Review,Journal,,749-759,40,5,10.1103/physrev.40.749,"The probability of a configuration is given in classical theory by the Boltzmann formula $\mathrm{exp}[\ensuremath{-}\frac{V}{\mathrm{hT}}]$ where $V$ is the potential energy of this configuration. For high temperatures this of course also holds in quantum theory. For lower temperatures, however, a correction term has to be introduced, which can be developed into a power series of $h$. The formula is developed for this correction by means of a probability function and the result discussed.","['Physics', 'Boltzmann constant', 'Quantum', 'Series (stratigraphy)', 'Term (time)', 'Quantum mechanics', 'Power series', 'Function (biology)', 'Energy (signal processing)', 'Statistical physics', 'Mathematics', 'Mathematical analysis', 'Paleontology', 'Evolutionary biology', 'Biology']","classical theory, boltzmann formula, potential energy, quantum theory, correction term, power series, probability function"
Paper_01835,A Computer Movie Simulating Urban Growth in the Detroit Region,['Waldo Tobler'],1970,Economic Geography,Journal,,234-234,46,,10.2307/143141,"(1970). A Computer Movie Simulating Urban Growth in the Detroit Region. Economic Geography: Vol. 46, PROCEEDINGS International Geographical Union Commission on Quantitative Methods, pp. 234-240.","['Economic geography', 'Computer science', 'Geography']","computer movie, urban growth, detroit, economic geography, international geographical union, quantitative methods, [PAD], [PAD] [PAD] [PAD]"
Paper_01837,Toward an experimental ecology of human development.,['Urie Bronfenbrenner'],1977,American Psychologist,Journal,,513-531,32,7,10.1037/0003-066x.32.7.513,"A broader approach to research in hu- j man development is proposed that focuses on the pro-  gressive accommodation, throughout the life span, between the growing human organism and the changing environments in which it actually lives and grows.  The latter include not only the immediate settings containing the developing person but also the larger social contexts, both formal and informal, in which these settings are embedded. In terms of method, the approach emphasizes the use of rigorousj^d^igned exp_erjments, both naturalistic and contrived, beginning in the early stages of the research process. The chang- ing relation between person and environment is con- ceived in systems terms. These systems properties are set forth in a series of propositions, each illus- trated by concrete research examples.","['Ecology', 'Human ecology', 'Psychology', 'Human development (humanity)', 'Biology', 'Political science', 'Law']",
Paper_01839,Random-Effects Models for Longitudinal Data,"['Nan M. Laird', 'James H. Ware']",1982,Biometrics,Journal,,963-963,38,4,10.2307/2529876,"Models for the analysis of longitudinal data must recognize the relationship between serial observations on the same unit. Multivariate models with general covariance structure are often difficult to apply to highly unbalanced data, whereas two-stage random-effects models can be used easily. In two-stage models, the probability distributions for the response vectors of different individuals belong to a single family, but some random-effects parameters vary across individuals, with a distribution specified at the second stage. A general family of models is discussed, which includes both growth models and repeated-measures models as special cases. A unified approach to fitting these models, based on a combination of empirical Bayes and maximum likelihood estimation of model parameters and using the EM algorithm, is discussed. Two examples are taken from a current epidemiological study of the health effects of air pollution.","['Random effects model', 'Covariance', ""Bayes' theorem"", 'Multivariate statistics', 'Statistics', 'Econometrics', 'Computer science', 'Mathematics', 'Longitudinal data', 'Mixed model', 'Bayesian probability', 'Data mining', 'Medicine', 'Meta-analysis', 'Internal medicine']","longitudinal data, serial observations, multivariate models, general covariance structure, unbalance, probability distributions, response vectors, growth models, empirical bayes, maximum likelihood estimation, em algorithm, ##ide, health effects, air pollution"
Paper_01840,"Glide: A New Approach for Rapid, Accurate Docking and Scoring. 1. Method and Assessment of Docking Accuracy","['Richard A. Friesner', 'Jay L. Banks', 'Robert B. Murphy', 'Thomas A. Halgren', 'Jasna Klicić', 'Daniel T. Mainz', 'Matthew P. Repasky', 'Eric H. Knoll', 'Mee Shelley', 'Jason K. Perry', 'David E. Shaw', 'Perry C. Francis', 'Peter S. Shenkin']",2004,Journal of Medicinal Chemistry,Journal,,1739-1749,47,7,10.1021/jm0306430,"Unlike other methods for docking ligands to the rigid 3D structure of a known protein receptor, Glide approximates a complete systematic search of the conformational, orientational, and positional space of the docked ligand. In this search, an initial rough positioning and scoring phase that dramatically narrows the search space is followed by torsionally flexible energy optimization on an OPLS-AA nonbonded potential grid for a few hundred surviving candidate poses. The very best candidates are further refined via a Monte Carlo sampling of pose conformation; in some cases, this is crucial to obtaining an accurate docked pose. Selection of the best docked pose uses a model energy function that combines empirical and force-field-based terms. Docking accuracy is assessed by redocking ligands from 282 cocrystallized PDB complexes starting from conformationally optimized ligand geometries that bear no memory of the correctly docked pose. Errors in geometry for the top-ranked pose are less than 1 Å in nearly half of the cases and are greater than 2 Å in only about one-third of them. Comparisons to published data on rms deviations show that Glide is nearly twice as accurate as GOLD and more than twice as accurate as FlexX for ligands having up to 20 rotatable bonds. Glide is also found to be more accurate than the recently described Surflex method.","['Docking (animal)', 'Chemistry', 'Force field (fiction)', 'OPLS', 'Searching the conformational space for docking', 'Monte Carlo method', 'Energy minimization', 'Protein Data Bank (RCSB PDB)', 'Algorithm', 'Crystallography', 'Computational chemistry', 'Molecular dynamics', 'Artificial intelligence', 'Stereochemistry', 'Protein structure', 'Computer science', 'Mathematics', 'Statistics', 'Medicine', 'Biochemistry', 'Nursing', 'Water model']","rigid 3d structure, protein receptor, glide, position, scoring, torsionally flexible energy optimization, monte carlo sampling, model energy function, docking, cocr, rms deviations, glide, rotatable bonds, glide, surflex method"
Paper_01841,Power analysis and determination of sample size for covariance structure modeling.,"['Robert C. MacCallum', 'Michael W. Browne', 'Hazuki M. Sugawara']",1996,Psychological Methods,Journal,,130-149,1,2,10.1037/1082-989x.1.2.130,"A framework for hypothesis testing and power analysis in the assessment of fit of covariance structure models is presented. We emphasize the value of confidence intervals for fit indices, and we stress the relationship of confidence intervals to a framework for hypothesis testing. The approach allows for testing null hypotheses of not-good fit, reversing the role of the null hypothesis in conventional tests of model fit, so that a significant result provides strong support for good fit. The approach also allows for direct estimation of power, where effect size is defined in terms of a null and alternative value of the root-mean-square error of approximation fit index proposed by J. H. Steiger and J. M. Lind (1980). It is also feasible to determine minimum sample size required to achieve a given level of power for any test of fit in this framework. Computer programs and examples are provided for power analyses and calculation of minimum sample sizes.","['Covariance', 'Sample size determination', 'Statistics', 'Analysis of covariance', 'Statistical power', 'Statistical analysis', 'Sample (material)', 'Mathematics', 'Power (physics)', 'Econometrics', 'Physics', 'Chromatography', 'Chemistry', 'Quantum mechanics']","hypothesis testing, power analysis, fit, covariance structure models, confidence intervals, fit indices, confidence intervals, hypothesis testing, null hypotheses, null hypothesis, model fit, effect size, approximation fit index, computer programs, power analyses, minimum sample sizes, [PAD], [PAD] [PAD]"
Paper_01842,An update of the Angiosperm Phylogeny Group classification for the orders and families of flowering plants: APG IV,[],2016,Botanical Journal of the Linnean Society,Journal,,1-20,181,1,10.1111/boj.12385,"An update of the Angiosperm Phylogeny Group (APG) classification of the orders and families of angiosperms is presented. Several new orders are recognized: Boraginales, Dilleniales, Icacinales, Metteniusiales and Vahliales. This brings the total number of orders and families recognized in the APG system to 64 and 416, respectively. We propose two additional informal major clades, superrosids and superasterids, that each comprise the additional orders that are included in the larger clades dominated by the rosids and asterids. Families that made up potentially monofamilial orders, Dasypogonaceae and Sabiaceae, are instead referred to Arecales and Proteales, respectively. Two parasitic families formerly of uncertain positions are now placed: Cynomoriaceae in Saxifragales and Apodanthaceae in Cucurbitales. Although there is evidence that some families recognized in APG III are not monophyletic, we make no changes in Dioscoreales and Santalales relative to APG III and leave some genera in Lamiales unplaced (e.g. Peltanthera). These changes in familial circumscription and recognition have all resulted from new results published since APG III, except for some changes simply due to nomenclatural issues, which include substituting Asphodelaceae for Xanthorrhoeaceae (Asparagales) and Francoaceae for Melianthaceae (Geraniales); however, in Francoaceae we also include Bersamaceae, Ledocarpaceae, Rhynchothecaceae and Vivianiaceae. Other changes to family limits are not drastic or numerous and are mostly focused on some members of the lamiids, especially the former Icacinaceae that have long been problematic with several genera moved to the formerly monogeneric Metteniusaceae, but minor changes in circumscription include Aristolochiaceae (now including Lactoridaceae and Hydnoraceae; Aristolochiales), Maundiaceae (removed from Juncaginaceae; Alismatales), Restionaceae (now re-including Anarthriaceae and Centrolepidaceae; Poales), Buxaceae (now including Haptanthaceae; Buxales), Peraceae (split from Euphorbiaceae; Malpighiales), recognition of Petenaeaceae (Huerteales), Kewaceae, Limeaceae, Macarthuriaceae and Microteaceae (all Caryophyllales), Petiveriaceae split from Phytolaccaceae (Caryophyllales), changes to the generic composition of Ixonanthaceae and Irvingiaceae (with transfer of Allantospermum from the former to the latter; Malpighiales), transfer of Pakaraimaea (formerly Dipterocarpaceae) to Cistaceae (Malvales), transfer of Borthwickia, Forchhammeria, Stixis and Tirania (formerly all Capparaceae) to Resedaceae (Brassicales), Nyssaceae split from Cornaceae (Cornales), Pteleocarpa moved to Gelsemiaceae (Gentianales), changes to the generic composition of Gesneriaceae (Sanango moved from Loganiaceae) and Orobanchaceae (now including Lindenbergiaceae and Rehmanniaceae) and recognition of Mazaceae distinct from Phrymaceae (all Lamiales).","['Biology', 'Circumscription', 'Monophyly', 'Clade', 'Botany', 'Phylogenetics', 'Zoology', 'Evolutionary biology', 'Genetics', 'Artificial intelligence', 'Computer science', 'Gene']","angiosperm phylogeny group, angiosperms, boraginal, dillenial, icacinal, mettenius, vahli, superros, superaster, aster, dasypogonac, sabia, ##cal, protea, cynomori, saxifragales, ##oda, dios, santalal, lam, ##ltant, ##phode, ##rhoe, asparagales, franco, meliantha, geraniales, francoaceae, bersamac, ledocarpaceae, r, ##otheca, vivian, ##acina, ##tenius, aristolochia, lactorida, hydnoraceae, aristolochiales, maund, juncagina, alismatales, restion, anarthria, centrole, poales, buxa, haptantha, bu, peraceae"
Paper_01845,Economic Growth in a Cross Section of Countries,['Robert J. Barro'],1991,The Quarterly Journal of Economics,Journal,,407-407,106,2,10.2307/2937943,"For 98 countries in the period 1960–1985, the growth rate of real per capita GDP is positively related to initial human capital (proxied by 1960 school-enrollment rates) and negatively related to the initial (1960) level of real per capita GDP. Countries with higher human capital also have lower fertility rates and higher ratios of physical investment to GDP. Growth is inversely related to the share of government consumption in GDP, but insignificantly related to the share of public investment. Growth rates are positively related to measures of political stability and inversely related to a proxy for market distortions.","['Economics', 'Per capita', 'Real gross domestic product', 'Human capital', 'Proxy (statistics)', 'Gross domestic product', 'Investment (military)', 'Demographic economics', 'Monetary economics', 'Consumption (sociology)', 'Politics', 'Macroeconomics', 'Economic growth', 'Demography', 'Population', 'Social science', 'Machine learning', 'Sociology', 'Computer science', 'Law', 'Political science']","real per capita gdp, initial human capital, human capital, physical investment, government consumption, public investment, political stability, market distortions, [PAD] [PAD]"
Paper_01846,The Role of Superoxide Anion in the Autoxidation of Epinephrine and a Simple Assay for Superoxide Dismutase,"['Hara P. Misra', 'Irwin Fridovich']",1972,Journal of Biological Chemistry,Journal,,3170-3175,247,10,10.1016/s0021-9258(19)45228-9,"The rate of autoxidation of epinephrine and the sensitivity of this autoxidation to inhibition by superoxide dismutase were both augmented, as the pH was raised from 7.8 → 10.2. O2-, generated by the xanthine oxidase reaction, caused the oxidation of epinephrine to adrenochrome and the yield of adrenochrome produced per O2- introduced, increased with increasing pH in the range 7.8 → 10.2 and also increased with increasing concentration of epinephrine. These results, in conjunction with complexities in the kinetics of adrenochrome accumulation, lead to the proposal that the autoxidation of epinephrine proceeds by at least two distinct pathways, only one of which is a free radical chain reaction involving O2- and hence inhibitable by superoxide dismutase. This chain reaction accounted for a progressively greater fraction of the total oxidation as the pH was raised. The ability of superoxide dismutase to inhibit the autoxidation of epinephrine at pH 10.2 has been used as the basis of a convenient and sensitive assay for this enzyme.","['Adrenochrome', 'Autoxidation', 'Chemistry', 'Superoxide', 'Superoxide dismutase', 'Epinephrine', 'Xanthine oxidase', 'Catechol', 'Biochemistry', 'Photochemistry', 'Enzyme', 'Endocrinology', 'Biology']","##xidation, superoxide dismutase, xanthine oxidase reaction, adrenochrome, free radical chain reaction, superoxide dismutase, superoxide dismuta, [PAD], [PAD]"
Paper_01847,Child abuse: Adolescent records vs. adult recall,"['Donna Della Femina', 'Catherine A. Yeager', 'Dorothy Otnow Lewis']",1990,Child Abuse & Neglect,Journal,,227-231,14,2,10.1016/0145-2134(90)90033-p,"In a follow-up study of incarcerated Connecticut youth, 69 subjects were interviewed during young adulthood. On follow-up, 26 gave histories of abuse discrepant with histories obtained from records and interviews conducted in adolescence. Eleven subjects agreed to an additional clarification interview, at which time they were apprised of the discrepancies. Of these, eight had adolescent records indicating that abuse had occurred but denied abuse during the adult follow-up interview. The remaining three had adolescent records indicating no abuse had ever occurred, but, on follow-up, reported having been abused. The additional clarification interviews revealed that all 11 subjects with discrepant histories had, in fact, been abused. Reasons for these discrepant data and strategies to enhance the investigator's ability to obtain accurate data regarding abuse are discussed. 69 personnes qui avaient été emprisonnées dans le Connecticut autrefois ont été soumises à un entretien alors qu'elles avaient atteint l'âge adulte. Dans ce suivi, 26 individus ont donné des récits de sévices subis qui n'étaient pas les mêmes que les récits extraits de leur dossier et entretiens enregistrés pendant l'adolescence. 11 de ces personnes ont accepté d'avoir un entretien de clarification supplémentaire au cours duquel on a évalué les discordances avec leurs anciens dossiers. Sur ces 11, 8 avaient des dossiers d'adolescent indiquant que des sévices avaient été subis; au cours de l'entretien de suivi à l'âge adulte, ils ont rétracté ces affirmations. Les 3 autres avaient indiqué qu'ils n'avaient pas subi de sévices comme adolescent mais au contraire à l'âge adulte ils ont dit qu'ils avaient en fait été maltraités. L'entretien de clarification additionnel a pu démontrer que tous ces 11 sujets sans exception avaient en fait bien été l'objet de sévices. Les raisons pour ces données discordantes et les stratégies à utiliser lorsqu'on interroge ce genre de personne font l'objet d'une discussion puisque l'on désire obtenir des données fiables. En una investigación complementaria dejóvenes encarcelados en Connecticut, 69 sujetos fueron entrevistados cuando eran adultos jóvenes. En las entrevistas, 26 dieron historias de abuso discrepantes con las historias obtenidas de documentos y entrevistas obtenidos durante su adolescencia. Once sujetos estuvieron de acuerdo con participar en una entrevista adicional de clarificación durante la cual se les informó de las discrepancias. Los documentos obtenidos durante la adolescencia de ocho de ellos indicaron que había ocumdo abuso, pero este fué negado durante la entrevista complementaria cuando adultos. Los documentos acerca de los otros tres indicaron que no había ocurrido abuso durante la adolescencia, pero ellos afirmaron en la entrevista complementaria cuando adultos que sí había ocurrido. Entrevistas clarificadoras subsecuentes revelaron que todos los once con historias discrepantes habían, en realidad, sido abusados. Se comentan las causas de las discrepancias así como estrategias para acrecentar la capacidad del investigador para obtener datos exactos con respecto al abuso.","['Psychology', 'Child abuse', 'Sexual abuse', 'Medicine', 'Poison control', 'Suicide prevention', 'Psychiatry', 'Medical emergency']",incarcerated connecticut youth
Paper_01849,"The Modern Industrial Revolution, Exit, and the Failure of Internal Control Systems",['Michael C. Jensen'],1993,The Journal of Finance,Journal,,831-880,48,3,10.1111/j.1540-6261.1993.tb04022.x,"ABSTRACT Since 1973 technological, political, regulatory, and economic forces have been changing the worldwide economy in a fashion comparable to the changes experienced during the nineteenth century Industrial Revolution. As in the nineteenth century, we are experiencing declining costs, increasing average (but decreasing marginal) productivity of labor, reduced growth rates of labor income, excess capacity, and the requirement for downsizing and exit. The last two decades indicate corporate internal control systems have failed to deal effectively with these changes, especially slow growth and the requirement for exit. The next several decades pose a major challenge for Western firms and political systems as these forces continue to work their way through the worldwide economy.","['Productivity', 'Industrial Revolution', 'Politics', 'Control (management)', 'Economics', 'Work (physics)', 'Market economy', 'Business', 'Economic policy', 'Economic system', 'Political science', 'Economic growth', 'Engineering', 'Management', 'Law', 'Mechanical engineering']","worldwide economy, nineteenth, labor income, excess capacity, corporate internal control systems, political systems, worldwide economy, [PAD]"
Paper_01851,Institutions and organizations,['W. Richard Scott'],1995,Choice Reviews Online,Journal,,33-1848,33,03,10.5860/choice.33-1848,"Institutions—the structures, practices, and meanings that define what people and organizations think, do, and aspire to—are created through process. They are “work in progress” that involves continual efforts to maintain, modify, or disturb them. Institutional logics are also in motion, holding varying degrees of dominance that change over time. This volume brings together two streams of thought within organization theory—institutional theory and process perspective—to advocate for stronger process ontology that highlights institutions as emergent, generative, political, and social. A stronger process view allows us to challenge our understanding of central concepts within institutional theory, such as “loose coupling,” “institutional work,” the work of institutional logics on the ground, and institutionalization between diffusion and translation. Enriched with an emphasis on practice and widened by taking a broad view of institutions, this volume draws on the Ninth International Symposium on Process Organization Studies to offer key insights that will inform our thinking of institutions as processes.","['Institutionalisation', 'Process (computing)', 'Work (physics)', 'Sociology', 'Politics', 'Perspective (graphical)', 'Institutional theory', 'Dominance (genetics)', 'Organization studies', 'Organizational theory', 'Political science', 'Epistemology', 'Public relations', 'Knowledge management', 'Management', 'Social science', 'Economics', 'Computer science', 'Mechanical engineering', 'Biochemistry', 'Chemistry', 'Philosophy', 'Artificial intelligence', 'Law', 'Gene', 'Engineering', 'Operating system']","institutions, institutional logics, organization theory, institutional theory, process perspective, process ontology, institutional theory, loose coupling, institutional work, institutional logics, institutionalization, institutions, process organization studies, institutions"
Paper_01853,2010 Rheumatoid arthritis classification criteria: An American College of Rheumatology/European League Against Rheumatism collaborative initiative,"['Daniel Aletaha', 'Tuhina Neogi', 'Alan J. Silman', 'Julia Funovits', 'David T. Felson', 'Clifton O. Bingham', 'Neal S. Birnbaum', 'Gerd R Burmester', 'Vivian P. Bykerk', 'Marc D. Cohen', 'Bernard Combe', 'Karen H. Costenbader', 'Maxime Dougados', 'Paul Emery', 'Gianfranco Ferraccioli', 'Johanna M. W. Hazes', 'Kathryn Hobbs', 'T. Huizinga', 'Arthur Kavanaugh', 'Jonathan Kay', 'Tore K. Kvien', 'Timothy Laing', 'Philip J. Mease', 'Henri A. Ménard', 'Larry W. Moreland', 'Raymond L. Naden', 'Theodore Pincus', 'Josef S Smolen', 'Ewa Stanisławska‐Biernat', 'Deborah Symmons', 'Paul P. Tak', 'Katherine S. Upchurch', 'Jiří Vencovský', 'Frederick Wolfe', 'Gillian Hawker']",2010,Arthritis & Rheumatism,Journal,,2569-2581,62,9,10.1002/art.27584,"The 1987 American College of Rheumatology (ACR; formerly, the American Rheumatism Association) classification criteria for rheumatoid arthritis (RA) have been criticized for their lack of sensitivity in early disease. This work was undertaken to develop new classification criteria for RA.A joint working group from the ACR and the European League Against Rheumatism developed, in 3 phases, a new approach to classifying RA. The work focused on identifying, among patients newly presenting with undifferentiated inflammatory synovitis, factors that best discriminated between those who were and those who were not at high risk for persistent and/or erosive disease--this being the appropriate current paradigm underlying the disease construct ""rheumatoid arthritis.""In the new criteria set, classification as ""definite RA"" is based on the confirmed presence of synovitis in at least 1 joint, absence of an alternative diagnosis that better explains the synovitis, and achievement of a total score of 6 or greater (of a possible 10) from the individual scores in 4 domains: number and site of involved joints (score range 0-5), serologic abnormality (score range 0-3), elevated acute-phase response (score range 0-1), and symptom duration (2 levels; range 0-1).This new classification system redefines the current paradigm of RA by focusing on features at earlier stages of disease that are associated with persistent and/or erosive disease, rather than defining the disease by its late-stage features. This will refocus attention on the important need for earlier diagnosis and institution of effective disease-suppressing therapy to prevent or minimize the occurrence of the undesirable sequelae that currently comprise the paradigm underlying the disease construct ""rheumatoid arthritis.""","['Rheumatism', 'Medicine', 'Rheumatology', 'Rheumatoid arthritis', 'Synovitis', 'Internal medicine', 'Disease', 'Physical therapy', 'League', 'Arthritis', 'Physics', 'Astronomy']","american college, american r, rheumatoid arthritis, rhe, rheumatoid arthritis, ser, ##gic abnormality, symptom duration, rheumatoid arthritis, [PAD]"
Paper_01856,Pathological findings of COVID-19 associated with acute respiratory distress syndrome,"['Zhe Xu', 'Lei Shi', 'Yijin Wang', 'Jiyuan Zhang', 'Lei Huang', 'Chao Zhang', 'Shuhong Liu', 'Peng Zhao', 'Hongxia Liu', 'Li Zhu', 'Yanhong Tai', 'Changqing Bai', 'Tingting Gao', 'Jin‐Wen Song', 'Peng Xia', 'Jinghui Dong', 'Jingmin Zhao', 'Fu‐Sheng Wang']",2020,The Lancet Respiratory Medicine,Journal,,420-422,8,4,10.1016/s2213-2600(20)30076-x,"Since late December, 2019, an outbreak of a novel coronavirus disease (COVID-19; previously known as 2019-nCoV)1Wu F Zhao S Yu B et al.A new coronavirus associated with human respiratory disease in China.Nature. 2020; (published online Feb 3.)DOI:10.1038/s41586-020-2008-3Crossref Scopus (7724) Google Scholar, 2Huang C Wang Y Li X et al.Clinical features of patients infected with 2019 novel coronavirus in Wuhan, China.Lancet. 2020; 395: 497-506Summary Full Text Full Text PDF PubMed Scopus (33292) Google Scholar was reported in Wuhan, China,2Huang C Wang Y Li X et al.Clinical features of patients infected with 2019 novel coronavirus in Wuhan, China.Lancet. 2020; 395: 497-506Summary Full Text Full Text PDF PubMed Scopus (33292) Google Scholar which has subsequently affected 26 countries worldwide. In general, COVID-19 is an acute resolved disease but it can also be deadly, with a 2% case fatality rate. Severe disease onset might result in death due to massive alveolar damage and progressive respiratory failure.2Huang C Wang Y Li X et al.Clinical features of patients infected with 2019 novel coronavirus in Wuhan, China.Lancet. 2020; 395: 497-506Summary Full Text Full Text PDF PubMed Scopus (33292) Google Scholar, 3Chan JF Yuan S Kok KH et al.A familial cluster of pneumonia associated with the 2019 novel coronavirus indicating person-to-person transmission: a study of a family cluster.Lancet. 2020; 395: 514-523Summary Full Text Full Text PDF PubMed Scopus (6268) Google Scholar As of Feb 15, about 66 580 cases have been confirmed and over 1524 deaths. However, no pathology has been reported due to barely accessible autopsy or biopsy.2Huang C Wang Y Li X et al.Clinical features of patients infected with 2019 novel coronavirus in Wuhan, China.Lancet. 2020; 395: 497-506Summary Full Text Full Text PDF PubMed Scopus (33292) Google Scholar, 3Chan JF Yuan S Kok KH et al.A familial cluster of pneumonia associated with the 2019 novel coronavirus indicating person-to-person transmission: a study of a family cluster.Lancet. 2020; 395: 514-523Summary Full Text Full Text PDF PubMed Scopus (6268) Google Scholar Here, we investigated the pathological characteristics of a patient who died from severe infection with severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) by postmortem biopsies. This study is in accordance with regulations issued by the National Health Commission of China and the Helsinki Declaration. Our findings will facilitate understanding of the pathogenesis of COVID-19 and improve clinical strategies against the disease. A 50-year-old man was admitted to a fever clinic on Jan 21, 2020, with symptoms of fever, chills, cough, fatigue and shortness of breath. He reported a travel history to Wuhan Jan 8–12, and that he had initial symptoms of mild chills and dry cough on Jan 14 (day 1 of illness) but did not see a doctor and kept working until Jan 21 (figure 1). Chest x-ray showed multiple patchy shadows in both lungs (appendix p 2), and a throat swab sample was taken. On Jan 22 (day 9 of illness), the Beijing Centers for Disease Control (CDC) confirmed by reverse real-time PCR assay that the patient had COVID-19. He was immediately admitted to the isolation ward and received supplemental oxygen through a face mask. He was given interferon alfa-2b (5 million units twice daily, atomisation inhalation) and lopinavir plus ritonavir (500 mg twice daily, orally) as antiviral therapy, and moxifloxacin (0·4 g once daily, intravenously) to prevent secondary infection. Given the serious shortness of breath and hypoxaemia, methylprednisolone (80 mg twice daily, intravenously) was administered to attenuate lung inflammation. Laboratory tests results are listed in the appendix (p 4). After receiving medication, his body temperature reduced from 39·0 to 36·4 °C. However, his cough, dyspnoea, and fatigue did not improve. On day 12 of illness, after initial presentation, chest x-ray showed progressive infiltrate and diffuse gridding shadow in both lungs. He refused ventilator support in the intensive care unit repeatedly because he suffered from claustrophobia; therefore, he received high-flow nasal cannula (HFNC) oxygen therapy (60% concentration, flow rate 40 L/min). On day 13 of illness, the patient's symptoms had still not improved, but oxygen saturation remained above 95%. In the afternoon of day 14 of illness, his hypoxaemia and shortness of breath worsened. Despite receiving HFNC oxygen therapy (100% concentration, flow rate 40 L/min), oxygen saturation values decreased to 60%, and the patient had sudden cardiac arrest. He was immediately given invasive ventilation, chest compression, and adrenaline injection. Unfortunately, the rescue was not successful, and he died at 18:31 (Beijing time). Biopsy samples were taken from lung, liver, and heart tissue of the patient. Histological examination showed bilateral diffuse alveolar damage with cellular fibromyxoid exudates (figure 2A, B). The right lung showed evident desquamation of pneumocytes and hyaline membrane formation, indicating acute respiratory distress syndrome (ARDS; figure 2A). The left lung tissue displayed pulmonary oedema with hyaline membrane formation, suggestive of early-phase ARDS (figure 2B). Interstitial mononuclear inflammatory infiltrates, dominated by lymphocytes, were seen in both lungs. Multinucleated syncytial cells with atypical enlarged pneumocytes characterised by large nuclei, amphophilic granular cytoplasm, and prominent nucleoli were identified in the intra-alveolar spaces, showing viral cytopathic-like changes. No obvious intranuclear or intracytoplasmic viral inclusions were identified. The pathological features of COVID-19 greatly resemble those seen in SARS and Middle Eastern respiratory syndrome (MERS) coronavirus infection.4Ding Y Wang H Shen H et al.The clinical pathology of severe acute respiratory syndrome (SARS): a report from China.J Pathol. 2003; 200: 282-289Crossref PubMed Scopus (628) Google Scholar, 5Ng DL Al Hosani F Keating MK et al.Clinicopathologic, immunohistochemical, and ultrastructural findings of a fatal case of Middle East respiratory syndrome coronavirus infection in the United Arab Emirates, April 2014.Am J Pathol. 2016; 186: 652-658Summary Full Text Full Text PDF PubMed Scopus (311) Google Scholar In addition, the liver biopsy specimens of the patient with COVID-19 showed moderate microvesicular steatosis and mild lobular and portal activity (figure 2C), indicating the injury could have been caused by either SARS-CoV-2 infection or drug-induced liver injury. There were a few interstitial mononuclear inflammatory infiltrates, but no other substantial damage in the heart tissue (figure 2D). Peripheral blood was prepared for flow cytometric analysis. We found that the counts of peripheral CD4 and CD8 T cells were substantially reduced, while their status was hyperactivated, as evidenced by the high proportions of HLA-DR (CD4 3·47%) and CD38 (CD8 39·4%) double-positive fractions (appendix p 3). Moreover, there was an increased concentration of highly proinflammatory CCR6+ Th17 in CD4 T cells (appendix p 3). Additionally, CD8 T cells were found to harbour high concentrations of cytotoxic granules, in which 31·6% cells were perforin positive, 64·2% cells were granulysin positive, and 30·5% cells were granulysin and perforin double-positive (appendix p 3). Our results imply that overactivation of T cells, manifested by increase of Th17 and high cytotoxicity of CD8 T cells, accounts for, in part, the severe immune injury in this patient. X-ray images showed rapid progression of pneumonia and some differences between the left and right lung. In addition, the liver tissue showed moderate microvesicular steatosis and mild lobular activity, but there was no conclusive evidence to support SARS-CoV-2 infection or drug-induced liver injury as the cause. There were no obvious histological changes seen in heart tissue, suggesting that SARS-CoV-2 infection might not directly impair the heart. Although corticosteroid treatment is not routinely recommended to be used for SARS-CoV-2 pneumonia,1Wu F Zhao S Yu B et al.A new coronavirus associated with human respiratory disease in China.Nature. 2020; (published online Feb 3.)DOI:10.1038/s41586-020-2008-3Crossref Scopus (7724) Google Scholar according to our pathological findings of pulmonary oedema and hyaline membrane formation, timely and appropriate use of corticosteroids together with ventilator support should be considered for the severe patients to prevent ARDS development. Lymphopenia is a common feature in the patients with COVID-19 and might be a critical factor associated with disease severity and mortality.3Chan JF Yuan S Kok KH et al.A familial cluster of pneumonia associated with the 2019 novel coronavirus indicating person-to-person transmission: a study of a family cluster.Lancet. 2020; 395: 514-523Summary Full Text Full Text PDF PubMed Scopus (6268) Google Scholar Our clinical and pathological findings in this severe case of COVID-19 can not only help to identify a cause of death, but also provide new insights into the pathogenesis of SARS-CoV-2-related pneumonia, which might help physicians to formulate a timely therapeutic strategy for similar severe patients and reduce mortality. This online publication has been corrected. The corrected version first appeared at thelancet.com/respiratory on February 25, 2020 This online publication has been corrected. The corrected version first appeared at thelancet.com/respiratory on February 25, 2020 Contributors F-SW and JZhao conceived the study. ZX and LS designed the study. F-SW and JZhao supervised the overall study. ZX and LS collected specimens. LH, PZ, and HL collected clinical data. SL collected pathological images. LZ and TG disposed of tissues and H&E staining. LS and YW analysed and interpreted the data. YT analysed the pathological data. CB and JD formulated the treatment regimen and analysed the x-ray images. JZhang, JS, PX, and CZ did the flow cytometric analysis. LS and YW made the tables and figures. LS and YW searched the literature. LS and YW wrote the manuscript. CZ, F-SW, and JZhao critically revised the manuscript. Declaration of interests We declare no competing interests. Download .pdf (1.17 MB) Help with pdf files Supplementary appendix Correction to Lancet Respir Med 2020; 8: 420–22Xu Z, Shi L, Wang Y, et al. Pathological findings of COVID-19 associated with acute respiratory distress syndrome. Lancet Respir Med 2020; 8: 420–22—In this Case Report ""by obtaining biopsy samples at autopsy"" has been replaced with ""by postmortem biopsies"" in paragraph 1, ""microvascular"" has been replaced with ""microvesicular"" in two incidences in paragraph 5, and ""(B) Frequency of Th17 (CD4+ CCR6+CCR4+) subset"" has been changed to ""(B) Frequency of Th17 (CD4+ CCR6+) subset"" on page 3 of the appendix. Full-Text PDF","['Medicine', 'Coronavirus disease 2019 (COVID-19)', 'Acute respiratory distress', 'Pathological', '2019-20 coronavirus outbreak', 'Severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2)', 'Betacoronavirus', 'Coronavirus Infections', 'Intensive care medicine', 'Respiratory distress', 'Respiratory system', 'MEDLINE', 'Pandemic', 'Internal medicine', 'Pathology', 'Lung', 'Disease', 'Anesthesia', 'Infectious disease (medical specialty)', 'Outbreak', 'Political science', 'Law']","human respiratory disease, progressive respiratory failure, ##lia"
Paper_01858,Applied Regression Analysis and Other Multivariable Methods,"['Esteban Walker', 'David G. Kleinbaum', 'Lawrence L. Kupper', 'Keith E. Muller']",1989,Technometrics,Journal,,117-117,31,1,10.2307/1270375,"1. CONCEPTS AND EXAMPLES OF RESEARCH. Concepts. Examples. Concluding Remarks. References. 2. CLASSIFICATION OF VARIABLES AND THE CHOICE OF ANALYSIS. Classification of Variables. Overlapping of Classification Schemes. Choice of Analysis. References. 3. BASIC STATISTICS: A REVIEW. Preview. Descriptive Statistics. Random Variables and Distributions. Sampling Distributions of t, ?O2, and F. Statistical Inference: Estimation. Statistical Inference: Hypothesis Testing. Error Rate, Power, and Sample Size. Problems. References. 4. INTRODUCTION TO REGRESSION ANALYSIS. Preview. Association versus Causality. Statistical versus Deterministic Models. Concluding Remarks. References. 5. STRAIGHT-LINE REGRESSION ANALYSIS. Preview. Regression with a Single Independent Variable. Mathematical Properties of a Straight Line. Statistical Assumptions for a Straight-line Model. Determining the Best-fitting Straight Line. Measure of the Quality of the Straight-line Fit and Estimate ?a2. Inferences About the Slope and Intercept. Interpretations of Tests for Slope and Intercept. Inferences About the Regression Line ?YY|X = ?O0 + ?O1X . Prediction of a New Value of Y at X0. Problems. References. 6. THE CORRELATION COEFFICIENT AND STRAIGHT-LINE REGRESSION ANALYSIS. Definition of r. r as a Measure of Association. The Bivariate Normal Distribution. r and the Strength of the Straight-line Relationship. What r Does Not Measure. Tests of Hypotheses and Confidence Intervals for the Correlation Coefficient. Testing for the Equality of Two Correlations. Problems. References. 7. THE ANALYSIS-OF-VARIANCE TABLE. Preview. The ANOVA Table for Straight-line Regression. Problems. 8. MULTIPLE REGRESSION ANALYSIS: GENERAL CONSIDERATIONS. Preview. Multiple Regression Models. Graphical Look at the Problem. Assumptions of Multiple Regression. Determining the Best Estimate of the Multiple Regression Equation. The ANOVA Table for Multiple Regression. Numerical Examples. Problems. References. 9. TESTING HYPOTHESES IN MULTIPLE REGRESSION. Preview. Test for Significant Overall Regression. Partial F Test. Multiple Partial F Test. Strategies for Using Partial F Tests. Tests Involving the Intercept. Problems. References. 10. CORRELATIONS: MULTIPLE, PARTIAL, AND MULTIPLE PARTIAL. Preview. Correlation Matrix. Multiple Correlation Coefficient. Relationship of RY|X1, X2, !KXk to the Multivariate Normal Distribution. Partial Correlation Coefficient. Alternative Representation of the Regression Model. Multiple Partial Correlation. Concluding Remarks. Problems. References. 11. CONFOUNDING AND INTERACTION IN REGRESSION. Preview. Overview. Interaction in Regression. Confounding in Regression. Summary and Conclusions. Problems. References. 12. DUMMY VARIABLES IN REGRESSION. Preview. Definitions. Rule for Defining Dummy Variables. Comparing Two Straight-line Regression Equations: An Example. Questions for Comparing Two Straight Lines. Methods of Comparing Two Straight Lines. Method I: Using Separate Regression Fits to Compare Two Straight Lines. Method II: Using a Single Regression Equation to Compare Two Straight Lines. Comparison of Methods I and II. Testing Strategies and Interpretation: Comparing Two Straight Lines. Other Dummy Variable Models. Comparing Four Regression Equations. Comparing Several Regression Equations Involving Two Nominal Variables. Problems. References. 13. ANALYSIS OF COVARIANCE AND OTHER METHODS FOR ADJUSTING CONTINUOUS DATA. Preview. Adjustment Problem. Analysis of Covariance. Assumption of Parallelism: A Potential Drawback. Analysis of Covariance: Several Groups and Several Covariates. Comments and Cautions. Summary Problems. Reference. 14. REGRESSION DIAGNOSTICS. Preview. Approaches to Diagnosing Problems in Data. Residual Analysis: Detecting Outliers and Violations of Model Assumptions. Strategies of Analysis. Collinearity. Scaling Problems. Diagnostics Example. An Important Caution. Problems. References. 15. POLYNOMIAL REGRESSION. Preview. Polynomial Models. Least-squares Procedure for Fitting a Parabola. ANOVA Table for Second-order Polynomial Regression. Inferences Associated with Second-order Polynomial Regression. Example Requiring a Second-order Model. Fitting and Testing Higher-order Model. Lack-of-fit Tests. Orthogonal Polynomials. Strategies for Choosing a Polynomial Model. Problems. 16. SELECTING THE BEST REGRESSION EQUATION. Preview. Steps in Selecting the Best Regression Equation. Step 1: Specifying the Maximum Model. Step 2: Specifying a Criterion for Selecting a Model. Step 3: Specifying a Strategy for Selecting Variables. Step 4: Conducting the Analysis. Step 5: Evaluating Reliability with Split Samples. Example Analysis of Actual Data. Issues in Selecting the Most Valid Model. Problems. References. 17. ONE-WAY ANALYSIS OF VARIANCE. Preview. One-way ANOVA: The Problem, Assumptions, and Data Configuration. for One-way Fixed-effects ANOVA. Regression Model for Fixed-effects One-way ANOVA Fixed-effects Model for One-way ANOVA. Random-effects Model for One-way ANOVA. -comparison Procedures for Fixed-effects One-way ANOVA. a Multiple-comparison Technique. Orthogonal Contrasts and Partitioning an ANOVA Sum of Squares. Problems. References. 18. RANDOMIZED BLOCKS: SPECIAL CASE OF TWO-WAY ANOVA. Preview. Equivalent Analysis of a Matched-pairs Experiment. Principle of Blocking. Analysis of a Randomized-blocks Experiment. ANOVA Table for a Randomized-blocks Experiment. Models for a Randomized-blocks Experiment. Fixed-effects ANOVA Model for a Randomized-blocks Experiment. Problems. References. 19. TWO-WAY ANOVA WITH EQUAL CELL NUMBERS. Preview. Using a Table of Cell Means. General Methodology. F Tests for Two-way ANOVA. Regression Model for Fixed-effects Two-way ANOVA. Interactions in Two-way ANOVA. Random- and Mixed-effects Two-way ANOVA Models. Problems. References. 20. TWO-WAY ANOVA WITH UNEQUAL CELL NUMBERS. Preview. Problem with Unequal Cell Numbers: Nonorthogonality. Regression Approach for Unequal Cell Sample Sizes. Higher-way ANOVA. Problems. References. 21. THE METHOD OF MAXIMUM LIKELIHOOD. Preview. The Principle of Maximum Likelihood. Statistical Inference Using Maximum Likelihood. Summary. Problems. 22. LOGISTIC REGRESSION ANALYSIS. Preview. The Logistic Model. Estimating the Odds Ratio Using Logistic Regression. A Numerical Example of Logistic Regression. Theoretical Considerations. An Example of Conditional ML Estimation Involving Pair-matched Data with Unmatched Covariates. Summary. Problems. References. 23. POLYTOMOUS AND ORDINAL LOGISTIC REGRESSION. Preview. Why Not Use Binary Regression? An Example of Polytomous Logistic Regression: One Predictor, Three Outcome Categories. An Example: Extending the Polytomous Logistic Model to Several Predictors. Ordinal Logistic Regression: Overview. A Simple Hypothetical Example: Three Ordinal Categories and One Dichotomous Exposure Variable. Ordinal Logistic Regression Example Using Real Data with Four Ordinal Categories and Three Predictor Variables. Summary. Problems. References. 24. POISSON REGRESSION ANALYSIS. Preview. The Poisson Distribution. Example of Poisson Regression. Poisson Regression: General Considerations. Measures of Goodness of Fit. Continuation of Skin Cancer Data Example. A Second Illustration of Poisson Regression Analysis. Summary. Problems. References. 25. ANALYSIS OF CORRELATED DATA PART 1: THE GENERAL LINEAR MIXED MODEL. Preview. Examples. General Linear Mixed Model Approach. Example: Study of Effects of an Air Polluion Episode on FEV1 Levels. Summary!XAnalysis of Correlated Data: Part 1. Problems. References. 26. ANALYSIS OF CORRELATED DATA PART 2: RANDOM EFFECTS AND OTHER ISSUES. Preview. Random Effects Revisited. Results for Random Effects Models Applied to Air Pollution Study Data. Second Example!XAnalysis of Posture Measurement Data. Recommendations about Choice of Correlation Structure. Analysis of Data for Discrete Outcomes. Problems. References. 27. SAMPLE SIZE PLANNING FOR LINEAR AND LOGISTIC REGRESSION AND ANALYSIS OF VARIANCE. Preview. Review: Sample Size Calculations for Comparisons of Means and Proportions. Sample Size Planning for Linear Regression. Sample Size Planning for Logistic Regression. Power and Sample Size Determination for Linear Models: A General Approach. Sample Size Determination for Matched Case-control Studies with a Dichotomous Outcome. Practical Considerations and Cautions. Problems. References. Appendix A. Appendix B. Appendix C. Solutions to Exercises. Index.","['Statistics', 'Regression analysis', 'Mathematics', 'Linear regression', 'Bivariate analysis', 'Statistical inference', 'Regression diagnostic', 'Regression', 'Variables', 'Measure (data warehouse)', 'Polynomial regression', 'Computer science', 'Data mining']","classification, classification, basic statistics, descriptive statistics, random variables, sampling distributions, statistical inference, statistical, hypothesis testing, regression analysis, correlation, bivariate normal distribution, confidence intervals, correlation, anova, multiple regression analysis, multiple regression models, multiple regression, anova table, multiple regression, multiple regression, partial, correlations, correlation matrix, multiple correlation coefficient, multivariate normal distribution, partial correlation coefficient, multiple partial correlation"
Paper_01859,Strategies for ensuring trustworthiness in qualitative research projects,['Andrew K. Shenton'],2004,Education for Information,Journal,,63-75,22,2,10.3233/efi-2004-22201,"Although many critics are reluctant to accept the trustworthiness of qualitative research, frameworks for ensuring rigour in this form of work have been in existence for many years. Guba's constructs, in particular, have won considerable favour and f","['Credibility', 'Rigour', 'Transferability', 'Trustworthiness', 'Qualitative research', 'Scrutiny', 'Dependability', 'Context (archaeology)', 'Engineering ethics', 'Focus group', 'Psychology', 'Vetting', 'Epistemology', 'Computer science', 'Social psychology', 'Sociology', 'Political science', 'Engineering', 'Social science', 'Philosophy', 'Paleontology', 'Computer security', 'Software engineering', 'Logit', 'Machine learning', 'Anthropology', 'Law', 'Biology']","qualitative research, [PAD] [PAD], [PAD], [PAD] [PAD], [PAD], [PAD]"
Paper_01860,Measuring individual differences in empathy: Evidence for a multidimensional approach.,['Mark H. Davis'],1983,Journal of Personality and Social Psychology,Journal,,113-126,44,1,10.1037/0022-3514.44.1.113,To facilitate a multidimensional approach to empathy the Interpersonal Reactivity Index (IRI) includes 4 subscales: Perspective-Taking (PT) Fantasy (FS) Empathic Concern (EC) and Personal Distress (PD). The aim of the present study was to establish the convergent and discriminant validity of these 4 subscales. Hypothesized relationships among the IRI subscales between the subscales and measures of other psychological constructs (social functioning self-esteem emotionality and sensitivity to others) and between the subscales and extant empathy measures were examined. Study subjects included 677 male and 667 female students enrolled in undergraduate psychology classes at the University of Texas. The IRI scales not only exhibited the predicted relationships among themselves but also were related in the expected manner to other measures. Higher PT scores were consistently associated with better social functioning and higher self-esteem; in contrast Fantasy scores were unrelated to these 2 characteristics. High EC scores were positively associated with shyness and anxiety but negatively linked to egotism. The most substantial relationships in the study involved the PD scale. PD scores were strongly linked with low self-esteem and poor interpersonal functioning as well as a constellation of vulnerability uncertainty and fearfulness. These findings support a multidimensional approach to empathy by providing evidence that the 4 qualities tapped by the IRI are indeed separate constructs each related in specific ways to other psychological measures.,"['Psychology', 'Empathy', 'Social psychology', 'Cognitive psychology', 'Developmental psychology']","multidimensional, empathy, interpersonal reactivity index, ir, fantasy, empathic concern, personal distress, empathy, undergraduate psychology, social functioning, fantasy, shyness, anxiety, egotism, interpersonal functioning, vulnerability uncertainty, fearful"
Paper_01861,Novel methods improve prediction of species’ distributions from occurrence data,"['Jane Elith', 'Catherine H. Graham', 'Robert P. Anderson', 'Miroslav Dudı́k', 'Simon Ferrier', 'Antoine Guisan', 'Robert J. Hijmans', 'Falk Huettmann', 'John R. Leathwick', 'Anthony Lehmann', 'Jin Li', 'Lúcia G. Lohmann', 'Bette A. Loiselle', 'Glenn Manion', 'Craig Moritz', 'Miguel Nakamura', 'Yoshinori Nakazawa', 'Jacob McC. Overton', 'A. Townsend Peterson', 'Steven J. Phillips', 'Karen Richardson', 'Ricardo Scachetti‐Pereira', 'Robert E. Schapire', 'Jorge Soberón', 'Stephen E. Williams', 'Mary S. Wisz', 'Niklaus E. Zimmermann']",2006,Ecography,Journal,,129-151,29,2,10.1111/j.2006.0906-7590.04596.x,"Prediction of species’ distributions is central to diverse applications in ecology, evolution and conservation science. There is increasing electronic access to vast sets of occurrence records in museums and herbaria, yet little effective guidance on how best to use this information in the context of numerous approaches for modelling distributions. To meet this need, we compared 16 modelling methods over 226 species from 6 regions of the world, creating the most comprehensive set of model comparisons to date. We used presence‐only data to fit models, and independent presence‐absence data to evaluate the predictions. Along with well‐established modelling methods such as generalised additive models and GARP and BIOCLIM, we explored methods that either have been developed recently or have rarely been applied to modelling species’ distributions. These include machine‐learning methods and community models, both of which have features that may make them particularly well suited to noisy or sparse information, as is typical of species’ occurrence data. Presence‐only data were effective for modelling species’ distributions for many species and regions. The novel methods consistently outperformed more established methods. The results of our analysis are promising for the use of data from museums and herbaria, especially as methods suited to the noise inherent in such data improve.","['Herbarium', 'Computer science', 'Context (archaeology)', 'Predictive modelling', 'Species distribution', 'Environmental niche modelling', 'Data set', 'Environmental data', 'Ecology', 'Machine learning', 'Data mining', 'Data science', 'Artificial intelligence', 'Geography', 'Biology', 'Habitat', 'Archaeology', 'Ecological niche']","evolution, conservation science, occurrence, herb, generalised additive models, garp, bioclim, machine ‐ learning methods, community models, sparse"
Paper_01863,Comprehensive Heterocyclic Chemistry II,"['Alan R. Katritzky', 'Charles W. Rees', 'Eric F. V. Scriven']",1997,['Synthesis'],Unknown,,124,1998,01,10.1055/s-1998-4509,"CHEC III is organized in 15 Volumes and closely follows the organization used in the previous edition: Volumes 1 and 2: Cover respectively three- and four-membered heterocycles, together with all fused systems containing a three- or four-membered heterocyclic ring. Volume 3: Five-membered rings with one heteroatom together with their benzo- and other carbocyclic-fused derivatives. Volumes 4, 5 and 6: Cover five-membered rings with two heteroatoms, and three or more heteroatoms, respectively, each with their fused carbocyclic compounds. Volumes 7, 8 and 9: Dedicated to six-membered rings with one, two, and more than two heteroatoms, respectively, again with the corresponding fused carbocylic compounds. Volumes 10, 11 and 12: Cover systems containing at least two directly fused heterocyclic five- and/or six-membered rings: of these Volume 10 deals with bi-heterocyclic rings without a ring junction heteroatom, and Volume 11 deals with 5:5 and 5:6 fused rings systems with at least one ring junction nitrogen, while Volume 12 is devoted to all other systems of five and/or six-membered fused or spiro heterocyclic rings with ring junction heteroatoms. Volumes 13 and 14: Seven-membered and larger heterocyclic rings including all their fused derivatives (except those containing three- or four-membered heterocyclic rings which are included in Volume 1 and 2, respectively). Volume 15: Author, ring and subject indexes.","['Heteroatom', 'Ring (chemistry)', 'Chemistry', 'Aromaticity', 'Volume (thermodynamics)', 'Stereochemistry', 'Ring size', 'Crystallography', 'Molecule', 'Organic chemistry', 'Physics', 'Thermodynamics']","che, fused systems, fused carbocy, fused carbocylic compounds, ring junction, ring, ring"
Paper_01866,"The particle swarm - explosion, stability, and convergence in a multidimensional complex space","['Maurice Clerc', 'James Kennedy']",2002,IEEE Transactions on Evolutionary Computation,Journal,,58-73,6,1,10.1109/4235.985692,"The particle swarm is an algorithm for finding optimal regions of complex search spaces through the interaction of individuals in a population of particles. This paper analyzes a particle's trajectory as it moves in discrete time (the algebraic view), then progresses to the view of it in continuous time (the analytical view). A five-dimensional depiction is developed, which describes the system completely. These analyses lead to a generalized model of the algorithm, containing a set of coefficients to control the system's convergence tendencies. Some results of the particle swarm optimizer, implementing modifications derived from the analysis, suggest methods for altering the original algorithm in ways that eliminate problems and increase the ability of the particle swarm to find optima of some well-studied test functions.","['Particle swarm optimization', 'Convergence (economics)', 'Stability (learning theory)', 'Multi-swarm optimization', 'Mathematical optimization', 'Set (abstract data type)', 'Swarm behaviour', 'Trajectory', 'Population', 'Computer science', 'Mathematics', 'Algorithm', 'Machine learning', 'Physics', 'Economics', 'Economic growth', 'Demography', 'Astronomy', 'Sociology', 'Programming language']","particle swarm, optimal regions, complex search spaces, algebraic, analytical, convergence, particle swarm optimizer, particle, [PAD], [PAD] [PAD], [PAD]"
Paper_01867,An argument for basic emotions,['Paul Ekman'],1992,Cognition & Emotion,Journal,,169-200,6,3-4,10.1080/02699939208411068,"Abstract Emotions are viewed as having evolved through their adaptive value in dealing with fundamental life-tasks. Each emotion has unique features: signal, physiology, and antecedent events. Each emotion also has characteristics in common with other emotions: rapid onset, short duration, unbidden occurrence, automatic appraisal, and coherence among responses. These shared and unique characteristics are the product of our evolution, and distinguish emotions from other affective phenomena.","['Antecedent (behavioral psychology)', 'Psychology', 'Cognitive psychology', 'Argument (complex analysis)', 'Coherence (philosophical gambling strategy)', 'Emotion classification', 'Value (mathematics)', 'Cognitive appraisal', 'Cognition', 'Social psychology', 'Computer science', 'Neuroscience', 'Biochemistry', 'Chemistry', 'Physics', 'Quantum mechanics', 'Machine learning']","abstract emotions, signal, physiology, antecedent events, rapid onset, short duration, unbidden occurrence, automatic appraisal, ##herence, [PAD] [PAD], [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD], [PAD], [PAD] [PAD] [PAD] [PAD], [PAD], [PAD] [PAD], [PAD] [PAD], [PAD], [PAD], [PAD] [PAD], [PAD], [PAD], [PAD] [PAD] [PAD] [PAD] [PAD], [PAD], [PAD]"
Paper_01868,Rough Sets: Theoretical Aspects of Reasoning about Data,['Zdzisław Pawlak'],1991,['Control Engineering Practice'],Unknown,,741-742,4,5,10.1016/s0967-0661(96)90021-0,"I. Theoretical Foundations.- 1. Knowledge.- 1.1. Introduction.- 1.2. Knowledge and Classification.- 1.3. Knowledge Base.- 1.4. Equivalence, Generalization and Specialization of Knowledge.- Summary.- Exercises.- References.- 2. Imprecise Categories, Approximations and Rough Sets.- 2.1. Introduction.- 2.2. Rough Sets.- 2.3. Approximations of Set.- 2.4. Properties of Approximations.- 2.5. Approximations and Membership Relation.- 2.6. Numerical Characterization of Imprecision.- 2.7. Topological Characterization of Imprecision.- 2.8. Approximation of Classifications.- 2.9. Rough Equality of Sets.- 2.10. Rough Inclusion of Sets.- Summary.- Exercises.- References.- 3. Reduction of Knowledge.- 3.1. Introduction.- 3.2. Reduct and Core of Knowledge.- 3.3. Relative Reduct and Relative Core of Knowledge.- 3.4. Reduction of Categories.- 3.5. Relative Reduct and Core of Categories.- Summary.- Exercises.- References.- 4. Dependencies in Knowledge Base.- 4.1. Introduction.- 4.2. Dependency of Knowledge.- 4.3. Partial Dependency of Knowledge.- Summary.- Exercises.- References.- 5. Knowledge Representation.- 5.1. Introduction.- 5.2. Examples.- 5.3. Formal Definition.- 5.4. Significance of Attributes.- 5.5. Discernibility Matrix.- Summary.- Exercises.- References.- 6. Decision Tables.- 6.1. Introduction.- 6.2. Formal Definition and Some Properties.- 6.3. Simplification of Decision Tables.- Summary.- Exercises.- References.- 7. Reasoning about Knowledge.- 7.1. Introduction.- 7.2. Language of Decision Logic.- 7.3. Semantics of Decision Logic Language.- 7.4. Deduction in Decision Logic.- 7.5. Normal Forms.- 7.6. Decision Rules and Decision Algorithms.- 7.7. Truth and Indiscernibility.- 7.8. Dependency of Attributes.- 7.9. Reduction of Consistent Algorithms.- 7.10. Reduction of Inconsistent Algorithms.- 7.11. Reduction of Decision Rules.- 7.12. Minimization of Decision Algorithms.- Summary.- Exercises.- References.- II. Applications.- 8. Decision Making.- 8.1. Introduction.- 8.2. Optician's Decisions Table.- 8.3. Simplification of Decision Table.- 8.4. Decision Algorithm.- 8.5. The Case of Incomplete Information.- Summary.- Exercises.- References.- 9. Data Analysis.- 9.1. Introduction.- 9.2. Decision Table as Protocol of Observations.- 9.3. Derivation of Control Algorithms from Observation.- 9.4. Another Approach.- 9.5. The Case of Inconsistent Data.- Summary.- Exercises.- References.- 10. Dissimilarity Analysis.- 10.1. Introduction.- 10.2. The Middle East Situation.- 10.3. Beauty Contest.- 10.4. Pattern Recognition.- 10.5. Buying a Car.- Summary.- Exercises.- References.- 11. Switching Circuits.- 11.1. Introduction.- 11.2. Minimization of Partially Defined Switching Functions.- 11.3. Multiple-Output Switching Functions.- Summary.- Exercises.- References.- 12. Machine Learning.- 12.1. Introduction.- 12.2. Learning From Examples.- 12.3. The Case of an Imperfect Teacher.- 12.4. Inductive Learning.- Summary.- Exercises.- References.","['Reduct', 'Rough set', 'Decision table', 'Knowledge base', 'Mathematics', 'Knowledge representation and reasoning', 'Dominance-based rough set approach', 'Equivalence (formal languages)', 'Dependency (UML)', 'Generalization', 'Relation (database)', 'Computer science', 'Characterization (materials science)', 'Theoretical computer science', 'Discrete mathematics', 'Artificial intelligence', 'Data mining', 'Mathematical analysis', 'Materials science', 'Nanotechnology']","theoretical foundations, knowledge, classification, knowledge base, equivalence, generalization, specialization of, imprecise categories, approximation, rough sets, rough sets, approximations, approximation, approximations, membership relation, numerical characterization, ##cision, topological characterization, ##recision, approximation, rough equality, rough inclusion, reduction, reduct, core of, relative reduct, relative core of, relative reduct, dependencies, knowledge base, dependency of, partial dependency of, knowledge representation, formal definition, significance, discernibility matrix, decision tables, formal definition, simplification, decision tables, decision logic, semantics, decision logic language, deduction, decision logic, normal forms, decision rules, decision algorithms, truth, indiscer, ##bility, dependency of, consistent algorithms, inconsistent algorithms"
Paper_01869,Item-based collaborative filtering recommendation algorithms,"['Badrul Sarwar', 'George Karypis', 'Joseph A. Konstan', 'John Riedl']",2001,Unknown,Unknown,,285-295,,,10.1145/371920.372071,"Article Share on Item-based collaborative filtering recommendation algorithms Authors: Badrul Sarwar GroupLens Research Group/Army HPC Research Center, Department of Computer Science and Engineering, University of Minnesota, Minneapolis, MN GroupLens Research Group/Army HPC Research Center, Department of Computer Science and Engineering, University of Minnesota, Minneapolis, MNView Profile , George Karypis GroupLens Research Group/Army HPC Research Center, Department of Computer Science and Engineering, University of Minnesota, Minneapolis, MN GroupLens Research Group/Army HPC Research Center, Department of Computer Science and Engineering, University of Minnesota, Minneapolis, MNView Profile , Joseph Konstan GroupLens Research Group/Army HPC Research Center, Department of Computer Science and Engineering, University of Minnesota, Minneapolis, MN GroupLens Research Group/Army HPC Research Center, Department of Computer Science and Engineering, University of Minnesota, Minneapolis, MNView Profile , John Riedl GroupLens Research Group/Army HPC Research Center, Department of Computer Science and Engineering, University of Minnesota, Minneapolis, MN GroupLens Research Group/Army HPC Research Center, Department of Computer Science and Engineering, University of Minnesota, Minneapolis, MNView Profile Authors Info & Claims WWW '01: Proceedings of the 10th international conference on World Wide WebMay 2001 Pages 285–295https://doi.org/10.1145/371920.372071Online:01 April 2001Publication History 4,816citation29,749DownloadsMetricsTotal Citations4,816Total Downloads29,749Last 12 Months2,414Last 6 weeks183 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my Alerts New Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteGet Access","['Research center', 'Library science', 'Computer Science and Engineering', 'Citation', 'Computer science', 'Center (category theory)', 'Medicine', 'Software engineering', 'Chemistry', 'Pathology', 'Crystallography']","collaborative, bad, ##l sarwar, ##et, alert, ##ername"
Paper_01872,Phonons and related crystal properties from density-functional perturbation theory,"['Stefano Baroni', 'Stefano de Gironcoli', 'Andrea Dal Corso', 'Paolo Giannozzi']",2001,Reviews of Modern Physics,Journal,,515-562,73,2,10.1103/revmodphys.73.515,"This article reviews the current status of lattice-dynamical calculations in crystals, using density-functional perturbation theory, with emphasis on the plane-wave pseudopotential method. Several specialized topics are treated, including the implementation for metals, the calculation of the response to macroscopic electric fields and their relevance to long-wavelength vibrations in polar materials, the response to strain deformations, and higher-order responses. The success of this methodology is demonstrated with a number of applications existing in the literature.","['Physics', 'Phonon', 'Perturbation (astronomy)', 'Perturbation theory (quantum mechanics)', 'Lattice (music)', 'Density functional theory', 'Plane wave', 'Lattice vibration', 'Condensed matter physics', 'Vibration', 'Statistical physics', 'Classical mechanics', 'Theoretical physics', 'Quantum mechanics', 'Acoustics']","crystals, metals, macroscopic electric fields, polar materials, strain deformations, [PAD], [PAD] [PAD] [PAD], [PAD] [PAD] [PAD]"
Paper_01873,"The Stakeholder Theory of the Corporation: Concepts, Evidence, and Implications","['Thomas Donaldson', 'Lee E. Preston']",1995,Academy of Management Review,Journal,,65-91,20,1,10.5465/amr.1995.9503271992,"?The stakeholder theory has been advanced and justified in the management literature on the basis of its descriptive accuracy, instrumental power, and normative validity. These three aspects of the theory, although interrelated, are quite distinct; they involve different types of evidence and argument and have different implications. In this article, we examine these three aspects of the theory and critique and integrate important contributions to the literature related to each. We conclude that the three aspects of stakeholder theory are mutually supportive and that the normative base of the theory-which includes the modern theory of property rights-is fundamental. If the unity of the corporate body is real, then there is reality and not simply legal fiction in the proposition that the managers of the unit are fiduciaries for it and not merely for its individual members, that they are . . . trustees for an institution [with multiple constituents] rather than attorneys for the stockholders.","['Corporation', 'Stakeholder', 'Stakeholder theory', 'Management', 'Organizational behavior', 'Sociology', 'Political science', 'Business', 'Economics', 'Law']","stakeholder theory, management literature, descriptive accuracy, instrumental power, normative validity, stakeholder theory, norma, property rights, corporate body, stock, [PAD] [PAD], [PAD], [PAD], [PAD], [PAD], [PAD] [PAD]"
Paper_01874,Dye-Sensitized Solar Cells,"['Anders Hagfeldt', 'Gerrit Boschloo', 'Licheng Sun', 'Lars Kloo', 'Henrik Pettersson']",2010,Chemical Reviews,Journal,,6595-6663,110,11,10.1021/cr900356p,"ADVERTISEMENT RETURN TO ISSUEPREVReviewNEXTDye-Sensitized Solar CellsAnders Hagfeldt*†‡∥, Gerrit Boschloo†, Licheng Sun‡∥, Lars Kloo‡, and Henrik Pettersson⊥View Author Information Department of Physical and Analytical Chemistry, Uppsala University, Box 259, SE-751 05 Uppsala, Sweden, Department of Chemistry, KTH - Royal Institute of Technology, Teknikringen 30, SE-100 44 Stockholm, Sweden, State Key Laboratory of Fine Chemicals, DUT-KTH Joint Education and Research Centre on Molecular Devices, Dalian University of Technology (DUT), Dalian 116012, China, and Swerea IVF AB, Box 104, SE-431 22 Mölndal, Sweden* To whom correspondence should be addressed. E-mail: [email protected]†Uppsala University.‡Royal Institute of Technology.∥Dalian University of Technology (DUT).⊥Swerea IVF AB.Cite this: Chem. Rev. 2010, 110, 11, 6595–6663Publication Date (Web):September 10, 2010Publication History Received30 October 2009Published online10 September 2010Published inissue 10 November 2010https://pubs.acs.org/doi/10.1021/cr900356phttps://doi.org/10.1021/cr900356preview-articleACS PublicationsCopyright © 2010 American Chemical SocietyRequest reuse permissionsArticle Views106777Altmetric-Citations7908LEARN ABOUT THESE METRICSArticle Views are the COUNTER-compliant sum of full text article downloads since November 2008 (both PDF and HTML) across all institutions and individuals. These metrics are regularly updated to reflect usage leading up to the last few days.Citations are the number of other articles citing this article, calculated by Crossref and updated daily. Find more information about Crossref citation counts.The Altmetric Attention Score is a quantitative measure of the attention that a research article has received online. Clicking on the donut icon will load a page at altmetric.com with additional details about the score and the social media presence for the given article. Find more information on the Altmetric Attention Score and how the score is calculated. Share Add toView InAdd Full Text with ReferenceAdd Description ExportRISCitationCitation and abstractCitation and referencesMore Options Share onFacebookTwitterWechatLinked InRedditEmail Other access optionsGet e-Alertsclose SUBJECTS:Differential scanning calorimetry,Dyes and pigments,Electrolytes,Oxides,Redox reactions Get e-Alerts","['Library science', 'Citation', 'Altmetrics', 'China', 'Computer science', 'History', 'Archaeology']","analytical chemistry, fine chemicals, molecular devices, ##a, american chemical society, altmetric attention score, social media, altmetric attention score"
Paper_01876,Measuring individual differences in implicit cognition: The implicit association test.,"['Anthony G. Greenwald', 'Debbie E. McGhee', 'Jordan L. K. Schwartz']",1998,Journal of Personality and Social Psychology,Journal,,1464-1480,74,6,10.1037/0022-3514.74.6.1464,"6.1464) is often used to predict people's behaviors.However, it has shown poor predictive ability potentially because of its typical scoring method (the D score), which is affected by the across-trial variability in the IAT data and might provide biased estimates of the construct.Linear Mixed-Effects Models (LMMs) can address this issue while providing a Rasch-like parametrization of accuracy and time responses.In this study, the predictive abilities of D scores and LMM estimates were compared.The LMMs estimates showed better predictive ability than the D score, and allowed for in-depth analyses at the stimulus level that helped in reducing the acrosstrial variability.Implications of the results and limitations of the study are discussed.","['Implicit-association test', 'Psychology', 'Implicit attitude', 'Association (psychology)', 'Test (biology)', 'Implicit personality theory', 'Social psychology', 'Cognition', 'Cognitive psychology', 'Social cognition', 'Personality', 'Paleontology', 'Neuroscience', 'Psychotherapist', 'Biology']","predictive ability, time responses, predictive abilities, lmm, predictive ability, ##al variability, [PAD]"
Paper_01877,THE BIG FIVE PERSONALITY DIMENSIONS AND JOB PERFORMANCE: A META‐ANALYSIS,"['Murray R. Barrick', 'Michael K. Mount']",1991,Personnel Psychology,Journal,,1-26,44,1,10.1111/j.1744-6570.1991.tb00688.x,"This study investigated the relation of the “Big Five” personality dimensions (Extraversion, Emotional Stability, Agreeableness, Conscientiousness, and Openness to Experience) to three job performance criteria (job proficiency, training proficiency, and personnel data) for five occupational groups (professionals, police, managers, sales, and skilled/semi‐skilled). Results indicated that one dimension of personality, Conscientiousness, showed consistent relations with all job performance criteria for all occupational groups. For the remaining personality dimensions, the estimated true score correlations varied by occupational group and criterion type. Extraversion was a valid predictor for two occupations involving social interaction, managers and sales (across criterion types). Also, both Openness to Experience and Extraversion were valid predictors of the training proficiency criterion (across occupations). Other personality dimensions were also found to be valid predictors for some occupations and some criterion types, but the magnitude of the estimated true score correlations was small (ρ &lt; .10). Overall, the results illustrate the benefits of using the 5‐factor model of personality to accumulate and communicate empirical findings. The findings have numerous implications for research and practice in personnel psychology , especially in the subfields of personnel selection, training and development, and performance appraisal.","['Psychology', 'Conscientiousness', 'Agreeableness', 'Openness to experience', 'Big Five personality traits', 'Extraversion and introversion', 'Personality', 'Social psychology', 'Hierarchical structure of the Big Five', 'Personnel selection', 'Alternative five model of personality', 'Big Five personality traits and culture', 'Applied psychology', 'Statistics', 'Mathematics']","personality dimensions, extraversion, emotional stability, agreeableness, conscientiousness, ##ness, job performance criteria, job proficiency, training proficiency, personnel data, professionals, police, managers, sales, conscientiousness, job performance criteria, extraversion, social interaction, managers, sales, extraversion, training proficiency criterion, personality, personnel psychology, personnel selection, training and development, performance appraisal"
Paper_01878,Emerging Photoluminescence in Monolayer MoS<sub>2</sub>,"['Andrea Splendiani', 'L. Sun', 'Yuanbo Zhang', 'Tianshu Li', 'Jonghwan Kim', 'Chi Yung Chim', 'Giulia Galli', 'Feng Wang']",2010,Nano Letters,Journal,,1271-1275,10,4,10.1021/nl903868w,"Novel physical phenomena can emerge in low-dimensional nanomaterials. Bulk MoS2, a prototypical metal dichalcogenide, is an indirect bandgap semiconductor with negligible photoluminescence. When the MoS2 crystal is thinned to monolayer, however, a strong photoluminescence emerges, indicating an indirect to direct bandgap transition in this d-electron system. This observation shows that quantum confinement in layered d-electron materials like MoS2 provides new opportunities for engineering the electronic structure of matter at the nanoscale.","['Photoluminescence', 'Monolayer', 'Materials science', 'Nanomaterials', 'Band gap', 'Semiconductor', 'Nanotechnology', 'Direct and indirect band gaps', 'Quantum dot', 'Nanoscopic scale', 'Optoelectronics', 'Condensed matter physics', 'Physics']","bulk mos2, metal dichalcogenide, bandgap semiconductor, ##ines, photolumines, quantum confinement, electronic structure"
Paper_01879,Experimental Design: Procedures for the Behavioral Sciences,['Roger E. Kirk'],2013,Unknown,Unknown,,,,,10.4135/9781483384733,Chapter 1. Research Strategies and the Control of Nuisance Variables Chapter 2. Experimental Designs: an Overview Chapter 3. Fundamental Assumptions in Analysis of Variance Chapter 4. Completely Randomized Design Chapter 5. Multiple Comparison Tests Chapter 6. Trend Analysis Chapter 7. General Linear Model Approach to ANOVA Chapter 8. Randomized Block Designs Chapter 9. Completely Randomized Factorial Design with Two Treatments Chapter 10. Completely Randomized Factorial Design with Three or More Treatments and Randomized Block Factorial Design Chapter 11. Hierarchical Designs Chapter 12. Split-Plot Factorial Design: Design with Group-Treatment Confounding Chapter 13. Analysis of Covariance Chapter 14. Latin Square and Related Designs Chapter 15. Confounded Factorial Designs: Designs with Group-Interaction Confounding Chapter 16. Fractional Factorial Designs: Designs with Treatment-Interaction Confounding,"['Behavioural sciences', 'Computer science', 'Psychology', 'Psychotherapist']","research strategies, nuisance variables, experimental designs, fundamental assumptions, analysis of, completely randomized design, multiple comparison tests, trend analysis, general linear model, anova, randomized block designs, completely randomized factorial design, completely randomized factorial design, randomized block factorial design, hierarchical designs, covariance, latin square, confounded factorial designs, fractional factorial designs"
Paper_01880,Particle-size Analysis,"['G.W. Gee', 'J. W. Bauder']",2013,Soil Science Society of America book series,Unknown,,383-411,,,10.2136/sssabookser5.1.2ed.c15,"Particle-size analysis (PSA) is a measurement of the size distribution of individual particles in a soil sample. The major features of PSA are the destruction or dispersion of soil aggregates into discrete units by chemical, mechanical, or ultrasonic means and the separation of particles according to size limits by sieving and sedimentation. Soils generally contain organic matter and often contain iron oxides and carbonate coatings that bind particles together. Chemical pretreatments are used for removal of these coatings; however, chemical treatment can result in destruction and dissolution of some soil minerals. In addition to sieving and sedimentation procedures, there are numerous techniques for measurement of particle-size distribution that have been developed for powder technology and other applications. These techniques include optical microscopy, transmission electron microscopy (TEM), scanning electron microscopy (SEM), electrical sensory zone (Coulter counter) methods, and light-scattering methods such as laserlight scattering, turbidimeters, holography, and x-ray centrifuges.","['Particle-size distribution', 'Coulter counter', 'Sedimentation', 'Dynamic light scattering', 'Particle size', 'Dissolution', 'Particle (ecology)', 'Materials science', 'Mineralogy', 'Transmission electron microscopy', 'Microscopy', 'Dispersion (optics)', 'Scanning electron microscope', 'Light scattering', 'Organic matter', 'Optical microscope', 'Analytical Chemistry (journal)', 'Scattering', 'Chemical engineering', 'Nanotechnology', 'Chemistry', 'Nanoparticle', 'Composite material', 'Optics', 'Chromatography', 'Sediment', 'Geology', 'Physics', 'Oceanography', 'Molecular biology', 'Engineering', 'Biology', 'Paleontology', 'Organic chemistry']","size distribution, soil sample, iron oxides, carbonate coatings, chemical pretreatments, chemical treatment, powder technology, optical microscopy, transmission electron microscopy, scanning electron microscopy, electrical sensory zone, coulter counter, laser, turbidimeters, holography"
Paper_01881,Politeness,"['Penelope Brown', 'Stephen C. Levinson', 'John J. Gumperz']",1987,Unknown,Unknown,,,,,10.1017/cbo9780511813085,"This study is about the principles for constructing polite speeches. The core of it first appeared in Questions and Politeness, edited by Esther N. Goody (now out of print). It is here reissued with a fresh introduction that surveys the considerable literature in linguistics, psychology and the social sciences that the original extended essay stimulated, and suggests distinct directions for research. The authors describe and account for some remarkable parallelisms in the linguistic construction of utterances with which people express themselves in different languages and cultures. A motive for these parallels is isolated and a universal model is constructed outlining the abstract principles underlying polite usages. This is based on the detailed study of three unrelated languages and cultures: the Tamil of South India, the Tzeltal spoken by Mayan Indians in Chiapas, Mexico, and the English of the USA and England. This volume will be of special interest to students in linguistic pragmatics, sociolinguistics, applied linguistics, anthropology, and the sociology and social psychology of interaction.","['Politeness', 'Linguistics', 'Sociolinguistics', 'Tamil', 'Pragmatics', 'Sociology', 'Parallels', 'Philosophy', 'Mechanical engineering', 'Engineering']","polite speeches, questions, politeness, linguistics, psychology, social sciences, polite usages, tamil, ##zeltal, english, linguistic pragmatics, sociolinguistics, applied linguistics, anthropology, social psychology, interaction, [PAD] [PAD]"
Paper_01882,Light Propagation with Phase Discontinuities: Generalized Laws of Reflection and Refraction,"['Zhiyuan Fan', 'Patrice Genevet', 'Mikhail A. Kats', 'Francesco Aieta', 'Jean‐Philippe Tetienne', 'Federico Capasso', 'Z. Gaburro']",2011,Science,Journal,,333-337,334,6054,10.1126/science.1210713,"Conventional optical components rely on gradual phase shifts accumulated during light propagation to shape light beams. New degrees of freedom are attained by introducing abrupt phase changes over the scale of the wavelength. A two-dimensional array of optical resonators with spatially varying phase response and subwavelength separation can imprint such phase discontinuities on propagating light as it traverses the interface between two media. Anomalous reflection and refraction phenomena are observed in this regime in optically thin arrays of metallic antennas on silicon with a linear phase variation along the interface, which are in excellent agreement with generalized laws derived from Fermat's principle. Phase discontinuities provide great flexibility in the design of light beams, as illustrated by the generation of optical vortices through use of planar designer metallic interfaces.","['Classification of discontinuities', ""Snell's law"", 'Optics', 'Refraction', 'Planar', 'Wavelength', 'Phase (matter)', 'Physics', 'Reflection (computer programming)', 'Resonator', 'Negative refraction', 'Light beam', 'Ray', 'Refractive index', 'Computer science', 'Mathematics', 'Mathematical analysis', 'Quantum mechanics', 'Programming language', 'Computer graphics (images)']","optical components, phase shifts, light propagation, light beams, phase changes, optical resonators, spatially varying phase response, subwavelength separation, an, ##lous reflection, refraction phenomena, optically thin arrays, metallic antennas, linear phase variation, phase discontinuities, optical vortices, planar designer metallic interfaces, [PAD], [PAD] [PAD], [PAD]"
Paper_01883,Fine Structure Constant Defines Visual Transparency of Graphene,"['Rahul R. Nair', 'Peter Blake', 'A. N. Grigorenko', 'Kostya S. Novoselov', 'Timothy J. Booth', 'Tobias Stauber', 'N. M. R. Peres', 'A. K. Geǐm']",2008,Science,Journal,,1308-1308,320,5881,10.1126/science.1156965,"There are few phenomena in condensed matter physics that are defined only by the fundamental constants and do not depend on material parameters. Examples are the resistivity quantum, h/e2 (h is Planck's constant and e the electron charge), that appears in a variety of transport experiments and the magnetic flux quantum, h/e, playing an important role in the physics of superconductivity. By and large, sophisticated facilities and special measurement conditions are required to observe any of these phenomena. We show that the opacity of suspended graphene is defined solely by the fine structure constant, a = e2/hc � 1/137 (where c is the speed of light), the parameter that describes coupling between light and relativistic electrons and that is traditionally associated with quantum electrodynamics rather than materials science. Despite being only one atom thick, graphene is found to absorb a significant (pa = 2.3%) fraction of incident white light, a consequence of graphene's unique electronic structure.","['Transparency (behavior)', 'Graphene', 'Constant (computer programming)', 'Nanotechnology', 'Materials science', 'Computer science', 'Computer security', 'Programming language']","condensed matter physics, fundamental constants, material parameters, resistivity quantum, electron charge, transport experiments, magnetic flux quantum, superconductivity, opacity, suspended graphene, fine structure constant, relativistic electrons, quantum electrodynamics, materials science"
Paper_01886,2017 ESC Guidelines for the management of acute myocardial infarction in patients presenting with ST-segment elevation,"['Borja Ibáñez', 'Stefan James', 'Stefan Agewall', 'Manuel J. Antunes', 'Chiara Bucciarelli‐Ducci', 'Héctor Bueno', 'Alida L.P. Caforio', 'Filippo Crea', 'John Goudevenos', 'Sigrun Halvorsen', 'Gerhard Hindricks', 'Adnan Kastrati', 'Mattie Lenzen', 'Eva Prescott', 'Marco Roffi', 'Marco Valgimigli', 'Christoph Varenhorst', 'Pascal Vranckx', 'Petr Widimský', 'Jean‐Philippe Collet', 'Steen Dalby Kristensen', 'Victor Aboyans', 'Andreas Baumbach', 'Raffaele Bugiardini', 'Ioan Mircea Coman', 'Victoria Delgado', 'Donna Fitzsimons', 'Oliver Gaemperli', 'Anthony Gershlick', 'Stephan Gielen', 'Veli‐Pekka Harjola', 'Hugo A. Katus', 'Juhani Knuuti', 'Philippe Kolh', 'Christophe Leclercq', 'Gregory Y.H. Lip', 'João Morais', 'Aleksandar Nešković', 'Franz‐Josef Neumann', 'Alexander Niessner', 'Massimo Piepoli', 'Dimitrios Richter', 'Е. V. Shlyakhto', 'Iain A. Simpson', 'Philippe Gabríel Steg', 'Christian Juhl Terkelsen', 'Kristian Thygesen', 'Stephan Windecker', 'José Luis Zamorano', 'Uwe Zeymer', 'Stephan Windecker', 'Victor Aboyans', 'Stefan Agewall', 'Emanuele Barbato', 'Héctor Bueno', 'António Coca', 'Jean‐Philippe Collet', 'Ioan Mircea Coman', 'Verónica Dean', 'Victoria Delgado', 'Donna Fitzsimons', 'Oliver Gaemperli', 'Gerhard Hindricks', 'Bernard Iung', 'Peter Jüni', 'Hugo A. Katus', 'Juhani Knuuti', 'Patrizio Lancellotti', 'Christophe Leclercq', 'Theresa A. McDonagh', 'Massimo Piepoli', 'Piotr Ponikowski', 'Dimitrios Richter', 'Marco Roffi', 'Е. V. Shlyakhto', 'Iain A. Simpson', 'José Luis Zamorano', 'Mohamed Chettibi', 'Hamlet Hayrapetyan', 'Bernhard Metzler', 'Firdovsi İbrahimov', 'Volha Sujayeva', 'Christophe Beauloye', 'Larisa Dizdarević‐Hudić', 'Kiril Karamfiloff', 'Boško Škorić', 'Loizos Antoniades', 'Petr Toušek', 'PetrChristian Juhl Terkelsen', 'Sameh Shaheen', 'Toomas Marandi', 'Matti Niemelä', 'Saško Kedev', 'Martine Gilard', 'Alexander Aladashvili', 'Albrecht Elsaesser', 'Ioannis Georgios Kanakakis', 'Béla Merkely', 'Þórarinn Guðnason', 'Zaza Iakobishvili']",2017,European Heart Journal,Journal,,119-177,39,2,10.1093/eurheartj/ehx393,2017 ESC Guidelines for the management of acute myocardial infarction in patients presenting with ST-segment elevation The Task Force for the management of acute myocardial infarction in patients presenting with ST-segment elevation of the European Society of Cardiology (ESC),"['Medicine', 'Myocardial infarction', 'Cardiology', 'Internal medicine', 'ST segment', 'Elevation (ballistics)', 'ST elevation', 'Acute ST segment elevation myocardial infarction', 'Task force', 'Myocardial infarction diagnosis', 'Percutaneous coronary intervention', 'Geometry', 'Mathematics', 'Public administration', 'Political science']","acute myocardial infarction, acute myocardial infarction, european, [PAD] [PAD]"
Paper_01889,"Power Generation, Operation, and Control","['Allen J. Wood', 'B.F. Wollenberg']",1984,['Fuel and Energy Abstracts'],Unknown,,195,37,3,10.1016/0140-6701(96)88715-7,"Topics considered include characteristics of power generation units, transmission losses, generation with limited energy supply, control of generation, and power system security. This book is a graduate-level text in electric power engineering as regards to planning, operating, and controlling large scale power generation and transmission systems. Material used was generated in the post-1966 period. Many (if not most) of the chapter problems require a digital computer. A background in steady-state power circuit analysis is required.","['Electricity generation', 'Power (physics)', 'Electric power system', 'Electrical engineering', 'Engineering', 'Power transmission', 'Power control', 'Computer science', 'Quantum mechanics', 'Physics']","power, transmission losses, limited energy supply, power system security, electric power engineering, large, digital computer"
Paper_01890,Diagnostic and Statistical Manual of Mental Disorders(DSM),['Frederick T. L. Leong'],2008,Encyclopedia of Counseling,Journal,,,,,10.4135/9781412963978.n182,"Title: Diagnostic and statistical manual of mental disorders (DSM-5) Author: American Psychiatric Association Editors of Croatian Edition: Vlado Jukic, Goran Arbanas ISBN: 978-953-191-787-2 Publisher: Naklada Slap, Jastrebarsko, Croatia Number of pages: 936Diagnostic and statistical manual of mental disorders is a national classification, but since its third edition it became a worldwide used manual. [1] It has been published by the American Psychiatric Association and two years ago the fifth edition was released. [2] Croatian was among the first languages this book was translated to. [3] DSM-5 was translated by psychiatrists and psychologists, mainly from the University hospital Vrapce and published by the Naklada Slap publisher.DSM has always been more publicly debated than the other main classification - the International Classification of Diseases (ICD). [4] The same happened with this fifth edition. Even before it was released, numerous individuals, organizations, groups and associations were publicly speaking about the classification, new diagnostic entities and changing criteria. [5]Although there is a tendency of authors of both DSM and ICD to synchronize these two classifications and to make them more harmonized with each new edition, there are several differences among them. While ICD covers all the diseases, disorders and reasons for making a contact with the health system, DSM covers only mental disorders. Other disorders (medical conditions, as they are named in DSM-5) are not included, except in situations when they lead to a development of a mental disorder. The other main difference is that DSM is more operational zed, and gives criteria for each of the disorders, listing how many criteria have to be met to make a diagnosis of a particular disorder, and what excluding criteria are.Due to the fact that it is used all around the globe and since it has become the most used manual, it is sometimes said that DSM is a psychiatric Bible. [6]Some critics of DSM say that it stigmatizes people and that in each edition it includes more diagnostic entities. It is true that in each edition of DSM there are more disorders listed, but this is due to the fact that medicine is a developing area and new insights are made every year, so some disorders are separated into different subtypes or subgroups and different new diagnoses, giving the impression more behaviour are being pathologized. The intention of the authors was to make more homogenous groups. But, the truth is that, compared with ICD, it is more difficult to get a diagnosis in DSM, than in ICD, with the same clinical presentation. [7] DSM requires functional impairment or distress to pathologize behaviour, while in ICD this criterion is not present in every case.During the process of developing DSM-5 there was an open public discussion. [2] For over a year any person was able to participate in the discussion about future criteria, inclusion or exclusion of diagnostic entities from DSM. More than 21000 letters was sent to the authors. This was the unprecedented way of developing a classification that ICD now tries to follow in preparation of its 11th edition.As a direct consequence of such an open and wide discussion, some new disorders were included (e.g. hoarding disorder), some were excluded even though they were included during the proposal period (e.g. hypersexual disorders), some were heavily debated (e.g. narcissistic personality disorder). [8-10]As previously mentioned, DSM and ICD systems try to harmonize more. There were more non-American authors included in DSM-5 than ever before and some of the experts in the field were in the task force of DSM-5 and ICD-11. [2, 11]What is new in DSM-5, compared to DSM-IV. The organization of the chapters has been changed, so now the flow of the disorders follow life cycle. The book starts with neurodevelopmental disorders, followed by schizophrenia, bipolar and depressive disorders, and closing with neurocognitive disorders. …","['DSM-5', 'Psychiatry', 'Psychology', 'Classification of mental disorders', 'Diagnostic Classification of Mental Health and Developmental Disorders of Infancy and Early Childhood', 'Clinical psychology', 'Prevalence of mental disorders', 'Mental health']","statistical manual, mental disorders, american psychiatric association, mental disorders, american psychiatric association, dsm, international classification of diseases, ##m, ##d, medical, ##m, ##m, psychiatric, ##m, medicine"
Paper_01892,A Short Physical Performance Battery Assessing Lower Extremity Function: Association With Self-Reported Disability and Prediction of Mortality and Nursing Home Admission,"['Jack M. Guralnik', 'E. M. Simonsick', 'Luigi Ferrucci', 'Robert J. Glynn', 'Lisa Berkman', 'Dan G. Blazer', 'Paul A. Scherr', 'Robert B. Wallace']",1994,Journal of Gerontology,Journal,,M85-M94,49,2,10.1093/geronj/49.2.m85,"Journal Article A Short Physical Performance Battery Assessing Lower Extremity Function: Association With Self-Reported Disability and Prediction of Mortality and Nursing Home Admission Get access Jack M. Guralnik, Jack M. Guralnik 1Epidemiology, Demography, and Biometry Program, National Institutes on Aging, National Institutes of Health, BethesdaMaryland Search for other works by this author on: Oxford Academic PubMed Google Scholar Eleanor M. Simonsick, Eleanor M. Simonsick 1Epidemiology, Demography, and Biometry Program, National Institutes on Aging, National Institutes of Health, BethesdaMaryland Search for other works by this author on: Oxford Academic PubMed Google Scholar Luigi Ferrucci, Luigi Ferrucci 2Geriatric Department, Hospital I Fraticini, INRCAFlorence, Italy Search for other works by this author on: Oxford Academic PubMed Google Scholar Robert J. Glynn, Robert J. Glynn 3Channing Laboratory, Department of Medicine, Harvard Medical School Search for other works by this author on: Oxford Academic PubMed Google Scholar Lisa F. Berkman, Lisa F. Berkman 4Department of Epidemiology, Yale University School of Medicine Search for other works by this author on: Oxford Academic PubMed Google Scholar Dan G. Blazer, Dan G. Blazer 5Department of Psychiatry, Duke University School of Medicine Search for other works by this author on: Oxford Academic PubMed Google Scholar Paul A. Scherr, Paul A. Scherr 6Aging Studies Branch, National Centers for Disease Prevention and Health Promotion, Centers for Disease ControlAtlanta, Georgia Search for other works by this author on: Oxford Academic PubMed Google Scholar Robert B. Wallace Robert B. Wallace 7Department of Preventive Medicine and Environmental Health, University of Iowa Search for other works by this author on: Oxford Academic PubMed Google Scholar Journal of Gerontology, Volume 49, Issue 2, March 1994, Pages M85–M94, https://doi.org/10.1093/geronj/49.2.M85 Published: 01 March 1994 Article history Accepted: 17 June 1993 Received: 03 August 1993 Published: 01 March 1994","['Test (biology)', 'Timed Up and Go test', 'Medicine', 'Balance (ability)', 'Physical therapy', 'Physical medicine and rehabilitation', 'Gait', 'Gerontology', 'Psychology', 'Paleontology', 'Biology']","short physical performance battery, lower extremity function, nursing home admission, demo, biometry, ##metry, ##aging, health promotion, environmental health"
Paper_01893,ROUGE: A Package for Automatic Evaluation of Summaries,['Chin-Yew Lin'],2004,"[""Proceedings of the 2009 Workshop on Language Generation and Summarisation - UCNLG+Sum '09""]",Conference,"the 2009 Workshop, Suntec, Singapore",23,,,10.3115/1708155.1708161,"ROUGE stands for Recall-Oriented Understudy for Gisting Evaluation. It includes measures to automatically determine the quality of a summary by comparing it to other (ideal) summaries created by humans. The measures count the number of overlapping units such as n-gram, word sequences, and word pairs between the computer-generated summary to be evaluated and the ideal summaries created by humans. This paper introduces four different ROUGE measures: ROUGE-N, ROUGE-L, ROUGE-W, and ROUGE-S included in the ROUGE summarization evaluation package and their evaluations. Three of them have been used in the Document Understanding Conference (DUC) 2004, a large-scale summarization evaluation sponsored by NIST.","['ROUGE', 'Automatic summarization', 'NIST', 'Computer science', 'Natural language processing', 'Ideal (ethics)', 'Word (group theory)', 'Artificial intelligence', 'Information retrieval', 'Mathematics', 'Philosophy', 'Geometry', 'Epistemology']","rouge, gisting evaluation, word sequences, word pairs, rouge summar, document understanding conference, ##st"
Paper_01894,Understanding Information Technology Usage: A Test of Competing Models,"['Shirley Taylor', 'Peter Todd']",1995,Information Systems Research,Journal,,144-176,6,2,10.1287/isre.6.2.144,"The Technology Acceptance Model and two variations of the Theory of Planned Behavior were compared to assess which model best helps to understand usage of information technology. The models were compared using student data collected from 786 potential users of a computer resource center. Behavior data was based on monitoring 3,780 visits to the resource center over a 12-week period. Weighted least squares estimation revealed that all three models performed well in terms of fit and were roughly equivalent in terms of their ability to explain behavior. Decomposing the belief structures in the Theory of Planned Behavior provided a moderate increase in the explanation of behavioral intention. Overall, the results indicate that the decomposed Theory of Planned Behavior provides a fuller understanding of behavioral intention by focusing on the factors that are likely to influence systems use through the application of both design and implementation strategies.","['Theory of planned behavior', 'Resource (disambiguation)', 'Computer science', 'Test (biology)', 'Information technology', 'Econometrics', 'Knowledge management', 'Artificial intelligence', 'Mathematics', 'Control (management)', 'Computer network', 'Paleontology', 'Biology', 'Operating system']","technology acceptance model, planned behavior, information technology, student data, computer resource center, weighted least squares estimation, belief structures, planned behavior, behavioral intention, planned behavior, behavioral intention, implementation"
Paper_01895,The capacity of wireless networks,"['Piyush Gupta', 'P. R. Kumar']",2000,IEEE Transactions on Information Theory,Journal,,388-404,46,2,10.1109/18.825799,"When n identical randomly located nodes, each capable of transmitting at W bits per second and using a fixed range, form a wireless network, the throughput /spl lambda/(n) obtainable by each node for a randomly chosen destination is /spl Theta/(W//spl radic/(nlogn)) bits per second under a noninterference protocol. If the nodes are optimally placed in a disk of unit area, traffic patterns are optimally assigned, and each transmission's range is optimally chosen, the bit-distance product that can be transported by the network per second is /spl Theta/(W/spl radic/An) bit-meters per second. Thus even under optimal circumstances, the throughput is only /spl Theta/(W//spl radic/n) bits per second for each node for a destination nonvanishingly far away. Similar results also hold under an alternate physical model where a required signal-to-interference ratio is specified for successful receptions. Fundamentally, it is the need for every node all over the domain to share whatever portion of the channel it is utilizing with nodes in its local neighborhood that is the reason for the constriction in capacity. Splitting the channel into several subchannels does not change any of the results. Some implications may be worth considering by designers. Since the throughput furnished to each user diminishes to zero as the number of users is increased, perhaps networks connecting smaller numbers of users, or featuring connections mostly with nearby neighbors, may be more likely to be find acceptance.","['Node (physics)', 'Throughput', 'Computer science', 'Computer network', 'Channel (broadcasting)', 'Wireless network', 'Transmission (telecommunications)', 'Upper and lower bounds', 'Topology (electrical circuits)', 'Product (mathematics)', 'Wireless', 'Mathematics', 'Telecommunications', 'Combinatorics', 'Physics', 'Mathematical analysis', 'Geometry', 'Quantum mechanics']","wireless network, noninterference protocol"
Paper_01897,Estimation of the surface free energy of polymers,"['D.K. Owens', 'R. C. Wendt']",1969,Journal of Applied Polymer Science,Journal,,1741-1747,13,8,10.1002/app.1969.070130815,Abstract A method for measuring the surface energy of solids and for resolving the surface energy into contributions from dispersion and dipole‐hydrogen bonding forces has been developed. It is based on the measurement of contact angles with water and methylene iodide. Good agreement has been obtained with the more laborious γ c method. Evidence for a finite value of liquid‐solid interfacial tension at zero contact angle is presented. The method is especially applicable to the surface characterization of polymers.,"['Contact angle', 'Surface energy', 'Surface tension', 'Polymer', 'Materials science', 'London dispersion force', 'Dispersion (optics)', 'Surface (topology)', 'Free surface', 'Energy (signal processing)', 'Methylene', 'Iodide', 'Dipole', 'Inverse gas chromatography', 'Composite material', 'Thermodynamics', 'Optics', 'Chemistry', 'Molecule', 'Organic chemistry', 'Physics', 'Geometry', 'van der Waals force', 'Mathematics', 'Quantum mechanics']","surface energy, solids, surface energy, dispersion, dipole, hydrogen bonding forces, contact angles, methylene, surface characterization, polymers, [PAD] [PAD], [PAD], [PAD], [PAD], [PAD], [PAD] [PAD], [PAD] [PAD], [PAD], [PAD], [PAD], [PAD] [PAD] [PAD], [PAD]"
Paper_01898,Semiconductor Nanocrystals as Fluorescent Biological Labels,"['Marcel P. Bruchez', 'Mario M. Moronne', 'Peter Gin', 'Shimon Weiss', 'A. Paul Alivisatos']",1998,Science,Journal,,2013-2016,281,5385,10.1126/science.281.5385.2013,"Semiconductor nanocrystals were prepared for use as fluorescent probes in biological staining and diagnostics. Compared with conventional fluorophores, the nanocrystals have a narrow, tunable, symmetric emission spectrum and are photochemically stable. The advantages of the broad, continuous excitation spectrum were demonstrated in a dual-emission, single-excitation labeling experiment on mouse fibroblasts. These nanocrystal probes are thus complementary and in some cases may be superior to existing fluorophores.","['Nanocrystal', 'Fluorescence', 'Semiconductor', 'Materials science', 'Optoelectronics', 'Excitation', 'Broad spectrum', 'Nanotechnology', 'Chemistry', 'Optics', 'Physics', 'Combinatorial chemistry', 'Quantum mechanics']","semiconductor nanocrystals, fluorescent probes, biological staining, diagnostics, mouse fibroblasts, nano, ##ystal probe, [PAD], [PAD], [PAD], [PAD] [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD] [PAD], [PAD], [PAD] [PAD]"
Paper_01902,Variable Selection via Nonconcave Penalized Likelihood and its Oracle Properties,"['Jianqing Fan', 'Runze Li']",2001,Journal of the American Statistical Association,Journal,,1348-1360,96,456,10.1198/016214501753382273,"Variable selection is fundamental to high-dimensional statistical modeling, including nonparametric regression. Many approaches in use are stepwise selection procedures, which can be computationally expensive and ignore stochastic errors in the variable selection process. In this article, penalized likelihood approaches are proposed to handle these kinds of problems. The proposed methods select variables and estimate coefficients simultaneously. Hence they enable us to construct confidence intervals for estimated parameters. The proposed approaches are distinguished from others in that the penalty functions are symmetric, nonconcave on (0, ∞), and have singularities at the origin to produce sparse solutions. Furthermore, the penalty functions should be bounded by a constant to reduce bias and satisfy certain conditions to yield continuous solutions. A new algorithm is proposed for optimizing penalized likelihood functions. The proposed ideas are widely applicable. They are readily applied to a variety of parametric models such as generalized linear models and robust regression models. They can also be applied easily to nonparametric modeling by using wavelets and splines. Rates of convergence of the proposed penalized likelihood estimators are established. Furthermore, with proper choice of regularization parameters, we show that the proposed estimators perform as well as the oracle procedure in variable selection; namely, they work as well as if the correct submodel were known. Our simulation shows that the newly proposed methods compare favorably with other variable selection techniques. Furthermore, the standard error formulas are tested to be accurate enough for practical applications.","['Feature selection', 'Estimator', 'Mathematical optimization', 'Nonparametric statistics', 'Mathematics', 'Penalty method', 'Model selection', 'Oracle', 'Computer science', 'Econometrics', 'Statistics', 'Machine learning', 'Software engineering']","variable selection, nonparametric regression, stepwise selection procedures, stochastic errors, variable selection, penalized likelihood approaches, confidence intervals, penalty functions, sparse, penalty functions, penalized likelihood functions, parametric models, generalized linear models, robust regression models, nonparametric modeling, wavelets, splines, penalized likelihood estimators, regular, oracle procedure, variable selection, variable selection, standard"
Paper_01903,Finance and Growth: Schumpeter Might Be Right,"['Robert G. King', 'Ross Levine']",1993,The Quarterly Journal of Economics,Journal,,717-737,108,3,10.2307/2118406,"We present cross-country evidence consistent with Schumpeter's view that the financial system can promote economic growth, using data on 80 countries over the 1960–1989 period. Various measures of the level of financial development are strongly associated with real per capita GDP growth, the rate of physical capital accumulation, and improvements in the efficiency with which economies employ physical capital. Further, the predetermined component of financial development is robustly correlated with future rates of economic growth, physical capital accumulation, and economic efficiency improvements.","['Economics', 'Physical capital', 'Per capita', 'Capital (architecture)', 'Capital accumulation', 'Capital formation', 'Monetary economics', 'Macroeconomics', 'Financial capital', 'Human capital', 'Market economy', 'Population', 'Demography', 'Archaeology', 'Sociology', 'History']","financial system, economic growth, financial development, physical capital accumulation, financial development, physical capital accumulation, economic efficiency"
Paper_01904,Mild Cognitive Impairment,"['Ronald C. Petersen', 'Glenn E. Smith', 'Stephen C. Waring', 'Robert J. Ivnik', 'Eric G. Tangalos', 'Emre Kokmen']",1999,Archives of Neurology,Journal,,303-303,56,3,10.1001/archneur.56.3.303,"Subjects with a mild cognitive impairment (MCI) have a memory impairment beyond that expected for age and education yet are not demented. These subjects are becoming the focus of many prediction studies and early intervention trials.To characterize clinically subjects with MCI cross-sectionally and longitudinally.A prospective, longitudinal inception cohort.General community clinic.A sample of 76 consecutively evaluated subjects with MCI were compared with 234 healthy control subjects and 106 patients with mild Alzheimer disease (AD), all from a community setting as part of the Mayo Clinic Alzheimer's Disease Center/Alzheimer's Disease Patient Registry, Rochester, Minn.The 3 groups of individuals were compared on demographic factors and measures of cognitive function including the Mini-Mental State Examination, Wechsler Adult Intelligence Scale-Revised, Wechsler Memory Scale-Revised, Dementia Rating Scale, Free and Cued Selective Reminding Test, and Auditory Verbal Learning Test. Clinical classifications of dementia and AD were determined according to the Diagnostic and Statistical Manual of Mental Disorders, Revised Third Edition and the National Institute of Neurological and Communicative Disorders and Stroke-Alzheimer's Disease and Related Disorders Association criteria, respectively.The primary distinction between control subjects and subjects with MCI was in the area of memory, while other cognitive functions were comparable. However, when the subjects with MCI were compared with the patients with very mild AD, memory performance was similar, but patients with AD were more impaired in other cognitive domains as well. Longitudinal performance demonstrated that the subjects with MCI declined at a rate greater than that of the controls but less rapidly than the patients with mild AD.Patients who meet the criteria for MCI can be differentiated from healthy control subjects and those with very mild AD. They appear to constitute a clinical entity that can be characterized for treatment interventions.","['Clinical Dementia Rating', 'Dementia', 'Wechsler Adult Intelligence Scale', 'Psychology', ""Alzheimer's disease"", 'Cognition', 'Audiology', 'Disease', 'Psychiatry', 'Clinical psychology', 'Medicine', 'Cognitive impairment', 'Internal medicine']","mild cognitive impairment, memory impairment, early intervention, general community clinic, healthy control, mild alzheimer disease, cognitive function, wechsler adult intelligence scale, wechsler memory scale, dementia rating scale, auditory verbal learning test, mental disorders"
Paper_01907,The Ecological Approach to Visual Perception,['James J. Gibson'],2014,Psychology Press eBooks,Unknown,,,,,10.4324/9781315740218,"This book, first published in 1979,&nbsp;is about how we see: the environment around us (its surfaces, their layout, and their colors and textures); where we are in the environment; whether or not we are moving and, if we are, where we are going; what things are good for; how to do things (to thread a needle or drive an automobile); or why things look as they do. The basic assumption is that vision depends on the eye which is connected to the brain. The author suggests that natural vision depends on the eyes in the head on a body supported by the ground, the brain being only the central organ of a complete visual system. When no constraints are put on the visual system, people look around, walk up to something interesting and move around it so as to see it from all sides, and go from one vista to another. That is natural vision -- and what this book is about.","['Perception', 'Geography', 'Psychology', 'Ecology', 'Cognitive psychology', 'Biology', 'Neuroscience']","natural vision, natural vision"
Paper_01908,The Pharmacological Basis of Therapeutics,"['Laurie Goodman', 'Alfred G. Gilman', 'Alfred G. Gilman', 'George B. Koelle']",1976,American Journal of Health-System Pharmacy,Journal,,373-373,33,4,10.1093/ajhp/33.4.373a,"Journal Article The Pharmacological Basis of Therapeutics Get access The Pharmacological Basis of Therapeutics, Fifth Edition, edited by Louis S. Goodman and Alfred Gilman. Published by Macmillan Publishing Co., Inc., 866 Third Avenue, New York, NY 10022, 1975. xvi + 1704 p. Price $30.00. American Journal of Hospital Pharmacy, Volume 33, Issue 4, 1 April 1976, Page 373, https://doi.org/10.1093/ajhp/33.4.373a Published: 01 April 1976","['Library science', 'Publishing', 'Pharmacy', 'Medicine', 'Gerontology', 'Classics', 'Art', 'Political science', 'Family medicine', 'Computer science', 'Law']","pharmacological basis, therapeutics, pharmacological basis, therapeutics, macmillan, american, hospital pharmacy, [PAD], [PAD] [PAD], [PAD], [PAD]"
Paper_01909,The Li-Ion Rechargeable Battery: A Perspective,"['John B. Goodenough', 'Kyu‐Sung Park']",2013,Journal of the American Chemical Society,Journal,,1167-1176,135,4,10.1021/ja3091438,"Each cell of a battery stores electrical energy as chemical energy in two electrodes, a reductant (anode) and an oxidant (cathode), separated by an electrolyte that transfers the ionic component of the chemical reaction inside the cell and forces the electronic component outside the battery. The output on discharge is an external electronic current I at a voltage V for a time Δt. The chemical reaction of a rechargeable battery must be reversible on the application of a charging I and V. Critical parameters of a rechargeable battery are safety, density of energy that can be stored at a specific power input and retrieved at a specific power output, cycle and shelf life, storage efficiency, and cost of fabrication. Conventional ambient-temperature rechargeable batteries have solid electrodes and a liquid electrolyte. The positive electrode (cathode) consists of a host framework into which the mobile (working) cation is inserted reversibly over a finite solid-solution range. The solid-solution range, which is reduced at higher current by the rate of transfer of the working ion across electrode/electrolyte interfaces and within a host, limits the amount of charge per electrode formula unit that can be transferred over the time Δt = Δt(I). Moreover, the difference between energies of the LUMO and the HOMO of the electrolyte, i.e., electrolyte window, determines the maximum voltage for a long shelf and cycle life. The maximum stable voltage with an aqueous electrolyte is 1.5 V; the Li-ion rechargeable battery uses an organic electrolyte with a larger window, which increase the density of stored energy for a given Δt. Anode or cathode electrochemical potentials outside the electrolyte window can increase V, but they require formation of a passivating surface layer that must be permeable to Li(+) and capable of adapting rapidly to the changing electrode surface area as the electrode changes volume during cycling. A passivating surface layer adds to the impedance of the Li(+) transfer across the electrode/electrolyte interface and lowers the cycle life of a battery cell. Moreover, formation of a passivation layer on the anode robs Li from the cathode irreversibly on an initial charge, further lowering the reversible Δt. These problems plus the cost of quality control of manufacturing plague development of Li-ion rechargeable batteries that can compete with the internal combustion engine for powering electric cars and that can provide the needed low-cost storage of electrical energy generated by renewable wind and/or solar energy. Chemists are contributing to incremental improvements of the conventional strategy by investigating and controlling electrode passivation layers, improving the rate of Li(+) transfer across electrode/electrolyte interfaces, identifying electrolytes with larger windows while retaining a Li(+) conductivity σ(Li) > 10(-3) S cm(-1), synthesizing electrode morphologies that reduce the size of the active particles while pinning them on current collectors of large surface area accessible by the electrolyte, lowering the cost of cell fabrication, designing displacement-reaction anodes of higher capacity that allow a safe, fast charge, and designing alternative cathode hosts. However, new strategies are needed for batteries that go beyond powering hand-held devices, such as using electrode hosts with two-electron redox centers; replacing the cathode hosts by materials that undergo displacement reactions (e.g. sulfur) by liquid cathodes that may contain flow-through redox molecules, or by catalysts for air cathodes; and developing a Li(+) solid electrolyte separator membrane that allows an organic and aqueous liquid electrolyte on the anode and cathode sides, respectively. Opportunities exist for the chemist to bring together oxide and polymer or graphene chemistry in imaginative morphologies.","['Electrolyte', 'Battery (electricity)', 'Anode', 'Cathode', 'Chemistry', 'Electrode', 'Energy storage', 'Electrochemistry', 'Voltage', 'Ion', 'Analytical Chemistry (journal)', 'Chemical engineering', 'Electrical engineering', 'Power (physics)', 'Thermodynamics', 'Organic chemistry', 'Physical chemistry', 'Physics', 'Engineering']","##uctan, ##te, storage efficiency, pass, pass, passivation layer, quality"
Paper_01911,European Guidelines on cardiovascular disease prevention in clinical practice (version 2012): The Fifth Joint Task Force of the European Society of Cardiology and Other Societies on Cardiovascular Disease Prevention in Clinical Practice (constituted by representatives of nine societies and by invited experts) * Developed with the special contribution of the European Association for Cardiovascular Prevention &amp; Rehabilitation (EACPR),"['Joep Perk', 'Guy De Backer', 'H. Gohlke', 'Ian Graham', 'Željko Reiner', 'M. Verschuren', 'Christian Albus', 'Pascale Benlian', 'G. Boysen', 'Renata Cífková', 'Christi Deaton', 'S. Ebrahim', 'Michael Fisher', 'Giuseppe Germanò', 'Richard Hobbs', 'A. Hoes', 'S. Karadeniz', 'Alessandro Mezzani', 'Eva Prescott', 'Lars Rydén', 'M. Scherer', 'Mikko Syvänne', 'Wilma J.M. Scholte op Reimer', 'Christian Vrints', 'David A. Wood', 'José Luis Zamorano', 'F Zannad', 'Marie Therese Cooney', 'Jeroen J. Bax', 'H. Baumgartner', 'Claudio Ceconi', 'V. Dean', 'Christi Deaton', 'Robert Fagard', 'Christian Funck‐Brentano', 'David Hasdai', 'A. Hoes', 'Paulus Kirchhof', 'Juhani Knuuti', 'Philippe Kolh', 'Theresa A. McDonagh', 'Bruno Moulin', 'Bogdan A. Popescu', 'Z. Reiner', 'U Sechtem', 'P. A. Sirnes', 'Michał Tendera', 'Adam Torbicki', 'A. Vahanian', 'Stephan Windecker', 'Christian Funck‐Brentano', 'P. A. Sirnes', 'Victor Aboyans', 'Eduardo Alegría Ezquerra', 'Colin Baigent', 'Carlos Brotons', 'G. Burell', 'Antonio Ceriello', 'Johan De Sutter', 'J. Deckers', 'Stefano Del Prato', 'H.‐C. Diener', 'Donna Fitzsimons', 'Zlatko Fras', 'Rainer Hambrecht', 'Piotr Jankowski', 'U Keil', 'Mike Kirby', 'Mogens Lytken Larsen', 'Giuseppe Mancia', 'Athanasios Manolis', 'John J.V. McMurray', 'A. Pajak', 'Alexander Parkhomenko', 'Loukianos Rallidis', 'Fausto Rigo', 'Evangelista Rocha', 'Luís M. Ruilope', 'Enno T. van der Velde', 'Diego Vanuzzo', 'Margus Viigimaa', 'Massimo Volpe', 'Olov Wiklund', 'Christian Wolpert']",2012,European Heart Journal,Journal,,1635-1701,33,13,10.1093/eurheartj/ehs092,C-reactive protein CURE Clopidogrel in Unstable Angina to Prevent Recurrent Events CVD cardiovascular disease DALYs disability-adjusted life years DBP diastolic blood,"['Medicine', 'Clinical Practice', 'Task force', 'Disease', 'Clopidogrel', 'Angina', 'Intensive care medicine', 'Cardiovascular health', 'Cardiology', 'Internal medicine', 'Atherosclerotic cardiovascular disease', 'Primary prevention', 'Aspirin', 'Physical therapy', 'Myocardial infarction', 'Public administration', 'Political science']","##op, unstable, cardiovascular disease, diastolic blood, [PAD], [PAD], [PAD], [PAD] [PAD], [PAD], [PAD] [PAD] [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD] [PAD], [PAD] [PAD], [PAD], [PAD], [PAD]"
Paper_01912,An Introduction to Qualitative Research,['Uwe Flick'],1998,['Handbook of Disability'],Unknown,,375-378,,,10.1007/978-981-19-6056-7_75,"PART ONE: FRAMEWORK Guide to this Book Qualitative Research: Why And How to Do It Qualitative and Quantitative Research Approaches to Qualitative Research Ethics of Qualitative Research PART TWO: THEORY IN QUALITATIVE RESEARCH Using the Existing Literature Theories Underlying Qualitative Research Texts as Data in Qualitative Research PART THREE: RESEARCH DESIGN Designing Qualitative Research The Qualitative Research Process Research Questions Entering the Field Sampling Triangulation PART FOUR: VERBAL DATA Collecting Verbal Data Interviews Focus Groups Using Narrative Data PART FIVE: DATA BEYOND TALK Collecting Data Beyond Talk Observation and Ethnography Visual Data: Photography, Film & Video Using Documents as Data PART SIX: QUALITATIVE DATA ANALYSIS Qualitative Data Analysis Transcription and Data Management Grounded Theory Coding Thematic Coding and Content Analysis Naturally Occuring Data: Conversation, Discourse, and Hermeneutic Analysis Using Software in Qualitative Data Analysis PART SEVEN: GROUNDING, WRITING AND OUTLOOK Quality of Qualitative Research: Criteria and Beyond Writing Qualitative Research State of the Art and the Future","['Qualitative research', 'Grounded theory', 'Qualitative property', 'Coding (social sciences)', 'Thematic analysis', 'Data science', 'Computer science', 'Sociology', 'Social science', 'Machine learning']","qualitative research, quantitative, qualitative, qualitative research, ##tative, research, ##tative, ##tative, verbal data, verbal data, narrative data, et, qualitative data analysis qualitative data analysis, data management grounded theory, thematic coding, content analysis, discourse, hermeneutic analysis, software, qualitative data analysis, outlook, [PAD] [PAD], [PAD], [PAD], [PAD], [PAD]"
Paper_01914,VSEARCH: a versatile open source tool for metagenomics,"['Torbjørn Rognes', 'Tomáš Flouri', 'Ben Nichols', 'Christopher Quince', 'Frédéric Mahé']",2016,PeerJ,Journal,,e2584-e2584,4,,10.7717/peerj.2584,"VSEARCH is an open source and free of charge multithreaded 64-bit tool for processing and preparing metagenomics, genomics and population genomics nucleotide sequence data. It is designed as an alternative to the widely used USEARCH tool (Edgar, 2010) for which the source code is not publicly available, algorithm details are only rudimentarily described, and only a memory-confined 32-bit version is freely available for academic use.When searching nucleotide sequences, VSEARCH uses a fast heuristic based on words shared by the query and target sequences in order to quickly identify similar sequences, a similar strategy is probably used in USEARCH. VSEARCH then performs optimal global sequence alignment of the query against potential target sequences, using full dynamic programming instead of the seed-and-extend heuristic used by USEARCH. Pairwise alignments are computed in parallel using vectorisation and multiple threads.VSEARCH includes most commands for analysing nucleotide sequences available in USEARCH version 7 and several of those available in USEARCH version 8, including searching (exact or based on global alignment), clustering by similarity (using length pre-sorting, abundance pre-sorting or a user-defined order), chimera detection (reference-based or de novo), dereplication (full length or prefix), pairwise alignment, reverse complementation, sorting, and subsampling. VSEARCH also includes commands for FASTQ file processing, i.e., format detection, filtering, read quality statistics, and merging of paired reads. Furthermore, VSEARCH extends functionality with several new commands and improvements, including shuffling, rereplication, masking of low-complexity sequences with the well-known DUST algorithm, a choice among different similarity definitions, and FASTQ file format conversion. VSEARCH is here shown to be more accurate than USEARCH when performing searching, clustering, chimera detection and subsampling, while on a par with USEARCH for paired-ends read merging. VSEARCH is slower than USEARCH when performing clustering and chimera detection, but significantly faster when performing paired-end reads merging and dereplication. VSEARCH is available at https://github.com/torognes/vsearch under either the BSD 2-clause license or the GNU General Public License version 3.0.VSEARCH has been shown to be a fast, accurate and full-fledged alternative to USEARCH. A free and open-source versatile tool for sequence analysis is now available to the metagenomics community.","['Computer science', 'Pairwise comparison', 'Source code', 'Metagenomics', 'Shuffling', 'Cluster analysis', 'Memory footprint', 'Data mining', 'Biology', 'Artificial intelligence', 'Programming language', 'Genetics', 'Gene']","vsearch, ##gen, gen, population genomics, ##ch, vs, ##ch, usearch, vsearch, global sequence alignment, full dynamic programming, usearch, pairwise alignment, ##isation, multiple, vsearch, use, ##ch, searching, global alignment, clustering, similarity, chimera detection, ##tion, pairwise alignment, reverse complementation, sorting, subsampling, vsearch, fastq file processing, format detection, filtering, read quality statistics, vs, ##ch, shuffling, rereplication, dust algorithm, similarity, fastq file format conversion, vsearch, ##ch, clustering, chimera detection, ##sampling, ##arch, vsearch, ##ch, clustering, chimera detection, der, ##tion, vs, ##ch, ##ch, vs, ##ch"
Paper_01915,Perception of Risk,['Paul Slovic'],1987,Science,Journal,,280-285,236,4799,10.1126/science.3563507,"Studies of risk perception examine the judgments people make when they are asked to characterize and evaluate hazardous activities and technologies. This research aims to aid risk analysis and policy-making by (i) providing a basis for understanding and anticipating public responses to hazards and (ii) improving the communication of risk information among lay people, technical experts, and decision-makers. This work assumes that those who promote and regulate health and safety need to understand how people think about and respond to risk. Without such understanding, well-intended policies may be ineffective.","['Perception', 'Risk perception', 'Risk communication', 'Work (physics)', 'Risk analysis (engineering)', 'Hazardous waste', 'Risk assessment', 'Public relations', 'Psychology', 'Business', 'Applied psychology', 'Computer science', 'Political science', 'Engineering', 'Computer security', 'Mechanical engineering', 'Neuroscience', 'Waste management']","risk perception, hazardous activities, public, technical experts"
Paper_01918,Primer3—new capabilities and interfaces,"['Andreas Untergasser', 'Ioana Cutcutache', 'Triinu Kõressaar', 'Jian Ye', 'Brant C. Faircloth', 'Maido Remm', 'Steve Rozen']",2012,Nucleic Acids Research,Journal,,e115-e115,40,15,10.1093/nar/gks596,"Polymerase chain reaction (PCR) is a basic molecular biology technique with a multiplicity of uses, including deoxyribonucleic acid cloning and sequencing, functional analysis of genes, diagnosis of diseases, genotyping and discovery of genetic variants. Reliable primer design is crucial for successful PCR, and for over a decade, the open-source Primer3 software has been widely used for primer design, often in high-throughput genomics applications. It has also been incorporated into numerous publicly available software packages and web services. During this period, we have greatly expanded Primer3's functionality. In this article, we describe Primer3's current capabilities, emphasizing recent improvements. The most notable enhancements incorporate more accurate thermodynamic models in the primer design process, both to improve melting temperature prediction and to reduce the likelihood that primers will form hairpins or dimers. Additional enhancements include more precise control of primer placement—a change motivated partly by opportunities to use whole-genome sequences to improve primer specificity. We also added features to increase ease of use, including the ability to save and re-use parameter settings and the ability to require that individual primers not be used in more than one primer pair. We have made the core code more modular and provided cleaner programming interfaces to further ease integration with other software. These improvements position Primer3 for continued use with genome-scale data in the decade ahead.","['Biology', 'Primer (cosmetics)', 'Computational biology', 'Software', 'Modular design', 'Genotyping', 'Genomics', 'Polymerase chain reaction', 'Genome', 'Source code', 'Computer science', 'Genetics', 'Programming language', 'Gene', 'Chemistry', 'Organic chemistry', 'Genotype']","polymerase chain reaction, pcr, molecular biology, ##yribon, ##leic acid, functional analysis, genotyping, genetic variants, ##r design, ##r, ##r, ##r, thermod, ##mic models, melting temperature prediction, primer placement, primer"
Paper_01919,Statistical Methods for Psychology.,"['Andrew C. Gudgeon', 'David C. Howell']",1994,Journal of the Royal Statistical Society Series D (The Statistician),Journal,,211-211,43,1,10.2307/2348956,"This seventh edition of Statistical Methods for Psychology, like the previous editions, surveys statistical techniques commonly used in the behavioral and social sciences, especially psychology and education. Although it is designed for advanced undergraduates and graduate students, it does not assume that students have had either a previous course in statistics or a course in mathematics beyond high-school algebra. Those students who have had an introductory course will find that the early material provides a welcome review. The book is suitable for either a one-term or a full-year course, and I have used it successfully for both. Since I have found that students, and faculty, frequently refer back to the book from which they originally learned statistics when they have a statistical problem, I have included material that will make the book a useful reference for future use. The instructor who wishes to omit this material will have no difficulty doing so. I have cut back on that material, however, to include only what is still likely to be useful. The idea of including every interesting idea had led to a book that was beginning to be daunting.","['Psychology', 'Econometrics', 'Mathematics']","statistical methods, psychology, statistical techniques, psychology, education, graduate students"
Paper_01921,Sensitive measurement of optical nonlinearities using a single beam,"['Mansoor Sheik‐Bahae', 'A. A. Said', 'Tai‐Huei Wei', 'David J. Hagan', 'Eric W. Van Stryland']",1990,IEEE Journal of Quantum Electronics,Journal,,760-769,26,4,10.1109/3.53394,"A sensitive single-beam technique for measuring both the nonlinear refractive index and nonlinear absorption coefficient for a wide variety of materials is reported. The authors describe the experimental details and present a comprehensive theoretical analysis including cases where nonlinear refraction is accompanied by nonlinear absorption. In these experiments, the transmittance of a sample is measured through a finite aperture in the far field as the sample is moved along the propagation path (z) of a focused Gaussian beam. The sign and magnitude of the nonlinear refraction are easily deduced from such a transmittance curve (Z-scan). Employing this technique, a sensitivity of better than lambda /300 wavefront distortion is achieved in n/sub 2/ measurements of BaF/sub 2/ using picosecond frequency-doubled Nd:YAG laser pulses.< <ETX xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">&gt;</ETX>","['Optics', 'Transmittance', 'Z-scan technique', 'Refractive index', 'Refraction', 'Distortion (music)', 'Nonlinear system', 'Physics', 'Laser', 'Wavefront', 'Gaussian beam', 'Beam (structure)', 'Attenuation coefficient', 'Materials science', 'Nonlinear optics', 'Optoelectronics', 'Amplifier', 'CMOS', 'Quantum mechanics']","nonlinear refractive index, nonlinear absorption coefficient, nonlinear refraction, nonlinear absorption, transmittance, finite aperture, propagation path, focused gaussian beam, nonlinear refraction, ##ink"
Paper_01922,Green Chemistry: Theory and Practice,"['Paul T. Anastas', 'John C. Warner']",1998,['Chemical Society Reviews'],Unknown,,2869,39,8,10.1039/b926439f,1: Introduction. 2: What is Green Chemistry?. 3: Tools of Green Chemistry. 4: Principles of Green Chemistry. 5: Evaluating the Impacts of Chemistry. 6: Evaluating Feedstocks and Starting Materials. 7: Evaluating Reaction Types. 8: Evaluation of Methods to Design Safer Chemicals. 9: Illustrative Examples. 10: Future Trends in Green Chemistry,"['Green chemistry', 'SAFER', 'Chemistry', 'Biochemical engineering', 'Engineering', 'Nanotechnology', 'Environmental chemistry', 'Computer science', 'Organic chemistry', 'Materials science', 'Reaction mechanism', 'Catalysis', 'Computer security']","green chemistry, green chemistry, green chemistry, feedstock, starting materials, ##rative, green chemistry, [PAD], [PAD], [PAD], [PAD], [PAD]"
Paper_01923,The Minimalist Program,['Noam Chomsky'],1992,['Lingua'],Unknown,,267-273,107,3-4,10.1016/s0024-3841(98)00042-4,"A classic work that situates linguistic theory in the broader cognitive sciences, formulating and developing the minimalist program. In his foundational book, The Minimalist Program, published in 1995, Noam Chomsky offered a significant contribution to the generative tradition in linguistics. This twentieth-anniversary edition reissues this classic work with a new preface by the author. In four essays, Chomsky attempts to situate linguistic theory in the broader cognitive sciences, with the essays formulating and progressively developing the minimalist approach to linguistic Building on the theory of principles and parameters and, in particular, on principles of economy of derivation and representation, the minimalist framework takes Universal Grammar as providing a unique computational system, with derivations driven by morphological properties, to which the syntactic variation of languages also restricted. Within this theoretical framework, linguistic expressions are generated by optimally efficient derivations that must satisfy the conditions that hold on interface levels, the only levels of linguistic representation. The interface levels provide instructions to two types of performance systems, articulatory-perceptual and conceptual-intentional. All syntactic conditions, then, express properties of these interface levels, reflecting the interpretive requirements of language and keeping to very restricted conceptual resources. In the preface to this edition, Chomsky emphasizes that the minimalist approach developed in the book and in subsequent work is a program, not a theory. With this book, Chomsky built on pursuits from the earliest days of generative grammar to formulate a new research program that had far-reaching implications for the field.","['Minimalist program', 'Generative grammar', 'Transformational grammar', 'Linguistics', 'Computer science', 'Theoretical linguistics', 'Universal grammar', 'Representation (politics)', 'Grammar', 'Applied linguistics', 'Interface (matter)', 'Cognitive science', 'Artificial intelligence', 'Psychology', 'Philosophy', 'Bubble', 'Maximum bubble pressure method', 'Politics', 'Parallel computing', 'Political science', 'Law']","linguistic theory, minimalist program, minimalist program, generative tradition, linguistics, minimal, minimal, universal grammar, morphological properties, syntactic variation, linguistic expressions, performance systems, ##ive requirements, minimal, generative grammar"
Paper_01924,A Theory of Sensitized Luminescence in Solids,['D. L. Dexter'],1953,The Journal of Chemical Physics,Journal,,836-850,21,5,10.1063/1.1699044,"The term ``sensitized luminescence'' in crystalline phosphors refers to the phenomenon whereby an impurity (activator, or emitter) is enabled to luminesce upon the absorption of light in a different type of center (sensitizer, or absorber) and upon the subsequent radiationless transfer of energy from the sensitizer to the activator. The resonance theory of Förster, which involves only allowed transitions, is extended to include transfer by means of forbidden transitions which, it is concluded, are responsible for the transfer in all inorganic systems yet investigated. The transfer mechanisms of importance are, in order of decreasing strength, the overlapping of the electric dipole fields of the sensitizer and the activator, the overlapping of the dipole field of the sensitizer with the quadrupole field of the activator, and exchange effects. These mechanisms will give rise to ``sensitization'' of about 103−104, 102, and 30 lattice sites surrounding each sensitizer in typical systems. The dependence of transfer efficiency upon sensitizer and activator concentrations and on temperature are discussed. Application is made of the theory to experimental results on inorganic phosphors, and further experiments are suggested.","['Activator (genetics)', 'Luminescence', 'Phosphor', 'Impurity', 'Chemistry', 'Dipole', 'Atomic physics', 'Energy transfer', 'Quadrupole', 'Lattice (music)', 'Materials science', 'Chemical physics', 'Optoelectronics', 'Physics', 'Acoustics', 'Biochemistry', 'Organic chemistry', 'Gene']","sensitized luminescence, crystalline phosphors, radiationless transfer, resonance theory, allowed transitions, forbidden transitions, transfer mechanisms, electric dipole fields, dipole field, quadrupole field, exchange effects, sensitization, transfer efficiency, inorganic phosphors"
Paper_01925,Acts of meaning,['Jerome S. Bruner'],1991,Choice Reviews Online,Journal,,28-6498,28,11,10.5860/choice.28-6498,"Jerome Bruner argues that the cognitive revolution, with its current fixation on mind as information processor; has led psychology away from the deeper objective of understanding mind as a creator of meanings. Only by breaking out of the limitations imposed by a computational model of mind can we grasp the special interaction through which mind both constitutes and is constituted by culture. (http://books.google.fr/books?id=YHt_M41uIuUC&pg=PA157&dq=Bruner,+J.+%281990%29.+Acts+of+meaning&hl=fr&ei=EwOXTrqpCsPWsgaGgO2YBA&sa=X&oi=book_result&ct=result&resnum=1&ved=0CDMQ6AEwAA#v=onepage&q&f=false)","['Meaning (existential)', 'Linguistics', 'Philosophy', 'History', 'Epistemology']","cognitive revolution, information processor, computational model"
Paper_01926,A new scale of social desirability independent of psychopathology.,"['Douglas P. Crowne', 'David Marlowe']",1960,Journal of Consulting Psychology,Journal,,349-354,24,4,10.1037/h0047358,"It has long been recognized that personality test scores are influenced by non-test-relevant response determinants. Wiggins and Rumrill (1959) distinguish three approaches to this problem. Briefly, interest in the problem of response distortion has been concerned with attempts at statistical correction for or (Meehl & Hathaway, 1946), the analysis of response sets (Cronbach, 1946,1950), and ratings of the social desirability of personality test items (Edwards, 19 5 7). A further distinction can be made, however, which results in a somewhat different division of approaches to the question of response distortion. Common to both the Meehl and Hathaway corrections for faking good and faking bad and Cronbach's notion of response sets is an interest in the test behavior of the subject(S). By social desirability, on the other hand, Edwards primarily means the value for any personality statement such that the scale value indicates the position of the statement on the social desirability continuum . (1957, p. 3). Social desirability, thus, has been used to refer to a characteristic of test items, i.e., their scale position on a social desirability scale. Whether the test behavior of 5s or the social desirability properties of items are the focus of interest, however, it now seems clear that underlying both these approaches is the concept of statistical deviance. In the construction of the MMPI K scale, for example, items were selected which differentiated between clinically normal persons producing abnormal te¥Tpfpfiles~snd^cTinically abnormal individuals with abnormal test profiles, and between clinically abnormal persons with normal test profiles and abnormal 5s whose test records were abnormal. Keyed responses to the K scale items tend to be statistically deviant in the parent populations. Similarly, the development of the Edwards Social Desirability Scale (SDS) illustrates this procedure. Items were drawn from various MMPI scales (F, L, K, and the Manifest Anxiety Scale [Taylor, 1953]) and submitted to judges who categorized them as either socially desirable or socially undesirable. Only items on which there was unanimous agreement among the 10 judges were included in the SDS. It seems clear that the items in Edwards SDS would, of necessity, have extreme social desirability scale positions or, in other words, be statistically deviant. Some unfortunate consequences follow from the strict use of the statistical deviance model in the development of-sOcialTtesirSbTBty scales. With items drawn from the MMPI, it is apparent that in addition to their scalability for social desirability the items may also be characterized by their content which,^n a general sense, has pathological implications. When a social desrrabtltty^scale constructed according to this procedure is then applied to a college student population, the meaning of high social desirability scores is not at all clear. When 5s given the Edwards SDS deny, for example, that their sleep is fitful and disturbed (Item 6) or that they worry quite a bit over possible misfortunes (Item 35), it cannot be determined whether these responses are attributable to social desirability or to a genuine absence of such symptoms. The probability of occurrence of the symptoms represented in MMPI items (and incorportated in the SDS)","['Social desirability', 'Psychology', 'Psychopathology', 'Scale (ratio)', 'Clinical psychology', 'Social psychology', 'Physics', 'Quantum mechanics']","personality test scores, response distortion, statistical correction, response sets, social desirability, personality test, response distortion, social desirability, social desirability continuum, social desirability, social desirability scale, social desirability properties, statistical deviance, abnormal test, clinical, normal, edwards social desirability scale, manifest anxiety scale"
Paper_01927,Composite Medium with Simultaneously Negative Permeability and Permittivity,"['David R. Smith', 'Willie J. Padilla', 'D. C. Vier', 'Sia Nemat‐Nasser', 'S. Schultz']",2000,Physical Review Letters,Journal,,4184-4187,84,18,10.1103/physrevlett.84.4184,"We demonstrate a composite medium, based on a periodic array of interspaced conducting nonmagnetic split ring resonators and continuous wires, that exhibits a frequency region in the microwave regime with simultaneously negative values of effective permeability &mgr;(eff)(omega) and permittivity varepsilon(eff)(omega). This structure forms a ""left-handed"" medium, for which it has been predicted that such phenomena as the Doppler effect, Cherenkov radiation, and even Snell's law are inverted. It is now possible through microwave experiments to test for these effects using this new metamaterial.","['Permittivity', 'Metamaterial', 'Microwave', 'Composite number', 'Permeability (electromagnetism)', 'Cherenkov radiation', 'Physics', 'Resonator', 'Split-ring resonator', 'Optics', 'Omega', 'Condensed matter physics', 'Materials science', 'Composite material', 'Optoelectronics', 'Quantum mechanics', 'Dielectric', 'Chemistry', 'Membrane', 'Detector', 'Biochemistry']","composite medium, periodic array, interspaced conducting nonmagnetic split ring resonators, continuous wires, frequency region, microwave regime, effective permeability, permittivity varepsilon, doppler effect, cherenkov radiation, microwave experiments, [PAD], [PAD], [PAD] [PAD], [PAD] [PAD], [PAD], [PAD], [PAD] [PAD], [PAD] [PAD], [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD], [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD], [PAD], [PAD], [PAD], [PAD] [PAD], [PAD], [PAD], [PAD], [PAD], [PAD] [PAD] [PAD] [PAD], [PAD] [PAD], [PAD] [PAD] [PAD] [PAD], [PAD], [PAD], [PAD], [PAD] [PAD] [PAD] [PAD], [PAD] [PAD], [PAD], [PAD], [PAD] [PAD], [PAD] [PAD] [PAD], [PAD] [PAD], [PAD], [PAD]"
Paper_01855,Large Mass Hierarchy from a Small Extra Dimension,"['Lisa Randall', 'Raman Sundrum']",1999,Physical Review Letters,Journal,,3370-3373,83,17,10.1103/physrevlett.83.3370,"We propose a new higher-dimensional mechanism for solving the hierarchy problem. The weak scale is generated from the Planck scale through an exponential hierarchy. However, this exponential arises not from gauge interactions but from the background metric (which is a slice of ${\mathrm{AdS}}_{5}$ spacetime). We demonstrate a simple explicit example of this mechanism with two 3-branes, one of which contains the standard model fields. The phenomenology of these models is new and dramatic. None of the current constraints on theories with very large extra dimensions apply.","['Hierarchy problem', 'Extra dimensions', 'Physics', 'Hierarchy', 'Theoretical physics', 'Phenomenology (philosophy)', 'Dimension (graph theory)', 'Large extra dimension', 'Spacetime', 'Simple (philosophy)', 'Planck scale', 'Exponential function', 'Statistical physics', 'Particle physics', 'Mathematics', 'Quantum mechanics', 'Quantum gravity', 'Pure mathematics', 'Supersymmetry', 'Quantum', 'Mathematical analysis', 'Epistemology', 'Philosophy', 'Economics', 'Market economy']","hierarchy problem, weak scale, planck scale, exponential hierarchy, gauge interactions, [PAD] [PAD], [PAD] [PAD], [PAD], [PAD], [PAD]"
Paper_01856,Interorganizational Collaboration and the Locus of Innovation: Networks of Learning in Biotechnology,"['Walter W. Powell', 'Kenneth W. Koput', 'Laurel Smith‐Doerr']",1996,Administrative Science Quarterly,Journal,,116-116,41,1,10.2307/2393988,"This research was supported by grants provided to the first author by the Social and Behavioral Sciences Research Institute, University of Arizona, and the Aspen Institute Nonprofit Sector Research Fund and by grants to the second author by the College of Business and Public Administration, University of Arizona. We have benefited from productive exchanges with numerous audiences to whom portions of this paper have been presented: a session at the 1994 Academy of Management meetings, the Social Organization workshop at the University of Arizona, the Work, Organizations, and Markets workshop at the Harvard Sociology Department, the 1994 SCOR Winter Conference at Stanford University, and colloquia at the business schools at the University of Alberta, UC-Berkeley, Duke, and Emory, and the JFK School at Harvard. For detailed comments on an earlier draft, we are extremely grateful to Victoria Alexander, Ashish Arora, Maryellen Kelley, Peter Marsden, Charles Kadushin, Dick Nelson, Christine Oliver, Lori Rosenkopf, Michael Sobel, Bill Starbuck, Art Stinchcombe, and anonymous reviewers at ASQ. We thank Dina Okamoto for research assistance and Linda Pike for editorial guidance. Address correspondence to Walter W. Powell, Department of Sociology, University of Arizona, Tucson, AZ 85721. We argue in this paper that when the knowledge base of an industry is both complex and expanding and the sources of expertise are widely dispersed, the locus of innovation will be found in networks of learning, rather than in individual firms. The large-scale reliance on interorganizational collaborations in the biotechnology industry reflects a fundamental and pervasive concern with access to knowledge. We develop a network approach to organizational learning and derive firm-level, longitudinal hypotheses that link research and development alliances, experience with managing interfirm relationships, network position, rates of growth, and portfolios of collaborative activities. We test these hypotheses on a sample of dedicated biotechnology firms in the years 1990-1994. Results from pooled, within-firm, time series analyses support a learning view and have broad implications for future theoretical and empirical research on organizational networks and strategic alliances.*","['Knowledge management', 'Business', 'Biotechnology', 'Biology', 'Computer science']","aspen institute nonprofit sector research fund, public administration, academy, social organization, ##al collaborations, biotechnology, organizational learning, development, network position, collaborative activities, biotechnology firms, organizational networks, strategic alliances"
Paper_01857,A social-cognitive approach to motivation and personality.,"['Carol S. Dweck', 'Ellen L. Leggett']",1988,Psychological Review,Journal,,256-273,95,2,10.1037/0033-295x.95.2.256,"Past work has documented and described major patterns of adaptive and maladaptive behavior: the mastery-oriented and the helpless patterns. In this article, we present a research-based model that accounts for these patterns in terms of underlying psychological processes. The model specifies how individuals' implicit theories orient them toward particular goals and how these goals set up the different patterns. Indeed, we show how each feature (cognitive, affective, and behavioral) of the adaptive and maladaptive patterns can be seen to follow directly from different goals. We then examine the generality of the model and use it to illuminate phenomena in a wide variety of domains. Finally, we place the model in its broadest context and examine its implications for our understanding of motivational and personality processes. The task for investigators of motivation and personality is to identify major patterns of behavior and link them to underlying psychological processes. In this article we (a) describe a research-based model that accounts for major patterns of behavior, (b) examine the generality of this model—its utility for understanding domains beyond the ones in which it was originally developed, and (c) explore the broader implications of the model for motivational and personality processes.","['Psychology', 'Personality', 'Cognitive psychology', 'Cognition', 'Social cognition', 'Social psychology', 'Neuroscience']","maladaptive behavior, helpless patterns, psychological processes, ##ptive, personality, personality, personality"
Paper_01858,"Time, clocks, and the ordering of events in a distributed system",['Leslie Lamport'],1978,Communications of the ACM,Journal,,558-565,21,7,10.1145/359545.359563,"The concept of one event happening before another in a distributed system is examined, and is shown to define a partial ordering of the events. A distributed algorithm is given for synchronizing a system of logical clocks which can be used to totally order the events. The use of the total ordering is illustrated with a method for solving synchronization problems. The algorithm is then specialized for synchronizing physical clocks, and a bound is derived on how far out of synchrony the clocks can become.","['Synchronizing', 'Computer science', 'Synchronization (alternating current)', 'Event (particle physics)', 'Distributed computing', 'Clock synchronization', 'Distributed algorithm', 'Algorithm', 'Theoretical computer science', 'Real-time computing', 'Computer network', 'Physics', 'Telecommunications', 'Channel (broadcasting)', 'Quantum mechanics', 'Transmission (telecommunications)']","distributed system, partial ordering, distributed algorithm, logical clocks, total ordering, synchronization problems, physical clocks, [PAD] [PAD], [PAD], [PAD] [PAD], [PAD], [PAD] [PAD], [PAD]"
Paper_01861,"Physical activity, exercise, and physical fitness: definitions and distinctions for health-related research.","['Carl J. Caspersen', 'K E Powell', 'Gregory M. Christenson']",1985,['Academic Sports Scholar'],Unknown,,1-5,II,III,10.9780/2277-3665/1112013/37,"""Physical activity,"" ""exercise,"" and ""physical fitness"" are terms that describe different concepts. However, they are often confused with one another, and the terms are sometimes used interchangeably. This paper proposes definitions to distinguish them. Physical activity is defined as any bodily movement produced by skeletal muscles that results in energy expenditure. The energy expenditure can be measured in kilocalories. Physical activity in daily life can be categorized into occupational, sports, conditioning, household, or other activities. Exercise is a subset of physical activity that is planned, structured, and repetitive and has as a final or an intermediate objective the improvement or maintenance of physical fitness. Physical fitness is a set of attributes that are either health- or skill-related. The degree to which people have these attributes can be measured with specific tests. These definitions are offered as an interpretational framework for comparing studies that relate physical activity, exercise, and physical fitness to health.","['Physical fitness', 'Physical activity', 'Set (abstract data type)', 'Energy expenditure', 'Psychology', 'Gerontology', 'Physical exercise', 'Calorie', 'Applied psychology', 'Physical therapy', 'Medicine', 'Computer science', 'Endocrinology', 'Programming language']","physical activity, physical fitness, physical activity, bodily movement, skeletal muscles, energy expenditure, daily life, physical fitness, physical fitness"
Paper_01862,Large Shareholders and Corporate Control,"['Andrei Shleifer', 'Robert W. Vishny']",1986,Journal of Political Economy,Journal,,461-488,94,"3, Part 1",10.1086/261385,"In a corporation with many small owners, it may not pay any one of them to monitor the performance of the management. We explore a model in which the presence of a large minority shareholder provides a partial solution to this free-rider problem. The model sheds light on the following questions: Under what circumstances will we observe a tender offer as opposed to a proxy fight or an internal management shake-up? How strong are the forces pushing toward increasing concentration of ownership of a diffusely held firm? Why do corporate and personal investors commonly hold stock in the same firm, despite their disparate tax preferences?","['Shareholder', 'Tender offer', 'Corporation', 'Business', 'Corporate governance', 'Proxy (statistics)', 'Stock (firearms)', 'Control (management)', 'Dividend', 'Corporate action', 'Accounting', 'Economics', 'Finance', 'Management', 'Mechanical engineering', 'Machine learning', 'Computer science', 'Engineering']","tender offer, proxy fight, internal management, personal investors, tax"
Paper_01863,A review of electrode materials for electrochemical supercapacitors,"['Guoping Wang', 'Lei Zhang', 'Jiujun Zhang']",2011,Chemical Society Reviews,Journal,,797-828,41,2,10.1039/c1cs15060j,"In this critical review, metal oxides-based materials for electrochemical supercapacitor (ES) electrodes are reviewed in detail together with a brief review of carbon materials and conducting polymers. Their advantages, disadvantages, and performance in ES electrodes are discussed through extensive analysis of the literature, and new trends in material development are also reviewed. Two important future research directions are indicated and summarized, based on results published in the literature: the development of composite and nanostructured ES materials to overcome the major challenge posed by the low energy density of ES (476 references).","['Supercapacitor', 'Nanotechnology', 'Electrochemistry', 'Materials science', 'Electrode', 'Energy density', 'Engineering physics', 'Engineering', 'Chemistry', 'Physical chemistry']","electrochemical supercapacitor, carbon materials, conducting polymers, es, material development, composite, nanostructured es materials, low energy density, [PAD], [PAD], [PAD] [PAD] [PAD]"
Paper_01864,Testing Structural Equation Models.,"['Clifford C. Clogg', 'Kenneth A. Bollen', 'J. Scott Long']",1995,Social Forces,Journal,,1161-1161,73,3,10.2307/2580595,Introduction - Kenneth A Bollen and J Scott Long Multifaceted Conceptions of Fit in Structural Equation Models - J S Tanaka Monte Carlo Evaluations of Goodness-of-Fit Indices for Structural Equation Models - David W Gerbing and James C Anderson Some Specification Tests for the Linear Regression Model - J Scott Long and Pravin K Trivedi Bootstrapping Goodness-of-Fit Measures in Structural Equation Models - Kenneth A Bollen and Robert A Stine Alternative Ways of Assessing Model Fit - Michael W Browne and Robert Cudeck Bayesian Model Selection in Structural Equation Models - Adrian E Raftery Power Evaluations in Structural Equation Models - Willem E Saris and Albert Satorra Goodness-of-Fit with Categorical and Other Nonnormal Variables - Bengt O Muthen Some New Covariance Structure Model Improvement Statistics - P M Bentler and Chih-Ping Chou Nonpositive Definite Matrices in Structural Modeling - Werner Wothke Testing Structural Equation Models - Karl G Joreskog,"['Structural equation modeling', 'Goodness of fit', 'Bootstrapping (finance)', 'Categorical variable', 'Econometrics', 'Covariance', 'Mathematics', 'Model selection', 'Bayesian probability', 'Statistics']","fit, structural equation models, structural equation models, linear regression model, structural equation models, structural equation models, structural equation models, nonnormal variables, covariance structure model improvement statistics, ##ive definite matrices, structural modeling, structural equation models"
Paper_01865,Thematic Analysis,"['Lorelli Nowell', 'Jill M. Norris', 'Deborah White', 'Nancy J. Moules']",2017,International Journal of Qualitative Methods,Journal,,,16,1,10.1177/1609406917733847,"As qualitative research becomes increasingly recognized and valued, it is imperative that it is conducted in a rigorous and methodical manner to yield meaningful and useful results. To be accepted as trustworthy, qualitative researchers must demonstrate that data analysis has been conducted in a precise, consistent, and exhaustive manner through recording, systematizing, and disclosing the methods of analysis with enough detail to enable the reader to determine whether the process is credible. Although there are numerous examples of how to conduct qualitative research, few sophisticated tools are available to researchers for conducting a rigorous and relevant thematic analysis. The purpose of this article is to guide researchers using thematic analysis as a research method. We offer personal insights and practical examples, while exploring issues of rigor and trustworthiness. The process of conducting a thematic analysis is illustrated through the presentation of an auditable decision trail, guiding interpreting and representing textual data. We detail our step-by-step approach to exploring the effectiveness of strategic clinical networks in Alberta, Canada, in our mixed methods case study. This article contributes a purposeful approach to thematic analysis in order to systematize and increase the traceability and verification of the analysis.","['Thematic analysis', 'Computer science', 'Traceability', 'Thematic map', 'Process (computing)', 'Data science', 'Presentation (obstetrics)', 'Management science', 'Qualitative research', 'Trustworthiness', 'Qualitative analysis', 'Process management', 'Sociology', 'Engineering', 'Software engineering', 'Medicine', 'Social science', 'Cartography', 'Computer security', 'Radiology', 'Geography', 'Operating system']","qualitative research, qu, ##tative, data analysis, thematic analysis, trustworthiness, auditable decision trail, textual data, strategic clinical networks, mixed methods, thematic analysis"
Paper_01866,Quantal phase factors accompanying adiabatic changes,['Michael Berry'],1984,Proceedings of the Royal Society of London A Mathematical and Physical Sciences,Journal,,45-57,392,1802,10.1098/rspa.1984.0023,"A quantal system in an eigenstate, slowly transported round a circuit C by varying parameters R in its Hamiltonian Ĥ(R), will acquire a geometrical phase factor exp{iγ(C)} in addition to the familiar dynamical phase factor. An explicit general formula for γ(C) is derived in terms of the spectrum and eigenstates of Ĥ(R) over a surface spanning C. If C lies near a degeneracy of Ĥ, γ(C) takes a simple form which includes as a special case the sign change of eigenfunctions of real symmetric matrices round a degeneracy. As an illustration γ(C) is calculated for spinning particles in slowly-changing magnetic fields; although the sign reversal of spinors on rotation is a special case, the effect is predicted to occur for bosons as well as fermions, and a method for observing it is proposed. It is shown that the Aharonov-Bohm effect can be interpreted as a geometrical phase factor.","['Eigenfunction', 'Physics', 'Eigenvalues and eigenvectors', 'Boson', 'Hamiltonian (control theory)', 'Degeneracy (biology)', 'Geometric phase', 'Fermion', 'Adiabatic process', 'Spinor', 'Sign (mathematics)', 'Quantum mechanics', 'Phase (matter)', 'Mathematical physics', 'Mathematics', 'Mathematical analysis', 'Mathematical optimization', 'Bioinformatics', 'Biology']","quantal system, geometrical phase factor, dynamical phase factor, sign change, real symmetric matrices, sign reversal, spin, geometrical phase factor"
Paper_01868,"Inflammation, Atherosclerosis, and Coronary Artery Disease",['Göran K. Hansson'],2005,New England Journal of Medicine,Journal,,1685-1695,352,16,10.1056/nejmra043430,"In this review article, Göran Hansson, a pioneer in the study of the role of inflammation in atherosclerosis and coronary artery disease, summarizes new ideas on the pathogenesis of acute coronary syndromes.","['Medicine', 'Coronary artery disease', 'Pathogenesis', 'Inflammation', 'Coronary atherosclerosis', 'Cardiology', 'Disease', 'Internal medicine', 'Artery', 'Vascular disease']","inflammation, atheros, coronary artery disease, acute coronary syndromes, [PAD], [PAD], [PAD], [PAD] [PAD] [PAD] [PAD], [PAD], [PAD] [PAD], [PAD] [PAD], [PAD] [PAD], [PAD] [PAD], [PAD] [PAD], [PAD] [PAD], [PAD] [PAD] [PAD], [PAD], [PAD] [PAD]"
Paper_01869,Methods of Mathematical Physics,"['R. Courant', 'David Hilbert']",1989,Unknown,Unknown,,,,,10.1002/9783527617210,Partial table of contents: THE ALGEBRA OF LINEAR TRANSFORMATIONS AND QUADRATIC FORMS. Transformation to Principal Axes of Quadratic and Hermitian Forms. Minimum-Maximum Property of Eigenvalues. SERIES EXPANSION OF ARBITRARY FUNCTIONS. Orthogonal Systems of Functions. Measure of Independence and Dimension Number. Fourier Series. Legendre Polynomials. LINEAR INTEGRAL EQUATIONS. The Expansion Theorem and Its Applications. Neumann Series and the Reciprocal Kernel. The Fredholm Formulas. THE CALCULUS OF VARIATIONS. Direct Solutions. The Euler Equations. VIBRATION AND EIGENVALUE PROBLEMS. Systems of a Finite Number of Degrees of Freedom. The Vibrating String. The Vibrating Membrane. Green's Function (Influence Function) and Reduction of Differential Equations to Integral Equations. APPLICATION OF THE CALCULUS OF VARIATIONS TO EIGENVALUE PROBLEMS. Completeness and Expansion Theorems. Nodes of Eigenfunctions. SPECIAL FUNCTIONS DEFINED BY EIGENVALUE PROBLEMS. Bessel Functions. Asymptotic Expansions. Additional Bibliography. Index.,"['Physics', 'Theoretical physics', 'Statistical physics', 'Classical mechanics']","linear transformations, quadratic forms, principal axes, hermitian forms, eigen, ##ues, series expansion, arbitrary functions, orthogonal systems of functions, measure of independence, dimension number, fourier series, legendre polynomials, linear integral equations, expansion theorem, neumann series, reciprocal kernel, fredholm formulas, calculus of variations, direct, euler equations, ##igenvalue problems, vibrating string, vibrating membrane, influence function, integral equations, eigenvalue problems, completeness, expansion theorems, ##ue problems, bessel functions, asymptotic expansions"
Paper_01871,MUSCLE: a multiple sequence alignment method with reduced time and space complexity,['R. C. Edgar'],2004,BMC Bioinformatics,Journal,,,5,1,10.1186/1471-2105-5-113,"Abstract Background In a previous paper, we introduced MUSCLE, a new program for creating multiple alignments of protein sequences, giving a brief summary of the algorithm and showing MUSCLE to achieve the highest scores reported to date on four alignment accuracy benchmarks. Here we present a more complete discussion of the algorithm, describing several previously unpublished techniques that improve biological accuracy and / or computational complexity. We introduce a new option, MUSCLE-fast, designed for high-throughput applications. We also describe a new protocol for evaluating objective functions that align two profiles. Results We compare the speed and accuracy of MUSCLE with CLUSTALW, Progressive POA and the MAFFT script FFTNS1, the fastest previously published program known to the author. Accuracy is measured using four benchmarks: BAliBASE, PREFAB, SABmark and SMART. We test three variants that offer highest accuracy (MUSCLE with default settings), highest speed (MUSCLE-fast), and a carefully chosen compromise between the two (MUSCLE-prog). We find MUSCLE-fast to be the fastest algorithm on all test sets, achieving average alignment accuracy similar to CLUSTALW in times that are typically two to three orders of magnitude less. MUSCLE-fast is able to align 1,000 sequences of average length 282 in 21 seconds on a current desktop computer. Conclusions MUSCLE offers a range of options that provide improved speed and / or alignment accuracy compared with currently available programs. MUSCLE is freely available at http://www.drive5.com/muscle .","['Sequence (biology)', 'Computational biology', 'Sequence alignment', 'Computer science', 'Multiple sequence alignment', 'Alignment-free sequence analysis', 'Space (punctuation)', 'DNA microarray', 'Biology', 'Bioinformatics', 'Genetics', 'Peptide sequence', 'Gene', 'Gene expression', 'Operating system']","muscle, protein sequences, alignment accuracy, biological accuracy, computational complexity, objective functions, clustalw, progressive poa, mafft script fftns, balibase, prefab, sabmark, smart, default, ##w, muscle, muscle"
Paper_01872,Teaching to transgress: education as the practice of freedom,['bell hooks'],1995,Choice Reviews Online,Journal,,32-4628,32,08,10.5860/choice.32-4628,"Introduction: Teaching to Transgress 1. Engaged Pedagogy 2. A Revolution of Values: The Promise of Multicultural Change 3. Embracing Change: Teaching in a Multicultural World 4. Paulo Freire 5. Theory as Liberatory Practice 6. Essentialism and Experience 7. Holding My Sister's Hand: Feminist Solidarity 8. Feminist Thinking: In the Classroom Right Now 9. Feminist Scholarship: Black Scholars 10. Building a Teaching Community: A Dialogue 11. Language: Teaching New Worlds / New Words 12. Confronting Class in the Classroom 13. Eros, Eroticism, and the Pedgagogical Process 14. Ecstasy: Teaching and Learning Without Limits","['Sociology', 'Aesthetics', 'Epistemology', 'Philosophy']","engaged pedagogy, multicultural change, multicultural world, essentialism, feminist solidarity, feminist thinking, feminist scholarship, black scholars, teaching community, eros, eroticism, pedgagogical process, ecstasy, [PAD], [PAD], [PAD], [PAD], [PAD]"
Paper_01874,THE UBIQUITIN SYSTEM,"['Avram Hershko', 'Aaron Ciechanover']",1998,Annual Review of Biochemistry,Journal,,425-479,67,1,10.1146/annurev.biochem.67.1.425,"The selective degradation of many short-lived proteins in eukaryotic cells is carried out by the ubiquitin system. In this pathway, proteins are targeted for degradation by covalent ligation to ubiquitin, a highly conserved small protein. Ubiquitin-mediated degradation of regulatory proteins plays important roles in the control of numerous processes, including cell-cycle progression, signal transduction, transcriptional regulation, receptor down-regulation, and endocytosis. The ubiquitin system has been implicated in the immune response, development, and programmed cell death. Abnormalities in ubiquitin-mediated processes have been shown to cause pathological conditions, including malignant transformation. In this review we discuss recent information on functions and mechanisms of the ubiquitin system. Since the selectivity of protein degradation is determined mainly at the stage of ligation to ubiquitin, special attention is focused on what we know, and would like to know, about the mode of action of ubiquitin-protein ligation systems and about signals in proteins recognized by these systems.","['Ubiquitin', 'Cell biology', 'Ubiquitin ligase', 'Ubiquitin-conjugating enzyme', 'Ubiquitin-Protein Ligases', 'Deubiquitinating enzyme', 'Biology', 'Signal transduction', 'Protein degradation', 'F-box protein', 'Endocytosis', 'Receptor', 'Chemistry', 'Biochemistry', 'Gene']","selective degradation, eukaryotic cells, ubiquitin system, covalent ligation, ##biquitin, signal transduction, ##al regulation, endocyt, programmed cell death, malignant transformation, ubiquitin"
Paper_01876,"Consumer Perceptions of Price, Quality, and Value: A Means-End Model and Synthesis of Evidence",['Valarie A. Zeithaml'],1988,Journal of Marketing,Journal,,2-22,52,3,10.1177/002224298805200302,"Evidence from past research and insights from an exploratory investigation are combined in a conceptual model that defines and relates price, perceived quality, and perceived value. Propositions about the concepts and their relationships are presented, then supported with evidence from the literature. Discussion centers on directions for research and implications for managing price, quality, and value.","['Value (mathematics)', 'Quality (philosophy)', 'Perception', 'Marketing', 'Exploratory research', 'Conceptual model', 'Business', 'Economics', 'Psychology', 'Sociology', 'Computer science', 'Epistemology', 'Philosophy', 'Database', 'Neuroscience', 'Machine learning', 'Anthropology']","price, perceived quality, perceived value, price, value, [PAD], [PAD] [PAD]"
Paper_01877,Moral Hazard and Observability,['Bengt Holmström'],1979,The Bell Journal of Economics,Journal,,74-74,10,1,10.2307/3003320,"The role of imperfect information in a principal-agent relationship subject to moral hazard is considered. A necessary and sufficient condition for imperfect information to improve on contracts based on the payoff alone is derived, and a characterization of the optimal use of such information is given.","['Observability', 'Moral hazard', 'Economics', 'Mathematical economics', 'Microeconomics', 'Mathematics', 'Applied mathematics', 'Incentive']","imperfect information, moral hazard, imperfect information, payoff, [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD] [PAD], [PAD] [PAD], [PAD], [PAD] [PAD], [PAD], [PAD], [PAD], [PAD], [PAD] [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD] [PAD], [PAD], [PAD] [PAD]"
Paper_01878,"Epidemiology of severe sepsis in the United States: Analysis of incidence, outcome, and associated costs of care","['Derek C. Angus', 'Walter T. Linde‐Zwirble', 'Jeffrey Lidicker', 'Gilles Clermont', 'Joseph A. Carcillo', 'Michael R. Pinsky']",2001,Critical Care Medicine,Journal,,1303-1310,29,7,10.1097/00003246-200107000-00002,"Objective To determine the incidence, cost, and outcome of severe sepsis in the United States. Design Observational cohort study. Setting All nonfederal hospitals (n = 847) in seven U.S. states. Patients All patients (n = 192,980) meeting criteria for severe sepsis based on the International Classification of Diseases, Ninth Revision, Clinical Modification. Interventions None. Measurements and Main Results We linked all 1995 state hospital discharge records (n = 6,621,559) from seven large states with population and hospital data from the U.S. Census, the Centers for Disease Control, the Health Care Financing Administration, and the American Hospital Association. We defined severe sepsis as documented infection and acute organ dysfunction using criteria based on the International Classification of Diseases, Ninth Revision, Clinical Modification. We validated these criteria against prospective clinical and physiologic criteria in a subset of five hospitals. We generated national age- and gender-adjusted estimates of incidence, cost, and outcome. We identified 192,980 cases, yielding national estimates of 751,000 cases (3.0 cases per 1,000 population and 2.26 cases per 100 hospital discharges), of whom 383,000 (51.1%) received intensive care and an additional 130,000 (17.3%) were ventilated in an intermediate care unit or cared for in a coronary care unit. Incidence increased >100-fold with age (0.2/1,000 in children to 26.2/1,000 in those >85 yrs old). Mortality was 28.6%, or 215,000 deaths nationally, and also increased with age, from 10% in children to 38.4% in those >85 yrs old. Women had lower age-specific incidence and mortality, but the difference in mortality was explained by differences in underlying disease and the site of infection. The average costs per case were $22,100, with annual total costs of $16.7 billion nationally. Costs were higher in infants, nonsurvivors, intensive care unit patients, surgical patients, and patients with more organ failure. The incidence was projected to increase by 1.5% per annum. Conclusions Severe sepsis is a common, expensive, and frequently fatal condition, with as many deaths annually as those from acute myocardial infarction. It is especially common in the elderly and is likely to increase substantially as the U.S. population ages.","['Medicine', 'Incidence (geometry)', 'Epidemiology', 'Population', 'Intensive care unit', 'Sepsis', 'Pediatrics', 'Observational study', 'Intensive care', 'Emergency medicine', 'Cohort', 'Cohort study', 'Acute care', 'Health care', 'Intensive care medicine', 'Internal medicine', 'Environmental health', 'Physics', 'Optics', 'Economics', 'Economic growth']","severe sepsis, observational cohort study, nonfederal hospitals, severe sepsis, international classification, state hospital discharge, health care financing administration, american hospital association, severe sepsis, acute organ dysfunction, international classification, clinical, nonsurvivors, intensive care unit, surgical patients, severe sepsis, acute myocardial infarction"
Paper_01881,Cancer: Principles and Practice of Oncology.,"['Vincent T. DeVita', 'Samuel Hellmän', 'Steven A. Rosenberg']",1991,Annals of Internal Medicine,Journal,,819-819,114,9,10.7326/0003-4819-114-9-819_4,"Part I: Molecular Biology of Cancer Molecular Methods in Oncology Section 1. Amplification Techniques Section 2. RNA Interference Section 3. cDNA arrays Section 4. Tissue arrays Section 5. Cytogenetics Section 6. Bioinformatics Genomics and Proteomics Molecular Targets in Oncology Section 1. Signal transduction systems Section 2. Cell cycle Section 3. Apoptosis Section 4. Telomerase Invasion and Metastases Angiogenesis Cancer Immunology Part II: Principles of Oncology Etiology of Cancer: Viruses Section 1. RNA Viruses Section 2. DNA Viruses Etiology of Cancer: Chemical Factors Etiology of Cancer: Tobacco Etiology of Cancer: Physical Factors Epidemiology of Cancer Section 1. Epidemiologic Methods Section 2. Cancer Statistics Principles of Surgical Oncology Section 1. General Issues Section 2. Laparascopic Surgery Principles of Radiation Oncology Principles of Medical Oncology Pharmacology of Cancer Chemotherapy Section 2. Pharmocokinetics Section 3. Pharmacogenomics Section 4. Alkylating Agents Section 5. Cisplatin and its Analogues Section 6. Antimetabolites Section 7. Topoisomerase Interactive Agents Section 8. Antimicrotubule Agents Section 9. Miscellaneous Chemotherapeutic Agents Pharmacology of Cancer Biotherapeutics Section 1. Interferon Section 2. Interleukin 2 Section 3. Histone deacetylase inhibitors as differentiation agents Section 4. Monoclonal Antibodies Pharmacology of Endocrine Manipulation Design and Analysis of Clinical Trials Part III: Practice of Oncology Cancer Prevention: Preventing Tobacco-Related Cancers Cancer Prevention: Diet and Chemopreventive Agents Section 1. Dietary fat Section 2. Dietary Fiber Section 3. Dietary fruits and vegetables: naturally occurring anticarcinogens Section 4. Retinoids, carotenoids and micronutrients Section 5. Dietary Carcinogens Section 6. Cyclo-oxygenase inhibitors Section 7. Physical Activity and Body Weight Cancer Prevention: Role of Surgery in Cancer Prevention Cancer Screening Advanced Molecular Diagnostics Advanced Imaging Methods Section 1. Functional and Metabolic Imaging Section 2. Interventional Radiology Cancer Diagnosis: Endoscopy Section 1. Gastrointestinal endoscopy Section 2. Respiratory Tract Cancer of the Head and Neck Section 1. Molecular Biology of Head and Neck Tumors Section 2. Treatment of Head and Neck Cancers Section 3. Rehabilitation after Treatment for Head Cancer of the Lung Section 1. Molecular Biology of Lung Cancer Section 2. Non-small Cell Lung Cancer Section 3. Small Cell Lung Cancer Neoplasms of the Mediastinum Cancers of the Gastrointestinal Tract","['Medicine', 'Clinical Oncology', 'Cancer', 'Internal medicine', 'Oncology', 'Intensive care medicine', 'Medical physics']","molecular biology, cancer, oncology, amplification techniques, rna interference, cdna arrays, tissue arrays, cytogenetic, bioinformatics, proteomics, on, signal transduction systems, cell cycle, apoptosis, tel, ##rase invasion, rna viruses, dna, tobacco etiology, epidemi, ##gic methods, cancer statistics, surgical oncology, laparascopic surgery, radiation on, medical on, cancer, pharmocokinetics, pharmacogenomics, alkylating agents, cis, anti, ##olites, topoisome, ##microt, interferon, ##leuki, ##tone deace, monoclonal antibodies, endocrine, clinical, on, ##vent, dietary fat, dietary fiber, ##nutrien, dietary carcinogens, body weight cancer prevention, cancer, gastrointestinal end, respiratory tract cancer, molecular, head cancer"
Paper_01882,SEVEN-YEAR<i>WILKINSON MICROWAVE ANISOTROPY PROBE</i>(<i>WMAP</i>) OBSERVATIONS: COSMOLOGICAL INTERPRETATION,"['Eiichiro Komatsu', 'Kendrick M. Smith', 'J. Dunkley', 'C. L. Bennett', 'B. Gold', 'G. Hinshaw', 'N. Jarosik', 'D. Larson', 'M. R. Nolta', 'Lyman A. Page', 'David N. Spergel', 'M. Halpern', 'Ryley Hill', 'A. Kogut', 'M. Limon', 'S. S. Meyer', 'N. Odegard', 'Gregory S. Tucker', 'J. L. Weiland', 'Edward J. Wollack', 'E. L. Wright']",2011,The Astrophysical Journal Supplement Series,Journal,,18-18,192,2,10.1088/0067-0049/192/2/18,"SEVEN-YEAR WILKINSON MICROWAVE ANISOTROPY PROBE (WMAP*) OBSERVATIONS: COSMOLOGICAL INTERPRETATION, E. Komatsu, K. M. Smith, J. Dunkley, C. L. Bennett, B. Gold, G. Hinshaw, N. Jarosik, D. Larson, M. R. Nolta, L. Page, D. N. Spergel, M. Halpern, R. S. Hill, A. Kogut, M. Limon, S. S. Meyer, N. Odegard, G. S. Tucker, J. L. Weiland, E. Wollack, E. L. Wright","['CMB cold spot', 'Physics', 'Cosmic microwave background', 'Astrophysics', 'Neutrino', 'Cosmic background radiation', 'Spectral density', 'Spectral index', ""Hubble's law"", 'Observational cosmology', 'Anisotropy', 'Galaxy', 'Particle physics', 'Spectral line', 'Redshift', 'Astronomy', 'Quantum mechanics', 'Statistics', 'Mathematics']","wilkinson microwave anisotropy probe, cosmological interpretation, [PAD] [PAD] [PAD] [PAD], [PAD] [PAD]"
Paper_01883,Apixaban versus Warfarin in Patients with Atrial Fibrillation,"['Christopher B. Granger', 'John H. Alexander', 'John J.V. McMurray', 'Renato D. Lópes', 'Elaine M. Hylek', 'Michael G. Hanna', 'Hussein R. Al‐Khalidi', 'Jack Ansell', 'Dan Atar', 'Álvaro Avezum', 'M. Cecilia Bahit', 'Rafael Díaz', 'J. Donald Easton', 'Justin A. Ezekowitz', 'Greg Flaker', 'David García', 'Margarida Geraldes', 'Bernard J. Gersh', 'Golitsyn Sp', 'Shinya Goto', 'Antonio G. Hermosillo', 'Stefan H. Hohnloser', 'John D. Horowitz', 'Puneet Mohan', 'Petr Janský', 'Basil S. Lewis', 'José López‐Sendón', 'Prem Pais', 'Alexander Parkhomenko', 'Freek W.A. Verheugt', 'Jun Zhu', 'Lars Wallentin']",2011,New England Journal of Medicine,Journal,,981-992,365,11,10.1056/nejmoa1107039,"Vitamin K antagonists are highly effective in preventing stroke in patients with atrial fibrillation but have several limitations. Apixaban is a novel oral direct factor Xa inhibitor that has been shown to reduce the risk of stroke in a similar population in comparison with aspirin.In this randomized, double-blind trial, we compared apixaban (at a dose of 5 mg twice daily) with warfarin (target international normalized ratio, 2.0 to 3.0) in 18,201 patients with atrial fibrillation and at least one additional risk factor for stroke. The primary outcome was ischemic or hemorrhagic stroke or systemic embolism. The trial was designed to test for noninferiority, with key secondary objectives of testing for superiority with respect to the primary outcome and to the rates of major bleeding and death from any cause.The median duration of follow-up was 1.8 years. The rate of the primary outcome was 1.27% per year in the apixaban group, as compared with 1.60% per year in the warfarin group (hazard ratio with apixaban, 0.79; 95% confidence interval [CI], 0.66 to 0.95; P<0.001 for noninferiority; P=0.01 for superiority). The rate of major bleeding was 2.13% per year in the apixaban group, as compared with 3.09% per year in the warfarin group (hazard ratio, 0.69; 95% CI, 0.60 to 0.80; P<0.001), and the rates of death from any cause were 3.52% and 3.94%, respectively (hazard ratio, 0.89; 95% CI, 0.80 to 0.99; P=0.047). The rate of hemorrhagic stroke was 0.24% per year in the apixaban group, as compared with 0.47% per year in the warfarin group (hazard ratio, 0.51; 95% CI, 0.35 to 0.75; P<0.001), and the rate of ischemic or uncertain type of stroke was 0.97% per year in the apixaban group and 1.05% per year in the warfarin group (hazard ratio, 0.92; 95% CI, 0.74 to 1.13; P=0.42).In patients with atrial fibrillation, apixaban was superior to warfarin in preventing stroke or systemic embolism, caused less bleeding, and resulted in lower mortality. (Funded by Bristol-Myers Squibb and Pfizer; ARISTOTLE ClinicalTrials.gov number, NCT00412984.).","['Apixaban', 'Medicine', 'Atrial fibrillation', 'Warfarin', 'Aspirin', 'Stroke (engine)', 'Internal medicine', 'Cardiology', 'Rivaroxaban', 'Population', 'Mechanical engineering', 'Engineering', 'Environmental health']","vitamin k antagonist, atrial fibrillation, apixaban, ##rin, apixa, atrial fibrillation, ##agi, systemic embolism, ##fer, ##ity, ##ban, ##orrhagic"
Paper_01884,Focus Groups as Qualitative Research,['David Morgan'],1997,Unknown,Unknown,,,,,10.4135/9781412984287,Introduction Focus Groups as Qualitative Method The Uses of Focus Groups Planning and Research Design for Focus Groups Conducting and Analyzing Focus Groups Additional Possibilities Conclusions,"['Focus group', 'Focus (optics)', 'Qualitative research', 'Psychology', 'Sociology', 'Social science', 'Anthropology', 'Physics', 'Optics']","focus groups, qualitative method, focus groups, research design, focus groups, focus groups, [PAD], [PAD], [PAD], [PAD] [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD]"
Paper_01885,Posterior Summarization in Bayesian Phylogenetics Using Tracer 1.7,"['Andrew Rambaut', 'Alexei J. Drummond', 'Dong Xie', 'Guy Baele', 'Marc A. Suchard']",2018,Systematic Biology,Journal,,901-904,67,5,10.1093/sysbio/syy032,"Bayesian inference of phylogeny using Markov chain Monte Carlo (MCMC) plays a central role in understanding evolutionary history from molecular sequence data. Visualizing and analyzing the MCMC-generated samples from the posterior distribution is a key step in any non-trivial Bayesian inference. We present the software package Tracer (version 1.7) for visualizing and analyzing the MCMC trace files generated through Bayesian phylogenetic inference. Tracer provides kernel density estimation, multivariate visualization, demographic trajectory reconstruction, conditional posterior distribution summary, and more. Tracer is open-source and available at http://beast.community/tracer.","['Markov chain Monte Carlo', 'Posterior probability', 'Bayesian probability', 'Bayesian inference', 'Computer science', 'Inference', 'Artificial intelligence', 'Biology']","bayesian inference, phylogen, markov chain monte carlo, mc, evolutionary history, molecular sequence data, posterior distribution, bayesian, tracer, bayesian phylogenetic inference, tracer, kernel density estimation, multivariate visualization, demographic trajectory reconstruction, conditional posterior distribution summary, ##r, [PAD], [PAD], [PAD] [PAD], [PAD] [PAD], [PAD], [PAD], [PAD], [PAD]"
Paper_01886,YOLOv4: Optimal Speed and Accuracy of Object Detection,"['Alexey Bochkovskiy', 'Chien-Yao Wang', 'Hong-Yuan Mark Liao']",2020,arXiv (Cornell University),Unknown,,,,,10.48550/arxiv.2004.10934,"There are a huge number of features which are said to improve Convolutional Neural Network (CNN) accuracy. Practical testing of combinations of such features on large datasets, and theoretical justification of the result, is required. Some features operate on certain models exclusively and for certain problems exclusively, or only for small-scale datasets; while some features, such as batch-normalization and residual-connections, are applicable to the majority of models, tasks, and datasets. We assume that such universal features include Weighted-Residual-Connections (WRC), Cross-Stage-Partial-connections (CSP), Cross mini-Batch Normalization (CmBN), Self-adversarial-training (SAT) and Mish-activation. We use new features: WRC, CSP, CmBN, SAT, Mish activation, Mosaic data augmentation, CmBN, DropBlock regularization, and CIoU loss, and combine some of them to achieve state-of-the-art results: 43.5% AP (65.7% AP50) for the MS COCO dataset at a realtime speed of ~65 FPS on Tesla V100. Source code is at https://github.com/AlexeyAB/darknet","['Object (grammar)', 'Computer science', 'Artificial intelligence', 'Computer vision']","convolutional neural network, cnn, wrc, csp, cmbn, sat, mish activation, mosaic data augmentation, cmbn, dropblock regularization, ciou loss, ms coco"
Paper_01887,Twelve years of SAMtools and BCFtools,"['Petr Danecek', 'James Bonfield', 'Jennifer Liddle', 'John Marshall', 'Valeriu Ohan', 'Martin Pollard', 'Andrew Whitwham', 'Thomas Keane', 'Shane McCarthy', 'Robert M. Davies', 'Heng Li']",2021,GigaScience,Journal,,,10,2,10.1093/gigascience/giab008,"Abstract Background SAMtools and BCFtools are widely used programs for processing and analysing high-throughput sequencing data. They include tools for file format conversion and manipulation, sorting, querying, statistics, variant calling, and effect analysis amongst other methods. Findings The first version appeared online 12 years ago and has been maintained and further developed ever since, with many new features and improvements added over the years. The SAMtools and BCFtools packages represent a unique collection of tools that have been used in numerous other software projects and countless genomic pipelines. Conclusion Both SAMtools and BCFtools are freely available on GitHub under the permissive MIT licence, free for both non-commercial and commercial use. Both packages have been installed &amp;gt;1 million times via Bioconda. The source code and documentation are available from https://www.htslib.org.","['Documentation', 'Computer science', 'Software', 'Sorting', 'File format', 'World Wide Web', 'Data science', 'Database', 'Programming language']","abstract background samtools, bcftools, file format conversion, sorting, querying, statistics, variant calling, effect analysis, samtools, bcftools, genomic pipeline, samtools, bcftools, github, bioconda"
Paper_01888,"WAF1, a potential mediator of p53 tumor suppression","['Wafik S. El‐Deiry', 'Takashi Tokino', 'Victor E. Velculescu', 'Daniel B. Levy', 'Ramon Parsons', 'J.M. Trent', 'David Pei‐Cheng Lin', 'W E Mercer', 'K W Kinzler', 'Bert Vogelstein']",1993,Cell,Journal,,817-825,75,4,10.1016/0092-8674(93)90500-p,"The ability of p53 to activate transcription from specific sequences suggests that genes induced by p53 may mediate its biological role as a tumor suppressor. Using a subtractive hybridization approach, we identified a gene, named WAF1, whose induction was associated with wild-type but not mutant p53 gene expression in a human brain tumor cell line. The WAF1 gene was localized to chromosome 6p21.2, and its sequence, structure, and activation by p53 was conserved in rodents. Introduction of WAF1 cDNA suppressed the growth of human brain, lung, and colon tumor cells in culture. Using a yeast enhancer trap, a p53-binding site was identified 2.4 kb upstream of WAF1 coding sequences. The WAF1 promoter, including this p53-binding site, conferred p53-dependent inducibility upon a heterologous reporter gene. These studies define a gene whose expression is directly induced by p53 and that could be an important mediator of p53-dependent tumor growth suppression.","['Biology', 'Enhancer', 'Gene', 'Tumor suppressor gene', 'Suppression subtractive hybridization', 'Molecular biology', 'Reporter gene', 'Mutant', 'Complementary DNA', 'Gene expression', 'cDNA library', 'Cancer research', 'Genetics', 'Carcinogenesis']","p53, tumor suppressor, subtractive hybridization, waf, human, waf, waf, colon tumor cells, yeast enhancer trap, wa"
Paper_01889,Global patterns of 16S rRNA diversity at a depth of millions of sequences per sample,"['J. Gregory Caporaso', 'Christian L. Lauber', 'William A. Walters', 'Donna Berg-Lyons', 'Catherine Lozupone', 'Peter J. Turnbaugh', 'Noah Fierer', 'Rob Knight']",2010,Proceedings of the National Academy of Sciences,Journal,,4516-4522,108,supplement_1,10.1073/pnas.1000080107,"The ongoing revolution in high-throughput sequencing continues to democratize the ability of small groups of investigators to map the microbial component of the biosphere. In particular, the coevolution of new sequencing platforms and new software tools allows data acquisition and analysis on an unprecedented scale. Here we report the next stage in this coevolutionary arms race, using the Illumina GAIIx platform to sequence a diverse array of 25 environmental samples and three known “mock communities” at a depth averaging 3.1 million reads per sample. We demonstrate excellent consistency in taxonomic recovery and recapture diversity patterns that were previously reported on the basis of metaanalysis of many studies from the literature (notably, the saline/nonsaline split in environmental samples and the split between host-associated and free-living communities). We also demonstrate that 2,000 Illumina single-end reads are sufficient to recapture the same relationships among samples that we observe with the full dataset. The results thus open up the possibility of conducting large-scale studies analyzing thousands of samples simultaneously to survey microbial communities at an unprecedented spatial and temporal resolution.","['Biology', 'Sample (material)', 'Illumina dye sequencing', 'Scale (ratio)', 'Consistency (knowledge bases)', 'Evolutionary biology', 'Computational biology', 'Computer science', 'DNA sequencing', 'Cartography', 'Genetics', 'Geography', 'Artificial intelligence', 'Gene', 'Chemistry', 'Chromatography']","software, ##tion, illumina gaiix platform, taxonomic recovery, recapture diversity patterns, temporal, [PAD] [PAD], [PAD] [PAD]"
Paper_01894,"One‐Dimensional Nanostructures: Synthesis, Characterization, and Applications","['Yan Xia', 'Pengfei Yang', 'Yugang Sun', 'Y. Wu', 'B. Mayers', 'Byron D. Gates', 'Yadong Yin', 'Franklin Kim', 'Hugen Yan']",2003,Advanced Materials,Journal,,353-389,15,5,10.1002/adma.200390087,"Abstract This article provides a comprehensive review of current research activities that concentrate on one‐dimensional (1D) nanostructures—wires, rods, belts, and tubes—whose lateral dimensions fall anywhere in the range of 1 to 100 nm. We devote the most attention to 1D nanostructures that have been synthesized in relatively copious quantities using chemical methods. We begin this article with an overview of synthetic strategies that have been exploited to achieve 1D growth. We then elaborate on these approaches in the following four sections: i) anisotropic growth dictated by the crystallographic structure of a solid material; ii) anisotropic growth confined and directed by various templates; iii) anisotropic growth kinetically controlled by supersaturation or through the use of an appropriate capping reagent; and iv) new concepts not yet fully demonstrated, but with long‐term potential in generating 1D nanostructures. Following is a discussion of techniques for generating various types of important heterostructured nanowires. By the end of this article, we highlight a range of unique properties (e.g., thermal, mechanical, electronic, optoelectronic, optical, nonlinear optical, and field emission) associated with different types of 1D nanostructures. We also briefly discuss a number of methods potentially useful for assembling 1D nanostructures into functional devices based on crossbar junctions, and complex architectures such as 2D and 3D periodic lattices. We conclude this review with personal perspectives on the directions towards which future research on this new class of nanostructured materials might be directed.","['Nanostructure', 'Materials science', 'Nanotechnology', 'Characterization (materials science)', 'Template', 'Nanowire', 'Anisotropy', 'Nonlinear optical', 'Nonlinear system', 'Physics', 'Quantum mechanics']","##stru, ##d nano, anisotropic growth, crystallographic structure, solid material, anisotropic growth, anisotropic growth, supersaturation, capping reagent, heterostructured nanowires, ##oele, nonlinear optical, field emission, ##d, functional devices, crossbar junctions, 3d periodic lattices, ##structured materials"
Paper_01896,The Construct of Resilience: A Critical Evaluation and Guidelines for Future Work,"['Suniya S. Luthar', 'Dante Cicchetti', 'Bronwyn E. Becker']",2000,Child Development,Journal,,543-562,71,3,10.1111/1467-8624.00164,"This paper presents a critical appraisal of resilience, a construct connoting the maintenance of positive adaptation by individuals despite experiences of significant adversity. As empirical research on resilience has burgeoned in recent years, criticisms have been levied at work in this area. These critiques have generally focused on ambiguities in definitions and central terminology; heterogeneity in risks experienced and competence achieved by individuals viewed as resilient; instability of the phenomenon of resilience; and concerns regarding the usefulness of resilience as a theoretical construct. We address each identified criticism in turn, proposing solutions for those we view as legitimate and clarifying misunderstandings surrounding those we believe to be less valid. We conclude that work on resilience possesses substantial potential for augmenting the understanding of processes affecting at‐risk individuals. Realization of the potential embodied by this construct, however, will remain constrained without continued scientific attention to some of the serious conceptual and methodological pitfalls that have been noted by skeptics and proponents alike.","['Construct (python library)', 'Psychology', 'Terminology', 'Competence (human resources)', 'Embodied cognition', 'Criticism', 'Critical appraisal', 'Vulnerability (computing)', 'Epistemology', 'Adaptation (eye)', 'Social psychology', 'Political science', 'Computer science', 'Medicine', 'Philosophy', 'Linguistics', 'Alternative medicine', 'Computer security', 'Pathology', 'Neuroscience', 'Law', 'Programming language']","resilience, positive adaptation, resilience, resilience, resilience, resilience"
Paper_01897,Crossing the Quality Chasm: A New Health System for the 21st Century,[],2002,Journal for Healthcare Quality,Journal,,52-52,24,5,10.1111/j.1945-1474.2002.tb00463.x,Journal For Healthcare Quality: September 2002 - Volume 24 - Issue 5 - p 52 doi: 10.1111/j.1945-1474.2002.tb00463.x,"['Quality (philosophy)', 'Healthcare system', 'Quality management', 'Health care', 'Volume (thermodynamics)', 'Medicine', 'Library science', 'Nursing', 'Computer science', 'Political science', 'Engineering', 'Operations management', 'Philosophy', 'Physics', 'Quantum mechanics', 'Management system', 'Epistemology', 'Law']","healthcare quality, [PAD]"
Paper_01898,Asset Stock Accumulation and Sustainability of Competitive Advantage,"['Ingemar Dierickx', 'Karel Cool']",1989,Management Science,Journal,,1504-1511,35,12,10.1287/mnsc.35.12.1504,"Given incomplete factor markets, appropriate time paths of flow variables must be chosen to build required stocks of assets. That is, critical resources are accumulated rather than acquired in “strategic factor markets” (Barney [Barney, J. 1986. Strategic factor markets: Expectations, luck, and business strategy. Management Sci. (October) 1231–1241.]). Sustainability of a firm's asset position hinges on how easily assets can be substituted or imitated. Imitability is linked to the characteristics of the asset accumulation process: time compression diseconomies, asset mass efficiencies, inter-connectedness, asset erosion and causal ambiguity.","['Divestment', 'Stock (firearms)', 'Business', 'Sustainability', 'Asset (computer security)', 'Diversification (marketing strategy)', 'Financial economics', 'Economics', 'Alternative asset', 'Microeconomics', 'Industrial organization', 'Capital asset pricing model', 'Finance', 'Consumption-based capital asset pricing model', 'Computer science', 'Marketing', 'Mechanical engineering', 'Ecology', 'Computer security', 'Engineering', 'Biology']","incomplete factor markets, time paths, flow variables, critical, strategic factor markets, strategic factor markets, expectations, luck, business strategy, ##bility, asset accumulation, time compression diseconomies, asset mass efficiencies, asset erosion, causal ambiguity, [PAD] [PAD], [PAD] [PAD] [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD] [PAD], [PAD] [PAD] [PAD], [PAD] [PAD]"
Paper_01899,Obesity is associated with macrophage accumulation in adipose tissue,"['Stuart P. Weisberg', 'Daniel McCann', 'Manisha Desai', 'Michael Rosenbaum', 'Rudolph L. Leibel', 'Anthony W. Ferrante']",2003,Journal of Clinical Investigation,Journal,,1796-1808,112,12,10.1172/jci19246,"Obesity alters adipose tissue metabolic and endocrine function and leads to an increased release of fatty acids, hormones, and proinflammatory molecules that contribute to obesity associated complications. To further characterize the changes that occur in adipose tissue with increasing adiposity, we profiled transcript expression in perigonadal adipose tissue from groups of mice in which adiposity varied due to sex, diet, and the obesity-related mutations agouti (Ay) and obese (Lepob). We found that the expression of 1,304 transcripts correlated significantly with body mass. Of the 100 most significantly correlated genes, 30% encoded proteins that are characteristic of macrophages and are positively correlated with body mass. Immunohistochemical analysis of perigonadal, perirenal, mesenteric, and subcutaneous adipose tissue revealed that the percentage of cells expressing the macrophage marker F4/80 (F4/80+) was significantly and positively correlated with both adipocyte size and body mass. Similar relationships were found in human subcutaneous adipose tissue stained for the macrophage antigen CD68. Bone marrow transplant studies and quantitation of macrophage number in adipose tissue from macrophage-deficient (Csf1op/op) mice suggest that these F4/80+ cells are CSF-1 dependent, bone marrow-derived adipose tissue macrophages. Expression analysis of macrophage and nonmacrophage cell populations isolated from adipose tissue demonstrates that adipose tissue macrophages are responsible for almost all adipose tissue TNF-alpha expression and significant amounts of iNOS and IL-6 expression. Adipose tissue macrophage numbers increase in obesity and participate in inflammatory pathways that are activated in adipose tissues of obese individuals.","['Adipose tissue', 'Obesity', 'Macrophage', 'Medicine', 'Adipose tissue macrophages', 'Endocrinology', 'Internal medicine', 'Biology', 'Pathology', 'White adipose tissue', 'Biochemistry', 'In vitro']","adipose tissue, endocrine function, proinflammat, adi, ##sity, ##cut, bone marrow transplant studies, ##mac, ##ha"
Paper_01901,The PRISMA 2020 statement: an updated guideline for reporting systematic reviews,"['Matthew J. Page', 'Joanne E. McKenzie', 'Patrick M. Bossuyt', 'Isabelle Boutron', 'Tammy Hoffmann', 'Cynthia D. Mulrow', 'Larissa Shamseer', 'Jennifer Tetzlaff', 'Elie A. Akl', 'Sue Brennan', 'Roger Chou', 'Julie Glanville', 'Jeremy Grimshaw', 'Asbjørn Hróbjartsson', 'Manoj M. Lalu', 'Tianjing Li', 'Elizabeth Loder', 'Evan Mayo‐Wilson', 'Steve McDonald', 'Luke A. McGuinness', 'Lesley Stewart', 'James Thomas', 'Andrea C. Tricco', 'Vivian Welch', 'Penny Whiting', 'David Moher']",2021,Systematic Reviews,Journal,,,10,1,10.1186/s13643-021-01626-4,"The Preferred Reporting Items for Systematic reviews and Meta-Analyses (PRISMA) statement, published in 2009, was designed to help systematic reviewers transparently report why the review was done, what the authors did, and what they found. Over the past decade, advances in systematic review methodology and terminology have necessitated an update to the guideline. The PRISMA 2020 statement replaces the 2009 statement and includes new reporting guidance that reflects advances in methods to identify, select, appraise, and synthesise studies. The structure and presentation of the items have been modified to facilitate implementation. In this article, we present the PRISMA 2020 27-item checklist, an expanded checklist that details reporting recommendations for each item, the PRISMA 2020 abstract checklist, and the revised flow diagrams for original and updated reviews.","['Checklist', 'Systematic review', 'Medicine', 'Guideline', 'Statement (logic)', 'Terminology', 'Presentation (obstetrics)', 'MEDLINE', 'Management science', 'Pathology', 'Psychology', 'Engineering', 'Political science', 'Law', 'Linguistics', 'Philosophy', 'Cognitive psychology', 'Radiology']","systematic reviews, prism, systematic reviewers, systematic review methodology, prisma, prisma, prisma 2020, flow diagrams"
Paper_01902,The American Economic Review,[],2012,American Economic Review,Journal,,i-iv,102,1,10.1257/aer.102.1.i,The front matter of the February 2012 issue contains the Table of Contents,['Economics'],
Paper_01904,Free Radicals in Biology and Medicine,"['Barry Halliwell', 'John M.C. Gutteridge']",2015,Unknown,Unknown,,,,,10.1093/acprof:oso/9780198717478.001.0001,"Abstract The new edition of this well-established book is thoroughly revised and gives a comprehensive account of the role of free radicals, other reactive species (RS), and antioxidants in life, health, and disease. Chapter 1 reviews how oxygen (O2) is used by living organisms, why it can be toxic, and introduces the concept of oxygen radicals and other RS; their chemistry is detailed in Chapter 2, especially for superoxide, hydroxyl radical (including Fenton chemistry), peroxynitrite, nitric oxide, ozone, and singlet O2, with emphasis on their redox properties. Subsequent chapters detail what antioxidants can be made in vivo (e.g. superoxide dismutases, peroxiredoxins) and which can come from diet (e.g. vitamins E and C, carotenoids, and polyphenols such as the flavonoids) and how they work in vivo. The role of RS in cell proliferation, senescence, and death (e.g. by apoptosis, necrosis, or intermediate forms) is presented. Methods for measuring RS are described in detail, including electron paramagnetic resonance and biomarker determination. Useful roles for RS (e.g. cell signalling, phagocyte action), as well as systems in which they cause particular problems (e.g. premature babies, the eye, the ear) are presented. Acute and chronic inflammation are used to illustrate both roles There is a comprehensive description of the role of RS in human diseases, from cancer to heart disease to dementia, in the ageing process, and in the toxicity of many agents, from ethanol to carbon tetrachloride to paraquat. Therapeutic agents active against RS are reviewed in detail, including NADPH oxidase inhibitors, N-acetylcysteine, and Ebselen.","['Reactive oxygen species', 'Radical', 'Chemistry', 'Peroxynitrite', 'Superoxide dismutase', 'Oxidative stress', 'Biochemistry', 'Antioxidant', 'Nitric oxide', 'Superoxide', 'Pharmacology', 'Biology', 'Organic chemistry', 'Enzyme']","free radicals, other, antioxida, oxygen radicals, fenton chemistry, per, ##ynit, ##tric, ozone, ##t o, superoxide dismutases, peroxired, carotenoids, flavonoids, cell proliferation, senescence, apoptosis, electron paramagnetic resonance, biomarker determination, premature babies, chronic, human, heart, ageing process, therapeutic, nadph, ebselen"
Paper_01906,<i>Mercury CSD 2.0</i>– new features for the visualization and investigation of crystal structures,"['Clare F. Macrae', 'Ian Bruno', 'James A. Chisholm', 'Paul R. Edgington', 'Patrick McCabe', 'Elna Pidcock', 'Lucía Rodríguez-Monge', 'Robin Taylor', 'Jacco van de Streek', 'P.A. Wood']",2008,Journal of Applied Crystallography,Journal,,466-470,41,2,10.1107/s0021889807067908,"The program Mercury , developed by the Cambridge Crystallographic Data Centre, is designed primarily as a crystal structure visualization tool. A new module of functionality has been produced, called the Materials Module , which allows highly customizable searching of structural databases for intermolecular interaction motifs and packing patterns. This new module also includes the ability to perform packing similarity calculations between structures containing the same compound. In addition to the Materials Module , a range of further enhancements to Mercury has been added in this latest release, including void visualization and links to ConQuest , Mogul and IsoStar .","['Visualization', 'Mercury (programming language)', 'Crystal structure', 'Void (composites)', 'Intermolecular force', 'Computer science', 'Materials science', 'Crystallography', 'Nanotechnology', 'Chemistry', 'Molecule', 'Data mining', 'Programming language', 'Organic chemistry', 'Composite material']","mercury, cambridge crystallographic data centre, crystal structure visualization tool, materials module, structural databases, intermolecular interaction motifs, packing patterns, packing similarity calculations, mercury, void visualization, conquest, mogul, isostar, [PAD], [PAD] [PAD] [PAD], [PAD] [PAD], [PAD] [PAD] [PAD], [PAD], [PAD] [PAD], [PAD] [PAD] [PAD], [PAD] [PAD] [PAD], [PAD], [PAD] [PAD], [PAD] [PAD], [PAD], [PAD], [PAD] [PAD], [PAD], [PAD] [PAD], [PAD], [PAD] [PAD], [PAD] [PAD]"
Paper_01907,Self-Rated Health and Mortality: A Review of Twenty-Seven Community Studies,"['Ellen Idler', 'Yael Benyamini']",1997,Journal of Health and Social Behavior,Journal,,21-21,38,1,10.2307/2955359,"We examine the growing number of studies of survey respondents' global self-ratings of health as predictors of mortality in longitudinal studies of representative community samples. Twenty-seven studies in U.S. and international journals show impressively consistent findings. Global self-rated health is an independent predictor of mortality in nearly all of the studies, despite the inclusion of numerous specific health status indicators and other relevant covariates known to predict mortality. We summarize and review these studies, consider various interpretations which could account for the association, and suggest several approaches to the next stage of research in this field.","['Self-rated health', 'Gerontology', 'Demography', 'Covariate', 'Psychology', 'Inclusion (mineral)', 'Medicine', 'Environmental health', 'Social psychology', 'Sociology', 'Econometrics', 'Economics']","survey respondents, longitudinal studies, representative community samples, health status indicators"
Paper_01908,QUAST: quality assessment tool for genome assemblies,"['Alexey Gurevich', 'Vladislav Saveliev', 'Nikolay Vyahhi', 'Glenn Tesler']",2013,Bioinformatics,Journal,,1072-1075,29,8,10.1093/bioinformatics/btt086,"Abstract Summary: Limitations of genome sequencing techniques have led to dozens of assembly algorithms, none of which is perfect. A number of methods for comparing assemblers have been developed, but none is yet a recognized benchmark. Further, most existing methods for comparing assemblies are only applicable to new assemblies of finished genomes; the problem of evaluating assemblies of previously unsequenced species has not been adequately considered. Here, we present QUAST—a quality assessment tool for evaluating and comparing genome assemblies. This tool improves on leading assembly comparison software with new ideas and quality metrics. QUAST can evaluate assemblies both with a reference genome, as well as without a reference. QUAST produces many reports, summary tables and plots to help scientists in their research and in their publications. In this study, we used QUAST to compare several genome assemblers on three datasets. QUAST tables and plots for all of them are available in the Supplementary Material, and interactive versions of these reports are on the QUAST website. Availability: http://bioinf.spbau.ru/quast Contact: gurevich@bioinf.spbau.ru Supplementary information: Supplementary data are available at Bioinformatics online.","['Benchmark (surveying)', 'Computer science', 'Genome', 'Sequence assembly', 'Software', 'Quality (philosophy)', 'Data mining', 'Biology', 'Genetics', 'Gene', 'Programming language', 'Philosophy', 'Gene expression', 'Transcriptome', 'Geodesy', 'Epistemology', 'Geography']","genome sequencing techniques, assembly algorithms, quast, quality assessment tool, assembly comparison software, quality metrics, quast, quast, summary tables, quast, genome assemblers, quast, quast, ##ast, bioinformatics"
Paper_01909,Magnetism from conductors and enhanced nonlinear phenomena,"['J. B. Pendry', 'A.J. Holden', 'David Robbins', 'Will Stewart']",1999,IEEE Transactions on Microwave Theory and Techniques,Journal,,2075-2084,47,11,10.1109/22.798002,"We show that microstructures built from nonmagnetic conducting sheets exhibit an effective magnetic permeability /spl mu//sub eff/, which can be tuned to values not accessible in naturally occurring materials, including large imaginary components of /spl mu//sub eff/. The microstructure is on a scale much less than the wavelength of radiation, is not resolved by incident microwaves, and uses a very low density of metal so that structures can be extremely lightweight. Most of the structures are resonant due to internal capacitance and inductance, and resonant enhancement combined with compression of electrical energy into a very small volume greatly enhances the energy density at critical locations in the structure, easily by factors of a million and possibly by much more. Weakly nonlinear materials placed at these critical locations will show greatly enhanced effects raising the possibility of manufacturing active structures whose properties can be switched at will between many states.","['Capacitance', 'Materials science', 'Electrical conductor', 'Inductance', 'Nonlinear system', 'Microwave', 'Magnetism', 'Microstructure', 'Optoelectronics', 'Wavelength', 'Metamaterial', 'Condensed matter physics', 'Physics', 'Electrical engineering', 'Composite material', 'Engineering', 'Voltage', 'Quantum mechanics', 'Electrode']","microstructure, nonmagnetic conducting sheets, magnetic permeability, naturally, imaginary components, incident microwaves, internal capacitance, inductance, resonant enhancement, electrical energy, weakly nonlinear materials"
Paper_01910,"The human brain is intrinsically organized into dynamic, anticorrelated functional networks","['Michael Fox', 'Abraham Z. Snyder', 'Justin L. Vincent', 'Maurizio Corbetta', 'David C. Van Essen', 'Marcus E. Raichle']",2005,Proceedings of the National Academy of Sciences,Journal,,9673-9678,102,27,10.1073/pnas.0504136102,"During performance of attention-demanding cognitive tasks, certain regions of the brain routinely increase activity, whereas others routinely decrease activity. In this study, we investigate the extent to which this task-related dichotomy is represented intrinsically in the resting human brain through examination of spontaneous fluctuations in the functional MRI blood oxygen level-dependent signal. We identify two diametrically opposed, widely distributed brain networks on the basis of both spontaneous correlations within each network and anticorrelations between networks. One network consists of regions routinely exhibiting task-related activations and the other of regions routinely exhibiting task-related deactivations. This intrinsic organization, featuring the presence of anticorrelated networks in the absence of overt task performance, provides a critical context in which to understand brain function. We suggest that both task-driven neuronal responses and behavior are reflections of this dynamic, ongoing, functional organization of the brain.","['Context (archaeology)', 'Neuroscience', 'Dynamic functional connectivity', 'Task (project management)', 'Human brain', 'Brain function', 'Brain activity and meditation', 'Cognition', 'Functional connectivity', 'Default mode network', 'Brain mapping', 'Functional magnetic resonance imaging', 'Function (biology)', 'Blood-oxygen-level dependent', 'Psychology', 'Nerve net', 'Computer science', 'Electroencephalography', 'Biology', 'Paleontology', 'Management', 'Evolutionary biology', 'Economics']","resting human brain, spontaneous fluctuations, functional, spontaneous correlations"
Paper_01915,Effective Approaches to Attention-based Neural Machine Translation,"['Thang Luong', 'Hieu Pham', 'Christopher D. Manning']",2015,Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing,Conference,"Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, Lisbon, Portugal",,,,10.18653/v1/d15-1166,"An attentional mechanism has lately been used to improve neural machine translation (NMT) by selectively focusing on parts of the source sentence during translation.However, there has been little work exploring useful architectures for attention-based NMT.This paper examines two simple and effective classes of attentional mechanism: a global approach which always attends to all source words and a local one that only looks at a subset of source words at a time.We demonstrate the effectiveness of both approaches on the WMT translation tasks between English and German in both directions.With local attention, we achieve a significant gain of 5.0 BLEU points over non-attentional systems that already incorporate known techniques such as dropout.Our ensemble model using different attention architectures yields a new state-of-the-art result in the WMT'15 English to German translation task with 25.9 BLEU points, an improvement of 1.0 BLEU points over the existing best system backed by NMT and an n-gram reranker. 1","['Machine translation', 'Computer science', 'Artificial intelligence', 'Translation (biology)', 'Machine learning', 'Natural language processing', 'Chemistry', 'Biochemistry', 'Messenger RNA', 'Gene']","attentional mechanism, neural machine translation, nmt, attention, wmt, ##al, dropout, attention architecture"
Paper_01916,The measurement of psychological androgyny.,['Lidia Sandra'],1974,Journal of Consulting and Clinical Psychology,Journal,,155-162,42,2,10.1037/h0036215,"This article describes the development of a new sex-role inventory that treats masculinity and femininity as two independent dimensions, thereby making it possible to characterize a person as masculine, feminine, or androgynous as a function of the difference between his or her endorsement of masculine and feminine personality characteristics. Normative data are presented, as well as the results of various psychometric analyses. The major findings of conceptual interest are: (a) the dimensions of masculinity and femininity are empirically as well as logically independent; (6) the concept of psychological androgyny is a reliable one; and (c) highly sex-typed scores do not reflect a general tendency to respond in a socially desirable direction, but rather a specific tendency to describe oneself in accordance with sex-typed standards of desirable behavior for men and women. Both in psychology and in society at large, masculinity and femininity have long been conceptualized as bipolar ends of a single continuum; accordingly, a person has had to be either masculine or feminine, but not both. This sex-role dichotomy has served to obscure two very plausible hypotheses: first, that many individuals might be androgynous ; that is, they might be both masculine and feminine, both assertive and yielding, both instrumental and expressive—depending on the situational appropriateness of these various behaviors; and conversely, that strongly sex-typed individuals might be seriously limited in the range of behaviors available to them as they move from situation to situation. According to both Kagan (1964) and Kohlberg (1966), the highly sex-typed individual is motivated to keep his behavior consistent with an internalized sex-role standard, a goal that he presumably accomplishes by suppressing any behavior that might be con","['Androgyny', 'Psychology', 'Psychological testing', 'California Psychological Inventory', 'Clinical psychology', 'Social psychology', 'Developmental psychology', 'Minnesota Multiphasic Personality Inventory', 'Psychoanalysis', 'Personality', 'Masculinity']","masculinity, femininity, androgynous, feminine personality characteristics, psychometric analyses, masculinity, femininity, psychological and, desirable behavior, masculinity, femininity"
Paper_01917,The integrative review: updated methodology,"['Robin Whittemore', 'Kathleen A. Knafl']",2005,Journal of Advanced Nursing,Journal,,546-553,52,5,10.1111/j.1365-2648.2005.03621.x,"The aim of this paper is to distinguish the integrative review method from other review methods and to propose methodological strategies specific to the integrative review method to enhance the rigour of the process.Recent evidence-based practice initiatives have increased the need for and the production of all types of reviews of the literature (integrative reviews, systematic reviews, meta-analyses, and qualitative reviews). The integrative review method is the only approach that allows for the combination of diverse methodologies (for example, experimental and non-experimental research), and has the potential to play a greater role in evidence-based practice for nursing. With respect to the integrative review method, strategies to enhance data collection and extraction have been developed; however, methods of analysis, synthesis, and conclusion drawing remain poorly formulated.A modified framework for research reviews is presented to address issues specific to the integrative review method. Issues related to specifying the review purpose, searching the literature, evaluating data from primary sources, analysing data, and presenting the results are discussed. Data analysis methods of qualitative research are proposed as strategies that enhance the rigour of combining diverse methodologies as well as empirical and theoretical sources in an integrative review.An updated integrative review method has the potential to allow for diverse primary research methods to become a greater part of evidence-based practice initiatives.","['Rigour', 'Systematic review', 'Management science', 'Data collection', 'Data extraction', 'Process (computing)', 'Computer science', 'Nursing research', 'Data science', 'Engineering ethics', 'MEDLINE', 'Medicine', 'Sociology', 'Epistemology', 'Engineering', 'Nursing', 'Social science', 'Philosophy', 'Political science', 'Law', 'Operating system']","integrative review method, ##ological, integrative review method, integrative reviews, systematic reviews, qu, ##tative, integrative review, nursing, integrative review, data collection, conclusion drawing, research, integrative, data analysis methods, qualitative research, integrative"
Paper_01918,In search of how people change. Applications to addictive behaviors.,"['Janice Prochaska', 'Carlo C. DiClemente', 'John C. Norcross']",1992,PubMed,Unknown,,1102-14,47,9,10.1037/0003-066x.47.9.1102,"How people intentionally change addictive behaviors with and without treatment is not well understood by behavioral scientists. This article summarizes research on self-initiated and professionally facilitated change of addictive behaviors using the key trans-theoretical constructs of stages and processes of change. Modification of addictive behaviors involves progression through five stages--pre-contemplation, contemplation, preparation, action, and maintenance--and individuals typically recycle through these stages several times before termination of the addiction. Multiple studies provide strong support for these stages as well as for a finite and common set of change processes used to progress through the stages. Research to date supports a trans-theoretical model of change that systematically integrates the stages with processes of change from diverse theories of psychotherapy.","['Addiction', 'Contemplation', 'Psychology', 'Behavior change', 'Set (abstract data type)', 'Action (physics)', 'Addictive behavior', 'Psychotherapist', 'Behaviour change', 'Social psychology', 'Cognitive psychology', 'Intervention (counseling)', 'Epistemology', 'Neuroscience', 'Psychiatry', 'Computer science', 'Philosophy', 'Physics', 'Quantum mechanics', 'Programming language']","addictive behaviors, behavioral scientists, addictive behaviors, addictive behaviors, psychotherapy, [PAD]"
Paper_01920,Genomic sequencing.,"['George M. Church', 'W Gilbert']",1984,Proceedings of the National Academy of Sciences,Journal,,1991-1995,81,7,10.1073/pnas.81.7.1991,"Unique DNA sequences can be determined directly from mouse genomic DNA. A denaturing gel separates by size mixtures of unlabeled DNA fragments from complete restriction and partial chemical cleavages of the entire genome. These lanes of DNA are transferred and UV-crosslinked to nylon membranes. Hybridization with a short 32P-labeled single-stranded probe produces the image of a DNA sequence ""ladder"" extending from the 3' or 5' end of one restriction site in the genome. Numerous different sequences can be obtained from a single membrane by reprobing. Each band in these sequences represents 3 fg of DNA complementary to the probe. Sequence data from mouse immunoglobulin heavy chain genes from several cell types are presented. The genomic sequencing procedures are applicable to the analysis of genetic polymorphisms, DNA methylation at deoxycytidines, and nucleic acid-protein interactions at single nucleotide resolution.","['DNA nanoball sequencing', 'Sequencing by hybridization', 'DNA', 'Biology', 'Genome', 'DNA sequencing', 'genomic DNA', 'Genetics', 'Sequencing by ligation', 'Nucleic acid', 'Genomic library', 'Nucleic acid thermodynamics', 'DNA methylation', 'Nucleic acid sequence', 'Molecular biology', 'Gene', 'DNA sequencer', 'Base sequence', 'Gene expression']","mouse genomic dna, denaturing gel, mouse immunoglobulin heavy chain genes, genetic polymorphisms, dna methylation, ##y"
Paper_01921,Asylums: Essays on the Social Situation of Mental Patients and Other Inmates.,"['Harold W. Pfautz', 'Erving Goffman']",1962,American Sociological Review,Journal,,555-555,27,4,10.2307/2090043,"A total institution is defined by Goffman as a place of residence and work where a large number of like-situated, individuals, cut off from the wider society for an appreciable period of time, together lead an enclosed, formally administered round of life. Prisons serve as a clear example, providing we appreciate that what is prison-like about prisons is found in institutions whose members have broken no laws. This volume deals with total institutions in general and, mental hospitals, in particular. The main focus is, on the world of the inmate, not the world of the staff. A chief concern is to develop a sociological version of the structure of the self.Each of the essays in this book were intended to focus on the same issue--the inmate's situation in an institutional context. Each chapter approaches the central issue from a different vantage point, each introduction drawing upon a different source in sociology and having little direct relation to the other chapters.This method of presenting material may be irksome, but it allows the reader to pursue the main theme of each paper analytically and comparatively past the point that would be allowable in chapters of an integrated book. If sociological concepts are to be treated with affection, each must be traced back to where it best applies, followed from there wherever it seems to lead, and pressed to disclose the rest of its family.","['Psychology', 'Criminology', 'Psychiatry', 'Sociology', 'Social psychology', 'Psychoanalysis']","total institution, total institutions, mental hospitals"
Paper_01922,A Treatise of Human Nature,['David Hume'],1970,"[""Hume's Ethical Writings""]",Unknown,,175-252,,,10.2307/j.ctvpj759p.7,"PART 1: INTRODUCTORY MATERIAL. How to Use this Book. List of Abbreviations. Editor's Introduction. Hume's Early years and Education. A Treatise of Human Nature. Book 1: Of the Understanding. Book 1 part 1: The Elements of the Mental World. Book 1 Part 2: The Ideas of Space and Time. Book 1 Part 3: Knowledge, Probability, Belief, and Causation. Book 1 Part 4: Forms of Scepticism. Book 2: Of the passions. Book 2 Part 1: The Indirect Passions of Pride and Humility. Book 2 Part 2: The Indirect Passions of Love and Hatred. Book 2 part 3: The Direct Passions and the Will. Book 3: Of Morals. Book 3 Part 1: The Source of Moral Distinctions. Book 3 Part 2: The Artificial Virtues. Book 3 Part 3: Natural Virtues and Natural Abilities. The Abstract and the Early Reception of the Treatise. Supplementary Reading. A Note on the Texts of this Edition. PART 2: THE TEXT. Advertisement. Introduction. Book 1: Of the Understanding. Part 1: Of ideas, their origin, composition, connexion, abstraction, etc.. Sect. 1: Of the origin of our ideas. Sect. 2: Division of the subject. Sect. 3: Of the ideas of the memory and imagination. Sect. 4: Of the connexion of association of ideas. Sect. 5. Of relations. Sect. 6 Of modes and substances. Sect. 7: Of abstract ideas. Part 2: Of ideas of space and time. Sect. 1: Of the infinite divisibility of our ideas of space and time. Sect. 2: Of the infinite divisibility of space and time. Sect. 3. Of the other qualities of our ideas of space and time. Sect. 4. Objections answered. Sect. 5: The same subject continued. Sect. 6: Of the idea of existence and of external existence. Part 3: of knowledge and probability. Sect. 1: Of knowledge. Sect. 2. Of probability and of the idea of cause and effect. Sect. 3: Why a cause is always necessary. Sect. 4: Of the component parts of our reasonings concerning cause and effect. Sect. 5: Of the impressions of the senses and memory. Section. 6: Of the inference from the impression to the idea. Sect. 7: Of the nature of the idea or belief. Sect. 8: Of the causes of belief. Sect. 9: Of the effects of other relations and other habits. Sect 10. Of the influence of belief. Sect. 11: Of the probability of chances. Sect. 12: Of the probability of causes. Sect. 13: Of unphilosophical probability. Sect. 14: Of the idea of necessary connexion. Sect. 15: Rules by which to judge of causes and effects. Sect. 16: Of the reason of animals. Part 4: Of the sceptical and other systems of philosophy. Sect. 1: Of scepticism with regard to reason. Sect. 2: Of scepticism with regard to the senses. Sect. 3. Of the ancient philosophy. Sect 4. Of the modern philosophy. Sect. 5: Of the immateriality of the soul. Sect. 6: Of personal identity. Sect. 7: Conclusion of this book. Book 2: Of the Passions. Part 1: Of pride and humility. Sect. 1: Division of the subject. Sect. 2: Of pride and humility their objects and causes. Sect. 3: Whence these objects and causes are derived. Sect. 4: Of the relations of impressions and ideas. Sect. 5: Of the influence of these relations on pride and humility. Sect. 6: Limitations of this system. Sect. 7: Of vice and virtue. Sect. 8: Of beauty and deformity. Sect. 9: Of external advantages and disadvantages. Sect. 10: Of property and riches. Sect. 11: Of the love of fame. Sect. 12: Of the pride and humility of animals. Part 2: Of love and hatred. Sect. 1: Of the objects and causes of love and hatred. Sect. 2: Experiments to confirm this system. Sect. 3: Difficulties solved. Sect. 4: Of the love of relations. Sect. 5: Of our esteem for the rich and powerful. Sect 6: Of benevolence and anger. Sect. 7: Of compassion. Sect. 8: Of malice and envy. Sect. 9: Of the mixture of benevolence and anger with compassion and malice. Sect. 10. Of respect and contempt. Sect. 11: Of the amorous passion, or love betwixt the sexes. Sect. 12: Of the love and hatred of animals. Part 3: Of the will and direct passions. Sect. 1: Of liberty and necessity. Sect. 2: The same subject continued. Sect. 3: Of the influencing motives of the will. Sect. 4: Of the causes of the violent passions. Sect. 5: Of the effects of custom. Sect. Of the influence of the imagination on passions. Sect. 7: Of contiguity and distance in space and time. Sect. 8: The same subject continued. Sect. 9: Of the direct passions. Sect. 10: Of curiosity, or the love of truth. Book 3: Of Morals. Advertisement. Part 1: Of virtue and vice in general. Sect. 1: Moral distinctions not derived from reason. Sect. 2: Moral distinctions derived from a moral sense. Part 2: Of justice and injustice. Sect. 1: Justice, whether a natural or artificial virtue?. Sect. 2: Of the origin of justice and property. Sect. 3: Of the rules, which determine property. Sect. 4: Of the transference of property by consent. Sect. 5: Of the obligation of promises. Sect. 6: Some farther reflections concerning justice and injustice. Sect. 7: Of the origin of government. Sect. 8: Of the source of allegiance. Sect. 9: Of the measures of allegiance. Sect. 10: Of the objects of allegiance. Sect. 11: Of the laws of nations. Sect. 12: Of chastity and modesty. Part 3: Of the other virtues and vices. Sect. 1: Of the origin of the natural virtues and vices. Sect. 2: Of greatness of mind. Sect. 3. Of goodness and benevolence. Sect. 4: Of natural abilities. Sect. 5: Some farther reflections concerning the natural virtues. Sect. 6: Conclusion of this book. Appendix. An Abstract of ... A Treatise of Human Nature. PART 3 SUPPLEMENTARY MATERIAL. Editors' Annotations. Annotations to the Treatise. Annotations to the Abstract. Glossary. References. Index","['Passions', 'Sect', 'Philosophy', 'Skepticism', 'Epistemology', 'Humility', 'Natural (archaeology)', 'Literature', 'History', 'Art', 'Theology', 'Archaeology']","mental world, space, knowledge, probability, belief, causation, sc, ##ici, indirect passions, pride, humility, hatred, direct passions, will, morals, moral distinctions, artificial virtues, natural virtues, natural abilities, infinite divisibility, infinite divisibility, existence, external existence, probability, knowledge, probability, memory"
Paper_01925,"Compilers: Principles, Techniques, and Tools","['Alfred V. Aho', 'Ravi Sethi', 'Jeffrey D. Ullman']",1986,Unknown,Unknown,,,,,10.1007/978-3-642-20835-5,1 Introduction 1.1 Language Processors 1.2 The Structure of a Compiler 1.3 The Evolution of Programming Languages 1.4 The Science of Building a Compiler 1.5 Applications of Compiler Technology 1.6 Programming Language Basics 1.7 Summary of Chapter 1 1.8 References for Chapter 1 2 A Simple Syntax-Directed Translator 2.1 Introduction 2.2 Syntax Definition 2.3 Syntax-Directed Translation 2.4 Parsing 2.5 A Translator for Simple Expressions 2.6 Lexical Analysis 2.7 Symbol Tables 2.8 Intermediate Code Generation 2.9 Summary of Chapter 2 3 Lexical Analysis 3.1 The Role of the Lexical Analyzer 3.2 Input Buffering 3.3 Specification of Tokens 3.4 Recognition of Tokens 3.5 The Lexical-Analyzer Generator Lex 3.6 Finite Automata 3.7 From Regular Expressions to Automata 3.8 Design of a Lexical-Analyzer Generator 3.9 Optimization of DFA-Based Pattern Matchers 3.10 Summary of Chapter 3 3.11 References for Chapter 3 4 Syntax Analysis 4.1 Introduction 4.2 Context-Free Grammars 4.3 Writing a Grammar 4.4 Top-Down Parsing 4.5 Bottom-Up Parsing 4.6 Introduction to LR Parsing: Simple LR 4.7 More Powerful LR Parsers 4.8 Using Ambiguous Grammars 4.9 Parser Generators 4.10 Summary of Chapter 4 4.11 References for Chapter 4 5 Syntax-Directed Translation 5.1 Syntax-Directed Definitions 5.2 Evaluation Orders for SDD's 5.3 Applications of Syntax-Directed Translation 5.4 Syntax-Directed Translation Schemes 5.5 Implementing L-Attributed SDD's 5.6 Summary of Chapter 5 5.7 References for Chapter 5 6 Intermediate-Code Generation 6.1 Variants of Syntax Trees 6.2 Three-Address Code 6.3 Types and Declarations 6.4 Translation of Expressions 6.5 Type Checking 6.6 Control Flow 6.7 Backpatching 6.8 Switch-Statements 6.9 Intermediate Code for Procedures 6.10 Summary of Chapter 6 6.11 References for Chapter 6 7 Run-Time Environments 7.1 Storage Organization 7.2 Stack Allocation of Space 7.3 Access to Nonlocal Data on the Stack 7.4 Heap Management 7.5 Introduction to Garbage Collection 7.6 Introduction to Trace-Based Collection 7.7 Short-Pause Garbage Collection 7.8 Advanced Topics in Garbage Collection 7.9 Summary of Chapter 7 7.10 References for Chapter 7 8 Code Generation 8.1 Issues in the Design of a Code Generator 8.2 The Target Language 8.3 Addresses in the Target Code 8.4 Basic Blocks and Flow Graphs 8.5 Optimization of Basic Blocks 8.6 A Simple Code Generator 8.7 Peephole Optimization 8.8 Register Allocation and Assignment 8.9 Instruction Selection by Tree Rewriting 8.10 Optimal Code Generation for Expressions 8.11 Dynamic Programming Code-Generation 8.12 Summary of Chapter 8 8.13 References for Chapter 8 9 Machine-Independent Optimizations 9.1 The Principal Sources of Optimization 9.2 Introduction to Data-Flow Analysis 9.3 Foundations of Data-Flow Analysis 9.4 Constant Propagation 9.5 Partial-Redundancy Elimination 9.6 Loops in Flow Graphs 9.7 Region-Based Analysis 9.8 Symbolic Analysis 9.9 Summary of Chapter 9 9.10 References for Chapter 9 10 Instruction-Level Parallelism 10.1 Processor Architectures 10.2 Code-Scheduling Constraints 10.3 Basic-Block Scheduling 10.4 Global Code Scheduling 10.5 Software Pipelining 10.6 Summary of Chapter 10 10.7 References for Chapter 10 11 Optimizing for Parallelism and Locality 11.1 Basic Concepts 11.2 Matrix Multiply: An In-Depth Example 11.3 Iteration Spaces 11.4 Affine Array Indexes 11.5 Data Reuse 11.6 Array Data-Dependence Analysis 11.7 Finding Synchronization-Free Parallelism 11.8 Synchronization Between Parallel Loops 11.9 Pipelining 11.10 Locality Optimizations 11.11 Other Uses of Affine Transforms 11.12 Summary of Chapter 11 11.13 References for Chapter 11 12 Interprocedural Analysis 12.1 Basic Concepts 12.2 Why Interprocedural Analysis? 12.3 A Logical Representation of Data Flow 12.4 A Simple Pointer-Analysis Algorithm 12.5 Context-Insensitive Interprocedural Analysis 12.6 Context-Sensitive Pointer Analysis 12.7 Datalog Implementation by BDD's 12.8 Summary of Chapter 12 12.9 References for Chapter 12 A A Complete Front End A.1 The Source Language A.2 Main A.3 Lexical Analyzer A.4 Symbol Tables and Types A.5 Intermediate Code for Expressions A.6 Jumping Code for Boolean Expressions A.7 Intermediate Code for Statements A.8 Parser A.9 Creating the Front End B Finding Linearly Independent Solutions Index,"['Computer science', 'Parsing', 'Programming language', 'Compiler', 'Compiler construction', 'Syntax', 'Lexical analysis', 'Abstract syntax tree', 'Syntax error', 'Rule-based machine translation', 'Grammar', 'Natural language processing', 'Artificial intelligence', 'Linguistics', 'Philosophy']","language processors, compiler, programming languages, compiler, compiler technology, programming language, syntax definition, lexical analysis, symbol tables, intermediate code generation, lexical analysis, lexical analyzer, input buffering, token, token, finite automata, regular expressions, automata, pattern, syntax analysis, ambiguous grammars, ##ser, evaluation, syntax trees, type checking, control flow, backpatch, intermediate, storage organization, stack allocation, heap management, garbage collection, garbage"
Paper_01926,Effect of Enalapril on Survival in Patients with Reduced Left Ventricular Ejection Fractions and Congestive Heart Failure,[],1991,New England Journal of Medicine,Journal,,293-302,325,5,10.1056/nejm199108013250501,"Patients with congestive heart failure have a high mortality rate and are also hospitalized frequently. We studied the effect of an angiotensin-converting–enzyme inhibitor, enalapril, on mortality and hospitalizaron in patients with chronic heart failure and ejection fractions ≤0.35.","['Enalapril', 'Heart failure', 'Medicine', 'Cardiology', 'Internal medicine', 'Ejection fraction', 'ACE inhibitor', 'Angiotensin-converting enzyme', 'Blood pressure']","congestive heart failure, enalapril, hospitaliza, chronic heart failure, ejection fraction, [PAD], [PAD], [PAD]"
Paper_01927,"Demarginalizing the Intersection of Race and Sex: A Black Feminist Critique of Antidiscrimination Doctrine, Feminist Theory, and Antiracist Politics [1989]",['Kimberlé W. Crenshaw'],2018,Routledge eBooks,Unknown,,57-80,,,10.4324/9780429500480-5,"This chapter examines how the tendency is perpetuated by a single-axis framework that is dominant in antidiscrimination law and that is also reflected in feminist theory and antiracist politics. It suggests that this single-axis framework erases Black women in the conceptualization, identification and remediation of race and sex discrimination by limiting inquiry to the experiences of otherwise-privileged members of the group. The chapter focuses on otherwise-privileged group members creates a distorted analysis of racism and sexism because the operative conceptions of race and sex become grounded in experiences that actually represent only a subset of a much more complex phenomenon. It argues that Black women are sometimes excluded from feminist theory and antiracist policy discourse because both are predicated on a discrete set of experiences that often does not accurately reflect the interaction of race and gender. The chapter discusses the feminist critique of rape and separate spheres ideology.","['Doctrine', 'Intersection (aeronautics)', 'Race (biology)', 'Gender studies', 'Politics', 'Sociology', 'Political science', 'Law', 'Geography', 'Cartography']","antidiscrimination law, feminist theory, antiracist politics, black women, sex discrimination, racism, sexism, black women, feminist theory, antiracist policy discourse, gender, feminist critique, rape, separate spheres ideology"
Paper_01930,"Organizational Learning and Communities-of-Practice: Toward a Unified View of Working, Learning, and Innovation","['John Seely Brown', 'Paul Duguid']",1991,Organization Science,Journal,,40-57,2,1,10.1287/orsc.2.1.40,"Recent ethnographic studies of workplace practices indicate that the ways people actually work usually differ fundamentally from the ways organizations describe that work in manuals, training programs, organizational charts, and job descriptions. Nevertheless, organizations tend to rely on the latter in their attempts to understand and improve work practice. We examine one such study. We then relate its conclusions to compatible investigations of learning and of innovation to argue that conventional descriptions of jobs mask not only the ways people work, but also significant learning and innovation generated in the informal communities-of-practice in which they work. By reassessing work, learning, and innovation in the context of actual communities and actual practices, we suggest that the connections between these three become apparent. With a unified view of working, learning, and innovating, it should be possible to reconceive of and redesign organizations to improve all three.","['Work (physics)', 'Context (archaeology)', 'Knowledge management', 'Organizational learning', 'Ethnography', 'Sociology', 'Public relations', 'Computer science', 'Political science', 'Engineering', 'Mechanical engineering', 'Paleontology', 'Anthropology', 'Biology']","##hnographic, workplace practices, training programs, organizational charts, job descriptions, work practice, learning, innovation"
Paper_01931,Speech recognition with deep recurrent neural networks,"['Alex Graves', 'Abdelrahman Mohamed', 'Geoffrey E. Hinton']",2013,IEEE International Conference on Acoustics Speech and Signal Processing,Conference,"ICASSP 2013 - 2013 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), Vancouver, BC, Canada",6645-6649,,,10.1109/icassp.2013.6638947,"Recurrent neural networks (RNNs) are a powerful model for sequential data. End-to-end training methods such as Connectionist Temporal Classification make it possible to train RNNs for sequence labelling problems where the input-output alignment is unknown. The combination of these methods with the Long Short-term Memory RNN architecture has proved particularly fruitful, delivering state-of-the-art results in cursive handwriting recognition. However RNN performance in speech recognition has so far been disappointing, with better results returned by deep feedforward networks. This paper investigates deep recurrent neural networks, which combine the multiple levels of representation that have proved so effective in deep networks with the flexible use of long range context that empowers RNNs. When trained end-to-end with suitable regularisation, we find that deep Long Short-term Memory RNNs achieve a test set error of 17.7% on the TIMIT phoneme recognition benchmark, which to our knowledge is the best recorded score.","['Recurrent neural network', 'Computer science', 'Connectionism', 'TIMIT', 'Speech recognition', 'Artificial intelligence', 'Deep learning', 'Context (archaeology)', 'Benchmark (surveying)', 'Time delay neural network', 'Artificial neural network', 'Hidden Markov model', 'Pattern recognition (psychology)', 'Paleontology', 'Geodesy', 'Biology', 'Geography']","recurrent neural networks, rn, sequential data, connectionist temporal classification, rn, sequence labelling problems, cursive handwriting recognition, speech recognition, deep feedforward networks, deep recurrent neural networks, timit phoneme recognition benchmark"
Paper_01932,Imaging Intracellular Fluorescent Proteins at Nanometer Resolution,"['Eric Betzig', 'George H. Patterson', 'Rachid Sougrat', 'O. Wolf Lindwasser', 'Scott G. Olenych', 'Juan S. Bonifacino', 'Michael W. Davidson', 'Jennifer Lippincott‐Schwartz', 'Harald F. Hess']",2006,Science,Journal,,1642-1645,313,5793,10.1126/science.1127344,"We introduce a method for optically imaging intracellular proteins at nanometer spatial resolution. Numerous sparse subsets of photoactivatable fluorescent protein molecules were activated, localized (to approximately 2 to 25 nanometers), and then bleached. The aggregate position information from all subsets was then assembled into a superresolution image. We used this method--termed photoactivated localization microscopy--to image specific target proteins in thin sections of lysosomes and mitochondria; in fixed whole cells, we imaged vinculin at focal adhesions, actin within a lamellipodium, and the distribution of the retroviral protein Gag at the plasma membrane.","['Vinculin', 'Lamellipodium', 'Microscopy', 'Actin', 'Superresolution', 'Resolution (logic)', 'Super-resolution microscopy', 'Photoactivated localization microscopy', 'Intracellular', 'Biophysics', 'Cell biology', 'Chemistry', 'Fluorescence', 'Fluorescence microscope', 'Focal adhesion', 'Biology', 'Optics', 'Cytoskeleton', 'Biochemistry', 'Cell', 'Physics', 'Image (mathematics)', 'Computer science', 'Artificial intelligence']","optical, intracellular proteins, nanometer spatial resolution, sparse subsets, photoactivatable fluorescent protein molecules, superresolution image, photoactivated localization microscopy, mit, fixed whole cells, focal adhesions, lamellipod, retroviral, [PAD], [PAD], [PAD] [PAD] [PAD] [PAD], [PAD], [PAD] [PAD]"
Paper_01933,Image Denoising by Sparse 3-D Transform-Domain Collaborative Filtering,"['Kostadin Dabov', 'Alessandro Foi', 'Vladimir Katkovnik', 'Karen Egiazarian']",2007,IEEE Transactions on Image Processing,Journal,,2080-2095,16,8,10.1109/tip.2007.901238,"We propose a novel image denoising strategy based on an enhanced sparse representation in transform domain. The enhancement of the sparsity is achieved by grouping similar 2D image fragments (e.g., blocks) into 3D data arrays which we call ""groups."" Collaborative Altering is a special procedure developed to deal with these 3D groups. We realize it using the three successive steps: 3D transformation of a group, shrinkage of the transform spectrum, and inverse 3D transformation. The result is a 3D estimate that consists of the jointly filtered grouped image blocks. By attenuating the noise, the collaborative filtering reveals even the finest details shared by grouped blocks and, at the same time, it preserves the essential unique features of each individual block. The filtered blocks are then returned to their original positions. Because these blocks are overlapping, for each pixel, we obtain many different estimates which need to be combined. Aggregation is a particular averaging procedure which is exploited to take advantage of this redundancy. A significant improvement is obtained by a specially developed collaborative Wiener filtering. An algorithm based on this novel denoising strategy and its efficient implementation are presented in full detail; an extension to color-image denoising is also developed. The experimental results demonstrate that this computationally scalable algorithm achieves state-of-the-art denoising performance in terms of both peak signal-to-noise ratio and subjective visual quality.","['Noise reduction', 'Non-local means', 'Sparse approximation', 'Computer science', 'Artificial intelligence', 'Video denoising', 'Block (permutation group theory)', 'Wiener filter', 'Redundancy (engineering)', 'Pixel', 'Transformation (genetics)', 'Algorithm', 'Pattern recognition (psychology)', 'Mathematics', 'Image denoising', 'Video processing', 'Biochemistry', 'Chemistry', 'Geometry', 'Video tracking', 'Multiview Video Coding', 'Gene', 'Operating system']","image denoising strategy, enhanced sparse representation, transform domain, spars, 2d image fragments, 3d data arrays, collaborative altering, 3d transformation, transform spectrum, inverse 3d transformation, collaborative filtering, aggregation, collaborative wiener filtering, subjective visual quality"
Paper_01935,"Healthy work: stress, productivity, and the reconstruction of working life","['Robert Karasek', 'Töres Theorell']",1990,Choice Reviews Online,Journal,,28-0381,28,01,10.5860/choice.28-0381,Suggests a strategy for redesigning jobs to reduce unnecessary stress and improve productivity and job satisfaction.,"['Productivity', 'Work (physics)', 'Stress (linguistics)', 'Economics', 'Engineering', 'Economic growth', 'Philosophy', 'Mechanical engineering', 'Linguistics']","productivity, job satisfaction"
Paper_01937,Multiple Attribute Decision Making: Methods and Applications,"['Shu-Jen J. Chen', 'C. L. Hwang', 'Martin J. Beckmann', 'Wilhelm Krelle']",1981,"['Springer Series in Advanced Manufacturing', 'Decision Making in Manufacturing Environment Using Graph Theory and Fuzzy Multiple Attribute Decision Making Methods']",Unknown,,7-39,,,10.1007/978-1-4471-4375-8_2,"I. Introduction.- II. Multiple Attribute Decision Making - An Overview.- 2.1 Basics and Concepts.- 2.2 Classifications of MADM Methods.- 2.2.1 Classification by Information.- 2.2.2 Classification by Solution Aimed At.- 2.2.3 Classification by Data Type.- 2.3 Description of MADM Methods.- Method (1): DOMINANCE.- Method (2): MAXIMIN.- Method (3): MAXIMAX.- Method (4): CONJUNCTIVE METHOD.- Method (5): DISJUNCTIVE METHOD.- Method (6): LEXICOGRAPHIC METHOD.- Method (7): LEXICOGRAPHIC SEMIORDER METHOD.- Method (8): ELIMINATION BY ASPECTS (EBA).- Method (9): LINEAR ASSIGNMENT METHOD (LAM).- Method (10): SIMPLE ADDITIVE WEIGHTING METHOD (SAW).- Method (11): ELECTRE (Elimination et Choice Translating Reality).- Method (12): TOPSIS (Technique for Order Preference by Similarity to Ideal Solution).- Method (13): WEIGHTED PRODUCT METHOD.- Method (14): DISTANCE FROM TARGET METHOD.- III. Fuzzy Sets and their Operations.- 3.1 Introduction.- 3.2 Basics of Fuzzy Sets.- 3.2.1 Definition of a Fuzzy Set.- 3.2.2 Basic Concepts of Fuzzy Sets.- 3.2.2.1 Complement of a Fuzzy Set.- 3.2.2.2 Support of a Fuzzy Set.- 3.2.2.3 ?-cut of a Fuzzy Set.- 3.2.2.4 Convexity of a Fuzzy Set.- 3.2.2.5 Normality of a Fuzzy Set.- 3.2.2.6 Cardinality of a Fuzzy Set.- 3.2.2.7 The mth Power of a Fuzzy Set.- 3.3 Set-Theoretic Operations with Fuzzy Sets.- 3.3.1 No Compensation Operators.- 3.3.1.1 The Min Operator.- 3.3.2 Compensation-Min Operators.- 3.3.2.1 Algebraic Product.- 3.3.2.2 Bounded Product.- 3.3.2.3 Hamacher's Min Operator.- 3.3.2.4 Yager's Min Operator.- 3.3.2.5 Dubois and Prade's Min Operator.- 3.3.3 Full Compensation Operators.- 3.3.3.1 The Max Operator.- 3.3.4 Compensation-Max Operators.- 3.3.4.1 Algebraic Sum.- 3.3.4.2 Bounded Sum.- 3.3.4.3 Hamacher's Max Operator.- 3.3.4.4 Yager's Max Operator.- 3.3.4.5 Dubois and Prade's Max Operator.- 3.3.5 General Compensation Operators.- 3.3.5.1 Zimmermann and Zysno's ? Operator.- 3.3.6 Selecting Appropriate Operators.- 3.4 The Extension Principle and Fuzzy Arithmetics.- 3.4.1 The Extension Principle.- 3.4.2 Fuzzy Arithmetics.- 3.4.2.1 Fuzzy Number.- 3.4.2.2 Addition of Fuzzy Numbers.- 3.4.2.3 Subtraction of Fuzzy Numbers.- 3.4.2.4 Multiplication of Fuzzy Numbers.- 3.4.2.5 Division of Fuzzy Numbers.- 3.4.2.6 Fuzzy Max and Fuzzy Min.- 3.4.3 Special Fuzzy Numbers.- 3.4.3.1 L-R Fuzzy Number.- 3.4.3.2 Triangular (or Trapezoidal) Fuzzy Number.- 3.4.3.3 Proof of Formulas.- 3.4.3.3.1 The Image of Fuzzy Number N.- 3.4.3.3.2 The Inverse of Fuzzy Number N.- 3.4.3.3.3 Addition and Subtraction.- 3.4.3.3.4 Multiplication and Division.- 3.5 Conclusions.- IV. Fuzzy Ranking Methods.- 4.1 Introduction.- 4.2 Ranking Using Degree of Optimality.- 4.2.1 Baas and Kwakernaak's Approach.- 4.2.2 Watson et al.'s Approach.- 4.2.3 Baldwin and Guild's Approach.- 4.3 Ranking Using Hamming Distance.- 4.3.1 Yager's Approach.- 4.3.2 Kerre's Approach.- 4.3.3 Nakamura's Approach.- 4.3.4 Kolodziejczyk's Approach.- 4.4 Ranking Using ?-Cuts.- 4.4.1 Adamo's Approach.- 4.4.2 Buckley and Chanas' Approach.- 4.4.3 Mabuchi's Approach.- 4.5 Ranking Using Comparison Function.- 4.5.1 Dubois and Prade's Approach.- 4.5.2 Tsukamoto et al.'s Approach.- 4.5.3 Delgado et al.'s Approach.- 4.6 Ranking Using Fuzzy Mean and Spread.- 4.6.1 Lee and Li's Approach.- 4.7 Ranking Using Proportion to The Ideal.- 4.7.1 McCahone's Approach.- 4.8 Ranking Using Left and Right Scores.- 4.8.1 Jain's Approach.- 4.8.2 Chen's Approach.- 4.8.3 Chen and Hwang's Approach.- 4.9 Ranking with Centroid Index.- 4.9.1 Yager's Centroid Index.- 4.9.2 Murakami et al.'s Approach.- 4.10 Ranking Using Area Measurement.- 4.10.1 Yager's Approach.- 4.11 Linguistic Ranking Methods.- 4.11.1 Efstathiou and Tong's Approach.- 4.11.2 Tong and Bonissone's Approach.- V. Fuzzy Multiple Attribute Decision Making Methods.- 5.1 Introduction.- 5.2 Fuzzy Simple Additive Weighting Methods.- 5.2.1 Baas and Kwakernaak's Approach.- 5.2.2 Kwakernaak's Approach.- 5.2.3 Dubois and Prade's Approach.- 5.2.4 Cheng and McInnis's Approach.- 5.2.5 Bonissone's Approach.- 5.3 Analytic Hierarchical Process (AHP) Methods.- 5.3.1 Saaty's AHP Approach.- 5.3.2 Laarhoven and Pedrycz's Approach.- 5.3.3 Buckley's Approach.- 5.4 Fuzzy Conjunctive/Disjunctive Method.- 5.4.1 Dubois, Prade, and Testemale's Approach.- 5.5 Heuristic MAUF Approach.- 5.6 Negi's Approach.- 5.7 Fuzzy Outranking Methods.- 5.7.1 Roy's Approach.- 5.7.2 Siskos et al.'s Approach.- 5.7.3 Brans et al.'s Approach.- 5.7.4 Takeda's Approach.- 5.8 Maximin Methods.- 5.8.1 Gellman and Zadeh's Approach.- 5.8.2 Yager's Approach.- 5.9 A New Approach to Fuzzy MADM Problems.- 5.9.1 Converting Linguistic Terms to Fuzzy Numbers.- 5.9.2 Converting Fuzzy Numbers to Crisp Scores.- 5.9.3 The Algorithm.- VI. Concluding Remarks.- 6.1 MADM Problems and Fuzzy Sets.- 6.2 On Existing MADM Solution Methods.- 6.2.1 Classical Methods for MADM Problems.- 6.2.2 Fuzzy Methods for MADM Problems.- 6.2.2.1 Fuzzy Ranking Methods.- 6.2.2.2 Fuzzy MADM Methods.- 6.3 Critiques of the Existing Fuzzy Methods.- 6.3.1 Size of Problem.- 6.3.2 Fuzzy vs. Crisp Data.- 6.4 A New Approach to Fuzzy MADM Problem Solving.- 6.4.1 Semantic Modeling of Linguistic Terms.- 6.4.2 Fuzzy Scoring System.- 6.4.3 The Solution.- 6.4.4 The Advantages of the New Approach.- 6.5 Other Multiple Criteria Decision Making Methods.- 6.5.1 Multiple Objective Decision Making Methods.- 6.5.2 Methods of Group Decision Making under Multiple Criteria.- 6.5.2.1 Social Choice Theory.- 6.5.2.2 Experts Judgement/Group Participation.- 6.5.2.3 Game Theory.- 6.6 On Future Studies.- 6.6.1 Semantics of Linguistic Terms.- 6.6.2 Fuzzy Ranking Methods.- 6.6.3 Fuzzy MADM Methods.- 6.6.4 MADM Expert Decision Support Systems.- VII. Bibliography.","['Mathematics', 'Fuzzy set operations', 'Fuzzy number', 'Fuzzy classification', 'Type-2 fuzzy sets and systems', 'Fuzzy logic', 'Mathematical optimization', 'Fuzzy set', 'Defuzzification', 'Lexicographical order', 'Data mining', 'Artificial intelligence', 'Computer science', 'Combinatorics']","multiple attribute decision making, madm, conjunctive method, disjunctive method, lexico, lexicographic semiorder method, linear assignment method, additive weighting method, topsis, order preference, weighted product method, fuzzy sets, fuzzy sets, fuzzy set, fuzzy sets, fuzzy, fuzzy set, fuzzy, convexity, fuzzy set, normality, fuzzy set, cardinality, fuzzy set, mth power, fuzzy set, fuzzy sets, compensation operators, min operator, algebraic product, bounded product, min operator"
Paper_01938,The Agenda-Setting Function of Mass Media,"['Maxwell McCombs', 'Donald L. Shaw']",1972,Public Opinion Quarterly,Journal,,176-176,36,2,10.1086/267990,"Journal Article THE AGENDA-SETTING FUNCTION OF MASS MEDIA Get access MAXWELL E. McCOMBS, MAXWELL E. McCOMBS associate professor of journalism University of North CarolinaChapel Hill Search for other works by this author on: Oxford Academic Google Scholar DONALD L. SHAW DONALD L. SHAW associate professor of journalism University of North CarolinaChapel Hill Search for other works by this author on: Oxford Academic Google Scholar Public Opinion Quarterly, Volume 36, Issue 2, SUMMER 1972, Pages 176–187, https://doi.org/10.1086/267990 Published: 01 January 1972","['Journalism', 'Function (biology)', 'Media studies', 'Mass media', 'Sociology', 'Political science', 'Law', 'Evolutionary biology', 'Biology']","mass media, oxford, public opinion quarterly"
Paper_01939,"Lung Cancer, Cardiopulmonary Mortality, and Long-term Exposure to Fine Particulate Air Pollution","['C. Arden Pope', 'Richard T. Burnett', 'Michael J. Thun', 'Eugenia E. Calle', 'Daniel Krewski', 'Kazuhiko Ito', 'George Thurston']",2002,JAMA,Journal,,1132-1132,287,9,10.1001/jama.287.9.1132,"ContextAssociations have been found between day-to-day particulate air pollution and increased risk of various adverse health outcomes, including cardiopulmonary mortality. However, studies of health effects of long-term particulate air pollution have been less conclusive.ObjectiveTo assess the relationship between long-term exposure to fine particulate air pollution and all-cause, lung cancer, and cardiopulmonary mortality.Design, Setting, and ParticipantsVital status and cause of death data were collected by the American Cancer Society as part of the Cancer Prevention II study, an ongoing prospective mortality study, which enrolled approximately 1.2 million adults in 1982. Participants completed a questionnaire detailing individual risk factor data (age, sex, race, weight, height, smoking history, education, marital status, diet, alcohol consumption, and occupational exposures). The risk factor data for approximately 500 000 adults were linked with air pollution data for metropolitan areas throughout the United States and combined with vital status and cause of death data through December 31, 1998.Main Outcome MeasureAll-cause, lung cancer, and cardiopulmonary mortality.ResultsFine particulate and sulfur oxide–related pollution were associated with all-cause, lung cancer, and cardiopulmonary mortality. Each 10-µg/m3 elevation in fine particulate air pollution was associated with approximately a 4%, 6%, and 8% increased risk of all-cause, cardiopulmonary, and lung cancer mortality, respectively. Measures of coarse particle fraction and total suspended particles were not consistently associated with mortality.ConclusionLong-term exposure to combustion-related fine particulate air pollution is an important environmental risk factor for cardiopulmonary and lung cancer mortality.","['Medicine', 'Lung cancer', 'Particulates', 'Particulate pollution', 'Environmental health', 'Risk factor', 'Cancer', 'Internal medicine', 'Ecology', 'Biology']","contextass, adverse health outcomes, cardiopulmonary mortality, fine particulate air pollution, cardiopulmonary mortality, american cancer society, cancer prevention, prospective mortality, weight, height, smoking history, education, marital status, alcohol consumption, occupational exposures, metropolitan, vital, lung, cardiopulmonary mortality, sulfur oxide, cardiopulmonary mortality, fine particulate air pollution, lung cancer, coarse particle fraction, total suspended particles, lung cancer mortality"
Paper_01940,Strategic assets and organizational rent,"['Raphael Amit', 'Paul J. H. Schoemaker']",1993,Strategic Management Journal,Journal,,33-46,14,1,10.1002/smj.4250140105,"Abstract We build on an emerging strategy literature that views the firm as a bundle of resources and capabilities, and examine conditions that contribute to the realization of sustainable economic rents. Because of (1) resource‐market imperfections and (2) discretionary managerial decisions about resource development and deployment, we expect firms to differ (in and out of equilibrium) in the resources and capabilities they control. This asymmetry in turn can be a source of sustainable economic rent. The paper focuses on the linkages between the industry analysis framework, the resource‐based view of the firm, behavioral decision biases and organizational implementation issues. It connects the concept of Strategic Industry Factors at the market level with the notion of Strategic Assets at the firm level. Organizational rent is shown to stem from imperfect and discretionary decisions to develop and deploy selected resources and capabilities, made by boundedly rational managers facing high uncertainty, complexity, and intrafirm conflict.","['Economic rent', 'Industrial organization', 'Business', 'Complementary assets', 'Resource (disambiguation)', 'Imperfect', 'Software deployment', 'Resource-based view', 'Microeconomics', 'Economics', 'Strategic management', 'Competitive advantage', 'Marketing', 'Computer science', 'Computer network', 'Linguistics', 'Philosophy', 'Operating system']","strategy, sustainable economic rents, discretionary managerial decisions, resource development, sustainable economic rent, industry analysis framework, behavioral decision biases, organizational implementation, strategic industry factors, strategic assets, organizational rent, ##ly rational managers"
Paper_01941,"Reproduction in Education, Society and Culture","['Michael Erben', 'Pierre Bourdieu', 'Jean-Claude Passeron']",1979,British Journal of Sociology,Journal,,257-257,30,2,10.2307/589547,Preface to the Second Edition - Pierre Bourdieu Foreword - Tom Bottomore PART ONE: FOUNDATIONS OF A THEORY OF SYMBOLIC VIOLENCE PART TWO: KEEPING ORDER Cultural Capital and Pedagogic Communication The Literate Tradition and Social Conservation Exclusion and Selection Dependence through Independence Appendix The Changing Structure of Higher Education Opportunities Redistribution or Translation?,"['Reproduction', 'Sociology', 'Social science', 'Environmental ethics', 'Biology', 'Ecology', 'Philosophy']","symbolic violence, cultural capital, pedagogic communication, literate tradition, social conservation, selection dependence, higher education opportunities, [PAD], [PAD]"
Paper_01945,SLIC Superpixels Compared to State-of-the-Art Superpixel Methods,"['Radhakrishna Achanta', 'Anil Shaji', 'Kevin Smith', 'Aurélien Lucchi', 'Pascal Fua', 'Sabine Süsstrunk']",2012,IEEE Transactions on Pattern Analysis and Machine Intelligence,Journal,,2274-2282,34,11,10.1109/tpami.2012.120,"Computer vision applications have come to rely increasingly on superpixels in recent years, but it is not always clear what constitutes a good superpixel algorithm. In an effort to understand the benefits and drawbacks of existing methods, we empirically compare five state-of-the-art superpixel algorithms for their ability to adhere to image boundaries, speed, memory efficiency, and their impact on segmentation performance. We then introduce a new superpixel algorithm, simple linear iterative clustering (SLIC), which adapts a k-means clustering approach to efficiently generate superpixels. Despite its simplicity, SLIC adheres to boundaries as well as or better than previous methods. At the same time, it is faster and more memory efficient, improves segmentation performance, and is straightforward to extend to supervoxel generation.","['Computer science', 'Cluster analysis', 'Artificial intelligence', 'Segmentation', 'Image segmentation', 'Pattern recognition (psychology)', 'Simplicity', 'Image (mathematics)', 'State (computer science)', 'Algorithm', 'Philosophy', 'Epistemology']","computer vision, superpixels, superpixel algorithm, superpi, ##el algorithms, memory efficiency, segmentation performance, superpi, ##el algorithm, simple linear iterative clustering, slic, slic, segmentation performance, supervoxel generation, [PAD]"
Paper_01949,FaceNet: A unified embedding for face recognition and clustering,"['Florian Schroff', 'Dmitry Kalenichenko', 'James Philbin']",2015,Unknown,Unknown,,815-823,,,10.1109/cvpr.2015.7298682,"Despite significant recent advances in the field of face recognition [10, 14, 15, 17], implementing face verification and recognition efficiently at scale presents serious challenges to current approaches. In this paper we present a system, called FaceNet, that directly learns a mapping from face images to a compact Euclidean space where distances directly correspond to a measure offace similarity. Once this space has been produced, tasks such as face recognition, verification and clustering can be easily implemented using standard techniques with FaceNet embeddings asfeature vectors. Our method uses a deep convolutional network trained to directly optimize the embedding itself, rather than an intermediate bottleneck layer as in previous deep learning approaches. To train, we use triplets of roughly aligned matching / non-matching face patches generated using a novel online triplet mining method. The benefit of our approach is much greater representational efficiency: we achieve state-of-the-artface recognition performance using only 128-bytes perface. On the widely used Labeled Faces in the Wild (LFW) dataset, our system achieves a new record accuracy of 99.63%. On YouTube Faces DB it achieves 95.12%. Our system cuts the error rate in comparison to the best published result [15] by 30% on both datasets.","['Computer science', 'Cluster analysis', 'Facial recognition system', 'Embedding', 'Artificial intelligence', 'Face (sociological concept)', 'Pattern recognition (psychology)', 'Social science', 'Sociology']","face recognition, face verification, recognition, facenet, face images, compact euclidean space, ##ace similarity, face recognition, verification, clustering, face, ##ature vectors, deep convolutional network, deep learning, online triplet mining method, representational efficiency, youtube"
Paper_01951,Determining Validity in Qualitative Inquiry,"['John W. Creswell', 'Dana L. Miller']",2000,Theory Into Practice,Journal,,124-130,39,3,10.1207/s15430421tip3903_2,"(2000). Determining Validity in Qualitative Inquiry. Theory Into Practice: Vol. 39, Getting Good Qualitative Data to Improve Eduational Practice, pp. 124-130.","['Psychology', 'Qualitative research', 'Mathematics education', 'Test validity', 'Pedagogy', 'Sociology', 'Developmental psychology', 'Psychometrics', 'Social science']","validity, qualitative inquiry, theory, qualitative data, eduational practice, [PAD], [PAD] [PAD], [PAD], [PAD] [PAD], [PAD] [PAD], [PAD] [PAD], [PAD] [PAD], [PAD], [PAD], [PAD], [PAD] [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD] [PAD] [PAD], [PAD], [PAD], [PAD] [PAD], [PAD], [PAD] [PAD], [PAD] [PAD], [PAD], [PAD], [PAD] [PAD], [PAD] [PAD] [PAD], [PAD], [PAD], [PAD], [PAD] [PAD] [PAD] [PAD]"
Paper_01952,PD-1 Blockade in Tumors with Mismatch-Repair Deficiency,"['Dung T. Le', 'Jennifer N. Uram', 'Hao Wang', 'Bjarne R. Bartlett', 'Holly Kemberling', 'Aleksandra Eyring', 'Andrew D. Skora', 'Brandon Luber', 'Nilofer S. Azad', 'Dan Laheru', 'Barbara Biedrzycki', 'Ross C. Donehower', 'Atif Zaheer', 'George A. Fisher', 'Todd S. Crocenzi', 'James J. Lee', 'Steven M. Duffy', 'Richard M. Goldberg', 'Albert de la Chapelle', 'Minori Koshiji', 'Feriyl Bhaijee', 'Thomas Huebner', 'Ralph H. Hruban', 'Laura D. Wood', 'Nathan Cuka', 'Drew M. Pardoll', 'Nickolas Papadopoulos', 'Kenneth W. Kinzler', 'Shibin Zhou', 'Toby C. Cornish', 'Janis M. Taube', 'Robert A. Anders', 'James R. Eshleman', 'Bert Vogelstein', 'Luis A. Díaz']",2015,New England Journal of Medicine,Journal,,2509-2520,372,26,10.1056/nejmoa1500596,"Somatic mutations have the potential to encode ""non-self"" immunogenic antigens. We hypothesized that tumors with a large number of somatic mutations due to mismatch-repair defects may be susceptible to immune checkpoint blockade.We conducted a phase 2 study to evaluate the clinical activity of pembrolizumab, an anti-programmed death 1 immune checkpoint inhibitor, in 41 patients with progressive metastatic carcinoma with or without mismatch-repair deficiency. Pembrolizumab was administered intravenously at a dose of 10 mg per kilogram of body weight every 14 days in patients with mismatch repair-deficient colorectal cancers, patients with mismatch repair-proficient colorectal cancers, and patients with mismatch repair-deficient cancers that were not colorectal. The coprimary end points were the immune-related objective response rate and the 20-week immune-related progression-free survival rate.The immune-related objective response rate and immune-related progression-free survival rate were 40% (4 of 10 patients) and 78% (7 of 9 patients), respectively, for mismatch repair-deficient colorectal cancers and 0% (0 of 18 patients) and 11% (2 of 18 patients) for mismatch repair-proficient colorectal cancers. The median progression-free survival and overall survival were not reached in the cohort with mismatch repair-deficient colorectal cancer but were 2.2 and 5.0 months, respectively, in the cohort with mismatch repair-proficient colorectal cancer (hazard ratio for disease progression or death, 0.10 [P<0.001], and hazard ratio for death, 0.22 [P=0.05]). Patients with mismatch repair-deficient noncolorectal cancer had responses similar to those of patients with mismatch repair-deficient colorectal cancer (immune-related objective response rate, 71% [5 of 7 patients]; immune-related progression-free survival rate, 67% [4 of 6 patients]). Whole-exome sequencing revealed a mean of 1782 somatic mutations per tumor in mismatch repair-deficient tumors, as compared with 73 in mismatch repair-proficient tumors (P=0.007), and high somatic mutation loads were associated with prolonged progression-free survival (P=0.02).This study showed that mismatch-repair status predicted clinical benefit of immune checkpoint blockade with pembrolizumab. (Funded by Johns Hopkins University and others; ClinicalTrials.gov number, NCT01876511.).","['Medicine', 'Pembrolizumab', 'DNA mismatch repair', 'Colorectal cancer', 'Hazard ratio', 'Internal medicine', 'Oncology', 'Cancer', 'Immune checkpoint', 'Microsatellite instability', 'Immune system', 'Gastroenterology', 'Immunology', 'Immunotherapy', 'Confidence interval', 'Gene', 'Allele', 'Biochemistry', 'Chemistry', 'Microsatellite']","somatic, immune checkpoint blockade, pembrolizuma"
Paper_01953,Interpreting chromosomal DNA restriction patterns produced by pulsed-field gel electrophoresis: criteria for bacterial strain typing,"['Fred C. Tenover', 'R D Arbeit', 'Richard V. Goering', 'P A Mickelsen', 'Barbara E. Murray', 'David H. Persing', 'Bala Swaminathan']",1995,Journal of Clinical Microbiology,Journal,,2233-2239,33,9,10.1128/jcm.33.9.2233-2239.1995,"FRED C. TENOVER,* ROBERT D. ARBEIT, RICHARD V. GOERING, PATRICIA A. MICKELSEN, BARBARA E. MURRAY, DAVID H. PERSING, AND BALA SWAMINATHAN National Center for Infectious Diseases, Centers for Disease Control and Prevention, Atlanta, Georgia 30333; Veterans Affairs Medical Center, Boston, Massachusetts 02130; Creighton University, Omaha, Nebraska 68178; Stanford University Medical Center, Stanford, California 94305; University of Texas Medical School, Houston, Texas 77030; and Mayo Clinic, Rochester, Minnesota 55905","['Atlanta', 'Veterans Affairs', 'Library science', 'Disease control', 'Typing', 'Medical school', 'Gerontology', 'National laboratory', 'Medicine', 'Family medicine', 'Virology', 'Biology', 'Genetics', 'Metropolitan area', 'Medical education', 'Pathology', 'Engineering', 'Computer science', 'Engineering physics', 'Internal medicine']","infectious diseases, veterans affairs medical center, [PAD], [PAD]"
Paper_01954,Aging: A Theory Based on Free Radical and Radiation Chemistry,['Denham Harman'],1956,Journal of Gerontology,Journal,,298-300,11,3,10.1093/geronj/11.3.298,"The phenomenon of growth, decline and death—aging—has been the source of considerable speculation (1, 8, 10). This cycle seems to be a more or less direct function of the metabolic rate and this in turn depends on the species (animal or plant) on which are superimposed the factors of heredity and the effects of the stresses and strains of life—which alter the metabolic activity. The universality of this phenomenon suggests that the reactions which cause it are basically the same in all living things. Viewing this process in the light of present day free radical and radiation chemistry and of radiobiology, it seems possible that one factor in aging may be related to deleterious side attacks of free radicals (which are normally produced in the course of cellular metabolism) on cell constituents.* Irradiation of living things induces mutation, cancer, and aging (9). Inasmuch as these also arise spontaneously in nature, it is natural to inquire if the processes might not be similar. It is believed that one mechanism of irradiation effect is through liberation of OH and HO 2 radicals (12). There is evidence, although indirect, that these two highly active free radicals are produced normally in living systems. In the first place, free radicals are present in living cells; this was recently demonstrated in vivo by a paramagnetic resonance absorption method (3). Further, it was shown that the concentration of free radicals increased with increasing metabolic activity in conformity with the postulates set forth some years ago that free radicals were involved in biologic oxidation-reduction reactions (11, 13). Are some of these free radicals OH and/or HO2, or radicals of a similar high order of reactivity, and where might they arise in the cell? The most likely source of OH and HO2 radicals, at least in the animal cell, would be the interaction of the respiratory enzymes involved",['Chemistry'],"aging, radiation chemistry, radiobiology, free radicals, cellular metabolism, cancer, aging, free radicals, free radicals, paramagnetic resonance absorption method, free, free, respiratory enzymes"
Paper_01955,Psychological Safety and Learning Behavior in Work Teams,['Amy C. Edmondson'],1999,Administrative Science Quarterly,Journal,,350-383,44,2,10.2307/2666999,"This paper presents a model of team learning and tests it in a multimethod field study. It introduces the construct of team psychological safety—a shared belief held by members of a team that the team is safe for interpersonal risk taking—and models the effects of team psychological safety and team efficacy together on learning and performance in organizational work teams. Results of a study of 51 work teams in a manufacturing company, measuring antecedent, process, and outcome variables, show that team psychological safety is associated with learning behavior, but team efficacy is not, when controlling for team psychological safety. As predicted, learning behavior mediates between team psychological safety and team performance. The results support an integrative perspective in which both team structures, such as context support and team leader coaching, and shared beliefs shape team outcomes.","['Psychological safety', 'Team effectiveness', 'Psychology', 'Team learning', 'Team composition', 'Coaching', 'Interpersonal communication', 'Antecedent (behavioral psychology)', 'Applied psychology', 'Context (archaeology)', 'Construct (python library)', 'Teamwork', 'Social psychology', 'Knowledge management', 'Cooperative learning', 'Management', 'Psychotherapist', 'Computer science', 'Teaching method', 'Pedagogy', 'Paleontology', 'Economics', 'Open learning', 'Biology', 'Programming language']","team learning, multimethod field study, team psychological safety, interpersonal risk taking, team psychological safety, team efficacy, organizational work teams, manufacturing company, team psychological safety, learning behavior, team efficacy, learning behavior, team performance, context support, team leader coaching"
Paper_01956,Molecular Mechanisms of Depression: Perspectives on New Treatment Strategies,"['Undine E. Lang', 'Stefan Borgwardt']",2013,Cellular Physiology and Biochemistry,Journal,,761-777,31,6,10.1159/000350094,"Major depressive disorder (MDD) has been associated with adverse medical consequences, including cardiovascular disease and osteoporosis. Patients with MDD may be classified as having melancholic, atypical, or undifferentiated features. The goal of the present study was to assess whether these clinical subtypes of depression have different endocrine and metabolic features and consequently, varying medical outcomes.","['Depression (economics)', 'Major depressive disorder', 'Melancholic depression', 'Disease', 'Medicine', 'Endocrine system', 'Melancholia', 'Osteoporosis', 'Atypical depression', 'Adverse effect', 'Psychiatry', 'Bioinformatics', 'Psychology', 'Internal medicine', 'Clinical psychology', 'Hormone', 'Cognition', 'Biology', 'Economics', 'Macroeconomics']","major depressive disorder, cardiovascular disease, osteoporosis, ##ifferentiated, [PAD] [PAD], [PAD], [PAD], [PAD] [PAD]"
Paper_01958,Acute Respiratory Distress Syndrome,"['Ards Definition Task Force', 'V. Marco Ranieri', 'Gordon D. Rubenfeld', 'Bruce Thompson', 'Niall D. Ferguson', 'Ellen Caldwell', 'Eddy Fan', 'Luigi Camporota', 'Arthur S. Slutsky']",2012,JAMA,Journal,,,307,23,10.1001/jama.2012.5669,"The acute respiratory distress syndrome (ARDS) was defined in 1994 by the American-European Consensus Conference (AECC); since then, issues regarding the reliability and validity of this definition have emerged. Using a consensus process, a panel of experts convened in 2011 (an initiative of the European Society of Intensive Care Medicine endorsed by the American Thoracic Society and the Society of Critical Care Medicine) developed the Berlin Definition, focusing on feasibility, reliability, validity, and objective evaluation of its performance. A draft definition proposed 3 mutually exclusive categories of ARDS based on degree of hypoxemia: mild (200 mm Hg &lt; PaO<sub>2</sub>/FIO<sub>2</sub> ≤ 300 mm Hg), moderate (100 mm Hg &lt; PaO<sub>2</sub>/FIO<sub>2</sub> ≤ 200 mm Hg), and severe (PaO<sub>2</sub>/FIO<sub>2</sub> ≤ 100 mm Hg) and 4 ancillary variables for severe ARDS: radiographic severity, respiratory system compliance (≤40 mL/cm H<sub>2</sub>O), positive end-expiratory pressure (≥10 cm H<sub>2</sub>O), and corrected expired volume per minute (≥10 L/min). The draft Berlin Definition was empirically evaluated using patient-level meta-analysis of 4188 patients with ARDS from 4 multicenter clinical data sets and 269 patients with ARDS from 3 single-center data sets containing physiologic information. The 4 ancillary variables did not contribute to the predictive validity of severe ARDS for mortality and were removed from the definition. Using the Berlin Definition, stages of mild, moderate, and severe ARDS were associated with increased mortality (27%; 95% CI, 24%-30%; 32%; 95% CI, 29%-34%; and 45%; 95% CI, 42%-48%, respectively; P &lt; .001) and increased median duration of mechanical ventilation in survivors (5 days; interquartile [IQR], 2-11; 7 days; IQR, 4-14; and 9 days; IQR, 5-17, respectively; P &lt; .001). Compared with the AECC definition, the final Berlin Definition had better predictive validity for mortality, with an area under the receiver operating curve of 0.577 (95% CI, 0.561-0.593) vs 0.536 (95% CI, 0.520-0.553; P &lt; .001). This updated and revised Berlin Definition for ARDS addresses a number of the limitations of the AECC definition. The approach of combining consensus discussions with empirical evaluation may serve as a model to create more accurate, evidence-based, critical illness syndrome definitions and to better inform clinical care, research, and health services planning.","['Medicine', 'ARDS', 'Acute respiratory distress', 'Hypoxemia', 'Intensive care', 'Intensive care medicine', 'Emergency medicine', 'Internal medicine', 'Lung']","acute respiratory distress syndrome, ar, intensive care medicine, critical care medicine, radiographic severity, respiratory system compliance, ph, ##ive, mechanical ventilation"
Paper_01960,Coordination of groups of mobile autonomous agents using nearest neighbor rules,"['Ali Jadbabaie', 'Jie Lin', 'A. Stephen Morse']",2003,IEEE Transactions on Automatic Control,Journal,,988-1001,48,6,10.1109/tac.2003.812781,"In a recent Physical Review Letters article, Vicsek et al. propose a simple but compelling discrete-time model of n autonomous agents (i.e., points or particles) all moving in the plane with the same speed but with different headings. Each agent's heading is updated using a local rule based on the average of its own heading plus the headings of its ""neighbors."" In their paper, Vicsek et al. provide simulation results which demonstrate that the nearest neighbor rule they are studying can cause all agents to eventually move in the same direction despite the absence of centralized coordination and despite the fact that each agent's set of nearest neighbors change with time as the system evolves. This paper provides a theoretical explanation for this observed behavior. In addition, convergence results are derived for several other similarly inspired models. The Vicsek model proves to be a graphic example of a switched linear system which is stable, but for which there does not exist a common quadratic Lyapunov function.","['Heading (navigation)', 'k-nearest neighbors algorithm', 'Computer science', 'Lyapunov function', 'Convergence (economics)', 'Simple (philosophy)', 'Set (abstract data type)', 'Autonomous agent', 'Plane (geometry)', 'Quadratic equation', 'Function (biology)', 'Multi-agent system', 'Mathematics', 'Artificial intelligence', 'Control theory (sociology)', 'Engineering', 'Control (management)', 'Philosophy', 'Physics', 'Geometry', 'Epistemology', 'Nonlinear system', 'Quantum mechanics', 'Evolutionary biology', 'Economic growth', 'Economics', 'Biology', 'Programming language', 'Aerospace engineering']","physical review, autonomous agents, local rule, nearest neighbor rule, centralized coordination, switched linear system, quadratic lyapunov function, [PAD] [PAD] [PAD] [PAD], [PAD], [PAD], [PAD], [PAD], [PAD]"
Paper_01961,Kinetics of Phase Change. II Transformation-Time Relations for Random Distribution of Nuclei,['Melvin Avrami'],1940,The Journal of Chemical Physics,Journal,,212-224,8,2,10.1063/1.1750631,"Following upon the general theory in Part I, a considerable simplification is here introduced in the treatment of the case where the grain centers of the new phase are randomly distributed. Also, the kinetics of the main types of crystalline growth, such as result in polyhedral, plate-like and lineal grains, are studied. A relation between the actual transformed volume V and a related extended volume V1 ex is derived upon statistical considerations. A rough approximation to this relation is shown to lead, under the proper conditions, to the empirical formula of Austin and Rickett. The exact relation is used to reduce the entire problem to the determination of V1 ex, in terms of which all other quantities are expressed. The approximate treatment of the beginning of transformation in the isokinetic range is shown to lead to the empirical formula of Krainer and to account quantitatively for certain relations observed in recrystallization phenomena. It is shown that the predicted shapes for isothermal transformation-time curves correspond well with the experimental data.","['Statistical physics', 'Isothermal process', 'Transformation (genetics)', 'Mathematics', 'Thermodynamics', 'Range (aeronautics)', 'Kinetics', 'Recrystallization (geology)', 'Phase (matter)', 'Volume (thermodynamics)', 'Mathematical analysis', 'Materials science', 'Physics', 'Chemistry', 'Classical mechanics', 'Geology', 'Quantum mechanics', 'Paleontology', 'Biochemistry', 'Composite material', 'Gene']","grain centers, crystalline growth, lineal grains, isokinetic range, recrystallization phenomena, [PAD], [PAD] [PAD]"
Paper_01964,"Avogadro: an advanced semantic chemical editor, visualization, and analysis platform","['Marcus D. Hanwell', 'Donald Curtis', 'David Lonie', 'Tim Vandermeersch', 'Eva Zurek', 'Geoffrey Hutchison']",2012,Journal of Cheminformatics,Journal,,,4,1,10.1186/1758-2946-4-17,"The Avogadro project has developed an advanced molecule editor and visualizer designed for cross-platform use in computational chemistry, molecular modeling, bioinformatics, materials science, and related areas. It offers flexible, high quality rendering, and a powerful plugin architecture. Typical uses include building molecular structures, formatting input files, and analyzing output of a wide variety of computational chemistry packages. By using the CML file format as its native document type, Avogadro seeks to enhance the semantic accessibility of chemical data types.The work presented here details the Avogadro library, which is a framework providing a code library and application programming interface (API) with three-dimensional visualization capabilities; and has direct applications to research and education in the fields of chemistry, physics, materials science, and biology. The Avogadro application provides a rich graphical interface using dynamically loaded plugins through the library itself. The application and library can each be extended by implementing a plugin module in C++ or Python to explore different visualization techniques, build/manipulate molecular structures, and interact with other programs. We describe some example extensions, one which uses a genetic algorithm to find stable crystal structures, and one which interfaces with the PackMol program to create packed, solvated structures for molecular dynamics simulations. The 1.0 release series of Avogadro is the main focus of the results discussed here.Avogadro offers a semantic chemical builder and platform for visualization and analysis. For users, it offers an easy-to-use builder, integrated support for downloading from common databases such as PubChem and the Protein Data Bank, extracting chemical data from a wide variety of formats, including computational chemistry output, and native, semantic support for the CML file format. For developers, it can be easily extended via a powerful plugin mechanism to support new features in organic chemistry, inorganic complexes, drug design, materials, biomolecules, and simulations. Avogadro is freely available under an open-source license from http://avogadro.openmolecules.net.","['Computer science', 'Visualization', 'Python (programming language)', 'Plug-in', 'Avogadro constant', 'Upload', 'Graphical user interface', 'Molecular graphics', 'PubChem', 'Computational science', 'Programming language', 'Computer graphics', 'World Wide Web', 'Computer graphics (images)', 'Chemistry', 'Data mining', 'Physics', 'Biochemistry', 'Thermodynamics']","avogadro, advanced molecule editor, visualizer, computational chemistry, molecular modeling, bioinformatics, materials science, plugin, computational chemistry, ##l, av, ##dro, semantic accessibility, avogadro, code library, application programming interface, materials science, av, ##dro, genetic algorithm, packmol, molecular dynamics, av, ##dro, av, ##dro, semantic chemical builder, pubchem, protein data bank, organic chemistry, inorganic complexes, drug design, materials, bio, ##s, av, ##dro, openmolecules"
Paper_01965,<scp>genepop</scp>’007: a complete re‐implementation of the <scp>genepop</scp> software for Windows and Linux,['François Rousset'],2007,Molecular Ecology Resources,Journal,,103-106,8,1,10.1111/j.1471-8286.2007.01931.x,"This note summarizes developments of the genepop software since its first description in 1995, and in particular those new to version 4.0: an extended input format, several estimators of neighbourhood size under isolation by distance, new estimators and confidence intervals for null allele frequency, and less important extensions to previous options. genepop now runs under Linux as well as under Windows, and can be entirely controlled by batch calls.","['Biology', 'Estimator', 'Software', 'Operating system', 'Confidence interval', 'Computer science', 'Statistics', 'Mathematics']","genepop, neighbourhood size, isolation, confidence intervals, null allele frequency, genepop, batch calls"
Paper_01967,Financial Intermediation and Delegated Monitoring,['Douglas W. Diamond'],1984,The Review of Economic Studies,Journal,,393-393,51,3,10.2307/2297430,"This paper develops a theory of financial intermediation based on minimizing the cost of monitoring information which is useful for resolving incentive problems between borrowers and lenders. It presents a characterization of the costs of providing incentives for delegated monitoring by a financial intermediary. Diversification within an intermediary serves to reduce these costs, even in a risk neutral economy. The paper presents some more general analysis of the effect of diversification on resolving incentive problems. In the environment assumed in the model, debt contracts with costly bankruptcy are shown to be optimal. The analysis has implications for the portfolio structure and capital structure of intermediaries.","['Financial intermediary', 'Incentive', 'Diversification (marketing strategy)', 'Economics', 'Portfolio', 'Bankruptcy', 'Intermediary', 'Finance', 'Debt', 'Capital structure', 'Intermediation', 'Business', 'Microeconomics', 'Marketing']","financial intermediation, incentive problems, ##d monitoring, financial intermediary, risk neutral, debt contracts, costly bankruptcy, portfolio structure, capital structure"
Paper_01968,Development of a Rating Scale for Primary Depressive Illness,['Max Hamilton'],1967,British Journal of Social and Clinical Psychology,Journal,,278-296,6,4,10.1111/j.2044-8260.1967.tb00530.x,"This is an account of further work on a rating scale for depressive states, including a detailed discussion on the general problems of comparing successive samples from a ‘population’, the meaning of factor scores, and the other results obtained. The intercorrelation matrix of the items of the scale has been factor‐analysed by the method of principal components, which were then given a Varimax rotation. Weights are given for calculating factor scores, both for rotated as well as unrotated factors. The data for 152 men and 120 women having been kept separate, it is possible to compare the two sets of results. The method of using the rating scale is described in detail in relation to the individual items.","['Varimax rotation', 'Rating scale', 'Psychology', 'Scale (ratio)', 'Population', 'Meaning (existential)', 'Statistics', 'Clinical psychology', 'Psychometrics', 'Developmental psychology', 'Mathematics', 'Medicine', 'Cartography', 'Geography', ""Cronbach's alpha"", 'Psychotherapist', 'Environmental health']","rating scale, depressive states, factor scores, intercorrelation matrix, principal components, varimax rotation, factor scores, ##rot, rating scale"
Paper_01969,Generative adversarial networks,"['Ian Goodfellow', 'Jean Pouget-Abadie', 'Mehdi Mirza', 'Bing Xu', 'David Warde-Farley', 'Sherjil Ozair', 'Aaron Courville', 'Yoshua Bengio']",2020,Communications of the ACM,Journal,,139-144,63,11,10.1145/3422622,"Generative adversarial networks are a kind of artificial intelligence algorithm designed to solve the generative modeling problem. The goal of a generative model is to study a collection of training examples and learn the probability distribution that generated them. Generative Adversarial Networks (GANs) are then able to generate more examples from the estimated probability distribution. Generative models based on deep learning are common, but GANs are among the most successful generative models (especially in terms of their ability to generate realistic high-resolution images). GANs have been successfully applied to a wide variety of tasks (mostly in research settings) but continue to present unique challenges and research opportunities because they are based on game theory while most other approaches to generative modeling are based on optimization.","['Generative grammar', 'Computer science', 'Adversarial system', 'Artificial intelligence', 'Generative Design', 'Machine learning', 'Generative model', 'Variety (cybernetics)', 'Generative adversarial network', 'Deep learning', 'Metric (unit)', 'Operations management', 'Economics']","generative adversarial networks, artificial intelligence algorithm, generative modeling problem, training examples, probability distribution, generative adversarial networks, gans, estimated probability distribution, generative models, deep learning, gans, ##s, game theory, optimization"
Paper_01970,Ethnographic Interview,['James P. Spradley'],2017,The SAGE Encyclopedia of Communication Research Methods,Journal,,,,,10.4135/9781483381411.n168,Part I. Ethnographic Research: Ethnography and Culture. Language and Field Work. Informants. Part II. The Developmental Research Sequences: Locating an Informant. Interviewing an Informant. Making an Ethnographic Record. Asking Descriptive Questions. Analyzing Ethnographic Interviews. Making a Domain Analysis. Asking Structural Questions. Making a Taxonomic Analysis. Asking Contrast Questions. Making a Componential Analysis. Discovering Cultural Themes. Writing an Ethnography. Notes. Appendices: A Taxonomy of Ethnographic Questions. Developmental Research Sequence Writing Tasks. The Development Research Sequence Method. Bibliography. Index.,"['Ethnography', 'Interview', 'Taxonomy (biology)', 'Linguistics', 'Sociology', 'Anthropology', 'Participant observation', 'Psychology', 'Biology', 'Philosophy', 'Botany']","ethnographic research, et, ##ography, culture, language, field work, informants, developmental research sequences, descriptive questions, ethnographic interviews, domain analysis, structural, taxonomic analysis, contrast, componential analysis, cultural themes, ##ices, developmental research sequence writing, development research sequence method, bibliography, [PAD] [PAD]"
Paper_01971,Image Super-Resolution Using Deep Convolutional Networks,"['Chao Dong', 'Chen Change Loy', 'Kaiming He', 'Xiaoou Tang']",2015,IEEE Transactions on Pattern Analysis and Machine Intelligence,Journal,,295-307,38,2,10.1109/tpami.2015.2439281,"We propose a deep learning method for single image super-resolution (SR). Our method directly learns an end-to-end mapping between the low/high-resolution images. The mapping is represented as a deep convolutional neural network (CNN) that takes the low-resolution image as the input and outputs the high-resolution one. We further show that traditional sparse-coding-based SR methods can also be viewed as a deep convolutional network. But unlike traditional methods that handle each component separately, our method jointly optimizes all layers. Our deep CNN has a lightweight structure, yet demonstrates state-of-the-art restoration quality, and achieves fast speed for practical on-line usage. We explore different network structures and parameter settings to achieve trade-offs between performance and speed. Moreover, we extend our network to cope with three color channels simultaneously, and show better overall reconstruction quality.","['Computer science', 'Convolutional neural network', 'Artificial intelligence', 'Deep learning', 'Pattern recognition (psychology)', 'Image (mathematics)', 'Coding (social sciences)', 'Superresolution', 'Image resolution', 'Computer vision', 'Mathematics', 'Statistics']","deep learning method, deep convolutional neural network, deep convolutional network, parameter settings, color"
Paper_01972,Metodologi penelitian kualitatif,['Lexy J. Moleong'],2017,Unknown,Unknown,,,,,10.31237/osf.io/jhxuw,"Buku ini disajikan secara gamblang, mulai dari perencanaan, penelitian hingga menyajikan hasil nya pada publik. Penieitian bukan hanya komprehensif tetapi juga oprasional.",['Computer science'],
Paper_01975,Possessions and the Extended Self,['Russell W. Belk'],1988,Journal of Consumer Research,Journal,,139-168,15,2,10.1086/209154,"Abstract Our possessions are a major contributor to and reflection of our identities. A variety of evidence is presented supporting this simple and compelling premise. Related streams of research are identified and drawn upon in developing this concept and implications are derived for consumer behavior. Because the construct of extended self involves consumer behavior rather than buyer behavior, it appears to be a much richer construct than previous formulations positing a relationship between self-concept and consumer brand choice.","['Construct (python library)', 'Premise', 'Variety (cybernetics)', 'Psychology', 'Simple (philosophy)', 'Consumer behaviour', 'Social psychology', 'Marketing', 'Epistemology', 'Business', 'Computer science', 'Philosophy', 'Artificial intelligence', 'Programming language']","consumer behavior, extended self, consumer behavior, buyer behavior, consumer brand choice"
Paper_01976,Parallel Organization of Functionally Segregated Circuits Linking Basal Ganglia and Cortex,"['Garrett E. Alexander', 'Mahlon R. DeLong', 'P L Strick']",1986,Annual Review of Neuroscience,Journal,,357-381,9,1,10.1146/annurev.ne.09.030186.002041,"Information about the basal ganglia has accumulated at a prodigious pace over the past decade, necessitating major revisions in our concepts of the structural and functional organization of these nuclei. From earlier data it had appeared that the basal ganglia served primarily to integrate diverse inputs from the entire cerebral cortex and to funnel these influences, via the ventrolateral thalamus, to the motor cortex (Allen & Tsukahara 1974, Evarts & Thach 1969, Kemp & Powell 1971). In particular, the basal","['Neuroscience', 'Basal ganglia', 'Functional organization', 'Nerve net', 'Cortex (anatomy)', 'Biology', 'Cerebral cortex', 'Indirect pathway of movement', 'Psychology', 'Central nervous system']","basal ganglia, functional organization, basal ganglia, entire cerebral cortex, ventrolateral thalamus, motor cortex, basal"
Paper_01978,"Headache Classification Committee of the International Headache Society (IHS) The International Classification of Headache Disorders, 3rd edition",[],2018,Cephalalgia,Journal,,1-211,38,1,10.1177/0333102417738202,"Free accessAbstractFirst published online January 25, 2018Headache Classification Committee of the International Headache Society (IHS) The International Classification of Headache Disorders, 3rd editionAll Articleshttps://doi.org/10.1177/0333102417738202","['International Classification of Headache Disorders', 'Medicine', 'Headache Disorders', 'Family medicine', 'Psychiatry', 'Migraine']","##ache classification committee, international headache society, i, international classification, headache disorders, [PAD], [PAD]"
Paper_01979,Independent Component Analysis,"['Aapo Hyvärinen', 'Juha Karhunen', 'Erkki Oja']",2004,The MIT Press eBooks,Unknown,,79-110,,,10.7551/mitpress/3717.003.0014,"In this chapter, we discuss a statistical generative model called independent component analysis. It is basically a proper probabilistic formulation of the ideas underpinning sparse coding. It shows how sparse coding can be interpreted as providing a Bayesian prior, and answers some questions which were not properly answered in the sparse coding framework.","['Independent component analysis', 'Component (thermodynamics)', 'Computer science', 'Artificial intelligence', 'Physics', 'Thermodynamics']","statistical generative model, independent component analysis, probabilistic formulation, sparse coding, sparse coding, bayesian prior, sparse coding framework, [PAD], [PAD] [PAD] [PAD] [PAD], [PAD], [PAD], [PAD], [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD], [PAD] [PAD] [PAD], [PAD], [PAD] [PAD], [PAD] [PAD], [PAD], [PAD], [PAD], [PAD] [PAD], [PAD], [PAD] [PAD] [PAD], [PAD], [PAD] [PAD], [PAD] [PAD], [PAD], [PAD], [PAD], [PAD] [PAD] [PAD], [PAD], [PAD], [PAD] [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD], [PAD] [PAD], [PAD] [PAD] [PAD], [PAD] [PAD], [PAD]"
Paper_01981,We Have Never Been Modern,['Tony Crawford'],1994,Configurations,Journal,,578-580,2,3,10.1353/con.1994.0041,"Reviewed by: We Have Never Been Modern T. Hugh Crawford (bio) Bruno Latour, We Have Never Been Modern. Translated by Catherine Porter. Cambridge, Mass: Harvard University Press, 1993. 157 pp. $29.95. In “Postmodernism, or the Cultural Logic of Late Capitalism”—an essay that has become the touchstone for discussions of contemporary cultural periodization—Fredric Jameson argues that the “last few years have been marked by an inverted millenarianism, in which premonitions of the future, catastrophic or redemptive, have been replaced by senses of the end of this or that” (Postmodernism [Durham, N.C.: Duke University Press, 1991], p. 1). The attempt to formulate some break with the immediate past is a characteristic of much contemporary theory, and, given the emergence of various theories of the postmodern at the end of our century, this impulse can be tied to anticipation, however inverted, of the coming millennium. One can approach such an ending with joy, trepidation, or downright cynicism, seeking in the new era either a complete rupture with the past or some lines of continuity. Bruno Latour’s We Have Never Been Modern takes the latter strategy, arguing that we are not moving into a radically new age configured by the trappings of postmodern techno-gadgetry and the philosophy of the simulacrum, nor do we have need to remain trapped in the hegemonic structures of the modern era. Instead, this state of affairs can be avoided through the simple recognition that, indeed, we have never been modern: the repertoire of modern critical analysis has always been internally inconsistent if not outright contradictory, and, more importantly, we have always been at home in the nonmodern world, living comfortably with hybrid combinations of natural and social objects/subjects. Latour developed the basis of this argument through his empirical laboratory studies (Laboratory Life, The Pasteurization of France), where he discovered that nothing particularly different from everyday life takes place within the laboratory. He argues that if there has never been such a thing as scientific reasoning (characterized by the production of sleek, ahuman technological systems and universal natural truths), then we have never actually attained modernity—let alone postmodernity, a concept Latour regards with disdain, noting that it is “a symptom, not a fresh solution” (p. 46) because the postmoderns “accept the total division between the material and technological world on the one hand and the linguistic play of speaking subjects on the other” (p. 61). His position regarding scientific reasoning finds partial support from the strong programme of the Edinburgh school. The principle of symmetry—that scientific successes as well as failures must have social explanations—helped demystify scientific knowledge; however, Latour advocates a generalized principle of symmetry, which requires both a natural and a social explanation for laboratory successes and failures. Indeed, if one were to follow out his program to its conclusion, those distinctions would become impossible to maintain, and we would recognize that we have never been modern. Latour’s definition of modernity is both simple and profound. He locates its roots in the time of Hobbes and Boyle, using Stephen Shapin and Simon Schaffer’s Leviathan and the Air-Pump as his primary example of (almost successful) [End Page 578] anthropology of science. The modern world emerged when the domain of knowledge was split between knowledge of people (Hobbes and politics) and knowledge of things (Boyle and science): “[The moderns] have cut the Gordian knot with a well-honed sword. The shaft is broken: on the left, they have put knowledge things; on the right, power and human politics” (p. 3). Latour argues that this is an impoverished model: neither natural objects nor social subjects have ever been simply real, social, or discursive. Instead, they are hybrids circulating in networks of translation and mediation while the moderns busily attempt to purify them of their hybrid qualities and locate them on one end or the other of the subject/object pole. From this perspective, current disciplines are both the cause and the symptom of the modern mind, and Latour has written the manifesto for the interdisciplinarians who must stop worrying over metaphysics and practice “infraphysics” (p. 128). In one swift move, the realist/constructivist debate is rendered uninteresting, the...","['Postmodernism', 'Simulacrum', 'Millenarianism', 'End of history', 'Late capitalism', 'Postmodernity', 'Philosophy', 'Hegemony', 'Aesthetics', 'Modernity', 'Classicism', 'Literature', 'History', 'Art history', 'Epistemology', 'Art', 'Law', 'Politics', 'Political science']","postmodernism, cultural logic, late capitalism, cultural periodization, ##rian, postmodernism, ##nicism, ##modern, empirical, laboratory life, pasteurization, everyday life, scientific reasoning, universal natural truths, ##mo, ##ity"
Paper_01982,Data Structures for Statistical Computing in Python,['Wes McKinney'],2010,Proceedings of the Python in Science Conferences,Journal,,56-61,,,10.25080/majora-92bf1922-00a,"In this paper we are concerned with the practical issues of working with data sets common to finance, statistics, and other related fields. pandas is a new library which aims to facilitate working with these data sets and to provide a set of fundamental building blocks for implementing statistical models. We will discuss specific design issues encountered in the course of developing pandas with relevant examples and some comparisons with the R language. We conclude by discussing possible future directions for statistical computing and data analysis using Python.","['Python (programming language)', 'Computer science', 'Data science', 'Data exploration', 'Statistical analysis', 'Data structure', 'Computational statistics', 'Theoretical computer science', 'Data mining', 'Software engineering', 'Programming language', 'Machine learning', 'Statistics', 'Visualization', 'Mathematics']","data sets, finance, statistics, pandas, statistical models, pandas, r, statistical computing, data analysis, python"
Paper_01984,Computed Tomography — An Increasing Source of Radiation Exposure,"['David J. Brenner', 'Eric J. Hall']",2007,New England Journal of Medicine,Journal,,2277-2284,357,22,10.1056/nejmra072149,"The number of computed tomographic (CT) studies performed is increasing rapidly. Because CT scans involve much higher doses of radiation than plain films, we are seeing a marked increase in radiation exposure in the general population. Epidemiologic studies indicate that the radiation dose from even two or three CT scans results in a detectable increase in the risk of cancer, especially in children. This article summarizes the facts about this form of radiation exposure and the implications for public health.","['Medicine', 'Radiation exposure', 'Computed tomography', 'Computed tomographic', 'Radiation dose', 'Radiation', 'Nuclear medicine', 'Population', 'Radiology', 'Environmental health', 'Optics', 'Physics']","computed tom, plain films, epidemi, radiation exposure, public health"
Paper_01985,Corruption and Growth,['Paolo Mauro'],1995,The Quarterly Journal of Economics,Journal,,681-712,110,3,10.2307/2946696,"This paper analyzes a newly assembled data set consisting of subjective indices of corruption, the amount of red tape, the efficiency of the judicial system, and various categories of political stability for a cross section of countries. Corruption is found to lower investment, thereby lowering economic growth. The results are robust to controlling for endogeneity by using an index of ethnolinguistic fractionalization as an instrument.","['Language change', 'Political science', 'Philosophy', 'Linguistics']","subjective indices, corruption, judicial system, political stability, corruption, economic growth, endogeneity, ethnolinguistic fractionalization, [PAD]"
Paper_01986,Principal component analysis,"['Hervé Abdi', 'Lynne J. Williams']",2010,Wiley Interdisciplinary Reviews Computational Statistics,Journal,,433-459,2,4,10.1002/wics.101,"Abstract Principal component analysis (PCA) is a multivariate technique that analyzes a data table in which observations are described by several inter‐correlated quantitative dependent variables. Its goal is to extract the important information from the table, to represent it as a set of new orthogonal variables called principal components, and to display the pattern of similarity of the observations and of the variables as points in maps. The quality of the PCA model can be evaluated using cross‐validation techniques such as the bootstrap and the jackknife. PCA can be generalized as correspondence analysis (CA) in order to handle qualitative variables and as multiple factor analysis (MFA) in order to handle heterogeneous sets of variables. Mathematically, PCA depends upon the eigen‐decomposition of positive semi‐definite matrices and upon the singular value decomposition (SVD) of rectangular matrices. Copyright © 2010 John Wiley &amp; Sons, Inc. This article is categorized under: Statistical and Graphical Methods of Data Analysis &gt; Multivariate Analysis Statistical and Graphical Methods of Data Analysis &gt; Dimension Reduction","['Principal component analysis', 'Singular value decomposition', 'Correspondence analysis', 'Dimensionality reduction', 'Jackknife resampling', 'Multiple correspondence analysis', 'Mathematics', 'Multivariate statistics', 'Dimension (graph theory)', 'Sparse PCA', 'Table (database)', 'Similarity (geometry)', 'Data set', 'Computer science', 'Statistics', 'Pattern recognition (psychology)', 'Data mining', 'Artificial intelligence', 'Algorithm', 'Combinatorics', 'Estimator', 'Image (mathematics)']","abstract principal component analysis, multivariate technique, data table, quantitative dependent variables, orthogonal variables, principal components, cross ‐ validation, bootstrap, jackk, ##fe, ##a, correspondence analysis, qualitative, multiple factor analysis, ##gen, eigen ‐ decomposition, positive semi, singular value decomposition, rectangular matrices, graphical methods, data analysis, multivariate analysis, graphical methods, data analysis, dimension reduction"
Paper_01987,Collinearity: a review of methods to deal with it and a simulation study evaluating their performance,"['Carsten F. Dormann', 'Jane Elith', 'Sven Bacher', 'Carsten M. Buchmann', 'Gudrun Carl', 'Gabriel Carré', 'Jaime Márquez', 'Bernd Gruber', 'Bruno Lafourcade', 'Pedro J. Leitão', 'Tamara Münkemüller', 'Colin J. McClean', 'Patrick E. Osborne', 'Björn Reineking', 'Boris Schröder', 'Andrew K. Skidmore', 'Damaris Zurell', 'Sven Lautenbach']",2012,Ecography,Journal,,27-46,36,1,10.1111/j.1600-0587.2012.07348.x,"Collinearity refers to the non independence of predictor variables, usually in a regression‐type analysis. It is a common feature of any descriptive ecological data set and can be a problem for parameter estimation because it inflates the variance of regression parameters and hence potentially leads to the wrong identification of relevant predictors in a statistical model. Collinearity is a severe problem when a model is trained on data from one region or time, and predicted to another with a different or unknown structure of collinearity. To demonstrate the reach of the problem of collinearity in ecology, we show how relationships among predictors differ between biomes, change over spatial scales and through time. Across disciplines, different approaches to addressing collinearity problems have been developed, ranging from clustering of predictors, threshold‐based pre‐selection, through latent variable methods, to shrinkage and regularisation. Using simulated data with five predictor‐response relationships of increasing complexity and eight levels of collinearity we compared ways to address collinearity with standard multiple regression and machine‐learning approaches. We assessed the performance of each approach by testing its impact on prediction to new data. In the extreme, we tested whether the methods were able to identify the true underlying relationship in a training dataset with strong collinearity by evaluating its performance on a test dataset without any collinearity. We found that methods specifically designed for collinearity, such as latent variable methods and tree based models, did not outperform the traditional GLM and threshold‐based pre‐selection. Our results highlight the value of GLM in combination with penalised methods (particularly ridge) and threshold‐based pre‐selection when omitted variables are considered in the final interpretation. However, all approaches tested yielded degraded predictions under change in collinearity structure and the ‘folk lore’‐thresholds of correlation coefficients between predictor variables of |r| &gt;0.7 was an appropriate indicator for when collinearity begins to severely distort model estimation and subsequent prediction. The use of ecological understanding of the system in pre‐analysis variable selection and the choice of the least sensitive statistical approaches reduce the problems of collinearity, but cannot ultimately solve them.","['Collinearity', 'Statistics', 'Feature selection', 'Computer science', 'Bivariate analysis', 'Latent variable', 'Lasso (programming language)', 'Categorical variable', 'Linear regression', 'Regression analysis', 'Econometrics', 'Mathematics', 'Machine learning', 'World Wide Web']","collinearity, non independence, predictor variables, descriptive ecological data set, parameter estimation, statistical model, collinearity, ##ity, collinearity, predict, collinearity, clustering, threshold ‐, latent variable methods, shrinkage, regularisation, collinearity, collin, ##ity, machine ‐ learning, collin, ##ity, latent variable methods, tree based models, glm, penal, collinearity structure, folk lore, correlation coefficients, predict, collinearity, ecological understanding, pre ‐ analysis variable selection, collin, ##ity"
Paper_01988,Comprehensive Mapping of Long-Range Interactions Reveals Folding Principles of the Human Genome,"['Erez Lieberman-Aiden', 'Nynke L. van Berkum', 'Louise Williams', 'Maxim Imakaev', 'Tobias Ragoczy', 'Agnes Telling', 'Ido Amit', 'Bryan R. Lajoie', 'Peter J. Sabo', 'Michael O. Dorschner', 'Richard Sandstrom', 'B Bernstein', 'M. A. Bender', 'Mark Groudine', 'Andreas Gnirke', 'J Stamatoyannopoulos', 'Leonid A. Mirny', 'Eric S. Lander', 'Job Dekker']",2009,Science,Journal,,289-293,326,5950,10.1126/science.1181369,"We describe Hi-C, a method that probes the three-dimensional architecture of whole genomes by coupling proximity-based ligation with massively parallel sequencing. We constructed spatial proximity maps of the human genome with Hi-C at a resolution of 1 megabase. These maps confirm the presence of chromosome territories and the spatial proximity of small, gene-rich chromosomes. We identified an additional level of genome organization that is characterized by the spatial segregation of open and closed chromatin to form two genome-wide compartments. At the megabase scale, the chromatin conformation is consistent with a fractal globule, a knot-free, polymer conformation that enables maximally dense packing while preserving the ability to easily fold and unfold any genomic locus. The fractal globule is distinct from the more commonly used globular equilibrium model. Our results demonstrate the power of Hi-C to map the dynamic conformations of whole genomes.","['Genome', 'Chromosome conformation capture', 'Biology', 'Chromatin', 'Fractal', 'Human genome', 'Computational biology', 'Locus (genetics)', 'Evolutionary biology', 'Genetics', 'Gene', 'Enhancer', 'Mathematical analysis', 'Mathematics', 'Gene expression']","whole genomes, massively parallel sequencing, spatial proximity maps, human genome, chromosome territories, spatial, spatial segregation, ##atin, fractal globule, maximal, fractal globule, globular equilibrium model, dynamic conformations, [PAD] [PAD], [PAD], [PAD], [PAD], [PAD] [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD], [PAD]"
Paper_01989,Architectural Innovation: The Reconfiguration of Existing Product Technologies and the Failure of Established Firms,"['Rebecca Henderson', 'Kim B. Clark']",1990,Administrative Science Quarterly,Journal,,9-9,35,1,10.2307/2393549,"ThP tiaditinn-Tl catPgori ?:ation nf innovation as t^ithpr ""inrrpnipntal "" or ""radical"" is incomplete and fundanient al ly inisl eadi ng .""Generational"" innovation - innovation that reconfigures a technical system without changing its elements -i^; qualitatively different from both incremental and radical innovation and often ha< important and unexpected organisational and competitive consequences.This paper defines generational innovation and illustrates the concept's explanatory force through an empirical study of the technical and competitive history of the semiconductor photolithographic alignment equipment industry.","['Control reconfiguration', 'Business', 'Product (mathematics)', 'Industrial organization', 'Process management', 'Knowledge management', 'Engineering', 'Computer science', 'Geometry', 'Mathematics', 'Embedded system']","generational innovation, semiconductor photolithographic alignment equipment industry"
Paper_01991,"Agendas, alternatives, and public policies",['John W. Kingdon'],1984,['Journal of Policy Analysis and Management'],Unknown,,621,4,4,10.2307/3323801,"1. How Does an Idea's Time Come? 2. Participants on the Inside of Government 3. Outside of Government, But Not Just Looking In 4. Processes: Origins, Rationality, Incrementalism, and Garbage Cans 5. Problems 6. The Policy Primeval Soup 7. The Political Stream 8. The Policy Window, and Joining the Streams 9. Wrapping Things Up 10. Some Further Reflections: New Case Studies Thoughts About the Modeling Appendix on Methods: The Interviews Coding Case Studies Noninterview Measures of Agenda Status.","['Incrementalism', 'Government (linguistics)', 'Politics', 'Public policy', 'Garbage', 'Rationality', 'Public administration', 'Coding (social sciences)', 'Political science', 'Sociology', 'Social science', 'Law', 'Engineering', 'Philosophy', 'Linguistics', 'Waste management']","origins, rationality, incrementalism, garbage cans, policy primeval soup, political stream, policy window, interviews coding, ##erview measures, agenda status"
Paper_01996,Economic Growth and Income Inequality,['Simon Kuznets'],2019,Routledge eBooks,Unknown,,25-37,,,10.4324/9780429311208-4,The process of industrialization engenders increasing income inequality as the labor force shifts from low-income agriculture to the high income sectors. On more advanced levels of development inequality starts decreasing and industrialized countries are again characterized by low inequality due to the smaller weight of agriculture in production (and income generation).,"['Economic inequality', 'Economics', 'Inequality', 'Development economics', 'Demographic economics', 'Mathematics', 'Mathematical analysis']","industrial, income inequality, industrial, income generation, [PAD], [PAD], [PAD], [PAD], [PAD]"
Paper_01997,Visible Light Photoredox Catalysis with Transition Metal Complexes: Applications in Organic Synthesis,"['Christopher K. Prier', 'Danica A. Rankic', 'David W. C. MacMillan']",2013,Chemical Reviews,Journal,,5322-5363,113,7,10.1021/cr300503r,"ADVERTISEMENT RETURN TO ISSUEPREVReviewNEXTVisible Light Photoredox Catalysis with Transition Metal Complexes: Applications in Organic SynthesisChristopher K. Prier, Danica A. Rankic, and David W. C. MacMillan*View Author Information Merck Center for Catalysis at Princeton University, Princeton, New Jersey 08544, United States*E-mail: [email protected]Cite this: Chem. Rev. 2013, 113, 7, 5322–5363Publication Date (Web):March 19, 2013Publication History Received14 December 2012Published online19 March 2013Published inissue 10 July 2013https://pubs.acs.org/doi/10.1021/cr300503rhttps://doi.org/10.1021/cr300503rreview-articleACS PublicationsCopyright © 2013 American Chemical SocietyRequest reuse permissionsArticle Views169398Altmetric-Citations7277LEARN ABOUT THESE METRICSArticle Views are the COUNTER-compliant sum of full text article downloads since November 2008 (both PDF and HTML) across all institutions and individuals. These metrics are regularly updated to reflect usage leading up to the last few days.Citations are the number of other articles citing this article, calculated by Crossref and updated daily. Find more information about Crossref citation counts.The Altmetric Attention Score is a quantitative measure of the attention that a research article has received online. Clicking on the donut icon will load a page at altmetric.com with additional details about the score and the social media presence for the given article. Find more information on the Altmetric Attention Score and how the score is calculated. Share Add toView InAdd Full Text with ReferenceAdd Description ExportRISCitationCitation and abstractCitation and referencesMore Options Share onFacebookTwitterWechatLinked InRedditEmail Other access optionsGet e-Alertsclose SUBJECTS:Addition reactions,Anions,Catalysis,Photocatalysts,Redox reactions Get e-Alerts","['Citation', 'Altmetrics', 'Computer science', 'Chemistry', 'Nanotechnology', 'Library science', 'World Wide Web', 'Materials science']","##visible light, ##x catalysis, transition metal complexes, organic synthesis, altmetric attention score, ##ut, alt, altmetric attention score, abstract, addition reactions, anions, catalysis, photocatalysts, redox reactions"
Paper_01999,Introduction to Statistical Quality Control,"['Roger Sauter', 'Douglas C. Montgomery']",1992,Technometrics,Journal,,232-232,34,2,10.2307/1269251,Quality Improvement in the Modern Business Environment.STAISTICAL METHODS USEFUL IN QUALITY IMPROVEMENT.Modeling Process Quality.Inferences About Process Quality.BASIC METHODS OF STATISTICAL PROCESS CONTROL AND CAPABILITY ANALYSIS.Methods and Philosophy of Statistical Process Control.Control Charts for Variables.Control Charts for Attributes.Process and Measurement Systems System Capability Analysis.OTHER STATISTICAL PROCESS MONITORING AND CONTROL TECHNIQUES.Cumulative Sum and Exponentially Weighted Moving Average Control Charts.Other Univariate SPC Techniques.Multivariate Process Monitoring and Control.Engineering Process Control and SPC.PROCESS DESIGN AND IMPROVEMENT WITH DESIGNED EXPERIMENTS.Factorial and Fractional Factorial Designs for Process Design and Improvement.Process Optimization with Designed Experiments.ACCEPTANCE SAMPLING.Lot--by--Lot Acceptance Sampling for Attributes.Other Acceptance Sampling Techniques.Appendix.Bibliography.Answers to Selected Exercises.Index.,"['Quality (philosophy)', 'Statistical process control', 'Statistics', 'Control (management)', 'Computer science', 'Mathematics', 'Artificial intelligence', 'Physics', 'Process (computing)', 'Operating system', 'Quantum mechanics']","quality improvement, business, staistical methods, quality improvement, process quality, statistical process control, capability analysis, statistical process control, control charts, control charts, statistical process monitoring, cumulative sum, exponentially weighted moving average control charts, univariate, multivariate process monitoring, engineering process control, process optimization, acceptance sampling, acceptance sampling, acceptance sampling"
Paper_02000,Quantum Fields in Curved Space,"['N. D. Birrell', 'P. C. W. Davies']",1982,Unknown,Unknown,,,,,10.1017/cbo9780511622632,"This book presents a comprehensive review of the subject of gravitational effects in quantum field theory. Although the treatment is general, special emphasis is given to the Hawking black hole evaporation effect, and to particle creation processes in the early universe. The last decade has witnessed a phenomenal growth in this subject. This is the first attempt to collect and unify the vast literature that has contributed to this development. All the major technical results are presented, and the theory is developed carefully from first principles. Here is everything that students or researchers will need to embark upon calculations involving quantum effects of gravity at the so-called one-loop approximation level.","['Hawking', 'Theoretical physics', 'Subject (documents)', 'Quantum gravity', 'Quantum field theory', 'Physics', 'Gravitation', 'Space (punctuation)', 'Field (mathematics)', 'Quantum', 'Loop quantum gravity', 'Spacetime', 'Universe', 'Computer science', 'Classical mechanics', 'Quantum mechanics', 'Mathematics', 'Library science', 'Pure mathematics', 'Operating system']","gravitational effects, quantum field theory, hawking black hole evaporation effect, particle creation processes, quantum effects of gravity, [PAD], [PAD] [PAD]"
Paper_02001,Application of Phylogenetic Networks in Evolutionary Studies,"['Daniel H. Huson', 'David Bryant']",2005,Molecular Biology and Evolution,Journal,,254-267,23,2,10.1093/molbev/msj030,"The evolutionary history of a set of taxa is usually represented by a phylogenetic tree, and this model has greatly facilitated the discussion and testing of hypotheses. However, it is well known that more complex evolutionary scenarios are poorly described by such models. Further, even when evolution proceeds in a tree-like manner, analysis of the data may not be best served by using methods that enforce a tree structure but rather by a richer visualization of the data to evaluate its properties, at least as an essential first step. Thus, phylogenetic networks should be employed when reticulate events such as hybridization, horizontal gene transfer, recombination, or gene duplication and loss are believed to be involved, and, even in the absence of such events, phylogenetic networks have a useful role to play. This article reviews the terminology used for phylogenetic networks and covers both split networks and reticulate networks, how they are defined, and how they can be interpreted. Additionally, the article outlines the beginnings of a comprehensive statistical framework for applying split network methods. We show how split networks can represent confidence sets of trees and introduce a conservative statistical test for whether the conflicting signal in a network is treelike. Finally, this article describes a new program, SplitsTree4, an interactive and comprehensive tool for inferring different types of phylogenetic networks from sequences, distances, and trees.","['Phylogenetic network', 'Phylogenetic tree', 'Reticulate', 'Reticulate evolution', 'Biology', 'Tree (set theory)', 'Phylogenetics', 'Evolutionary biology', 'Terminology', 'Set (abstract data type)', 'Computational phylogenetics', 'Tree of life (biology)', 'Phylogenetic comparative methods', 'Horizontal gene transfer', 'Taxon', 'Computer science', 'Gene', 'Genetics', 'Paleontology', 'Mathematics', 'Mathematical analysis', 'Linguistics', 'Philosophy', 'Programming language']","evolutionary history, phylogenetic tree, phylogenetic networks, retic, hybridization, horizontal gene transfer, recombination, gene duplication, phylogenetic networks, phylogenetic networks, split networks, reticulate networks, statistical framework, split network methods, split networks, conservative statistical test, splitstree, phylogenetic networks"
Paper_02002,Scheduling Algorithms for Multiprogramming in a Hard-Real-Time Environment,"['C. L. Liu', 'J. W. Layland']",1973,Journal of the ACM,Journal,,46-61,20,1,10.1145/321738.321743,The problem of multiprogram scheduling on a single processor is studied from the viewpoint of the characteristics peculiar to the program functions that need guaranteed service. It is shown that an optimum fixed priority scheduler possesses an upper bound to processor utilization which may be as low as 70 percent for large task sets. It is also shown that full processor utilization can be achieved by dynamically assigning priorities on the basis of their current deadlines. A combination of these two scheduling techniques is also discussed.,"['Computer multitasking', 'Computer science', 'Scheduling (production processes)', 'Fixed-priority pre-emptive scheduling', 'Earliest deadline first scheduling', 'Parallel computing', 'Fair-share scheduling', 'Distributed computing', 'Dynamic priority scheduling', 'Rate-monotonic scheduling', 'Algorithm', 'Real-time computing', 'Quality of service', 'Mathematical optimization', 'Computer network', 'Mathematics']","multiprogram scheduling, program functions, guaranteed service, optimum fixed priority scheduler, processor utilization, full processor utilization, [PAD], [PAD], [PAD], [PAD], [PAD] [PAD] [PAD], [PAD]"
Paper_02003,Selective gas adsorption and separation in metal–organic frameworks,"['Jian‐Rong Li', 'Ryan J. Kuppler', 'Hong‐Cai Zhou']",2009,Chemical Society Reviews,Journal,,1477-1477,38,5,10.1039/b802426j,"Adsorptive separation is very important in industry. Generally, the process uses porous solid materials such as zeolites, activated carbons, or silica gels as adsorbents. With an ever increasing need for a more efficient, energy-saving, and environmentally benign procedure for gas separation, adsorbents with tailored structures and tunable surface properties must be found. Metal-organic frameworks (MOFs), constructed by metal-containing nodes connected by organic bridges, are such a new type of porous materials. They are promising candidates as adsorbents for gas separations due to their large surface areas, adjustable pore sizes and controllable properties, as well as acceptable thermal stability. This critical review starts with a brief introduction to gas separation and purification based on selective adsorption, followed by a review of gas selective adsorption in rigid and flexible MOFs. Based on possible mechanisms, selective adsorptions observed in MOFs are classified, and primary relationships between adsorption properties and framework features are analyzed. As a specific example of tailor-made MOFs, mesh-adjustable molecular sieves are emphasized and the underlying working mechanism elucidated. In addition to the experimental aspect, theoretical investigations from adsorption equilibrium to diffusion dynamics via molecular simulations are also briefly reviewed. Furthermore, gas separations in MOFs, including the molecular sieving effect, kinetic separation, the quantum sieving effect for H2/D2 separation, and MOF-based membranes are also summarized (227 references).","['Adsorption', 'Gas separation', 'Metal-organic framework', 'Molecular sieve', 'Porosity', 'Selective adsorption', 'Porous medium', 'Chemical engineering', 'Nanotechnology', 'Materials science', 'Chemistry', 'Membrane', 'Organic chemistry', 'Biochemistry', 'Engineering']","adsorptive separation, porous solid materials, zeolites, activated carbons, silica gels, gas separation, tailored, tunable surface properties, organic bridges, gas separation, thermal stability, gas separation, selective adsorption, gas selective adsorption, flexible mofs, selective adsorptions, ##fs, adsorption equilibrium, diffusion dynamics, molecular simulations, gas separations, ##fs, molecular sieving effect, kinetic separation, quantum sieving effect"
Paper_02004,Innate Immune Recognition,"['Charles A. Janeway', 'Ruslan Medzhitov']",2002,Annual Review of Immunology,Journal,,197-216,20,1,10.1146/annurev.immunol.20.083001.084359,"The innate immune system is a universal and ancient form of host defense against infection. Innate immune recognition relies on a limited number of germline-encoded receptors. These receptors evolved to recognize conserved products of microbial metabolism produced by microbial pathogens, but not by the host. Recognition of these molecular structures allows the immune system to distinguish infectious nonself from noninfectious self. Toll-like receptors play a major role in pathogen recognition and initiation of inflammatory and immune responses. Stimulation of Toll-like receptors by microbial products leads to the activation of signaling pathways that result in the induction of antimicrobial genes and inflammatory cytokines. In addition, stimulation of Toll-like receptors triggers dendritic cell maturation and results in the induction of costimulatory molecules and increased antigen-presenting capacity. Thus, microbial recognition by Toll-like receptors helps to direct adaptive immune responses to antigens derived from microbial pathogens.","['Biology', 'Pattern recognition receptor', 'Innate immune system', 'Immune system', 'Immune receptor', 'Receptor', 'Acquired immune system', 'Pathogen-associated molecular pattern', 'Immunology', 'Toll-like receptor', 'Cell biology', 'Genetics']","innate immune system, host defense, innate immune recognition, microbial metabolism, micro, pathogen recognition, inflammatory cytokines, dendritic cell maturation, cost, microbial recognition, adaptive immune responses"
Paper_02006,CANOCO Reference Manual and CanoDraw for Windows User's Guide: Software for Canonical Community Ordination (version 4.5),"['Cajo J. F. ter Braak', 'Petr Šmilauer']",2002,Unknown,Unknown,,,,,10.21236/ada417320,"Canoco is a software package for multivariate data analysis, with an emphasis on dimesional reduction (ordination), regression analysis, and the combination of the two, constrained ordination. Canoco makes effective and powerful ordination methods easilyt accessible for scientists wanting to infer and visualize pattern and structure in complex multivariate data, e.g. biologists researching the relations between plant and animal communities and their environment. Canoco contains linear and unimodal ordination methods, with the possibility to account for background variation specified by covariates. In combination with extensive facilities for permutation tests, these methods have proven to be remarkably effective in solving applied research problems.","['Ordination', 'Multivariate statistics', 'Software', 'Computer science', 'Permutation (music)', 'Data mining', 'Multivariate analysis', 'Machine learning', 'Programming language', 'Physics', 'Acoustics']","canoco, multivariate data analysis, dimesional reduction, ordination, regression analysis, constrained ordination, canoco, canoco, unimodal ordination, background variation, covariates, permutation tests, [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD], [PAD], [PAD], [PAD]"
Paper_02008,<tt>BLAT</tt>—The <tt>BLAST</tt>-Like Alignment Tool,['W. James Kent'],2002,Genome Research,Journal,,656-664,12,4,10.1101/gr.229202,"Analyzing vertebrate genomes requires rapid mRNA/DNA and cross-species protein alignments. A new tool, BLAT, is more accurate and 500 times faster than popular existing tools for mRNA/DNA alignments and 50 times faster for protein alignments at sensitivity settings typically used when comparing vertebrate sequences. BLAT's speed stems from an index of all nonoverlapping K-mers in the genome. This index fits inside the RAM of inexpensive computers, and need only be computed once for each genome assembly. BLAT has several major stages. It uses the index to find regions in the genome likely to be homologous to the query sequence. It performs an alignment between homologous regions. It stitches together these aligned regions (often exons) into larger alignments (typically genes). Finally, BLAT revisits small internal exons possibly missed at the first stage and adjusts large gap boundaries that have canonical splice sites where feasible. This paper describes how BLAT was optimized. Effects on speed and sensitivity are explored for various K-mer sizes, mismatch schemes, and number of required index matches. BLAT is compared with other alignment programs on various test sets and then used in several genome-wide applications. http://genome.ucsc.edu hosts a web-based BLAT server for the human genome.","['Genome', 'Biology', 'Sequence alignment', 'Genome browser', 'Computational biology', 'Human genome', 'Exon', 'Genetics', 'Reference genome', 'Computer science', 'Genomics', 'Gene', 'Peptide sequence']","##rtebrate genomes, blat, protein alignments, ##lat, ##lat, ##lat, canonical, ##lat, ##ch, ##lat"
Paper_02009,Compendium of Physical Activities: an update of activity codes and MET intensities,"['Barbara E. Ainsworth', 'William L. Haskell', 'Melicia C. Whitt', 'Melinda L. Irwin', 'Ann M. Swartz', 'Scott J. Strath', 'WILLIAM L. O BRIEN', 'David R. Bassett', 'Kathryn H. Schmitz', 'PATRICIA O. EMPLAINCOURT', 'David R. Jacobs', 'Arthur S. Leon']",2000,Medicine & Science in Sports & Exercise,Journal,,S498-S516,32,Supplement,10.1097/00005768-200009001-00009,"AINSWORTH, B. E,., W. L. HASKELL, M. C. WHITT, M. L. IRWIN, A. M. SWARTZ, S .J. STRATH, W. L. O'BRIEN, D. R. BASSETT, JR., K. H. SCHMITZ, P. O EMPLAINCOURT, D. R. JACOBS, JR., and A. S. LEON. Compendium of physical activities: an update of activity codes and MET intensities. Med. Sci. Sports Exerc., Vol. 32, No. 9, Suppl., pp. S498–S516, 2000. We provide an updated version of the Compendium of Physical Activities, a coding scheme that classifies specific physical activity (PA) by rate of energy expenditure. It was developed to enhance the comparability of results across studies using self-reports of PA. The Compendium coding scheme links a five-digit code that describes physical activities by major headings (e.g., occupation, transportation, etc.) and specific activities within each major heading with its intensity, defined as the ratio of work metabolic rate to a standard resting metabolic rate (MET). Energy expenditure in MET-minutes, MET-hours, kcal, or kcal per kilogram body weight can be estimated for specific activities by type or MET intensity. Additions to the Compendium were obtained from studies describing daily PA patterns of adults and studies measuring the energy cost of specific physical activities in field settings. The updated version includes two new major headings of volunteer and religious activities, extends the number of specific activities from 477 to 605, and provides updated MET intensity levels for selected activities.","['Compendium', 'Comparability', 'Energy expenditure', 'Metabolic equivalent', 'Physical activity', 'Coding (social sciences)', 'Kilogram', 'Computer science', 'Body weight', 'Statistics', 'Mathematics', 'Medicine', 'Physical therapy', 'Geography', 'Archaeology', 'Combinatorics', 'Endocrinology', 'Internal medicine']","physical activities, met, specific physical activity, work metabolic rate, resting metabolic rate, daily pa patterns, energy cost, religious activities"
Paper_02010,Improved tangent estimate in the nudged elastic band method for finding minimum energy paths and saddle points,"['Graeme Henkelman', 'Hannes Jónsson']",2000,The Journal of Chemical Physics,Journal,,9978-9985,113,22,10.1063/1.1323224,"An improved way of estimating the local tangent in the nudged elastic band method for finding minimum energy paths is presented. In systems where the force along the minimum energy path is large compared to the restoring force perpendicular to the path and when many images of the system are included in the elastic band, kinks can develop and prevent the band from converging to the minimum energy path. We show how the kinks arise and present an improved way of estimating the local tangent which solves the problem. The task of finding an accurate energy and configuration for the saddle point is also discussed and examples given where a complementary method, the dimer method, is used to efficiently converge to the saddle point. Both methods only require the first derivative of the energy and can, therefore, easily be applied in plane wave based density-functional theory calculations. Examples are given from studies of the exchange diffusion mechanism in a Si crystal, Al addimer formation on the Al(100) surface, and dissociative adsorption of CH4 on an Ir(111) surface.","['Saddle point', 'Tangent', 'Saddle', 'Tangent space', 'Path (computing)', 'Mathematical analysis', 'Energy (signal processing)', 'Trajectory', 'Perpendicular', 'Elastic energy', 'Surface (topology)', 'Geometry', 'Mathematics', 'Physics', 'Mathematical optimization', 'Computer science', 'Quantum mechanics', 'Programming language']","local tangent, nudged elastic band method, minimum energy paths, restoring force, elastic band, local tangent, dimer method, exchange diffusion mechanism, si crystal, al addimer formation, dissociative adsorption, [PAD], [PAD], [PAD] [PAD], [PAD], [PAD] [PAD] [PAD] [PAD], [PAD], [PAD], [PAD]"
Paper_02012,Statistical Theories of Mental Test Scores,"['William W. Rozeboom', 'Frederic M. Lord', 'Melvin R. Novick', 'Allan Birnbaum']",1969,American Educational Research Journal,Journal,,112-112,6,1,10.2307/1162101,"This is a reprint of the orginal book released in 1968. Our primary goal in this book is to sharpen the skill, sophistication, and in- tuition of the reader in the interpretation of mental test data, and in the construction and use of mental tests both as instruments of psychological theory and as tools in the practical problems of selection, evaluation, and guidance. We seek to do this by exposing the reader to some psychologically meaningful statistical theories of mental test scores. Although this book is organized in terms of test-score theories and models, the practical applications and limitations of each model studied receive substantial emphasis, and these discussions are presented in as nontechnical a manner as we have found possible. Since this book catalogues a host of test theory models and formulas, it may serve as a reference handbook. Also, for a limited group of specialists, this book aims to provide a more rigorous foundation for further theoretical research than has heretofore been available.One aim of this book is to present statements of the assumptions, together with derivations of the implications, of a selected group of statistical models that the authors believe to be useful as guides in the practices of test construction and utilization. With few exceptions we have given a complete proof for each major result presented in the book. In many cases these proofs are simpler, more complete, and more illuminating than those originally offered. When we have omitted proofs or parts of proofs, we have generally provided a reference containing the omitted argument. We have left some proofs as exercises for the reader, but only when the general method of proof has already been demonstrated. At times we have proved only special cases of more generally stated theorems, when the general proof affords no additional insight into the problem and yet is substantially more complex mathematically.","['Psychology', 'Test (biology)', 'Statistical hypothesis testing', 'Statistical analysis', 'Test validity', 'Econometrics', 'Statistics', 'Clinical psychology', 'Psychometrics', 'Mathematics education', 'Mathematics', 'Paleontology', 'Biology']","orginal, mental test data, mental tests, psychological theory, statistical theories, mental test scores, test theory, statistical models, test construction"
Paper_02013,An algorithm for suffix stripping,['Martin Porter'],1980,Program electronic library and information systems,Journal,,130-137,14,3,10.1108/eb046814,"The automatic removal of suffixes from words in English is of particular interest in the field of information retrieval. An algorithm for suffix stripping is described, which has been implemented as a short, fast program in BCPL. Although simple, it performs slightly better than a much more elaborate system with which it has been compared. It effectively works by treating complex suffixes as compounds made up of simple suffixes, and removing the simple suffixes in a number of steps. In each step the removal of the suffix is made to depend upon the form of the remaining stem, which usually involves a measure of its syllable length.","['Suffix', 'Stripping (fiber)', 'Simple (philosophy)', 'Computer science', 'Suffix array', 'Generalized suffix tree', 'Compressed suffix array', 'Algorithm', 'Field (mathematics)', 'Measure (data warehouse)', 'SIMPLE algorithm', 'Natural language processing', 'Suffix tree', 'Artificial intelligence', 'Mathematics', 'Data mining', 'Linguistics', 'Physics', 'Pure mathematics', 'Engineering', 'Philosophy', 'Epistemology', 'Electrical engineering', 'Thermodynamics']","suffixes, information retrieval, suffix stripping, ##pl, [PAD] [PAD] [PAD], [PAD] [PAD]"
Paper_02016,Probability-based protein identification by searching sequence databases using mass spectrometry data,"['David N. Perkins', 'Darryl Pappin', 'David M. Creasy', 'John S. Cottrell']",1999,Electrophoresis,Journal,,3551-3567,20,18,10.1002/(sici)1522-2683(19991201)20:18<3551::aid-elps3551>3.0.co;2-2,"Several algorithms have been described in the literature for protein identification by searching a sequence database using mass spectrometry data. In some approaches, the experimental data are peptide molecular weights from the digestion of a protein by an enzyme. Other approaches use tandem mass spectrometry (MS/MS) data from one or more peptides. Still others combine mass data with amino acid sequence data. We present results from a new computer program, Mascot, which integrates all three types of search. The scoring algorithm is probability based, which has a number of advantages: (i) A simple rule can be used to judge whether a result is significant or not. This is particularly useful in guarding against false positives. (ii) Scores can be com pared with those from other types of search, such as sequence homology. (iii) Search parameters can be readily optimised by iteration. The strengths and limitations of probability-based scoring are discussed, particularly in the context of high throughput, fully automated protein identification.","['Mascot', 'Computer science', 'False positive paradox', 'Database search engine', 'Tandem mass spectrometry', 'Mass spectrometry', 'Data mining', 'Identification (biology)', 'Context (archaeology)', 'Sequence database', 'Tandem mass tag', 'Protein sequencing', 'Sequence (biology)', 'Peptide sequence', 'Search engine', 'Proteomics', 'Chemistry', 'Artificial intelligence', 'Information retrieval', 'Quantitative proteomics', 'Chromatography', 'Biology', 'Paleontology', 'Biochemistry', 'Botany', 'Political science', 'Gene', 'Law']","protein identification, sequence database, mass spectrometry data, peptide molecular weights, tandem mass spectrometry, amino, mascot, probability, sequence homology, search, [PAD], [PAD]"
Paper_02019,Phylogenetic identification and in situ detection of individual microbial cells without cultivation,"['Rudolf Amann', 'Wolfgang Ludwig', 'Karl‐Heinz Schleifer']",1995,Microbiological Reviews,Journal,,143-169,59,1,10.1128/mr.59.1.143-169.1995,"The frequent discrepancy between direct microscopic counts and numbers of culturable bacteria from environmental samples is just one of several indications that we currently know only a minor part of the diversity of microorganisms in nature. A combination of direct retrieval of rRNA sequences and whole-cell oligonucleotide probing can be used to detect specific rRNA sequences of uncultured bacteria in natural samples and to microscopically identify individual cells. Studies have been performed with microbial assemblages of various complexities ranging from simple two-component bacterial endosymbiotic associations to multispecies enrichments containing magnetotactic bacteria to highly complex marine and soil communities. Phylogenetic analysis of the retrieved rRNA sequence of an uncultured microorganism reveals its closest culturable relatives and may, together with information on the physicochemical conditions of its natural habitat, facilitate more directed cultivation attempts. For the analysis of complex communities such as multispecies biofilms and activated-sludge flocs, a different approach has proven advantageous. Sets of probes specific to different taxonomic levels are applied consecutively beginning with the more general and ending with the more specific (a hierarchical top-to-bottom approach), thereby generating increasingly precise information on the structure of the community. Not only do rRNA-targeted whole-cell hybridizations yield data on cell morphology, specific cell counts, and in situ distributions of defined phylogenetic groups, but also the strength of the hybridization signal reflects the cellular rRNA content of individual cells. From the signal strength conferred by a specific probe, in situ growth rates and activities of individual cells might be estimated for known species. In many ecosystems, low cellular rRNA content and/or limited cell permeability, combined with background fluorescence, hinders in situ identification of autochthonous populations. Approaches to circumvent these problems are discussed in detail.","['Biology', 'Phylogenetic tree', 'Ribosomal RNA', 'In situ', 'Microorganism', 'Microbial ecology', 'Bacteria', '16S ribosomal RNA', 'Microbial population biology', 'Biofilm', 'Evolutionary biology', 'Taxonomic rank', 'Oligomer restriction', 'Computational biology', 'Ecology', 'Genetics', 'Gene', 'Oligonucleotide', 'Chemistry', 'Organic chemistry', 'Taxon']","culturable bacteria, ##na, ##culture, micro, ##ies, magnet, phylogenetic, ##culture, multi, ##ecies biofilms, signal strength, in situ growth rates, limited cell permeability, background fluorescence"
Paper_02020,"Postmodernism, or, The cultural logic of late capitalism",['Fredric Jameson'],1991,Choice Reviews Online,Journal,,28-4470,28,08,10.5860/choice.28-4470,"Now in paperback, Fredric Jameson’s most wide-ranging work seeks to crystalize a definition of ”postmodernism”. Jameson’s inquiry looks at the postmodern across a wide landscape, from “high” art to “low” from market ideology to architecture, from painting to “punk” film, from video art to literature.","['Postmodernism', 'Capitalism', 'Late capitalism', 'Aesthetics', 'Philosophy', 'Sociology', 'History', 'Neoclassical economics', 'Epistemology', 'Economics', 'Political science', 'Law', 'Politics']","##modern, ##dern, market ideology, video art"
Paper_02022,MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications,"['Andrew Howard', 'Menglong Zhu', 'Bo Chen', 'Dmitry Kalenichenko', 'Weijun Wang', 'Tobias Weyand', 'Marco Andreetto', 'Hartwig Adam']",2017,"['International Journal on Advanced Science, Engineering and Information Technology']",Unknown,,2290-2296,10,6,10.18517/ijaseit.10.6.10948,"We present a class of efficient models called MobileNets for mobile and embedded vision applications. MobileNets are based on a streamlined architecture that uses depth-wise separable convolutions to build light weight deep neural networks. We introduce two simple global hyper-parameters that efficiently trade off between latency and accuracy. These hyper-parameters allow the model builder to choose the right sized model for their application based on the constraints of the problem. We present extensive experiments on resource and accuracy tradeoffs and show strong performance compared to other popular models on ImageNet classification. We then demonstrate the effectiveness of MobileNets across a wide range of applications and use cases including object detection, finegrain classification, face attributes and large scale geo-localization.","['Computer science', 'Convolutional neural network', 'Latency (audio)', 'Artificial intelligence', 'Deep neural networks', 'Face (sociological concept)', 'Architecture', 'Deep learning', 'Mobile device', 'Object detection', 'Class (philosophy)', 'Simple (philosophy)', 'Range (aeronautics)', 'Artificial neural network', 'Scale (ratio)', 'Machine learning', 'Pattern recognition (psychology)', 'Engineering', 'Telecommunications', 'Art', 'Social science', 'Philosophy', 'Physics', 'Epistemology', 'Quantum mechanics', 'Sociology', 'Visual arts', 'Aerospace engineering', 'Operating system']","mobilenets, embedded vision applications, mobilenets, streamlined architecture, light weight deep neural networks, late, accuracy, imagenet classification, mobilenets, object detection, finegrain classification, face attributes"
Paper_02023,p53 Mutations in Human Cancers,"['Monica Hollstein', 'David Sidransky', 'Bert Vogelstein', 'Curtis C. Harris']",1991,Science,Journal,,49-53,253,5015,10.1126/science.1905840,"Mutations in the evolutionarily conserved codons of the p53 tumor suppressor gene are common in diverse types of human cancer. The p53 mutational spectrum differs among cancers of the colon, lung, esophagus, breast, liver, brain, reticuloendothelial tissues, and hemopoietic tissues. Analysis of these mutations can provide clues to the etiology of these diverse tumors and to the function of specific regions of p53. Transitions predominate in colon, brain, and lymphoid malignancies, whereas G:C to T:A transversions are the most frequent substitutions observed in cancers of the lung and liver. Mutations at A:T base pairs are seen more frequently in esophageal carcinomas than in other solid tumors. Most transitions in colorectal carcinomas, brain tumors, leukemias, and lymphomas are at CpG dinucleotide mutational hot spots. G to T transversions in lung, breast, and esophageal carcinomas are dispersed among numerous codons. In liver tumors in persons from geographic areas in which both aflatoxin B 1 and hepatitis B virus are cancer risk factors, most mutations are at one nucleotide pair of codon 249. These differences may reflect the etiological contributions of both exogenous and endogenous factors to human carcinogenesis.","['Biology', 'Carcinogenesis', 'Mutation', 'Cancer research', 'Leukemia', 'Colorectal cancer', 'Cancer', 'Esophagus', 'Gene', 'Genetics', 'Anatomy']","p53, human cancer, ##ha, ##tic, hemopoietic, colorectal carcinomas, brain tumors, l, ##ph, liver tumors, afl, hepatitis, cancer"
Paper_02024,An Introduction to the Fractional Calculus and Fractional Differential Equations,"['Kenneth S. Miller', 'Bertram Ross']",1993,['Fractional Partial Differential Equations and Their Numerical Solutions'],Unknown,,34-108,,,10.1142/9789814667050_0002,Historical Survey The Modern Approach The Riemann-Liouville Fractional Integral The Riemann-Liouville Fractional Calculus Fractional Differential Equations Further Results Associated with Fractional Differential Equations The Weyl Fractional Calculus Some Historical Arguments.,"['Fractional calculus', 'Calculus (dental)', 'Mathematics', 'Applied mathematics', 'Time-scale calculus', 'Multivariable calculus', 'Medicine', 'Engineering', 'Dentistry', 'Control engineering']","fraction, fractional differential equations, fractional differential equations, weyl fractional calculus, [PAD] [PAD] [PAD], [PAD] [PAD] [PAD], [PAD], [PAD], [PAD] [PAD] [PAD], [PAD] [PAD] [PAD], [PAD], [PAD], [PAD] [PAD], [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD], [PAD], [PAD], [PAD], [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD], [PAD], [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD], [PAD] [PAD], [PAD] [PAD] [PAD]"
Paper_02025,OpenFlow,"['Nick McKeown', 'Tom Anderson', 'Hari Balakrishnan', 'Guru Parulkar', 'Larry Peterson', 'Jennifer Rexford', 'Scott Shenker', 'Jonathan Turner']",2008,ACM SIGCOMM Computer Communication Review,Journal,,69-74,38,2,10.1145/1355734.1355746,"This whitepaper proposes OpenFlow: a way for researchers to run experimental protocols in the networks they use every day. OpenFlow is based on an Ethernet switch, with an internal flow-table, and a standardized interface to add and remove flow entries. Our goal is to encourage networking vendors to add OpenFlow to their switch products for deployment in college campus backbones and wiring closets. We believe that OpenFlow is a pragmatic compromise: on one hand, it allows researchers to run experiments on heterogeneous switches in a uniform way at line-rate and with high port-density; while on the other hand, vendors do not need to expose the internal workings of their switches. In addition to allowing researchers to evaluate their ideas in real-world traffic settings, OpenFlow could serve as a useful campus component in proposed large-scale testbeds like GENI. Two buildings at Stanford University will soon run OpenFlow networks, using commercial Ethernet switches and routers. We will work to encourage deployment at other schools; and We encourage you to consider deploying OpenFlow in your university network too","['OpenFlow', 'Computer science', 'Software deployment', 'Computer network', 'Ethernet', 'Network switch', 'Port (circuit theory)', 'Table (database)', 'Software-defined networking', 'Operating system', 'Engineering', 'Electrical engineering', 'Data mining']","openflow, openflow, ethernet switch, standardized interface, networking, openflow, college campus backbones, wiring closets, openflow, heterogeneous switches, openflow, geni, stanford university, openflow, ethernet switches, routers, openflow"
Paper_02026,The Sociological Imagination,['Charles W. Mills'],1959,The Mississippi Valley Historical Review,Journal,,355-355,46,2,10.2307/1891592,"Journal Article The Sociological Imagination. By C. Wright Mills. (New York: Oxford University Press, 1959. 234 pp. Index. $6.00.) Get access Journal of American History, Volume 46, Issue 2, September 1959, Pages 355–356, https://doi.org/10.2307/1891592 Published: 01 September 1959","['Wright', 'Sociological imagination', 'Sociology', 'Index (typography)', 'Art history', 'Media studies', 'Anthropology', 'Art', 'Computer science', 'World Wide Web']","sociological imagination, american history"
Paper_02027,Longman Grammar of Spoken and Written English,"['Kathleen M. Broussard', 'Douglas Biber', 'Stig Johansson', 'Geoffrey Leech', 'Susan Conrad', 'Edward Finegan']",2000,TESOL Quarterly,Journal,,787-787,34,4,10.2307/3587792,"* Over 350 tables and graphs show the frequency of constructions in different contexts, from conversation to fiction to academic prose * Entirely corpus-based with 6000 authentic examples from the 40 million-word Longman Spoken and Written English Corpus * Suggests the reasons why we choose a particular structure in a particular context * Compares British and American spoken and written English Areas covered include basic grammar: description and distribution, key word classes and their phrases and complex structures. Each area is subdivided into more detailed content.","['Linguistics', 'Grammar', 'Spoken language', 'Psychology', 'History', 'Philosophy']","conversation, academic prose, written english, written english, basic grammar, key word classes"
Paper_02029,A comparison of normalization methods for high density oligonucleotide array data based on variance and bias,"['Benjamin M. Bolstad', 'Rafael A. Irizarry', 'Magnus Åstrand', 'Terence P. Speed']",2003,Bioinformatics,Journal,,185-193,19,2,10.1093/bioinformatics/19.2.185,"When running experiments that involve multiple high density oligonucleotide arrays, it is important to remove sources of variation between arrays of non-biological origin. Normalization is a process for reducing this variation. It is common to see non-linear relations between arrays and the standard normalization provided by Affymetrix does not perform well in these situations.We present three methods of performing normalization at the probe intensity level. These methods are called complete data methods because they make use of data from all arrays in an experiment to form the normalizing relation. These algorithms are compared to two methods that make use of a baseline array: a one number scaling based algorithm and a method that uses a non-linear normalizing relation by comparing the variability and bias of an expression measure. Two publicly available datasets are used to carry out the comparisons. The simplest and quickest complete data method is found to perform favorably.Software implementing all three of the complete data normalization methods is available as part of the R package Affy, which is a part of the Bioconductor project http://www.bioconductor.org.Additional figures may be found at http://www.stat.berkeley.edu/~bolstad/normalize/index.html","['Bioconductor', 'Normalization (sociology)', 'Computer science', 'R package', 'Data mining', 'Software', 'Algorithm', 'Linear scale', 'Statistics', 'Pattern recognition (psychology)', 'Mathematics', 'Artificial intelligence', 'Biochemistry', 'Chemistry', 'Geodesy', 'Sociology', 'Anthropology', 'Gene', 'Programming language', 'Geography']","normalization, affymetrix, normal, probe intensity level, complete data methods, normalizing relation, baseline array, one number scaling, non - linear, expression measure, complete data method, complete data normalization, affy, bioconductor project, bioconductor"
Paper_02030,"Quantity and Quality of Exercise for Developing and Maintaining Cardiorespiratory, Musculoskeletal, and Neuromotor Fitness in Apparently Healthy Adults","['Carol Ewing Garber', 'Bryan Blissmer', 'Michael R. Deschenes', 'Barry A. Franklin', 'Michael J. LaMonte', 'I‐Min Lee', 'David C. Nieman', 'David P. Swain']",2011,Medicine & Science in Sports & Exercise,Journal,,1334-1359,43,7,10.1249/mss.0b013e318213fefb,"The purpose of this Position Stand is to provide guidance to professionals who counsel and prescribe individualized exercise to apparently healthy adults of all ages. These recommendations also may apply to adults with certain chronic diseases or disabilities, when appropriately evaluated and advised by a health professional. This document supersedes the 1998 American College of Sports Medicine (ACSM) Position Stand, ""The Recommended Quantity and Quality of Exercise for Developing and Maintaining Cardiorespiratory and Muscular Fitness, and Flexibility in Healthy Adults."" The scientific evidence demonstrating the beneficial effects of exercise is indisputable, and the benefits of exercise far outweigh the risks in most adults. A program of regular exercise that includes cardiorespiratory, resistance, flexibility, and neuromotor exercise training beyond activities of daily living to improve and maintain physical fitness and health is essential for most adults. The ACSM recommends that most adults engage in moderate-intensity cardiorespiratory exercise training for ≥30 min·d on ≥5 d·wk for a total of ≥150 min·wk, vigorous-intensity cardiorespiratory exercise training for ≥20 min·d on ≥3 d·wk (≥75 min·wk), or a combination of moderate- and vigorous-intensity exercise to achieve a total energy expenditure of ≥500-1000 MET·min·wk. On 2-3 d·wk, adults should also perform resistance exercises for each of the major muscle groups, and neuromotor exercise involving balance, agility, and coordination. Crucial to maintaining joint range of movement, completing a series of flexibility exercises for each the major muscle-tendon groups (a total of 60 s per exercise) on ≥2 d·wk is recommended. The exercise program should be modified according to an individual's habitual physical activity, physical function, health status, exercise responses, and stated goals. Adults who are unable or unwilling to meet the exercise targets outlined here still can benefit from engaging in amounts of exercise less than recommended. In addition to exercising regularly, there are health benefits in concurrently reducing total time engaged in sedentary pursuits and also by interspersing frequent, short bouts of standing and physical activity between periods of sedentary activity, even in physically active adults. Behaviorally based exercise interventions, the use of behavior change strategies, supervision by an experienced fitness instructor, and exercise that is pleasant and enjoyable can improve adoption and adherence to prescribed exercise programs. Educating adults about and screening for signs and symptoms of CHD and gradual progression of exercise intensity and volume may reduce the risks of exercise. Consultations with a medical professional and diagnostic exercise testing for CHD are useful when clinically indicated but are not recommended for universal screening to enhance the safety of exercise.","['Cardiorespiratory fitness', 'Flexibility (engineering)', 'Physical therapy', 'Sports medicine', 'Medicine', 'Physical fitness', 'Exercise physiology', 'Physical medicine and rehabilitation', 'Quality of life (healthcare)', 'Exercise intensity', 'Heart rate', 'Blood pressure', 'Internal medicine', 'Nursing', 'Statistics', 'Mathematics']","individualized exercise, regular exercise, flexibility, neuromotor exercise training, balance, agility, coordination, flexibility, ##dentary pursuits, ##dent, behavior change strategies"
Paper_02031,Orthonormal bases of compactly supported wavelets,['Ingrid Daubechies'],1988,Communications on Pure and Applied Mathematics,Journal,,909-996,41,7,10.1002/cpa.3160410705,"Abstract We construct orthonormal bases of compactly supported wavelets, with arbitrarily high regularity. The order of regularity increases linearly with the support width. We start by reviewing the concept of multiresolution analysis as well as several algorithms in vision decomposition and reconstruction. The construction then follows from a synthesis of these different approaches.","['Orthonormal basis', 'Wavelet', 'Mathematics', 'Multiresolution analysis', 'Construct (python library)', 'Order (exchange)', 'Decomposition', 'Pure mathematics', 'Algebra over a field', 'Applied mathematics', 'Wavelet transform', 'Artificial intelligence', 'Computer science', 'Discrete wavelet transform', 'Ecology', 'Physics', 'Finance', 'Quantum mechanics', 'Economics', 'Biology', 'Programming language']","orthonormal bases, compactly supported wavelets, arbitrarily high regularity, regular, support width, multiresolution analysis, vision decomposition, reconstruction, [PAD] [PAD], [PAD] [PAD], [PAD], [PAD], [PAD] [PAD], [PAD], [PAD] [PAD] [PAD], [PAD], [PAD] [PAD], [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD] [PAD], [PAD] [PAD], [PAD] [PAD], [PAD], [PAD], [PAD] [PAD], [PAD] [PAD] [PAD] [PAD], [PAD] [PAD], [PAD], [PAD] [PAD], [PAD], [PAD] [PAD] [PAD], [PAD] [PAD], [PAD] [PAD], [PAD], [PAD], [PAD] [PAD] [PAD], [PAD] [PAD]"
Paper_02032,"The Metabolic Phenotype in Obesity: Fat Mass, Body Fat Distribution, and Adipose Tissue Function",['Gijs H. Goossens'],2017,Obesity Facts,Journal,,207-215,10,3,10.1159/000471488,"The current obesity epidemic poses a major public health issue since obesity predisposes towards several chronic diseases. BMI and total adiposity are positively correlated with cardiometabolic disease risk at the population level. However, body fat distribution and an impaired adipose tissue function, rather than total fat mass, better predict insulin resistance and related complications at the individual level. Adipose tissue dysfunction is determined by an impaired adipose tissue expandability, adipocyte hypertrophy, altered lipid metabolism, and local inflammation. Recent human studies suggest that adipose tissue oxygenation may be a key factor herein. A subgroup of obese individuals - the ‘metabolically healthy obese' (MHO) - have a better adipose tissue function, less ectopic fat storage, and are more insulin sensitive than obese metabolically unhealthy persons, emphasizing the central role of adipose tissue function in metabolic health. However, controversy has surrounded the idea that metabolically healthy obesity may be considered really healthy since MHO individuals are at increased (cardio)metabolic disease risk and may have a lower quality of life than normal weight subjects due to other comorbidities. Detailed metabolic phenotyping of obese persons will be invaluable in understanding the pathophysiology of metabolic disturbances, and is needed to identify high-risk individuals or subgroups, thereby paving the way for optimization of prevention and treatment strategies to combat cardiometabolic diseases.","['Adipose tissue', 'Medicine', 'Obesity', 'Internal medicine', 'Endocrinology', 'Insulin resistance', 'Adipocyte', 'Population', 'Diabetes mellitus', 'Type 2 diabetes', 'Environmental health']","obesity, public, ##mi, total adiposity, cardiometabolic disease, body fat distribution, impaired adipose tissue function, total fat mass, insulin resistance, adipose tissue dysfunction, ##te hypertrophy, altered lipid metabolism, local inflammation, adipose tissue oxygenation, metabolically healthy obe, adipose tissue function, ectopic fat storage, adi, ##ally, metabolic phenotyping, obe, metabolic disturbances, card"
Paper_02033,Interrater reliability: the kappa statistic.,['Mary L. McHugh'],2012,['Biochemia Medica'],Unknown,,276-282,,,10.11613/bm.2012.031,"The kappa statistic is frequently used to test interrater reliability. The importance of rater reliability lies in the fact that it represents the extent to which the data collected in the study are correct representations of the variables measured. Measurement of the extent to which data collectors (raters) assign the same score to the same variable is called interrater reliability. While there have been a variety of methods to measure interrater reliability, traditionally it was measured as percent agreement, calculated as the number of agreement scores divided by the total number of scores. In 1960, Jacob Cohen critiqued use of percent agreement due to its inability to account for chance agreement. He introduced the Cohen's kappa, developed to account for the possibility that raters actually guess on at least some variables due to uncertainty. Like most correlation statistics, the kappa can range from -1 to +1. While the kappa is one of the most commonly used statistics to test interrater reliability, it has limitations. Judgments about what level of kappa should be acceptable for health research are questioned. Cohen's suggested interpretation may be too lenient for health related studies because it implies that a score as low as 0.41 might be acceptable. Kappa and percent agreement are compared, and levels for both kappa and percent agreement that should be demanded in healthcare studies are suggested.","['Inter-rater reliability', 'Kappa', ""Cohen's kappa"", 'Statistics', 'Statistic', 'Reliability (semiconductor)', 'Psychology', 'Test (biology)', 'Mathematics', 'Medicine', 'Rating scale', 'Paleontology', 'Power (physics)', 'Geometry', 'Physics', 'Quantum mechanics', 'Biology']","kappa statistic, interrater reliability, rater reliability, interrater reliability, inter, ##r reliability, percent agreement, agreement scores, percent agreement, chance agreement, correlation statistics, interrater reliability, health research, health, percent agreement, percent agreement, healthcare studies"
Paper_02034,k-ANONYMITY: A MODEL FOR PROTECTING PRIVACY,['Latanya Sweeney'],2002,International Journal of Uncertainty Fuzziness and Knowledge-Based Systems,Journal,,557-570,10,05,10.1142/s0218488502001648,"Consider a data holder, such as a hospital or a bank, that has a privately held collection of person-specific, field structured data. Suppose the data holder wants to share a version of the data with researchers. How can a data holder release a version of its private data with scientific guarantees that the individuals who are the subjects of the data cannot be re-identified while the data remain practically useful? The solution provided in this paper includes a formal protection model named k-anonymity and a set of accompanying policies for deployment. A release provides k-anonymity protection if the information for each person contained in the release cannot be distinguished from at least k-1 individuals whose information also appears in the release. This paper also examines re-identification attacks that can be realized on releases that adhere to k-anonymity unless accompanying policies are respected. The k-anonymity protection model is important because it forms the basis on which the real-world systems known as Datafly, μ-Argus and k-Similar provide guarantees of privacy protection.","['Anonymity', 'Computer security', 'k-anonymity', 'Computer science', 'Internet privacy', 'Identification (biology)', 'Software deployment', 'Data Protection Act 1998', 'Set (abstract data type)', 'Private information retrieval', 'Information privacy', 'Botany', 'Biology', 'Programming language', 'Operating system']","data holder, bank, formal protection model, anonymity, anonymity, identification, ##onymity, ##mity, datafly, privacy protection"
Paper_02035,"THE IMPACT OF HUMAN RESOURCE MANAGEMENT PRACTICES ON TURNOVER, PRODUCTIVITY, AND CORPORATE FINANCIAL PERFORMANCE.",['Mark A. Huselid'],1995,Academy of Management Journal,Journal,,635-672,38,3,10.2307/256741,This study comprehensively evaluated the links between systems of High Performance Work Practices and firm performance. Results based on a national sample of nearly one thousand firms indicate that these practices have an economically and statistically significant impact on both intermediate employee outcomes (turnover and productivity) and short- and long-term measures of corporate financial performance. Support for predictions that the impact of High Performance Work Practices on firm performance is in part contingent on their interrelationships and links with competitive strategy was limited. The impact of human resource management (HRM) policies and prac,"['Human resource management', 'Productivity', 'Business', 'Turnover', 'Human resources', 'Employee motivation', 'Industrial organization', 'Environmental resource management', 'Economics', 'Management', 'Marketing', 'Macroeconomics']","high performance work practices, firm performance, intermediate employee outcomes, turnover, productivity, corporate financial performance, high performance work practices, firm performance, competitive strategy, human resource management, hr, pr, [PAD], [PAD] [PAD], [PAD] [PAD], [PAD] [PAD]"
Paper_02036,Male-Female Wage Differentials in Urban Labor Markets,['Ronald L. Oaxaca'],1973,International Economic Review,Journal,,693-693,14,3,10.2307/2525981,"CULTURE, TRADITION, AND OVERT DISCRIMINATION tend to make restrictive the terms by which women may participate in the labor force. These influences combine to generate an unfavorable occupational distribution of female workers vis-a-vis male workers and to create pay differences between males and females within the same occupation. The result is a chronic earnings gap between male and female full-time, year-round workers. Unfortunately, explanations at this level of generality are mainly descriptive. It is the purpose of this paper to estimate the average extent of discrimination against female workers in the United States and to provide a quantitative assessment of the sources of male-female wage differentials.","['Earnings', 'Wage', 'Generality', 'Male female', 'Labour economics', 'Economics', 'Distribution (mathematics)', 'Demographic economics', 'Management', 'Mathematical analysis', 'Mathematics', 'Accounting']","overt discrimination, women, occupational distribution, female workers, male workers, pay differences, earnings gap, female workers, united"
Paper_02037,Narrative Inquiry: Experience and Story in Qualitative Research,"['D. Jean Clandinin', 'F. Michael Connelly']",1999,['Qualitative Social Work'],Unknown,,117-119,2,1,10.1177/1473325003002001125,"'The literature on narrative inquiry has been, until now, widely scattered and theoretically incomplete. Clandinin and Connelly have created a major tour de force. This book is lucid, fluid, beautifully argued, and rich in examples. Students will find a wealth of arguments to support their research, and teaching faculty will find everything they need to teach narrative inquiry theory and methods' - Yvonna S. Lincoln, professor, Department of Educational Administration, Texas A&M University.Understanding experience as lived and told stories - also known as narrative inquiry - has gained popularity and credence in qualitative research. Unlike more traditional methods, narrative inquiry successfully captures personal and human dimensions that cannot be quantified into dry facts and numerical data. In this definitive guide, Jean Clandinin and Michael Connelly draw from more than twenty years of field experience to show how narrative inquiry can be used in educational and social science research. Tracing the origins of narrative inquiry in the social sciences, they offer new and practical ideas for conducting fieldwork, composing field notes, and conveying research results. Throughout the book, stories and examples reveal a wide range of narrative methods. Engaging and easy to read, Narrative Inquiry is a practical resource from experts who have long pioneered the use of narrative in qualitative research.","['Narrative', 'Narrative inquiry', 'Narrative criticism', 'Narrative network', 'Popularity', 'Qualitative research', 'Credence', 'Field (mathematics)', 'Educational research', 'Pedagogy', 'Sociology', 'Epistemology', 'Mathematics education', 'Psychology', 'Social science', 'Literature', 'Computer science', 'Art', 'Social psychology', 'Mathematics', 'Philosophy', 'Machine learning', 'Pure mathematics']","narrative inquiry, narrative inquiry, educational administration, narrative inquiry, qualitative research, narrative inquiry, numerical data, narrative inquiry, social science, narrative inquiry, social, narrative inquiry, qualitative research"
Paper_02038,A simplest systematics for the organization of turn-taking for conversation,"['Harvey Sacks', 'Emanuel A. Schegloff', 'Gail Jefferson']",1974,Language,Journal,,696-735,50,4,10.1353/lan.1974.0010,"A SIMPLEST SYSTEMATICS FOR THE ORGANIZATION OF TURN-TAKING FOR CONVERSATION Harvey SacksEmanuel A. SchegloffGail Jefferson University of California, University of California, University ofPennsylvania IrvineLos Angeles The organization of taking turns to talk is fundamental to conversation, as well as to other speech-exchange systems. A model for the turn-taking organization for conversation is proposed, and is examined for its compatibility with a list of grossly observable facts about conversation. The results of the examination suggest that, at least, a model for turn-taking in conversation will be characterized as locally managed , party-administered, interactionally controlled, and sensitive to recipient design. Several general consequences of the model are explicated, and contrasts are sketched with turn-taking organizations for other speech-exchange systems.* 1. Introduction. Turn-taking is used for the ordering of moves in games, for allocating political office, for regulating traffic at intersections, for serving customers at business establishments, and for talking in interviews, meetings, debates, ceremonies , conversations etc.—these last being members of the set which we shall refer to as 'speech exchange systems'. It is obviously a prominent type of social organization, one whose instances are implicated in a wide range of other activities. For socially organized activities, the presence of 'turns' suggests an economy, with turns for something being valued—and with means for allocating them, which affect their relative distribution, as in economies. An investigator interested in the sociology of a turn-organized activity will want to determine, at least, the shape of the turn-taking organization device, and how it affects the distribution of turns for the activities on which it operates. For the investigator of turn-taking systems per se, it is not surprising that turntaking systems can be workably built in various ways. Since they are used to organize sorts of activities that are quite different from one another, it is of particular interest to see how operating turn-taking systems are characterizable as adapting to properties of the sorts of activities in which they operate. Again, an investigator interested in some sort of activity that is organized by a turn-taking system will want to determine how the sort of activity investigated is adapted to, or constrained by, the particular form of turn-taking system which operates on it. The subject of this report is the turn-taking system for conversation, and the foregoing are among the questions to which it will be addressed. Others have noted that the organization of taking turns at talk is one type of organization operative in conversation, and have located a range of interesting features and details of that sort of organization.1 But no account of the systematics of the organization of * An earlier version of this paper was presented at the Conference on the Sociology of Language and Theory of Speech Acts, Bielefeld, Germany, April 1973. 1 For example, Goffman 1955, 1964, 1971 ; Albert 1964; Kendon 1967; Yngve 1970; Duncan 1972a,b, 1973. Thus Goffman (1964:135-6): Card games, ball-room couplings, surgical teams in operation, and fist fights provide examples of encounters ; all illustrate the social organization of shared current orientation, and all involve an organized interplay of acts of some kind. I want to suggest that when 696 SYSTEMATICS FOR THE ORGANIZATION OF TURN-TAKING697 turn-taking for conversation is yet available. Here, on the basis of research using audio recordings of naturally occurring conversations, we attempt to characterize, in its simplest systematic form, the organization of turn-taking for conversation, and to extract some of the interest Of that organization. Aspects of the organization we call turn-taking have forced themselves on investigators of ' small-group' behavior—who, in dealing with problems concerning the distribution of talk among participants in small groups,2 or the kinds of 'acts' which form sequences in small-group sessions,3 have encountered problems conditioned in central ways by the turn-taking system, though for the most part they have not addressed them in this light. Again, students of 'interview' behavior, and such two-party conversation as approximates it in form,4 have concerned themselves with the distribution of talk among the parties, the distribution of silences, the sequences in which the talk...","['Conversation', 'Turn-taking', 'Politics', 'Set (abstract data type)', 'Sociology', 'Public relations', 'Linguistics', 'Political science', 'Computer science', 'Communication', 'Law', 'Philosophy', 'Programming language']","business, speech exchange systems, socially organized activities, turn"
Paper_02039,Measuring agreement in method comparison studies,"['John M. Bland', 'Douglas G. Altman']",1999,Statistical Methods in Medical Research,Journal,,135-160,8,2,10.1177/096228029900800204,"Agreement between two methods of clinical measurement can be quantified using the differences between observations made using the two methods on the same subjects. The 95% limits of agreement, estimated by mean difference +/- 1.96 standard deviation of the differences, provide an interval within which 95% of differences between measurements by the two methods are expected to lie. We describe how graphical methods can be used to investigate the assumptions of the method and we also give confidence intervals. We extend the basic approach to data where there is a relationship between difference and magnitude, both with a simple logarithmic transformation approach and a new, more general, regression approach. We discuss the importance of the repeatability of each method separately and compare an estimate of this to the limits of agreement. We extend the limits of agreement approach to data with repeated measurements, proposing new estimates for equal numbers of replicates by each method on each subject, for unequal numbers of replicates, and for replicated data collected in pairs, where the underlying value of the quantity being measured is changing. Finally, we describe a nonparametric approach to comparing methods.","['Statistics', 'Mathematics', 'Nonparametric statistics', 'Repeatability', 'Confidence interval', 'Standard deviation', 'Logarithm', 'Transformation (genetics)', 'Standard error', 'Computer science', 'Mathematical analysis', 'Biochemistry', 'Chemistry', 'Gene']","clinical measurement, graphical, confidence intervals, logarithmic transformation, repeat, une, nonparametric, [PAD], [PAD] [PAD], [PAD] [PAD] [PAD], [PAD], [PAD] [PAD], [PAD], [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD], [PAD] [PAD], [PAD] [PAD] [PAD] [PAD]"
Paper_02040,Controlling Electromagnetic Fields,"['J. B. Pendry', 'David Schurig', 'David R. Smith']",2006,Science,Journal,,1780-1782,312,5781,10.1126/science.1125907,"Using the freedom of design that metamaterials provide, we show how electromagnetic fields can be redirected at will and propose a design strategy. The conserved fields—electric displacement field D , magnetic induction field B , and Poynting vector B —are all displaced in a consistent manner. A simple illustration is given of the cloaking of a proscribed volume of space to exclude completely all electromagnetic fields. Our work has relevance to exotic lens design and to the cloaking of objects from electromagnetic fields.","['Cloaking', 'Poynting vector', 'Electromagnetic field', 'Physics', 'Metamaterial', 'Metamaterial cloaking', 'Electromagnetic induction', 'Electromagnetic radiation', 'Classical mechanics', 'Optical field', 'Electromagnetic compatibility', 'Magnetic field', 'Quantum electrodynamics', 'Optics', 'Quantum mechanics', 'Electromagnetic coil', 'Tunable metamaterials', 'Metamaterial absorber']","freedom of design, metamaterials, electromagnetic fields, conserved fields, electric displacement field, magnetic induction field, poynting vector, cloak, exotic lens design, electromagnetic, [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD], [PAD], [PAD] [PAD] [PAD], [PAD], [PAD], [PAD] [PAD] [PAD] [PAD], [PAD], [PAD], [PAD], [PAD], [PAD] [PAD] [PAD] [PAD], [PAD] [PAD], [PAD], [PAD], [PAD], [PAD], [PAD] [PAD], [PAD] [PAD] [PAD] [PAD], [PAD] [PAD], [PAD], [PAD] [PAD], [PAD] [PAD]"
Paper_02041,"Risk Factors Associated With Acute Respiratory Distress Syndrome and Death in Patients With Coronavirus Disease 2019 Pneumonia in Wuhan, China","['Chaomin Wu', 'Xiaohong Chen', 'Yanping Cai', 'Jiaan Xia', 'Xing Zhou', 'Sha Xu', 'Han-Ping Huang', 'Li Zhang', 'Xia Zhou', 'Chunling Du', 'Yuye Zhang', 'Juan Song', 'Sijiao Wang', 'Yencheng Chao', 'Zeyong Yang', 'Jie Xu', 'Xin Zhou', 'Dechang Chen', 'Weining Xiong', 'Lei Xu', 'Feng Zhou', 'Jinjun Jiang', 'Chunxue Bai', 'Junhua Zheng', 'Yuanlin Song']",2020,JAMA Internal Medicine,Journal,,934-934,180,7,10.1001/jamainternmed.2020.0994,"<h3>Importance</h3> Coronavirus disease 2019 (COVID-19) is an emerging infectious disease that was first reported in Wuhan, China, and has subsequently spread worldwide. Risk factors for the clinical outcomes of COVID-19 pneumonia have not yet been well delineated. <h3>Objective</h3> To describe the clinical characteristics and outcomes in patients with COVID-19 pneumonia who developed acute respiratory distress syndrome (ARDS) or died. <h3>Design, Setting, and Participants</h3> Retrospective cohort study of 201 patients with confirmed COVID-19 pneumonia admitted to Wuhan Jinyintan Hospital in China between December 25, 2019, and January 26, 2020. The final date of follow-up was February 13, 2020. <h3>Exposures</h3> Confirmed COVID-19 pneumonia. <h3>Main Outcomes and Measures</h3> The development of ARDS and death. Epidemiological, demographic, clinical, laboratory, management, treatment, and outcome data were also collected and analyzed. <h3>Results</h3> Of 201 patients, the median age was 51 years (interquartile range, 43-60 years), and 128 (63.7%) patients were men. Eighty-four patients (41.8%) developed ARDS, and of those 84 patients, 44 (52.4%) died. In those who developed ARDS, compared with those who did not, more patients presented with dyspnea (50 of 84 [59.5%] patients and 30 of 117 [25.6%] patients, respectively [difference, 33.9%; 95% CI, 19.7%-48.1%]) and had comorbidities such as hypertension (23 of 84 [27.4%] patients and 16 of 117 [13.7%] patients, respectively [difference, 13.7%; 95% CI, 1.3%-26.1%]) and diabetes (16 of 84 [19.0%] patients and 6 of 117 [5.1%] patients, respectively [difference, 13.9%; 95% CI, 3.6%-24.2%]). In bivariate Cox regression analysis, risk factors associated with the development of ARDS and progression from ARDS to death included older age (hazard ratio [HR], 3.26; 95% CI 2.08-5.11; and HR, 6.17; 95% CI, 3.26-11.67, respectively), neutrophilia (HR, 1.14; 95% CI, 1.09-1.19; and HR, 1.08; 95% CI, 1.01-1.17, respectively), and organ and coagulation dysfunction (eg, higher lactate dehydrogenase [HR, 1.61; 95% CI, 1.44-1.79; and HR, 1.30; 95% CI, 1.11-1.52, respectively] and D-dimer [HR, 1.03; 95% CI, 1.01-1.04; and HR, 1.02; 95% CI, 1.01-1.04, respectively]). High fever (≥39 °C) was associated with higher likelihood of ARDS development (HR, 1.77; 95% CI, 1.11-2.84) and lower likelihood of death (HR, 0.41; 95% CI, 0.21-0.82). Among patients with ARDS, treatment with methylprednisolone decreased the risk of death (HR, 0.38; 95% CI, 0.20-0.72). <h3>Conclusions and Relevance</h3> Older age was associated with greater risk of development of ARDS and death likely owing to less rigorous immune response. Although high fever was associated with the development of ARDS, it was also associated with better outcomes among patients with ARDS. Moreover, treatment with methylprednisolone may be beneficial for patients who develop ARDS.","['Medicine', 'ARDS', 'Interquartile range', 'Pneumonia', 'Internal medicine', 'Retrospective cohort study', 'Epidemiology', 'Comorbidity', 'Pediatrics', 'Lung']","coronavirus disease, risk factors, acute respiratory distress syndrome, ards, dyspnea, hyper, bivariate cox regression analysis, hazard ratio"
Paper_02043,"Job demands, job resources, and their relationship with burnout and engagement: a multi‐sample study","['Wilmar B. Schaufeli', 'Arnold B. Bakker']",2004,Journal of Organizational Behavior,Journal,,293-315,25,3,10.1002/job.248,"Abstract This study focuses on burnout and its positive antipode—engagement. A model is tested in which burnout and engagement have different predictors and different possible consequences. Structural equation modeling was used to simultaneously analyze data from four independent occupational samples (total N = 1698). Results confirm the hypothesized model indicating that: (1) burnout and engagement are negatively related, sharing between 10 per cent and 25 per cent of their variances; (2) burnout is mainly predicted by job demands but also by lack of job resources, whereas engagement is exclusively predicted by available job resources; (3) burnout is related to health problems as well as to turnover intention, whereas engagement is related only to the latter; (4) burnout mediates the relationship between job demands and health problems, whereas engagement mediates the relationship between job resources and turnover intention. The fact that burnout and engagement exhibit different patterns of possible causes and consequences implies that different intervention strategies should be used when burnout is to be reduced or engagement is to be enhanced. Copyright © 2004 John Wiley &amp; Sons, Ltd.","['Burnout', 'Work engagement', 'Psychology', 'Social psychology', 'Structural equation modeling', 'Employee engagement', 'Clinical psychology', 'Management', 'Chemistry', 'Economics', 'Statistics', 'Mathematics', 'Sense (electronics)', 'Physical chemistry']","burnout, engagement, burnout, engagement, structural equation modeling, occupational samples, burnout, engagement, burnout, burnout, health problems, turnover intention, burnout, health problems, engagement, job resources, turnover intention, burn, engagement, ##out"
Paper_02045,Escherichia coli and Salmonella :cellular and molecular biology,['Frederick C. Neidhardt'],1996,['Biochimie'],Unknown,,857,70,6,10.1016/0300-9084(88)90119-8,"Preface The Enteric Bacterial Cell and the Age of Bacteria Variations on a Theme by Escherichia Part I: Molecular Architecture and Assembly of Cell Parts (11 chapters) Part II: Metabolism and General Physiology (58 chapters) Part III: Utilization of Energy for Cell Activities (7 chapters) Part IV: Regulation of Gene Expression (19 chapters) Part V: Growth of Cells and Cultures (12 chapters) Part VI: Genome, Genetics and Evolution (40 chapters) Part VII: Molecular Pathogenesis (7 chapters)","['Escherichia coli', 'Biology', 'Salmonella', 'Bacteria', 'Genetics', 'Cell metabolism', 'Gene', 'Molecular genetics', 'Theme (computing)', 'Microbiology', 'Computational biology', 'Cell', 'Computer science', 'Operating system']","enteric bacterial cell, molecular architecture, metabolism, general physiology, gene expression, molecular pathogenesis, [PAD]"
Paper_02046,Science in action : how to follow scientists and engineers through society,['Bruno Latour'],1987,['Contemporary Sociology'],Unknown,,788,18,5,10.2307/2073372,"Acknowledgements Introduction Opening Pandora's Black Box PART I FROM WEARER TO STRONGER RHETORIC Chapter I Literature Part A: Controversies Part B: When controversies flare up the literature becomes technical Part C: Writing texts that withstand the assaults of a hostile environment Conclusion: Numbers, more numbers Chapter 2 Laboratories Part A: From texts to things: A showdown Part B: Building up counter-laboratories Part C: Appealing (to) nature PART II FROM WEAR POINTS TO STRONGHOLDS Chapter 3 Machines Introduction: The quandary of the fact-builder Part A: Translating interests Part B: Keeping the interested groups in line Part C: The model of diffusion versus the model of translation Chapter 4 Insiders Out Part A: Interesting others in the laboratories Part B: Counting allies and resources PART III FROM SHORT TO LONGER NETWORKS Chapter 5 Tribunals of Reason Part A: The trials of rationality Part B: Sociologics Part C: Who needs hard facts? Chapter 6 Centres of calculation Prologue: The domestication of the savage mind Part A: Action at a distance Part B: Centres of calculation Part C: Metrologies Appendix 1","['Prologue', 'Rationality', 'Action (physics)', 'Rhetoric', 'Engineering', 'Political science', 'Sociology', 'Epistemology', 'Law', 'Literature', 'Art', 'Philosophy', 'Physics', 'Linguistics', 'Quantum mechanics']","diffusion, translation, tribunal, rationality, sociologic, centres, savage mind, centres, metrologies"
Paper_02047,Social Choice and Individual Values.,"['G. L. S. Shackle', 'Kenneth J. Arrow']",1951,Economica,Journal,,430-430,18,72,10.2307/2549613,"Originally published in 1951, Social Choice and Individual Values introduced Impossibility Theorem and founded the field of social choice theory in economics and political science. This new edition, including a new foreword by Nobel laureate Eric Maskin, reintroduces Arrow's seminal book to a new generation of students and researchers. Far beyond a classic, this small book unleashed the ongoing explosion of interest in social choice and voting theory. A half-century later, the book remains full of profound insight: its central message, 'Arrow's Theorem,' has changed the way we think.-Donald G. Saari, author of Decisions and Elections: Explaining the Unexpected","['Economics', 'Sociology', 'Psychology']","social choice, individual values, impossibility theorem, social choice theory, economics, political science, social choice, voting theory, decisions, [PAD] [PAD], [PAD] [PAD]"
Paper_02048,Symmetric Functions and Hall Polynomials,['I. G. Macdonald'],1995,Oxford University Press eBooks,Unknown,,,,,10.1093/oso/9780198534891.001.0001,"Abstract This is a new and much expanded edition of Professor Macdonald's acclaimed monograph on Symmetric Functions and Hall Polynomials. Almost every chapter has new sections and many new examples have been included throughout. In addition there are two new chapters (6 and 7). Chapter 6 contains an extended account of a family of symmetric functions depending on two parameters. These symmetric functions include as particular cases many of those encountered earlier in the book and they also include, as a limiting case, Jack's symmetric functions depending on a parameter a. Many of the properties of the Schur functions generalize to these two-parameter symmetric functions. Chapter 7 is devoted to the study of the zxonal polynomials, long familiar to staticians. From one point of view, they are a special case of Jack's symmetric functions (the parameter a being equal to 2) but their combinatorial and group-theoretic connections make them worthy of study in their own right.","['Symmetric function', 'Stanley symmetric function', 'Complete homogeneous symmetric polynomial', 'Schur polynomial', 'Ring of symmetric functions', 'Symmetric group', 'Mathematics', 'Elementary symmetric polynomial', 'Pure mathematics', 'Symmetric polynomial', 'Limiting', 'Power sum symmetric polynomial', 'Orthogonal polynomials', 'Combinatorics', 'Algebra over a field', 'Macdonald polynomials', 'Mathematical analysis', 'Polynomial', 'Classical orthogonal polynomials', 'Mechanical engineering', 'Matrix polynomial', 'Engineering']","symmetric functions, hall polynomials, symmetric functions, symmetric functions, symmetric functions, schur functions, zxonal polynomials, static, symmetric functions, [PAD], [PAD] [PAD], [PAD], [PAD], [PAD] [PAD], [PAD], [PAD] [PAD], [PAD], [PAD] [PAD]"
Paper_02049,Handbook of conducting polymers,"['Terje A. Skotheim', 'Ronald L. Elsenbaumer', 'John R. Reynolds']",1986,['IEEE Electrical Insulation Magazine'],Unknown,,37-37,15,1,10.1109/mei.1999.744595,"Volume 1: Conjugated Polymers: Theory, Synthesis, Properties, and Characterization PART 1: THEORY OF CONJUGATED POLYMERS On the Transport, Optical, and Self-Assembly Properties of -Conjugated Materials: A Combined Theoretical/Experimental Insight D. Beljonne, J. Cornil, V. Coropceanu, D.A. da Silva Filho, V. Geskin, R. Lazzaroni, P. Leclere, and J.-L. Bredas Theoretical Studies of Electron-Lattice Dynamics in Organic Systems S. Stafstroem PART 2: SYNTHESIS AND CLASSES OF CONJUGATED POLYMERS Helical Polyacetylene Synthesized in Chiral Nematic Liquid Crystals K. Akagi Synthesis and Properties of Poly(arylene vinylene)s A.C. Grimsdale and A.B. Holmes Blue-Emitting Poly(para-Phenylene)-Type Polymers E.J.W. List and U. Scherf Poly(paraPhenyleneethynylene)s and Poly(aryleneethynylene)s: Materials with a Bright Future U.H.F. Bunz Polyaniline Nanofibers: Synthesis, Properties, and Applications J. Huang and R.B. Kaner Recent Advances in Polypyrrole S.H. Cho, K.T. Song, and J.Y. Lee Regioregular Polythiophenes M. Jeffries-El and R.D. McCullough Poly(3,4-Ethylenedioxythiophene)-Scientific Importance, Remarkable Properties, and Applications S. Kirchmeyer, K. Reuter, and J.C. Simpson Thienothiophenes: From Monomers to Polymers G.A. Sotzing, V. Seshadri, and F.J. Waller Low Bandgap Conducting Polymers S.C. Rasmussen and M. Pomerantz Advanced Functional Polythiophenes Based on Tailored Precursors P. Blanchard, P. Leriche, P. Frere, and J. Roncali Structure-Property Relationships and Applications of Conjugated Polyelectrolytes K.S. Schanze and X. Zhao PART 3: PROPERTIES AND CHARACTERIZATION OF CONJUGATED POLYMERS Insulator-Metal Transition and Metallic State in Conducting Polymers A.J. Epstein One-Dimensional Charge Transport in Conducting Polymer Nanofibers A.N. Aleshin and Y.W. Park Structure Studies of - and - Conjugated Polymers M.J. Winokur Electrochemistry of Conducting Polymers P. Audebert and F. Miomandre Internal Fields and Electrode Interfaces in Organic Semiconductor Devices: Noninvasive Investigations via Electroabsorption T.M. Brown and F. Cacialli Electrochromism of Conjugated Conducting Polymers A.L. Dyer and J.R. Reynolds Photoelectron Spectroscopy of Conjugated Polymers M.P. de Jong, G. Greczyniski, W. Osikowicz, R. Friedlein, X. Crispin, M. Fahlman, and W.R. Salaneck Ultrafast Exciton Dynamics and Laser Action in -ConjugatedSemiconductors Z. Valy Vardeny and O. Korovyanko Volume 2: Conjugated Polymers: Processing and Applications PART 1: PROCESSING OF CONJUGATED POLYMERS Conductive Polymers as Organic Nanometals B. Wessling Conducting Polymer Fiber Production and Applications I.D. Norris and B.R. Mattes Inkjet Printing and Patterning of PEDOT-PSS: Application to Optoelectronic Devices Y. Yoshioka and G.E. Jabbour Printing Organic Electronics on Flexible Substrates N.D. Robinson and M. Berggren PART 2: APPLICATIONS AND DEVICES BASED ON CONJUGATED POLYMERS Polymers for Use in Polymeric Light-Emitting Diodes: Structure-Property Relationships H. Christian-Pandya, S. Vaidyanathan, and M. Galvin Organic Electro-Optic Materials L.R. Dalton Conjugated Polymer Electronics-Engineering Materials and Devices N. Tessler, J. Veres, O. Globerman, N. Rappaport, Y. Preezant, Y. Roichman, O. Solomesch, S. Tal, E. Gershman, M. Adler, V. Zolotarev, V. Gorelik, and Y. Eichen Electrical Bistable Polymer Films and Their Applications in Memory Devices J. Ouyang, C.-W. Chu, R.J. Tseng, A. Prakash, and Y. Yang Electroactive Polymers for Batteries and Supercapacitors J.A. Irvin, D.J. Irvin, and J.D. Stenger-Smith Conjugated Polymer-Based Photovoltaic Devices A.J. Mozer and N.S. Sariciftci Biomedical Applications of Inherently Conducting Polymers (ICPs),P.C. Innis, S.E. Moulton, and G.G. Wallace Biosensors Based on Conducting Electroactive Polymers S. Brahim, A.M. Wilson, and A. Guiseppi-Elie Optical Biosensors Based on Conjugated Polymers K. Peter, R. Nilsson, and O. Inganas Conjugated Polymers for Microelectromechanical and Other Microdevices G.M. Spinks and E. Smela Corrosion Protection Using Conducting Polymers D.E. Tallman and G.P. Bierwagen Artificial Muscles T.F. Otero","['Polyacetylene', 'Polymer', 'Materials science', 'Conjugated system', 'Polymer chemistry', 'Conductive polymer', 'Arylene', 'Monomer', 'Condensation polymer', 'Polymer science', 'Nanotechnology', 'Chemistry', 'Organic chemistry', 'Aryl', 'Composite material', 'Alkyl']","conjugated polymers, conjugated polymers, con, ##gated polymers, ##l polyace, chiral nematic liquid crystals, functional poly, tailored precursors, ##gated, conducting polymers, conducting polymer"
Paper_02050,The Death and Life of Great American Cities,['Jane Jacobs'],2015,"John Wiley & Sons, Ltd eBooks",Unknown,,94-109,,,10.1002/9781119084679.ch4,1 Introduction Part One: The Peculiar Nature of Cities 2 The uses of sidewalks: safety 3 The uses of sidewalks: contact 4 The uses of sidewalks: assimilating children 5 The uses of neighbourhood parks 6 The uses of city neighbourhoods. Part Two: The Conditions for City Diversity 7 The generators of diversity 8 The need for mixed primary uses 9 The need for small blocks 10 The need for aged buildings 11 The need for concentration 12 Some myths about diversity. Part Three: Forces of Decline and Regeneration 13 The self-destruction of diversity 14 The curse of border vacuums 15 Unslumming and slumming 16 Gradual money and cataclysmic money. Part Four: Different Tactics 17 Subsidizing dwellings 18 Erosion of cities or attrition of automobiles 19 Visual order: its limitations and possibilities 20 Salvaging projects 21 Governing and planning districts 22 The kind of problem a city is Index.,"['History', 'Geography']","sidewalks, safety, sidewalks, sidewalks, neighbourhood parks, city neighbourhoods, city diversity, mixed primary uses, aged buildings, regeneration, border vacuums, gradual money, cataclysmic money, sub, ##ging, planning districts"
Paper_02052,Reinforcement Learning: A Survey,"['Leslie Pack Kaelbling', 'Michael L. Littman', 'Andrew Moore']",1996,Journal of Artificial Intelligence Research,Journal,,237-285,4,,10.1613/jair.301,"This paper surveys the field of reinforcement learning from a computer-science perspective. It is written to be accessible to researchers familiar with machine learning. Both the historical basis of the field and a broad selection of current work are summarized. Reinforcement learning is the problem faced by an agent that learns behavior through trial-and-error interactions with a dynamic environment. The work described here has a resemblance to work in psychology, but differs considerably in the details and in the use of the word ``reinforcement.'' The paper discusses central issues of reinforcement learning, including trading off exploration and exploitation, establishing the foundations of the field via Markov decision theory, learning from delayed reinforcement, constructing empirical models to accelerate learning, making use of generalization and hierarchy, and coping with hidden state. It concludes with a survey of some implemented systems and an assessment of the practical utility of current methods for reinforcement learning.","['Reinforcement learning', 'Computer science', 'Reinforcement', 'Artificial intelligence', 'Markov decision process', 'Field (mathematics)', 'Perspective (graphical)', 'Machine learning', 'Hierarchy', 'Generalization', 'Markov process', 'Psychology', 'Social psychology', 'Mathematical analysis', 'Statistics', 'Mathematics', 'Economics', 'Pure mathematics', 'Market economy']","reinforcement learning, machine learning, reinforcement learning, dynamic environment, reinforcement learning, markov decision theory, delayed reinforcement, ##ization, hierarchy, hidden state, reinforcement learning"
Paper_02053,Earnings Management During Import Relief Investigations,['Jennifer Jones'],1991,Journal of Accounting Research,Journal,,193-193,29,2,10.2307/2491047,"This study tests whether firms that would benefit from import relief (e.g., tariff increases and quota reductions) attempt to decrease earnings through earnings management during import relief investigations by the United States International Trade Commission (ITC). The import relief determination made by the ITC is based on several factors that are specified in the federal trade acts, including the profitability of the industry. Explicit use of accounting numbers in import relief regulation provides incentives for managers to manage earnings in order to increase the likelihood of obtaining import relief and/or increase the amount of relief granted. While studies of earnings management typically examine situations in which all contracting parties have incentives to perfectly monitor (adjust) accounting numbers for such manipulation, import relief investigations provide a specific motive for earnings management that is not","['Business', 'Earnings management', 'Earnings', 'Accounting', 'Finance']","import relief, tariff increases, quota reductions, earnings management, import relief investigations, united states international trade commission, it, import, federal trade acts, profit, accounting numbers, import relief regulation, earnings management, import, earnings management, [PAD], [PAD], [PAD], [PAD], [PAD] [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD], [PAD], [PAD] [PAD] [PAD], [PAD]"
Paper_01992,Photonic Crystals: Molding the Flow of Light,"['John D. Joannopoulos', 'Steven G. Johnson', 'Joshua N. Winn', 'Robert D. Meade']",1995,['Conference on Lasers and Electro-Optics'],Unknown,,FM2G.3,,,10.1364/cleo_qels.2017.fm2g.3,"Since it was first published in 1995, Photonic Crystals has remained the definitive text for both undergraduates and researchers on photonic band-gap materials and their use in controlling the propagation of light. This newly expanded and revised edition covers the latest developments in the field, providing the most up-to-date, concise, and comprehensive book available on these novel materials and their applications. Starting from Maxwell's equations and Fourier analysis, the authors develop the theoretical tools of photonics using principles of linear algebra and symmetry, emphasizing analogies with traditional solid-state physics and quantum theory. They then investigate the unique phenomena that take place within photonic crystals at defect sites and surfaces, from one to three dimensions. This new edition includes entirely new chapters describing important hybrid structures that use band gaps or periodicity only in some directions: periodic waveguides, photonic-crystal slabs, and photonic-crystal fibers. The authors demonstrate how the capabilities of photonic crystals to localize light can be put to work in devices such as filters and splitters. A new appendix provides an overview of computational methods for electromagnetism. Existing chapters have been considerably updated and expanded to include many new three-dimensional photonic crystals, an extensive tutorial on device design using temporal coupled-mode theory, discussions of diffraction and refraction at crystal interfaces, and more. Richly illustrated and accessibly written, Photonic Crystals is an indispensable resource for students and researchers.Extensively revised and expanded Features improved graphics throughout Includes new chapters on photonic-crystal fibers and combined index-and band-gap-guiding Provides an introduction to coupled-mode theory as a powerful tool for device design Covers many new topics, including omnidirectional reflection, anomalous refraction and diffraction, computational photonics, and much more.","['Photonic crystal', 'Photonics', 'Yablonovite', 'Photonic metamaterial', 'Optics', 'Optoelectronics', 'Physics', 'Photonic integrated circuit']","photonic crystals, fourier analysis, photonics, linear algebra, symmetry, quantum, photonic crystals, hybrid structures, band gaps, periodicity, periodic waveguides, photonic crystals, filters, splitters, computational methods, electromagnetism, device design, diff, photonic crystals, device, omnidirectional reflection, anomalous, diff, computational photonics"
Paper_01993,RADAR: an in-building RF-based user location and tracking system,"['Paramvir Bahl', 'Venkat Padmanabhan']",2002,Unknown,Unknown,,775-784,2,,10.1109/infcom.2000.832252,"The proliferation of mobile computing devices and local-area wireless networks has fostered a growing interest in location-aware systems and services. In this paper we present RADAR, a radio-frequency (RF)-based system for locating and tracking users inside buildings. RADAR operates by recording and processing signal strength information at multiple base stations positioned to provide overlapping coverage in the area of interest. It combines empirical measurements with signal propagation modeling to determine user location and thereby enable location-aware services and applications. We present experimental results that demonstrate the ability of RADAR to estimate user location with a high degree of accuracy.","['Computer science', 'Radar', 'Real-time computing', 'Base station', 'Radar tracker', 'Location-based service', 'Fire-control radar', 'Man-portable radar', 'Tracking (education)', 'Radio frequency', 'Radio propagation', 'Continuous-wave radar', 'Telecommunications', 'Radar imaging', 'Psychology', 'Pedagogy']","mobile computing devices, radar, radar, signal strength information, overlapping coverage, empirical measurements, signal propagation modeling, radar"
Paper_01994,The Genotype-Tissue Expression (GTEx) project,"['John T. Lonsdale', 'Jeffrey Thomas', 'Mike Salvatore', 'Rebecca Phillips', 'Edmund Lo', 'Saboor Shad', 'Richard Hasz', 'Gary Walters', 'Fernando U. Garcia', 'Nancy Young', 'Barbara A. Foster', 'Mike Moser', 'Ellen Karasik', 'Bryan M. Gillard', 'Kimberley Ramsey', 'Susan Sullivan', 'Jason Bridge', 'Harold I. Magazine', 'John Syron', 'Johnelle Fleming', 'Laura A. Siminoff', 'Heather M. Traino', 'Maghboeba Mosavel', 'Laura K. Barker', 'Scott D. Jewell', 'Dan Rohrer', 'Dan Maxim', 'Dana Filkins', 'P.R. Harbach', 'Eddie Cortadillo', 'Bree D. Berghuis', 'Lisa Turner', 'Eric A. Hudson', 'Kristin Feenstra', 'Leslie H. Sobin', 'James Robb', 'Phillip Branton', 'Greg E. Korzeniewski', 'Charles Shive', 'David E. Tabor', 'Liqun Qi', 'Kevin Groch', 'Sreenath Nampally', 'Steve Buia', 'Angela Zimmerman', 'Anna M. Smith', 'Robin Burges', 'Karna Robinson', 'Kim Valentino', 'Deborah Bradbury', 'Mark Cosentino', 'Norma Diaz-Mayoral', 'Mary Kennedy', 'Theresa Engel', 'Penelope Williams', 'Kenyon Erickson', 'Kristin Ardlie', 'Wendy Winckler', 'Gad Getz', 'David S. DeLuca', 'Daniel G. MacArthur', 'Manolis Kellis', 'Alexander Thomson', 'Taylor Young', 'Ellen Gelfand', 'Molly Donovan', 'Yan Meng', 'George Grant', 'Deborah C. Mash', 'Yvonne Marcus', 'Margaret J. Basile', 'Jun S. Liu', 'Jun Zhu', 'Zhidong Tu', 'Nancy J. Cox', 'Dan L. Nicolae', 'Eric R. Gamazon', 'Hae Kyung Im', 'Anuar Konkashbaev', 'Jonathan K. Pritchard', 'Matthew Stevens', 'Timothée Flutre', 'Xiaoquan Wen', 'Emmanouil T. Dermitzakis', 'Tuuli Lappalainen', 'Roderic Guigó', 'Jean Monlong', 'Michael Sammeth', 'Daphne Koller', 'Alexis Battle', 'Sara Mostafavi', 'Mark I. McCarthy', 'Manual Rivas', 'Julian Maller', 'Ivan Rusyn', 'Andrew B. Nobel', 'Fred A. Wright', 'Andrey A. Shabalin', 'Mike Feolo', 'Nataliya Sharopova']",2013,Nature Genetics,Journal,,580-585,45,6,10.1038/ng.2653,"Genome-wide association studies have identified thousands of loci for common diseases, but, for the majority of these, the mechanisms underlying disease susceptibility remain unknown. Most associated variants are not correlated with protein-coding changes, suggesting that polymorphisms in regulatory regions probably contribute to many disease phenotypes. Here we describe the Genotype-Tissue Expression (GTEx) project, which will establish a resource database and associated tissue bank for the scientific community to study the relationship between genetic variation and gene expression in human tissues.","['Biology', 'Genetics', 'Genome-wide association study', 'Genotype', 'Phenotype', 'Gene', 'Expression quantitative trait loci', 'Disease', 'Genetic association', 'Genome', 'Computational biology', 'Human genome', 'Genetic variation', 'Single-nucleotide polymorphism', 'Medicine', 'Pathology']","poly, resource database, associated tissue bank, genetic variation"
Paper_01995,Double-slit photoelectron interference in strong-field ionization of the neon dimer,"['M. Kunitski', 'Nicolas Eicke', 'P. Huber', 'Jonas Köhler', 'S. Zeller', 'J. Voigtsberger', 'Nikolai Schlott', 'K. Henrichs', 'H. Sann', 'Florian Trinter', 'Lothar Schmidt', 'Anton Kalinin', 'M. S. Schöffler', 'T. Jahnke', 'Manfred Lein', 'R. Dörner']",2018,Nature Communications,Journal,,,10,1,10.1038/s41467-018-07882-8,"Wave-particle duality is an inherent peculiarity of the quantum world. The double-slit experiment has been frequently used for understanding different aspects of this fundamental concept. The occurrence of interference rests on the lack of which-way information and on the absence of decoherence mechanisms, which could scramble the wave fronts. In this letter, we report on the observation of two-center interference in the molecular frame photoelectron momentum distribution upon ionization of the neon dimer by a strong laser field. Postselection of ions, which were measured in coincidence with electrons, allowed choosing the symmetry of the continuum electronic wave function, leading to observation of both, gerade and ungerade, types of interference.","['Neon', 'Double-slit experiment', 'Physics', 'Ionization', 'Interference (communication)', 'Atomic physics', 'Electron', 'Ion', 'Field (mathematics)', 'Momentum (technical analysis)', 'Quantum mechanics', 'Quantum', 'Channel (broadcasting)', 'Argon', 'Electrical engineering', 'Engineering', 'Mathematics', 'Finance', 'Pure mathematics', 'Economics']","quantum world, decoherence mechanisms, molecular frame photoelectron momentum distribution, neon dimer, strong laser field, posts, ##ction, continuum electronic wave function, [PAD], [PAD]"
Paper_01997,Describing the uncertainties in experimental results,['R. J. Moffat'],1988,Experimental Thermal and Fluid Science,Journal,,3-17,1,1,10.1016/0894-1777(88)90043-x,"It is no longer acceptable, in most circles, to present experimental results without describing the uncertainties involved. Besides its obvious role in publishing, uncertainty analysis provides the experimenter a rational way of evaluating the significance of the scatter on repeated trials. This can be a powerful tool in locating the source of trouble in a misbehaving experiment. To the user of the data, a statement (by the experimenter) of the range within which the results of the present experiment might have fallen by chance alone is of great help in deciding whether the present data agree with past results or differ from them. These benefits can be realized only if both the experimenter and the reader understand what an uncertainty analysis is, what it can do (and cannot do), and how to interpret its results. This paper begins with a general description of the sources of errors in engineering measurements and the relationship between error and uncertainty. Then the path of an uncertainty analysis is traced from its first step, identifying the intended true value of a measurement, through the quantitative estimation of the individual errors, to the end objective—the interpretation and reporting of the results. The basic mathematics of both single-sample and multiple-sample analysis are presented, as well as a technique for numerically executing uncertainty analyses when computerized data interpretation is involved. The material presented in this paper covers the method of describing the uncertainties in an engineering experiment and the necessary background material.","['Computer science', 'Interpretation (philosophy)', 'Sample (material)', 'Range (aeronautics)', 'Statement (logic)', 'Uncertainty analysis', 'Propagation of uncertainty', 'Data mining', 'Data science', 'Experimental data', 'Econometrics', 'Industrial engineering', 'Statistics', 'Algorithm', 'Simulation', 'Mathematics', 'Epistemology', 'Philosophy', 'Chemistry', 'Materials science', 'Chromatography', 'Engineering', 'Composite material', 'Programming language']","uncertainty analysis, uncertainty analysis, engineering measurements, uncertainty analysis, quantitative estimation, uncertainty analyses, computerized data interpretation"
Paper_01999,Pseudoreplication and the Design of Ecological Field Experiments,['Stuart H. Hurlbert'],1984,Ecological Monographs,Journal,,187-211,54,2,10.2307/1942661,"Pseudoreplication is defined as the use of inferential statistics to test for treatment effects with data from experiments where either treatments are not replicated (though samples may be) or replicates are not statistically independent. In ANOVA terminology, it is the testing for treatment effects with an error term inappropriate to the hypothesis being considered. Scrutiny of 176 experimental studies published between 1960 and the present revealed that pseudoreplication occurred in 27% of them, or 48% of all such studies that applied inferential statistics. The incidence of pseudoreplication is especially high in studies of marine benthos and small mammals. The critical features of controlled experimentation are reviewed. Nondemonic intrusion is defined as the impingement of chance events on an experiment in progress. As a safeguard against both it and preexisting gradients, interspersion of treatments is argued to be an obligatory feature of good design. Especially in small experiments, adequate interspersion can sometimes be assured only by dispensing with strict randomization procedures. Comprehension of this conflict between interspersion and randomization is aided by distinguishing pre—layout (or conventional) and layout—specific alpha (probability of type I error). Suggestions are offered to statisticians and editors of ecological journals as to how ecologists' understanding of experimental design and statistics might be improved.","['Ecology', 'Type I and type II errors', 'Statistics', 'Terminology', 'Statistical hypothesis testing', 'Computer science', 'Biology', 'Mathematics', 'Philosophy', 'Linguistics']","pseudoreplication, inferential statistics, treatment effects, anova, treatment effects, pseudoreplication, inferential statistics, pseudoreplication, marine benthos, small mammals, controlled experimentation, nondemonic intrusion, chance events, preexisting, interspersion, interspersion, strict randomization procedures, interspersion, randomization, pre, stat, ecological journals, eco, experimental design, [PAD] [PAD] [PAD], [PAD] [PAD] [PAD], [PAD], [PAD] [PAD], [PAD] [PAD] [PAD], [PAD] [PAD], [PAD], [PAD], [PAD], [PAD], [PAD] [PAD], [PAD] [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD], [PAD], [PAD] [PAD] [PAD], [PAD] [PAD]"
Paper_02001,A First Course in Turbulence,"['Henk Tennekes', 'John L. Lumley']",1972,Unknown,Unknown,,,,,10.7551/mitpress/3014.001.0001,"This is the first book specifically designed to offer the student a smooth transitionary course between elementary fluid dynamics (which gives only last-minute attention to turbulence) and the professional literature on turbulent flow, where an advanced viewpoint is assumed.The subject of turbulence, the most forbidding in fluid dynamics, has usually proved treacherous to the beginner, caught in the whirls and eddies of its nonlinearities and statistical imponderables. This is the first book specifically designed to offer the student a smooth transitionary course between elementary fluid dynamics (which gives only last-minute attention to turbulence) and the professional literature on turbulent flow, where an advanced viewpoint is assumed. Moreover, the text has been developed for students, engineers, and scientists with different technical backgrounds and interests. Almost all flows, natural and man-made, are turbulent. Thus the subject is the concern of geophysical and environmental scientists (in dealing with atmospheric jet streams, ocean currents, and the flow of rivers, for example), of astrophysicists (in studying the photospheres of the sun and stars or mapping gaseous nebulae), and of engineers (in calculating pipe flows, jets, or wakes). Many such examples are discussed in the book. The approach taken avoids the difficulties of advanced mathematical development on the one side and the morass of experimental detail and empirical data on the other. As a result of following its midstream course, the text gives the student a physical understanding of the subject and deepens his intuitive insight into those problems that cannot now be rigorously solved. In particular, dimensional analysis is used extensively in dealing with those problems whose exact solution is mathematically elusive. Dimensional reasoning, scale arguments, and similarity rules are introduced at the beginning and are applied throughout. A discussion of Reynolds stress and the kinetic theory of gases provides the contrast needed to put mixing-length theory into proper perspective: the authors present a thorough comparison between the mixing-length models and dimensional analysis of shear flows. This is followed by an extensive treatment of vorticity dynamics, including vortex stretching and vorticity budgets. Two chapters are devoted to boundary-free shear flows and well-bounded turbulent shear flows. The examples presented include wakes, jets, shear layers, thermal plumes, atmospheric boundary layers, pipe and channel flow, and boundary layers in pressure gradients. The spatial structure of turbulent flow has been the subject of analysis in the book up to this point, at which a compact but thorough introduction to statistical methods is given. This prepares the reader to understand the stochastic and spectral structure of turbulence. The remainder of the book consists of applications of the statistical approach to the study of turbulent transport (including diffusion and mixing) and turbulent spectra.","['Turbulence', 'Eddy', 'Subject (documents)', 'Course (navigation)', 'Mechanics', 'Physics', 'Natural (archaeology)', 'Meteorology', 'Theoretical physics', 'Engineering', 'Computer science', 'Geology', 'Astronomy', 'Library science', 'Paleontology']","elementary fluid dynamics, turbulent flow, turbulence, fluid dynamics, statistical, turbulent flow, atmospheric jet streams, ocean currents, astro, gas, pipe flows, wakes, dimensional analysis, dimensional reasoning, scale arguments, similarity rules, reynolds stress, kinetic theory, gases, shear flows, vorticity dynamics, vortex stretching, vorticity budgets, wakes, jets, shear layers, thermal plumes, atmospheric boundary layers, channel flow, boundary layers, pressure gradients, statistical methods"
Paper_02004,Applications of case study research,['Robert K. Yin'],1993,['Remediation of Soil and Groundwater'],Unknown,,355-378,,,10.1007/978-94-009-0319-7_24,"Theory The Role of Theory in Doing Case Studies What is the Case Study Method? What is the Role of Theory in Doing Case Studies Exploratory Case Studies Case Selection and Screening: Criteria and Procedures Causal Case Studies I: Factor Theories Causal Case Studies II: Explanatory Theories Descriptive Scase Studies Conclusions Descriptive Case Studies A Case Study of a Neighborhood Organization Initiation and Structure of the Organization Revitalization Activities and Their Support Relationship to Voluntary Associations and Networks Relationship to City Government Outcomes List of Respondents and Annotated Bibliography Computer Implementation in a Local School System The Computer System in Operation Organizational Issues Explanatory Case Studies A Nutshell Example: The Effect of a Federal Award on a University Computer Science Department Essential Ingredients of Explanatory Case Studies: Three Drug Prevention Examples Simplified Case Example No. 1: Town Meetings Galvanize Action Against Drug Dealing Simplified Case Example No. 2: Interagency Collaboration to Reduce BWI Incidents Simplified Case Example No. 3: Designated Driver Program, Delivered Through Vendors Transforming a Business Firm Through Strategic Planning Company Profile and Conditions Leading to Change Strategic Plan Transforms the Business Chronology Sheriff's Combined Auto Theft Task Force The Practice and Its Funding Implementation of the Practice Outcomes to Date Chronology Cross-Case Analyses Technical Assistance for HIV/AIDS Community Planning Defining a Framework for Assessing the Effectiveness of Technical Assistance (TA) Documented Outcomes, Varieties of TA Studied and Possible Rival Explanations for the Outcomes Findings on Individual Hypotheses Regarding Reasons for Successful TA Delivery Proposal Processing by Public and Private Universities Introduction to the Study The Time Needed to Process and Submit Proposals Costs of Preparing Proposals Case Studies of Transformed Firms Why Study Transformed Firms? What is a Transformed Firm? What Kind of Transformation Did the Firms Experience? Did the Transformations Share Common Conditions Summary: General Lessons About Transformed Firms About the author","['Government (linguistics)', 'Exploratory research', 'Action (physics)', 'Public relations', 'Psychology', 'Political science', 'Sociology', 'Social science', 'Philosophy', 'Linguistics', 'Physics', 'Quantum mechanics']","##tory, neighborhood organization, city government, local school system, drug, town meetings, interagency collaboration, ##wi, designated driver"
Paper_02006,Emotion Circuits in the Brain,['Joseph E. LeDoux'],2000,Annual Review of Neuroscience,Journal,,155-184,23,1,10.1146/annurev.neuro.23.1.155,"The field of neuroscience has, after a long period of looking the other way, again embraced emotion as an important research area. Much of the progress has come from studies of fear, and especially fear conditioning. This work has pinpointed the amygdala as an important component of the system involved in the acquisition, storage, and expression of fear memory and has elucidated in detail how stimuli enter, travel through, and exit the amygdala. Some progress has also been made in understanding the cellular and molecular mechanisms that underlie fear conditioning, and recent studies have also shown that the findings from experimental animals apply to the human brain. It is important to remember why this work on emotion succeeded where past efforts failed. It focused on a psychologically well-defined aspect of emotion, avoided vague and poorly defined concepts such as “affect,” “hedonic tone,” or “emotional feelings,” and used a simple and straightforward experimental approach. With so much research being done in this area today, it is important that the mistakes of the past not be made again. It is also time to expand from this foundation into broader aspects of mind and behavior","['Amygdala', 'Psychology', 'Neuroscience', 'Feeling', 'Fear processing in the brain', 'Affective neuroscience', 'Cognitive psychology', 'Fear conditioning', 'Affective science', 'Affect (linguistics)', 'Cognitive science', 'Emotionality', 'Cognition', 'Social psychology', 'Communication']","neuroscience, emotion, fear, fear conditioning, amygdala, fear memory, fear conditioning, human brain, emotion, emotion, “ affect, hedonic tone, emotional feelings"